"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"2I36X2AP","journalArticle","2022","Deng, ZL; Zhou, B; He, P; Huang, JF; Alfarraj, O; Tolba, A","A Position-Aware Transformer for Image Captioning","CMC-COMPUTERS MATERIALS & CONTINUA","","1546-2218","10.32604/cmc.2022.019328","","Image captioning aims to generate a corresponding description of an image. In recent years, neural encoder-decoder models have been the dominant approaches, in which the Convolutional Neural Network (CNN) and Long Short Term Memory (LSTM) are used to translate an image into a natural language description. Among these approaches, the visual attention mechanisms are widely used to enable deeper image understanding through fine-grained analysis and even multiple steps of reasoning. However, most conventional visual attention mechanisms are based on high-level image features, ignoring the effects of other image features, and giving insufficient consideration to the relative positions between image features. In this work, we propose a Position Aware Transformer model with image-feature attention and position-aware attention mechanisms for the above problems. The image-feature attention firstly extracts multi-level features by using Feature Pyramid Network (FPN), then utilizes the scaled-dot-product to fuse these features, which enables our model to detect objects of different scales in the image more effectively without increasing parameters. In the position-aware attention mechanism, the relative positions between image features are obtained at first, afterwards the relative positions are incorporated into the original image features to generate captions more accurately. Experiments are carried out on the MSCOCO dataset and our approach achieves competitive BLEU-4, METEOR, ROUGE-L, CIDEr scores compared with some state-of-the-art approaches, demonstrating the effectiveness of our approach.","2022","2025-02-26 20:43:25","2025-02-26 20:43:25","","2065-2081","","1","70","","","","","","","","","","English","","","","WOS:000709118000035","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","attention; Deep learning; image captioning; position-aware; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CBM4UGQ5","journalArticle","2024","Hayashi, Y; Kondo, Y; Ishii, Y","Automated speech scoring of dialogue response by Japanese learners of English as a foreign language","INNOVATION IN LANGUAGE LEARNING AND TEACHING","","1750-1229","10.1080/17501229.2023.2217181","","Purpose: This study builds a new system for automatically assessing learners' speech elicited from an oral discourse completion task (DCT), and evaluates the prediction capability of the system with a view to better understanding factors deemed influential in predicting speaking proficiency scores and the pedagogical implications of the system. Methodology: We developed a system with a tripartite structure using an automatic speech recogniser, a set of modules that compute a number of speech features, and a scoring model. In total, 210 participants with intermediate English language proficiency level were administered a multi-turn oral DCT, a task which closely resembles discourse in real-life situations. The collected speech and transcribed files were eyeballed and rated by human raters first. Eighty percent of the original dataset was then used to train and examine our prediction model against the remainder of the dataset. Findings: The exact agreement between human and machine scores was 72%, moderately high, and comparable to the literature on automated speech scoring. It could provide a basis for deploying the system in a low-stakes practice environment. Originality/value: This study makes a unique contribution to the wider scholarship, where the use of single-turn DCTs remains prevalent, by presenting a new reliable scoring system for learner speech using an automated DCT with multiple turns. It offers useful insight into ways in which the system could be used in a low-stakes environment, including foreign language classroom settings.","2024-01-01","2025-02-26 20:43:25","2025-02-26 20:43:25","","32-46","","1","18","","","","","","","","","","English","","","","WOS:000996108800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Automated scoring system; automatic speech recognition; discourse completion task; intelligibility; SCORES; speaking proficiency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KNTJP7I3","journalArticle","2024","Ali, J; Saleem, N; Bourouis, S; Alabdulkreem, E; El Mannai, H; Dhahbi, S","Spatio-Temporal Features Representation Using Recurrent Capsules for Monaural Speech Enhancement","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3361286","","Single-channel speech enhancement is important for modern communication systems and has received a lot of attention. A convolutional neural network (CNN) successfully learns feature representations from speech spectrograms but loses spatial information due to distortion, which is important for humans to understand speech. Speech feature learning is an important ongoing research to capture higher-level representations of speech that go beyond conventional techniques. By considering the hierarchical structure and temporal relationships within speech signals, capsule networks (CapsNets) have the potential to provide more expressive and context-aware feature representations. By considering the advantages of CapNets over CNN, this study presents a model for monaural speech enhancement that keeps spatial information in a capsule and uses dynamic routing to pass it to higher layers. Dynamic routing replaces the pooling recurrent hidden states to get speech features from the outputs of the capsule. Leveraging long-term contexts provides identification of the target speaker. Therefore, a gated recurrent layer, gated recurrent unit (GRU), or long-short-term memory (LSTM), is placed above the CNN module and next to the capsule module in the architecture. This makes it viable to extract spatial features and long-term temporal dynamics. The suggested convolutional recurrent CapNet performs better compared to the models based on CNNs and recurrent neural networks. The suggested speech enhancement produces considerably better speech quality and intelligibility. With the LibriSpeech and VoiceBank+DEMAND databases, the suggested speech enhancement improves the intelligibility and quality by 18.33% and (0.94) 36.82% over the noisy mixtures.","2024","2025-02-26 20:43:25","2025-02-26 20:43:25","","21287-21303","","","12","","","","","","","","","","English","","","","WOS:001163608200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;84</p>","","","A-PRIORI SNR; capsule networks; CONVOLUTIONAL NEURAL-NETWORK; convolutional recurrent networks; MODEL; recurrent capsules; Speech enhancement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"86K7A4MA","journalArticle","2021","Wang, TL; Cao, JW; Pei, LY","A Novel Underground Pipeline Surveillance System Based on Hybrid Acoustic Features","IEEE SENSORS JOURNAL","","1530-437X","10.1109/JSEN.2020.3009112","","Underground pipeline network suffers severe damages caused by construction machines used in the rapid urbanization development and construction, leading to profound impact to people's life. An intelligent construction machinery classification (CMC) system thus becomes important to urban security and smart city engineering. Conventional methods are always problematic in one way or another. For instance, the one-dimensional speech features based recognition algorithms are usually less discriminative in the complex urban acoustic environment, and the two-dimensional spectrogram based convolution neural network (CNN) suffers a long model learning time and is less robust to the background noises. To address these deficiencies, a novel CMC system based on new hybrid acoustic features is presented. Two novel acoustic feature extraction methods are developed, where the first explores the concentrations of the Mel-frequency spectrogram (MFS) using the statistics of the binary MFS (SBMS) and the second characterizes the information entropy sequence feature of the binary MFS (IESF) based on the pulse-coupled neural network (PCNN) model. Then, the hybrid features of SBMS/IESF and the Linear Prediction Cepstral Coefficients (LPCC)/Mel-Frequency Cepstral Coefficients (MFCC) are further studied. A database consisting of 84,900 acoustic samples from 6 typical construction machines, horns of vehicles and other urban noises is recorded for experiment and performance validation. The comparisons with many state-of-the-art algorithms demonstrate the superiority of the proposed method.","2021-01-15","2025-02-26 20:43:25","2025-02-26 20:43:25","","1040-1050","","2","21","","","","","","","","","","English","","","","WOS:000600900300018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","acoustic spectrogram; ALGORITHM; construction machinery classification; Feature extraction; IESF; INPUT; MACHINE; Mel frequency cepstral coefficient; Neural networks; PCNN; Pipelines; RECOGNITION; SBMS; SCALE; Spectrogram; Surveillance; Underground pipeline surveillance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M5V54GEE","journalArticle","2024","Alduais, A; Alfadda, H","Childhood Apraxia of Speech: A Descriptive and Prescriptive Model of Assessment and Diagnosis","BRAIN SCIENCES","","2076-3425","10.3390/brainsci14060540","","Childhood apraxia of speech (CAS) represents a significant diagnostic and therapeutic challenge within the field of clinical neuropsychology, characterized by its nuanced presentation and multifactorial nature. The aim of this study was to distil and synthesize the broad spectrum of research into a coherent model for the assessment and diagnosis of CAS. Through a mixed-method design, the quantitative phase analyzed 290 studies, unveiling 10 clusters: developmental apraxia, tabby talk, intellectual disabilities, underlying speech processes, breakpoint localization, speech characteristics, functional characteristics, clinical practice, and treatment outcome. The qualitative phase conducted a thematic analysis on the most cited and recent literature, identifying 10 categories: neurobiological markers, speech motor control, perceptual speech features, auditory processing, prosody and stress patterns, parent- and self-report measures, intervention response, motor learning and generalization, comorbidity analysis, and cultural and linguistic considerations. Integrating these findings, a descriptive and prescriptive model was developed, encapsulating the complexities of CAS and providing a structured approach for clinicians. This model advances the understanding of CAS and supports the development of targeted interventions. This study concludes with a call for evidence-based personalized treatment plans that account for the diverse neurobiological and cultural backgrounds of children with CAS. Its implications for practice include the integration of cutting-edge assessment tools that embrace the heterogeneity of CAS presentations, ensuring that interventions are as unique as the children they aim to support.","2024-06","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","6","14","","","","","","","","","","English","","","","WOS:001254670700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","apraxia of speech; assessment model; childhood apraxia; CHILDREN; cultural diversity; DEVELOPMENTAL APRAXIA; DISORDERS; DYSPRAXIA; FREQUENCY; LANGUAGE; neurobiological markers; SCALE; speech motor control; SYLLABLE TRANSITION TREATMENT; TOOL; TRIAL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BSEVYPZ7","journalArticle","2021","Ayo, FE; Folorunso, O; Ibharalu, FT; Osinuga, IA; Abayomi-Alli, A","A probabilistic clustering model for hate speech classification in twitter","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2021.114762","","The key challenges for automatic hate-speech classification in Twitter are the lack of generic architecture, imprecision, threshold settings and fragmentation issues. Most studies used binary classifiers for hate speech classification, but these classifiers cannot really capture other emotions that may overlap between positive or negative class. Hence, a probabilistic clustering model for hate speech classification in twitter was developed to tackle problems with hate speech classification. A metadata extractor was used to collect tweets containing hate speech keywords and a crowd-sourced experts was employed to label the collected hate tweets into two categories: hate speech and non-hate speech. Features representation was done with Term Frequency-Inverse Document Frequency (TF-IDF) model and enhanced with topics inferred by a Bayes classifier. A rule-based clustering method was used to automatically classify real-time tweets into the correct topic clusters. Fuzzy logic was then used for hate speech classification using semantic fuzzy rules and a score computation module. From the evaluation results, it was observed that the developed model performed better in hate speech detection with F1-sore of 0.9256 using a 5-fold cross validation. Similarly, the developed model for hate speech classification performed better with F1-score of 91.5 compared to related models. The developed model also indicates a more perfect test having an AUC of 0.9645, when compared to similar methods. The Paired Sample t-Test validated the efficiency of the developed model for hate speech classification.","2021-07-01","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","","173","","","","","","","","","","English","","","","WOS:000636782300006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;27<br/>Total Times Cited:&nbsp;&nbsp;28<br/>Cited Reference Count:&nbsp;&nbsp;99</p>","","","Bayesian function; Combinatorial algorithm; Fuzzy logic; Hate speech; Sentiment analysis; SOCIAL NETWORK; Twitter","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BT46FMN2","journalArticle","2024","Kaminskaya, TL","""NEW SINCERITY"" IN SOCIAL MEDIA TEXTS: INTENTIONS, EFFECTS AND SPEECH FEATURES","VESTNIK VOLGOGRADSKOGO GOSUDARSTVENNOGO UNIVERSITETA-SERIYA 2-YAZYKOZNANIE","","1998-9911","10.15688/jvolsu2.2024.2.4","","The article presents the results of a study on the phenomenon of ""new sincerity"" examined on the material of posts on social networks (about 2 thousand contexts in total). It has been noticed that while in registered media the phenomenon mainly exists as initiated by the journalist (in the genres of interviews with famous people), in social media it acts as an initiative of the author. The object of the study was the intentions of the authors of the posts, manifested in their speech, as well as the feedback that the authors received in response to their confession. The discursive approach used in the study has demonstrated the correlation between the topics of confessional posts and the general tasks of public social networks, between author's intentions and word usage. Thus, feminist public accounts are created specifically to demonstrate those aspects of women's life in society that have not been publicly discussed before. Borrowed vocabulary is widely used in such cases, as well as words that belong to the field of psychotherapy. Confessional posts on the authors' personal accounts are much rarer, more varied in topic, most often aimed at creative self-expression and focused on a circle of familiar people. The types of addressees' reactions to confessional posts are characterized: from distrust of what has been said to support with a demonstration of their similar experience and advice. The research contributes to the development of communication studies in general and media text linguistics in particular.","2024","2025-02-26 20:43:25","2025-02-26 20:43:25","","46-56","","2","23","","","","","","","","","","English","","","","WOS:001241626800004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","author's intention; feminist media discourse; new sincerity; social networks; VKontakte","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZPXVRQT4","journalArticle","2022","Huang, YB; Hou, HX; Chen, TF; Li, H; Zhang, QY","Long sequence biometric hashing authentication based on 2D-SIMM and CQCC cosine values","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-021-11708-z","","The existing speech authentication algorithms hash extracted speech features directly and saved them to the cloud, which is easy to cause speech feature leakage. In the process of constructing hashing, the utilization efficiency of speech feature is poor, and the short hashing sequence will lead to the lack of discrimination of hashing sequence and the deviation of authentication. In order to solve the above problems, a long sequence biometric hashing authentication algorithm based on two-dimensional Sine ICMI Cmodulation map (2D-SIMM) and constant Q cepstral coefficients (CQCC) cosine was proposed. First, this algorithm extracts the CQCC of the speech signal, then obtains the eigenvalue of the space cosine distance of the adjacent speech frame CQCC, and finally performs projection mapping between the eigenvalue and the pseudorandom matrix generated by 2D-SIMM to construct a biometric hashing sequence. This paper evaluates the proposed robust feature schemes of MFCC and CQCC space cosine distance through experiments. The experimental results show that CQCC spatial distance combined with 2D-SIMM biometrics characteristics can reach 10(-21). when the threshold is 0.35. The BER mean was only 0.0383 for maintaining the robustness of operation for different contents. When the SNR is -5 dB, the matching rate of different noises can reach 45%. At the same time, it also improves the security of the biological template, and the overall performance is greatly improved compared with the existing algorithm.","2022-01","2025-02-26 20:43:25","2025-02-26 20:43:25","","2873-2899","","2","81","","","","","","","","","","English","","","","WOS:000715720000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","2D-SIMM; ALGORITHM; AUDIO; Biometric security template; CQCC cosine; Discrimination; MFCC; ROBUST; Speech content authentication; TEMPLATE PROTECTION; TRANSFORM; Unidirectional","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UXYLDHTH","journalArticle","2022","Rajeswari, KC; Mohana, RS; Manikandan, S; Prabaharan, SB","Speech Quality Enhancement Using Phoneme with Cepstrum Variation Features","INTELLIGENT AUTOMATION AND SOFT COMPUTING","","1079-8587","10.32604/iasc.2022.022681","","In recent years, Text-to-Speech (TTS) synthesis is taking a new dimension. People prefer voice embedded toys, online buyers are interested in interactive chat application in the form of text-to-speech facility, screen readers for visually challenged people, and many more applications use TTS module. TTSis a system that is capable of converting the arbitrary text input into natural sounding speech. It's success lies in producing more human like speech sounding more natural. The most importanttechnical aspect of TTS is feature extraction process. Both text and speech features are needed but it is not that easy to select meaningful and useful features from the text or from speech. There are many feature extraction techniques available for both text and speech, still there is a need for very simplest form of feature extraction technique. Though the emergence of Deep learning technique automates feature extraction, it is suitable only when the volume of data is enormous. This paper proposes a novel text and speech feature extraction technique which is based on special symbols present in the text and phoneme with cepstrum variation of the speech signal respectively. These techniques are simple and works well for real-time applications in which size of data is small or moderate. The proposed methods not only extract useful features but also meaningful features in terms of fetching the salient traits of the text and speech cepstrum. The experimental results have shown that the quality of speech is increased by 14% when compared to the other conevntional feature extraction techniques.","2022","2025-02-26 20:43:25","2025-02-26 20:43:25","","65-86","","1","34","","","","","","","","","","English","","","","WOS:000791160000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","feature extraction; intonation; prosody; Speech synthesis; tamil TTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AGLPHQGG","journalArticle","2025","Li, N; Wang, LB; Zhang, QQ; Dang, JW","Dual-stream Noise and Speech Information Perception based Speech Enhancement","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.125432","","In real-world scenarios, dynamic ambient noise often degrades speech quality, highlighting the need for advanced speech enhancement techniques. Traditional methods, which rely on static embeddings as auxiliary features, struggle to address the complexities of varying noise conditions. To overcome this, we propose a Dual- stream Noise and Speech Information Perception (DNSIP) approach that dynamically detects and processes both noise and speech through innovative information extraction and suppression mechanisms. Initially, non- speech segments predominantly contain environmental noise, while speech segments carry information about the intended speaker. To handle this dynamic nature, real-time voice activity detection (VAD) is employed to accurately differentiate between speech and noise components. Building on VAD estimates, we propose an innovative information extraction framework that selectively extracts relevant noise and speech features from the noisy input, establishing a dual-stream network for concurrent noise and speech learning. To account for the temporal and spectral variability of noise and speech, a frequency-sequence attention mechanism is integrated, enhancing the model's ability to learn contextual and spectral dependencies. Additionally, an information suppression module is introduced to minimize cross-stream interference by attenuating noise within the speech stream and suppressing speech content within the noise stream. The derived noise and speech spectrograms are then utilized to formulate a minimum mean square error log-spectral amplitude (MMSE-LSA) estimator for robust speech enhancement. Experimental evaluations on the WSJ0 and VCTK+DEMAND datasets demonstrate that our DNSIP approach surpasses existing state-of-the-art methods, underscoring its efficacy in challenging acoustic environments.","2025-02-01","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","","261","","","","","","","","","","English","","","","WOS:001336181700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","Attention; Dual-stream; MMSE-LSA; ROBUST; Speech enhancement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9YSJSRRC","journalArticle","2025","Wang, JH; Dong, GY; Shen, YF; Xu, XL; Zhang, MH; Sun, P","REDT: a specialized transformer model for the respiratory phase and adventitious sound detection","PHYSIOLOGICAL MEASUREMENT","","0967-3334","10.1088/1361-6579/adaf08","","Background and objective. In contrast to respiratory sound classification, respiratory phase and adventitious sound event detection provides more detailed and accurate respiratory information, which is clinically important for respiratory disorders. However, current respiratory sound event detection models mainly use convolutional neural networks to generate frame-level predictions. A significant drawback of the frame-based model lies in its pursuit of optimal frame-level predictions rather than the best event-level ones. Moreover, it demands post-processing and is incapable of being trained in an entirely end-to-end fashion. Based on the above research status, this paper proposes an event-based transformer method - Respiratory Events Detection Transformer (REDT) for multi-class respiratory sound event detection task to achieve efficient recognition and localization of the respiratory phase and adventitious sound events. Approach. Firstly, REDT approach employs the Transformer for time-frequency analysis of respiratory sound signals to extract essential features. Secondly, REDT converts these features into timestamp representations and achieves sound event detection by predicting the location and category of timestamps. Main results. Our method is validated on the public dataset HF_Lung_V1. The experimental results show that our F1 scores for inspiration, expiration, continuous adventitious sound and discontinuous adventitious sound are 90.5%, 77.3%, 78.9%, and 59.4%, respectively. Significance. These results demonstrate the method's significant performance in respiratory sound event detection.","2025-02-28","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","2","13","","","","","","","","","","English","","","","WOS:001417249000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","event-based detection; fine-tuning pretrained model; hierarchical transformer; respiratory sound event detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TNZA89LF","journalArticle","2024","Feng, ZY; Chen, JY; Hai, YL; Pang, XL; Zheng, K; Xie, CL; Zhang, XJ; Li, SQ; Zhang, CJ; Liu, KD; Zhu, LL; Hu, XY; Li, SL; Zhang, J; Zhang, K; Li, HL","Sliding-attention transformer neural architecture for predicting T cell receptor-antigen-human leucocyte antigen binding","NATURE MACHINE INTELLIGENCE","","2522-5839","10.1038/s42256-024-00901-y","","Neoantigens are promising targets for immunotherapy by eliciting immune response and removing cancer cells with high specificity, low toxicity and ease of personalization. However, identifying effective neoantigens remains difficult because of the complex interactions among T cell receptors, antigens and human leucocyte antigen sequences. In this study, we integrate important physical and biological priors with the Transformer model and propose the physics-inspired sliding transformer (PISTE). In PISTE, the conventional, data-driven attention mechanism is replaced with physics-driven dynamics that steers the positioning of amino acid residues along the gradient field of their interactions. This allows navigating the intricate landscape of biosequence interactions intelligently, leading to improved accuracy in T cell receptor-antigen-human leucocyte antigen binding prediction and robust generalization to rare sequences. Furthermore, PISTE effectively recovers residue-level contact relationships even in the absence of three-dimensional structure training data. We applied PISTE in a multitude of immunogenic tumour types to pinpoint neoantigens and discern neoantigen-reactive T cells. In a prospective study of prostate cancer, 75% of the patients elicited immune responses through PISTE-predicted neoantigens. Predicting TCR-antigen-human leucocyte antigen binding opens the door to neoantigen identification. In this study, a physics-inspired sliding transformer (PISTE) system is used to guide the positioning of amino acid residues along the gradient field of their interactions, boosting binding prediction accuracy.","2024-10","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","10","6","","","","","","","","","","English","","","","WOS:001321579200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;85</p>","","","ANTI-PD-1; CANCER; CLASS-I BINDING; DATABASE; DISCOVERY; IMPROVE; MHC CLASS-I; NEOANTIGEN VACCINE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6EZJFLNE","journalArticle","2024","Li, BY; Li, HR; Zhu, YH; Zhao, DB","MAT: Morphological Adaptive Transformer for Universal Morphology Policy Learning","IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS","","2379-8920","10.1109/TCDS.2024.3383158","","Agent-agnostic reinforcement learning aims to learn a universal control policy that can simultaneously control a set of robots with different morphologies. Recent studies have suggested that using the transformer model can address variations in state and action spaces caused by different morphologies, and morphology information is necessary to improve policy performance. However, existing methods have limitations in exploiting morphological information, where the rationality of observation integration cannot be guaranteed. We propose morphological adaptive transformer (MAT), a transformer-based universal control algorithm that can adapt to various morphologies without any modifications. MAT includes two essential components: functional position encoding (FPE) and morphological attention mechanism (MAM). The FPE provides robust and consistent positional prior information for limb observation to avoid limb confusion and implicitly obtain functional descriptions of limbs. The MAM enhances the attribute prior information of limbs, improves the correlation between observations, and makes the policy pay attention to more limbs. We combine observation with prior information to help policy adapt to the morphology of robots, thereby optimizing its performance with unknown morphologies. Experiments on agent-agnostic tasks in Gym MuJoCo environment demonstrate that our algorithm can assign more reasonable morphological prior information to each limb, and the performance of our algorithm is comparable to the prior state-of-the-art algorithm with better generalization.","2024-08","2025-02-26 20:43:25","2025-02-26 20:43:25","","1611-1621","","4","16","","","","","","","","","","English","","","","WOS:001292741200009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Agent-agnostic reinforcement learning; Encoding; functional position encoding (FPE); Graph neural networks; morphological attention mechanism (MAM); morphological information; Morphology; Reinforcement learning; Robots; Transformers; Vectors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R6FWQGBI","journalArticle","2024","Gomez, W; Wang, FK; Chou, JH","Li-ion battery capacity prediction using improved temporal fusion transformer model","ENERGY","","0360-5442","10.1016/j.energy.2024.131114","","Lithium-ion (Li-ion) batteries have near-zero energy emissions and provide power to various devices, such as automobiles and portable equipment. The strategy predicts the capacity of Li-ion in advance and can also help arrange maintenance tasks. To improve state of health (SOH) and remaining useful life (RUL) prediction accuracy, we propose an improved temporal fusion transformer (ITFT) method based on bidirectional long short-term memory (Bi-LSTM) encoder-decoder layer replacing the long short-term memory for probabilistic online RUL prediction. A novel interpretable hyperparameter tuning method called Bayesian optimization based on treestructure Parzen estimator (TPE) is coupled with a unique ITFT model to improve RUL prediction accuracy. Furthermore, we consider the effects of keen-onset to establish the starting point of our training. The root mean square error for four batteries using the proposed model for the test data are 0.0018, 0.0019, 0.0013, and 0.0025, respectively, which outperforms the other models, with an improvement accuracy rate above 25%. The proposed model SOH results indicate that our proposed approach outperforms some previously published methods. Our online RUL prediction demonstrates relative errors of 1.18%, 1.54%, 1.06%, 2.70%, 0.67%, 2%, 3.90%, 0%, and 3.08% for nine batteries, respectively. These results for SOH and RUL predictions emphasize the excellent performance of our proposed method.","2024-06-01","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","","296","","","","","","","","","","English","","","","WOS:001221569200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;18<br/>Total Times Cited:&nbsp;&nbsp;18<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Bidirectional long short-term memory; Improved temporal fusion transformer; Remaining useful life prediction; Tree-structure parzen estimator","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4CEHFTEG","journalArticle","2024","Li, ZM; Han, HJ; Li, ZW; Zhang, R","Predicting the Shanghai Composite Index Using Chinese TikTok Self-Media Data and Machine Learning Model in China","DISCRETE DYNAMICS IN NATURE AND SOCIETY","","1026-0226","10.1155/ddns/7201831","","The generation and application of new self-media provide new ways to acquire information access for Internet users. It also provides a large amount of quality data for the accurate prediction of the Shanghai composite index. In this paper, we combined various machine learning and deep learning models with the search data of Chinese TikTok, which is related to the Shanghai composite index, to predict the Shanghai composite index. In addition, we compared and analyzed the prediction results of several machine learning and deep learning models in the short term, medium term, and long term. The results showed that the support vector regression model had the lowest mean absolute percentage error and the highest prediction accuracy in the short, medium, and long term, and the strongest robustness compared with other models. This was followed by random forest regression, which outperformed the remaining five benchmark prediction models (convolutional neural network, LSTM, GRU neural network, radial basis function neural network, extreme learning machine, and transformer model) in terms of prediction accuracy and robustness. The prediction results provide an innovative exploration of the prediction of the Shanghai composite index using self-media network search data. The prediction method provides a new research idea for macroeconomic prediction and forecasting and also enriches the theoretical research of machine learning methods in the field of macroeconomic index prediction.","2024","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","1","2024","","","","","","","","","","English","","","","WOS:001386516100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","CONVOLUTIONAL NEURAL-NETWORKS; deep learning; ENERGY; IMPACT; machine learning; PRICES; self-media search data; Shanghai composite index prediction; STOCK","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BEHKZBJF","journalArticle","2023","Chai, GZ; Li, SM; Yang, Y; Zhou, GH; Wang, YH","CTSF: An Intrusion Detection Framework for Industrial Internet Based on Enhanced Feature Extraction and Decision Optimization Approach","SENSORS","","1424-8220","10.3390/s23218793","","The traditional Transformer model primarily employs a self-attention mechanism to capture global feature relationships, potentially overlooking local relationships within sequences and thus affecting the modeling capability of local features. For Support Vector Machine (SVM), it often requires the joint use of feature selection algorithms or model optimization methods to achieve maximum classification accuracy. Addressing the issues in both models, this paper introduces a novel network framework, CTSF, specifically designed for Industrial Internet intrusion detection. CTSF effectively addresses the limitations of traditional Transformers in extracting local features while compensating for the weaknesses of SVM. The framework comprises a pre-training component and a decision-making component. The pre-training section consists of both CNN and an enhanced Transformer, designed to capture both local and global features from input data while reducing data feature dimensions. The improved Transformer simultaneously decreases certain training parameters within CTSF, making it more suitable for the Industrial Internet environment. The classification section is composed of SVM, which receives initial classification data from the pre-training phase and determines the optimal decision boundary. The proposed framework is evaluated on an imbalanced subset of the X-IIOTID dataset, which represent Industrial Internet data. Experimental results demonstrate that with SVM using both ""linear"" and ""rbf"" kernel functions, CTSF achieves an overall accuracy of 0.98875 and effectively discriminates minor classes, showcasing the superiority of this framework.","2023-11","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","21","23","","","","","","","","","","English","","","","WOS:001099497500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","convolutional neural network; Industrial Internet; intrusion detection; Support Vector Machines; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DN8PZLKV","journalArticle","2023","Asiri, AA; Shaf, A; Ali, T; Shakeel, U; Irfan, M; Mehdar, KM; Halawani, HT; Alghamdi, AH; Alshamrani, AFA; Alqhtani, SM","Exploring the Power of Deep Learning: Fine-Tuned Vision Transformer for Accurate and Efficient Brain Tumor Detection in MRI Scans","DIAGNOSTICS","","2075-4418","10.3390/diagnostics13122094","","A brain tumor is a significant health concern that directly or indirectly affects thousands of people worldwide. The early and accurate detection of brain tumors is vital to the successful treatment of brain tumors and the improved quality of life of the patient. There are several imaging techniques used for brain tumor detection. Among these techniques, the most common are MRI and CT scans. To overcome the limitations associated with these traditional techniques, computer-aided analysis of brain images has gained attention in recent years as a promising approach for accurate and reliable brain tumor detection. In this study, we proposed a fine-tuned vision transformer model that uses advanced image processing and deep learning techniques to accurately identify the presence of brain tumors in the input data images. The proposed model FT-ViT involves several stages, including the processing of data, patch processing, concatenation, feature selection and learning, and fine tuning. Upon training the model on the CE-MRI dataset containing 5712 brain tumor images, the model could accurately identify the tumors. The FT-Vit model achieved an accuracy of 98.13%. The proposed method offers high accuracy and can significantly reduce the workload of radiologists, making it a practical approach in medical science. However, further research can be conducted to diagnose more complex and rare types of tumors with more accuracy and reliability.","2023-06","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","12","13","","","","","","","","","","English","","","","WOS:001017024100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","brain tumor; diagnosis; healthcare; SEGMENTATION; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DZ2BKUIS","journalArticle","2023","Cheng, D; Wang, GR; Wang, B; Zhang, Q; Han, JG; Zhang, DW","Hybrid routing transformer for zero-shot learning","PATTERN RECOGNITION","","0031-3203","10.1016/j.patcog.2022.109270","","Zero-shot learning (ZSL) aims to learn models that can recognize unseen image semantics based on the training of data with seen semantics. Recent studies either leverage the global image features or mine discriminative local patch features to associate the extracted visual features to the semantic attributes. However, due to the lack of the necessary top-down guidance and semantic alignment for ensuring the model attend to the real attribute-correlation regions, these methods still encounter a significant se-mantic gap between the visual modality and the attribute modality, which makes their prediction on unseen semantics unreliable. To solve this problem, this paper establishes a novel transformer encoder -decoder model, called hybrid routing transformer (HRT). In HRT encoder, we embed an active attention, which is constructed by both the bottom-up and the top-down dynamic routing pathways to generate the attribute-aligned visual feature. While in HRT decoder, we use static routing to calculate the correlation among the attribute-aligned visual features, the corresponding attribute semantics, and the class attribute vectors to generate the final class label predictions. This design makes the presented transformer model a hybrid of 1) top-down and bottom-up attention pathways and 2) dynamic and static routing pathways. Comprehensive experiments on three widely-used benchmark datasets, namely CUB, SUN, and AWA2, are conducted. The obtained experimental results demonstrate the effectiveness of the proposed method. Our code is released in https://github.com/KORIYN/HRT . (c) 2022 Elsevier Ltd. All rights reserved.","2023-05","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","","137","","","","","","","","","","English","","","","WOS:000914006400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;57<br/>Total Times Cited:&nbsp;&nbsp;57<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Attention; Hybrid routing; Transformer; Zero -shot learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"65GPRL5U","journalArticle","2022","Chang, YH; Li, FD; Chen, JL; Liu, YL; Li, ZP","Efficient temporal flow Transformer accompanied with multi-head probsparse self-attention mechanism for remaining useful life prognostics","RELIABILITY ENGINEERING & SYSTEM SAFETY","","0951-8320","10.1016/j.ress.2022.108701","","Predictive maintenance, such as remaining useful life (RUL) prognostics, requires precise long time-series forecasting, which demands a higher predictive capability of data-driven models. Nevertheless, the typical convolution and recurrent frameworks are still inadequate in the feature extraction and temporal complexity analysis, which makes them difficult to efficiently capture the precise long-term dependency coupling. Recent research has demonstrated the potential of Transformer-based framework to improve the prediction capability by the massive success in sequence processing. Inspired by the above, this paper proposes an efficient end-to-end Temporal Flow Transformer (TFT) for RUL prognostics of rolling bearings. Its main framework is composed of multi-layer encoders, which can directly extract effective degradation features from the time-frequency repre-sentations of raw signals, with two distinctive characteristics: (1) Specially designed multi-head probsparse self -attention mechanism can effectively highlight the dominant attention, which makes the TFT have considerable performance in reducing the computational complexity of extremely long time-series; (2) The TFT trained by knowledge-induced distillation strategy can significantly improve its domain adaptability, making it possible to achieve accurate RUL prediction under cross-operating conditions. Extensive experiments on two life-cycle bearing datasets indicate that the TFT greatly outperforms the existing state-of-the-art methods and provides a new solution for RUL prognostics.","2022-10","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","","226","","","","","","","","","","English","","","","WOS:000829034400004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;48<br/>Total Times Cited:&nbsp;&nbsp;48<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","PREDICTION; Probsparse self -attention mechanism; RECURRENT NEURAL-NETWORK; Remaining useful life prognostics; Rolling bearings; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C2LIWTRS","journalArticle","2024","Bhargava, Y; Kottapalli, A; Baths, V","Validation and comparison of virtual reality and 3D mobile games for cognitive assessment against ACE-III in 82 young participants","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-75065-1","","Current medical and clinical ecosystem for dementia detection is inadequate for its early detection. Traditional cognitive assessments are introduced after cognitive impairment has begun to disrupt the real-world functioning of the person. Moreover, these tools are paper-pen based and fail to replicate the real-world situations wherein the person ultimately lives, acts and grows. The lack of tools for early detection of dementia, combined with absence of reliable pharmacological cure compound the problems associated with dementia diagnosis and care. Advancement of technology has facilitated early prediction of disease like cancer, diabetes, heart disease, but hardly any such translation has been observed for dementia or cognitive impairment. Given this background, we examine the potential of Virtual Reality (VR) and 3D Mobile-based goal-oriented games for cognitive assessment. We evaluate three games (2 in VR, one in mobile) among 82 young participants (aged 18-28 years) and compare and contrast the game-based results with their Addenbrooke Cognitive Examination (ACE-III) scores. Three main analysis methods are used: Correlative, Z-score and Regression analysis. Positive correlation was observed for ACE-III and game-based scores. Z-scores analysis revealed no difference between the two scores, and stronger statistical significance was found between game scores and cognitive health factors like age, smoking compared to ACE-III. Specific game performances also revealed about real-world traits of participants, like hand-use confusion and direction confusion. Results establish the plausibility of using goal-oriented games for more granular, time-based, and functional cognitive assessment.","2024-10-13","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","1","14","","","","","","","","","","English","","","","WOS:001338624000036","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;153</p>","","","AGE-DIFFERENCES; ALZHEIMERS-DISEASE; Cognitive assessment; Cognitive impairment; Dementia; DEMENTIA; ECOLOGICAL VALIDITY; Ecological validity, Validation, Mobile Games, Regression Analysis, Correlation, Early detection; EXECUTIVE FUNCTIONS; Gamification, Z-score analysis; HUMAN BRAIN; IMPAIRMENT; INSTRUMENTAL ACTIVITIES; OLDER-ADULTS; SPATIAL NAVIGATION; Virtual reality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5D3REES6","journalArticle","2022","Perales-Puchalt, J; Townley, R; Niedens, M; Vidoni, ED; Greiner, KA; Zufer, T; Schwasinger-Schmidt, T; McGee, JL; Arreaza, H; Burns, JM","Acceptability and Preliminary Effectiveness of a Remote Dementia Educational Training Among Primary Care Providers and Health Navigators","JOURNAL OF ALZHEIMERS DISEASE","","1387-2877","10.3233/JAD-220235","","Background: Optimal care can improve lives of families with dementia but remains under-implemented. Most healthcare professional training is in person, time-intensive, and does not focus on key aspects such as early detection, and cultural competency. Objective: We explored the acceptability and preliminary effectiveness of a training, The Dementia Update Course, which addressed these issues. We hypothesized that the training would lead to increased levels of perceived dementia care competency among key healthcare workers, namely primary care providers (PCPs) and health navigators (HNs). Methods: We conducted pre-post training assessments among 22 PCPs and 32 HNs. The 6.5-h training was remote, and included didactic lectures, case discussion techniques, and materials on dementia detection and care. Outcomes included two 5-point Likert scales on acceptability, eleven on perceived dementia care competency, and the three subscales of the General Practitioners Confidence and Attitude Scale for Dementia. We used paired samples t-tests to assess the mean differences in all preliminary effectiveness outcomes. Results: The training included 28.6% of PCPs and 15.6% of HNs that self-identified as non-White or Latino and 45.5% of PCPs and 21.9% of HNs who served in rural areas. PCPs (84.2%) and HNs (91.7%) reported a high likelihood to recommend the training and high satisfaction. Most preliminary effectiveness outcomes analyzed among PCPs (11/14) and all among HNs (8/8) experienced an improvement from pre- to post-training (p < 0.05). Conclusion: A relatively brief, remote, and inclusive dementia training was associated with high levels of acceptability and improvements in perceived dementia care competency among PCPs and HNs.","2022","2025-02-26 20:43:25","2025-02-26 20:43:25","","1375-1384","","4","89","","","","","","","","","","English","","","","WOS:000869690400022","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","ALZHEIMERS-DISEASE; Attitude of health personnel; dementia; DIAGNOSIS; education; healthcare professionals; INTERVENTIONS; KNOWLEDGE; MANAGEMENT; PATIENT; PREVALENCE; PROGRAM; QUALITY-OF-CARE; RACIAL CONCORDANCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DLDBE8VR","journalArticle","2023","Ye, EM; Sun, HQ; Krishnamurthy, P; Adra, N; Ganglberger, W; Thomas, RJ; Lam, AD; Westover, MB","Dementia detection from brain activity during sleep","SLEEP","","0161-8105","10.1093/sleep/zsac286","","Study Objectives Dementia is a growing cause of disability and loss of independence in the elderly, yet remains largely underdiagnosed. Early detection and classification of dementia can help close this diagnostic gap and improve management of disease progression. Altered oscillations in brain activity during sleep are an early feature of neurodegenerative diseases and be used to identify those on the verge of cognitive decline. Methods Our observational cross-sectional study used a clinical dataset of 10 784 polysomnography from 8044 participants. Sleep macro- and micro-structural features were extracted from the electroencephalogram (EEG). Microstructural features were engineered from spectral band powers, EEG coherence, spindle, and slow oscillations. Participants were classified as dementia (DEM), mild cognitive impairment (MCI), or cognitively normal (CN) based on clinical diagnosis, Montreal Cognitive Assessment, Mini-Mental State Exam scores, clinical dementia rating, and prescribed medications. We trained logistic regression, support vector machine, and random forest models to classify patients into DEM, MCI, and CN groups. Results For discriminating DEM versus CN, the best model achieved an area under receiver operating characteristic curve (AUROC) of 0.78 and area under precision-recall curve (AUPRC) of 0.22. For discriminating MCI versus CN, the best model achieved an AUROC of 0.73 and AUPRC of 0.18. For discriminating DEM or MCI versus CN, the best model achieved an AUROC of 0.76 and AUPRC of 0.32. Conclusions Our dementia classification algorithms show promise for incorporating dementia screening techniques using routine sleep EEG. The findings strengthen the concept of sleep as a window into neurodegenerative diseases.","2023-03-09","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","3","46","","","","","","","","","","English","","","","WOS:000911332700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","ALPHA; ALZHEIMERS-DISEASE; biomarker; CLASSIFICATION; dementia; EEG; FREQUENCY; LEWY BODIES; machine learning; MEMORY; MILD COGNITIVE IMPAIRMENT; QUANTITATIVE EEG; sleep; STATE; THETA OSCILLATIONS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A5Y63LP9","journalArticle","2021","Kong, SDX; Hoyos, CM; Phillips, CL; McKinnon, AC; Lin, PS; Duffy, SL; Mowszowski, L; LaMonica, HM; Grunstein, RR; Naismith, SL; Gordon, CJ","Altered heart rate variability during sleep in mild cognitive impairment","SLEEP","","0161-8105","10.1093/sleep/zsaa232","","Study Objectives Cardiovascular autonomic dysfunction, as measured by short-term diurnal heart rate variability (HRV), has been reported in older adults with mild cognitive impairment (MCI). However, it is unclear whether this impairment also exists during sleep in this group. We, therefore, compared overnight HRV during sleep in older adults with MCI and those with subjective cognitive impairment (SCI). Methods Older adults (n = 210) underwent overnight polysomnography. Eligible participants were characterized as multi-domain MCI or SCI. The multi-domain MCI group was comprised of amnestic and non-amnestic subtypes. Power spectral analysis of HRV was conducted on the overnight electrocardiogram during non-rapid eye movement (NREM), rapid eye movement (REM), N1, N2, N3 sleep stages, and wake periods. High-frequency HRV (HF-HRV) was employed as the primary measure to estimate parasympathetic function. Results The MCI group showed reduced HF-HRV during NREM sleep (p = 0.018), but not during wake or REM sleep (p > 0.05) compared to the SCI group. Participants with aMCI compared to SCI had the most pronounced reduction in HF-HRV across all NREM sleep stages-N1, N2, and N3, but not during wake or REM sleep. The naMCI sub-group did not show any significant differences in HF-HRV during any sleep stage compared to SCI. Conclusions Our study showed that amnestic MCI participants had greater reductions in HF-HRV during NREM sleep, relative to those with SCI, suggesting potential vulnerability to sleep-related parasympathetic dysfunction. HF-HRV, especially during NREM sleep, may be an early biomarker for dementia detection.","2021-04-09","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","4","44","","","","","","","","","","English","","","","WOS:000838816400022","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;80</p>","","","aging; ALZHEIMERS-DISEASE; ASSOCIATION; AUTONOMIC DYSFUNCTION; CARDIAC SYMPATHETIC DENERVATION; CHOLINERGIC SYSTEM; dementia; DISTURBANCE; heart rate variability; mild cognitive impairment; NERVOUS-SYSTEM; POWER SPECTRUM ANALYSIS; RISK; sleep; TIME","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JPJ9RTZP","journalArticle","2024","Xu, SJ; Fouladi-Nashta, N; Chen, Y; Zissimopoulos, J","Dementia severity at incident diagnosis in a population representative sample of older Americans","ALZHEIMERS & DEMENTIA-TRANSLATIONAL RESEARCH & CLINICAL INTERVENTIONS","","2352-8737","10.1002/trc2.12491","","INTRODUCTIONWe provide the first analysis of distribution of dementia severity at incident diagnosis for a population representative sample of older Americans.METHODSUsing data from the Aging, Demographics, and Memory Study (ADAMS), the Health Retirement Study (HRS), and traditional Medicare claims, we estimated the Clinical Dementia Rating Scale for ADAMS respondents and applied parameter estimates to predict dementia severity for HRS respondents with claims-based incident dementia diagnosis.RESULTSSeventy percent of older adults received a dementia diagnosis of mild cognitive impairment or mild dementia (early stages). Fewer individuals were diagnosed at early stages in years 2000 to 2008 (65%) compared to years 2009 to 2016 (76%). About 72% of non-Hispanic white persons were diagnosed at early stages, compared to 63% non-Hispanic black and 59% Hispanic persons. More males than females were diagnosed at early stages (75% vs 67%).DISCUSSIONThese data linkages allow population surveillance of early and equitable dementia detection in the older US population to assess clinical and policy levers to improve detection.Highlights For the US population 70 and older, 30% were diagnosed with dementia at a moderate or severe stage. Fewer were diagnosed at early stages in years 2000 to 2008 compared to 2009 to 2016 (65% vs 76%). A total of 72% of white persons were diagnosed at early stages, compared to 63% black and 59% Hispanic persons. More males than females were diagnosed at early stages (75% vs 67%). High wealth and education level were associated with diagnosis at early stages disease.","2024-07","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","3","10","","","","","","","","","","English","","","","WOS:001264757700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","ADULTS; CLAIMS; dementia severity; DEMOGRAPHICS; DISEASE; EMERGENCY-DEPARTMENT USE; health disparities; NURSING-HOME RESIDENTS; PREVALENCE; racial/ethnic minorities; timely dementia diagnosis; TRANSITIONS; UNITED-STATES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7IT7BVU7","journalArticle","2024","Yang, KL; Kelble, L; Felten, K; Carlsson, CM; Clark, LR","Memory screening in the community: Facilitating earlier dementia diagnosis and care-Preliminary data","JOURNAL OF THE AMERICAN GERIATRICS SOCIETY","","0002-8614","10.1111/jgs.19302","","BackgroundThis program evaluation was conducted to assess the effectiveness of a community memory screening initiative across 25 Aging and Disability Resource Centers, spanning 39 counties and 5 tribal communities in the state of Wisconsin.MethodsWe evaluated the screened individuals' characteristics and reasons for screening, the screen results and topics addressed during screening, the rate of sending positive screens to primary care providers, and the incidence of subsequent dementia diagnosis as well as health behavior changes.ResultsProgram evaluation results showed 791 completed surveys from individuals, indicating the program's accessibility and potential to reach populations in both urban and rural counties across Wisconsin. Evaluation results also showed that brain health was the most frequently discussed topic during memory screens (discussed during 689 screens, 87.1%), along with other topics such as potential causes of dementia symptoms (670 screens, 84.5%), dementia warning signs (656, 83%), the importance of early detection (605 screens, 76.5%), and caregiver support (106 screens, 13.4%). Of all 791, a total of 273 (34.5%) individuals had screen results sent to a primary care provider. Follow-up surveys completed with a subset of individuals (n = 49) who had their results sent to a primary care provider indicated that 10 (20%) received a diagnosis of dementia and over half made a health behavior change to improve brain health.ConclusionsThe evaluation results presented herein highlight the program's success in addressing the critical need for accessible dementia-related services. Overall, our evaluation results underscore the importance of community-based initiatives in promoting early dementia detection and intervention, which are crucial for disease management.","2024-12-06","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","","","","","","","","","","","","English","","","","WOS:001374190300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","ALZHEIMERS-DISEASE; community; memory screening; MINI-COG; program evaluation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8IYEEBW5","journalArticle","2024","Kamalzadeh, L; Tayyebi, G; Shariati, B; Shati, M; Saeedi, V; Malakouti, SK","Diagnostic accuracy of cognitive screening tools validated for older adults in Iran: a systematic review and meta-analysis","BMC GERIATRICS","","1471-2318","10.1186/s12877-024-04963-w","","Background This systematic review aims to comprehensively assess the diagnostic accuracy of cognitive screening tools validated for older adults in Iran, providing evidence-based recommendations for clinicians and researchers. Methods A comprehensive search in March 2023 across Web of Science, PubMed, Scopus, ScienceDirect, SID, IranMedex, and IranDoc, enhanced by hand-searching references and Google Scholar, identified cross-sectional studies on cognitive screening in Iranian seniors. We assessed diagnostic accuracy, cognitive domains, and test strengths and weaknesses. A bivariate random-effects meta-analysis provided summary estimates and 95% confidence intervals, illustrated in forest plots. Results Our review, derived from an initial screening of 38 articles, focused on 17 studies involving 14 cognitive screening tools and participant counts from 60 to 350, mostly from specialized clinics. The MMSE was the only tool examined in at least three studies, prompting a meta-analysis revealing its sensitivity at 0.89 and specificity at 0.77 for dementia detection, albeit amidst significant heterogeneity (I<^>2 > 80%). ACE-III demonstrated the highest diagnostic accuracy for MCI and dementia, while MoCA's performance was deemed adequate for MCI and excellent for dementia. High bias risk in studies limits interpretation. Conclusion This review identifies key cognitive tools for dementia and MCI in Iranian older adults, tailored to educational levels for use in primary and specialized care. It emphasizes the need for further validation to enhance diagnostic precision across diverse settings, within a concise framework prioritizing brevity and accuracy for clinical applicability.","2024-05-14","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","1","24","","","","","","","","","","English","","","","WOS:001222707000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","Aged; ALZHEIMERS-DISEASE; Cognitive screening; DEMENTIA; Diagnostic accuracy; IMPAIRMENT; INPATIENTS; Iran; MINI-MENTAL STATE; PREVALENCE; PSYCHOMETRIC PROPERTIES; QUALITY; Risk of Bias; TEST SCORE; TESTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SAMXGG2Y","journalArticle","2023","Obermann, M; Gebauer, A; Arweiler-Harbeck, D; Lang, S; Seilheimer, B; Kleinschnitz, C; Diener, HC; Holle, D; Naegel, S","Cognitive deficits in patients with peripheral vestibular dysfunction","EUROPEAN JOURNAL OF NEUROLOGY","","1351-5101","10.1111/ene.15907","","Background and purpose: Previous studies demonstrated cognitive deficits in patients with peripheral vestibulopathy (PVP) with dysfunction of spatial navigation and orientation, but also documented cognitive decline in nonspatial abilities. This study evaluates cognitive deficits in patients with unilateral vestibulopathy (UVP) as well as bilateral vestibulopathy (BVP) in multiple cognitive domains using common screening tests to reliably detect these deficits in clinical practice. Methods: This prospective study compared patients with UVP and BVP to age- and sex-matched healthy controls (HC). Tests included the Alzheimer's Disease Assessment Scale (ADAS), Mini-Mental Status Examination (MMSE), Trail Making Test Part A and B, Clock Drawing Task, Executive Interview-25 (EXIT25), Dementia Detection (DemTect), and the Judgment of Line Orientation (JLO). The Montgomery-Asberg Depression Rating Scale was used to control for depression. Videonystagmography objectively reconfirmed PVP. The Vertigo Symptoms Scale and the Dizziness Handicap Inventory were used to assess for symptom severity and restrictions of activities of daily living. Results: Eighty-one patients (65 UVP, 16 BVP) were compared to 55 HC. Patients showed impairment in ADAS, MMSE, DemTect, EXIT25, and JLO. No differences between UVP and BVP were detected. The relative risk (RR) estimates of developing cognitive deficits following PVP were increased. The RR for the ADAS was higher in BVP (RR = 4.91, 95% confidence interval [CI] = 1.87-12.9, p = 0.001) than in UVP (RR = 3.75, 95% CI = 1.65-8.51, p = 0.002), but was similar for the MMSE and DemTect between groups. Conclusions: Patients with PVP showed deficits in multiple cognitive domains including nonspatial cognitive abilities. Vestibulopathy could be a risk factor for the development of cognitive impairment.","2023-06-20","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","","","","","","","","","","","","English","","","","WOS:001014973600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","cognitive deficit; dementia; DIZZINESS; IMPAIRMENT; nonspatial abilities; peripheral vestibulopathy; SCALE; screening tests; SPATIAL MEMORY; VERTIGO; VISUOSPATIAL ABILITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F8Q3SX97","journalArticle","2022","Kherchouche, A; Ben-Ahmed, O; Guillevin, C; Tremblais, B; Julian, A; Fernandez-Maloigne, C; Guillevin, R","Attention-guided neural network for early dementia detection using MRS data","COMPUTERIZED MEDICAL IMAGING AND GRAPHICS","","0895-6111","10.1016/j.compmedimag.2022.102074","","Imaging bio-markers have been widely used for Computer-Aided Diagnosis (CAD) of Alzheimer's Disease (AD) with Deep Learning (DL). However, the structural brain atrophy is not detectable at an early stage of the disease (namely for Mild Cognitive Impairment (MCI) and Mild Alzheimer's Disease (MAD)). Indeed, potential biological bio-markers have been proved their ability to early detect brain abnormalities related to AD before brain structural damage and clinical manifestation. Proton Magnetic Resonance Spectroscopy (1H-MRS) provides a promising solution for biological brain changes detection in a no invasive manner. In this paper, we propose an attention-guided supervised DL framework for early AD detection using 1H-MRS data. In the early stages of AD, features may be closely related and often complex to delineate between subjects. Hence, we develop a 1D attention mechanism that explicitly guides the classifier to focus on diagnostically relevant metabolites for classes discrimination. Synthetic data are used to tackle the lack of data problem and to help in learning the feature space. Data used in this paper are collected in the University Hospital of Poitiers, which contained 111 1H-MRS samples extracted from the Posterior Cingulate Cortex (PCC) brain region. The data contain 33 Normal Control (NC), 49 MCI due to AD, and 29 MAD subjects. The proposed model achieves an average classification accuracy of 95.23%. Our framework outperforms state of the art imaging-based approaches, proving the robustness of learning metabolites features against traditional imaging bio-markers for early AD detection.","2022-07","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","","99","","","","","","","","","","English","","","","WOS:000817168800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","Alzheimer ?s disease; ALZHEIMERS-DISEASE DIAGNOSIS; Attention mechanism; BIOMARKER; Computer-Aided Diagnosis; CORTEX; Deep learning; Feature refinement; Magnetic resonance spectroscopy; MAGNETIC-RESONANCE-SPECTROSCOPY; MARKERS; MILD COGNITIVE IMPAIRMENT; RATIOS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5LH6ETCQ","journalArticle","2022","Disler, R; Pascoe, A; Anderson, H; Piejko, E; Asaid, A; Disler, P","A new model for general practice-led, regional, community-based, memory clinics","BMC PRIMARY CARE","","2731-4553","10.1186/s12875-022-01829-1","","Background Dementia is a major international health issue with high impact on the patient, relatives, and broader society. Routine screening for dementia is limited, despite known benefit of early detection and intervention on quality of care and patient outcomes. Screening is particularly limited in rural and regional areas, despite high burden and projected growth of dementia in these populations. The current study aimed to implement a new general practitioner (GP) led, multidisciplinary, model of care providing dementia detection and referral pathway to a community-based specialist clinic across six regional general practices. Methods Cross-sectional analysis of dementia screening and referral characteristics in the St Anthony Family Medical Practices group based in the regional area of Loddon-Mallee, Victoria. Data were collected on demographics and relevant medical history. Cognitive state was assessed using the Mini-Mental State Examination (MMSE), GP Assessment of Cognition (GPCog), and Geriatric Depression Scale (GDS). Referrals and referral outcomes were recorded for geriatrician, psycho-geriatrician, or both. Results Eight hundred and eighteenth patients over 65 years were screened, accounting for approximately 24.2% of 65 and over presentations for the practice network. Of those screened, 68.9% were indicated for referral and 30.3% of these were successfully referred. Of the indicated patients who received referrals, 34.2% declined. Many who declined referral had intermediate scores on the cognitive assessments utilized. Conclusion Standardised models of care, integrated within community services, are necessary to improve access to early detection, referral and quality management of dementia. The St Anthony Memory Service model will be invaluable in informing future service development, and in particular the development of services for people living with dementia in rural and regional communities.","2022-09-20","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","1","23","","","","","","","","","","English","","","","WOS:000855762900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","Dementia; DEMENTIA; Dementia screening; DIAGNOSIS; General practice; GPCOG; Models of care; Primary care; PRIMARY-CARE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UMIJAL3K","journalArticle","2024","Barua, PD; Tuncer, T; Baygin, M; Dogan, S; Acharya, UR","N-BodyPat: Investigation on the dementia and Alzheimer's disorder detection using EEG signals","KNOWLEDGE-BASED SYSTEMS","","0950-7051","10.1016/j.knosys.2024.112510","","The N-body problem is a remarkable research topic in physics. We propose a new feature extraction model inspired by the N-body trajectory and test its feature extraction capability. In the first part of the research, an open-access electroencephalogram (EEG) dataset is used to test the proposed method. This dataset has three classes, namely (i) Alzheimer's Disorder (AD), (ii) frontal dementia (FD), and (iii) control groups. In the second step of the study, the EEG signals were divided into segments of 15 s in length, which resulted in 4,661 EEG signals. In the third part of the study, the proposed new self-organized feature engineering (SOFE) model is used to classify the EEG signals automatically. For this SOFE, two novel methods were presented: (i) a dynamic feature extraction function using a graph of the N-Body orbital, termed N-BodyPat, and (ii) an attention pooling function. A multileveled and combinational feature extraction method was proposed by deploying both methods. A feature selection function using ReliefF and Neighborhood Component Analysis (RFNCA) was used to choose the most informative features. An ensemble k-nearest neighbors (EkNN) classifier was employed in the classification phase. Our proposed N-BodyPat generates seven feature vectors for each channel, and the utilized EEG signal dataset contains 19 channels. In this aspect,133 (=19 x 7) EkNN-based outcomes were created. To attain higher classification performance by employing these 133 EkNN-based outcomes, an iterative majority voting (IMV)based information fusion method was applied, and the most accurate outcomes were selected automatically. The recommended N-BodyPat-based SOFE achieved a classification accuracy of 99.64 %.","2024-11-25","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","","304","","","","","","","","","","English","","","","WOS:001316305200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","AD detection; Attention pooling; Dementia detection; DISEASE; FRONTOTEMPORAL DEMENTIA; N -body pattern; SOFE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SYSXQSHD","journalArticle","2024","Choi, Y; Nguyen, HT; Han, TH; Choi, Y; Ahn, J","Sequence Deep Learning for Seismic Ground Response Modeling: 1D-CNN, LSTM, and Transformer Approach","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14156658","","Accurate seismic ground response analysis is crucial for the design and safety of civil infrastructure and establishing effective mitigation measures against seismic risks and hazards. This is a complex process due to the nonlinear soil properties and complicated underground geometries. As a simplified approach, the one-dimensional wave propagation model, which assumes that seismic waves travel vertically through a horizontally layered medium, is widely adopted for its reasonable performance in many practical applications. This study explores the potential of sequence deep learning models, specifically 1D convolutional neural networks (1D-CNNs), long short-term memory (LSTM) networks, and transformers, as an alternative for seismic ground response modeling. Utilizing ground motion data from the Kiban Kyoshin Network (KiK-net), we train these models to predict ground surface acceleration response spectra based on bedrock motions. The performance of the data-driven models is compared with the conventional equivalent-linear analysis model, SHAKE2000. The results demonstrate that the deep learning models outperform the physics-based model across various sites, with the transformer model exhibiting the smallest average prediction error due to its ability to capture long-range dependencies. The 1D-CNN model also shows a promising performance, albeit with occasional higher errors than the other models. All the data-driven models exhibit efficient computation times of less than 0.4 s for estimation. These findings highlight the potential of sequence deep learning approaches for seismic ground response modeling.","2024-08","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","15","14","","","","","","","","","","English","","","","WOS:001287137000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","convolutional neural networks (CNNs); earthquake; long short-term memory (LSTM) networks; MOTION; PROPAGATION; seismic ground response modeling; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FDMHRSR2","journalArticle","2024","Wang, A; Niu, Y","Integrating Social Media Insights for Innovation Performance Enhancement: A Transformer-Based Analysis","JOURNAL OF THE KNOWLEDGE ECONOMY","","1868-7865","10.1007/s13132-024-02162-x","","With the development of the times, social media in daily work is increasingly popular, which has a potential impact on employee innovation performance. However, current research only focuses on single factor analysis. In order to enhance this research, this paper studies transformer model, attention mechanism, and other advanced data analysis methods to investigate the subtle relationship between employees' use of social media and its impact on a company's innovation performance. Our research introduces a multidimensional approach that encompasses both organizational and individual perspectives, offering a comprehensive understanding of social media's dualistic nature in fostering innovation. Employing an innovative methodological framework, we integrate factor analysis with a transformer-based feature fusion module, effectively capturing and analyzing the rich semantic nuances embedded in employee-generated social media content. This approach allows for the extraction and synthesis of key sentiment indicators, facilitating a more granular analysis of how social media engagement influences innovation-related behaviors and outcomes. Findings reveal that the strategic use of social media within corporate environments can significantly enhance innovation performance by providing a fertile ground for knowledge sharing, collaborative engagement, and the nurturing of a culture conducive to innovation. The proposed multimodal data fusion technique demonstrates superior accuracy in sentiment analysis, surpassing traditional unimodal approaches by significant margins. These insights contribute to the academic discourse on technology management and knowledge economy and offer practical implications for organizations aiming to harness social media's potential in augmenting their innovation ecosystem.","2024-06-18","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","","","","","","","","","","","","English","","","","WOS:001249459900006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Attention mechanisms; Employee engagement; Innovation performance; Knowledge integration; Multimodal data fusion; Sentiment analysis; SENTIMENT ANALYSIS; Social media analysis; Transformer models; USAGE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q5LCDYAQ","journalArticle","2024","Ma, JB; Chen, H","Efficient Supervised Pretraining of Swin-Transformer for Virtual Staining of Microscopy Images","IEEE TRANSACTIONS ON MEDICAL IMAGING","","0278-0062","10.1109/TMI.2023.3337253","","Fluorescence staining is an important technique in life science for labeling cellular constituents. However, it also suffers from being time-consuming, having difficulty in simultaneous labeling, etc. Thus, virtual staining, which does not rely on chemical labeling, has been introduced. Recently, deep learning models such as transformers have been applied to virtual staining tasks. However, their performance relies on large-scale pretraining, hindering their development in the field. To reduce the reliance on large amounts of computation and data, we construct a Swin-transformer model and propose an efficient supervised pretraining method based on the masked autoencoder (MAE). Specifically, we adopt downsampling and grid sampling to mask 75% of pixels and reduce the number of tokens. The pretraining time of our method is only 1/16 compared with the original MAE. We also design a supervised proxy task to predict stained images with multiple styles instead of masked pixels. Additionally, most virtual staining approaches are based on private datasets and evaluated by different metrics, making a fair comparison difficult. Therefore, we develop a standard benchmark based on three public datasets and build a baseline for the convenience of future researchers. We conduct extensive experiments on three benchmark datasets, and the experimental results show the proposed method achieves the best performance both quantitatively and qualitatively. In addition, ablation studies are conducted, and experimental results illustrate the effectiveness of the proposed pretraining method. The benchmark and code are available at https://github.com/birkhoffkiki/CAS-Transformer.","2024-04","2025-02-26 20:43:25","2025-02-26 20:43:25","","1388-1399","","4","43","","","","","","","","","","English","","","","WOS:001196733400013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Benchmark testing; Computational modeling; Computer architecture; deep learning; Microscopy; microscopy images; SUPERRESOLUTION; supervised pretraining; Task analysis; Training; Transformers; Virtual staining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5BGTU6GT","journalArticle","2024","Alnajem, NA; Binkhonain, M; Hossain, MS","Siamese Neural Networks Method for Semantic Requirements Similarity Detection","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3469636","","Detecting semantic similarity between textual requirements is a crucial task for various natural language processing (NLP)-based requirements engineering (RE) applications. It is also challenging due to the nature of these requirements, which are written in natural language (NL), include domain knowledge, and often follow pre-defined templates that contain duplicated words. Recently, deep neural networks (DNNs) have shown promising results in measuring semantic similarity between texts. Siamese neural networks (SNNs), a class of DNNs, are widely used for measuring similarity between various data types, demonstrating their capability and independence of language and domain. Nevertheless, SNNs have a limited use in measuring semantic requirements similarity (SRS). In this paper, a novel metric-based learning method is proposed using SNNs that combines a sentence Transformer model (LLM) and long short-term memory (LSTM) networks with a backward network layer to measure semantic similarity between pairs of requirements. The proposed method is evaluated on an annotated SRS dataset that was built based on public datasets (i.e., PROMISE and PURE) and compared with other state-of-the-art methods (i.e., fine-tuning and zero-shot methods) using accuracy, precision, recall, and F1-score classification metrics. The results show that the proposed method achieved an accuracy of 95.42% and an F1-score of 95.71%, outperforming the state-of-the-art methods.","2024","2025-02-26 20:43:25","2025-02-26 20:43:25","","140932-140947","","","12","","","","","","","","","","English","","","","WOS:001328996100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Accuracy; Artificial intelligence; Artificial intelligence for requirements engineering; Computer architecture; large language models; Long short term memory; long short-term memory networks; Natural language processing; Neural networks; requirements; requirements engineering; Requirements engineering; requirements similarity; semantic requirements similarity; Semantics; Siamese neural networks; similarity; Software; transformer models; Transformers; Vectors; XML","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZWDM6X6F","journalArticle","2023","Li, N; Dong, J; Liu, LY; Li, H; Yan, J","A novel EMD and causal convolutional network integrated with Transformer for ultra short-term wind power forecasting","INTERNATIONAL JOURNAL OF ELECTRICAL POWER & ENERGY SYSTEMS","","0142-0615","10.1016/j.ijepes.2023.109470","","Accurate wind power forecasting can enhance the safety, stability, economy and controllability of the power system. Traditional physical methods and statistical methods are easily affected by data quality and extraction methods in wind power forecasting. The commonly used recursive neural network method may have memory decline phenomenon in wind power forecasting and does not support parallel calculation, thus limiting the forecasting accuracy. To solve the above problems, in this paper, a wind power forecasting method based on EMD-CCTransformer is proposed. The network model is based on an encoder-decoder structure, where the encoder is used to parse historical wind power sequences, the decoder generates future wind power, and the encoder and decoder are connected using an attention mechanism. In this method, the EMD algorithm is used to decompose the wind power series and obtain the changes of power signals in different time scales, which improves the ability of Transformer to maintain long-term information. Meanwhile, in view of the partial unknowability of the Transformer model, the convolutional attention mechanism is introduced to replace the dot product attention mechanism to form the CCTransformer model, which further improves the forecasting accuracy. We use large-scale wind power data (annual data of the year of 2020 ) to train and test the proposed model. Experimental results show that compared with commonly used wind power forecasting methods, the forecasting error of the proposed EMD-CCTransformer forecasting method in this paper is lower and its model training time is further shortened.","2023-12","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","","154","","","","","","","","","","English","","","","WOS:001073656000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;38<br/>Total Times Cited:&nbsp;&nbsp;38<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Causal convolutional attention; EMD-CCTransformer; Local unknowability; MODEL; OUTPUT POWER; RATIONAL CUBIC SPLINE; Wind power forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"67BQ3QM9","journalArticle","2023","Li, JJ; Xing, HF; Ao, ZR; Wang, HF; Liu, WK; Zhang, AB","Convolution-Transformer Adaptive Fusion Network for Hyperspectral Image Classification","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13010492","","Hyperspectral image (HSI) classification is an important but challenging topic in the field of remote sensing and earth observation. By coupling the advantages of convolutional neural network (CNN) and Transformer model, the CNN-Transformer hybrid model can extract local and global features simultaneously and has achieved outstanding performance in HSI classification. However, most of the existing CNN-Transformer hybrid models use artificially specified hybrid strategies, which have poor generalization ability and are difficult to meet the requirements of recognizing fine-grained objects in HSI of complex scenes. To overcome this problem, we proposed a convolution-Transformer adaptive fusion network (CTAFNet) for pixel-wise HSI classification. A local-global fusion feature extraction unit, called the convolution-Transformer adaptive fusion kernel, was designed and integrated into the CTAFNet. The kernel captures the local high-frequency features using a convolution module and extracts the global and sequential low-frequency information using a Transformer module. We developed an adaptive feature fusion strategy to fuse the local high-frequency and global low-frequency features to obtain a robust and discriminative representation of the HSI data. An encoder-decoder structure was adopted in the CTAFNet to improve the flow of fused local-global information between different stages, thus ensuring the generalization ability of the model. Experimental results conducted on three large-scale and challenging HSI datasets demonstrate that the proposed network is superior to nine state-of-the-art approaches. We highlighted the effectiveness of adaptive CNN-Transformer hybrid strategy in HSI classification.","2023-01","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","1","13","","","","","","","","","","English","","","","WOS:000908715400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","convolutional neural networks; deep learning; feature fusion; hybrid strategy; hyperspectral image classification; SPECTRAL-SPATIAL CLASSIFICATION; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8PSVVL3W","journalArticle","2025","Gao, R; Chen, ZW; Wu, XY; Yu, YH; Zhang, L","Dynamic deep graph convolution with enhanced transformer networks for time series anomaly detection in IoT","CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND APPLICATIONS","","1386-7857","10.1007/s10586-024-04707-w","","Anomaly detection of multi-time series data during the working process of Internet of Things systems that utilize sensors is one of the key aspects to prevent accidents in industrial information systems. The key challenge is to discover generalized normal patterns by capturing spatio-temporal correlations in multi-sensor data. However, most of the existing studies face the following challenges: (1) Complex topologies and nonlinear connectivity among sensors lack effective characterization methods. (2) Sophisticated correlations among time series need to be mined deeply. Therefore, we propose a novel dynamic deep graph convolution with enhanced transformer networks (DDGCT) for time series anomaly detection. We first construct a dynamic deep graph convolutional network to automatically learn the complex spatial dependencies of sensor data, which introduces l0\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$l_0$$\end{document} norm with Hard Concrete distribution to further guide the optimization of graph structure in graph learning. Meanwhile, we devise a new transformer model to deeply mine temporal dependencies from time-series data by designing a new positional encoding coupled with patch design as well as channel independence constraint. Then, DDGCT fuses and optimizes the captured temporal and deep spatial features using attention networks. Finally, anomaly scores are efficiently computed by prediction methods with threshold-based approaches to detect anomalies. Extensive experiments on real datasets show that DDGCT outperforms several state-of-the-art methods.","2025-02","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","1","28","","","","","","","","","","English","","","","WOS:001335084600003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Anomaly detection; Graph neural network; MODEL; SUPPORT; Time series; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JLZUXTGG","journalArticle","2025","Chen, XY; Zhao, LY; Xu, JW; Dai, ZP; Xu, LX; Guo, N; Zhang, H","Feature-Adaptive Self-Supervised Leaning for Microthrust Measurement Signals Blind Denoising","IEEE SENSORS JOURNAL","","1530-437X","10.1109/JSEN.2024.3493104","","Effective denoising of microthrust measurement signals (MTMSs) is crucial for analyzing the dynamic characteristics of microthrusters. Existing methods struggle to suppress noise while accurately reconstructing smooth trend features and step edge features. These issues can lead to potential misjudgments and omissions of microthrust step effects. In this article, we propose a novel perspective on self-supervised blind denoising algorithm with advantage of feature-adaptive supervision for MTMSs denoising. Specifically, the cascaded learning framework comprises a blind-aware network (BAN), a local perception network (LPN), and a feature-adaptive blind denoising network. BAN employs the ""noise2noise"" denoising concept, utilizing a patch-Transformer model to capture short- and long-term smooth trend features, providing denoising supervision for smooth regions. Besides, LPN uses the local receptive fields of the convolutional layer to capture step edge features and provide denoising supervision for the step regions. Through the proposed feature-adaptive regulatory factor, the LPN is selectively supervised by the BAN's output. Finally, the blind denoising network adaptively integrates supervisions from both smooth and step regions through the regulatory factor, achieving effective denoising of MTMSs. A numerical example shows that the proposed method has 50.6% and 23.4% root-mean-square error (RMSE) reductions over the low-pass Butterworth filter and the total variation denoising (TVD) algorithm. Moreover, the experimental results demonstrate that the proposed method outperforms existing baseline methods in denoising performance and effectively reconstructs smooth trend and step edge features.","2025-01-01","2025-02-26 20:43:25","2025-02-26 20:43:25","","1015-1028","","1","25","","","","","","","","","","English","","","","WOS:001389581900039","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Blind denoising; Extraterrestrial measurements; feature adaptive; Market research; microthrust measurement signal (MTMS); Noise; Noise reduction; self-supervised leaning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BNEZFDFQ","journalArticle","2024","Karim, AAJ; Mahmud, MZ; Khan, R","Advanced vision transformers and open-set learning for robust mosquito classification: A novel approach to entomological studies","PLOS COMPUTATIONAL BIOLOGY","","1553-734X","10.1371/journal.pcbi.1012654","","Mosquito-related diseases pose a significant threat to global public health, necessitating efficient and accurate mosquito classification for effective surveillance and control. This work presents an innovative approach to mosquito classification by leveraging state-of-the-art vision transformers and open-set learning techniques. A novel framework has been introduced that integrates Transformer-based deep learning models with comprehensive data augmentation and preprocessing methods, enabling robust and precise identification of ten mosquito species. The Swin Transformer model achieves the best performance for traditional closed-set learning with 99.60% accuracy and 0.996 F1 score. The lightweight MobileViT technique attains an almost equivalent accuracy of 98.90% with significantly reduced parameters and model complexities. Next, the applied deep learning models' adaptability and generalizability in a static environment have been enhanced by using new classes of data samples during the inference stage that have not been included in the training set. The proposed framework's ability to handle unseen classes like insects similar to mosquitoes, even humans, through open-set learning further enhances its practical applicability employing the OpenMax technique and Weibull distribution. The traditional CNN model, Xception, outperforms the latest transformer with higher accuracy and F1 score for open-set learning. The study's findings highlight the transformative potential of advanced deep-learning architectures in entomology, providing a strong groundwork for future research and development in mosquito surveillance and vector control. The implications of this work extend beyond mosquito classification, offering valuable insights for broader ecological and environmental monitoring applications.","2024-12","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","12","20","","","","","","","","","","English","","","","WOS:001405213100006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YY763C3D","journalArticle","2024","Busia, P; Cossettini, A; Ingolfsson, TM; Benatti, S; Burrello, A; Jung, VJB; Scherer, M; Scrugli, MA; Bernini, A; Ducouret, P; Ryvlin, P; Meloni, P; Benini, L","Reducing False Alarms in Wearable Seizure Detection With EEGformer: A Compact Transformer Model for MCUs","IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS","","1932-4545","10.1109/TBCAS.2024.3357509","","The long-term, continuous analysis of electroencephalography (EEG) signals on wearable devices to automatically detect seizures in epileptic patients is a high-potential application field for deep neural networks, and specifically for transformers, which are highly suited for end-to-end time series processing without handcrafted feature extraction. In this work, we propose a small-scale transformer detector, the EEGformer, compatible with unobtrusive acquisition setups that use only the temporal channels. EEGformer is the result of a hardware-oriented design exploration, aiming for efficient execution on tiny low-power micro-controller units (MCUs) and low latency and false alarm rate to increase patient and caregiver acceptance.Tests conducted on the CHB-MIT dataset show a 20% reduction of the onset detection latency with respect to the state-of-the-art model for temporal acquisition, with a competitive 73% seizure detection probability and 0.15 false-positive-per-hour (FP/h). Further investigations on a novel and challenging scalp EEG dataset result in the successful detection of 88% of the annotated seizure events, with 0.45 FP/h.We evaluate the deployment of the EEGformer on three commercial low-power computing platforms: the single-core Apollo4 MCU and the GAP8 and GAP9 parallel MCUs. The most efficient implementation (on GAP9) results in as low as 13.7 ms and 0.31 mJ per inference, demonstrating the feasibility of deploying the EEGformer on wearable seizure detection systems with reduced channel count and multi-day battery duration.","2024-06","2025-02-26 20:43:25","2025-02-26 20:43:25","","608-621","","3","18","","","","","","","","","","English","","","","WOS:001236736100017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Biomedical monitoring; Brain modeling; Deep learning; electroencephalography; Electroencephalography; Epilepsy; Monitoring; Recording; time traces; transformer; Transformers; wearable","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GU2HR4VN","journalArticle","2023","Zhu, R; Leng, JS; Fu, Q; Wang, XY; Cai, H; Wen, GY; Zhang, T; Shi, HD; Li, YC; Jiang, HL","Transformer-based target tracking algorithm for space-based optoelectronic detection","FRONTIERS IN PHYSICS","","2296-424X","10.3389/fphy.2023.1266927","","The target tracking by space-based surveillance systems is difficult due to the long distances, weak energies, fast speeds, high false alarm rates, and low algorithmic efficiencies involved in the process. To mitigate the impact of these difficulties, this article proposes a target tracking algorithm based on image processing and Transformer, which employs a two-dimensional Gaussian soft-thresholding method to reduce the image noise, and combines a Laplace operator-weighted fusion method to augment the image, so as to improve the overall quality of the image and increase the accuracy of target tracking. Based on the SiamCAR framework, the Transformer model in the field of natural language processing is introduced, which can be used to enhance the image features extracted from the backbone network by mining the rich temporal information between the initial and dynamic templates. In order to capture the information of the target's appearance change in the temporal sequence, a template update branch is introduced at the input of the algorithm, which realizes the dynamic update of the templates by constructing a template memory pool, and selecting the best templates for the candidate templates in the memory pool using the cosine similarity-based selection, thus ensuring the robustness of the tracking algorithm. The experimental results that compared with the SiamCAR algorithm and the mainstream algorithms, the TrD-Siam algorithm proposed in this article effectively improves the tracking success rate and accuracy, addressing poor target tracking performance under space-based conditions, and has a good value of application in the field of optoelectronic detection.","2023-09-01","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","","11","","","","","","","","","","English","","","","WOS:001066466300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","dynamic template updates; image processing; OBJECTS; optoelectronic detection; target tracking; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MK99349B","journalArticle","2023","Quan, JN; Ge, BZ; Wang, M","CrackViT: a unified CNN-transformer model for pixel-level crack extraction","NEURAL COMPUTING & APPLICATIONS","","0941-0643","10.1007/s00521-023-08277-7","","Pixel-level crack extraction (PCE) is challenging due to topology complexity, irregular edges, low contrast ratio, and complex background. Recently, Transformer architectures have shown great potential on many vision tasks and even outperform convolutional neural networks (CNNs). Benefiting from the self-attention mechanism, Transformers can invariably capture the global context information to establish long-range dependencies on the detected objects. However, there was little work on the Transformer architectures for PCE. In this paper, a systematic analysis of three well-designed Transformer architectures for PCE task in terms of network structures and parameters, feature fusion modes, training data and strategy, and generalization ability was developed for the first time. We proposed a Crack extraction network with Vision Transformer (CrackViT) that jointly captures the detailed structures and long-distance dependencies with a novel hybrid encoder with CNN and Transformer to keep the corresponding topologies. In order to be more suitable for PCE task, we explored three feature fusion modes between CNN and Transformer. In addition, a novel feature aggregation block was proposed to sharpen the edges of the decoder upsampling and reduce the noise effect of shallow features. Moreover, a multi-task supervised training strategy was adopted to further improve the details of crack edges. Results on four challenging datasets, including CrackForest, DeepCrack, CRKWH100, and CRACK500, show that CrackViT outperforms state-of-the-art CNN-based methods and the other two novel Transformer architectures. Our codes are available at: https:// github.com/SmilQe/CrackViT.","2023-05","2025-02-26 20:43:25","2025-02-26 20:43:25","","10957-10973","","15","35","","","","","","","","","","English","","","","WOS:000922531700004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;20<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","Crack extraction; Crack structures; NETWORK; SYSTEM; UNet framework; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BS6FQAWB","journalArticle","2021","Roy, D; Fernando, B","Action Anticipation Using Pairwise Human-Object Interactions and Transformers","IEEE TRANSACTIONS ON IMAGE PROCESSING","","1057-7149","10.1109/TIP.2021.3113114","","The ability to anticipate future actions of humans is useful in application areas such as automated driving, robot-assisted manufacturing, and smart homes. These applications require representing and anticipating human actions involving the use of objects. Existing methods that use human-object interactions for anticipation require object affordance labels for every relevant object in the scene that match the ongoing action. Hence, we propose to represent every pairwise human-object (HO) interaction using only their visual features. Next, we use cross-correlation to capture the second-order statistics across human-object pairs in a frame. Cross-correlation produces a holistic representation of the frame that can also handle a variable number of human-object pairs in every frame of the observation period. We show that cross-correlation based frame representation is more suited for action anticipation than attention-based and other second-order approaches. Furthermore, we observe that using a transformer model for temporal aggregation of frame-wise HO representations results in better action anticipation than other temporal networks. So, we propose two approaches for constructing an end-to-end trainable multi-modal transformer (MM-Transformer; code at https://github.com/debadityaroy/MM-Transformer_ActAnt) model that combines the evidence across spatio-temporal, motion, and HO representations. We show the performance of MM-Transformer on procedural datasets like 50 Salads and Breakfast, and an unscripted dataset like EPIC-KITCHENS55. Finally, we demonstrate that the combination of human-object representation and MM-Transformers is effective even for long-term anticipation.","2021","2025-02-26 20:43:25","2025-02-26 20:43:25","","8116-8129","","","30","","","","","","","","","","English","","","","WOS:000701249000003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","Affordances; Convolutional codes; Feature extraction; image motion analysis; image representation; Image sequence analysis; object recognition; Predictive models; Task analysis; Transformers; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D3E4KRF4","journalArticle","2023","Zheng, WZ; Han, JY; Cheng, HL; Chu, WC; Chen, KC; Lai, YH","Comparing the performance of classic voice-driven assistive systems for dysarthric speech","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2022.104447","","Voice-driven communication assistive systems-speech enhancement (SE), voice conversion (VC), and automatic speech recognition with text-to-speech (ASR-TTS)-are recognized approaches for improving dysarthric speakers' speech intelligibility. However, which approach performs better for moderate dysarthric patients is unclear. This study compared the benefits of three classic difference-type voice-driven assistive systems for dysarthric patients under identical test conditions. The benefits of the three systems for dysarthric patients' speech intelligibility were compared; 14 mild-to-severe dysarthric patients and five speakers with normal speech were invited to record the training sets for these systems. Five moderate dysarthric patients were selected to record two additional testing sets, which were used for evaluating the systems' benefits. Google Automatic Speech Recognition's (Google ASR) evaluation metrics and listening tests verified each system's speech intelligibility and quality. The speech intelligibility results produced by Google ASR were 7.0%, 22.9%, and 93.8% for the SE, VC, and ASR-TTS systems, respectively. Regarding the listening test, the performance of speech intelligibility and quality were 38.7%, 40.5%, 95.5%, and 1.81, 2.18, 4.56 for SE, VC, and ASR-TTS systems, respectively. The ASR-TTS system performed better than SE and VC. Furthermore, t-distributed stochastic neighbor embedding (t-SNE) analysis was used to additionally compare the differences between the systems. The t-SNE analysis results indicated that ASR-TTS' phonetic posteriorgram features provided stable performance compared with the other speech features (log-power spectrum and spectra) in the SE and VC systems. Results showed that the ASR-TTS is a potential system to improve moderate dysarthric patients' speech intelligibility and quality in future applications.","2023-03","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","","81","","","","","","","","","","English","","","","WOS:000898953000003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","Deep learning; Dysarthria; FREQUENCY; INTELLIGIBILITY; Speech intelligibility; Voice -driven assistive","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YGUA4GMC","journalArticle","2025","Han, XD; Oishi, N; Tian, YY; Ucurum, E; Young, R; Chatwin, C; Birch, P","ETTrack: enhanced temporal motion predictor for multi-object tracking","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-024-05866-4","","Many Multi-Object Tracking (MOT) approaches exploit motion information to associate all the detected objects across frames. However, traditional tracking-by-detection (TBD) methods, relying on the Kalman Filter, often work well in linear motion scenarios but struggle to accurately predict the locations of objects undergoing complex and non-linear movements. To overcome these limitations, we propose ETTrack, a novel motion prediction method with an enhanced temporal motion predictor. Specifically, the motion predictor integrates a transformer model and a Temporal Convolutional Network (TCN) to capture both long-term and short-term motion patterns, and it predicts the future motion of individual objects based on the historical motion information. Additionally, we propose a novel Momentum Correction Loss function that provides additional information regarding the motion direction of objects during training. This allows the motion predictor to rapidly adapt to sudden motion variations and more accurately predict future motion. Our experimental results demonstrate that ETTrack achieves a competitive performance compared with state-of-the-art trackers on DanceTrack and SportsMOT, scoring 56.4%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document} and 74.4%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document} in HOTA metrics, respectively. Our work provides a robust solution for MOT in complex dynamic environments, which enhances the non-linear motion prediction capabilities of tracking algorithms.","2025-01","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","1","55","","","","","","","","","","English","","","","WOS:001365462200005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","Kalman filter; Motion model; Multi-object tracking; Temporal convolutional network; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IPSR4LH7","journalArticle","2024","Yun, S; Nam, G; Koo, J","HiMolformer: Integrating graph and sequence representations for predicting liver microsome stability with SMILES","COMPUTATIONAL BIOLOGY AND CHEMISTRY","","1476-9271","10.1016/j.compbiolchem.2024.108263","","In the initial stages of drug discovery or pre-clinical studies, understanding the metabolic stability of new molecules is crucial. Recently, research on pre-trained deep learning for molecular property prediction has been actively progressing, with various models being made open-source. However, most of these models rely on either 2D graph or 1D sequence for training, and the representation varies depending on the data format used. Consequently, combining multiple representations can broaden the scope of learning and may potentially be a manageable and most effective method to enhance performance. Therefore, we propose a novel hybrid model for predicting metabolic stability, which integrates representations from both graph-based and sequence-based models pre-trained for molecular features. This approach utilizes the combined strengths of 2D topological and 1D sequential information of molecules. HiMol, a graph- based graph neural network (GNN) model, and Molformer, a sequence-based Transformer model, were selected for integration, thus we named it HiMolformer. HiMolformer demonstrated superior performance compared to other models. We also focus on regression task for prediction with a empirical dataset from Korea Chemical Bank (KCB), comprising 3,498 molecules with mouse liver microsome (MLM) and human liver microsome (HLM) data obtained from actual metabolic reaction experiments. To the best of our knowledge, it is the first attempt to develop MLM and HLM prediction models using regression with a single SMILES input. The source code of this model is available at https://github.com/YUNSEOKWOO/HiMolformer.","2024-12","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","","113","","","","","","","","","","English","","","","WOS:001357376000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;79</p>","","","DRUG DISCOVERY; GNN; Graph; IDENTIFICATION; Liver microsome stability; METABOLISM; MODELS; Representation learning; Sequence; SMILES; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TMCX36SR","journalArticle","2024","He, M; Bakker, EM; Lew, MS","DPD (DePression Detection) Net: a deep neural network for multimodal depression detection","HEALTH INFORMATION SCIENCE AND SYSTEMS","","2047-2501","10.1007/s13755-024-00311-9","","Depression is one of the most prevalent mental conditions which could impair people's productivity and lead to severe consequences. The diagnosis of this disease is complex as it often relies on a physician's subjective interview-based screening. The aim of our work is to propose deep learning models for automatic depression detection by using different data modalities, which could assist in the diagnosis of depression. Current works on automatic depression detection mostly are tested on a single dataset, which might lack robustness, flexibility and scalability. To alleviate this problem, we design a novel Graph Neural Network-enhanced Transformer model named DePressionDetect Net (DPD Net) that leverages textual, audio and visual features and can work under two different application settings: the clinical setting and the social media setting. The model consists of a unimodal encoder module for encoding single modality, a multimodal encoder module for integrating the multimodal information, and a detection module for producing the final prediction. We also propose a model named DePressionDetect-with-EEG Net (DPD-E Net) to incorporate Electroencephalography (EEG) signals and speech data for depression detection. Experiments across four benchmark datasets show that DPD Net and DPD-E Net can outperform the state-of-the-art models on three datasets (i.e., E-DAIC dataset, Twitter depression dataset and MODMA dataset), and achieve competitive performance on the fourth one (i.e., D-vlog dataset). Ablation studies demonstrate the advantages of the proposed modules and the effectiveness of combining diverse modalities for automatic depression detection.","2024-11-12","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","1","12","","","","","","","","","","English","","","","WOS:001352942300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Deep neural network; Depression detection; Ensemble model; FRAMEWORK; Graph neural networks; Multimodal data; RECOGNITION; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TIJW2K9M","journalArticle","2024","Wang, LF; Zhang, CH; Li, J","A Hybrid CNN-Transformer Model for Predicting N Staging and Survival in Non-Small Cell Lung Cancer Patients Based on CT-Scan","TOMOGRAPHY","","2379-1381","10.3390/tomography10100123","","Accurate assessment of N staging in patients with non-small cell lung cancer (NSCLC) is critical for the development of effective treatment plans, the optimization of therapeutic strategies, and the enhancement of patient survival rates. This study proposes a hybrid model based on 3D convolutional neural networks (CNNs) and transformers for predicting the N-staging and survival rates of NSCLC patients within the NSCLC radiogenomics and Nsclc-radiomics datasets. The model achieved accuracies of 0.805, 0.828, and 0.819 for the training, validation, and testing sets, respectively. By leveraging the strengths of CNNs in local feature extraction and the superior performance of transformers in global information modeling, the model significantly enhances predictive accuracy and efficacy. A comparative analysis with traditional CNN and transformer architectures demonstrates that the CNN-transformer hybrid model outperforms N-staging predictions. Furthermore, this study extracts the one-year survival rate as a feature and employs the Lasso-Cox model for survival predictions at various time intervals (1, 3, 5, and 7 years), with all survival prediction p-values being less than 0.05, illustrating the time-dependent nature of survival analysis. The application of time-dependent ROC curves further validates the model's accuracy and reliability for survival predictions. Overall, this research provides innovative methodologies and new insights for the early diagnosis and prognostic evaluation of NSCLC.","2024-10","2025-02-26 20:43:25","2025-02-26 20:43:25","","1676-1693","","10","10","","","","","","","","","","English","","","","WOS:001341969700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","CNN-transformer hybrid model; INVASION; LYMPH-NODE METASTASIS; N-staging prediction; non-small cell lung cancer; PROLIFERATION; survival analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B26Y6T23","journalArticle","2024","Fan, YZ; Song, JH; Yuan, L; Jia, YL","HCT-Unet: multi-target medical image segmentation via a hybrid CNN-transformer Unet incorporating multi-axis gated multi-layer perceptron","VISUAL COMPUTER","","0178-2789","10.1007/s00371-024-03612-y","","In recent years, for the purpose of integrating the individual strengths of convolutional neural networks (CNN) and Transformer, a network structure has been built to integrate the two methods in medical image segmentation. But most of the methods only integrate CNN and Transformer at a single level and cannot extract low-level detail features and high-level abstract information simultaneously. Meanwhile, this structure lacks flexibility, unable to dynamically adjust the contributions of different feature maps. To address these limitations, we introduce HCT-Unet, a hybrid CNN-Transformer model specifically designed for multi-organ medical images segmentation. HCT-Unet introduces a tunable hybrid paradigm that differs significantly from conventional hybrid architectures. It deploys powerful CNN to capture short-range information and Transformer to extract long-range information at each stage. Furthermore, we have designed a multi-functional multi-scale fusion bridge, which progressively integrates information from different scales and dynamically modifies attention weights for both local and global features. With the benefits of these two innovative designs, HCT-Unet demonstrates robust discriminative dependency and representation capabilities in multi-target medical image tasks. Experimental results reveal the remarkable performance of our approach in medical image segmentation tasks. Specifically, in multi-organ segmentation tasks, HCT-Unet achieved a Dice similarity coefficient (DSC) of 82.23%. Furthermore, in cardiac segmentation tasks, it reached a DSC of 91%, significantly outperforming previous state-of-the-art networks. The code has been released on Zenodo: https://zenodo.org/doi/10.5281/zenodo.11070837.","2024-09-06","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","","","","","","","","","","","","English","","","","WOS:001306546100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","CNN; GMLP; Medical image segmentation; Multi-scale fusion; NET; NETWORK; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2PGTMS87","journalArticle","2024","Borchert, F; Llorca, I; Schapranow, MP","Improving biomedical entity linking for complex entity mentions with LLM-based text simplification","DATABASE-THE JOURNAL OF BIOLOGICAL DATABASES AND CURATION","","1758-0463","10.1093/database/baae067","","Large amounts of important medical information are captured in free-text documents in biomedical research and within healthcare systems, which can be made accessible through natural language processing (NLP). A key component in most biomedical NLP pipelines is entity linking, i.e. grounding textual mentions of named entities to a reference of medical concepts, usually derived from a terminology system, such as the Systematized Nomenclature of Medicine Clinical Terms. However, complex entity mentions, spanning multiple tokens, are notoriously hard to normalize due to the difficulty of finding appropriate candidate concepts. In this work, we propose an approach to preprocess such mentions for candidate generation, building upon recent advances in text simplification with generative large language models. We evaluate the feasibility of our method in the context of the entity linking track of the BioCreative VIII SympTEMIST shared task. We find that instructing the latest Generative Pre-trained Transformer model with a few-shot prompt for text simplification results in mention spans that are easier to normalize. Thus, we can improve recall during candidate generation by 2.9 percentage points compared to our baseline system, which achieved the best score in the original shared task evaluation. Furthermore, we show that this improvement in recall can be fully translated into top-1 accuracy through careful initialization of a subsequent reranking model. Our best system achieves an accuracy of 63.6% on the SympTEMIST test set. The proposed approach has been integrated into the open-source xMEN toolkit, which is available online via https://github.com/hpi-dhc/xmen.","2024-07-26","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","","2024","","","","","","","","","","English","","","","WOS:001276846000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z8B89GDY","journalArticle","2024","Erdas, CB","Computer-aided colorectal cancer diagnosis: AI-driven image segmentation and classification","PEERJ COMPUTER SCIENCE","","2376-5992","10.7717/peerj-cs.2071","","Colorectal cancer is an enormous health concern since it is among the most lethal types of malignancy. The manual examination has its limitations, including subjectivity and data overload. To overcome these challenges, computer -aided diagnostic systems focusing on image segmentation and abnormality classi fi cation have been developed. This study presents a two -stage approach for the automatic detection of fi ve types of colorectal abnormalities in addition to a control group: polyp, low-grade intraepithelial neoplasia, high-grade intraepithelial neoplasia, serrated adenoma, adenocarcinoma. In the fi rst stage, UNet3+ was used for image segmentation to locate the anomalies, while in the second stage, the Cross -Attention Multi -Scale Vision Transformer deep learning model was used to predict the type of anomaly after highlighting the anomaly on the raw images. In anomaly segmentation, UNet3+ achieved values of 0.9872, 0.9422, 0.9832, and 0.9560 for Dice Coef fi cient, Jaccard Index, Sensitivity, Speci fi city respectively. In anomaly detection, the Cross -Attention Multi -Scale Vision Transformer model attained a classi fi cation performance of 0.9340, 0.9037, 0.9446, 0.8723, 0.9102, 0.9849 for accuracy, F1 score, precision, recall, Matthews correlation coef fi cient, and speci fi city, respectively. The proposed approach proves its capacity to alleviate the overwhelm of pathologists and enhance the accuracy of colorectal cancer diagnosis by achieving high performance in both the identi fi cation of anomalies and the segmentation of regions.","2024-05-17","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","","10","","","","","","","","","","English","","","","WOS:001229315800003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Anomaly classi fi cation; Colorectal cancer; Computer-aided diagnosis; Deep learning; Histopathology; Image segmentation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DSMZFVV5","journalArticle","2023","Alsayed, A; Qadah, TM; Arif, M","A performance analysis of transformer-based deep learning models for Arabic image captioning","JOURNAL OF KING SAUD UNIVERSITY-COMPUTER AND INFORMATION SCIENCES","","1319-1578","10.1016/j.jksuci.2023.101750","","Image captioning has become a fundamental operation that allows the automatic generation of text descriptions of images. However, most existing work focused on performing the image captioning task in English, and only a few proposals exist that address the image captioning task in Arabic. This paper focuses on understanding the factors that affect the performance of machine learning models performing Arabic image captioning (AIC). In particular, we focus on transformer-based models for AIC and study the impact of various text-preprocessing methods: CAMeL Tools, ArabertPreprocessor, and Stanza. Our study shows that using CAMeL Tools to preprocess text labels improves the AIC performance by up to 34-92% in the BLEU-4 score. In addition, we study the impact of image recognition models. Our results show that ResNet152 is better than EfficientNet-B0 and can improve BLEU scores performance by 9-11%. Furthermore, we investigate the impact of different datasets on the overall AIC performance and build an extended version of the Arabic Flickr8k dataset. Using the extended version improves the BLEU-4 score of the AIC model by up to 148%. Finally, utilizing our results, we build a model that significantly outperforms the state-of-the-art proposals in AIC by up to 196-379% in the BLUE-4 score. (c) 2023 The Author(s). Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).","2023-10","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","9","35","","","","","","","","","","English","","","","WOS:001098924200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Arabic image captioning; Arabic technologies; Deep learning; Image captioning; Machine learning; Performance analysis and evaluation; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X5LJHKT2","journalArticle","2023","Wang, YB; Ma, WR; Xu, HT; Liu, YW; Yin, P","A Lightweight Multi-View Learning Approach for Phishing Attack Detection Using Transformer with Mixture of Experts","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13137429","","Phishing poses a significant threat to the financial and privacy security of internet users and often serves as the starting point for cyberattacks. Many machine-learning-based methods for detecting phishing websites rely on URL analysis, offering simplicity and efficiency. However, these approaches are not always effective due to the following reasons: (1) highly concealed phishing websites may employ tactics such as masquerading URL addresses to deceive machine learning models, and (2) phishing attackers frequently change their phishing website URLs to evade detection. In this study, we propose a robust, multi-view Transformer model with an expert-mixture mechanism for accurate phishing website detection utilizing website URLs, attributes, content, and behavioral information. Specifically, we first adapted a pretrained language model for URL representation learning by applying adversarial post-training learning in order to extract semantic information from URLs. Next, we captured the attribute, content, and behavioral features of the websites and encoded them as vectors, which, alongside the URL embeddings, constitute the website's multi-view information. Subsequently, we introduced a mixture-of-experts mechanism into the Transformer network to learn knowledge from different views and adaptively fuse information from various views. The proposed method outperforms state-of-the-art approaches in evaluations of real phishing websites, demonstrating greater performance with less label dependency. Furthermore, we show the superior robustness and enhanced adaptability of the proposed method to unseen samples and data drift in more challenging experimental settings.","2023-07","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","13","13","","","","","","","","","","English","","","","WOS:001028342300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","MALICIOUS URL; MODEL; multi-view learning; phishing attack detection; self-supervised learning; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XSWT2XXC","journalArticle","2022","Patil, RR; Kumar, S","Rice Transformer: A Novel Integrated Management System for Controlling Rice Diseases","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3200688","","Rice disease classification is vital during the cultivation of rice crops. However, rice diseases were initially detected by visual examination from agricultural experts. Later the detection process progressed to automation, which involved images. The images captured lead to a lack of supporting information. The traditional approaches are less accurate when used with real time images. To address this limitation, a novel Rice Transformer is proposed in the paper that merges inputs from agricultural sensors and image data captured from the fields simultaneously. The proposed system consists of two branches: the sensor and image branches. Specifically, the attention approach is employed to extract the features from both modalities. Later, the extracted features are sent to the cross-attention module as input in a crisscross fashion, enhancing the ability to identify the features specific to rice diseases. The extracted features are further pooled, merged, and later passed through the Softmax classifier to classify the rice disease precisely. The dataset collected is a customized dataset with 4200 samples collected on a real-time basis from rice farms. The experiments conducted on the dataset represent that the proposed approach outperforms all the other fusion and attention models considered for comparison in this paper. The ablation analysis and performance metrics are measured to determine the effectiveness of the proposed system. The results achieved are quite promising as the proposed Rice transformer model achieves an accuracy of 97.38% for controlling rice disease.","2022","2025-02-26 20:43:25","2025-02-26 20:43:25","","87698-87714","","","10","","","","","","","","","","English","","","","WOS:000845005100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;21<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Agriculture; Crops; cross attention; data fusion; Data integration; Deep learning; Diseases; Feature extraction; Image sensors; IMAGES; multimodal; PLANTS; rice diseases; Rice transformer; self attention; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X668JVWR","journalArticle","2023","Kashyap, B; Pathirana, PN; Horne, M; Power, L; Szmulewicz, DJ","Machine Learning-Based Scoring System to Predict the Risk and Severity of Ataxic Speech Using Different Speech Tasks","IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING","","1534-4320","10.1109/TNSRE.2023.3334718","","The assessment of speech in Cerebellar Ataxia (CA) is time-consuming and requires clinical interpretation. In this study, we introduce a fully automated objective algorithm that uses significant acoustic features from time, spectral, cepstral, and non-linear dynamics present in microphone data obtained from different repeated Consonant-Vowel (C-V) syllable paradigms. The algorithm builds machine-learning models to support a 3-tier diagnostic categorisation for distinguishing Ataxic Speech from healthy speech, rating the severity of Ataxic Speech, and nomogram-based supporting scoring charts for Ataxic Speech diagnosis and severity prediction. The selection of features was accomplished using a combination of mass univariate analysis and elastic net regularization for the binary outcome, while for the ordinal outcome, Spearman's rank-order correlation criterion was employed. The algorithm was developed and evaluated using recordings from 126 participants: 65 individuals with CA and 61 controls (i.e., individuals without ataxia or neurotypical). For Ataxic Speech diagnosis, the reduced feature set yielded an area under the curve (AUC) of 0.97 (95% CI 0.90-1), the sensitivity of 97.43%, specificity of 85.29%, and balanced accuracy of 91.2% in the test dataset. The mean AUC for severity estimation was 0.74 for the test set. The high C-indexes of the prediction nomograms for identifying the presence of Ataxic Speech (0.96) and estimating its severity (0.81) in the test set indicates the efficacy of this algorithm. Decision curve analysis demonstrated the value of incorporating acoustic features from two repeated C-V syllable paradigms. The strong classification ability of the specified speech features supports the framework's usefulness for identifying and monitoring Ataxic Speech.","2023","2025-02-26 20:43:25","2025-02-26 20:43:25","","4839-4850","","","31","","","","","","","","","","English","","","","WOS:001127167800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Cerebellar ataxia; cerebellar dysarthria; CEREBELLAR-ATAXIA; DYSARTHRIA; FRIEDREICH ATAXIA; QUANTITATIVE ASSESSMENT; speech processing; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GIKTL2DB","journalArticle","2025","Han, Y; Moghaddam, M","Design Knowledge as Attention Emphasizer in Large Language Model-Based Sentiment Analysis","JOURNAL OF COMPUTING AND INFORMATION SCIENCE IN ENGINEERING","","1530-9827","10.1115/1.4067212","","Aspect-based sentiment analysis (ABSA) enables a systematic identification of user opinions on particular aspects, thus improving the idea creation process in the initial stages of a product/service design. Large language models (LLMs) such as T5 and GPT have proven powerful in ABSA tasks due to their inherent attention mechanism. However, some key limitations remain. First, existing research mainly focuses on relatively simpler ABSA tasks such as aspect-based sentiment analysis, while the task of extracting aspects, opinions, and sentiment in a unified model remains largely unaddressed. Second, current ABSA tasks overlook implicit opinions and sentiments. Third, most attention-based LLMs use position encoding in a linear projected manner or through split-position relations in word distance schemes, which could lead to relation biases during the training process. This paper incorporates domain knowledge into LLMs by introducing a new position encoding strategy for the transformer model. This paper addresses these gaps by (1) introducing the ACOSI (aspect, category, opinion, sentiment, implicit indicator) analysis task, developing a unified model capable of extracting all five types of labels in the ACOSI analysis task simultaneously in a generative manner; (2) designing a new position encoding method in the attention-based model; and (3) introducing a new benchmark based on ROUGE score that incorporates design domain knowledge inside. The numerical experiments on manually labeled data from three major e-Commerce retail stores for apparel and footwear products showcase the domain knowledge inserted transformer method's performance, scalability, and potential.","2025-02-01","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","2","25","","","","","","","","","","English","","","","WOS:001403467800010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;113</p>","","","design knowledge; large language model; MARKET ORIENTATION; MASS CUSTOMIZATION; multi-instance inference; position encoding; PRODUCT DESIGN; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y5JAJTSL","journalArticle","2025","Qin, BS; Li, JC; Tang, SL; Zhuang, YT","DBA: Efficient Transformer With Dynamic Bilinear Low-Rank Attention","IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS","","2162-237X","10.1109/TNNLS.2025.3527046","","Many studies have aimed to improve Transformer model efficiency using low-rank-based methods that compress sequence length with predetermined or learned compression matrices. However, these methods fix compression coefficients for tokens in the same position during inference, ignoring sequence-specific variations. They also overlook the impact of hidden state dimensions on efficiency gains. To address these limitations, we propose dynamic bilinear low-rank attention (DBA), an efficient and effective attention mechanism that compresses sequence length using input-sensitive dynamic compression matrices. DBA achieves linear time and space complexity by jointly optimizing sequence length and hidden state dimension while maintaining state-of-the-art performance. Specifically, we demonstrate through experiments and the properties of low-rank matrices that sequence length can be compressed with compression coefficients dynamically determined by the input sequence. In addition, we illustrate that the hidden state dimension can be approximated by extending the Johnson-Lindenstrauss lemma, thereby introducing only a small amount of error. DBA optimizes the attention mechanism through bilinear forms that consider both the sequence length and hidden state dimension. Moreover, the theoretical analysis substantiates that DBA excels at capturing high-order relationships in cross-attention problems. Experimental results across different tasks with varied sequence length conditions demonstrate that DBA achieves state-of-the-art performance compared to several robust baselines. DBA also maintains higher processing speed and lower memory usage, highlighting its efficiency and effectiveness across diverse applications.","2025-01-16","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","","","","","","","","","","","","English","","","","WOS:001398744700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;82</p>","","","Attention mechanisms; Bilinear optimization; Complexity theory; dynamic compression; efficient transformer; Image coding; Kernel; Learning systems; low-rank attention; Memory management; Optimization; Sparse matrices; Training; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KLWY9IYK","journalArticle","2024","Wang, TT; Hu, YF; Fang, Q; He, BB; Gong, X; Wang, P","DK-Former: A Hybrid Structure of Deep Kernel Gaussian Process Transformer Network for Enhanced Traffic Sign Recognition","IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS","","1524-9050","10.1109/TITS.2024.3436911","","Traffic sign recognition is crucial for enhancing the safety and efficiency of intelligent transportation systems (ITS). This paper proposes a hybrid structure named DK-former, a lightweight and robust deep kernel Gaussian process transformer network, aiming to tackle non-linear small samples, high model parameters, and environmental variations, providing a distinctive solution that enhances robustness and adaptability in intelligent transportation systems. The whole structure is trained end-to-end based on the Bayesian framework. First, introducing convolutional random Fourier features facilitates effective non-linear sample feature mapping, capturing complex patterns inherent in traffic signs and enhancing computational efficiency. Second, the transformer model refines feature representations with its powerful self-attention mechanism to capture the global relationship between traffic sign pixels. Furthermore, the hybrid structure enhances the generalization capability of the model, allowing it to adapt to diverse scenarios, such as varying lighting conditions and weather fluctuations commonly encountered in real-world traffic environments. Extensive experiments have been conducted to validate the effectiveness of the proposed DK-former for traffic sign recognition. The model has achieved an outstanding recognition accuracy of 99.09% on the German Traffic Sign Recognition Benchmark (GTSRB) dataset, superior to current state-of-the-art deep kernel learning traffic sign models with only 8.3 million parameters. Experiments on Indian and Chinese datasets comprehensively demonstrate the generalization of the model across different geographies and environments. The code is publicly available at: https://github.com/w-tingting/DK-former.","2024-11","2025-02-26 20:43:25","2025-02-26 20:43:25","","18561-18572","","11","25","","","","","","","","","","English","","","","WOS:001288380600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Accuracy; Autonomous vehicles; Computational modeling; Convolution; deep kernel network; Feature extraction; Kernel; random Fourier feature; traffic sign recognition; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NWTMSXT2","journalArticle","2024","Peng, S; Guo, Y; Wang, JH; Wang, Y; Zhang, WH; Zhou, X; Jiang, LF; Lai, B","The coagulation-precipitation turbidity prediction model for precision drug delivery system based on deep learning and machine vision","JOURNAL OF ENVIRONMENTAL CHEMICAL ENGINEERING","","2213-2929","10.1016/j.jece.2024.112211","","The process effect of coagulation and precipitation is an important factor affecting the quality and economic cost of wastewater treatment, but it is very difficult to automatically control the dosage due to its nonlinear and large lag characteristics. Model prediction method will be the main direction to deal with nonlinearity and lag. In the process of coagulation and precipitation, the morphological characteristics of the floc reflect the quality of the flocculation, which has a great influence on the effluent quality. However, many modeling studies only use the water quality parameters of the previous moment to predict the effluent quality of the current moment, without considering the continuity of the flocculation precipitation process and the information represented by the floc image. The purpose of this paper is to solve the problem of precise dosing during coagulation and precipitation, save dosing cost. In this study, a self-built continuous coagulation and precipitation experimental system based on machine vision was used to conduct experiments and collect data, a self-written image processing program was used to quantitatively analyze the flocculation effect. LSTM model and Transformer model were used for training. The results showed that the deep learning model using time series data and flocs feature parameters had higher prediction accuracy, and both models achieved more accurate prediction (R-2>0.95). The results of this study provide a new direction for the model predictive control of coagulation-precipitation process and precise dosing.","2024-04","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","2","12","","","","","","","","","","English","","","","WOS:001188090100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Coagulation precipitation; Deep learning; FLOCCULATION; FLOCS; Image processing; Neural network; NEURAL-NETWORK; QUALITY; Turbidity prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CM3JHG4A","journalArticle","2024","Ishtiaq, A; Munir, K; Raza, A; Samee, NA; Jamjoom, MM; Ullah, Z","Product Helpfulness Detection With Novel Transformer Based BERT Embedding and Class Probability Features","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3390605","","Nowadays global market products are readily accessible worldwide, and a vast array of reviews across numerous platforms are posted daily in several categories, making it challenging for customers to stay informed about their product interests. To make informed decisions regarding product quality, users require access to reviews and ratings. Owners and managers must analyze customer ratings and the underlying emotional content of reviews to enhance the product's quality, cost, customer service, and environmental impact. The primary aim of our proposed research is to accurately predict product helpfulness through customer reviews using the Large Language Model (LLM), thereby assisting customers in saving time and money. We employed a benchmark dataset, the Amazon Fine Food Reviews, to develop numerous advanced machine-learning techniques. We introduced a novel transformer approach BERF (BERT Random Forest) for feature engineering to enhance the value of user evaluations for Amazon's gourmet food products. The BERF method utilizes BERT embeddings and class probability features derived from product helpfulness online reviews textual data. We have balanced the dataset using the Synthetic Minority Over-sampling TEchnique (SMOTE) approach. Our comprehensive study results demonstrated that the Light Gradient Boosting Machine (LGBM) strategy outperformed existing state-of-the-art approaches, achieving an accuracy of 98%. The performance of each method is confirmed using a k-fold method and further improved through hyperparameter optimization. Our innovative study employing a transformer model has significantly enhanced the utility of customer reviews, substantially reducing online product scams and preventing wasted time and money.","2024","2025-02-26 20:43:25","2025-02-26 20:43:25","","55905-55917","","","12","","","","","","","","","","English","","","","WOS:001208020100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","BERT; CLASSIFICATION; deep learning; large language model (LLM); machine learning; Product helpfulness; text mining; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P9H26HAC","journalArticle","2023","Meng, YQ; Jiang, JG; Wu, JC; Wang, D","Transformer-based deep learning models for predicting permeability of porous media","ADVANCES IN WATER RESOURCES","","0309-1708","10.1016/j.advwatres.2023.104520","","The direct acquisition of the permeability of porous media by digital images helps to enhance our understanding of and facilitate research into the problem of subsurface flow. A complex pore space makes the numerical simulation methods used to calculate the permeability quite time-consuming. Deep learning models represented by three-dimensional convolutional neural networks (3D CNNs), as a promising approach to improving efficiency, have made significant advances concerning predicting the permeability of porous media. However, 3D CNNs require significant computational resources due to their extensive parameters, which limit studies to small sized porous media, and their generalization capabilities are insufficiently explored. To address these challenges, we propose a novel CNN-Transformer hybrid neural network, merging a 2D CNN with a self-attention mechanism. Additionally, we incorporate physical information into digital images, constructing a PhyCNN-Transformer model to reflect the impact of physical properties on permeability prediction. In terms of dataset preparation, we employ the publicly available DeePore porous media dataset with sample size of 2563 cubic voxels and labeled permeability calculated by Pore network modelling (PNM). We compare the two transformer-based models with a 3D CNN in terms of parameter number, training efficiency, prediction performance, and generalization, and the results show significant improvement. By employing transfer learning, the well-trained transformer-based models proved capable of adapting to porous media with different sizes (achieving an R2 score of 0.9563 with 300 training samples), while the 3D CNN lacks this transferability.","2023-09","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","","179","","","","","","","","","","English","","","","WOS:001087215200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;92</p>","","","FLOW; FRAMEWORK; Neural network; Permeability; PORE-NETWORK; Porous media; RELATIVE PERMEABILITY; SCALE; Self-attention mechanism; Transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G3ZNPZ9Y","journalArticle","2022","Lu, XY; Yang, R; Zhou, J; Jiao, J; Liu, F; Liu, YF; Su, BF; Gu, PW","A hybrid model of ghost-convolution enlightened transformer for effective diagnosis of grape leaf disease and pest","JOURNAL OF KING SAUD UNIVERSITY-COMPUTER AND INFORMATION SCIENCES","","1319-1578","10.1016/j.jksuci.2022.03.006","","Disease and pest are the main factors causing grape yield reduction. Correct and timely identification of these symptoms are necessary for the vineyard. However, the commonly used CNN models limit their performance on leaf images with complex backgrounds, due to the lack of global receptive field. In this article, we propose an effective and accurate approach based on Ghost-convolution and Transformer networks for diagnosing grape leaf in field. First, a grape leaf disease and pest dataset containing 11 classes and 12,615 images, namely GLDP12k is collected. Ghost network is adopted as the convolutional backbone to generate intermediate feature maps with cheap linear operations. Transformer encoders with multi-head self-attention are integrated behind to extract deep semantic features. Then we get the Ghost enlightened Transformer model, namely GeT. After analyzing five hyper-parameters, the optimized GeT is transfer-learnt from ImageNet which provides a 4.3% accuracy bonus. As the results show, with 180 frame-per-second, 1.16 M weights and 98.14% accuracy, GeT surpasses other models, and is 1.7 times faster and 3.6 times lighter than MobilenetV3_large (97.7%). This study shows that the GeT model is effective and provides an optional benchmark for field grape leaf diagnosis. (c) 2022 The Author(s). Published by Elsevier B.V. on behalf of King Saud University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).","2022-05","2025-02-26 20:43:25","2025-02-26 20:43:25","","1755-1767","","5","34","","","","","","","","","","English","","","","WOS:000796192500012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;50<br/>Total Times Cited:&nbsp;&nbsp;52<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","CLASSIFICATION; Deep learning; Ghost convolution; Grape disease identification; RECOGNITION; SEGMENTATION; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y367K32Y","journalArticle","2024","Yao, DJ; Zhang, BB; Zhan, XJ; Zhang, B; Li, XK","Predicting lncRNA-Disease Associations Based on a Dual-Path Feature Extraction Network with Multiple Sources of Information Integration","ACS OMEGA","","2470-1343","10.1021/acsomega.4c05365","","Identifying the associations between long noncoding RNAs (lncRNAs) and disease is critical for disease prevention, diagnosis and treatment. However, conducting wet experiments to discover these associations is time-consuming and costly. Therefore, computational modeling for predicting lncRNA-disease associations (LDAs) has become an important alternative. To enhance the accuracy of LDAs prediction and alleviate the issue of node feature oversmoothing when exploring the potential features of nodes using graph neural networks, we introduce DPFELDA, a dual-path feature extraction network that leverages the integration of information from multiple sources to predict LDA. Initially, we establish a dual-view structure of lncRNAs and disease and a heterogeneous network of lncRNA-disease-microRNA (miRNA) interactions. Subsequently, features are extracted using a dual-path feature extraction network. In particular, we employ a combination of a graph convolutional network, a convolutional block attention module, and a node aggregation layer to perform multilayer topology feature extraction for the dual-view structure of lncRNAs and diseases. Additionally, we utilize a Transformer model to construct the node topology feature residual network for obtaining node-specific features in heterogeneous networks. Finally, XGBoost is employed for LDA prediction. The experimental results demonstrate that DPFELDA outperforms the benchmark model on various benchmark data sets. In the course of model exploration, it becomes evident that DPFELDA successfully alleviates the issue of node feature oversmoothing induced by graph-based learning. Ablation experiments confirm the effectiveness of the innovative module, and a case study substantiates the accuracy of DPFELDA model in predicting novel LDAs for characteristic diseases.","2024-07-30","2025-02-26 20:43:25","2025-02-26 20:43:25","","35100-35112","","32","9","","","","","","","","","","English","","","","WOS:001282029500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","SIMILARITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C23TUS66","journalArticle","2024","Alghanmi, N; Alotaibi, R; Alshammari, S; Mahmood, A","Population Fusion Transformer for Subnational Population Forecasting","INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS","","1875-6891","10.1007/s44196-024-00413-y","","Forecasting the subnational population accurately is needed for sustainable development, including planning for the future, allocating resources, or providing health services. Two approaches are used for forecasting subnational populations: local forecasting where a model is trained for each area, and global forecasting, where one model is trained with all areas. Local forecasting (e.g., statistical models) is limited to capturing the population growth patterns in a single area. Machine learning models, such as the light gradient boosting model (LGBM), are considered a more suitable approach for global forecasting, but it is limited to one-step predictions, leading to error accumulation. Also, combining several models into one ensemble model are used which helped in reduce forecasting errors. However, the nature of population growth is nonlinear, and there is a need to reduce error accumulation. This study overcomes these issues and proposes a population fusion transformer (PFT) as a global forecasting model for population forecasting, which outputs multi-step predictions. The PFT is based on a temporal fusion transformer (TFT) proposing a novel deep gated residual network (DGRN) block to capture data nonlinearity. This study also incorporates the proposed PFT model into various ensemble models to reduce forecasting errors using different prediction and learning approaches. The proposed models are applied to four subnational population datasets from several countries. The PFT model outperforms the LGBM and TFT with lower forecasting errors in three and two datasets. More importantly, combining the PFT with other models in ensemble models reduced errors further.","2024-02-06","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","1","17","","","","","","","","","","English","","","","WOS:001157082600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Population forecasts; Population fusion transformer; Population growth prediction; Subnational area population forecasting; Time-series model; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BWS2XQYQ","journalArticle","2025","Guan, QL; Dong, X; Zhang, W; Sun, LY; Zhu, JJ; Luo, TG; Xu, SG","Mode recognition in a kerosene-fueled scramjet combustor by a Swin Transformer neural network","PHYSICS OF FLUIDS","","1070-6631","10.1063/5.0251192","","Recognizing the combustion mode in scramjet engines is critical for suppressing oscillations and stabilizing the combustion process in hypersonic aircrafts. Current accesses mainly depend on mechanical measurement and dominant frequencies based on image analysis methods, such as proper orthogonal decomposition and dynamic mode decomposition. However, these traditional methods either lack of precision or fall short of the need for prior knowledge, poor generalization, and low efficiency, posing challenges in practical implementations, especially when online controlling is highlighted in the scramjet combustions. Recently, machine learning (ML) has been introduced to the combustion community due to its superiority in high flexibility and efficiency in addressing complex problems. The classical convolutional neural network (CNN) architectures have been reported to achieve efficient combustion mode recognition in furnace combustion, swirling combustor, and rotating detonation engines. However, those CNN-based models are incapable of utilizing the global flame features and the coherences of local areas, resulting in insufficient accuracy and robustness in scramjet combustions with high inflow speed and distinct mode variations. To address this problem, this paper reports a Swin (shifted window) Transformer model, an advanced ML structure outstanding in capturing both global and local features by its self-attention mechanism with high computational efficiency, to identify combustion modes in scramjet engines. The Swin-T was trained and validated in a kerosene-fueled cavity-based scramjet combustor, and results show that it can achieve a considerable accuracy of 95.28%. Comparisons with CNN-based models further indicate that Swin-T outperforms in accuracy, efficiency, and robustness by around 0.7%, 80%, and 3%, respectively.","2025-02","2025-02-26 20:43:25","2025-02-26 20:43:25","","","","2","37","","","","","","","","","","English","","","","WOS:001413948400039","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","FLAME STABILIZATION; IGNITION; INSTABILITY; SUPERSONIC COMBUSTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZR7UPCJ4","journalArticle","2025","Trachoo, V; Taetragool, U; Pianchoopat, P; Sukitporn-udom, C; Morakrant, N; Warin, K","Deep Learning for Predicting the Difficulty Level of Removing the Impacted Mandibular Third Molar","INTERNATIONAL DENTAL JOURNAL","","0020-6539","10.1016/j.identj.2024.06.021","","Background: Preoperative assessment of the impacted mandibular third molar (LM3) in a panoramic radiograph is important in surgical planning. The aim of this study was to develop and evaluate a computer-aided visualisation-based deep learning (DL) system using a panoramic radiograph to predict the difficulty level of surgical removal of an impacted LM3. Methods: The study included 1367 LM3 images from 784 patients who presented from 2021-2023 to the University Dental Hospital; images were collected retrospectively. The difficulty level of surgically removing impacted LM3s was assessed via our newly developed DL system, which seamlessly integrated 3 distinct DL models. ResNet101V2 handled binary classification for identifying impacted LM3s in panoramic radiographs, RetinaNet detected the precise location of the impacted LM3, and Vision Transformer performed multiclass image classification to evaluate the difficulty levels of removing the detected impacted LM3. Results: The ResNet101V2 model achieved a classification accuracy of 0.8671. The RetinaNet model demonstrated exceptional detection performance, with a mean average precision of 0.9928. Additionally, the Vision Transformer model delivered an average accuracy of 0.7899 in predicting removal difficulty levels. Conclusions: The development of a 3-phase computer-aided visualisation-based DL system has yielded a very good performance in using panoramic radiographs to predict the difficulty level of surgically removing an impacted LM3. (c) 2024 The Authors. Published by Elsevier Inc. on behalf of FDI World Dental Federation. (http://creativecommons.org/licenses/by-nc-nd/4.0/)","2025-02","2025-02-26 20:43:26","2025-02-26 20:43:26","","144-150","","1","75","","","","","","","","","","English","","","","WOS:001406120000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","AGREEMENT; Artificial intelligence; COMPLICATIONS; Deep learning; Impacted tooth; Neural network; Panoramic radiograph; PATHOLOGY; SURGERY; TEETH; Third molar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CYBQYGCM","journalArticle","2024","Wang, XY; Wang, SF","ACP-PDAFF: Pretrained model and dual-channel attentional feature fusion for anticancer peptides prediction","COMPUTATIONAL BIOLOGY AND CHEMISTRY","","1476-9271","10.1016/j.compbiolchem.2024.108141","","Anticancer peptides(ACPs) have attracted significant interest as a novel method of treating cancer due to their ability to selectively kill cancer cells without damaging normal cells. Many artificial intelligence-based methods have demonstrated impressive performance in predicting ACPs. Nevertheless, the limitations of existing methods in feature engineering include handcrafted features driven by prior knowledge, insufficient feature extraction, and inefficient feature fusion. In this study, we propose a model based on a pretrained model, and dual-channel attentional feature fusion(DAFF), called ACP-PDAFF. Firstly, to reduce the heavy dependence on expert knowledge-based handcrafted features, binary profile features (BPF) and physicochemical properties features(PCPF) are used as inputs to the transformer model. Secondly, aimed at learning more diverse feature informations of ACPs, a pretrained model ProtBert is utilized. Thirdly, for better fusion of different feature channels, DAFF is employed. Finally, to evaluate the performance of the model, we compare it with other methods on five benchmark datasets, including ACP-Mixed-80 dataset, Main and Alternate datasets of AntiCP 2.0, LEE and Independet dataset, and ACPred-Fuse dataset. And the accuracies obtained by ACP-PDAFF are 0.86, 0.80, 0.94, 0.97 and 0.95 on five datasets, respectively, higher than existing methods by 1% to 12%. Therefore, by learning rich feature informations and effectively fusing different feature channels, ACD-PDAFF achieves outstanding performance. Our code and the datasets are available at https://github.com/wongsing/ ACP-PDAFF.","2024-10","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","112","","","","","","","","","","English","","","","WOS:001269389600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Anticancer peptides; Attentional feature fusion; CLASSIFICATION; Handcrafted features; IACP; Pretrained model; Transformer; WEB SERVER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"642QI46G","journalArticle","2024","Chen, XR; Zhao, CY; Liu, XJ; Zhang, SC; Xi, JB; Khan, BA","An Embedding Swin Transformer Model for Automatic Slow-Moving Landslide Detection Based on InSAR Products","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2024.3470325","","Interferometric synthetic aperture radar (InSAR) technology is the most advanced and effective method for monitoring large-scale slow-moving landslides. However, automatic landslide detection based on InSAR products regarding landslide samples and deep learning models is still challenging. Different InSAR products are inconsistent for slow-moving landslide detection due to the fuzzy boundaries of potential landslides and complex deformation characteristics. In addition, the accuracy of existing landslide detection models is not high because multiscale factors in feature abstract and feature fusion are rarely considered. This article proposes a multiscale Swin Transformer InSAR products detection network (MSIDNet) to detect slow-moving landslides automatically. First, we adopt an advanced Swin Transformer as the backbone to extract features and multiscale spatial-temporal attention blocks in the neck to improve the feature fusion capability. Meanwhile, to train the new model, we built a landslide dataset based on visual interpretation, including deformation rate, phase gradient, and C-index (GRCI). Experiments demonstrate that our proposed method outperforms the existing deep learning models such as Faster R-CNN and Yolov3. The GRCI dataset is more efficient and less biased than the traditional deformation rate and phase gradient datasets. The precision of detected landslides in a given testing area is 0.89, and it has good generalization ability. This study provides a new dataset and method for slow-moving landslide detection based on InSAR products.","2024","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","62","","","","","","","","","","English","","","","WOS:001336387700037","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","Accuracy; Automatic detection; Deep learning; Deformable models; Deformation; deformation phase gradient; EARTHQUAKE; FAILURE; Feature extraction; interferometric synthetic aperture radar (InSAR) deformation rate; Landslides; Rivers; Sentinel-1; Shape; Swin Transformer; Transformers; Yolo","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3E86R8N6","journalArticle","2023","Elsir, AMT; Khaled, A; Shen, YM","STTG-TTE: spatial-temporal gated multi-modality approach for travel time estimation based on temporal convolutional networks","NEURAL COMPUTING & APPLICATIONS","","0941-0643","10.1007/s00521-022-07977-w","","Travel time forecasting has become a core component of smart transportation systems, which assists both travelers and traffic organizers with route planning, travel schedule adjustments, ride-sharing, navigation applications, and efficient traffic management. However, timely and accurate travel time forecasting still remains a critical challenge owing to the complex nonlinear and dynamic fluctuations of spatial-temporal dependencies. Also, spatial sparseness is a big issue in traffic forecasting, since adopting the implicit interactions between the close traffic regions leads to superficial characterization of spatio-temporal dependences. In this paper, we propose a new deep learning-based framework (STTG-TTE) that addresses these drawbacks and improves the travel time estimation. First, we build a geo-hashing algorithm for the data sparsity issue that incorporates fluctuations of nearby and distant traffic situations in terms of spatio-temporal dependencies. Second, a new spatio-temporal correlation modeling method is proposed to fully leverage large-scale spatial and temporal traffic patterns using temporal convolutional networks integrated with a gated multi-modality mechanism. Then, for external factors' representation, a new dual-gated Res-Net multi-modality-based module is proposed. Finally, we fuse these representations of multi-components dynamically and utilize the transformer model, which is conducive to learning intersections among these multiple factors for obtaining accurate prediction results. Experiments on two large-scale real-world traffic datasets from two different urban regions (Chengdu taxi-datsets and NYC-Bike datasets) demonstrate that the proposed model is superior to state-of-the-art baseline models.","2023-03","2025-02-26 20:43:26","2025-02-26 20:43:26","","5535-5551","","7","35","","","","","","","","","","English","","","","WOS:000879156400005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Gated multi-modality; PREDICTION; Spatio-temporal dependencies; Temporal convolutional networks; Travel time estimation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VTF9GTXN","journalArticle","2022","Mogan, JN; Lee, CP; Lim, KM; Muthu, KS","Gait-ViT: Gait Recognition with Vision Transformer","SENSORS","","1424-8220","10.3390/s22197362","","Identifying an individual based on their physical/behavioral characteristics is known as biometric recognition. Gait is one of the most reliable biometrics due to its advantages, such as being perceivable at a long distance and difficult to replicate. The existing works mostly leverage Convolutional Neural Networks for gait recognition. The Convolutional Neural Networks perform well in image recognition tasks; however, they lack the attention mechanism to emphasize more on the significant regions of the image. The attention mechanism encodes information in the image patches, which facilitates the model to learn the substantial features in the specific regions. In light of this, this work employs the Vision Transformer (ViT) with an attention mechanism for gait recognition, referred to as Gait-ViT. In the proposed Gait-ViT, the gait energy image is first obtained by averaging the series of images over the gait cycle. The images are then split into patches and transformed into sequences by flattening and patch embedding. Position embedding, along with patch embedding, are applied on the sequence of patches to restore the positional information of the patches. Subsequently, the sequence of vectors is fed to the Transformer encoder to produce the final gait representation. As for the classification, the first element of the sequence is sent to the multi-layer perceptron to predict the class label. The proposed method obtained 99.93% on CASIA-B, 100% on OU-ISIR D and 99.51% on OU-LP, which exhibit the ability of the Vision Transformer model to outperform the state-of-the-art methods.","2022-10","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","19","22","","","","","","","","","","English","","","","WOS:000867208600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","attention; deep learning; FRAMEWORK; FUSION; gait; gait recognition; IMAGE; MODEL; NETWORK; ROBUST; SELECTION; transformers; vision transformer; vit","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C3JBEZQ9","journalArticle","2022","Al-onazi, BB; Nauman, MA; Jahangir, R; Malik, MM; Alkhammash, EH; Elshewey, AM","Transformer-Based Multilingual Speech Emotion Recognition Using Data Augmentation and Feature Fusion","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app12189188","","In recent years data science has been applied in a variety of real-life applications such as human-computer interaction applications, computer gaming, mobile services, and emotion evaluation. Among the wide range of applications, speech emotion recognition (SER) is also an emerging and challenging research topic. For SER, recent studies used handcrafted features that provide the best results but failed to provide accuracy while applied in complex scenarios. Later, deep learning techniques were used for SER that automatically detect features from speech signals. Deep learning-based SER techniques overcome the issues of accuracy, yet there are still significant gaps in the reported methods. Studies using lightweight CNN failed to learn optimal features from composite acoustic signals. This study proposed a novel SER model to overcome the limitations mentioned earlier in this study. We focused on Arabic vocal emotions in particular because they received relatively little attention in research. The proposed model performs data augmentation before feature extraction. The 273 derived features were fed as input to the transformer model for emotion recognition. This model is applied to four datasets named BAVED, EMO-DB, SAVEE, and EMOVO. The experimental findings demonstrated the robust performance of the proposed model compared to existing techniques. The proposed SER model achieved 95.2%, 93.4%, 85.1%, and 91.7% accuracy on BAVED, EMO-DB, SAVEE, and EMOVO datasets respectively. The highest accuracy was obtained using BAVED dataset, indicating that the proposed model is well suited to Arabic vocal emotions.","2022-09","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","18","12","","","","","","","","","","English","","","","WOS:000856222200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Arabic vocal emotion; artificial intelligence; multilingual; SER; speech emotion recognition; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"56HUYITT","journalArticle","2021","Ma, TH; Yang, HM; Tian, Q; Tian, Y; Al-Nabhan, N","A Hybrid Chinese Conversation model based on retrieval and generation","FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE","","0167-739X","10.1016/j.future.2020.08.030","","Conversation generation is an important natural language processing task and has attracted much attention in recent years. The realization of the conversation model is also of great significance to the field of social computing, helping to build artificial intelligence robots on social networks. The open domain conversation model is fundamentally data-driven, which can be roughly divided into retrieval models and generation models. Although remarkable progress has been achieved in recent years, it is still difficult to get responses that are grammatically and semantically appropriate. We propose the Rerank of Retrieval-based and Transformer-based Conversation model (RRT), a novel conversation model that combines the retrieval model with the generation model for the purpose of obtaining context-appropriate response. The context-response pairs with the highest similarity from training set are retrieved using traditional retrieval method, and further ranked to obtain the retrieval candidate response. We replaced the traditional sequence-to-sequence models for conversation generation by the transformer model and achieved better results with less training time. Finally, the post-reranking module is used to rank the retrieved candidate and the generated one to obtain the final response. We conducted detailed experiments on two datasets and the results show that compared with the traditional generation model, our model has a significant improvement in each metric, and the training time is decreased by a factor of 5. Furthermore, our model is more informative and relevant to the input context than the retrieval model. (C) 2020 Elsevier B.V. All rights reserved.","2021-01","2025-02-26 20:43:26","2025-02-26 20:43:26","","481-490","","","114","","","","","","","","","","English","","","","WOS:000579186700039","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Conversation model; Generation model; Post-reranking; Retrieval model; Social computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M5S6NUAJ","journalArticle","2024","Acevedo, J; Garcia, G; Ramirez, R; Fabregas, E; Hermosilla, G; Dormido-Canto, S; Farias, G","Uncertainty Detection in Supervisor-Operator Audio Records of Real Electrical Network Operations","ELECTRONICS","","2079-9292","10.3390/electronics13010141","","The quality of verbal communication, understood as the absence of uncertainty in the message transmitted, is a key factor in mission-critical processes. Several processes are handled by direct voice communication between these endpoints and any miscommunication could have an impact in success of the task. For that reason, the quality control of verbal communication is required to ensure that the instructions issued are effectively understood and adequately executed. In this context, it is expected that instructions from the command center are issued once, and that the acknowledgment from the field are minimal. In the present work, the communication between an electrical company control center and factory workers in the field was chosen for analysis. We developed two complementary approaches by using machine learning and deep learning algorithms to assess, in an automatic way, the quality of information transmission in the voice communications. Preliminary results demonstrate that the automatic uncertainty detection is feasible, despite the small number of samples available at the present time. To support further studies, a repository was created in GitHub with the spectrogram and the tokenized words of all audios.","2024-01","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","1","13","","","","","","","","","","English","","","","WOS:001139251000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","spectral analysis; speech analysis; support vector machine (SVM); uncertainty","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7HSGXJ54","journalArticle","2021","Kruyt, J; Benus, S","Prosodic entrainment in individuals with autism spectrum disorder","TOPICS IN LINGUISTICS","","1337-7590","10.2478/topling-2021-0010","","Entrainment is the tendency of people to behave similarly during an interaction. It occurs on different levels of behaviour, including speech, and has been associated with pro-social behaviour and increased rapport. This review paper outlines the current understanding of linguistic entrainment, particularly at the speech level, in individuals with autism spectrum disorder (ASD), a disorder that is associated with social difficulties and unusual prosody. Aberrant entrainment patterns in individuals with ASD could thus contribute to both their perceived unusual prosody and their social difficulties. Studying the relationship between speech entrainment and ASD holds great potential for applied benefits in utilizing this knowledge for pre-screening or diagnosis, monitoring progress longitudinally, and intervention practices. Our findings suggest that research on entrainment in ASD is sparse and exploratory, and the ecological validity of experimental paradigms varies. Moreover, there is little consistency in methodology and results vary between studies, which highlights the need for standardized methods in entrainment research. A promising way to standardize methods, facilitate their use, and extend them to everyday clinical practice, is by implementing automatic methods for speech analysis and adhering to open-science principles.","2021-12-01","2025-02-26 20:43:26","2025-02-26 20:43:26","","47-61","","2","22","","","","","","","","","","English","","","","WOS:000736162200004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;92</p>","","","alignment; ALIGNMENT; autism spectrum disorders; BEHAVIORS; CHILDREN; CONVERGENCE; CONVERSATIONAL ENTRAINMENT; DYNAMICS; entrainment; GENDER; interpersonal synchrony; LANGUAGE; LEXICAL CHOICE; MIND; prosody","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4A9SHSQF","journalArticle","2025","Lu, PL; Gao, JJ; Liu, WZ","DMNAG: Prediction of disease-metabolite associations based on Neighborhood Aggregation Graph Transformer","COMPUTATIONAL BIOLOGY AND CHEMISTRY","","1476-9271","10.1016/j.compbiolchem.2024.108320","","The metabolic level within an organism typically reflects its health status. Studying the relationship between human diseases and metabolites helps enhance medical professionals' ability for early disease diagnosis and risk prediction. However, traditional biological experimental methods often require substantial resources and manpower, and there is still room for improvement in the performance of existing predictive models. To tackle these, we propose a novel method based on the Neighborhood Aggregation Graph Transformer (NAGphormer) to predict potential associations between diseases and metabolites (DMNAG), aiming to provide guidance for biological experiments and improve experimental efficiency. First, we calculated the Gaussian kernel similarity of diseases and the physicochemical similarity of metabolites, and combined them with known associations to construct a bipartite heterogeneous network. We then calculated the semantic similarity of diseases and the Mol2vec similarity of metabolites, using them respectively as the similarity feature vectors for the disease nodes and metabolite nodes. Meanwhile, we calculate the positional information features of nodes and combine them with similarity features as the initial features of the nodes. Next, we input the bipartite heterogeneous network and node initial features into the Hop2Token module to capture multihop neighborhood information between nodes. Finally, we input the multi-hop features of nodes into the Transformer model for training and obtain the edge prediction probabilities through the decoder. Through experiments, our model achieved an AUC value of 0.9801 and an AUPR value of 0.9818 in five-fold cross-validation. Incase studies, most DMNAG-predicted associations have been validated, showcasing the model's reliability and superiority.","2025-04","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","115","","","","","","","","","","English","","","","WOS:001410260900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Disease-metabolite; Graph transformer; Mol2vec; Neighborhood aggregation; Physicochemical similarity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LJNFHLVE","journalArticle","2025","Wei, H; Zhao, LC; Li, RP; Zhang, M","RFAConv-CBM-ViT: enhanced vision transformer for metal surface defect detection","JOURNAL OF SUPERCOMPUTING","","0920-8542","10.1007/s11227-024-06662-0","","Detecting surface defects in metal manufacturing is critical, as they can greatly affect product quality and production efficiency. While vision transformers (ViTs) have advanced in surface defect detection, challenges remain, particularly due to high variability and sample imbalance in metal defects. To address these challenges, this paper proposes a vision transformer model that combines receptive-field attention convolution (RFAConv) and context broadcasting median (CBM), referred to as RFAConv-CBM-ViT. Firstly, this paper introduces RFAConv in the patch embedding stage, which adaptively adjusts the receptive field size, enhancing the model's ability to capture global features and improving its capability to handle defects of varying scales. Its advantage lies in improving the model's accuracy and convergence speed without introducing additional computational overhead, while also enhancing its robustness in addressing complex defects. Secondly, this paper design a method called CBM to enhance the performance of the ViT backbone. CBM utilizes median tokens within the multi-layer perceptron to reduce the density of the attention map. By aggregating local contextual information, CBM effectively suppresses noise and irrelevant features, leading to improved model accuracy without increasing computational cost. Experimental results demonstrate that the proposed RFAConv-CBM-ViT model achieves competitive performance across multiple public metal surface defect datasets. This method significantly enhances the performance of vision transformers in metal surface defect detection tasks, demonstrating its potential for applications in the metal manufacturing industry. Code is available at https://github.com/Vzoooong/RFAConv-CBM-ViT/tree/main.","2025-01","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","1","81","","","","","","","","","","English","","","","WOS:001352388100004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Context broadcasting median; Metal surface defect detection; Receptive-field attention; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I5GTXXJW","journalArticle","2024","Qi, HN; Li, HY; Chen, LP; Chen, FN; Luo, JH; Zhang, C","Hyperspectral Imaging Using a Convolutional Neural Network with Transformer for the Soluble Solid Content and pH Prediction of Cherry Tomatoes","FOODS","","2304-8158","10.3390/foods13020251","","Cherry tomatoes are cultivated worldwide and favored by consumers of different ages. The soluble solid content (SSC) and pH are two of the most important quality attributes of cherry tomatoes. The rapid and non-destructive measurement of the SSC and pH of cherry tomatoes is of great significance to their production and consumption. In this research, hyperspectral imaging combined with a convolutional neural network with Transformer (CNN-Transformer) was utilized to analyze the SSC and pH of cherry tomatoes. Conventional machine learning and deep learning models were established for the determination of the SSC and pH. The findings demonstrated that CNN-Transformer yielded outstanding results in predicting the SSC, with the coefficient of determination of calibration (R2C), validation (R2V), and prediction (R2P) for the SSC being 0.83, 0.87, and 0.83, respectively. Relatively worse results were obtained for the pH value prediction, with R2C, R2V, and R2P values of 0.74, 0.68, and 0.60, respectively. Furthermore, the visualization of the CNN-Transformer model revealed the wavelength weight distributions, indicating that the 1380-1650 nm range served as the characteristic band for the SSC, while the spectral range at 945-1280 nm was the characteristic band for pH. In conclusion, integrating spectral information features with the attention mechanism of Transformer through a convolutional neural network can enhance the accuracy of predicting the SSC and pH for cherry tomatoes.","2024-01","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","2","13","","","","","","","","","","English","","","","WOS:001148897600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","deep learning regression; NIR; non-destructive testing; PLS; QUALITY; REGRESSION; SPECTROSCOPY; tomato quality; wavelength weight visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"269MXQCB","journalArticle","2023","Chen, YQ; Guo, ZT","TranSpeckle: An edge-protected transformer for medical ultrasound image despeckling","IET IMAGE PROCESSING","","1751-9659","10.1049/ipr2.12915","","The transformer, a type of neural architecture, has demonstrated exceptional performance improvements in vision and natural language tasks. While overcoming the disadvantages of limited perceptual field and non-adaptive input content exhibited in CNNs, the computational complexity of the Transformer model increases quadratically with spatial resolution. As such, this model is not frequently employed in image processing tasks such as image denoising, and there is a shortage of studies that investigate ultrasonic image multiplication speckle removal. In light of this, we present TranSpeckle, an effective and efficient despeckle architecture that employs Multi-Dconv Head Transposed Attention and Dconv Feed-Forward Network as the core components of its Transformer block. Multiple Transformer blocks are then utilized to implement a hierarchical encoder-decoder network. TranSpeckle architecture considerably reduces the computational complexity of feature maps while also effectively capturing long-range pixel interactions and local context information. In this study, an edge protection module is combined to augment the edges of ultrasound images. The module incorporates extracted image edge features into the TranSpeckle architecture, which ameliorates the issue of edge information loss engendered by the image despeckling process. Extensive experimental results clearly show that our proposed network outperforms state-of-the-art methods in terms of quantitative metrics and visual quality. A novel denoising network, TranSpeckle, is proposed to remove speckle noise from medical ultrasound images. It utilizes a Transformer block to efficiently capture global contextual relationships without compromising computational efficiency. Additionally, an edge protection module is incorporated to enhance edges, improving the overall despeckling effect of ultrasound images.image","2023-12","2025-02-26 20:43:26","2025-02-26 20:43:26","","4014-4027","","14","17","","","","","","","","","","English","","","","WOS:001066876700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","CNN; image denoising; image processing; image restoration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6KQQ5QA2","journalArticle","2023","Vasanthi, P; Mohan, L","A reliable anchor regenerative-based transformer model for x-small and dense objects recognition","NEURAL NETWORKS","","0893-6080","10.1016/j.neunet.2023.06.020","","The past decade has witnessed significant progress in detecting objects by using enormous features of deep learning models. But, most of the existing models are unable to detect x-small and dense objects, due to the futility of feature extraction, and substantial misalignments between anchor boxes and axis-aligned convolution features, which leads to the discrepancy between the categorization score and positioning accuracy. This paper introduces an anchor regenerative-based transformer module in a feature refinement network to solve this problem. The anchor-regenerative module can generate anchor scales based on the semantic statistics of the objects present in the image, which avoids the inconsistency between the anchor boxes and axis-aligned convolution features. Whereas, the Multi-Head-Self-Attention (MHSA) based transformer module extracts the in-depth information from the feature maps based on the query, key, and value parameter information. This proposed model is experimentally verified on the VisDrone, VOC, and SKU-110K datasets. This model generates different anchor scales for these three datasets and achieves higher mAP, precision, and recall values on three datasets. These tested results prove that the suggested model has outstanding achievements compared with existing models in detecting x-small objects as well as dense objects. Finally, we evaluated the performance of these three datasets by using accuracy, kappa coefficient, and ROC metrics. These evaluated metrics demonstrate that our model is a good fit for VOC, and SKU-110K datasets. (c) 2023 Elsevier Ltd. All rights reserved.","2023-08","2025-02-26 20:43:26","2025-02-26 20:43:26","","809-829","","","165","","","","","","","","","","English","","","","WOS:001040438800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","Auto-anchor; Multi-head-self-attention; Object detection; Spatial pyramid pooling-faster; YOLOv5","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M6CEYK4Q","journalArticle","2023","Wu, XX; Li, T","Sentimental Visual Captioning using Multimodal Transformer","INTERNATIONAL JOURNAL OF COMPUTER VISION","","0920-5691","10.1007/s11263-023-01752-7","","We propose a new task called sentimental visual captioning that generates captions with the inherent sentiment reflected by the input image or video. Compared with the stylized visual captioning task that requires a predefined style independent of the image or video, our new task automatically analyzes the inherent sentiment tendency from the visual content. With this in mind, we propose a multimodal Transformer model namely Senti-Transformer for sentimental visual captioning, which integrates both content and sentiment information from multiple modalities and incorporates prior sentimental knowledge to generate sentimental sentence. Specifically, we extract prior knowledge from sentimental corpus to obtain sentimental textual information and design a multi-head Transformer encoder to encode multimodal features. Then we decompose the attention layer in the middle of Transformer decoder to focus on important features of each modality, and the attended features are integrated through an intra-and inter-modality fusion mechanism for generating sentimental sentences. To effectively train the proposed model using the external sentimental corpus as well as the paired images or videos and factual sentences in existing captioning datasets, we propose a two-stage training strategy that first learns to incorporate sentimental elements into the sentences via a regularization term and then learns to generate fluent and relevant sentences with the inherent sentimental styles via reinforcement learning with a sentimental reward. Extensive experiments on both image and video datasets demonstrate the effectiveness and superiority of our Senti-Transformer on sentimental visual captioning. Source code is available at https:// github.com/ezeli/InSentiCap_ext.","2023-04","2025-02-26 20:43:26","2025-02-26 20:43:26","","1073-1090","","4","131","","","","","","","","","","English","","","","WOS:000927075900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","Sentimental visual captioning; Transformer; Visual sentiment analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BEZG7JHK","journalArticle","2023","Mao, JS; Guan, SH; Chen, YQ; Zeb, A; Sun, QX; Lu, RL; Dong, J; Wang, JM; Cao, DS","Application of a deep generative model produces novel and diverse functional peptides against microbial resistance","COMPUTATIONAL AND STRUCTURAL BIOTECHNOLOGY JOURNAL","","2001-0370","10.1016/j.csbj.2022.12.029","","Antimicrobial resistance could threaten millions of lives in the immediate future. Antimicrobial peptides (AMPs) are an alternative to conventional antibiotics practice against infectious diseases. Despite the po-tential contribution of AMPs to the antibiotic's world, their development and optimization have en-countered serious challenges. Cutting-edge methods with novel and improved selectivity toward resistant targets must be established to create AMPs-driven treatments. Here, we present AMPTrans-lstm, a deep generative network-based approach for the rational design of AMPs. The AMPTrans-lstm pipeline involves pre-training, transfer learning, and module identification. The AMPTrans-lstm model has two sub-models, namely, (long short-term memory) LSTM sampler and Transformer converter, which can be connected in series to make full use of the stability of LSTM and the novelty of Transformer model. These elements could generate AMPs candidates, which can then be tailored for specific applications. By analyzing the generated sequence and trained AMPs, we prove that AMPTrans-lstm can expand the design space of the trained AMPs and produce reasonable and brand-new AMPs sequences. AMPTrans-lstm can generate functional peptides for antimicrobial resistance with good novelty and diversity, so it is an efficient AMPs design tool.(c) 2022 Published by Elsevier B.V. on behalf of Research Network of Computational and Structural Biotechnology. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/ licenses/by-nc-nd/4.0/).","2023","2025-02-26 20:43:26","2025-02-26 20:43:26","","463-471","","","21","","","","","","","","","","English","","","","WOS:000910121100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","AMPs; ANTIBACTERIAL PEPTIDES; ANTIMICROBIAL PEPTIDES; Antimicrobial resistance; DATABASE; Deep generative model; LSTM; MOLECULAR-DYNAMICS SIMULATION; SEQUENCES; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S6T2L77H","journalArticle","2025","Yemets, K; Izonin, I; Dronyuk, I","Time Series Forecasting Model Based on the Adapted Transformer Neural Network and FFT-Based Features Extraction","SENSORS","","1424-8220","10.3390/s25030652","","In today's data-driven world, where information is one of the most valuable resources, forecasting the behavior of time series, collected by modern sensor networks and IoT systems, is crucial across various fields, including finance, climatology, and engineering. However, existing neural network models often struggle with time series forecasting collected by different sensors due to challenges such as large data volumes, long-term dependencies, noise, and anomalies, which can negatively impact predictive accuracy. This paper aims to enhance the accuracy of time series forecasting by proposing an adapted transformer architecture combined with an innovative data preprocessing method. The proposed preprocessing technique employs the fast Fourier transform (FFT) to transition from the time domain to the frequency domain, enriching the data with additional frequency-domain features. These features are represented as complex numbers, which improve the informational content of the data for subsequent analysis, thereby boosting forecasting performance. Furthermore, the paper introduces a modified transformer model specifically designed to address the identified challenges in time series prediction. The performance of the proposed model was evaluated using three diverse datasets collected by different sensors, each with varying measurement frequencies, data types, and application domains, providing a comprehensive comparison with state-of-the-art models such as LSTM, FFT-LSTM, DeepAR, Transformer, and FFT-Transformer. Extensive evaluation using five distinct performance metrics demonstrates that the proposed model consistently outperforms existing methods, achieving the highest accuracy across all datasets.","2025-02","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","3","25","","","","","","","","","","English","","","","WOS:001419643300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","ANN; attention mechanism; Big Data; deep learning; DeepAR; fast Fourier transform; feature extraction; forecasting; FOURIER-TRANSFORM; LSTM; performance evaluation; sensors; time series; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SBFGC9T9","journalArticle","2024","Ansari, SA; Agrawal, AP; Wajid, MA; Wajid, MS; Zafar, A","MetaV: A Pioneer in feature Augmented Meta-Learning Based Vision Transformer for Medical Image Classification","INTERDISCIPLINARY SCIENCES-COMPUTATIONAL LIFE SCIENCES","","1913-2751","10.1007/s12539-024-00630-1","","Image classification, a fundamental task in computer vision, faces challenges concerning limited data handling, interpretability, improved feature representation, efficiency across diverse image types, and processing noisy data. Conventional architectural approaches have made insufficient progress in addressing these challenges, necessitating architectures capable of fine-grained classification, enhanced accuracy, and superior generalization. Among these, the vision transformer emerges as a noteworthy computer vision architecture. However, its reliance on substantial data for training poses a drawback due to its complexity and high data requirements. To surmount these challenges, this paper proposes an innovative approach, MetaV, integrating meta-learning into a vision transformer for medical image classification. N-way K-shot learning is employed to train the model, drawing inspiration from human learning mechanisms utilizing past knowledge. Additionally, deformational convolution and patch merging techniques are incorporated into the vision transformer model to mitigate complexity and overfitting while enhancing feature representation. Augmentation methods such as perturbation and Grid Mask are introduced to address the scarcity and noise in medical images, particularly for rare diseases. The proposed model is evaluated using diverse datasets including Break His, ISIC 2019, SIPaKMed, and STARE. The achieved performance accuracies of 89.89%, 87.33%, 94.55%, and 80.22% for Break His, ISIC 2019, SIPaKMed, and STARE, respectively, present evidence validating the superior performance of the proposed model in comparison to conventional models, setting a new benchmark for meta-vision image classification models.","2024-06","2025-02-26 20:43:26","2025-02-26 20:43:26","","469-488","","2","16","","","","","","","","","","English","","","","WOS:001259371500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Data augmentation; DEEP; Few-shot learning; Grid mask; Medical image classification; Meta-learning; MetaV; NEURAL-NETWORKS; Perturbation; REGRESSION; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WFY8YSE4","journalArticle","2024","Guo, JC; Liu, J; Liu, X; Wan, Y; Zhao, YJ; Li, L; Liu, K; Klein, J; Bissyande, TF","PyScribe-Learning to describe python code","SOFTWARE-PRACTICE & EXPERIENCE","","0038-0644","10.1002/spe.3291","","Code comment generation, which attempts to summarize the functionality of source code in textual descriptions, plays an important role in automatic software development research. Currently, several structural neural networks have been exploited to preserve the syntax structure of source code based on abstract syntax trees (ASTs). However, they can not well capture both the long-distance and local relations between nodes while retaining the overall structural information of AST. To mitigate this problem, we present a pro-to type tool titled PyScribe, which extends the Transformer model to a new encoder-decoder-based framework. Particularly, the triplet position is designed and integrated into the node-level and edge-level structural features of AST for producing Python code comments automatically. This paper, to the best of our knowledge, makes the first effort to model the edges of AST as an explicit component for improved code representation. By specifying triplet positions for each node and edge, the overall structural information can be well preserved in the learning process. Moreover, the captured node and edge features go through a two-stage decoding process to yield higher qualified comments. To evaluate the effectiveness of PyScribe, we resort to a large dataset of code-comment pairsby mining Jupyter Notebooks from GitHub, for which we have made it publicly available to support further studies. The experimental results reveal that PyScribe is indeed effective, outperforming the state-of the-art by achieving an average BLEU score (i.e., av-BLEU) of approximate to 0.28.","2024-03","2025-02-26 20:43:26","2025-02-26 20:43:26","","501-527","","3","54","","","","","","","","","","English","","","","WOS:001117942500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","code comprehension; code documentation; code embedding; code summarization; deep learning; representation learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GJC9DX8N","journalArticle","2025","Dhar, S; Jana, ND; Das, S","GLGAN-VC: A Guided Loss-Based Generative Adversarial Network for Many-to-Many Voice Conversion","IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS","","2162-237X","10.1109/TNNLS.2023.3335119","","Many-to-many voice conversion (VC) is a technique aimed at mapping speech features between multiple speakers during training and transferring the vocal characteristics of one source speaker to another target speaker, all while maintaining the content of the source speech unchanged. Existing research highlights a notable gap between the original and generated speech samples in terms of naturalness within many-to-many VC. Therefore, there is substantial room for improvement in achieving more natural-sounding speech samples for both parallel and nonparallel VC scenarios. In this study, we introduce a generative adversarial network (GAN) system with a guided loss (GLGAN-VC) designed to enhance many-to-many VC by focusing on architectural improvements and the integration of alternative loss functions. Our approach includes a pair-wise downsampling and upsampling (PDU) generator network for effective speech feature mapping (FM) in multidomain VC. In addition, we incorporate an FM loss to preserve content information and a residual connection (RC)-based discriminator network to improve learning. A guided loss (GL) function is introduced to efficiently capture differences in latent feature representations between source and target speakers, and an enhanced reconstruction loss is proposed for better contextual information preservation. We evaluate our model on various datasets, including VCC 2016, VCC 2018, VCC 2020, and an emotional speech dataset (ESD). Our results, based on both subjective and objective evaluation metrics, demonstrate that our model outperforms state-of-the-art (SOTA) many-to-many GAN-based VC models in terms of speech quality and speaker similarity in the generated speech samples.","2025-01","2025-02-26 20:43:26","2025-02-26 20:43:26","","1813-1826","","1","36","","","","","","","","","","English","","","","WOS:001394761300046","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Data models; Frequency modulation; Generative adversarial network (GAN); Generative adversarial networks; Generators; GLGAN-voice conversion (GLGAN-VC); Hidden Markov models; many-to-many VC; Measurement; SPEECH SYNTHESIS; Task analysis; voice conversion (VC)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V6BELQ5N","journalArticle","2023","Liu, ZB; Zhao, WJ","Chinese sentiment analysis model by integrating multi-granularity semantic features","DATA TECHNOLOGIES AND APPLICATIONS","","2514-9288","10.1108/DTA-10-2022-0385","","Purpose In recent years, Chinese sentiment analysis has made great progress, but the characteristics of the language itself and downstream task requirements were not explored thoroughly. It is not practical to directly migrate achievements obtained in English sentiment analysis to the analysis of Chinese because of the huge difference between the two languages. Design/methodology/approach In view of the particularity of Chinese text and the requirement of sentiment analysis, a Chinese sentiment analysis model integrating multi-granularity semantic features is proposed in this paper. This model introduces the radical and part-of-speech features based on the character and word features, with the application of bidirectional long short-term memory, attention mechanism and recurrent convolutional neural network. Findings The comparative experiments showed that the F1 values of this model reaches 88.28 and 84.80 per cent on the man-made dataset and the NLPECC dataset, respectively. Meanwhile, an ablation experiment was conducted to verify the effectiveness of attention mechanism, part of speech, radical, character and word factors in Chinese sentiment analysis. The performance of the proposed model exceeds that of existing models to some extent. Originality/value The academic contribution of this paper is as follows: first, in view of the particularity of Chinese texts and the requirement of sentiment analysis, this paper focuses on solving the deficiency problem of Chinese sentiment analysis under the big data context. Second, this paper borrows ideas from multiple interdisciplinary frontier theories and methods, such as information science, linguistics and artificial intelligence, which makes it innovative and comprehensive. Finally, this paper deeply integrates multi-granularity semantic features such as character, word, radical and part of speech, which further complements the theoretical framework and method system of Chinese sentiment analysis.","2023-10-20","2025-02-26 20:43:26","2025-02-26 20:43:26","","605-622","","4","57","","","","","","","","","","English","","","","WOS:000935880600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Attention mechanism; Chinese text; Deep learning model; Multi-granularity semantic feature; Radical; Sentiment analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4EKC8PPM","journalArticle","2022","Xu, XL; Li, DD; Zhou, YJ; Wang, Z","Multi-type features separating fusion learning for Speech Emotion Recognition","APPLIED SOFT COMPUTING","","1568-4946","10.1016/j.asoc.2022.109648","","Speech Emotion Recognition (SER) is a challengeable task to improve human-computer interaction. Speech data have different representations, and choosing the appropriate features to express the emotion behind the speech is difficult. The human brain can comprehensively judge the same thing in different dimensional representations to obtain the final result. Inspired by this, we believe that it is reasonable to have complementary advantages between different representations of speech data. Therefore, a Hybrid Deep Learning with Multi-type features Model (HD-MFM) is proposed to integrate the acoustic, temporal and image information of speech. Specifically, we utilize Convolutional Neural Network (CNN) to extract image information from the spectrogram of speech. Deep Neural Network (DNN) is used for extracting the acoustic information from the statistic features of speech. Then, Long Short-Term Memory (LSTM) is chosen to extract the temporal information from the Mel-Frequency Cepstral Coefficients (MFCC) of speech. Finally, three different types of speech features are concatenated together to get a richer emotion representation with better discriminative property. Considering that different fusion strategies affect the relationship between features, we consider two fusion strategies in this paper named separating and merging. To evaluate the feasibility and effectiveness of the proposed HD-MFM, we perform extensive experiments on EMO-DB and IEMOCAP of SER. The experimental results show that the separating method has more significant advantages in feature complementarity. The proposed HD-MFM obtains 91.25% and 72.02% results on EMO-DB and IEMOCAP. The obtained results indicate the proposed HD-MFM can make full use of the effective complementary feature representations by separating strategy to further enhance the performance of SER. (c) 2022 Elsevier B.V. All rights reserved.","2022-11","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","130","","","","","","","","","","English","","","","WOS:000907771700005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","ADAPTATION; CLASSIFICATION; CNN; CONVOLUTIONAL NEURAL-NETWORKS; Feature-level fusion; GMM; Hybrid feature selection; RECURRENT; REPRESENTATIONS; Speaker-independent; Speech emotion recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PAEP7K29","journalArticle","2022","Manohar, K; Logashanmugam, DE","Hybrid deep learning with optimal feature selection for speech emotion recognition using improved meta-heuristic algorithm","KNOWLEDGE-BASED SYSTEMS","","0950-7051","10.1016/j.knosys.2022.108659","","Speech emotion recognition is the crucial stream in emotional computing and also create few issues owing to its complication in processing. The efficiency of the acoustic methods and their speech features are improved using various existing methods. Yet, the conventional acoustic methods are not effective in handling speech emotion recognition because of their drawbacks. The main intend of this research is to implement a new speech emotion recognition using the hybrid deep learning model. Initially, few speech emotion recognition dataset is gathered from the public sources and is put forwarded for pre-processing using artifacts removal and filtering techniques. Then, the feature extraction of the speech signals is performed by the Mel-Frequency Cepstral Coefficients (MFCC), mel-scale spectrogram, tonal power, and spectral flux. In the aim of decreasing the feature size for boosting up the learning performance, for selecting the optimal feature is adopted by the Deer Hunting with Adaptive Search (DH-AS) algorithm. These optimal features are used for the emotion classification by the Hybrid Deep Learning (HDL) with ""Deep Neural Network (DNN) and Recurrent Neural Network (RNN) "". These two networks are enhanced by the developed DH-AS, thus could reach high classification accuracy while classifying the emotions like ""happy, sad, anger, fear, calm etc "". The performance of the suggested DH-AS-HDL correspondingly improves 3.15%, 5.37%, 4.25% and 4.81% better accuracy than the PSO-HDL, GWO-HDL, WOA-HDL and DHOA-HDL, when the learning rate as 85. The achieved results prove that the developed model obtains superior performance by evaluating its performance through various performance metrics.(C)& nbsp;2022 Elsevier B.V. All rights reserved.","2022-06-21","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","246","","","","","","","","","","English","","","","WOS:000795588200007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;27<br/>Total Times Cited:&nbsp;&nbsp;27<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Deep Neural Network; Deer hunting with adaptive search; Hybrid Deep Learning; Optimal feature selection; Recurrent Neural Network; Speech emotion recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FCEH79CL","journalArticle","2024","Shen, L; Jin, X","VaBTFER: An Effective Variant Binary Transformer for Facial Expression Recognition","SENSORS","","1424-8220","10.3390/s24010147","","Existing Transformer-based models have achieved impressive success in facial expression recognition (FER) by modeling the long-range relationships among facial muscle movements. However, the size of pure Transformer-based models tends to be in the million-parameter level, which poses a challenge for deploying these models. Moreover, the lack of inductive bias in Transformer usually leads to the difficulty of training from scratch on limited FER datasets. To address these problems, we propose an effective and lightweight variant Transformer for FER called VaTFER. In VaTFER, we firstly construct action unit (AU) tokens by utilizing action unit-based regions and their histogram of oriented gradient (HOG) features. Then, we present a novel spatial-channel feature relevance Transformer (SCFRT) module, which incorporates multilayer channel reduction self-attention (MLCRSA) and a dynamic learnable information extraction (DLIE) mechanism. MLCRSA is utilized to model long-range dependencies among all tokens and decrease the number of parameters. DLIE's goal is to alleviate the lack of inductive bias and improve the learning ability of the model. Furthermore, we use an excitation module to replace the vanilla multilayer perception (MLP) for accurate prediction. To further reduce computing and memory resources, we introduce a binary quantization mechanism, formulating a novel lightweight Transformer model called variant binary Transformer for FER (VaBTFER). We conduct extensive experiments on several commonly used facial expression datasets, and the results attest to the effectiveness of our methods.","2024-01","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","1","24","","","","","","","","","","English","","","","WOS:001140701400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","binary quantization mechanism; dynamic learnable information extraction; facial expression recognition; lightweight variant Transformer; multilayer channel reduction self-attention; NEURAL-NETWORK; spatial-channel feature relevance Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D8KX3VPB","journalArticle","2023","Srivastava, S; Sharma, H","RelNet-MAM: Relation Network with Multilevel Attention Mechanism for Image Captioning","MICROPROCESSORS AND MICROSYSTEMS","","0141-9331","10.1016/j.micpro.2023.104931","","Text present in an image contains rich semantic information which is crucial for the understanding of an image. For example, a signboard having the text ""deep water"" conveys the danger involved in the image. The current image captioning models do not effectively utilize this useful semantic information due to their limited representation capabilities of scene-text tokens. Our work presents a novel image captioning model called RelNetMAM, which utilizes a multilevel attention mechanism and relation network. To improve the appearance feature representation, RelNet-MAM uses multilevel attention which consists of spatial attention, channel-wise attention, and semantic attention. For representing the scene-text token effectively, RelNet-MAM uses appearance, FastText, location, and PHOC features for each token. Further, the proposed RelNet-MAM uses the relation network to establish the relationships between the objects and scene-text tokens. Finally, the transformer model together with dynamic pointer networks is used as a decoder in the caption generation process. The proposed RelNet-MAM model outperforms the state-of-the-art models on TextCaps, Flickr30k, and MS COCO datasets. TextCaps requires models to read and reason about the texts in an image for caption generation. MSCOCO and Flickr30k contain diverse images; persons, animals, automobiles, indoor and outdoor scenes. Remarkably, the proposed RelNet-MAM model outperforms the current best model by 2.3% on B-4, 1.8% on METEOR, 2.2% on ROUGE-L, 2.0% on CIDEr-D and 3.0% on SPICE metric scores on TextCaps dataset.","2023-10","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","102","","","","","","","","","","English","","","","WOS:001088740400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Attention; Image captioning; Multilevel; SCENE TEXT DETECTION; Semantic; Spatial; TRANSFORMER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ESSXLYZN","journalArticle","2022","Xu, Q; Xu, QQ; Shi, N; Dong, LN; Zhu, H; Xu, K","A multitask classification framework based on vision transformer for predicting molecular expressions of glioma","EUROPEAN JOURNAL OF RADIOLOGY","","0720-048X","10.1016/j.ejrad.2022.110560","","Purpose: The purpose of this study is to develop a Vision Transformer model with multitask classification framework that is appropriate for predicting four molecular expressions of glioma simultaneously based on MR imaging.Materials and methods: A total of 188 glioma (grades II-IV) patients with an immunohistochemical diagnosis of IDH, MGMT, Ki67 and P53 expression were enrolled in our study. A Vision Transformer (ViT) model, including three independent networks based on T2WI, T1CWI and T2 + T1CWI (T2-net, T1C-net and TU-net), was developed for the prediction of four glioma molecular expressions simultaneously. To evaluate the model per-formance, the accuracy rate, recall, precision, F1-score, and area under the receiver operating characteristic curve (AUC) were calculated.Results: The proposed ViT model achieved high accuracy in predicting IDH, MGMT, Ki67 and P53 expression in gliomas. Among the three networks using the ViT model, TU-net achieved the best results with the highest values of accuracy (range, 0.937-0.969), precision (range, 0.949-0.972), recall (range, 0.873-0.991), F1-score (range, 0.910-0.981) and AUC (range, 0.976-0.984). Comparisons were also made between our ViT model and con-volutional neural network (CNN)-based models, and the proposed ViT model outperformed the existing CNN -based models.Conclusion: Vision Transformer is a reliable approach for the prediction of glioma molecular biomarkers and can be a viable alternative to CNNs.","2022-12","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","157","","","","","","","","","","English","","","","WOS:000883338900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Convolutional neural network; Deep learning; Glioma; IDH; Magnetic resonance imaging; MGMT PROMOTER METHYLATION; Molecular expression; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B6QMMPXA","journalArticle","2021","Fiok, K; Karwowski, W; Gutierrez-Franco, E; Davahli, MR; Wilamowski, M; Ahram, T; Al-Juaid, A; Zurada, J","Text Guide: Improving the Quality of Long Text Classification by a Text Selection Method Based on Feature Importance","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2021.3099758","","The performance of text classification methods has improved greatly over the last decade for text instances of less than 512 tokens. This limit has been adopted by most state-of-the-research transformer models due to the high computational cost of analyzing longer text instances. To mitigate this problem and to improve classification for longer texts, researchers have sought to resolve the underlying causes of the computational cost and have proposed optimizations for the attention mechanism, which is the key element of every transformer model. In our study, we are not pursuing the ultimate goal of long text classification, i.e., the ability to analyze entire text instances at one time while preserving high performance at a reasonable computational cost. Instead, we propose a text truncation method called Text Guide, in which the original text length is reduced to a predefined limit in a manner that improves performance over naive and semi-naive approaches while preserving low computational costs. Text Guide benefits from the concept of feature importance, a notion from the explainable artificial intelligence domain. We demonstrate that Text Guide can be used to improve the performance of recent language models specifically designed for long text classification, such as Longformer. Moreover, we discovered that parameter optimization is the key to Text Guide performance and must be conducted before the method is deployed. Future experiments may reveal additional benefits provided by this new method.","2021","2025-02-26 20:43:26","2025-02-26 20:43:26","","105439-105450","","","9","","","","","","","","","","English","","","","WOS:000681074300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","Analytical models; Classification; Computational efficiency; Computational modeling; feature importance; language model; Licenses; long text; method; Standards; Task analysis; Text categorization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N5MGW8DG","journalArticle","2024","Sun, Q; Fu, YW; Xue, XY","Learning a Mixture of Conditional Gating Blocks for Visual Question Answering","JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY","","1000-9000","10.1007/s11390-024-2113-0","","As a Turing test in multimedia, visual question answering (VQA) aims to answer the textual question with a given image. Recently, the ""dynamic"" property of neural networks has been explored as one of the most promising ways of improving the adaptability, interpretability, and capacity of the neural network models. Unfortunately, despite the prevalence of dynamic convolutional neural networks, it is relatively less touched and very nontrivial to exploit dynamics in the transformers of the VQA tasks through all the stages in an end-to-end manner. Typically, due to the large computation cost of transformers, researchers are inclined to only apply transformers on the extracted high-level visual features for downstream vision and language tasks. To this end, we introduce a question-guided dynamic layer to the transformer as it can effectively increase the model capacity and require fewer transformer layers for the VQA task. In particular, we name the dynamics in the Transformer as Conditional Multi-Head Self-Attention block (cMHSA). Furthermore, our questionguided cMHSA is compatible with conditional ResNeXt block (cResNeXt). Thus a novel model mixture of conditional gating blocks (McG) is proposed for VQA, which keeps the best of the Transformer, convolutional neural network (CNN), and dynamic networks. The pure conditional gating CNN model and the conditional gating Transformer model can be viewed as special examples of McG. We quantitatively and qualitatively evaluate McG on the CLEVR and VQA-Abstract datasets. Extensive experiments show that McG has achieved the state-of-the-art performance on these benchmark datasets.","2024-07","2025-02-26 20:43:26","2025-02-26 20:43:26","","912-928","","4","39","","","","","","","","","","English","","","","WOS:001317441800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","dynamic network; Transformer; visual question answering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VBNP77JM","journalArticle","2024","Zhou, YF; Huang, XH; Yang, XF; Peng, JT; Ban, YF; Jiang, N","MSMT-LCL: Multiscale Spatial-Spectral Masked Transformer With Local Contrastive Learning for Hyperspectral Image Classification","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2024.3472066","","Deep learning plays a crucial role in hyperspectral image (HSI) classification, with the Transformer being highly favored by researchers due to its exceptional ability to model long-range dependencies. However, the Transformer necessitates a substantial amount of labeled training samples to train its numerous parameters, exacerbating the challenge of training an effective HSI classification Transformer model, particularly given the inherent scarcity of HSI data. Therefore, we propose a novel method for HSI classification, termed multiscale spatial-spectral masked Transformer with local contrastive learning (MSMT-LCL). This method consists of two stages: self-supervised pretraining and supervised fine-tuning. Initially, we utilize the multiscale augmented feature mapping module (MAFM) to project original HSI data into two mixed-scale feature maps, which are then separately fed into two masked Transformer branches for reconstruction. To facilitate the model in learning the dependency relationships between central pixel land-cover information and neighboring land cover, we introduce a novel mask strategy based on center-patch. Furthermore, in the pretraining stage, we integrate local contrastive learning (LCL) to enable the model to focus on local center information at varying scales. Upon completion of pretraining, the network undergoes fine-tuning to obtain feature maps at two different scales. Subsequently, we devise a novel adaptive multiscale feature fusion module (AMFM) to adaptively aggregate these two features and produce the final classification results. Extensive experiments on three real datasets demonstrate the superiority of our proposed MSMT-LCL method over several state-of-the-art HSI classification methods.","2024","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","62","","","","","","","","","","English","","","","WOS:001338406700037","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Contrastive learning (CL); deep learning; FUSION; hyperspectral image (HSI) classification; masked Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5UQKGKKB","journalArticle","2023","Park, H; Kang, Y; Kim, J","Enhancing Structure-Property Relationships in Porous Materials through Transfer Learning and Cross-Material Few-Shot Learning","ACS APPLIED MATERIALS & INTERFACES","","1944-8244","10.1021/acsami.3c10323","","Porous materials have emerged as promising solutions for a wide range of energy and environmental applications. However, the asymmetric development in the field of metal-organic frameworks (MOFs) has led to a data imbalance when it comes to MOFs versus other porous materials such as covalent organic frameworks (COFs), porous polymer networks (PPNs), and zeolites. To address this issue, we introduce PMTransformer (Porous Material Transformer), a multimodal Transformer model pretrained on a vast data set of 1.9 million hypothetical porous materials, including metal-organic frameworks, covalent organic frameworks, porous polymer networks, and zeolites. PMTransformer showcases remarkable transfer learning capabilities, resulting in state-of-the-art performance in predicting various porous material properties. To address the challenge of asymmetric data aggregation, we propose cross-material few-shot learning, which leverages the synergistic effect among different porous material classes to enhance the fine-tuning performance with a limited number of examples. As a proof of concept, we demonstrate its effectiveness in predicting band gap values of COFs using the available MOF data in the training set. Moreover, we established cross-material relationships in porous materials by predicting the unseen properties of other classes of porous materials. Our approach presents a new pathway for understanding the underlying relationships among various classes of porous materials, paving the way toward a more comprehensive understanding and design of porous materials.","2023-11-20","2025-02-26 20:43:26","2025-02-26 20:43:26","","56375-56385","","48","15","","","","","","","","","","English","","","","WOS:001115540600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","covalent organic frameworks; COVALENT ORGANIC FRAMEWORKS; CRYSTALLINE; DATABASE; IN-SILICO DESIGN; machine learning; metal-organicframeworks; METHANE STORAGE; NETWORKS; porous materials; porouspolymer networks; SELECTION; structure-property relationships; transfer learning; zeolites","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JZ84QSCW","journalArticle","2023","Sharma, D; Dhiman, C; Kumar, D","XGL-T transformer model for intelligent image captioning","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-023-15291-3","","Image captioning extracts multiple semantic features from an image and integrates them into a sentence-level description. For efficient description of the captions, it becomes necessary to learn higher order interactions between detected objects and the relationship among them. Most of the existing systems take into account the first order interactions while ignoring the higher order ones. It is challenging to extract discriminant higher order semantics visual features in images with highly populated objects for caption generation. In this paper, an efficient higher order interaction learning framework is proposed using encoder-decoder based image captioning. A scaled version of Gaussian Error Linear Unit (GELU) activation function, x-GELU is introduced that controls the vanishing gradients and enhances the feature learning. To leverage higher order interactions among multiple objects, an efficient XGL Transformer (XGL-T) model is introduced that exploits both spatial and channel-wise attention by integrating four XGL attention modules in image encoder and one in Bilinear Long Short-Term Memory guided sentence decoder. The proposed model captures rich semantic concepts from objects, attributes, and their relationships. Extensive experiments are conducted on publicly available MSCOCO Karapathy test split and the best performance of the work is observed as 81.5 BLEU@1, 67.1 BLEU@2, 51.6 BLEU@3, 39.9 BLEU@4, 134 CIDEr, 59.9 ROUGE-L, 29.8 METEOR, 23.8 SPICE using CIDEr-D Score Optimization Strategy. The scores validate the significant improvements over state-of-the-art results. An ablation study is also carried out to support the experimental observations.","2023-05-24","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","","","","","","","","","","","English","","","","WOS:000994104400005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Activation Function; Attention; Computer Vision; Higher Order Interaction; Image Captioning; Transformer; XGL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D27X8WZM","journalArticle","2024","Zhu, FX; Xie, J; Alshahrani, M","Learning Dual-Layer User Representation for Enhanced Item Recommendation","CMC-COMPUTERS MATERIALS & CONTINUA","","1546-2218","10.32604/cmc.2024.051046","","User representation learning is crucial for capturing different user preferences, but it is also critical challenging because user intentions are latent and dispersed in complex and different patterns of user-generated data, and thus cannot be measured directly. Text-based data models can learn user representations by mining latent semantics, which is beneficial to enhancing the semantic function of user representations. However, these technologies only extract common features in historical records and cannot represent changes in user intentions. However, sequential feature can express the user's interests and intentions that change time by time. But the sequential recommendation results based on the user representation of the item lack the interpretability of preference factors. To address these issues, we propose in this paper a novel model with Dual-Layer User Representation, named DLUR, where the user's intention is learned based on two different layer representations. Specifically, the latent semantic layer adds an interactive layer based on Transformer to extract keywords and key sentences in the text and serve as a basis for interpretation. The sequence layer uses the Transformer model to encode the user's preference intention to clarify changes in the user's intention. Therefore, this dual-layer user mode is more comprehensive than a single text mode or sequence mode and can effectually improve the performance of recommendations. Our extensive experiments on five benchmark datasets demonstrate DLUR's performance over state-of-the-art recommendation models. In addition, DLUR's ability to explain recommendation results is also demonstrated through some specific cases.","2024","2025-02-26 20:43:26","2025-02-26 20:43:26","","949-971","","1","80","","","","","","","","","","English","","","","WOS:001290839400007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","interpretability; latent semantic; sequential feature; User representation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8DSLYSHE","journalArticle","2023","Xia, Y; Xiong, YQ; Wang, KQ","A transformer model blended with CNN and denoising autoencoder for inter-patient ECG arrhythmia classification","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2023.105271","","Researchers have proposed numerous novel features and models under the intra-patient paradigm. However, their performance suffers when considering the inter-patient paradigm. While some state-of-the-art results have been reported in recent years under the inter-patient paradigm, many of them deviate from the standard test protocol. The performance of minority classes remains unsatisfactory for practical applications under strict test protocols. This paper presents a novel framework based on a lightweight Transformer combined with CNN and a denoising autoencoder, which enhances the performance of minority classes under the standard test protocol. The proposed model includes a new seq2seq network that extracts local features from a single heartbeat using CNN or a denoising encoder, and attends to global features from neighboring heartbeats based on a lightweight Transformer encoder. In particular, we pretrained the autoencoder on the MIT-BIH dataset and an additional dataset, considering several transfer modes for feature representation. We organized multiple continuous heartbeats into a vector sequence, where each heartbeat incorporates information from its neighbors to improve feature representation. The model evaluation was conducted using the MIT-BIH inter-patient dataset, following the AAMI standard. The Transformer with CNN embedding achieved a total accuracy of 97.66% on the test set, while the Transformer with pretrained denoising autoencoder achieved a total accuracy of 97.93%. These results demonstrate the promising performance of our models for imbalanced inter-patient ECG classification under the standard test protocol.","2023-09","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","86","","","","","","","","","","English","","","","WOS:001058873100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;20<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","CNN; CONVOLUTIONAL NEURAL-NETWORK; Denoising autoencoder; ECG classification; ELECTROCARDIOGRAM; HEARTBEAT CLASSIFICATION; Seq2seq model; Transfer learning; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"43PNMJY8","journalArticle","2023","Koshy, R; Elango, S","Multimodal tweet classification in disaster response systems using transformer-based bidirectional attention model","NEURAL COMPUTING & APPLICATIONS","","0941-0643","10.1007/s00521-022-07790-5","","The goal of this research is to use social media to gain situational awareness in the wake of a crisis. With the developments in information and communication technologies, social media became the de facto norm for gathering and disseminating information. We present a method for classifying informative tweets from the massive volume of user tweets on social media. Once the informative tweets have been found, emergency responders can use them to gain situational awareness so that recovery actions can be carried out efficiently. The majority of previous research has focused on either text data or images in tweets. A thorough review of the literature illustrates that text and image carry complementary information. The proposed method is a deep learning framework which utilizes multiple input modalities, specifically text and image from a user-generated tweet. We mainly focused to devise an improved multimodal fusion strategy. The proposed system has a transformer-based image and text models. The main building blocks include fine-tuned RoBERTa model for text, Vision Transformer model for image, biLSTM and attention mechanism. We put forward a multiplicative fusion strategy for image and text inputs. Extensive experiments have been done on various network architectures with seven datasets spanning different types of disasters, including wildfire, hurricane, earth-quake and flood. Several state-of-the-art approaches were surpassed by our system. It showed good accuracy in the range of 94-98%. The results showed that identifying the interaction between multiple related modalities will enhance the quality of a deep learning classifier.","2023-01","2025-02-26 20:43:26","2025-02-26 20:43:26","","1607-1627","","2","35","","","","","","","","","","English","","","","WOS:000862525100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Attention; BiLSTM; Disaster tweet classification; Multimodal data fusion; RoBERTa; TWITTER; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8M8F95W7","journalArticle","2022","Kang, JL; Chiu, CT; Huang, JS; Wong, DSH","A surrogate model of sigma profile and COSMOSAC activity coefficient predictions of using transformer with SMILES input","DIGITAL CHEMICAL ENGINEERING","","2772-5081","10.1016/j.dche.2022.100016","","COSMOSAC is a model that allows apriori predictions of activity coefficients for characterizing solute-solvent interactions. The method requires the input of sigma profile, the charge distribution on the surface of the molecules, which can be obtained through quantum mechanics calculation. Since Sigma profile is a unique function of molecular structure, it is desirable that they can be obtained using a surrogate model of the quantum computation with a molecular description as input. Previously, a model, the Universal Digital Chemical Space (UDCS), that was developed that allowed us to calculate the Sigma profiles used Simplified Molecular-Input-Line-Entry system (SMILES) as input. In this work, an improved version of this approach was developed using a Transformer model to encode the SMILES text string. Successive input elements in the text string, known as K-mers was also encoded and errors of predicted moments of Sigma profiles and prediction of activity coefficient of reference solvents were also considered as in the loss function. Results showed that while the prediction accuracy of Sigma profile (coefficient of determination R 2 ) were not significantly improved, prediction accuracy of the first and second moment, especially the poorer ranked results; as well as the activity coefficients can be significantly improved with the inclusion of higher K-mers. Further improvement can be achieved with the inclusion of activity loss which substantially improved the accuracy of the 5th and 25th percentile of the moment loss and the activity coefficient of the species in n-hexane.","2022-03","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","2","","","","","","","","","","English","","","","WOS:001100941100009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;17</p>","","","COSMOSAC activity coefficient; K-mer; Sigma profile; SMILES; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HNAJ4TGC","journalArticle","2024","Cha, JS; Athanasiadis, DI; Peng, YH; Wu, D; Anton, NE; Stefanidis, D; Yu, D","Objective Nontechnical Skills Measurement Using Sensor-based Behavior Metrics in Surgical Teams","HUMAN FACTORS","","0018-7208","10.1177/00187208221101292","","Objective The purpose of this study was to identify objective measures that predict surgeon nontechnical skills (NTS) during surgery. Background NTS are cognitive and social skills that impact operative performance and patient outcomes. Current methods for NTS assessment in surgery rely on observation-based tools to rate intraoperative behavior. These tools are resource intensive (e.g., time for observation or manual labeling) to perform; therefore, more efficient approaches are needed. Method Thirty-four robotic-assisted surgeries were observed. Proximity sensors were placed on the surgical team and voice recorders were placed on the surgeon. Surgeon NTS was assessed by trained observers using the NonTechnical Skills for Surgeons (NOTSS) tool. NTS behavior metrics from the sensors included communication, speech, and proximity features. The metrics were used to develop mixed effect models to predict NOTSS score and in machine learning classifiers to distinguish between exemplar NTS scores (highest NOTSS score) and non-exemplar scores. Results NTS metrics were collected from 16 nurses, 12 assistants, 11 anesthesiologists, and four surgeons. Nineteen behavior features and overall NOTSS score were significantly correlated (12 communication features, two speech features, five proximity features). The random forest classifier achieved the highest accuracy of 70% (80% F1 score) to predict exemplar NTS score. Conclusion Sensor-based measures of communication, speech, and proximity can potentially predict NOTSS scores of surgeons during robotic-assisted surgery. These sensing-based approaches can be utilized for further reducing resource costs of NTS and team performance assessment in surgical environments. Application Sensor-based assessment of operative teams' behaviors can lead to objective, real-time NTS measurement.","2024-03","2025-02-26 20:43:26","2025-02-26 20:43:26","","729-743","","3","66","","","","","","","","","","English","","","","WOS:000804746900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","COGNITIVE WORKLOAD; communication; COMMUNICATION; DISTRACTIONS; EFFICIENCY; machine learning; MOVEMENT; OPERATING-ROOM; POLITENESS; prosody; proximity; ROBOTIC SURGERY; robotic-assisted surgery; SITUATION AWARENESS; speech; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YW5TVNUA","journalArticle","2021","Shahamiri, SR","Speech Vision: An End-to-End Deep Learning-Based Dysarthric Automatic Speech Recognition System","IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING","","1534-4320","10.1109/TNSRE.2021.3076778","","Dysarthria is a disorder that affects an individual's speech intelligibility due to the paralysis of muscles and organs involved in the articulation process. As the condition is often associated with physically debilitating disabilities, not only do such individuals face communication problems, but also interactions with digital devices can become a burden. For these individuals, automatic speech recognition (ASR) technologies can make a significant difference in their lives as computing and portable digital devices can become an interaction medium, enabling them to communicate with others and computers. However, ASR technologies have performed poorly in recognizing dysarthric speech, especially for severe dysarthria, due to multiple challenges facing dysarthric ASR systems. We identified these challenges are due to the alternation and inaccuracy of dysarthric phonemes, the scarcity of dysarthric speech data, and the phoneme labeling imprecision. This paper reports on our second dysarthric-specific ASR system, called Speech Vision (SV) that tackles these challenges by adopting a novel approach towards dysarthric ASR in which speech features are extracted visually, then SV learns to see the shape of the words pronounced by dysarthric individuals. This visual acoustic modeling feature of SV eliminates phoneme-related challenges. To address the data scarcity problem, SV adopts visual data augmentation techniques, generates synthetic dysarthric acoustic visuals, and leverages transfer learning. Benchmarking with other state-of-the-art dysarthric ASR considered in this study, SV outperformed them by improving recognition accuracies for 67% of UA-Speech speakers, where the biggest improvements were achieved for severe dysarthria.","2021","2025-02-26 20:43:26","2025-02-26 20:43:26","","852-861","","","29","","","","","","","","","","English","","","","WOS:000648152000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;66<br/>Total Times Cited:&nbsp;&nbsp;68<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Acoustics; deep learning; Dysarthria; dysarthric speech recognition; Hidden Markov models; IMPROVING ACOUSTIC MODELS; Neural networks; NEURAL-NETWORKS; Speech recognition; Standards; synthetic speech; Training; Vocabulary","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PBUMZYI2","journalArticle","2022","Narain, J; Johnson, KT; Quatieri, TF; Picard, RW; Maes, P","Modeling Real-World Affective and Communicative Nonverbal Vocalizations From Minimally Speaking Individuals","IEEE TRANSACTIONS ON AFFECTIVE COMPUTING","","1949-3045","10.1109/TAFFC.2022.3208233","","Nonverbal vocalizations from non- and minimally speaking individuals who speak fewer than 20 words (mv* individuals) convey important communicative and affective information. While nonverbal vocalizations that occur amidst typical speech and infant vocalizations have been studied extensively in the literature, there is limited prior work on vocalizations by mv* individuals. Our work is among the first studies of the communicative and affective information expressed in nonverbal vocalizations by mv* children and adults. We collected labeled vocalizations in real-world settings with eight mv* communicators, with communicative and affective labels provided in-the-moment by a close family member. Using evaluation strategies suitable for messy, real-world data, we show that nonverbal vocalizations can be classified by function (with 4- and 5-way classifications) with F1 scores above chance for all participants. We analyze labeling and data collection practices for each participating family, and discuss the classification results in the context of our novel real-world data collection protocol. The presented work includes results from the largest classification experiments with nonverbal vocalizations from mv* communicators to date.","2022-10-01","2025-02-26 20:43:26","2025-02-26 20:43:26","","2238-2253","","4","13","","","","","","","","","","English","","","","WOS:000892948500041","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","ADULTS; affect sensing and analysis; Affective computing; AUTISM SPECTRUM DISORDER; CHILDREN; EMOTION; EXPRESSIVE LANGUAGE; GESTURES; INFANTS; INTERVENTION; nonverbal speech; RECOGNITION; RISK; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HM6LFIW7","journalArticle","2024","Tong, CF; Hou, HF; Zheng, HX; Wang, Y; Liu, J","A Coupled Model for Forecasting Spatiotemporal Variability of Regional Drought in the Mu Us Sandy Land Using a Meta-Heuristic Algorithm","LAND","","2073-445X","10.3390/land13111731","","Vegetation plays a vital role in terrestrial ecosystems, and droughts driven by rising temperatures pose significant threats to vegetation health. This study investigates the evolution of vegetation drought from 2010 to 2024 and introduces a deep-learning-based forecasting model for analyzing regional spatial and temporal variations in drought. Extensive time-series remote-sensing data were utilized, and we integrated the Temperature-Vegetation Dryness Index (TVDI), Drought Severity Index (DSI), Evaporation Stress Index (ESI), and the Temperature-Vegetation-Precipitation Dryness Index (TVPDI) to develop a comprehensive methodology for extracting regional vegetation drought characteristics. To mitigate the effects of regional drought non-stationarity on predictive accuracy, we propose a coupling-enhancement strategy that combines the Whale Optimization Algorithm (WOA) with the Informer model, enabling more precise forecasting of long-term regional drought variations. Unlike conventional deep-learning models, this approach introduces rapid convergence and global search capabilities, utilizing a sparse self-attention mechanism that improves performance while reducing model complexity. The results demonstrate that: (1) compared to the traditional Transformer model, test accuracy is improved by 43%; (2) the WOA-Informer model efficiently handles multi-objective forecasting for extended time series, achieving MAE (Mean Absolute Error) <= 0.05, MSE (Mean Squared Error) <= 0.001, MSPE (Mean Squared Percentage Error) <= 0.01, and MAPE (Mean Absolute Percentage Error) <= 5%. This research provides advanced predictive tools and precise model support for long-term vegetation restoration efforts.","2024-11","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","11","13","","","","","","","","","","English","","","","WOS:001365644000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","ANT COLONY OPTIMIZATION; PARAMETERS; predictive accuracy; sparse self-attention mechanism; vegetation drought; WHALE OPTIMIZATION ALGORITHM; Whale Optimization Algorithm (WOA)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XSEWHQ5F","journalArticle","2024","Kanakgiri, K; Bhardwaj, DI; Ram, BS; Kulkarni, SV","A Circuit-Based Formulation for Soft Magnetic Materials Using the Jiles-Atherton Model","IEEE TRANSACTIONS ON MAGNETICS","","0018-9464","10.1109/TMAG.2024.3452593","","It is crucial to accurately estimate the performance of magnetic components, such as inductors and transformers, during their pre-design stage. The magnetic characteristics of soft magnetic materials are significantly affected by their excitation. For example, a time-varying excitation results in dynamic losses (eddy and excess loss components), and an excitation with harmonics leads to extra losses. To accurately model these components with a generalized approach, it is important to consider a physics-based hysteresis formulation in electromagnetic analysis. Some circuit and electromagnetic field simulators can model hysteresis characteristics using formulations, such as the Jiles-Atherton (JA) hysteresis model. However, these simulators require the JA model parameters as input, and it is a challenge for simulation engineers to calculate the JA model parameters. In this work, an inductor circuit element is proposed using the JA model to define the magnetic characteristics of soft magnetic materials in an open-source circuit simulator. Providing hysteresis (or B-H loop) data as input to the circuit element in the proposed approach obviates the need of calculating the JA model parameters for circuit simulation. The B-H data are used to determine the JA model parameters, which are automatically transferred to the inductor model in the circuit simulation. The approach can be used to model the topological-based equivalent circuit of magnetic components, such as inductors and transformers.","2024-10","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","10","60","","","","","","","","","","English","","","","WOS:001322634500007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","HYSTERESIS; Hysteresis model; IDENTIFICATION; Inductors; Integrated circuit modeling; Jiles-Atherton (JA) model; Levenberg-Marquardt (LM) algorithm; LOSSES; Magnetic circuits; Magnetic hysteresis; Magnetization; Mathematical models; Saturation magnetization; SIMULATION; TRANSFORMER MODEL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6IH792AU","journalArticle","2024","Chilumbu, C; Huang, QX; Sun, HM","Utilizing a DenseSwin Transformer Model for the Classification of Maize Plant Pathology in Early and Late Growth Stages: A Case Study of Its Utilization Among Zambian Farmers","IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE","","2471-285X","10.1109/TETCI.2024.3444603","","Maize, which is the primarycrop in many sub-Saharan countries, including Zambia, is susceptible to a wide range of diseases that have a significant impact on food production. To tackle this challenge and improve disease detection efficiency, deep learning methods have been employed to accurately classify and identify plant diseases. In recent times, manual inspection of maize fields for disease detection has been the standard practice in many parts of Zambia. However, this approach is not only time-consuming but also impractical for large-scale agricultural operations. Hence, the development of precise and automated classification models has become crucial in modern agriculture. In this study, we propose a novel deep-learning model called DenseSwin, specifically designed for maize disease classification in both the early visible stage and late indisputable stage of the disease. DenseSwin combines the strengths of densely connected convolution blocks with a shifted windows-based multi-head self-attention mechanism. This unique fusion of techniques enables the model to effectively capture intricate patterns and features in maize plant images, thereby enhancing disease classification performance. Through extensive experimentation and evaluation, DenseSwin achieves an impressive accuracy of 97.18%. These results highlight the model's remarkable ability to accurately detect and classify maize diseases, offering promising potential for real-world applications in agricultural settings, particularly in Zambia.","2024-09-17","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","","","","","","","","","","","English","","","","WOS:001317699300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Accuracy; Computational modeling; Crops; DenseSwin; Diseases; maize disease classification; maize pathology; multi-head self-attention mechanism; Pathology; Plant diseases; transformer architecture; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YTABQRS3","journalArticle","2024","Jiang, H; Chen, Y; Wu, D; Yan, JL","EEG-driven automatic generation of emotive music based on transformer","FRONTIERS IN NEUROROBOTICS","","1662-5218","10.3389/fnbot.2024.1437737","","Utilizing deep features from electroencephalography (EEG) data for emotional music composition provides a novel approach for creating personalized and emotionally rich music. Compared to textual data, converting continuous EEG and music data into discrete units presents significant challenges, particularly the lack of a clear and fixed vocabulary for standardizing EEG and audio data. The lack of this standard makes the mapping relationship between EEG signals and musical elements (such as rhythm, melody, and emotion) blurry and complex. Therefore, we propose a method of using clustering to create discrete representations and using the Transformer model to reverse mapping relationships. Specifically, the model uses clustering labels to segment signals and independently encodes EEG and emotional music data to construct a vocabulary, thereby achieving discrete representation. A time series dictionary was developed using clustering algorithms, which more effectively captures and utilizes the temporal and structural relationships between EEG and audio data. In response to the insensitivity to temporal information in heterogeneous data, we adopted a multi head attention mechanism and positional encoding technology to enable the model to focus on information in different subspaces, thereby enhancing the understanding of the complex internal structure of EEG and audio data. In addition, to address the mismatch between local and global information in emotion driven music generation, we introduce an audio masking prediction loss learning method. Our method generates music that Hits@20 On the indicator, a performance of 68.19% was achieved, which improved the score by 4.9% compared to other methods, indicating the effectiveness of this method.","2024-08-19","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","18","","","","","","","","","","English","","","","WOS:001301864600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","EEG; emotive music generation; information retrieval; latent features; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HQZ5NUWR","journalArticle","2024","Zhang, F; Nghiem, L; Chen, ZX","A novel approach to solve hyperbolic Buckley-Leverett equation by using a transformer based physics informed neural network","GEOENERGY SCIENCE AND ENGINEERING","","2949-8929","10.1016/j.geoen.2024.212711","","Solving hyperbolic partial differential equation is a challenging task due to the non-linear feature that requires to capture the shock wave. Numerical solution relies on discretization of both spatial and temporal domain, and iterative approach like Newton's method is involved and time step size is crucial for stability and convergence in the presence of non-linearity. Physics-informed neural networks (PINNs) offer a new and versatile approach for solving partial different equations by minimizing the residual of governing equations and approaching to the initial and boundary conditions. Currently, most PINNs are built based on a simple fully connected neural network which exhibits some limitations to model complex non-linear partial differential equations. In this paper, a novel method is developed to combine Transformer model and PINNs approach (Tr-PINN) to solving a hyperbolic partial differential equation directly without any prior knowledge. Tr-PINN method is based on a series of Transformer blocks where self-attention mechanism is used to capture the non-linearity features of the solution. Unlike most PINNs models generate inputs with spatial and temporal vectors only, Tr-PINN introduces the non-linearity term mobility ratio as additional input vector. The method is tested on a classical hyperbolic problem, called Buckley-Leverett equation with non-convex flux function. We found that the Tr-PINN method can capture the water shock front effectively and provide a general solution for Buckley-Leverett equation under various mobility ratio conditions.","2024-05","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","236","","","","","","","","","","English","","","","WOS:001208065400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Hyperbolic equation; Physics Informed Neural Network; Self-attentional; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"33R2JMUN","journalArticle","2023","Lee, S; Shin, Y; Kim, M; Seo, J","IR-UWB Radar-Based Contactless Silent Speech Recognition of Vowels, Consonants, Words, and Phrases","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3344177","","Several sensing techniques have been proposed for silent speech recognition (SSR); however, many of these methods require invasive processes or sensor attachment to the skin using adhesive tape or glue, rendering them unsuitable for frequent use in daily life. By contrast, impulse radio ultra-wideband (IR-UWB) radar can operate without physical contact with users' articulators and related body parts, offering several advantages for SSR. These advantages include high range resolution, high penetrability, low power consumption, robustness to external light or sound interference, and the ability to be embedded in space-constrained handheld devices. This study demonstrated IR-UWB radar-based contactless SSR using four types of speech stimuli (vowels, consonants, words, and phrases). To achieve this, a novel speech feature extraction algorithm specifically designed for IR-UWB radar-based SSR is proposed. Each speech stimulus is recognized by applying a classification algorithm to the extracted speech features. Two different algorithms, multidimensional dynamic time warping (MD-DTW) and deep neural network-hidden Markov model (DNN-HMM), were compared for the classification task. Additionally, a favorable radar antenna position, either in front of the user's lips or below the user's chin, was determined to achieve higher recognition accuracy. Experimental results demonstrated the efficacy of the proposed speech feature extraction algorithm combined with DNN-HMM for classifying vowels, consonants, words, and phrases. Notably, this study represents the first demonstration of phoneme-level SSR using contactless radar.","2023","2025-02-26 20:43:26","2025-02-26 20:43:26","","144844-144859","","","11","","","","","","","","","","English","","","","WOS:001131660300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","ARTICULOGRAPHY; CLASSIFICATION; Classification algorithms; COMMUNICATION; consonant and vowel classification; contactless silent speech recognition; Doppler radar; Feature extraction; Impulse radio ultra-wideband (IR-UWB) radar; MOVEMENTS; Natural language processing; NETWORK; POINTS; Radar antennas; speech feature extraction; Speech recognition; SYSTEM; Ultra wideband technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CR924IH6","journalArticle","2024","Li, YX; Ugli, INR; Ugli, YIH; Lee, T; Kim, TK","Optimizing Models and Data Denoising Algorithms for Power Load Forecasting","ENERGIES","","1996-1073","10.3390/en17215513","","To handle the data imbalance and inaccurate prediction in power load forecasting, an integrated data denoising power load forecasting method is designed. This method divides data into administrative regions, industries, and load characteristics using a four-step method, extracts periodic features using Fourier transform, and uses Kmeans++ for clustering processing. On this basis, a Transformer model based on an adversarial adaptive mechanism is designed, which aligns the data distribution of the source domain and target domain through a domain discriminator and feature extractor, thereby reducing the impact of domain offset on prediction accuracy. The mean square error of the Fourier transform clustering method used in this study was 0.154, which was lower than other methods and had a better data denoising effect. In load forecasting, the mean square errors of the model in predicting long-term load, short-term load, and real-time load were 0.026, 0.107, and 0.107, respectively, all lower than the values of other comparative models. Therefore, the load forecasting model designed for research has accuracy and stability, and it can provide a foundation for the precise control of urban power systems. The contributions of this study include improving the accuracy and stability of the load forecasting model, which provides the basis for the precise control of urban power systems. The model tracks periodicity, short-term load stochasticity, and high-frequency fluctuations in long-term loads well, and possesses high accuracy in short-term, long-term, and real-time load forecasting.","2024-11","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","21","17","","","","","","","","","","English","","","","WOS:001351414900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","cluster analysis; data noise reduction; Kmeans plus plus; load forecasting; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E2M68MPD","journalArticle","2024","Xiong, YG; Xiao, XM; Yao, MB; Cui, HT; Fu, YG","Light4Mars: A lightweight transformer model for semantic segmentation on unstructured environment like Mars","ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING","","0924-2716","10.1016/j.isprsjprs.2024.06.008","","Auto-semantic segmentation is important for robots on unstructured and dynamic environments like planets where ambient conditions cannot be controlled and the scale is larger than that found indoors. Current learning- based methods have achieved breathtaking improvements on this topic. For onboard applications, however, all those methods still suffer from huge computational costs and are difficult to deploy on edge devices. In this paper, unlike previous transformer-based SOTA approaches that heavily relied on complex design, we proposed Light4Mars, a lightweight model with minimal computational complexity while maintaining high segmenting accuracy. We designed a lightweight squeeze window transformer module that focuses on window-scale feature extraction and is more effective in learning global and local contextual information. The aggregated local attention decoder is utilized to fuse semantic information at different scales, especially for unstructured scenes. Since there are few all-terrain datasets for semantic segmentation of unstructured scenes like Mars, we built a synthetic dataset SynMars-TW, referencing images collected by the ZhuRong rover on the Tianwen-1 mission and the Curiosity rover. Extensive experiments on SynMars-TW and the real Mars dataset, MarsScapes show that our approach achieves state-of-the-art performance with favorable computational simplicity. To the best of our knowledge, the proposed Light4Mars-T network is the first segmentation model for Mars image segmentation with parameters lower than 0.1M. . Code and datasets are available at https://github.com/CVIR-Lab/Light4Mars.","2024-08","2025-02-26 20:43:26","2025-02-26 20:43:26","","167-178","","","214","","","","","","","","","","English","","","","WOS:001333956200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","DESCENT; ENTRY; GUIDANCE; Lightweight model; Mars; NETWORK; Semantic segmentation; SYSTEM-DESIGN; TIANWEN-1; Unstructured environment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H2MG6YZD","journalArticle","2024","Xia, Y; Luo, JY; Zhou, G; Lan, MJ; Chen, XH; Chen, J","DT4KGR: Decision transformer for fast and effective multi-hop reasoning over knowledge graphs","INFORMATION PROCESSING & MANAGEMENT","","0306-4573","10.1016/j.ipm.2024.103648","","Multi -hop reasoning over knowledge graphs has received plenty of attention from researchers and is being widely applied to facilitate the development of recommender systems, question answering systems, and other information retrieval systems. Existing multi -hop reasoning methods tend to suffer from poor training efficiency as a result of the large search space and have difficulty tackling missing paths during the reasoning process. Accordingly, we propose a sequence -to -sequence model called DT4KGR, in which an encoder-decoder Transformer framework was designed for knowledge graph reasoning. We trained our Transformer model using teacher forcing, so the model processes the entire sequence of reasoning paths in a highly parallel fashion. In this way, faster training speeds are achieved. The model conditions an autoregressive architecture to implement sequence path generation, rather than preceding path exploration, thus performed more robustly to missing paths. We also designed a ruleguided path exploration strategy by combining the local path semantic similarity with the attention mechanism and the global graph information with rule guidance, to sample highquality training paths for our model. We evaluated DT 4KGR through various tasks on seven different real -world datasets. The experimental results reveal DT 4KGR achieves better link prediction results compared with the state-of-the-art baseline models while converging 5-8 times faster, especially achieving an approximately 7.8% relative improvement for MRR on NELL-995 dataset. In addition, efficiency studies indicate our model performs better scalability in large-scale knowledge graph environments compared with other methods.","2024-05","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","3","61","","","","","","","","","","English","","","","WOS:001167388400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Knowledge graphs; Knowledge reasoning; Reinforcement learning pattern; Sequence-to-sequence framework","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YJVMF7HY","journalArticle","2024","Wang, NQ","Research on Deep Learning-Based Social Media Word-of-Mouth Analysis Model","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3437734","","With the popularization of social media, Word-of-mouth analysis, as an important market research method, can help companies understand users' attitudes and opinions towards their brands. However, existing social media word-of-mouth analysis methods face challenges such as insufficient feature fusion, low accuracy of sentiment analysis, low precision of topic identification, as well as data sparsity and high annotation costs, which hinder the comprehensive and accurate analysis of word-of-mouth. To address these challenges, this paper proposes a social media word-of-mouth analysis model combining the Adaptive Vision Transformer (AViT) model and Enhanced BERT (EBERT) model. Firstly, we improve the traditional Transformer model by introducing dynamic attention mechanism and multi-scale processing to enhance its adaptability to different types of images, effectively adjusting computational resources, and enhancing attention to various parts of the images. Secondly, enhancements are made to the BERT model, including learnable positional encodings, sparse Transformer mechanism, and enhanced Masked Language Model, enabling better capture of semantic information and contextual relationships. Furthermore, by introducing the idea of multi-task learning, sentiment classification, topic recognition, and other tasks are combined to achieve comprehensive analysis of word-of-mouth. Through experiments on large-scale social media datasets, the proposed model not only achieves high accuracy in sentiment analysis and topic recognition tasks but also demonstrates good generalization ability, providing an effective social media marketing strategy and decision support tool for enterprises and marketing practitioners.","2024","2025-02-26 20:43:26","2025-02-26 20:43:26","","106537-106549","","","12","","","","","","","","","","English","","","","WOS:001288429000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Adaptation models; Analytical models; AViT; Computational modeling; EBERT; Encoding; Multi-task learning; social media; Social networking (online); Solid modeling; Transformers; word-of-mouth analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PY6IPHAT","journalArticle","2023","Yang, ER; Li, MD; Raghavan, S; Deng, FC; Lang, M; Succi, MD; Huang, AJ; Kalpathy-cramer, J","Transformer versus traditional natural language processing: how much data is enough for automated radiology report classification?","BRITISH JOURNAL OF RADIOLOGY","","0007-1285","10.1259/bjr.20220769","","Objectives: Current state-of-the-art natural language processing (NLP) techniques use transformer deeplearning architectures, which depend on large training datasets. We hypothesized that traditional NLP techniques may outperform transformers for smaller radiology report datasets. Methods: We compared the performance of BioBERT, a deeplearning - based transformer model pre- trained on biomedical text, and three traditional machine- learning models (gradient boosted tree, random forest, and logistic regression) on seven classification tasks given free - text radiology reports. Tasks included detection of appendicitis, diverticulitis, bowel obstruction, and enteritis/colitis on abdomen/pelvis CT reports, ischemic infarct on brain CT/MRI reports, and medial and lateral meniscus tears on knee MRI reports (7,204 total annotated reports). The performance of NLP models on held - out test sets was compared after training using the full training set, and 2.5%, 10%, 25%, 50%, and 75% random subsets of the training data. Results: In all tested classification tasks, BioBERT performed poorly at smaller training sample sizes compared to nondeeplearning NLP models. Specifically, BioBERT required training on approximately 1,000 reports to perform similarly or better than nondeeplearning models. At around 1,250 to 1,500 training samples, the testing performance for all models began to plateau, where additional training data yielded minimal performance gain. Conclusions: With larger sample sizes, transformer NLP models achieved superior performance in radiology report binary classification tasks. However, with smaller sizes (<1000) and more imbalanced training data, traditional NLP techniques performed better. Advances in knowledge: Our benchmarks can help guide clinical NLP researchers in selecting machine- learning models according to their dataset characteristics.","2023","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","1149","96","","","","","","","","","","English","","","","WOS:001171489400003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","ANNOTATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J4EZS4SV","journalArticle","2022","Lu, MY; Wang, ML; Zhang, Q; Yu, MZ; He, CF; Zhang, YD; Li, YC","A vision transformer for lightning intensity estimation using 3D weather radar","SCIENCE OF THE TOTAL ENVIRONMENT","","0048-9697","10.1016/j.scitotenv.2022.158496","","Lightning has strong destructive powers; its blast wave, high temperature, and high voltage can pose a great threat to human production, life, and personal safety. The destructive power of high-intensity lightning is much greater than that of low-intensity lightning. The estimation of lightning intensity can provide an important reference for determin-ing the lightning protection level and lightning disaster risk assessment. Lightning is a type of small-scale severe con-vective weather phenomenon. Weather radar is one of the best monitoring systems that can frequently sample the detailed three-dimensional (3D) structures of convective storms, with a small spatial scale and short lifetime at high temporal and spatial resolutions. Therefore, it is possible to extract the 3D spatial feature strongly correlated with light-ning from 3D weather radar for estimating lightning intensity. This paper proposes a Vision Transformer model for lightning intensity estimation that can automatically estimate lightning intensity from 3D weather radar data. In an experiment, we transferred the task of estimating lightning intensity into a multicategory classification task. A frame-work was designed to produce lightning feature samples for model input from 3D weather radar and lightning location data. Then, the Synthetic Minority Over-Sampling Technique (SMOTE) algorithm was used to balance and optimize the sample distribution. Finally, samples were input into the proposed lightning intensity estimation model based on Vision Transformer for training and evaluation. Experimental results show that the proposed model based on Vision Transformers performs well with lightning intensity estimation.","2022-12-20","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","853","","","","","","","","","","English","","","","WOS:000865439400014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","3D weather radar; Lightning intensity estimation; Multicategoryclassification; SMOTE; TROPICAL CYCLONE INTENSITY; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HDAWGHID","journalArticle","2025","Abadi, VNM; Ghasemian, F","Enhancing Persian text summarization through a three-phase fine-tuning and reinforcement learning approach with the mT5 transformer model","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-78235-3","","In the contemporary era, grappling with the vast expanse of big data presents a formidable obstacle, particularly when it comes to extracting vital information from extensive textual sources. The constant influx of news articles from various agencies necessitates an enormous amount of time to digest comprehensively. A viable solution to address this challenge lies in the realm of automatic text summarization, which is a pivotal and intricate endeavor within the field of natural language processing. Text summarization involves transforming pertinent textual content into a concise format that reduces its word count without compromising its underlying meaning. In recent years, transformers have emerged as a prominent force in the landscape of natural language processing, particularly in the realm of text summarization. This research endeavors to harness the power of transformers by training the mT5-base model on a three-step fine-tuning phase on Persian news articles. Subsequently, reinforcement learning via the PPO algorithm is integrated with the fine-tuned model. Finally, we evaluate the model's performance in summarizing Persian texts, shedding light on its efficacy in addressing the formidable task of distilling meaningful insights from a sea of textual data. Our model has set a new benchmark in the field of Persian text summarization, achieving outstanding ROUGE scores of 53.17 for ROUGE-1, 37.12 for ROUGE-2, and 44.13 for ROUGE-L. These remarkable results reflect a significant advancement in the quality of Persian text summarization, signaling a promising era of more refined and context-aware summaries.","2025-01-02","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","1","15","","","","","","","","","","English","","","","WOS:001390087500028","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NGPPVLBT","journalArticle","2025","Li, R; Zou, ZB","How far back shall we peer? Optimal air handling unit control leveraging extensive past observations","BUILDING AND ENVIRONMENT","","0360-1323","10.1016/j.buildenv.2024.112347","","Heating, Ventilation, and Air Conditioning (HVAC) systems playa critical role in ensuring occupant comfort in buildings. Traditional Rule-Based Feedback Control (RBFC) systems, while widely deployed for their simplicity, suffer from low adaptability. Recent improvements, such as Model Predictive Control (MPC) methods demand complex mathematical modeling and substantial expert knowledge, creating a high barrier for system design and optimization. Reinforcement Learning (RL) emerges as a promising solution with its adaptability and model-free nature, albeit challenged by sample inefficiency and suboptimal convergence. Given the intrinsic delayed effects from previous actions and prolonged thermal inertia in the HVAC systems, this study introduces an innovative deep RL framework that can leverage historical observations to refine RL agent performance. By incorporating a state-of-the-art (SOTA) Transformer model, we capture the temporal patterns in HVAC data and build amore precise RL training environment. Implemented on high-resolution, real-world HVAC datasets, our framework showed superior performance in both HVAC system modeling and RL control performance. Specifically, compared to the two baseline models-Bidirectional Long Short-Term Memory (BiLSTM) and vanilla Transformer, our proposed RL environment model achieved an average of 30.5% and 35.8% prediction accuracy improvement, respectively. Moreover, our optimal past observable RL agent swiftly delivers 35.3% of electricity saving and 54.4% of thermal comfort improvement over traditional RBFC. These results show the effectiveness of the pioneering integration of extensive historical observations for HVAC operation optimization.","2025-02-01","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","269","","","","","","","","","","English","","","","WOS:001377235000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","BUILDINGS; ENERGY-CONSUMPTION; HVAC optimization; IDENTIFICATION; Learning-based control; MODEL-PREDICTIVE CONTROL; SIMULATION; SYSTEM; Thermal comfort; THERMAL COMFORT; Time-series modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8AFJZS5A","journalArticle","2024","Fentaye, AD; Kyprianidis, KG","Gas turbine prognostics via Temporal Fusion Transformer","AERONAUTICAL JOURNAL","","0001-9240","10.1017/aer.2024.40","","Gas turbines play a vital role in various industries. Timely and accurately predicting their degradation is essential for efficient operation and optimal maintenance planning. Diagnostic and prognostic outcomes aid in determining the optimal compressor washing intervals. Diagnostics detects compressor fouling and estimates the trend up to the current time. If the forecast indicates fast progress in the fouling trend, scheduling offline washing during the next inspection event or earlier may be crucial to address the fouling deposit comprehensively. This approach ensures that compressor cleaning is performed based on its actual health status, leading to improved operation and maintenance costs. This paper presents a novel prognostic method for gas turbine degradation forecasting through a time-series analysis. The proposed approach uses the Temporal Fusion Transformer model capable of capturing time-series relationships at different scales. It combines encoder and decoder layers to capture temporal dependencies and temporal-attention layers to capture long-range dependencies across the encoded degradation trends. Temporal attention is a self-attention mechanism that enables the model to consider the importance of each time step degradation in the context of the entire degradation profile of the given health parameter. Performance data from multiple two-spool turbofan engines is employed to train and test the method. The test results show promising forecasting ability of the proposed method multiple flight cycles into the future. By leveraging the insights provided by the method, maintenance events and activities can be scheduled in a proactive manner. Future work is to extend the method to estimate remaining useful life.","2024-07","2025-02-26 20:43:26","2025-02-26 20:43:26","","1594-1609","","1325","128","","","","","","","","","","English","","","","WOS:001207525400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","compressor washing; DIAGNOSTICS; gas turbines prognostics; maintenance optimisation; PERFORMANCE; predictive maintenance; remaining useful life; Temporal Fusion Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"373J8QMY","journalArticle","2024","Jiang, TY; Fu, XB; Wang, M","BBO-CFAT: Network Intrusion Detection Model Based on BBO Algorithm and Hierarchical Transformer","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3386405","","In today's network environments, vulnerable to cyber threats such as hackers and viruses, intrusion detection technology is considered the most effective means of detection and defense. Deep neural networks are commonly used in intrusion detection technology. However, improving the model's ability to extract feature information and reducing computational space while retaining local feature information are critical challenges that need to be addressed. To tackle these issues, this paper proposes a model named BBO-CFAT, which combines the Biogeography-Based Optimization algorithm (BBO) for feature selection and an improved Transformer model for preserving context information and reducing computational space. Specifically, the BBO-CFAT model employs a roulette selection method to control the operations of migration and mutation operators. It utilizes feature information entropy to weight updates of adaptive variables in these operators, thereby enhancing the credibility of feature selection. Furthermore, the Transformer framework is hierarchically designed to facilitate the acquisition of context information. Additionally, depthwise separable convolutions are employed to reduce computational space, thereby improving computational efficiency and training speed. Experimental evaluations using the CIC-IDS2017 and NSL-KDD datasets demonstrate promising accuracies for BBO-CFAT on both datasets, achieving 99.1% and 97.5% accuracy, respectively, surpassing the performance of comparative experiments. Overall, the BBO-CFAT model provides a comprehensive solution to the challenges of intrusion detection, effectively balancing feature preservation, computational efficiency, and training accuracy.","2024","2025-02-26 20:43:26","2025-02-26 20:43:26","","54191-54201","","","12","","","","","","","","","","English","","","","WOS:001205751000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","Adaptation models; ANOMALY DETECTION; BBO; Biological system modeling; Computational efficiency; Computational modeling; Context modeling; Cyber terrorism; Feature extraction; feature selection; FEATURE-SELECTION; Habitats; Intrusion detection; Optimization methods; SVM; SYSTEM; Threat assessment; TIME; Training; transformer; Transformers; Vectors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8QEP47DI","journalArticle","2024","Racic, M; Ostir, K; Zupanc, A; Zajc, LC","Multi-Year Time Series Transfer Learning: Application of Early Crop Classification","REMOTE SENSING","","2072-4292","10.3390/rs16020270","","Crop classification is an important task in remote sensing with many applications, such as estimating yields, detecting crop diseases and pests, and ensuring food security. In this study, we combined knowledge from remote sensing, machine learning, and agriculture to investigate the application of transfer learning with a transformer model for variable length satellite image time series (SITS). The objective was to produce a map of agricultural land, reduce required interventions, and limit in-field visits. Specifically, we aimed to provide reliable agricultural land class predictions in a timely manner and quantify the necessary amount of reference parcels to achieve these outcomes. Our dataset consisted of Sentinel-2 satellite imagery and reference crop labels for Slovenia spanning over years 2019, 2020, and 2021. We evaluated adaptability through fine-tuning in a real-world scenario of early crop classification with limited up-to-date reference data. The base model trained on a different year achieved an average F1 score of 82.5% for the target year without having a reference from the target year. To increase accuracy with a new model trained from scratch, an average of 48,000 samples are required in the target year. Using transfer learning, the pre-trained models can be efficiently adapted to an unknown year, requiring less than 0.3% (1500) samples from the dataset. Building on this, we show that transfer learning can outperform the baseline in the context of early classification with only 9% of the data after 210 days in the year.","2024-01","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","2","16","","","","","","","","","","English","","","","WOS:001151354700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","crop type mapping; early classification; satellite image time series; Sentinel-2; Slovenia; transfer learning; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5CXHSLQE","journalArticle","2023","Tan, DH; Liang, XH","Multiclass malaria parasite recognition based on transformer models and a generative adversarial network","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-023-44297-y","","Malaria is an extremely infectious disease and a main cause of death worldwide. Microscopic examination of thin slide serves as a common method for the diagnosis of malaria. Meanwhile, the transformer models have gained increasing popularity in many regions, such as computer vision and natural language processing. Transformers also offer lots of advantages in classification task, such as Fine-grained Feature Extraction, Attention Mechanism etc. In this article, we propose to assist the medical professionals by developing an effective framework based on transformer models and a generative adversarial network for multi-class plasmodium classification and malaria diagnosis. The Generative Adversarial Network is employed to generate extended training samples from multiclass cell images, with the aim of enhancing the robustness of the resulting model. We aim to optimize plasmodium classification to achieve an exact balance of high accuracy and low resource consumption. A comprehensive comparison of the transformer models to the state-of-the-art methods proves their efficiency in the classification of malaria parasite through thin blood smear microscopic images. Based on our findings, the Swin Transformer model and MobileVit outperform the baseline architectures in terms of precision, recall, F1-score, specificity, and FPR on test set (the data was divided into train: validation: test splits). It is evident that the Swin Transformer achieves superior detection performance (up to 99.8% accuracy), while MobileViT demonstrates lower memory usage and shorter inference times. High accuracy empowers healthcare professionals to conduct precise diagnoses, while low memory usage and short inference times enable the deployment of predictive models on edge devices with limited computational and memory resources.","2023-10-10","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","1","13","","","","","","","","","","English","","","","WOS:001099084800071","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","MICROSCOPY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8HXCFPDF","journalArticle","2023","Li, YX; Wei, YM; Xu, S; Tan, QX; Zong, LC; Wang, JM; Wang, YX; Chen, JY; Hong, L; Li, Y","AcrNET: predicting anti-CRISPR with deep learning","BIOINFORMATICS","","1367-4803","10.1093/bioinformatics/btad259","","Motivation: As an important group of proteins discovered in phages, anti-CRISPR inhibits the activity of the immune system of bacteria (i.e. CRISPR-Cas), offering promise for gene editing and phage therapy. However, the prediction and discovery of anti-CRISPR are challenging due to their high variability and fast evolution. Existing biological studies rely on known CRISPR and anti-CRISPR pairs, which may not be practical considering the huge number. Computational methods struggle with prediction performance. To address these issues, we propose a novel deep neural network for anti-CRISPR analysis (AcrNET), which achieves significant performance. Results: On both the cross-fold and cross-dataset validation, our method outperforms the state-of-the-art methods. Notably, AcrNET improves the prediction performance by at least 15% regarding the F1 score for the cross-dataset test problem comparing with state-of-art Deep Learning method. Moreover, AcrNET is the first computational method to predict the detailed anti-CRISPR classes, which may help illustrate the anti-CRISPR mechanism. Taking advantage of a Transformer protein language model ESM-1b, which was pre-trained on 250 million protein sequences, AcrNET overcomes the data scarcity problem. Extensive experiments and analysis suggest that the Transformer model feature, evolutionary feature, and local structure feature complement each other, which indicates the critical properties of anti-CRISPR proteins. AlphaFold prediction, further motif analysis, and docking experiments further demonstrate that AcrNET can capture the evolutionarily conserved pattern and the interaction between anti-CRISPR and the target implicitly.","2023-05-04","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","5","39","","","","","","","","","","English","","","","WOS:000987817300006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","DISCOVERY; DOCKING; HDOCK; PROTEIN-PROTEIN; RECOGNITION; RESOURCE; SECONDARY STRUCTURE; WEB SERVER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EP62R7MF","journalArticle","2022","Alshammari, H; Gasmi, K; Ben Ltaifa, I; Krichen, M; Ben Ammar, L; Mahmood, MA","Olive Disease Classification Based on Vision Transformer and CNN Models","COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE","","1687-5265","10.1155/2022/3998193","","It has been noted that disease detection approaches based on deep learning are becoming increasingly important in artificial intelligence-based research in the field of agriculture. Studies conducted in this area are not at the level that is desirable due to the diversity of plant species and the regional characteristics of many of these species. Although numerous researchers have studied diseases on plant leaves, it is undeniable that timely diagnosis of diseases on olive leaves remains a difficult task. It is estimated that people have been cultivating olive trees for 6000 years, making it one of the most useful and profitable fruit trees in history. Symptoms that appear on infected leaves can vary from one plant to another or even between individual leaves on the same plant. Because olive groves are susceptible to a variety of pathogens, including bacterial blight, olive knot, Aculus olearius, and olive peacock spot, it has been difficult to develop an effective olive disease detection algorithm. For this reason, we developed a unique deep ensemble learning strategy that combines the convolutional neural network model with vision transformer model. The goal of this method is to detect and classify diseases that can affect olive leaves. In addition, binary and multiclassification systems based on deep convolutional models were used to categorize olive leaf disease. The results are encouraging and show how effectively CNN and vision transformer models can be used together. Our model outperformed the other models with an accuracy of about 96% for multiclass classification and 97% for binary classification, as shown by the experimental results reported in this study.","2022-07-31","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","2022","","","","","","","","","","English","","","","WOS:000855557500013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;35<br/>Total Times Cited:&nbsp;&nbsp;35<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","ALGORITHM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EVHHTAXN","journalArticle","2025","Schleier, M; Esen, C; Hellmann, R","Vision transformer based cut interruption detection and prediction of laser fusion cutting from monitored melt pool images","JOURNAL OF LASER APPLICATIONS","","1042-346X","10.2351/7.0001611","","Incomplete cuts during laser fusion cutting result in a closed kerf, preventing the workpiece from detaching from the sheet and resulting in rework or rejection. We demonstrate the approach of a vision transformer, used for image classification, to detect cut interruption during laser fusion cutting in steel and aluminum. With events impending an incomplete cut in steel, we attempt to predict cut interruption before they even occur. To build a data set for training, cutting experiments are carried out with a 4 kW fiber laser, forcing incomplete cuts by varying the process parameters such as laser power and feed rate. The thermal radiation from the process zone during the cutting process is captured with a size of 256 x 256 px(2 )at sample rates of 20 x 10(3) fps. The kerf is recorded with a spectral sensitivity between 400 and 700 nm, without external illumination, which enables the melt to be observed in the range of the visual spectrum. The vision transformer model, which is used for image classification, splits the image into patches, linearly embedded with an added position embedding, and fed to a standard transformer encoder. For training the model, a set of images was labeled for the respective classes of a complete, incomplete, and impending incomplete cut. With the trained model, incomplete cuts in steel and aluminum can then be recognized and impending incomplete cuts in steel can be predicted in advance.","2025-02","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","1","37","","","","","","","","","","English","","","","WOS:001416707900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","computer vision; fiber laser cutting; high-speed camera; image classification; machine learning; process monitoring; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EGKS9MEE","journalArticle","2025","Gao, R; Wang, JM; Yu, YH; Wu, J; Zhang, L","Enhanced graph diffusion learning with dynamic transformer for anomaly detection in multivariate time series","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2024.129168","","In recent years, deep learning-based multivariate time series anomaly detection methods have significantly improved detection performance by accurately modeling the spatiotemporal correlations in sensor data. However, they still face the following challenges: the complexity of signals acquired from sensors makes it difficult to capture the true hidden spatial relationships between sensors. Local features and global correlations of time series data are ignored in capturing accurately the temporal correlations of multivariate time series. To address these problems, we propose a G raph D iffusion T ransformed S patiotemporal model(GDTS) for multivariate time series anomaly detection. Specifically, we first extend a newly developed diffusion probability model to spatial correlation modeling of sensors, which results in anew graph diffusion network. During the diffusion process, we design a novel L2 regularized weighted dot product diffusion function with energy constraints to guide information propagation for accurately capturing the hidden spatial dependencies between sensors. Moreover, we develop a variant of the transformer model with a hybrid sampling strategy to capture the local features and global correlations of time series, which comprehensively describes the temporal correlation of time series data. Subsequently, the multivariate time series features are jointly optimized at the spatio-temporal level for prediction. Finally, the threshold method is used to measure the deviation between the actual observed value and the predicted value to accomplish anomaly detection. Extensive experiments on real-world publicly available datasets demonstrate that GDTS significantly outperforms several state-of-the-art methods.","2025-02-28","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","619","","","","","","","","","","English","","","","WOS:001393271900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","Anomaly detection; Graph diffusion; Multivariate time series; NEURAL-NETWORK; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JPI6Z7VB","journalArticle","2024","Liu, YZ; Guo, YB","CL-AP2: A composite learning approach to attack prediction via attack portraying","JOURNAL OF NETWORK AND COMPUTER APPLICATIONS","","1084-8045","10.1016/j.jnca.2024.103963","","The capabilities of accurate prediction of cyberattacks have long been desired as detection methods cannot avoid the damages caused by occurrences of cyberattack. Attack prediction still remains an open issue especially to specify the upcoming steps of an attack with the quickly evolving intelligent techniques at the attackers' side. This study proposes a composite learning approach (namely CL-AP2), 2 ), which fulfills this task in two phases of ""attack portraying""and ""attack prediction"": (1) (Attack Portraying) CL-AP2 2 generates a Temporal Attack Knowledge Graph (TAKG) from real-time system logs providing full knowledge that formulates time- aware entities related to attacks and the relations amongst them; Over the TAKG, a Tactic-based Cyber Kill Chain (TCKC) model highlights the attacker's portrait via evaluation of behaviors in the past, i.e., , presenting the tactical path and attack steps taken by the attacker; (2) (Attack Prediction) The Soft Actor-Critic algorithm applies to identify the most possible attack trajectory confined in the attack portrait; The transformer model finally derives the specific attack technique to be taken next. Experiments have been performed versus the state-of-the-art counterparts over a public dataset and results indicate that: (1) CL-AP2 2 can effectively reveal the tactical path taken by the attacker and form a complete portrait of the attack; and (2) CL-AP2 2 excels in predicting attack techniques to be taken by attackers and providing the defense guidance against the predicted attacks.","2024-10","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","230","","","","","","","","","","English","","","","WOS:001274515300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Attack portraying; Attack prediction; BERT; Cyber security; Knowledge graph; Reinforcement learning; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"789HALZC","journalArticle","2024","Jeong, D; Han, K","PRECYSE: Predicting Cybersickness using Transformer for Multimodal Time-Series Sensor Data","PROCEEDINGS OF THE ACM ON INTERACTIVE MOBILE WEARABLE AND UBIQUITOUS TECHNOLOGIES-IMWUT","","2474-9567","10.1145/3659594","","Cybersickness, a factor that hinders user immersion in VR, has been the subject of ongoing attempts to predict it using AI. Previous studies have used CNN and LSTM for prediction models and used attention mechanisms and XAI for data analysis, yet none explored a transformer that can better reflect the spatial and temporal characteristics of the data, beneficial for enhancing prediction and feature importance analysis. In this paper, we propose cybersickness prediction models using multimodal time-series sensor data (i.e., eye movement, head movement, and physiological signals) based on a transformer algorithm, considering sensor data pre-processing and multimodal data fusion methods. We constructed the MSCVR dataset consisting of normalized sensor data, spectrogram formatted sensor data, and cybersickness levels collected from 45 participants through a user study. We proposed two methods for embedding multimodal time-series sensor data into the transformer: modality-specific spatial and temporal transformer encoders for normalized sensor data (MS-STTN) and modality-specific spatial-temporal transformer encoder for spectrogram (MS-STTS). MS-STTN yielded the highest performance in the ablation study and the comparison of the existing models. Furthermore, by analyzing the importance of data features, we determined their relevance to cybersickness over time, especially the salience of eye movement features. Our results and insights derived from multimodal time-series sensor data and the transformer model provide a comprehensive understanding of cybersickness and its association with sensor data. Our MSCVR dataset and code are publicly available: https://github.com/dayoung- jeong/PRECYSE.git.","2024-05","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","2","8","","","","","","","","","","English","","","","WOS:001229316000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;95</p>","","","Cybersickness; MOTION SICKNESS; Multimodal time-series sensor data; SIGNALS; Transformer; Virtual reality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TRFQGUIN","journalArticle","2024","Marques, A Jr; Silva, LJS; Cagliari, J; Scalco, L; da Silva, LCF; Veronez, MR; Gonzaga, L Jr","A Lithological Classification Model Based on Fourier Neural Operators and Channel-Wise Self-Attention","IEEE GEOSCIENCE AND REMOTE SENSING LETTERS","","1545-598X","10.1109/LGRS.2024.3438547","","Lithological characterization plays a crucial role in geological studies, and outcrops serve as the primary source of geological information. Automatic identification of lithologies enhances geological mapping and reduces costs and risks associated with mapping less accessible outcrops. These outcrops are typically imaged using remote sensing techniques, enabling the identification of geological structures and lithologies through computer vision and machine learning (ML) approaches. In this context, convolutional neural networks (CNNs) have significantly contributed to lithological characterization in outcrop images. Recent advancements include novel architectures based on residual and attention blocks, which improve upon base CNN models. In addition, transformer-based architectures have surpassed CNNs in various tasks. Taking a step further, we propose a novel architecture that incorporates Fourier operators. Our proposed architecture builds upon the Transformer model, utilizing a sequential combination of Fourier neural operators (FNOs) and channelwise self-attention layers. To train our model, we adopt a transfer learning strategy, initially training it on a texture dataset with 47 classes. Subsequently, we fine-tune the same model to classify five specific lithologies in our custom dataset. These lithologies include sandstone, gray and brownish-gray shale, limestone, and laminated limestone images from the Tres Irm & atilde;os quarry within the Araripe Basin-an outcrop analogous to oil exploration reservoirs. The proposed architecture achieved an F1-score of up to 98%, performing better than reference CNN and ResNet models. This advancement holds promise for accurate lithological characterization, benefiting geological research and exploration efforts.","2024","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","21","","","","","","","","","","English","","","","WOS:001329046400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","ARARIPE BASIN; Attention mechanisms; convolutional neural networks (CNNs); deep learning (DL); Fourier transform; geology; image classification; rocks; stratigraphy; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X95ZIES3","journalArticle","2022","Wang, J; Xu, YT; Tian, JH; Li, HY; Jiao, WD; Sun, Y; Li, G","Driving Fatigue Detection with Three Non-Hair-Bearing EEG Channels and Modified Transformer Model","ENTROPY","","1099-4300","10.3390/e24121715","","Driving fatigue is the main cause of traffic accidents, which seriously affects people's life and property safety. Many researchers have applied electroencephalogram (EEG) signals for driving fatigue detection to reduce negative effects. The main challenges are the practicality and accuracy of the EEG-based driving fatigue detection method when it is applied on the real road. In our previous study, we attempted to improve the practicality of fatigue detection based on the proposed non-hair-bearing (NHB) montage with fewer EEG channels, but the recognition accuracy was only 76.47% with the random forest (RF) model. In order to improve the accuracy with NHB montage, this study proposed an improved transformer architecture for one-dimensional feature vector classification based on introducing the Gated Linear Unit (GLU) in the Attention sub-block and Feed-Forward Networks (FFN) sub-block of a transformer, called GLU-Oneformer. Moreover, we constructed an NHB-EEG-based feature set, including the same EEG features (power ratio, approximate entropy, and mutual information (MI)) in our previous study, and the lateralization features of the power ratio and approximate entropy based on the strategy of brain lateralization. The results indicated that our GLU-Oneformer method significantly improved the recognition performance and achieved an accuracy of 86.97%. Our framework demonstrated that the combination of the NHB montage and the proposed GLU-Oneformer model could well support driving fatigue detection.","2022-12","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","12","24","","","","","","","","","","English","","","","WOS:000902687100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","ASYMMETRIES; CLASSIFICATION; driving fatigue detection; electroencephalogram (EEG); GLU-Oneformer; HUMAN BRAIN; lateralization; MENTAL FATIGUE; NETWORK; non-hair-bearing (NHB); RECOGNITION; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F8KDNGA9","journalArticle","2021","Miao, XX; McLoughlin, I; Wang, WC; Zhang, PY","D-MONA: A dilated mixed-order non-local attention network for speaker and language recognition","NEURAL NETWORKS","","0893-6080","10.1016/j.neunet.2021.03.014","","Attention-based convolutional neural network (CNN) models are increasingly being adopted for speaker and language recognition (SR/LR) tasks. These include time, frequency, spatial and channel attention, which can focus on useful time frames, frequency bands, regions or channels while extracting features. However, these traditional attention methods lack the exploration of complex information and multi-scale long-range speech feature interactions, which can benefit SR/LR tasks. To address these issues, this paper firstly proposes mixed-order attention (MOA) for low frame-level speech features to gain the finest grain multi-order information at higher resolution. We then combine that with a non local attention (NLA) mechanism and a dilated residual structure to balance fine grained local detail with convolution from multi-scale long-range time/frequency regions in feature space. The proposed dilated mixed-order non-local attention network (D-MONA) exploits the detail available from the first and the second-order feature attention analysis, but achieves this over a much wider context than purely local attention. Experiments are conducted on three datasets, including two SR tasks of Voxceleb and CN-celeb, and one LR task, NIST LRE 07. For SR, D-MONA improves on ResNet-34 results by at least 29% and 15% for Voxceleb1 and CN-celeb respectively. For the LR task, a large improvement is achieved over ResNet-34 of 21% for the challenging 3s utterance condition, 59% for the 10s condition and 67% for the 30s condition. It also outperforms the state-of-the-art deep bottleneck feature-DNN (DBF-DNN) x-vector system at all scales. (C) 2021 Elsevier Ltd. All rights reserved.","2021-07","2025-02-26 20:43:26","2025-02-26 20:43:26","","201-211","","","139","","","","","","","","","","English","","","","WOS:000652682000003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Dilated network; Mixed-order attention; Non-local attention; Speaker/language recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LWDD5YKR","journalArticle","2021","Lin, Y; Guo, DY; Zhang, JW; Chen, ZM; Yang, B","A Unified Framework for Multilingual Speech Recognition in Air Traffic Control Systems","IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS","","2162-237X","10.1109/TNNLS.2020.3015830","","This work focuses on robust speech recognition in air traffic control (ATC) by designing a novel processing paradigm to integrate multilingual speech recognition into a single framework using three cascaded modules: an acoustic model (AM), a pronunciation model (PM), and a language model (LM). The AM converts ATC speech into phoneme-based text sequences that the PM then translates into a word-based sequence, which is the ultimate goal of this research. The LM corrects both phoneme- and word-based errors in the decoding results. The AM, including the convolutional neural network (CNN) and recurrent neural network (RNN), considers the spatial and temporal dependences of the speech features and is trained by the connectionist temporal classification loss. To cope with radio transmission noise and diversity among speakers, a multiscale CNN architecture is proposed to fit the diverse data distributions and improve the performance. Phoneme-to-word translation is addressed via a proposed machine translation PM with an encoder-decoder architecture. RNN-based LMs are trained to consider the code-switching specificity of the ATC speech by building dependences with common words. We validate the proposed approach using large amounts of real Chinese and English ATC recordings and achieve a 3.95% label error rate on Chinese characters and English words, outperforming other popular approaches. The decoding efficiency is also comparable to that of the end-to-end model, and its generalizability is validated on several open corpora, making it suitable for real-time approaches to further support ATC applications, such as ATC prediction and safety checking.","2021-08","2025-02-26 20:43:26","2025-02-26 20:43:26","","3608-3620","","8","32","","","","","","","","","","English","","","","WOS:000681169500031","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;73<br/>Total Times Cited:&nbsp;&nbsp;81<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","Acoustic model (AM); air traffic control (ATC); Atmospheric modeling; Decoding; DEEP NEURAL-NETWORKS; Hidden Markov models; machine translation pronunciation model (PM); multilingual; multiscale CNN (MCNN); Real-time systems; robust speech recognition; Speech recognition; Task analysis; Vocabulary","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8FZQJGFH","journalArticle","2021","Sivapatham, S; Kar, A; Ramadoss, R","Performance analysis of various training targets for improving speech quality and intelligibility","APPLIED ACOUSTICS","","0003-682X","10.1016/j.apacoust.2020.107817","","Denoising a single-channel speech (recorded using one microphone) remains an open problem in many speech-related applications. Recently, supervised deep learning methods are used to denoise the speech signal. This work uses Deep Neural Network (DNN) to learn the Time-Frequency (T-F) mask of the clean speech from its noisy speech features. In general, Ideal Binary Mask (IBM) is used as the binary mask training target to improve speech intelligibility, and Ideal Ratio Mask (IRM) is used as a non-binary mask training target to improve speech quality. Still, it may not necessarily be the best T-F mask to analyze the performance of improvement in speech quality/intelligibility. However, an appropriate training target remains to be unclear for supervised deep learning methods. In this work, a non-binary novel soft T-F mask named Optimum Soft Mask (OSM) is proposed, analyzed and compared with different T-F mask types used for single-channel speech denoising methods. In addition, the target T-F mask is compared with the existing state of art approaches to show a clear performance advantage of supervised deep learning models. The performance of the binary and non-binary training targets of DNN is evaluated under different Signal-to-Noise-Ratio's and noise conditions ti improve speech quality and intelligibility. The experimental results reveal that the binary mask IBM shows significant improvement in speech intelligibility; the non-binary mask IRM shows a substantial improvement in speech quality. At the same time, the proposed novel soft T-F mask shows notable improvement in both quality and intelligibility under various test conditions. (C) 2020 Elsevier Ltd. All rights reserved.","2021-04","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","175","","","","","","","","","","English","","","","WOS:000613270700026","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","DATABASE; ENHANCEMENT; FEATURES; Ideal Binary Mask; Ideal Ratio Mask; Intelligibility; NEURAL-NETWORKS; NOISE; Optimum Soft Mask; PITCH TRACKING; Quality; RECOGNITION; SEGREGATION; SUPPRESSION; SYSTEM; Training targets","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"49YLIIYR","journalArticle","2024","Feng, N; Zhao, SS; Wang, K; Chen, PZ; Wang, YP; Gao, Y; Wang, ZP; Lu, YD; Chen, C; Yao, JC; Lei, ZK; Xu, D","Deep learning model for diagnosis of thyroid nodules with size less than 1 cm: A multicenter, retrospective study","EUROPEAN JOURNAL OF RADIOLOGY OPEN","","2352-0477","10.1016/j.ejro.2024.100609","","Objective: To develop a ultrasound images based dual-channel deep learning model to achieve accurate early diagnosis of thyroid nodules less than 1 cm.<br /> Methods: A dual-channel deep learning model called thyroid nodule transformer network (TNT-Net) was proposed. The model has two input channels for transverse and longitudinal ultrasound images of thyroid nodules, respectively. A total of 9649 nodules from 8455 patients across five hospitals were retrospectively collected. The data were divided into a training set (8453 nodules, 7369 patients), an internal test set (565 nodules, 512 patients), and an external test set (631 nodules, 574 patients). Results: TNT-Net achieved an area under the curve (AUC) of 0.953 (95 % confidence interval (CI): 0.934, 0.969) on the internal test set and 0.941 (95 % CI: 0.921, 0.957) on the external test set, significantly outperforming traditional deep convolutional neural network models and single-channel swin transformer model, whose AUCs ranged from 0.800 (95 % CI: 0.759, 0.837) to 0.856 (95 % CI: 0.819, 0.881). Furthermore, feature heatmap visualization showed that TNT-Net could extract richer and more energetic malignant nodule patterns.<br /> Conclusion: The proposed TNT-Net model significantly improved the recognition capability for thyroid nodules with size less than 1 cm. This model has the potential to reduce overdiagnosis and overtreatment of such nodules, providing essential support for precise management of thyroid nodules while complementing fine-needle aspiration biopsy.","2024-12","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","13","","","","","","","","","","English","","","","WOS:001350727600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Deep Learning; Early diagnosis; Thyroid nodules; Transformer; Ultrasound image","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D4TYFLY4","journalArticle","2024","Zhao, SY; Ou, K; Gu, XX; Dan, ZM; Zhang, JJ; Wang, YX","A novel transformer-embedded lithium-ion battery model for joint estimation of state-of-charge and state-of-health","RARE METALS","","1001-0521","10.1007/s12598-024-02942-z","","The state-of-charge (SOC) and state-of-health (SOH) of lithium-ion batteries affect their operating performance and safety. The coupled SOC and SOH are difficult to estimate adaptively in multi-temperatures and aging. This paper proposes a novel transformer-embedded lithium-ion battery model for joint estimation of state-of-charge and state-of-health. The battery model is formulated across temperatures and aging, which provides accurate feedback for unscented Kalman filter-based SOC estimation and aging information. The open-circuit voltages (OCVs) are corrected globally by the temporal convolutional network with accurate OCVs in time-sliding windows. Arrhenius equation is combined with estimated SOH for temperature-aging migration. A novel transformer model is introduced, which integrates multiscale attention with the transformer's encoder to incorporate SOC-voltage differential derived from battery model. This model simultaneously extracts local aging information from various sequences and aging channels using a self-attention and depth-separate convolution. By leveraging multi-head attention, the model establishes information dependency relationships across different aging levels, enabling rapid and precise SOH estimation. Specifically, the root mean square error for SOC and SOH under conditions of 15 degrees C dynamic stress test and 25 degrees C constant current cycling was less than 0.9% and 0.8%, respectively. Notably, the proposed method exhibits excellent adaptability to varying temperature and aging conditions, accurately estimating SOC and SOH.","2024-11","2025-02-26 20:43:26","2025-02-26 20:43:26","","5637-5651","","11","43","","","","","","","","","","English","","","","WOS:001290123100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Aging migration; CO-ESTIMATION; Global correction; Multiscale attention; State-of-charge (SOC); State-of-health (SOH); Temperature; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6DLM3PXL","journalArticle","2024","Chen, HY; Yang, GY; Zhang, HY","Hider: A Hyperspectral Image Denoising Transformer With Spatial-Spectral Constraints for Hybrid Noise Removal","IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS","","2162-237X","10.1109/TNNLS.2022.3215751","","Hyperspectral image (HSI) qualities are limited by a mixture of Gaussian noise, impulse noise, stripes, and deadlines during the sensor imaging process, resulting in weak application performance. To enhance HSI qualities, methods based on convolutional neural networks have been successively applied to restore clean data from the observed data. However, the architecture of these methods lacks spectral and spatial constraints, and the convolution operators have limited receptive fields and inflexible model inferences. Thus, in this study, we propose an efficient end-to-end transformer, named HSI denoising transformer (Hider), for mixed HSI noise removal. First, a U-shaped 3-D transformer architecture is built for multiscale feature aggregation. Second, a multihead global spectral attention module within the spectral transformer block is designed to excavate information in different spectral patterns. Finally, an additional locally enhanced cross-spatial attention module within the spatial-spectral transformer block is constructed to build the long-range spatial relationship to avoid the high computational complexity of global spatial self-attention. Through the imposition of global correlations along spectrum and spatial self-similarity constraints on the transformer, our proposed Hider aims to capture long-range spatial contextual information and cluster objects with the same spectral pattern for HSI denoising. To verify the effectiveness and efficiency of Hider, we conducted extensive simulated and real experiments. The denoising results on both simulated and real-world datasets show that Hider achieves superior evaluation metrics and visual assessments compared with other state-of-the-art methods.","2024-07","2025-02-26 20:43:26","2025-02-26 20:43:26","","8797-8811","","7","35","","","","","","","","","","English","","","","WOS:001271419000075","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;22<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;107</p>","","","Global correlation along spectrum (GCS); hyperspectral image (HSI) denoising; multiscale features; REPRESENTATION; SPARSE; spatial self-similarity; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"38F2JXHD","journalArticle","2024","Sun, YZ; Pang, SC; Zhang, YA","Enhancing fluid identification via an innovative transformer model with bidirectional recurrent units network leveraging well logging data","PHYSICS OF FLUIDS","","1070-6631","10.1063/5.0206645","","In oil and gas exploration, accurate fluid prediction is crucial for strategic decisions. Our study introduces the BiGRU-Transformer, a deep learning model merging bidirectional gated recurrent units (BiGRUs) with the Transformer. The BiGRU interprets well logging data in a bidirectional manner, ensuring a comprehensive understanding of temporal factors at different depths and time intervals, enhancing fluid prediction precision. The model's sensitivity to local temporal dynamics is heightened by its recurrent neural network structure and gating mechanisms. This feature is particularly beneficial in identifying essential details during brief geological occurrences and minor temporal shifts. The bidirectional approach of the model is tailored to accommodate geological variations across assorted depths and timelines, thus boosting its capability to adapt to diverse geological formations. In the Transformer, the self-attention mechanism dynamically adjusts information importance in geological sequences, enabling flexible handling of diverse relationships and a deeper understanding of intricate structures. Primary data come from key well log curves, providing essential features for analysis. Fed into the BiGRU-Transformer, it links fluid attributes with logging parameters. Benchmarking against state-of-the-art models shows our BiGRU-Transformer's superior accuracy and impressive generalization in fluid prediction across various scenarios. This innovation marks a significant advancement in machine learning for well logging, offering a precise tool for geologists and engineers, enhancing exploration and development quality. The BiGRU-Transformer highlights the transformative impact of advanced machine learning in geosciences, paving the way for novel approaches in oil and gas resource exploration and utilization.","2024-07","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","7","36","","","","","","","","","","English","","","","WOS:001281716500006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","LITHOLOGY; PREDICTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QBMDE4WT","journalArticle","2024","Pitz, E; Pochiraju, K","paper A neural network transformer model for composite microstructure","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2024.108622","","Heterogeneity and uncertainty in a composite microstructure lead to either computational bottlenecks if modeled rigorously or to solution inaccuracies in the stress field and failure predictions if approximated. Although methods suitable for analyzing arbitrary and non-linear microstructures exist, their computational cost makes them impractical to use in large-scale structural analysis. Surrogate models or Reduced Order Models (ROMs) commonly enhance efficiencies but are typically calibrated with a single microstructure. Homogenization methods, such as the Mori-Tanaka method, offer rapid homogenization for a wide range of constituent properties. However, simplifying assumptions, like stress and strain averaging in phases, render the consideration of both deterministic and stochastic variations in microstructure infeasible. This paper illustrates a transformer neural network architecture that captures the knowledge of various microstructures and constituents, enabling it to function as a computationally efficient homogenization surrogate model. Given an image or an abstraction of an arbitrary composite microstructure of linearly elastic fibers in an elastoplastic matrix, the transformer network predicts the history -dependent, non-linear, and homogenized stress-strain response. Two methods for encoding microstructure features were tested: calculating two -point statistics using Principal Component Analysis (PCA) for dimensionality reduction and employing an autoencoder with a Convolutional Neural Network (CNN). Both methods accurately predict the homogenized material response. The developed transformer neural network offers an efficient means for microstructure -to -property translation, generalizable and extendable to a variety of microstructures. The paper describes the network architecture, training and testing data generation, and performance under cycling and random loadings.","2024-08","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","134","","","","","","","","","","English","","","","WOS:001246777800004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","FRAMEWORK; History-dependence; HOMOGENIZATION; Microstructure encoding; Microstructure homogenization; Surrogate model; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"95T588ZY","journalArticle","2024","Kim, M; Kwak, BI; Hou, JU; Kim, T","Robust Long-Term Vehicle Trajectory Prediction Using Link Projection and a Situation-Aware Transformer","SENSORS","","1424-8220","10.3390/s24082398","","The trajectory prediction of a vehicle emerges as a pivotal component in Intelligent Transportation Systems. On urban roads where external factors such as intersections and traffic control devices significantly affect driving patterns along with the driver's intrinsic habits, the prediction task becomes much more challenging. Furthermore, long-term forecasting of trajectories accumulates prediction errors, leading to substantially inaccurate predictions that may deviate from the actual road. As a solution to these challenges, we propose a long-term vehicle trajectory prediction method that is robust to error accumulation and prevents off-road predictions. In this study, the Transformer model is utilized to analyze and forecast vehicle trajectories. In addition, we propose an extra encoding network to precisely capture the effect of the external factors on the driving pattern by producing an abstract representation of the situation nearby the driver. To avoid off-road predictions, we propose a post-processing method, called link projection, which projects predictions onto the road geometry. Moreover, to overcome the limitations of Euclidean distance-based evaluation metrics in evaluating the accuracy of the entire trajectory, we propose a new metric called area-between-curves (ABC). It measures the similarity between two trajectories, and thus the accordance between the two can be effectively evaluated. Extensive evaluations are conducted using real-world datasets against widely-used methods to demonstrate the effectiveness of the proposed approach. The results show that the proposed approach outperforms the conventional deep learning models by up to 65.74% (RMSE), 60.13% (MAE) and 91.45% (ABC).","2024-04","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","8","24","","","","","","","","","","English","","","","WOS:001209957100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","deep learning; intelligent transport system; predictive model; situation-aware transformer; trajectory prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5HDBNSSM","journalArticle","2024","Mehra, S; Ranga, V; Agarwal, R; Susan, S","Speaker independent recognition of low-resourced multilingual Arabic spoken words through hybrid fusion","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-024-18804-w","","This article introduces a supervised strategy designed to enhance spoken word recognition within the constraints of a resource-limited multilingual dataset, specifically focusing on the Arabic language. Notably, existing methodologies often neglect the critical influence of morphology and phonology on the comprehension of spoken language. The Multilingual Spoken Words Corpus comprises audio files in the OPUS format. Our approach strategically employs the pre-trained Arabic Large xlsr-Wav2Vec2-53 transformer model to extract text transcripts, unfolding in two distinct forms: Buckwalter transliterations and Arabic scripts. For Buckwalter transliterations form of text transcripts, we adopt the CMU pronouncing dictionary for phonetic representation. Specifically, a specialized Arabic-based grapheme-2-phoneme model is utilized to convert Buckwalter transliterations into phonemes. Subsequently, these phonemes are transformed into vectors through the application of FastText's character n-gram-based subword embeddings. Shifting focus to the Arabic script form, a stemming process is applied, followed by further conversion into unigrams. Once again, FastText word embeddings are harnessed to represent these unigrams as vectors. To maintain uniformity, vectors are concatenated and padded across both scenarios. For classification, a three-layered dense model, augmented by batch normalization, processes the accumulated vectors, ultimately generating probabilistic scores. The final outcomes are obtained by averaging results from both forms. Comparative evaluation against the state-of-the-art (SOTA) approach substantiates the accuracy of this methodology. Crucially, our method demonstrates promising results, indicating its potential to significantly advance spoken word recognition in complex multilingual contexts.","2024-03-14","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","","","","","","","","","","","English","","","","WOS:001183193800012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","DEEP NEURAL-NETWORK; Hybrid fusion; Morphology; Multilingual spoken words; Phonology; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2CLCP9VG","journalArticle","2024","Tong, SG; Yang, Q; Tong, ZM; Wang, HD; Chen, X","PREDICTION OF PARAMETERS OF BOILER SUPERHEATER BASED ON TRANSFER LEARNING METHOD","HEAT TRANSFER RESEARCH","","1064-2285","","","The superheater in the boiler is the key of equipment connecting high -temperature steam to the turbine for power generation. At present, the problems of large variable fluctuations, strong timing coupling, and multi -power plant data utilization prevent the temperature, flow, and pressure prediction of the boiler superheater. In this paper, a method for predicting the parameters of boiler superheater based on a transfer learning model is proposed, which realizes the joint utilization of data from multiple power plants. The method first collects data from a waste incineration boiler power plant for pre -training the long short-term memory (LSTM)-transformer model, and then completes the transfer learning training on the new power plant. The proposed method has the advantages of high prediction accuracy, good robustness, and more reliable location prediction with drastic changes. The predictions on the test set are within +/- 5% of the experimental value. Compared with the model not trained by the transfer learning, the proposed method achieves the lowest relative errors for all prediction intervals in the 3-15 min range. Compared to the linear regression (LR), support vector regression (SVR), and random forest (RF), the proposed method improves the average absolute percentage error (MAPE) by 30%, 13%, and 20%, respectively. Flatter loss sharpness value and better robust performance obtained from the transfer learning method is verified by an experimental verification. Finally, a digital system design for power plants with real-time data visualization monitoring, parameter prediction, and fault warning functions are implemented.","2024","2025-02-26 20:43:26","2025-02-26 20:43:26","","39-54","","12","55","","","","","","","","","","English","","","","WOS:001235970400003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","AIR; boiler superheater; EMISSIONS; energy; heat transfer; HEAT-TRANSFER; long short-term memory network; machine learning; NEURAL-NETWORK; NOX; OPTIMIZATION; TEMPERATURE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6VQM5D6W","journalArticle","2025","Zeng, YY; Jia, XN; Li, HY; Zhou, N; Liang, XM; Liu, KZ; Yang, BZ; Xiang, B","Oral microbiota among treatment-naïve adolescents with depression: A case-control study","JOURNAL OF AFFECTIVE DISORDERS","","0165-0327","10.1016/j.jad.2025.01.089","","Background: Adolescent depression has profound impacts on physical, cognitive, and emotional development. While gut microbiota changes have been linked to depression, the relationship between oral microbiota and depression remains elusive. Our study aims to investigate the oral microbiota in treatment-na & iuml;ve adolescents experiencing depression and examine their potential associations with cognitive function. Methods: Our case-control study comprised two groups of adolescents aged 12-17: the depression group, including treatment-na & iuml;ve individuals diagnosed with DSM-5 major depressive disorder (MDD), and a healthy control group of non-depressed individuals (HC). Participants underwent structured neuropsychiatric assessments, and fasting morning saliva samples were collected for the 16S rRNA sequencing to investigate the oral microbiota. Results: Significant differences were identified in the alpha- and beta-diversities of the oral microbiota between MDD and HC groups. Specific bacterial taxa, including genera Streptococcus, Neisseria, Hemophilus, Fusobacterium, and g_norank_f_norank_o_Absconditabacteriales_SR1, were significantly associated with MDD. The association extends to cognitive functions, where correlations were observed between certain oral bacteria and cognitive scores, including instant and delayed memory, visual breadth, and speech features for the combined MDD and HC individuals (p < 0.05). Random forest analysis identified ten genera of oral microbes with the highest predictive values for MDD. The area under the curve (AUC) is 0.78 in the receiver operating characteristic (ROC) curve analysis. Conclusion: Our results highlight the oral microbiota's role as a biomarker for adolescent depression and its impact on cognitive functions. These insights underscore the need for further research into the links between oral health, mental health, and cognitive functions.","2025-04-15","2025-02-26 20:43:26","2025-02-26 20:43:26","","93-102","","","375","","","","","","","","","","English","","","","WOS:001411666500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","Adolescents; BRAIN; Cognitive functions; FECAL MICROBIOTA; GUT MICROBIOTA; HEALTH; Major Depressive Disorder; Oral Microbiome; QUESTIONNAIRE; SCALE; STRESS; VALIDATION; VALIDITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZPXB9W4A","journalArticle","2025","Osa-Sanchez, A; Balaha, HM; Mahmoud, A; Sewelam, A; Ghazal, M; Garcia-Zapirain, B; El-Baz, A","Explainable AI-Based Approach for Age-Related Macular Degeneration (AMD) Detection via Fundus Imaging","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3522862","","Age-related macular degeneration (AMD) is a leading cause of vision loss in older people and is characterized by subtle retinal changes that make early identification difficult. Previous studies have demonstrated the efficacy of Vision Transformers (ViTs) in classifying medical images by successfully detecting retinal disorders such as AMD. This paper addresses multiple shortcomings in conventional AMD diagnostic techniques by exploring the detection and explanation of various AMD subtypes from numerical features extracted with a ViT model from fundus images through cascaded artificial intelligence (AI) models using transformers, convolutional neural networks (CNNs), and multilayer perceptrons (MLPs). The data were preprocessed to recognize intricate disease-related patterns. The best test results using the cascade method for each model type show that the MLP model achieved an accuracy of 91.86% (with a sensitivity of 92.22% and a specificity of 95.74%). The Transformer model achieved its highest accuracy of 83.72% (with a sensitivity of 83.86% and a specificity of 89.74%). The CNN model demonstrated the best performance, with an accuracy of 94.19% (with a sensitivity of 93.84% and a specificity of 96.00%). This work helps clinicians interpret AMD cases and supports decision-making revealing hidden features of AMD that are not visible to the human eye. Future research will focus on improving these systems by expanding the databases in aggregate and incorporating multimodal data.","2025","2025-02-26 20:43:26","2025-02-26 20:43:26","","341-360","","","13","","","","","","","","","","English","","","","WOS:001389554800043","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Accuracy; Age-related macular degeneration (AMD); Aging; Artificial intelligence; computer aided diagnosis (CAD); Deep learning; deep learning (DL); eXplainable artificial intelligence (XAI); Feature extraction; Medical diagnostic imaging; Retina; Sensitivity; Solid modeling; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DH8ZCWIC","journalArticle","2024","Yi, MH; Kwak, KC; Shin, JH","KoHMT: A Multimodal Emotion Recognition Model Integrating KoELECTRA, HuBERT with Multimodal Transformer","ELECTRONICS","","2079-9292","10.3390/electronics13234674","","With the advancement of human-computer interaction, the role of emotion recognition has become increasingly significant. Emotion recognition technology provides practical benefits across various industries, including user experience enhancement, education, and organizational productivity. For instance, in educational settings, it enables real-time understanding of students' emotional states, facilitating tailored feedback. In workplaces, monitoring employees' emotions can contribute to improved job performance and satisfaction. Recently, emotion recognition has also gained attention in media applications such as automated movie dubbing, where it enhances the naturalness of dubbed performances by synchronizing emotional expression in both audio and visuals. Consequently, multimodal emotion recognition research, which integrates text, speech, and video data, has gained momentum in diverse fields. In this study, we propose an emotion recognition approach that combines text and speech data, specifically incorporating the characteristics of the Korean language. For text data, we utilize KoELECTRA to generate embeddings, and for speech data, we extract features using HuBERT embeddings. The proposed multimodal transformer model processes text and speech data independently, subsequently learning interactions between the two modalities through a Cross-Modal Attention mechanism. This approach effectively combines complementary information from text and speech, enhancing the accuracy of emotion recognition. Our experimental results demonstrate that the proposed model surpasses single-modality models, achieving a high accuracy of 77.01% and an F1-Score of 0.7703 in emotion classification. This study contributes to the advancement of emotion recognition technology by integrating diverse language and modality data, suggesting the potential for further improvements through the inclusion of additional modalities in future work.","2024-12","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","23","13","","","","","","","","","","English","","","","WOS:001377760000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","cross modal attention; HuBERT; KoELECTRA; multimodal transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P3XHFT28","journalArticle","2024","Kang, J; Yang, CS; Yi, J; Lee, Y","Detection of Marine Oil Spill from PlanetScope Images Using CNN and Transformer Models","JOURNAL OF MARINE SCIENCE AND ENGINEERING","","2077-1312","10.3390/jmse12112095","","The contamination of marine ecosystems by oil spills poses a significant threat to the marine environment, necessitating the prompt and effective implementation of measures to mitigate the associated damage. Satellites offer a spatial and temporal advantage over aircraft and unmanned aerial vehicles (UAVs) in oil spill detection due to their wide-area monitoring capabilities. While oil spill detection has traditionally relied on synthetic aperture radar (SAR) images, the combined use of optical satellite sensors alongside SAR can significantly enhance monitoring capabilities, providing improved spatial and temporal coverage. The advent of deep learning methodologies, particularly convolutional neural networks (CNNs) and Transformer models, has generated considerable interest in their potential for oil spill detection. In this study, we conducted a comprehensive and objective comparison to evaluate the suitability of CNN and Transformer models for marine oil spill detection. High-resolution optical satellite images were used to optimize DeepLabV3+, a widely utilized CNN model; Swin-UPerNet, a representative Transformer model; and Mask2Former, which employs a Transformer-based architecture for both encoding and decoding. The results of cross-validation demonstrate a mean Intersection over Union (mIoU) of 0.740, 0.840 and 0.804 for all the models, respectively, indicating their potential for detecting oil spills in the ocean. Additionally, we performed a histogram analysis on the predicted oil spill pixels, which allowed us to classify the types of oil. These findings highlight the considerable promise of the Swin Transformer models for oil spill detection in the context of future marine disaster monitoring.","2024-11","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","11","12","","","","","","","","","","English","","","","WOS:001365301000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","CNN; deep learning; oil spill detection; optical satellite image; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4STVTEL5","journalArticle","2025","Cao, Q; Cheng, X","A hybrid feature fusion deep learning framework for multi-source medical image analysis","INFORMATION PROCESSING & MANAGEMENT","","0306-4573","10.1016/j.ipm.2024.103934","","Despite the widespread adoption of deep learning to enhance image classification, significant obstacles remain. First, multisource data with diverse sizes and formats is a great challenge for most current deep learning models. Second, lacking manual labeled data for model training limits the application of deep learning. Third, the widely used CNN-based methods shows their limitations in extracting global features and yield poor performance for image topology. To address these issues, we propose a Hybrid Feature Fusion Deep Learning (HFFDL) framework for image classification. This framework consists of an automated image segmentation module, a two- stream backbone module, and a classification module. The automatic image segmentation module utilizes the U-Net model and transfer learning to detect region of interest (ROI) in multisource images; the two-stream backbone module integrates the Swin Transformer architecture with the Inception CNN, with the aim of simultaneous extracting local and global features for efficient representation learning. We evaluate the performance of HFFDL framework with two publicly available image datasets: one for identifying COVID-19 through X-ray scans of the chest (30,386 images), and another for multiclass skin cancer screening using dermoscopy images (25,331 images). The HFFDL framework exhibited greater performance in comparison to many cutting-edge models, achieving the AUC score 0.9835 and 0.8789, respectively. Furthermore, a practical application study conducted in a hospital, identifying viable embryos using medical images, revealed the HFFDL framework outperformed embryologists.","2025-01","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","1","62","","","","","","","","","","English","","","","WOS:001340098100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;106</p>","","","ARTIFICIAL-INTELLIGENCE; CANCER; CLASSIFICATION; Deep learning; Image classification; Inception CNN; MODEL; NEURAL-NETWORK; SEGMENTATION; TIME-LAPSE; Transformer model; U-Net","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P46MDVCL","journalArticle","2024","Urdaneta, C; Jeong, C; Wu, XQ; Chen, JF","Deep Learning Method for Improving Rate of Penetration Prediction in Drilling","SPE JOURNAL","","1086-055X","","","The urgent global need to reduce CO2 emissions necessitates the development of sustainable power generation sources. Geothermal power emerges as a renewable and dependable energy option, harnessing the Earth's natural heat sources for electricity generation. Unlike other renewables, geothermal energy offers uninterrupted power, immune to weather conditions. However, its efficiency hinges on technological innovation, particularly in the challenging realm of geothermal drilling. Rate of penetration (ROP) is a crucial drilling performance metric, and this study explores how deep learning models, particularly transformers, can optimize ROP prediction. Leveraging data from Utah Frontier Observatory for Research in Geothermal Energy (FORGE), we analyze the relationship between drilling parameters and ROP. Traditional drilling optimization methods face limitations, as drilling dysfunctions can disrupt the linear relationship between ROP and weight on bit (WOB). We propose a dynamic approach that allows adapting drilling parameters in real time to optimize ROP. Our experiments investigate optimal sampling intervals and forecast horizons for ROP prediction. We find that a 60- second sampling interval maximizes the transformer model's forecasting accuracy. Additionally, we explore retraining to fine- tune models for specific wells, improving forecasting performance. Our transformer- based ROP forecaster outperforms deep learning models, achieving a low overall 5.22% symmetrical mean average percentage error (SMAPE) over a forecast horizon of 10 minutes. This model offers opportunities for cost- effective drilling optimization, with real- time accuracy, speed, and scalability. Future work will focus on larger data sets and integration with drilling automation systems to further enhance the model's practicality and effectiveness in the field.","2024-07","2025-02-26 20:43:26","2025-02-26 20:43:26","","3440-3448","","7","29","","","","","","","","","","English","","","","WOS:001275054000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;16</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EJ6B9G2R","journalArticle","2024","Wu, XQ; Fan, CH; Tang, J; Cheng, YS","Forecast of global ionospheric TEC using an improved transformer model","ADVANCES IN SPACE RESEARCH","","0273-1177","10.1016/j.asr.2024.02.003","","The total electron content (TEC) is a critical parameter of ionosphere morphology. Precise modeling and prediction of the TEC time series can significantly aid the functioning of the Global Navigation Satellite System (GNSS), satellite as well as shortwave communications. An improved Transformer-based TEC prediction model (ITM) is proposed in this study, in response to the high noise characteristics of the temporal data for TEC in the global ionosphere. The ITM model forecasts the global ionospheric TEC data provided by the Center for Orbit Determination in Europe (CODE) for the year 2018. Experimental results indicate that the model obtains an annual average root mean square error of 1.4 TECU, which represents a 6.67 % advancement over the daily forecast product C1PG published by the CODE center. The model also attains an annual average mean absolute error of 1 TECU, representing a 9.09 % improvement over the accuracy of C1PG. The annual average correlation coefficient is 0.98, which indicates a 0.62 % upgrade in C1PG's accuracy. Additionally, the model exhibits a maximum increase of 23.53 % in monthly average root mean square error over C1PG, a maximum increase of 25 % in monthly average mean absolute error, and a maximum increase of 1.55 % in monthly average correlation coefficient. During the more geomagnetically active phases of 2018, the ITM model's forecast accuracy exhibited an overall improvement of 5 % in RMSE, 7.14 % in MAE, and 0.83 % in correlation coefficient R compared to the C1PG product. (c) 2024 COSPAR. Published by Elsevier B.V. All rights reserved.","2024-05-01","2025-02-26 20:43:26","2025-02-26 20:43:26","","4519-4538","","9","73","","","","","","","","","","English","","","","WOS:001221921700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","ARMA; Deep autoencoder; Forecast; Ionosphere; NETWORK; Total electron content; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PGG6UU54","journalArticle","2024","Damseh, R; Hireche, A; Sirpal, P; Belkacem, AN","Multimodal EEG-fNIRS Seizure Pattern Decoding Using Vision Transformer","IEEE OPEN JOURNAL OF THE COMPUTER SOCIETY","","2644-1268","10.1109/OJCS.2024.3500032","","Epilepsy has been analyzed through uni-modality non-invasive brain measurements such as electroencephalogram (EEG) signal, but identifying seizure patterns is more challenging due to the non-stationary nature of the brain activity and various non-brain artifacts. In this article, we leverage a vision transformer model (ViT) to classify three types of seizure patterns based on multimodal EEG and functional near-infrared spectroscopy (fNIRS) recordings. We used spectral encoding techniques to capture temporal and spatial relationships for brain signals as feature map inputs to the transformer architecture. We evaluated model performance using the receiver operating characteristic (ROC) curves and the area under the curve (AUC), demonstrating that multimodal EEG-fNIRS signals improved the classification accuracy of seizure patterns. Our work showed that power spectral density (PSD) features often led to better results than features derived from dynamic mode decomposition (DMD), particularly for seizures with high-frequency oscillations (HFO) and generalized spike-and-wave discharge (GSWD) patterns, with an accuracy of 93.14% and 91.69%, respectively. Low-voltage fast activity (LVFA) seizures achieved consistently high performance in EEG, fNIRS, and multimodal EEG-fNIRS setups. Overall, our findings suggest the effectiveness of using the ViT architecture with multimodal brain data accompanied by appropriate spectral features to classify the neural activity of epileptic seizure patterns.","2024","2025-02-26 20:43:26","2025-02-26 20:43:26","","724-735","","","5","","","","","","","","","","English","","","","WOS:001410821800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Accuracy; Brain modeling; Computer architecture; Electroencephalogram (EEG); Electroencephalography; epilepsy; Epilepsy; EPILEPSY; Functional near-infrared spectroscopy; functional near-infrared spectroscopy (fNIRS); generalized spike-and-wave discharge (GSWD); Hafnium oxide; high-frequency oscillation (HFO); HIGH-FREQUENCY OSCILLATIONS; low-voltage fast activity (LVFA); ONSET; Recording; seizure; Standards; Transformers; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8SSFPXGP","journalArticle","2022","Lu, W; Yang, ZZ; Buehler, MJ","Rapid mechanical property prediction and de novo design of three-dimensional spider webs through graph and GraphPerceiver neural networks","JOURNAL OF APPLIED PHYSICS","","0021-8979","10.1063/5.0097589","","Spider webs feature advanced structural performance due to the evolutionary success of over more than 3 x 10(9) years, including lightweight design and exceptional mechanical properties. Spider webs are appealing for bio-inspired design since web designs serve multiple functions including mechanical protection and prey catching. However, high computational cost and limited quantified web properties render extensive spider web studies challenging in part due to the high structural complexity and randomness of fiber arrangements in 3D webs. Here, we report a computational method to relate spider web graph microstructures to effective mechanical properties, focusing on strength and toughness, and upscaling from the microscopic to the mesoscale level. The new computational framework uses deep neural networks, trained on graph-structured Cyrtophora citricola spider web mechanical data, in order to capture complex cross-scale structural relationships. Three different models are developed and compared. First, two Graph Neural Network (GNN) models, a Graph Convolutional Network, and a Principal Neighborhood Aggregation method. Second, a GraphPerceiver transformer model that is fed similar input data as provided to the GNN approach but within a natural language modeling context using self-attention mechanisms. The GraphPerceiver model can achieve similar performance as the GNN model, offering added flexibility for building deep learning models of diverse hierarchical biological materials. As an application of the model, we propose a computational optimization tool for synthetic web design that is used to generate synthetic, de novo spider web architectures. Finally, multi-objective optimization enables us to discover web structures that meet specific mechanical properties as design objectives. (C) 2022 Author(s).","2022-08-21","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","7","132","","","","","","","","","","English","","","","WOS:000843008200007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KJ9Z53LD","journalArticle","2022","Jiang, Y; Malliaras, P; Chen, B; Kulic, D","Real-time forecasting of exercise-induced fatigue from wearable sensors","COMPUTERS IN BIOLOGY AND MEDICINE","","0010-4825","10.1016/j.compbiomed.2022.105905","","Although a number of studies attempt to classify human fatigue, most models can only identify fatigue after fatigue has already occurred. In this paper, we propose a novel time series approach to forecasting wearable sensor data and associated fatigue progression during exercise. The proposed framework consists of spatiotemporal attention-based Transformer with an auxiliary critic and a fatigue classifier. The Transformer network is used to analyze the person-independent pattern underlying the past kinematic sequence obtained from wearable sensors and generate short term predictions of the human motion. Adversarial training is employed to regularize the Transformer and improve the time series forecasting performance. A fatigue classifier is used to estimate person-independent fatigue levels based on the forecasted wearable sensor data from the Transformer model. The proposed approach is validated with simulated and real squat datasets which were collected from young healthy participants. The proposed network can accurately forecast a time horizon of up to 80 timesteps for motion signal forecasting and fatigue classification. In terms of fatigue prediction, an accuracy of 83% and a Pearson correlation coefficient of 0.92 were achieved on forecasted motion data with unseen participant data. The experimental results show that our model can predict fatigue progression and outperforms other state-of-the-art techniques, achieving 95% correlation compared to 83% for the best performing baseline method. Successfully predicting fatigue progression can help a patient or athlete monitor and adjust their exercise session to prevent overexertion and fatigue-induced injury.","2022-09","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","148","","","","","","","","","","English","","","","WOS:000856081800012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Fatigue prediction; Human motion data analysis; HUMAN MOVEMENT; Inertial Measurement Unit (IMU); Machine learning; MUSCLE FATIGUE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R9MFCYFT","journalArticle","2022","Zhang, Z; Miao, CL; Liu, CA; Tian, Q; Zhou, YS","HA-RoadFormer: Hybrid Attention Transformer with Multi-Branch for Large-Scale High-Resolution Dense Road Segmentation","MATHEMATICS","","2227-7390","10.3390/math10111915","","Road segmentation is one of the essential tasks in remote sensing. Large-scale high-resolution remote sensing images originally have larger pixel sizes than natural images, while the existing models based on Transformer have the high computational cost of square complexity, leading to more extended model training and inference time. Inspired by the long text Transformer model, this paper proposes a novel hybrid attention mechanism to improve the inference speed of the model. By calculating several diagonals and random blocks of the attention matrix, hybrid attention achieves linear time complexity in the token sequence. Using the superposition of adjacent and random attention, hybrid attention introduces the inductive bias similar to convolutional neural networks (CNNs) and retains the ability to acquire long-distance dependence. In addition, the dense road segmentation result of remote sensing image still has the problem of insufficient continuity. However, multiscale feature representation is an effective means in the network based on CNNs. Inspired by this, we propose a multi-scale patch embedding module, which divides images by patches with different scales to obtain coarse-to-fine feature representations. Experiments on the Massachusetts dataset show that the proposed HA-RoadFormer could effectively preserve the integrity of the road segmentation results, achieving a higher Intersection over Union (IoU) 67.36% of road segmentation compared to other state-of-the-art (SOTA) methods. At the same time, the inference speed has also been greatly improved compared with other Transformer based models.","2022-06","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","11","10","","","","","","","","","","English","","","","WOS:000808670000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","dense road segmentation; EXTRACTION; hybrid-attention; multiscale patches; NETWORK; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"933IVW4D","journalArticle","2021","Fiok, K; Karwowski, W; Gutierrez, E; Wilamowski, M","Analysis of sentiment in tweets addressed to a single domain-specific Twitter account: Comparison of model performance and explainability of predictions","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2021.115771","","Many institutions and companies find it valuable to know how people feel about their ventures; hence, scientific research in sentiment analysis has been intensely developed over time. Automated sentiment analysis can be considered as a machine learning (ML) prediction task, with classes representing human affective states. Due to the rapid development of ML and deep learning (DL), improvements in automatic sentiment analysis performance are achieved almost every year. Since 2013, Semantic Evaluation (SemEval) has hosted a worldwide community-acknowledged competition that allows for comparisons of recent innovations. The sentiment analysis tasks focus on assessing sentiment in Twitter posts authored by various publishers and addressing multiple subjects. Our study aimed to compare selected popular and recent natural language processing methods using a new data set of Twitter posts sent to a single Twitter account. For improved comparability of our experiments with SemEval, we adopted their metrics and also deployed our models on data published for SemEval-2017. In addition, we investigated if an unsupervised ML technique applied for the detection of topics in tweets can be leveraged to improve the predictive performance of a selected transformer model. We also demonstrated how a recent explainable artificial intelligence technique can be used in Twitter sentiment analysis to gain a deeper understanding of the models' predictions. Our results show that the most recent DL language modeling approach provides the highest quality; however, this quality comes at reduced model transparency.","2021-12-30","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","186","","","","","","","","","","English","","","","WOS:000701874800007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;21<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","Deep learning; Explainability; Machine learning; Natural language processing; Sentiment analysis; Twitter","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F6EN86AV","journalArticle","2023","Agarwal, P; Kumar, S","EEG-based imagined words classification using Hilbert transform and deep networks","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-023-15664-8","","The completely paralyzed and quadriplegic patients cannot communicate with others. However, the imagined thoughts of these patients can be used to drive assistive devices by brain-computer interfacing (BCI), the success of which relies on better classification accuracies. In this paper, we have performed an experiment for the classification of imagined words, which can provide an alternative neural path of speech communication for deprived people. A 32-channel industry-standard physiological signal system is used to measure imagined electroencephalogram (EEG) signals of five words (sos, stop, medicine, washroom, comehere) from 13 subjects. We have used the Hilbert transform to calculate time and joint time-frequency features from the imagined EEG signals. The above features are extracted individually in electrodes corresponding to nine brain regions. Each region of the brain is further analyzed in seven EEG frequency bands. The imagined speech features from each of the 63 combinations of brain region and frequency band are classified by the proposed deep architectures like long short term memory (LSTM), gated recurrent unit, and convolutional neural network (CNN). Some combinations are also classified by six traditional machine learning classifiers for performance comparison. In a five-class classification framework, we achieved the average and maximum accuracy of 71.75% and 94.29%. CNN gave high accuracy, but LSTM gave less network prediction time. Our results show that the alpha band can classify imagined speech better than other frequency bands. We have implemented subject-independent BCI, and the results are better than the state-of-the-art methods present in the literature.","2023-05-10","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","","","","","","","","","","","English","","","","WOS:000985378600006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Brain-computer interface; Convolutional neural network; COVERT SPEECH; Electroencephalography; EMPIRICAL MODE DECOMPOSITION; Hilbert transform; Imagined speech classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VXRIPNRR","journalArticle","2025","Esen, AT; Mete, AL; Çapraz, N; Stenstad, AE","Discrimination of Speech Content in Unipolar Depression and Bipolar Mania: A Computer-Based Analysis with ""General Inquirer""","TURK PSIKIYATRI DERGISI","","1300-2163","10.5080/u27618","","Objective: Speech disorders in mental illnesses are usually chronic and associated with poorer outcome. Recently, different types of speech features in mental illnesses can be examined by computer technology. The aim of our study is to examine the content of speech in depression and mania and to investigate the themes that differentiate the diagnostic groups. Method: 30 patients diagnosed with depression, 30 patients diagnosed with bipolar disorder manic episode and 30 healthy control were included in the study. All participants were performed with the Structured Clinical Interview for DSM-IV Axis I Disorders. The participants were asked to speak free for ten minutes and then their speech content was analyzed with the ""General Inquirer"" computer program. This program analyzes the participants' use of a total of 4919 words in the Harvard Psychosocial Dictionary, which are categorized in 83 themes on topics related to psychosocial, emotion, behavior, thought, natural and cultural environment. Results: The diagnostic groups were identified by speech content categories with an accuracy rate of 81%. Patients in mania and depression groups were clustered in the same direction in discriminant analysis by the themes of speech content. ''self"" and ''academic"" themes were the most discriminative categories between the patient and control groups. Conclusion: The content of speech in mania and depression is different from individuals without mental disorders and that computer-assisted analysis tools can distinguish diagnostic groups from each other and from healthy group. Future studies in which structural, vocal and content features of speech are evaluated together and used more advanced computer technologies will contribute to the literature.","2025-01-13","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","","","","","","","","","","","English","","","","WOS:001398215700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Bipolar Disorder; Depression; DISORDER; General Inquirer; Language; LINGUISTIC ANALYSIS; Linguistics; RATING-SCALE; RELIABILITY; SCHIZOPHRENIA; Speech; VALIDITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XXVLKG93","journalArticle","2023","Wang, YA; Chen, AB; Li, HC; Zhou, GX; Yi, JZ; Zhang, ZQ","A hierarchical birdsong feature extraction architecture combining static and dynamic modeling","ECOLOGICAL INDICATORS","","1470-160X","10.1016/j.ecolind.2023.110258","","To conserve bird biodiversity and monitor the distribution of species in the region, it is of tremendous necessity to identify birds by their songs and explore the rich ecological information birdsong contains. The audios recorded in the monitoring area generally have complex background noise, the characteristics of the song are not prominent and the biological spectrum information is not comprehensive, which brings some challenges to the identification of birds. This study proposes a hierarchical birdsong feature extraction architecture combining dynamic and static modeling to cope with complex environments as a modeling context. Firstly, six common speech features were extracted for the characteristics of birdsong. The Pearson correlation coefficient is then used to analyze the correlations between birdsong and human speech, examining the correlations between each feature in the presence and absence of environmental noise interference. Combined with the scatter plot matrix analysis, we conclude that Mel Frequency Cepstral Coefficient (MFCC) is more suitable comparing with other features when dealing with birdsong and can superiorly cope with a complex background noise. Secondly, a feature extraction architecture is built, which integrates static and dynamic modeling to fully explore the contextual relationship, to solve the problem of ignoring the internal structure information of the patch and losing some spatial information in the Transformer-type model. Finally, a hierarchical refinement module is designed to help extract more detailed features, as well as to optimize the computational cost of the Transformer -type model that requires many training data and has high complexity. The performance of the model can be detected with 93.67 % accuracy on the self-built birdsong dataset, 95.19 % accuracy on the public birdsong dataset Birdsdata and 97.02 % accuracy on the public environmental dataset UrbanSound8k.","2023-06","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","150","","","","","","","","","","English","","","","WOS:000984010100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Birdsong classification; Complex background noise; Context modeling; Hierarchical refinement model; Pearson correlation coefficient; Self-built dataset","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9ZFNIBHX","journalArticle","2022","Xing, YJ; Liu, ZY; Li, G; Ding, ZJ; Hu, B","2-level hierarchical depression recognition method based on task-stimulated and integrated speech features","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2021.103287","","Depression had been paid more and more attention by researchers because of its high prevalence, recurrence, disability and mortality. Speech depression recognition had become a research hotspot due to its advantages of non-invasiveness and easy access to data. However, the problems such as the speech variation in different emotional stimulus, gender impact, the speaker and channel variation and the variable length of frame feature, would have a great impact on recognition performance. In order to solve these problems, a novel 2-level hierarchical depression recognition method was proposed in this paper. It contained two stages. In 1st-level classification stage, i-vectors were extracted based on spectral features, prosodic features, formants and voice quality of speech segments in different task stimulus respectively. Then, support vector machine (SVM) and random forest (RF) were used to obtain primary results. In the stage of 2nd-level classification, the results of tasks with significant accuracy differences were aggregated into new integrated features. The final result was achieved on new features by SVM. Our experiments were based on the depression speech database of the Gansu Provincial Key Laboratory of Wearable Computing. The experimental results showed that the proposed method had achieved good results in both gender-independent and gender-dependent experiments. Compared with baseline method and bagging classification, the highest accuracy of our method was raised by 9.62% and 9.49% respectively in gender-independent experiments, and F1 score also got improvement obviously. The results also showed that our method had better robustness on gender effect.","2022-02","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","72","","","","","","","","","","English","","","","WOS:000718844500005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Bagging classification; Depression recognition; EMOTIONS; GENDER; Hierarchical classification; I-vector; MODEL; SEVERITY; Speech task stimulus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VQSUTDSY","journalArticle","2024","Osman, N; Camporese, G; Ballan, L","Multi-modal transformer with language modality distillation for early pedestrian action anticipation","COMPUTER VISION AND IMAGE UNDERSTANDING","","1077-3142","10.1016/j.cviu.2024.104144","","Language-vision integration has become an increasingly popular research direction within the computer vision field. In recent years, there has been a growing recognition of the importance of incorporating linguistic information into visual tasks, particularly in domains such as action anticipation. This integration allows anticipation models to leverage textual descriptions to gain deeper contextual understanding, leading to more accurate predictions. In this work, we focus on pedestrian action anticipation, where the objective is the early prediction of pedestrians' future actions in urban environments. Our method relies on a multi-modal transformer model that encodes past observations and produces predictions at different anticipation times, employing a learned mask technique to filter out redundancy in the observed frames. Instead of relying solely on visual cues extracted from images or videos, we explore the impact of integrating textual information in enriching the input modalities of our pedestrian action anticipation model. We investigate various techniques for generating descriptive captions corresponding to input images, aiming to enhance the anticipation performance. Evaluation results on available public benchmarks demonstrate the effectiveness of our method in improving the prediction performance at different anticipation times compared to previous works. Additionally, incorporating the language modality in our anticipation model proved significant improvement, reaching a 29.5% increase in the F1 score at 1-second anticipation and a 16.66% increase at 4-second anticipation. These results underscore the potential of language-vision integration in advancing pedestrian action anticipation in complex urban environments.","2024-12","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","249","","","","","","","","","","English","","","","WOS:001318164000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Action anticipation; Image-to-video captioning; Language-vision models; Multi-modal transformers; Pedestrian intent prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4Q2G3JND","journalArticle","2024","Gurrala, A; Arora, K; Sharma, H; Qamar, S; Roy, A; Chakraborty, S","Classification of High-Resolution Chest CT Scan Images Using Adaptive Fourier Neural Operators for COVID-19 Diagnosis","COVID","","2673-8112","10.3390/covid4080088","","In the pursuit of advancing COVID-19 diagnosis through imaging, this paper introduces a novel approach utilizing adaptive Fourier neural operators (AFNO) for the analysis of high-resolution computed tomography (HRCT) chest images. The study population comprised 395 patients with 181,106 labeled high-resolution COVID-19 CT images from the HRCTCov19 dataset, categorized into four classes: ground glass opacity (GGO), crazy paving, air space consolidation, and negative for COVID-19. The methods included image preprocessing, involving resizing and normalization, followed by the application of the AFNO model, which enables efficient token mixing in the Fourier domain independent of input resolution. The model was trained using the Adam optimizer with a learning rate of 1 x 10(-4) and evaluated using metrics such as accuracy, precision, recall, and F1 score. The results demonstrate AFNO's superior performance in few-shot segmentation tasks over traditional self-attention mechanisms, achieving an overall accuracy of 94%. Specifically, the model showed high precision and recall for the GGO and negative classes, indicating its robustness and effectiveness. This research has significant implications for the development of AI-powered diagnostic tools, particularly in environments with limited access to high-quality imaging data and those where computational efficiency is critical. Our findings suggest that AFNO could serve as a powerful model for analyzing HRCT images, potentially leading to improved diagnosis and understanding of COVID-19, representing a critical step in combating the pandemic.","2024-08","2025-02-26 20:43:26","2025-02-26 20:43:26","","1236-1244","","8","4","","","","","","","","","","English","","","","WOS:001305056700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","chest image; computed tomography; COVID-19; CT scan; Fourier transform; token mixers; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5KS67HQI","journalArticle","2024","Lu, DN; Schwartz, S; Xu, LL; Shafiee, MJ; Vinson, NG; Czarnecki, KJ; Wong, ALXD","Integrating deep transformer and temporal convolutional networks for SMEs revenue and employment growth prediction","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.124129","","Although the accurate potential for growth prediction is very important for Government grants and contributions programs to better support Small and Medium-sized Enterprises (SMEs), it is a challenging task due to the data heterogeneity (both structured data and free text data bilingual in English and French), the class imbalance issue, and the difficulties in efficient feature learning. To address these challenges, this paper presents a novel BERT-TCN model for portfolio predictions in government funding programs, with the following key contributions. First, we describe the application of a novel architecture to a prediction task involving sequential, structured, partially quantitative input data and free text input data. Specifically, our novel model predicts the growth of firms receiving government funding for innovation. Our model also deals with class imbalance in the data and the difficulties in efficient feature learning. Our model integrates a Transformer model, i.e., BERT, for text modeling with a Temporal Convolutional Network (TCN) for sequential prediction. Second, we also developed various performance evaluation criteria in Section 4.3, allowing comprehensive assessments of the proposed approach from both the machine learning perspective and funding program -specific perspective. Third, the importance of features (both text and numerical features) is quantified and evaluated, allowing insights into how different features contribute to the prediction and explainability of the proposed model. The proposed approach is trained and tested on a large dataset from a rich database, demonstrating that the proposed approach can greatly help individual human experts improve their results.","2024-10-15","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","252","","","","","","","","","","English","","","","WOS:001239382800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","BERT; Feature importance evaluation; Heterogeneous data modeling; Revenue growth prediction; Temporal convolutional network; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M9C8UTDR","journalArticle","2024","Yu, SQ; Wang, YT; Chen, LL; Zhang, XL; Li, JM","3D hand pose and mesh estimation via a generic Topology-aware Transformer model","FRONTIERS IN NEUROROBOTICS","","1662-5218","10.3389/fnbot.2024.1395652","","In Human-Robot Interaction (HRI), accurate 3D hand pose and mesh estimation hold critical importance. However, inferring reasonable and accurate poses in severe self-occlusion and high self-similarity remains an inherent challenge. In order to alleviate the ambiguity caused by invisible and similar joints during HRI, we propose a new Topology-aware Transformer network named HandGCNFormer with depth image as input, incorporating prior knowledge of hand kinematic topology into the network while modeling long-range contextual information. Specifically, we propose a novel Graphformer decoder with an additional Node-offset Graph Convolutional layer (NoffGConv). The Graphformer decoder optimizes the synergy between the Transformer and GCN, capturing long-range dependencies and local topological connections between joints. On top of that, we replace the standard MLP prediction head with a novel Topology-aware head to better exploit local topological constraints for more reasonable and accurate poses. Our method achieves state-of-the-art 3D hand pose estimation performance on four challenging datasets, including Hands2017, NYU, ICVL, and MSRA. To further demonstrate the effectiveness and scalability of our proposed Graphformer Decoder and Topology aware head, we extend our framework to HandGCNFormer-Mesh for the 3D hand mesh estimation task. The extended framework efficiently integrates a shape regressor with the original Graphformer Decoder and Topology aware head, producing Mano parameters. The results on the HO-3D dataset, which contains various and challenging occlusions, show that our HandGCNFormer-Mesh achieves competitive results compared to previous state-of-the-art 3D hand mesh estimation methods.","2024-05-03","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","18","","","","","","","","","","English","","","","WOS:001225462800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","3D hand mesh estimation; 3D hand pose estimation; GCN; Graphformer; HandGCNFormer; REGRESSION; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"68R4YSSS","journalArticle","2024","Xu, BA; Zhou, YY; Bian, X","Self-supervised learning based on Transformer for flow reconstruction and prediction","PHYSICS OF FLUIDS","","1070-6631","10.1063/5.0188998","","Machine learning has great potential for efficient reconstruction and prediction of flow fields. However, existing datasets may have highly diversified labels for different flow scenarios, which are not applicable for training a model. To this end, we make a first attempt to apply the self-supervised learning (SSL) technique to fluid dynamics, which disregards data labels for pre-training the model. The SSL technique embraces a large amount of data (8000 snapshots) at Reynolds numbers of Re = 200, 300, 400, and 500 without discriminating between them, which improves the generalization of the model. The Transformer model is pre-trained via a specially designed pretext task, where it reconstructs the complete flow fields after randomly masking 20% data points in each snapshot. For the downstream task of flow reconstruction, the pre-trained model is fine-tuned separately with 256 snapshots for each Reynolds number. The fine-tuned models accurately reconstruct the complete flow fields based on less than 5% random data points within a limited window even for Re = 250 and 600, whose data were not seen in the pre-trained phase. For the other downstream task of flow prediction, the pre-training model is fine-tuned separately with 128 consecutive snapshot pairs for each corresponding Reynolds number. The fine-tuned models then correctly predict the evolution of the flow fields over many periods of cycles. We compare all results generated by models trained via SSL and models trained via supervised learning, where the former has unequivocally superior performance. We expect that the methodology presented here will have wider applications in fluid mechanics.","2024-02","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","2","36","","","","","","","","","","English","","","","WOS:001159051800011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","DEEP; NEURAL-NETWORKS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8LU5ZWXT","journalArticle","2024","Wang, ZL; Yuan, YJ; Zhang, SY; Lin, YC; Tan, JR","A multi-state fusion informer integrating transfer learning for metal tube bending early wrinkling prediction","APPLIED SOFT COMPUTING","","1568-4946","10.1016/j.asoc.2023.110991","","Wrinkling is one of the most fatal defects of metal tube bending, which may seriously affect the forming quality and even lead to forming failure. Traditional wrinkling prediction methods fail to provide accurate results due to the complexity of multi -die coupling in the bending process and the neglect of time -varying effects. To this end, a novel early wrinkling prediction method is proposed in this paper, distinct from conventional methods, realizing to forecast future wrinkling trends during the bending process and laying the foundation for real-time wrinkling prediction. It leverages the wrinkling factor (WrF), calculated using the energy method, as temporal data during the bending process to indirectly predict future tube wrinkling trends. Since the wrinkling occurs at the beginning of the bending process, a multi -state informer -based early prediction of tube wrinkling is put forward utilizing the limited WrF collected at the start of the bending process. To meet the demand for high accuracy and efficiency of wrinkling early prediction in a dynamic process, the model pre -trained by the multi -state fusion wrinkling data from the fully bent tube is migrated to the target model through the transfer learning approach. A stainless -steel tube bending case is conducted as the verification experiment, which is simultaneously compared with the finite element analysis (FEA) result. The results show the superior prediction accuracy and higher efficiency of the proposed method mainly compared with the traditional Informer model, Transformer model, and Long Short -Term Memory (LSTM).","2024-01","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","151","","","","","","","","","","English","","","","WOS:001153287700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;32<br/>Total Times Cited:&nbsp;&nbsp;32<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Energy method; Informer -based prediction; INSTABILITY; LIMIT; MODEL; Multi -state fusion; Transfer learning approach; Tube wrinkling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6XAXZQUQ","journalArticle","2024","Zou, W; Zhang, WB; Tian, ZF; Wu, WH","A syntactic features and interactive learning model for aspect-based sentiment analysis","COMPLEX & INTELLIGENT SYSTEMS","","2199-4536","10.1007/s40747-024-01449-5","","The aspect-based sentiment analysis (ABSA) consists of two subtasks: aspect term extraction (AE) and aspect term sentiment classification (ASC). Previous research on the AE task has not adequately leveraged syntactic information and has overlooked the issue of multi-word aspect terms in text. Current researchers tend to focus on one of the two subtasks, neglecting the connection between the AE and ASC tasks. Moreover, the problem of error propagation easily occurs between two independent subtasks when performing the complete ABSA task. To address these issues, we present a unified ABSA model based on syntactic features and interactive learning. The proposed model is called syntactic interactive learning based aspect term sentiment classification model (SIASC). To overcome the problem of extracting multi-word aspect terms, the model utilizes part-of-speech features, words features, and dependency features as textual information. Meanwhile, we designs a unified ABSA structure based on the end-to-end framework, reducing the impact of error propagation issues. Interaction learning in the model can establish a connection between the AE task and the ASC task. The information from interactive learning contributes to improving the model's performance on the ASC task. We conducted an extensive array of experiments on the Laptop14, Restaurant14, and Twitter datasets. The experimental results show that the SIASC model achieved average accuracy of 84.11%, 86.65%, and 78.42% on the AE task, respectively. Acquiring average accuracy of 81.35%, 86.71% and 76.56% on the ASC task, respectively. The SIASC model demonstrates superior performance compared to the baseline model.","2024-08","2025-02-26 20:43:26","2025-02-26 20:43:26","","5359-5377","","4","10","","","","","","","","","","English","","","","WOS:001208630500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Dependency features; Error propagation; Interactive learning; Multi-word aspect terms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LJN8682B","journalArticle","2023","Natarajan, I; Shanmugam, M; Dhanalakshmi, S; Easwaramoorthy, S; Kuppusamy, S; Balu, S","Longitudinal Investigation of Work Stressors Using Human Voice Features","ACTA INFORMATICA PRAGENSIA","","1805-4951","10.18267/j.aip.208","","Stress is a part of everyone's life. Any event or thought that makes you upset, furious or anxious can set it off. It will affect the human health mentally and physically and produce a negative impact on nervous and immune systems in our body. The human voice carries a lot of information about the person speaking. It also aids in determining a person's current state. In this proposed method, stress was detected using a deep learning model. Automatic stress detection is becoming an intriguing study topic as the necessity for communication between humans and intelligent systems rises. The hormone called cortisol can also be used to determine the body's stress state. For most people, however, it is not a viable option. Speech features are particularly affected by stress, which is combined with the aim that voice data would serve as an easy-to-capture measure of everyday human stress levels and hence as an early warning signal of stress-related health problems. The proposed technique extracts Mel filter bank spectral coefficients from pre-processed voice input and the spectrum coefficients are extracted. The features of Mel frequency cepstral coefficients are applied to feed-forward networks and long short-term memory to predict the status of stress output using a binary decision, i.e., unstressed or stressed. The Mel spectrum and spectrogram output shows the variation in stressed and unstressed voice features. The results of the proposed method indicate better performance compared to an existing model. The model was developed as a web application to be used by workers to test their state of stress at any time.","2023","2025-02-26 20:43:26","2025-02-26 20:43:26","","104-122","","1","12","","","","","","","","","","English","","","","WOS:001106204000006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","FFT; LSTM; Mel filter bank; Mel scale; MFCC; RECOGNITION; Spectrogram; SPEECH; Stress","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T39LMDV3","journalArticle","2022","Cooney, C; Folli, R; Coyle, D","A Bimodal Deep Learning Architecture for EEG-fNIRS Decoding of Overt and Imagined Speech","IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING","","0018-9294","10.1109/TBME.2021.3132861","","Objective: Brain-computer interfaces (BCI) studies are increasingly leveraging different attributes of multiple signal modalities simultaneously. Bimodal data acquisition protocols combining the temporal resolution of electroencephalography (EEG) with the spatial resolution of functional near-infrared spectroscopy (fNIRS) require novel approaches to decoding. Methods: We present an EEG-fNIRS Hybrid BCI that employs a new bimodal deep neural network architecture consisting of two convolutional sub-networks (subnets) to decode overt and imagined speech. Features from each subnet are fused before further feature extraction and classification. Nineteen participants performed overt and imagined speech in a novel cue-based paradigm enabling investigation of stimulus and linguistic effects on decoding. Results: Using the hybrid approach, classification accuracies (46.31% and 34.29% for overt and imagined speech, respectively (chance: 25%)) indicated a significant improvement on EEG used independently for imagined speech (p = 0.020) while tending towards significance for overt speech (p = 0.098). In comparison with fNIRS, significant improvements for both speech-types were achieved with bimodal decoding (p<0.001). There was a mean difference of similar to 12.02% between overt and imagined speech with accuracies as high as 87.18% and 53%. Deeper subnets enhanced performance while stimulus effected overt and imagined speech in significantly different ways. Conclusion: The bimodal approach was a significant improvement on unimodal results for several tasks. Results indicate the potential of multi-modal deep learning for enhancing neural signal decoding. Significance: This novel architecture can be used to enhance speech decoding from bimodal neural signals.","2022-06","2025-02-26 20:43:26","2025-02-26 20:43:26","","1983-1994","","6","69","","","","","","","","","","English","","","","WOS:000799622400021","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;18<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","ACTIVATION; bimodal deep learning; brain-computer interfaces; CLASSIFICATION; Decoding; deep learning; Deep learning; EEG; Electroencephalography; fNIRS; functional near-infrared spectroscopy; Functional near-infrared spectroscopy; IMAGERY; imagined speech; LEXICAL ACCESS; Linguistics; PHRASES; Production; Task analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QHGDTDXD","journalArticle","2025","Dhar, S; Jana, ND; Das, S","GLGAN-VC: A Guided Loss-Based Generative Adversarial Network for Many-to-Many Voice Conversion","IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS","","2162-237X","10.1109/TNNLS.2023.3335119","","Many-to-many voice conversion (VC) is a technique aimed at mapping speech features between multiple speakers during training and transferring the vocal characteristics of one source speaker to another target speaker, all while maintaining the content of the source speech unchanged. Existing research highlights a notable gap between the original and generated speech samples in terms of naturalness within many-to-many VC. Therefore, there is substantial room for improvement in achieving more natural-sounding speech samples for both parallel and nonparallel VC scenarios. In this study, we introduce a generative adversarial network (GAN) system with a guided loss (GLGAN-VC) designed to enhance many-to-many VC by focusing on architectural improvements and the integration of alternative loss functions. Our approach includes a pair-wise downsampling and upsampling (PDU) generator network for effective speech feature mapping (FM) in multidomain VC. In addition, we incorporate an FM loss to preserve content information and a residual connection (RC)-based discriminator network to improve learning. A guided loss (GL) function is introduced to efficiently capture differences in latent feature representations between source and target speakers, and an enhanced reconstruction loss is proposed for better contextual information preservation. We evaluate our model on various datasets, including VCC 2016, VCC 2018, VCC 2020, and an emotional speech dataset (ESD). Our results, based on both subjective and objective evaluation metrics, demonstrate that our model outperforms state-of-the-art (SOTA) many-to-many GAN-based VC models in terms of speech quality and speaker similarity in the generated speech samples.","2025-01","2025-02-26 20:43:26","2025-02-26 20:43:26","","1813-1826","","1","36","","","","","","","","","","English","","","","WOS:001123011600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Data models; Frequency modulation; Generative adversarial network (GAN); Generative adversarial networks; Generators; GLGAN-voice conversion (GLGAN-VC); Hidden Markov models; many-to-many VC; Measurement; SPEECH SYNTHESIS; Task analysis; voice conversion (VC)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WZL8AYWP","journalArticle","2023","Gutz, SE; Maffei, MF; Green, JR","Feedback From Automatic Speech Recognition to Elicit Clear Speech in Healthy Speakers","AMERICAN JOURNAL OF SPEECH-LANGUAGE PATHOLOGY","","1058-0360","10.1044/2023_AJSLP-23-00030","","Purpose: This study assessed the effectiveness of feedback generated by automatic speech recognition (ASR) for eliciting clear speech from young, healthy individuals. As a preliminary step toward exploring a novel method for eliciting clear speech in patients with dysarthria, we investigated the effects of ASR feedback in healthy controls. If successful, ASR feedback has the potential to facilitate independent, at-home clear speech practice.Method: Twenty-three healthy control speakers (ages 23-40 years) read sentences aloud in three speaking modes: Habitual, Clear (over-enunciated), and in response to ASR feedback (ASR). In the ASR condition, we used Mozilla Deep Speech to transcribe speech samples and provide participants with a value indicating the accuracy of the ASR's transcription. For speakers who achieved sufficiently high ASR accuracy, noise was added to their speech at a participant specific signal-to-noise ratio to ensure that each participant had to over enunciate to achieve high ASR accuracy. Results: Compared to habitual speech, speech produced in the ASR and Clear conditions was clearer, as rated by speech-language pathologists, and more intelligible, per speech-language pathologist transcriptions. Speech in the Clear and ASR conditions aligned on several acoustic measures, particularly those associated with increased vowel distinctiveness and decreased speaking rate. However, ASR accuracy, intelligibility, and clarity were each correlated with different speech features, which may have implications for how people change their speech for ASR feedback. Conclusions: ASR successfully elicited outcomes similar to clear speech in healthy speakers. Future work should investigate its efficacy in eliciting clear speech in people with dysarthria.","2023-11","2025-02-26 20:43:26","2025-02-26 20:43:26","","2940-2959","","6","32","","","","","","","","","","English","","","","WOS:001128706800008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;103</p>","","","ACOUSTIC CHARACTERISTICS; CONVERSATIONAL SPEECH; DYSARTHRIA; INTELLIGIBILITY; MOTOR-PERFORMANCE; MULTIPLE-SCLEROSIS; PARKINSONS-DISEASE; PERCEPTUAL CONSEQUENCES; SPEAKING RATE; TALKER DIFFERENCES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W88AIM6U","journalArticle","2022","Swoboda, D; Boasen, J; Leger, PM; Pourchon, R; Senecal, S","Comparing the Effectiveness of Speech and Physiological Features in Explaining Emotional Responses during Voice User Interface Interactions","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app12031269","","The rapid rise of voice user interface technology has changed the way users traditionally interact with interfaces, as tasks requiring gestural or visual attention are swapped by vocal commands. This shift has equally affected designers, required to disregard common digital interface guidelines in order to adapt to non-visual user interaction (No-UI) methods. The guidelines regarding voice user interface evaluation are far from the maturity of those surrounding digital interface evaluation, resulting in a lack of consensus and clarity. Thus, we sought to contribute to the emerging literature regarding voice user interface evaluation and, consequently, assist user experience professionals in their quest to create optimal vocal experiences. To do so, we compared the effectiveness of physiological features (e.g., phasic electrodermal activity amplitude) and speech features (e.g., spectral slope amplitude) to predict the intensity of users' emotional responses during voice user interface interactions. We performed a within-subjects experiment in which the speech, facial expression, and electrodermal activity responses of 16 participants were recorded during voice user interface interactions that were purposely designed to elicit frustration and shock, resulting in 188 analyzed interactions. Our results suggest that the physiological measure of facial expression and its extracted feature, automatic facial expression-based valence, is most informative of emotional events lived through voice user interface interactions. By comparing the unique effectiveness of each feature, theoretical and practical contributions may be noted, as the results contribute to voice user interface literature while providing key insights favoring efficient voice user interface evaluation.","2022-02","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","3","12","","","","","","","","","","English","","","","WOS:000756229200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;105</p>","","","COMMUNICATION; emotional arousal; emotional valence; implicit measures; INFORMATION-SYSTEMS; MODEL; PERCEPTION; PITCH; RECOGNITION; user experience; VOCAL EXPRESSION; voice user interface","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YHP6P2FV","journalArticle","2021","Berger, SE; Branco, P; Vachon-Presseau, E; Abdullah, TB; Cecchi, G; Apkarian, AV","Quantitative language features identify placebo responders in chronic back pain","PAIN","","0304-3959","10.1097/j.pain.0000000000002175","","Although placebo effect sizes in clinical trials of chronic pain treatments have been increasing, it remains unknown if characteristics of individuals' thoughts or previous experiences can reliably infer placebo pill responses. Research using language to investigate emotional and cognitive processes has recently gained momentum. Here, we quantified placebo responses in chronic back pain using more than 300 semantic and psycholinguistic features derived from patients' language. This speech content was collected in an exit interview as part of a clinical trial investigating placebo analgesia (62 patients, 42 treated; 20 not treated). Using a nested leave-one-out cross-validated approach, we distinguished placebo responders from nonresponders with 79% accuracy using language features alone; a subset of these features-semantic distances to identity and stigma and the number of achievement-related words-also explained 46% of the variance in placebo analgesia. Importantly, these language features were not due to generic treatment effects and were associated with patients' specific baseline psychological traits previously shown to be predictive of placebo including awareness and personality characteristics, explaining an additional 31% of the variance in placebo analgesia beyond that of personality. Initial interpretation of the features suggests that placebo responders differed in how they talked about negative emotions and the extent that they expressed awareness to various aspects of their experiences; differences were also seen in time spent talking about leisure activities. These results indicate that patients' language is sufficient to identify a placebo response and implie that specific speech features may be predictive of responders' previous treatment.","2021-06","2025-02-26 20:43:26","2025-02-26 20:43:26","","1692-1704","","6","162","","","","","","","","","","English","","","","WOS:000711803600013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","ANALGESIA; Chronic back pain; GENDER; Interview; Machine learning; Natural language processing; PERSONALITY; Placebo response; Psycholinguistics; Semantic proximity; SPEECH; WORDS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4BUJ258M","journalArticle","2024","Wang, HW; Wang, YH; Jin, J","Application of multimodality perception scene construction based on Internet of Things (IoT) technology in art teaching","PEERJ COMPUTER SCIENCE","","2376-5992","10.7717/peerj-cs.2047","","Numerous impediments beset contemporary art education, notably the unidimensional delivery of content and the absence of real-time interaction during instructional sessions. This study endeavors to surmount these challenges by devising a multimodal perception system entrenched in Internet of Things (IoT) technology. This system captures students' visual imagery, vocalizations, spatial orientation, movements, ambient luminosity, and contextual data by harnessing an array of interaction modalities encompassing visual, auditory, tactile, and olfactory sensors. The synthesis of this manifold information about learning scenarios entails strategically placing sensors within physical environments to facilitate intuitive and seamless interactions. Utilizing digital art flower cultivation as a quintessential illustration, this investigation formulates tasks imbued with multisensory channel interactions, pushing the boundaries of technological advancement. It pioneers advancements in critical domains such as visual feature extraction by utilizing DenseNet networks and voice feature extraction leveraging SoundNet convolutional neural networks. This innovative paradigm establishes a novel art pedagogical framework, accentuating the importance of visual stimuli while enlisting other senses as complementary contributors. Subsequent evaluation of the usability of the multimodal perceptual interaction system reveals a remarkable task recognition accuracy of 96.15% through the amalgamation of Mel-frequency cepstral coefficients (MFCC) speech features with a long-short-term memory (LSTM) classifier model, accompanied by an average response time of merely 6.453 seconds-significantly outperforming comparable models. The system notably enhances experiential fidelity, realism, interactivity, and content depth, ameliorating the limitations inherent in solitary sensory interactions. This augmentation markedly elevates the caliber of art pedagogy and augments learning efficacy, thereby effectuating an optimization of art education.","2024-05-21","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","10","","","","","","","","","","English","","","","WOS:001229654600004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Art teaching; DenseNet; Interactive tasks; IoT; Multimodality perception; RECOGNITION; Visual perception","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9PZWXLX2","journalArticle","2024","Wang, YC; Zhou, JX; Li, ZJ; Zhang, S; Han, XY","Automatically Difficulty Grading Method for English Reading Corpus With Multifeature Embedding Based on a Pretrained Language Model","IEEE TRANSACTIONS ON LEARNING TECHNOLOGIES","","1939-1382","10.1109/TLT.2023.3319582","","Graded reading is one of the important ways of English learning. How to automatically judge and grade the difficulty of the English reading corpus is of great significance for precision teaching and personalized learning. However, the current rule-based readability assessment methods have some limitations, such as low efficiency and poor accuracy. In particular, these traditional methods usually lack semantics, which is crucial for students to understand the reading material. Meanwhile, they are difficult to be mapped to the difficulty level, which is not conducive to flexible application in actual personalized teaching. In this study, a method for grading the difficulty of the English reading corpus is proposed. This approach makes use of a pretrained language model and feature fusion embedding to make the most of multifeature data when training. First, based on linguists' evaluations of the variables influencing the difficulty of English reading corpus, three primary statistical features-sentence length, word length, and the number of prepositions-are taken into consideration. Then, the semantic features and part-of-speech features of the text are learned by a pretrained language model and long short-term memory, respectively, to capture polysemy features and fine-grained semantic representations that are difficult to represent with traditional models. Finally, multifeature embedding extractions are fused to grade the difficulty of the English reading corpus. Extensive experimental comparisons on a self-built dataset and two datasets that are freely accessible with various models indicate that our method outperforms the others in the task of grading the difficulty of English reading corpora.","2024","2025-02-26 20:43:26","2025-02-26 20:43:26","","474-484","","","17","","","","","","","","","","English","","","","WOS:001141545900028","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;16</p>","","","ALGORITHM; Deep learning; difficulty grading; feature fusion; graded reading; pretrained language models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KFBQUUBS","journalArticle","2024","Sun, QK","EEG-powered cerebral transformer for athletic performance","FRONTIERS IN NEUROROBOTICS","","1662-5218","10.3389/fnbot.2024.1499734","","Introduction In recent years, with advancements in wearable devices and biosignal analysis technologies, sports performance analysis has become an increasingly popular research field, particularly due to the growing demand for real-time monitoring of athletes' conditions in sports training and competitive events. Traditional methods of sports performance analysis typically rely on video data or sensor data for motion recognition. However, unimodal data often fails to fully capture the neural state of athletes, leading to limitations in accuracy and real-time performance when dealing with complex movement patterns. Moreover, these methods struggle with multimodal data fusion, making it difficult to fully leverage the deep information from electroencephalogram (EEG) signals.Methods To address these challenges, this paper proposes a ""Cerebral Transformer"" model based on EEG signals and video data. By employing an adaptive attention mechanism and cross-modal fusion, the model effectively combines EEG signals and video streams to achieve precise recognition and analysis of athletes' movements. The model's effectiveness was validated through experiments on four datasets: SEED, DEAP, eSports Sensors, and MODA. The results show that the proposed model outperforms existing mainstream methods in terms of accuracy, recall, and F1 score, while also demonstrating high computational efficiency.Results and discussion The significance of this study lies in providing a more comprehensive and efficient solution for sports performance analysis. Through cross-modal data fusion, it not only improves the accuracy of complex movement recognition but also provides technical support for monitoring athletes' neural states, offering important applications in sports training and medical rehabilitation.","2024-12-20","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","18","","","","","","","","","","English","","","","WOS:001388576300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","attention mechanism; cross-modal fusion; EEG signals; sports performance analysis; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7J2AACX6","journalArticle","2025","Strem, N; Dhami, D; Schmidt, B; Kersting, K","Multimodal transformer for early alarm prediction","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2024.109643","","Alarms are an essential part of distributed control systems designed to help plant operators keep the processes stable and safe. In reality, however, alarms are often noisy and thus can be easily overlooked. Early alarm prediction can give the operator more time to assess the situation and introduce corrective actions to avoid downtime and negative impact on human safety and environment. Existing studies on alarm prediction typically rely on signals directly coupled with these alarms. However, using more sources of information could benefit early prediction by letting the model learn characteristic patterns in the interactions of signals and events. Meanwhile, multimodal deep learning has recently seen impressive developments. Combination (or fusion) of modalities has been shown to be a key success factor, yet choosing the best fusion method fora given task introduces anew degree of complexity, in addition to existing architectural choices and hyperparameter tuning. This is one of the reasons why real-world problems are still typically tackled with unimodal approaches. To bridge this gap, we introduce a multimodal Transformer model for early alarm prediction based on a combination of recent events and signal data. The model learns the optimal representation of data from multiple fusion strategies automatically. The model is validated on real-world industrial data. We show that our model is capable of predicting alarms with the given horizon and that the proposed multimodal fusion method yields state-of-the-art predictive performance while eliminating the need to choose among conventional fusion techniques, thus reducing tuning costs and training time.","2025-01","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","139","","","","","","","","","","English","","","","WOS:001380491900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Alarm management; Alarm prediction; FAULT-DETECTION; Industrial processes; Multimodal fusion; Multimodal transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZA7Y4WJB","journalArticle","2024","Wang, HW; Tang, FZ; Wei, JY; Zhu, BC; Wang, YQ; Zhang, K","Online Semi-Supervised Transformer for Resilient Vehicle GNSS/INS Navigation","IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY","","0018-9545","10.1109/TVT.2024.3422680","","The Inertial Navigation Systems (INS) and Global Navigation Satellite Systems (GNSS) integrated navigation system is widely employed for vehicular positioning. However, obstacles in the wireless signal path often lead to GNSS outages, diminishing the reliability of positioning. Many deep learning-based methods have been proposed for their high accuracy and outstanding generalization capabilities. Nevertheless, they overlook the constraints posed by limited computational resources and memory capacity within real-time, online navigation systems. To strike a balance between positioning accuracy and model complexity, this paper proposes an Online Semi-supervised Transformer (OSS-Transformer) model for GNSS/INS integrated navigation that functions effectively during GNSS signal outages and has low computational requirements. This model comprises three critical components: 1) A Transformer-based architecture for adaptive feature extraction; 2) A self-supervised Masked Language Model (MLM) task to understand contextual relationships and feature distributions within INS data; 3) An improved memory replay technique for efficient online network training. Verified by the road test, the proposed OSS-Transformer based integrated navigation system reaches a maximum error of 6.02 m during 40 s outages and 9.81 m during 100 s outages, significantly outperforming traditional deep-learning methods. Additionally, the improved memory replay technique reduces loss by 26.23% compared to conventional methods, making it feasible on navigation devices with constrained computational resources and memory.","2024-11","2025-02-26 20:43:26","2025-02-26 20:43:26","","16295-16311","","11","73","","","","","","","","","","English","","","","WOS:001359239100005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Accuracy; ALGORITHM; Complexity theory; Deep learning; Global navigation satellite system; global navigation satellite system (GNSS); GPS OUTAGES; HYBRID; inertial navigation system (INS); integrated navigation; INTEGRATION; Kalman filters; Navigation; NETWORK; online training; SYSTEM; Task analysis; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SQPSSMQ8","journalArticle","2024","Zhou, YH; Luo, T; He, ZY; Jiang, GY; Xu, HY; Chang, CC","CAISFormer: Channel-wise attention transformer for image steganography","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2024.128295","","Current Transformer-based image steganography cannot embed data properly without considering the correlation of the cover image and the secret image. In addition, to save computational complexity, spatial-wise Transformer is often used to apply in small spatial windows, which limits the extraction of the global feature. To solve those limitations, we present a channel-wise attention Transformer model for image steganography (CAISFormer), which aims to construct long-range dependencies for identifying inconspicuous positions to embed data. A channel self-attention module (CSAM) is deployed to focus the feature channels suitable for data hiding by establishing channel relationships. Meanwhile, a non-linear enhancement (NLE) layer is employed to enhance the beneficial features while weaken the irrelevant ones. For building feature coupling between the cover image and the secret image, a channel-wise cross attention module (CCAM) is designed to fine-tune cover image features by capturing their cross-dependencies. In addition, for concealing data properly, a global-local aggregation module (GLAM) is deployed to adjust fused features by combining global and local attention, which can focus on inconspicuous and texture regions, respectively. The experimental results demonstrate that CAISFormer obtains PSNR gains of more than 0.36 dB and 0.90 dB for the cover/stego image pair and the secret/recovery image pair, respectively, and the detection ratio is decreased by 3.43%, in single image hiding compared to the state-of-the-art. Moreover, the generalization ability is also proved across a variety of datasets. The code will be made publicly available at https://github.com/YuhangZhouCJY/CAISFormer.","2024-10-28","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","603","","","","","","","","","","English","","","","WOS:001291543500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Cross attention; Feature coupling; Image steganography; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ALLPUWN8","journalArticle","2023","Liu, BS; Jia, ZT; Guo, PG; Kong, WL","Hyperspectral Image Classification Based on Transposed Convolutional Neural Network Transformer","ELECTRONICS","","2079-9292","10.3390/electronics12183879","","Hyperspectral imaging is a technique that captures images of objects within a wide spectrum range, allowing for the acquisition of additional spectral information to reveal subtle variations and compositional components in the objects. Convolutional neural networks (CNNs) have shown remarkable feature extraction capabilities for HSI classification, but their ability to capture deep semantic features is limited. On the other hand, transformer models based on attention mechanisms excel at handling sequential data and have demonstrated great potential in various applications. Motivated by these two facts, this paper proposes a multiscale spectral-spatial transposed transformer (MSSTT) that captures the high-level semantic features of an HSI while preserving the spectral information as much as possible. The MSSTT consists of a spectral-spatial Inception module that extracts spectral and spatial features using multiscale convolutional kernels, and a spatial transpose Inception module that further enhances and extracts spatial information. A transformer model with a cosine attention mechanism is also included to extract deep semantic features, with the QKV matrix constrained to ensure the output remains within the activation range. Finally, the classification results are obtained by applying a linear layer to the learnable tokens. The experimental results from three public datasets show that the proposed MSSTT outperforms other deep learning methods in HSI classification. On the India Pines, Pavia University, and Salinas datasets, accuracies of 97.19%, 99.47%, and 99.90% were achieved, respectively, with a training set proportion of 5%.","2023-09","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","18","12","","","","","","","","","","English","","","","WOS:001071730700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","CNN; cross-cosine attention mechanism; hyperspectral image; REMOTE-SENSING TECHNIQUE; spatial transposed inception; spectral inception; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RLNJGRN7","journalArticle","2023","Jin, YH; Hou, L; Zhong, S; Yi, HM; Chen, YS","Invertible Koopman Network and its application in data-driven modeling for dynamic systems","MECHANICAL SYSTEMS AND SIGNAL PROCESSING","","0888-3270","10.1016/j.ymssp.2023.110604","","Koopman operator, acting on an infinite-dimensional Hilbert space of the observables, provides a global systematic linear representation of nonlinear systems, which is a leading candidate for data-driven modeling. In practical applications, the observable function is required to have an invertible property to predict or control the original system. However, two approaches for constructing the invertible observable functions in current research, introducing the full-state observables and adopting the auto-encoder, have drawbacks such as overly strong assumptions and lossy reconstruction. To address these issues, we propose the Invertible Koopman Network (IKN) to approximate the Koopman operator. With special invertible blocks, IKN achieves structure-level reversibility while retaining sufficient nonlinear mapping capability. This net-work results in a transformation from the complex dynamic system's states to the observables with simpler dynamics and affords lossless reconstruction via its invertible process. Then, we use the IKN as a dynamical embedding model and adopt the Transformer based on an autoregressive task to learn the evolution pattern of the observables. Through the greedy decoding strategy, the trained IKN and Transformer model enable data-driven prediction where only initial value is provided. The method is tested on three typical chaotic dynamic systems (Lorenz system, Chen system, and Kuramoto-Sivashinsky equation) and is shown to capture the systems' intrinsic evolution patterns, such as the structure of the strange attractor. Comparative experiments with alternative data-driven modeling approaches illustrate that our proposed method can model a longer evolutionary process with less error, further demonstrating its effectiveness and superiority.","2023-10-01","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","200","","","","","","","","","","English","","","","WOS:001050839400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Data-driven modeling; Deep learning; Dynamic systems; Koopman theory; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8QYSEAMN","journalArticle","2023","Xiong, YG; Xiao, XM; Yao, MB; Liu, HQ; Yang, H; Fu, YG","MarsFormer: Martian Rock Semantic Segmentation With Transformer","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2023.3302649","","Semantic segmentation of Mars scenes has a crucial role in Mars rovers science missions. Current convolutional neural network (CNN)-based composition of U-Net has powerful information extraction capabilities; however, convolutional localization suffers from the limited global context modeling capability. Although transformer global modeling has performed well, it still encounters obstacles in the extraction and retention of low-level features. This issue is particularly relevant for Martian rocks with their varying shapes, textures, and sizes in Mars scenes. In this article, we propose a novel transformer semantic segmentation framework for Martian rock images, called MarsFormer, that consists of an encoder-decoder structure connected through a feature enhancement module (FEM) and a window transformer block (WTB). Specifically, multiscale hierarchical features are generated by the mix transformer (MiT) encoders, upgraded-FFN decoder (UFD) fuse and filter features at different scales, preserving the rich local and global contextual information. FEM enhances the inter-multiscale feature correlation from both spatial and channel perspectives. WTB captures the long-range contexts and preserves the local features. We built two datasets of synthetic and real Martian rocks. The synthetic dataset is SynMars, referencing data from the ZhuRong rover taken from its virtual terrain engine. The other dataset is MarsData-V2, from real Mars scenes, and published recently in our previous study. Extensive experiments conducted on both datasets showed that MarsFormer achieves superiority in Martian rock segmentation, obtaining state-of-the-art performance with favorable computational simplicity. The data are available at: https://github.com/CVIR-Lab/SynMars.","2023","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","61","","","","","","","","","","English","","","","WOS:001051753100006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","Mars exploration; semantic segmentation; synthetic Mars; TERRAIN; transformer model; U-NET ARCHITECTURE; VISION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CZUR9HME","journalArticle","2024","van den Berg, RL; de Boer, C; Zwan, MD; Jutten, RJ; van Liere, M; van de Glind, MCABJ; Dubbelman, MA; Schlueter, LM; van Harten, AC; Teunissen, CE; Barkhof, F; van de Giessen, E; Collij, LE; Robin, J; Simpson, W; Harrison, JE; van der Flier, WM; Sikkes, SAM","Digital remote assessment of speech acoustics in cognitively unimpaired adults: feasibility, reliability and associations with amyloid pathology","ALZHEIMERS RESEARCH & THERAPY","","1758-9193","10.1186/s13195-024-01543-3","","BackgroundDigital speech assessment has potential relevance in the earliest, preclinical stages of Alzheimer's disease (AD). We evaluated the feasibility, test-retest reliability, and association with AD-related amyloid-beta (A beta) pathology of speech acoustics measured over multiple assessments in a remote setting.MethodsFifty cognitively unimpaired adults (Age 68 +/- 6.2 years, 58% female, 46% A beta-positive) completed remote, tablet-based speech assessments (i.e., picture description, journal-prompt storytelling, verbal fluency tasks) for five days. The testing paradigm was repeated after 2-3 weeks. Acoustic speech features were automatically extracted from the voice recordings, and mean scores were calculated over the 5-day period. We assessed feasibility by adherence rates and usability ratings on the System Usability Scale (SUS) questionnaire. Test-retest reliability was examined with intraclass correlation coefficients (ICCs). We investigated the associations between acoustic features and A beta-pathology, using linear regression models, adjusted for age, sex and education.ResultsThe speech assessment was feasible, indicated by 91.6% adherence and usability scores of 86.0 +/- 9.9. High reliability (ICC >= 0.75) was found across averaged speech samples. A beta-positive individuals displayed a higher pause-to-word ratio in picture description (B = -0.05, p = 0.040) and journal-prompt storytelling (B = -0.07, p = 0.032) than A beta-negative individuals, although this effect lost significance after correction for multiple testing.ConclusionOur findings support the feasibility and reliability of multi-day remote assessment of speech acoustics in cognitively unimpaired individuals with and without A beta-pathology, which lays the foundation for the use of speech biomarkers in the context of early AD.","2024-08-01","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","1","16","","","","","","","","","","English","","","","WOS:001282152200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","Alzheimer's disease; Amyloid; Digital biomarker; FMRI; Language; LANGUAGE; MEMORY; Remote assessment; SENSITIVITY; Speech acoustics; SUS; USABILITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QKJ4IJKP","journalArticle","2023","Xie, ZL; Brodbeck, C; Chandrasekaran, B","Cortical Tracking of Continuous Speech Under Bimodal Divided Attention","NEUROBIOLOGY OF LANGUAGE","","2641-4368","10.1162/nol_a_00100","","Speech processing often occurs amid competing inputs from other modalities, for example, listening to the radio while driving. We examined the extent to which dividing attention between auditory and visual modalities (bimodal divided attention) impacts neural processing of natural continuous speech from acoustic to linguistic levels of representation. We recorded electroencephalographic (EEG) responses when human participants performed a challenging primary visual task, imposing low or high cognitive load while listening to audiobook stories as a secondary task. The two dual-task conditions were contrasted with an auditory single-task condition in which participants attended to stories while ignoring visual stimuli. Behaviorally, the high load dual-task condition was associated with lower speech comprehension accuracy relative to the other two conditions. We fitted multivariate temporal response function encoding models to predict EEG responses from acoustic and linguistic speech features at different representation levels, including auditory spectrograms and information-theoretic models of sublexical-, word-form-, and sentence-level representations. Neural tracking of most acoustic and linguistic features remained unchanged with increasing dual-task load, despite unambiguous behavioral and neural evidence of the high load dual-task condition being more demanding. Compared to the auditory single-task condition, dual-task conditions selectively reduced neural tracking of only some acoustic and linguistic features, mainly at latencies >200 ms, while earlier latencies were surprisingly unaffected. These findings indicate that behavioral effects of bimodal divided attention on continuous speech processing occur not because of impaired early sensory representations but likely at later cognitive processing stages. Crossmodal attention-related mechanisms may not be uniform across different speech processing levels.","2023-04-11","2025-02-26 20:43:26","2025-02-26 20:43:26","","318-343","","2","4","","","","","","","","","","English","","","","WOS:000970945000006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","acoustic processing; BRAIN-STEM; CAPACITY; COGNITIVE LOAD; continuous speech; CORTEX; crossmodal; divided attention; EEG; ERP; linguistic processing; MEMORY; RESPONSES; SELECTIVE ATTENTION; VISUAL PERCEPTUAL LOAD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WS8BRB77","journalArticle","2022","Bhati, S; Villalba, J; Zelasko, P; Moro-Velazquez, L; Dehak, N","Unsupervised Speech Segmentation and Variable Rate Representation Learning Using Segmental Contrastive Predictive Coding","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2022.3180684","","Typically, unsupervised segmentation of speech into the phone- and wordlike units are treated as separate tasks and are often done via different methods which do not fully leverage the inter-dependence of the two tasks. Here, we unify them and propose a technique that can jointly perform both, showing that these two tasks indeed benefit from each other. Recent attempts employ self-supervised learning, such as contrastive predictive coding (CPC), where the next frame is predicted given past context. However, CPC only looks at the audio signal's frame-level structure. We overcome this limitation with a segmental contrastive predictive coding (SCPC) framework to model the signal structure at a higher level, e.g., phone level. A convolutional neural network learns frame-level representation from the raw waveform via noise-contrastive estimation (NCE). A differentiable boundary detector finds variable-length segments, which are then used to optimize a segment encoder via NCE to learn segment representations. The differentiable boundary detector allows us to train frame-level and segment-level encoders jointly. Experiments show that our single model outperforms existing phone and word segmentation methods on TIMIT and Buckeye datasets. Finally, we use SCPC to extract speech features at the segment level rather than at the uniformly spaced frame level (e.g., 10 ms) and produce variable rate representations that change according to the contents of the utterance. We lower the feature extraction rate from the typical 100 Hz to 14.5 Hz on average while still outperforming the hand-crafted features such as MFCC on the linear phone classification task.","2022","2025-02-26 20:43:26","2025-02-26 20:43:26","","2002-2014","","","30","","","","","","","","","","English","","","","WOS:000812527100006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","Detectors; Feature extraction; FRAMEWORK; Hidden Markov models; NEURAL-NETWORKS; Predictive coding; Representation learning; Self-supervised learning; Speech processing; Task analysis; unsupervised phone segmentation; unsupervised word segmentation; variable-rate representation learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YL7TJFWD","journalArticle","2024","Liang, LL; Wang, HL; Zhang, WS","Decoding paradoxical identities: The discourse construction of left-behind children in news reports","DISCOURSE & COMMUNICATION","","1750-4813","10.1177/17504813241239895","","This paper presents an empirical corpus-based study on the identity of left-behind children in China, employing the discourse-historical approach (DHA) framework. It is the first study to combine Latent Dirichlet Allocation (LDA) topic modeling and reported speech analysis to examine how China Daily constructs the identity of left-behind children and explore the cultural and rhetorical factors influencing this identity construction. By integrating computational techniques and qualitative analysis methods, this study provides a comprehensive understanding of the intricate nature of identity construction for left-behind children. This interdisciplinary approach strengthens the theoretical foundations of media analysis and offers fresh insights into the dynamics of media discourse. The findings reveal that China Daily portrays left-behind children in a multifaceted and diverse manner, encompassing both positive and negative aspects, while placing emphasis on their vulnerability and passivity. Furthermore, the media employs communication techniques such as identification by sympathy, antithesis, and inaccuracy to establish emotional resonance and foster audience identification, ultimately influencing the audience's perspectives on these children.","2024-08","2025-02-26 20:43:26","2025-02-26 20:43:26","","535-556","","4","18","","","","","","","","","","English","","","","WOS:001193943000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","CHINA; Discourse-historical approach; HEALTH; identity construction; LANGUAGE; LDA topic modeling; left-behind children; media discourse; PARENTAL MIGRATION; TELEVISION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KFEFYIBT","journalArticle","2024","Li, F; Chen, YX; Liu, HY; Zhao, ZX; Yao, YZ; Liao, X","Vocoder Detection of Spoofing Speech Based on GAN Fingerprints and Domain Generalization","ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS","","1551-6857","10.1145/3630751","","As an important part of the text-to-speech (TTS) system, vocoders convert acoustic features into speech waveforms. The difference in vocoders is key to producing different types of forged speech in the TTS system. With the rapid development of general adversarial networks (GANs), an increasing number of GAN vocoders have been proposed. Detectors often encounter vocoders of unknown types, which leads to a decline in the generalization performance of models. However, existing studies lack research on detection generalization based on GAN vocoders. To solve this problem, this study proposes vocoder detection of spoofed speech based on GAN fingerprints and domain generalization. The framework can widen the distance between real speech and forged speech in feature space, improving the detection model's performance. Specifically, we utilize a fingerprint extractor based on an autoencoder to extract GAN fingerprints from vocoders. We then weight them to the forged speech for subsequent classification to learn the forged speech features with high differentiation. Subsequently, domain generalization is used to further improve the generalization ability of the model for unseen forgery types. We achieve domain generalization using domain-adversarial learning and asymmetric triplet loss to learn a better generalized feature space in which real speech is compact and forged speech synthesized by different vocoders is dispersed. Finally, to optimize the training process, curriculum learning is used to dynamically adjust the contributions of the samples with different difficulties in the training process. Experimental results show that the proposed method achieves the most advanced detection results among four GAN vocoders. The code is available at https://github.com/multimedia-infomation-security/GAN-Vocoder-detection.","2024-06","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","6","20","","","","","","","","","","English","","","","WOS:001208681800007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","curriculum learning; domain generalization; FEATURES; GAN fingerprint; Speech forgery; vocoder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KW3AQ64N","journalArticle","2021","Ayyub, K; Iqbal, S; Nisar, MW; Ahmad, SG; Munir, EU","Stance detection using diverse feature sets based on machine learning techniques","JOURNAL OF INTELLIGENT & FUZZY SYSTEMS","","1064-1246","10.3233/JIFS-202269","","Sentiment analysis is the field that analyzes sentiments, and opinions of people about entities such as products, businesses, and events. As opinions influence the people's behaviors, it has numerous applications in real life such as marketing, politics, social media etc. Stance detection is the sub-field of sentiment analysis. The stance classification aims to automatically identify from the source text, whether the source is in favor, neutral, or opposed to the target. This research study proposed a framework to explore the performance of the conventional (NB, DT, SVM), ensemble learning (RF, AdaBoost) and deep learning-based (DBN, CNN-LSTM, and RNN) machine learning techniques. The proposed method is feature centric and extracted the (sentiment, content, tweet specific and part-of-speech) features from both datasets of SemEval2016 and SemEval2017. The proposed study has also explored the role of deep features such as GloVe and Word2Vec for stance classification which has not received attention yet for stance detection. Some base line features such as Bag of words, Ngram, TF-IDF are also extracted from both datasets to compare the proposed features along with deep features. The proposed features are ranked using feature ranking methods such as (information gain, gain ration and relief-f). Further, the results are evaluated using standard performance evaluation measures for stance classification with existing studies. The calculated results show that the proposed feature sets including sentiment, (part-of-speech, content, and tweet specific) are helpful for stance classification when applied with SVM and GloVe a deep feature has given the best results when applied with deep learning method RNN.","2021","2025-02-26 20:43:26","2025-02-26 20:43:26","","9721-9740","","5","40","","","","","","","","","","English","","","","WOS:000644456300071","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","CLASSIFICATION; content based; deep features; deep learning; SENTIMENT; sentiment analysis; Stance classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SZ49I2D4","journalArticle","2024","Bachiri, YA; Mouncif, H; Bouikhalene, B; Hamzaoui, R","INTEGRATING AI-BASED SPEECH RECOGNITION TECHNOLOGY TO ENHANCE READING ASSESSMENTS WITHIN MOROCCO'S TaRL PROGRAM","TURKISH ONLINE JOURNAL OF DISTANCE EDUCATION","","1302-6488","","","This study examined the integration of artificial intelligence-powered speech recognition technology within early reading assessments in Morocco's Teaching at the Right Level (TaRL) program. The purpose was to evaluate the effectiveness of an automated speech recognition tool compared to traditional paper- based assessments in improving reading skills among 100 Moroccan first to third-graders. The mixed- method approach combined pre-post standardized reading tests with qualitative feedback. Results showed students receiving the AI-enabled speech recognition assessments demonstrated significant gains in reading achievement compared to peers assessed via traditional methods. Qualitative findings revealed benefits of instant feedback and enhanced engagement provided by the speech recognition tool. This study contributes timely empirical evidence on adopting learning technologies, specifically AI-driven automated speech assessment instruments, to enhance foundational literacy development within under-resourced education systems implementing student-centered pedagogical techniques like TaRL. It provides valuable insights and guidance for integrating innovative speech analysis tools within localized teaching and learning frameworks to strengthen early reading instruction and monitoring.","2024-10","2025-02-26 20:43:26","2025-02-26 20:43:26","","1-16","","4","25","","","","","","","","","","English","","","","WOS:001367356800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","Artificial intelligence; automatic speech recognition; e-learning; Moroccan education system; reading assessment; Teaching at the Right Level (TaRL)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VRW3LGXD","journalArticle","2022","Miao, XL; Li, Y; Wen, M; Liu, YY; Julian, IN; Guo, H","Fusing features of speech for depression classification based on higher-order spectral analysis","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2022.07.006","","Approximately 300 million people worldwide suffer from depression, and more than 60% of psychiatric patients do not have access to mental health services due to the shortage of psychiatrists and the high costs associated with clinical diagnosis and treatment. Correct and efficient diagnosis of depression can help overcome these straits. Automatic detection of depressive symptoms can help improve the accuracy and availability of diagnosis. In this paper, a fusion feature for Bispectral Features and Bicoherent Features by using higher-order spectral analysis. Experiments were performed on the Depression Sub-Challenge Dataset of the Audio/Visual Emotion Challenge 2017. The fusion feature fuses higher-order spectral features and traditional speech features with classification weights greater than 100 extracted by using A Collaborative Voice Analysis Repository. The support vector machine and k-nearest neighbor classification algorithms were used as the traditional machine learning models, and the convolutional neural network was used as the deep learning model to verify the proposed features. The experimental results show that under the support vector machine algorithm, the accuracies of extraction of speech-related features by using a collaborative voice analysis repository, The higher-order spectral analysis, and their fusion features were 63.15%, 68.42%, and 73.68%, respectively. Under the k-nearest neighbor classification algorithms model algorithm, the corresponding accuracies were 68.18%, 72.73%, and 77.27%, respectively. For the convolutional neural network model, the corresponding accuracies were 70%, 77%, and 85%, respectively. The results demonstrate that the fusion feature recognition accuracy is high and can be employed to improve the accuracy of depression identification by using traditional machine learning and deep learning models.","2022-09","2025-02-26 20:43:26","2025-02-26 20:43:26","","46-56","","","143","","","","","","","","","","English","","","","WOS:000848095200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Classifier; Depression; DETECTING DEPRESSION; GERIATRIC DEPRESSION; Higher -order spectrum analysis; Machine learning; SCALE; Speech -related features","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XHU8P5UV","journalArticle","2025","Lan, L; Li, K; Li, D","Exploring the application of AI in the education of children with autism: a public health perspective","FRONTIERS IN PSYCHIATRY","","1664-0640","10.3389/fpsyt.2024.1521926","","Introduction Autism Spectrum Disorder (ASD) presents significant challenges in social communication and interaction, critically impacting the lives of children with ASD. Traditional interventions, such as Applied Behavior Analysis (ABA) and Social Skills Training (SST), have been widely used to address social skill deficits in these children. While these methods are effective, they often require substantial resources, long-term engagement, and specialized expertise, which limit their accessibility and adaptability to diverse social contexts. Recent advancements in artificial intelligence (Al), particularly Transformer-based models, offer a novel opportunity to enhance and personalize social skills training.Methods This study introduces a Public Health-Driven Transformer (PHDT) model specifically designed to improve social skills in children with ASD. By integrating public health principles with state-of-the-art Al methodologies, the PHDT model creates interventions that are adaptable, accessible, and sensitive to individual needs. Leveraging multi-modal data inputs-such as text, audio, and facialcues-PHDT provides real-time social context interpretation and adaptive feedback, enabling a more naturalistic and engaging learning experience.Results and discussion Experimental results reveal that PHDT significantly outperforms traditional methods in fostering engagement, retention, and social skill acquisition. These findings highlight PHDT's potential to improve social competencies in children with ASD and to revolutionize access to specialized support within public health frameworks. This work underscores the transformative impact of Al-driven, public health-oriented interventions in promoting equitable access to essential developmental resources and enhancing the quality of life for children with ASD.","2025-01-28","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","15","","","","","","","","","","English","","","","WOS:001417203700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","autism spectrum disorder; Frontiers; multi-modal AI; public health intervention; social skills enhancement; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G5CWSMK8","journalArticle","2024","Ma, BQ; Guo, JP; De Biase, A; van Dijk, L; van Ooijen, PMA; Langendijk, JA; Both, S; Sijtsema, NM","PET/CT based transformer model for multi-outcome prediction in oropharyngeal cancer","RADIOTHERAPY AND ONCOLOGY","","0167-8140","10.1016/j.radonc.2024.110368","","Background and purpose: To optimize our previously proposed TransRP, a model integrating CNN (convolutional neural network) and ViT (Vision Transformer) designed for recurrence-free survival prediction in oropharyngeal cancer and to extend its application to the prediction of multiple clinical outcomes, including locoregional control (LRC), Distant metastasis-free survival (DMFS) and overall survival (OS). Materials and Methods: Data was collected from 400 patients (300 for training and 100 for testing) diagnosed with oropharyngeal squamous cell carcinoma (OPSCC) who underwent (chemo)radiotherapy at University Medical Center Groningen. Each patient's data comprised pre-treatment PET/CT scans, clinical parameters, and clinical outcome endpoints, namely LRC, DMFS and OS. The prediction performance of TransRP was compared with CNNs when inputting image data only. Additionally, three distinct methods (m1-3) of incorporating clinical predictors into TransRP training and one method (m4) that uses TransRP prediction as one parameter in a clinical Cox model were compared. Results: TransRP achieved higher test C-index values of 0.61, 0.84 and 0.70 than CNNs for LRC, DMFS and OS, respectively. Furthermore, when incorporating TransRP's prediction into a clinical Cox model (m4), a higher Cindex of 0.77 for OS was obtained. Compared with a clinical routine risk stratification model of OS, our model, using clinical variables, radiomics and TransRP prediction as predictors, achieved larger separations of survival curves between low, intermediate and high risk groups. Conclusion: TransRP outperformed CNN models for all endpoints. Combining clinical data and TransRP prediction in a Cox model achieved better OS prediction.","2024-08","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","197","","","","","","","","","","English","","","","WOS:001251455300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Deep learning; HEAD; IMAGE-BIOMARKERS; NETWORK; Oropharyngeal cancer; Outcome prediction; SURVIVAL; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DNNBATRD","journalArticle","2024","Yu, WL; Liu, RN; Chen, DY; Hu, QH","Explainability Enhanced Object Detection Transformer With Feature Disentanglement","IEEE TRANSACTIONS ON IMAGE PROCESSING","","1057-7149","10.1109/TIP.2024.3492733","","Explainability is a pivotal factor in determining whether a deep learning model can be authorized in critical applications. To enhance the explainability of models of end-to-end object DEtection with TRansformer (DETR), we introduce a disentanglement method that constrains the feature learning process, following a divide-and-conquer decoupling paradigm, similar to how people understand complex real-world problems. We first demonstrate the entangled property of the features between the extractor and detector and find that the regression function is a key factor contributing to the deterioration of disentangled feature activation. These highly entangled features always activate the local characteristics, making it difficult to cover the semantic information of an object, which also reduces the interpretability of single-backbone object detection models. Thus, an Explainability Enhanced object detection Transformer with feature Disentanglement (DETD) model is proposed, in which the Tensor Singular Value Decomposition (T-SVD) is used to produce feature bases and the Batch averaged Feature Spectral Penalization (BFSP) loss is introduced to constrain the disentanglement of the feature and balance the semantic activation. The proposed method is applied across three prominent backbones, two DETR variants, and a CNN based model. By combining two optimization techniques, extensive experiments on two datasets consistently demonstrate that the DETD model outperforms the counterpart in terms of object detection performance and feature disentanglement. The Grad-CAM visualizations demonstrate the enhancement of feature learning explainability in the disentanglement view.","2024","2025-02-26 20:43:26","2025-02-26 20:43:26","","6439-6454","","","33","","","","","","","","","","English","","","","WOS:001358281600005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Analytical models; Computational modeling; Deep learning; explainability; feature disentanglement; Feature extraction; hybrid transformer model; Mathematical models; MODELS; object detection; Object detection; REPRESENTATION; Semantics; Transformers; Vectors; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KD2DP2TF","journalArticle","2024","Yu, T; Zhang, LH; Liu, HL; Liu, HB; Wang, JJ","Service recommendation based on contrastive learning and multi-task learning","COMPUTER COMMUNICATIONS","","0140-3664","10.1016/j.comcom.2023.11.018","","Service recommendation is an efficient method for service-oriented software that can improve software quality. Applications often require the integration of multiple services to create more powerful and complex functionality while saving software development time. However, the vast number of available candidate Web services can impose a heavy burden on software developers' selection decisions. The existing service recommendation challenges are mainly come from: (1) the development requirements entered by users are too arbitrary (2) the extreme sparsity of invocation records. To address the above challenges, in this paper, we propose a Service Recommendation method based on Contrastive Learning and Multi-task Learning (SRCLML). Specifically, we utilize the Transformer model to extract the development requirements of users, conduct indepth mining of text descriptions, and extract features of applications. Next, the features are fed into the DNN model to predict the probability that the service will be selected. Moreover, we add a tag judgment task to make it capable of multi-task learning, through which, the training signal information implied can be used as an inductive bias to improve service recommendation capabilities. Additionally, we build three subgraphs based on the global graph, conduct in-depth mining of historical invocation records based on contrastive learning and graph neural network to extract features of applications and services and calculate application preferences for each service. Finally, we combined the above two to obtain the final recommendation service list. Extensive experiments on real-world datasets demonstrate that our method, SRCLML, outperforms several state-of-the-art comparison methods in the domain of service recommendation.","2024-01-01","2025-02-26 20:43:26","2025-02-26 20:43:26","","285-295","","","213","","","","","","","","","","English","","","","WOS:001121053000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Application development; Contrastive learning; Multi-task learning; Recommendation system; Service recommendation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T8JN4IBV","journalArticle","2022","Malla, S; Alphonse, PJA","Fake or real news about COVID-19? Pretrained transformer model to detect potential misleading news","EUROPEAN PHYSICAL JOURNAL-SPECIAL TOPICS","","1951-6355","10.1140/epjs/s11734-022-00436-6","","The World Health Organization declared the novel coronavirus disease 2019 a pandemic on March 11, 2020. Along with the coronavirus pandemic, a new crisis has emerged, characterized by widespread fear and panic caused by a lack of information or, in some cases, outright fake messages. In these circumstances, Twitter is one of the most eminent and trusted social media platforms. Fake tweets, on the other hand, are challenging to detect and differentiate. The primary goal of this paper is to educate society about the importance of accurate information and prevent the spread of fake information. This paper has investigated COVID-19 fake data from various social media platforms such as Twitter, Facebook, and Instagram. The objective of this paper is to categorize given tweets as either fake or real news. The authors have tested various deep learning models on the COVID-19 fake dataset. Finally, the CT-BERT and RoBERTa deep learning models outperformed other deep learning models like BERT, BERTweet, AlBERT, and DistlBERT. The proposed ensemble deep learning architecture outperformed CT-BERT and RoBERTa on the COVID-19 fake news dataset using the multiplicative fusion technique. The proposed model's performance in this technique was determined by the multiplicative product of the final predictive values of CT-BERT and RoBERTa. This technique overcomes the disadvantage of these CT-BERT and RoBERTa models' incorrect predictive nature. The proposed architecture outperforms both well-known ML and DL models, with 98.88% accuracy and a 98.93% F1-score.","2022-12","2025-02-26 20:43:26","2025-02-26 20:43:26","","3347-3356","","18-20","231","","","","","","","","","","English","","","","WOS:000742318800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;16<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","DISEASE DIAGNOSIS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SRLHMXVN","journalArticle","2025","Tripathi, S; Priyadarshni; Misra, R; Singh, TN","Multilayer multivariate forecasting network for precise resource utilization prediction in edge data centers","FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE","","0167-739X","10.1016/j.future.2024.107692","","Efficient resource management and accurate prediction of cloud workloads are vital in modern cloud computing environments, where dynamic and volatile workloads present significant challenges. Traditional forecasting models often fail to fully capture the intricate temporal dependencies and non-linear patterns inherent in cloud data, leading to inefficiencies in resource utilization. To overcome these limitations, this research introduces the MultiLayer Multivariate Resource Predictor (MMRP), a novel deep learning architecture that seamlessly integrates a Multi-Head Attention Transformer model with Convolutional Neural Networks and Bidirectional Long Short-Term Memory units. The proposed model is designed to excel in capturing long-range dependencies and complex patterns, thereby significantly enhancing the accuracy of workload predictions. Extensive, rigorous experimentation using real-world Alibaba and Google cluster traces reveals that the proposed model consistently outperforms existing state-of-the-art models and related cloud resource utilization prediction in both univariate and multivariate time series forecasting tasks. The model demonstrates a remarkable improvement in prediction performance, with an average R squared increase of 5.76% and a Mean Absolute Percentage Error reduction of 84.9% compared to the best-performing baseline models. Furthermore, our model achieves a significant reduction in Root Mean Square Error by approximately 35.34% and decreases Mean Absolute Error by about 39.49% on average. Its scalability and adaptability across various cloud environments underscore the proposed model's potential to optimize resource allocation, paving the way for more efficient and reliable cloud-based systems.","2025-05","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","166","","","","","","","","","","English","","","","WOS:001399722000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","Attention mechanism; CLOUD; Cloud data center; Convolution; Forecasting; LSTM; MANAGEMENT; NEURAL-NETWORK; Time series; Transformer; Workload prediction; WORKLOAD PREDICTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7PCHJJLV","journalArticle","2025","Khan, NA; Goyal, T; Hussain, F; Jamwal, PK; Hussain, S","Transformer-Based Approach for Predicting Transactive Energy in Neurorehabilitation","IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING","","1534-4320","10.1109/TNSRE.2024.3515175","","Advancements in robotic neurorehabilitation have made it imperative to enhance the safety and personalization of physical human-robot interactions (pHRI). Estimation and management of energy transfer between humans and robots is essential for enhancing safety during the rehabilitation. Traditional control methods, which rely on coordinate-based monitoring of robot velocity and external forces, often fail in unstructured environments due to their susceptibility to sensor noise and limited adaptability to individual patient needs. This paper introduces the concept of transactive energy, a coordinate-invariant entity that captures the energy dynamics between the human and the robot during robot-assisted rehabilitation and can be used for personalized robot control. However, estimation of such energy transfer is a complex process and therefore, we have developed a transformer-based model to predict the transactive potential energy. The proposed model is implemented on an ankle rehabilitation robot which is a compliant parallel robot and provides the required three rotational degrees of freedom (DOF). The model learns from the data obtained from the experiments carried out using the ankle robot with five stroke patients on two types of controllers: an impedance controller operated in zero impedance control mode and a trajectory tracking controller. This study provides a baseline, for future research on energy-based control mechanisms in pHRI applications, by utilizing the advanced deep learning models.","2025","2025-02-26 20:43:26","2025-02-26 20:43:26","","46-57","","","33","","","","","","","","","","English","","","","WOS:001380656700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Adaptation models; adaptive learning; Ankle; Assistive robots; DESIGN; Energy exchange; energy transfer; Human-robot interaction; Impedance; IMPEDANCE CONTROL; neurorehabilitation; OPTIMIZATION; physical human-robot interaction; REHABILITATION; ROBOT; Robot kinematics; Robot sensing systems; Robots; Transactive energy; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XFFE2GAV","journalArticle","2024","Li, Y; Yang, XF; Tang, D; Zhou, Z","RDTN: Residual Densely Transformer Network for hyperspectral image classification","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.123939","","Transformer -based methods have achieved significant success in hyperspectral image (HSI) classification, which attribute to the strong capability of capturing the global dependencies from the input. However, the existing Transformer -based HSI classification methods are challenged in retrieving sufficient abound local information using the linear projection modules. Moreover, they do not fully use the hierarchical representations extracted from the original hyperspectral images. To overcome these challenges, this paper proposes a novel transformer model, called Residual Densely Transformer Network (RDTN) to comprehensively exploit the multi -hierarchical features and the local-global dependencies along the spatial-spectral dimensions from the hyperspectral images. Specially, the proposed RDTN is built with two modules: a Cross -Scale Convolution Attention (CSCA) module to extract abundant local spatial-spectral features using the multiscale convolution attention layers, and a Local Residual Transformer Block (LRTB) to respectively capture the abundant global dependencies along the spatial-spectral dimensions. Additionally, LRTB uses a residual connection operation to make full use of the hierarchical representations of all the transformer encoder layers. After acquiring dense global representations, we introduce a Global Residual Connection (GRC) to jointly fuse the local features obtained by CSCA, and then feed the fusion representations into the final avg-pooling layer and a classifier to predict the category. Finally, we conduct the extensive experiments based on four public benchmarks datasets, whose results are demonstrated that the proposed RDTN outperforms the state-of-the-art methods. The codes of this work are available at https://github.com/xiachangxue/DeepHyperX.","2024-09-15","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","250","","","","","","","","","","English","","","","WOS:001228574900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Convolution neural network; Hyperspectral image classification; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R8DPVDHN","journalArticle","2024","Li, DX; Li, BY; Liu, Y","HFSI-TF: Hierarchical Full-Scale Interactive Transformer Model for Object Detection in Remote Sensing Image","IEEE GEOSCIENCE AND REMOTE SENSING LETTERS","","1545-598X","10.1109/LGRS.2024.3482693","","Transformer-based object detection models usually adopt an encoding-decoding architecture that mainly combines self-attention (SA) and multilayer perceptron (MLP). Although this architecture does not require nonmaximum suppression (NMS) and can really achieve end-to-end object detection, it also suffers from the disadvantage of insufficient multiscale object perception in the image, which leads to low accuracy in detecting small objects. Focusing on these issues, a new full-scale bidirectional interactive attention (FSBDIA) mechanism is constructed, thereby a novel hierarchical full-scale interactive transformer (HFSI-TF) model is designed for object detection in remote sensing image (RSI). First, in order to enhance the multiscale perception ability of the model, the FSBDIA mechanism is designed under the guidance of full-scale information. Then, based on FSBDIA, a hierarchical HFSI-TF encoder is constructed to interactively fuse multilayer feature maps layer by layer, thereby obtaining multiscale encoded features of RSI. Finally, a mixed cross attention (MCA) mechanism is also constructed, and an iterative decoding architecture is designed based on it to improve the accuracy of small object detection. Comparative experiments based on two benchmark datasets (i.e., DIOR and HRSC2016) show that the designed HFSI-TF model can effectively improve the accuracy of object detection in RSI, and the model we designed has superior performance compared to other state-of-the-art methods.","2024","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","21","","","","","","","","","","English","","","","WOS:001346122100004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","Accuracy; Computational modeling; Computer architecture; Decoding; Encoding; Feature extraction; Hierarchical full-scale interactive (HFSI); Iterative decoding; mixed cross attention (MCA); object detection; Object detection; remote sensing image (RSI); Semantics; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7XLLS7JZ","journalArticle","2021","Abrol, A; Kapoor, N; Lehana, PK","Fractal-Based Speech Analysis for Emotional Content Estimation","CIRCUITS SYSTEMS AND SIGNAL PROCESSING","","0278-081X","10.1007/s00034-021-01737-2","","Speech emotional content estimation is still a challenge for building robust human-machine interaction systems. Accuracy of emotion estimation depends upon the corpus used for training and the acoustic features employed for modelling the speech signal. Generally, emotion estimation is computationally expensive, and hence, there is a need of developing alternative techniques. In this paper, a low complexity fractal-based technique has been explored. Our hypothesis is that fractal analysis would provide better emotional content estimation because of the nonlinear nature of the speech signals. Fractal analysis involves two important parameters, i.e. fractal dimension and loop area. Fractal dimension has been computed using the Katz algorithm. The investigations using a GMM-based model show that the proposed technique is capable of identifying the emotional content within the given speech signals reliably and accurately. Further, the technique is robust in the sense that it can bear the noise level in the signal up to 10 dB. The analysis also shows that the technique is gender insensitive. The scope of the investigations presented here is limited to phonemic-level analysis, although the technique works efficiently with speech phrases as well.","2021-11","2025-02-26 20:43:26","2025-02-26 20:43:26","","5632-5653","","11","40","","","","","","","","","","English","","","","WOS:000650093100004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","DIMENSION; Emotion estimation; FEATURES; Fractal analysis; Fractal dimension; GMM; Katz algorithm; MODEL; Speech emotion recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PYUTJAZA","journalArticle","2024","Zhang, X; Zhang, XC; Chen, WS; Li, CL; Yu, CY","Improving speech depression detection using transfer learning with wav2vec 2.0 in low-resource environments","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-60278-1","","Depression, a pervasive global mental disorder, profoundly impacts daily lives. Despite numerous deep learning studies focused on depression detection through speech analysis, the shortage of annotated bulk samples hampers the development of effective models. In response to this challenge, our research introduces a transfer learning approach for detecting depression in speech, aiming to overcome constraints imposed by limited resources. In the context of feature representation, we obtain depression-related features by fine-tuning wav2vec 2.0. By integrating 1D-CNN and attention pooling structures, we generate advanced features at the segment level, thereby enhancing the model's capability to capture temporal relationships within audio frames. In the realm of prediction results, we integrate LSTM and self-attention mechanisms. This incorporation assigns greater weights to segments associated with depression, thereby augmenting the model's discernment of depression-related information. The experimental results indicate that our model has achieved impressive F1 scores, reaching 79% on the DAIC-WOZ dataset and 90.53% on the CMDC dataset. It outperforms recent baseline models in the field of speech-based depression detection. This provides a promising solution for effective depression detection in low-resource environments.","2024-04-25","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","1","14","","","","","","","","","","English","","","","WOS:001211032500034","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","NETWORK; TIME","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TVL6T3ZA","journalArticle","2023","Yan, KF","Application of speech software based on mobile network technology in oral English teaching and classroom feedback","SOFT COMPUTING","","1432-7643","10.1007/s00500-023-08433-0","","Mobile network education is a new education model, and the spoken language teaching software based on mobile app device instant feedback is an indispensable part of the model. The use of the software can effectively improve students' speaking skills, as it can provide real-time feedback in class to help students correct pronunciation and grammar mistakes in a timely manner, as well as provide speech analysis and assessment, so that students can better understand their oral expression ability. In addition, the software can also increase students' learning interest and enthusiasm, so that they are more willing to participate in oral English teaching, improve the teaching results and students' participation. The test results of the software verify the effectiveness of the system, and also prove that the software can be used in oral English teaching and classroom feedback. English teaching based on instant voice feedback of mobile app devices is an innovative way of education, which can better meet the needs of students and adapt to the development needs of today's society. It will play an increasingly important role in the future education field.","2023-05-23","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","","","","","","","","","","","English","","","","WOS:000994160900005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;15</p>","","","Mobile internet; Oral English teaching; System research; Wireless network technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E4JZCA54","journalArticle","2021","Shimon, C; Shafat, G; Dangoor, I; Ben-Shitrit, A","Artificial intelligence enabled preliminary diagnosis for COVID-19 from voice cues and questionnairesa)","JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA","","0001-4966","10.1121/10.0003434","","The COVID-19 outbreak was announced as a global pandemic by the World Health Organization in March 2020 and has affected a growing number of people in the past few months. In this context, advanced artificial intelligence techniques are brought to the forefront as a response to the ongoing fight toward reducing the impact of this global health crisis. In this study, potential use-cases of intelligent speech analysis for COVID-19 identification are being developed. By analyzing speech recordings from COVID-19 positive and negative patients, we constructed audio- and symptomatic-based models to automatically categorize the health state of patients, whether they are COVID-19 positive or not. For this purpose, many acoustic features were established, and various machine learning algorithms are being utilized. Experiments show that an average accuracy of 80% was obtained estimating COVID-19 positive or negative, derived from multiple cough and vowel /a/ recordings, and an average accuracy of 83% was obtained estimating COVID-19 positive or negative patients by evaluating six symptomatic questions. We hope that this study can foster an extremely fast, low-cost, and convenient way to automatically detect the COVID-19 disease.","2021-02","2025-02-26 20:43:26","2025-02-26 20:43:26","","1120-1124","","2","149","","","","","","","","","","English","","","","WOS:000630492900007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;9</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B59J97AP","journalArticle","2022","Alnuaim, AA; Zakariah, M; Shukla, PK; Alhadlaq, A; Hatamleh, WA; Tarazi, H; Sureshbabu, R; Ratna, R","Human-Computer Interaction for Recognizing Speech Emotions Using Multilayer Perceptron Classifier","JOURNAL OF HEALTHCARE ENGINEERING","","2040-2295","10.1155/2022/6005446","","Human-computer interaction (HCI) has seen a paradigm shift from textual or display-based control toward more intuitive control modalities such as voice, gesture, and mimicry. Particularly, speech has a great deal of information, conveying information about the speaker's inner condition and his/her aim and desire. While word analysis enables the speaker's request to be understood, other speech features disclose the speaker's mood, purpose, and motive. As a result, emotion recognition from speech has become critical in current human-computer interaction systems. Moreover, the findings of the several professions involved in emotion recognition are difficult to combine. Many sound analysis methods have been developed in the past. However, it was not possible to provide an emotional analysis of people in a live speech. Today, the development of artificial intelligence and the high performance of deep learning methods bring studies on live data to the fore. This study aims to detect emotions in the human voice using artificial intelligence methods. One of the most important requirements of artificial intelligence works is data. The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) open-source dataset was used in the study. The RAVDESS dataset contains more than 2000 data recorded as speeches and songs by 24 actors. Data were collected for eight different moods from the actors. It was aimed at detecting eight different emotion classes, including neutral, calm, happy, sad, angry, fearful, disgusted, and surprised moods. The multilayer perceptron (MLP) classifier, a widely used supervised learning algorithm, was preferred for classification. The proposed model's performance was compared with that of similar studies, and the results were evaluated. An overall accuracy of 81% was obtained for classifying eight different emotions by using the proposed model on the RAVDESS dataset.","2022-03-28","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","2022","","","","","","","","","","English","","","","WOS:000820172900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;35<br/>Total Times Cited:&nbsp;&nbsp;35<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","AFFECT RECOGNITION; FEATURES; ROBUSTNESS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V6WHITHM","journalArticle","2021","Tankus, A; Lustig, Y; Fried, I; Strauss, I","Impaired Timing of Speech-Related Neurons in the Subthalamic Nucleus of Parkinson Disease Patients Suffering Speech Disorders","NEUROSURGERY","","0148-396X","10.1093/neuros/nyab293","","BACKGROUND: Our previous study found degradation to subthalamic neuronal encoding of speech features in Parkinson disease (PD) patients suffering from speech disorders. OBJECTIVE: To find how timing of speech-related neuronal firing changes in PD patients with speech disorders compared to PD patients without speech disorders. METHODS: During the implantation of deep brain stimulator (DBS), we recorded the activity of single neurons in the subthalamic nucleus (STN) of 18 neurosurgical patients with PD while they articulated, listened to, or imagined articulation of 5 vowel sounds, each following a beep. We compared subthalamic activity of PD patients with (n =10) vs without speech disorders. RESULTS: In this comparison, patients with speech disorders had longer reaction times and shorter lengths of articulation. Their speech-related neuronal activity preceding speech onset (planning) was delayed relative to the beep, but the time between this activity and the emission of speech sound was similar. Notwithstanding, speech-related neuronal activity following the onset of speech (feedback) was delayed when computed relative to the onset. Only in these patients was the time lag of planning neurons significantly correlated with the reaction time. Neuronal activity in patients with speech disorders was delayed during imagined articulation of vowel sounds but earlier during speech perception. CONCLUSION: Our findings indicate that longer reaction times in patients with speech disorders are due to STN or earlier activity of the speech control network. This is a first step in locating the source(s) of PD delays within this network and is therefore of utmost importance for future treatment of speech disorders.","2021-11","2025-02-26 20:43:26","2025-02-26 20:43:26","","800-809","","5","89","","","","","","","","","","English","","","","WOS:000728383600025","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","BILATERAL STIMULATION; DEEP BRAIN-STIMULATION; DISCRIMINATION; Human neurophysiology; INDIVIDUALS; MEDICATION; MOVEMENTS; Parkinson disease; PERCEPTION; POTENTIALS; RHYTHM; Single neuron recordings; Speech disorders; Speech reaction time; Subthalamic nucleus; Timing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5BTWKZTV","journalArticle","2025","Wang, LF; Wang, YL; Ren, WJ; Yu, J; Chang, XY; Guo, XD; Hu, LH","A dual encoder LDCT image denoising model based on cross-scale skip connections☆","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2024.128741","","LDCT image denoising is crucial in medical imaging as it aims to minimize patient radiation exposure while maintaining diagnostic image quality. However, current convolutional neural network-based denoising methods struggle to incorporate global contexts, often focusing solely on local features. This limitation poses a significant challenge. To address this, a dual encoder denoising model is introduced that utilizes the Transformer model's proficiency in capturing long-range dependencies and global context. This model integrates the Transformer branch and the convolutional branch in the encoder. By concatenating the features of these two different branches, the model can capture both global and local image features, substantially enhancing denoising efficacy. A cross-scale skip connection mechanism is introduced to integrate the encoder's low-level features with the decoder' s high-level features, enriching contextual information and preserving image details. In addition, to meet the requirements of multi-scale feature fusion, the decoder is equipped with different multi-scale convolution modules to optimize feature processing. The number of layers in these modules gradually decreases as the depth of the decoder increases. In order to enhance the discriminative ability of the model, a multi-scale discriminator is also introduced, which effectively improves the recognition ability of the image by extracting features from four different scales. Consequently, our approach demonstrates remarkable performance in reducing noise and improving LDCT image quality, as evidenced by the substantial improvements in PSNR (17.75%) and SSIM (7.31%) values.","2025-01-14","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","613","","","","","","","","","","English","","","","WOS:001368551500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","Cross-scale skip connection; GENERATIVE ADVERSARIAL NETWORK; Low-dose CT; Multi-scale convolution modules; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3V2MISBJ","journalArticle","2024","Yilmaz, M; Fondrie, WE; Bittremieux, W; Melendez, CF; Nelson, R; Ananth, V; Oh, S; Noble, WS","Sequence-to-sequence translation from mass spectra to peptides with a transformer model","NATURE COMMUNICATIONS","","2041-1723","10.1038/s41467-024-49731-x","","A fundamental challenge in mass spectrometry-based proteomics is the identification of the peptide that generated each acquired tandem mass spectrum. Approaches that leverage known peptide sequence databases cannot detect unexpected peptides and can be impractical or impossible to apply in some settings. Thus, the ability to assign peptide sequences to tandem mass spectra without prior information-de novo peptide sequencing-is valuable for tasks including antibody sequencing, immunopeptidomics, and metaproteomics. Although many methods have been developed to address this problem, it remains an outstanding challenge in part due to the difficulty of modeling the irregular data structure of tandem mass spectra. Here, we describe Casanovo, a machine learning model that uses a transformer neural network architecture to translate the sequence of peaks in a tandem mass spectrum into the sequence of amino acids that comprise the generating peptide. We train a Casanovo model from 30 million labeled spectra and demonstrate that the model outperforms several state-of-the-art methods on a cross-species benchmark dataset. We also develop a version of Casanovo that is fine-tuned for non-enzymatic peptides. Finally, we demonstrate that Casanovo's superior performance improves the analysis of immunopeptidomics and metaproteomics experiments and allows us to delve deeper into the dark proteome. Identification of the peptide that generates each acquired tandem mass spectrum is a fundamental challenge in mass spectrometry-based proteomics. Here, the authors present Casanovo, a machine learning model that translates the sequence of peaks in a tandem mass spectrum into the sequence of amino acids that comprise the generating peptide.","2024-07-30","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","1","15","","","","","","","","","","English","","","","WOS:001281271000030","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","IDENTIFICATION; STRATEGY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M5576FTP","journalArticle","2024","Li, P; Hu, Y","Deep magnetic resonance fingerprinting based on Local and Global Vision Transformer","MEDICAL IMAGE ANALYSIS","","1361-8415","10.1016/j.media.2024.103198","","To mitigate systematic errors in magnetic resonance fingerprinting (MRF), the precomputed dictionary is usually computed with minimal granularity across the entire range of tissue parameters. However, the dictionary grows exponentially with the number of parameters increase, posing significant challenges to the computational efficiency and matching accuracy of pattern-matching algorithms. Existing works, primarily based on convolutional neural networks (CNN), focus solely on local information to reconstruct multiple parameter maps, lacking in-depth investigations on the MRF mechanism. These methods may not exploit long-distance redundancies and the contextual information within voxel fingerprints introduced by the Bloch equation dynamics, leading to limited reconstruction speed and accuracy. To overcome these limitations, we propose a novel end-to-end neural network called the Local and Global Vision Transformer (LG-ViT) for MRF parameter reconstruction. Our proposed LG-ViT employs a multi-stage architecture that effectively reduces the computational overhead associated with the high-dimensional MRF data and the transformer model. Specifically, a local Transformer encoder is proposed to capture contextual information embedded within voxel fingerprints and local correlations introduced by the interconnected human tissues. Additionally, a global Transformer encoder is proposed to leverage long-distance dependencies arising from shared characteristics among different tissues across various spatial regions. By incorporating MRF physics-based data priors and effectively capturing local and global correlations, our proposed LG-ViT can achieve fast and accurate MRF parameter reconstruction. Experiments on both simulation and in vivo data demonstrate that the proposed method enables faster and more accurate MRF parameter reconstruction compared to state-of-the-art deep learning-based methods.","2024-07","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","95","","","","","","","","","","English","","","","WOS:001298818800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Deep learning; Magnetic resonance fingerprinting; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XGPJ7CG8","journalArticle","2024","Olorunnimbe, K; Viktor, H","Ensemble of temporal Transformers for financial time series","JOURNAL OF INTELLIGENT INFORMATION SYSTEMS","","0925-9902","10.1007/s10844-024-00851-2","","The accuracy of price forecasts is important for financial market trading strategies and portfolio management. Compared to traditional models such as ARIMA and other state-of-the-art deep learning techniques, temporal Transformers with similarity embedding perform better for multi-horizon forecasts in financial time series, as they account for the conditional heteroscedasticity inherent in financial data. Despite this, the methods employed in generating these forecasts must be optimized to achieve the highest possible level of precision. One approach that has been shown to improve the accuracy of machine learning models is ensemble techniques. To this end, we present an ensemble approach that efficiently utilizes the available data over an extended timeframe. Our ensemble combines multiple temporal Transformer models learned within sliding windows, thereby making optimal use of the data. As combination methods, along with an averaging approach, we also introduced a stacking meta-learner that leverages a quantile estimator to determine the optimal weights for combining the base models of smaller windows. By decomposing the constituent time series of an extended timeframe, we optimize the utilization of the series for financial deep learning. This simplifies the training process of a temporal Transformer model over an extended time series while achieving better performance, particularly when accounting for the non-constant variance of financial time series. Our experiments, conducted across volatile and non-volatile extrapolation periods, using 20 companies from the Dow Jones Industrial Average show more than 40% and 60% improvement in predictive performance compared to the baseline temporal Transformer.","2024-08","2025-02-26 20:43:26","2025-02-26 20:43:26","","1087-1111","","4","62","","","","","","","","","","English","","","","WOS:001171457400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Deep learning; Ensemble; Financial price prediction; Multi-horizon forecast; Stock market forecast; Temporal Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2ZH4YMZK","journalArticle","2024","Zhao, QS; Dong, LQ; Liu, M; Kong, LQ; Chu, XH; Hui, M; Zhao, YJ","Visible/Infrared Image Registration Based on Region-Adaptive Contextual Multifeatures","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2024.3385088","","Visible (VIS) and infrared image registration is a challenging problem in computer vision due to the significant differences in appearance and physical properties between the two modalities. A single feature is not enough to remove nonlinear differences, and the matching method faces a trade-off between the high-resolution feature map and the transformer model. In this article, we propose a novel method called adaptive-neighborhood contextual multifeatures (ANCM-Net) for VIS/infrared image registration. Our method addresses the limitations of existing approaches by incorporating depth features and cross-modal similar contour features to form contextual feature representations. Additionally, we propose a region-spanning adaptive cross-attention module to handle low spatial resolution and redundancy in attention computation. This module enables attentional encoding of limited information in the attention location and cross-modal adaptive region through attention region adjustment. In the matching task, we compute an adaptive attention region for each pixel point in the cross-modal image and encode and match the depth features and edge features together. As a result, ANCM-Net not only preserves the long-range dependency of the image feature structure but also achieves fine-grained attention between highly correlated pixels. By extracting cross-modal consistent contextual features to compensate for modality-specific information, our approach improves the cross-modal matching performance. Extensive experiments on real-world captured thermal infrared (TIR) and VIS datasets demonstrate that ANCM-Net outperforms existing image matching methods.","2024","2025-02-26 20:43:26","2025-02-26 20:43:26","","","","","62","","","","","","","","","","English","","","","WOS:001205148500041","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","Adaptive-neighborhood; contextual multifeatures; cross-modality matching; Deep learning; Feature extraction; Image edge detection; image matching; Image matching; INFRARED IMAGE; Task analysis; transformer; Transformers; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WN9UUNJS","journalArticle","2023","Akbari, M; Mostafaei, M; Rezaei-Zare, A","Estimation of Hot-Spot Heating in OIP Transformer Bushings Due to Geomagnetically Induced Current","IEEE TRANSACTIONS ON POWER DELIVERY","","0885-8977","10.1109/TPWRD.2022.3212322","","This paper studies the temperature distribution in the transformer bushing in the presence of Geomagnetically Induced Current (GIC). The thermal stress can significantly affect the transformer bushing reliability and lifespan. However, the existing research works have focused on thermal modeling of transformer bushing due to loading, and the impact of GIC on this valuable apparatus has not been investigated yet. In this paper, the hot-spot temperature (HST) in an oil-impregnated paper (OIP) bushing is studied during the GIC. The harmonic currents at various GIC levels are obtained from the EMTP-RV time-domain simulations using a detailed topological transformer model. Based on a frequency-dependent model of the bushing resistance, the total power loss is calculated by taking into account the GIC, load current, and harmonic currents. Subsequently, the temperature distribution in the modeled bushing is obtained from the finite-element method (FEM), considering all thermal mechanisms, including fluid flow, internal convection, and thermal conduction. In addition, a Thermal Equivalent Circuit (TEC) is developed for the bushing that replicates the FEM results. The simulation results reveal that the bushing HST may exceeds the recommended permissible temperature of the IEEE bushing standard. This situation may result in bushing insulation deterioration and reduction of the bushing lifespan.","2023-04","2025-02-26 20:43:26","2025-02-26 20:43:26","","1277-1285","","2","38","","","","","","","","","","English","","","","WOS:000967198300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Circuit faults; computational fluid dynamics (CFD); DESIGN; Finite element analysis; finite element method; geomagnetic disturbance (GMD); geomagnetically induced current (GIC); Harmonic analysis; HIGH-VOLTAGE BUSHINGS; hot-spot temperature; INSULATION; Insulators; MODEL; Oil insulation; POWER-SYSTEM; SIMULATION; Temperature distribution; TEMPERATURE DISTRIBUTION; thermal modeling; Transformer bushing; Transformer cores; TRANSMISSION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IJI5R9JT","journalArticle","2022","Liu, CF; Liu, DR; Mu, L","Improved Transformer Model for Enhanced Monthly Streamflow Predictions of the Yangtze River","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3178521","","Over the past few decades, floods have severely damaged production and daily life, causing enormous economic losses. Streamflow forecasts prepare us to fight floods ahead of time and mitigate the disasters arising from them. Streamflow forecasting demands a high-capacity model that can make precise long-term predictions. Traditional physics-based hydrological models can only make short-term predictions for streamflow, while current machine learning methods can only obtain acceptable results in normal years without floods. Previous studies have demonstrated a close relation between El Nino-Southern Oscillation (ENSO) and the streamflow of the Yangtze River. However, traditional models, holding the encoder-decoder architecture, only have one encoder block that can not support bivariate time series forecasting. In this study, a transformer-based double-encoder-enabled model was proposed, called the double-encoder Transformer, with a distinctive characteristic: ""cross-attention"" mechanism that can capture the relation between two time series sequences. Using river flow observation collected by the Yangtze River Water Resources Commission and El Nino-Southern Oscillation (ENSO) observation collected by the National Oceanic and Atmospheric Administration, the model can achieve better performance. By using variational mode decomposition (VMD) technique for preprocessing, the model can make precise long-term predictions for the river flow of the Yangtze River. A monthly prediction of 21 years (from January 1998 to December 2018) was made, and the results indicate that the double-encoder Transformer outperforms mainstream time series models.","2022","2025-02-26 20:43:27","2025-02-26 20:43:27","","58240-58253","","","10","","","","","","","","","","English","","","","WOS:000808035400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;30<br/>Total Times Cited:&nbsp;&nbsp;30<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","ANN; Atmospheric modeling; deep learning; DISCHARGE; ENSO; flood forecasts; Floods; Numerical models; Predictive models; Rivers; Streamflow prediction; SWAT; Time series analysis; transformer; Transformers; variational modal decomposition; Yangtze River","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V5BGZNIM","journalArticle","2021","Gelin, L; Daniel, M; Pinquier, J; Pellegrini, T","End-to-end acoustic modelling for phone recognition of young readers","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2021.08.003","","Automatic recognition systems for child speech are lagging behind those dedicated to adult speech in the race of performance. This phenomenon is due to the high acoustic and linguistic variability present in child speech caused by their body development, as well as the lack of available child speech data. Young readers' speech additionally displays peculiarities, such as slow reading rate and presence of reading mistakes, that hardens the task. This work attempts to tackle the main challenges in phone acoustic modelling for young child speech with limited data and improve understanding of strengths and weaknesses of a wide selection of model architectures in this domain. We find that transfer learning techniques are highly efficient on end-to-end architectures for adult-to-child adaptation with a small amount of child speech data. Through transfer learning, a Transformer model complemented with a Connectionist Temporal Classification (CTC) objective function, reaches a phone error rate of 28.1%, outperforming a state-of-the-art DNN-HMM model by 6.6% relative, as well as other end-to-end architectures by more than 8.5% relative. An analysis of the models' performance on two specific reading tasks (isolated words and sentences) is provided, showing the influence of the utterance length on attention-based and CTC-based models. The Transformer+CTC model displays an ability to better detect reading mistakes made by children, which can be attributed to the CTC objective function effectively constraining the attention mechanisms to be monotonic.","2021-11","2025-02-26 20:43:27","2025-02-26 20:43:27","","71-84","","","134","","","","","","","","","","English","","","","WOS:000707045500003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","Child speech; Connectionist temporal classification; HYBRID; Low-resource; Phone recognition; SPEECH RECOGNITION; Transfer learning; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TUE4C26K","journalArticle","2024","Sun, HQ; Pang, YW; Cao, JL; Xie, J; Li, XL","Transformer-Based Stereo-Aware 3D Object Detection From Binocular Images","IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS","","1524-9050","10.1109/TITS.2024.3462795","","Transformers have shown promising progress in various visual object detection tasks, including monocular 2D/3D detection and surround-view 3D detection. More importantly, the attention mechanism in the Transformer model and the 3D information extraction in binocular stereo are both similarity-based. However, directly applying existing Transformer-based detectors to binocular stereo 3D object detection leads to slow convergence and significant precision drops. We argue that a key cause of that defect is that existing Transformers ignore the binocular-stereo-specific image correspondence information. In this paper, we explore the model design of Transformers in binocular 3D object detection, focusing particularly on extracting and encoding task-specific image correspondence information. To achieve this goal, we present TS3D, a Transformer-based Stereo-aware 3D object detector. In the TS3D, a Disparity-Aware Positional Encoding (DAPE) module is proposed to embed the image correspondence information into stereo features. The correspondence is encoded as normalized sub-pixel-level disparity and is used in conjunction with sinusoidal 2D positional encoding to provide the 3D location information of the scene. To enrich multi-scale stereo features, we propose a Stereo Preserving Feature Pyramid Network (SPFPN). The SPFPN is designed to preserve the correspondence information while fusing intra-scale and aggregating cross-scale stereo features. Our proposed TS3D achieves a 41.29% Moderate Car detection average precision on the KITTI test set and takes 88 ms to detect objects from each binocular image pair. It is competitive with advanced counterparts in terms of both precision and inference speed.","2024-12","2025-02-26 20:43:27","2025-02-26 20:43:27","","19675-19687","","12","25","","","","","","","","","","English","","","","WOS:001328981400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","3D object detection; feature pyramid; image correspondence; positional encoding; Stereo vision; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BDW55VLR","journalArticle","2024","Sharma, V; Gupta, AK; Sharma, A; Saini, S","A unified approach for continuous sign language recognition and translation","INTERNATIONAL JOURNAL OF DATA SCIENCE AND ANALYTICS","","2364-415X","10.1007/s41060-024-00549-2","","Sign language recognition (SLR) is an emerging technology that shows potential in facilitating communication between the deaf and the hearing people. The sign language system employs a recognition module to generate glosses from videos of sign language. Subsequently, a translation module is employed to convert these glosses into spoken sentences. In recent years, researchers have implemented neural machine translation (NMT) techniques for sign language translation (SLT). These methods typically rely on extensive training using large corpus. Nevertheless, the publicly accessible SLT dataset is severely restricted, resulting in the inaccuracy of generated tokens. Moreover, the predominant focus of existing research endeavors is primarily directed toward either the stage of recognition or the stage of translation individually, with comparatively less emphasis on concurrently addressing both stages. Hence, in this work, we propose a continuous sign language recognition and translation (CSLRT) system that places equal emphasis on both modules. We assess the accuracy and efficiency of recognition and translation on the newly introduced words dataset for two-hand Indian sign language (W-THISL). In order to improve the accuracy of recognition, pose features are extracted and subsequently inputted into the proposed TCN (temporal convolution network) architecture. The SLT pipeline is proposed utilizing a pretrained t5 (text-to-text transfer transformer) transformer model. The empirical findings indicate that the system that was created exhibits a recognition rate of 99.6% and a BLEU-1 score of 81.24.","2024-04-29","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","","","","","","","","","","","English","","","","WOS:001209865600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","Indian sign language (ISL); Sign language recognition (SLR); Sign language translation (SLT); Temporal convolutional network (TCN); Text-to-text transfer transformer (t5)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PT2T7Q3X","journalArticle","2024","Zhou, ZL; Yeung, W; Soleymani, S; Gravel, N; Salcedo, M; Li, S; Kannan, N","Using explainable machine learning to uncover the kinase-substrate interaction landscape","BIOINFORMATICS","","1367-4803","10.1093/bioinformatics/btae033","","Motivation Phosphorylation, a post-translational modification regulated by protein kinase enzymes, plays an essential role in almost all cellular processes. Understanding how each of the nearly 500 human protein kinases selectively phosphorylates their substrates is a foundational challenge in bioinformatics and cell signaling. Although deep learning models have been a popular means to predict kinase-substrate relationships, existing models often lack interpretability and are trained on datasets skewed toward a subset of well-studied kinases.Results Here we leverage recent peptide library datasets generated to determine substrate specificity profiles of 300 serine/threonine kinases to develop an explainable Transformer model for kinase-peptide interaction prediction. The model, trained solely on primary sequences, achieved state-of-the-art performance. Its unique multitask learning paradigm built within the model enables predictions on virtually any kinase-peptide pair, including predictions on 139 kinases not used in peptide library screens. Furthermore, we employed explainable machine learning methods to elucidate the model's inner workings. Through analysis of learned embeddings at different training stages, we demonstrate that the model employs a unique strategy of substrate prediction considering both substrate motif patterns and kinase evolutionary features. SHapley Additive exPlanation (SHAP) analysis reveals key specificity determining residues in the peptide sequence. Finally, we provide a web interface for predicting kinase-substrate associations for user-defined sequences and a resource for visualizing the learned kinase-substrate associations.Availability and implementation All code and data are available at https://github.com/esbgkannan/Phosformer-ST. Web server is available at https://phosformer.netlify.app.","2024-02-01","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","2","40","","","","","","","","","","English","","","","WOS:001157921900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;16</p>","","","PROTEIN-KINASES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QQB7AVL5","journalArticle","2023","Chen, JR; Lu, YQ; Zhang, Y; Huang, F; Qin, JC","A management knowledge graph approach for critical infrastructure protection: Ontology design, information extraction and relation prediction","INTERNATIONAL JOURNAL OF CRITICAL INFRASTRUCTURE PROTECTION","","1874-5482","10.1016/j.ijcip.2023.100634","","Critical Infrastructures (CI) underpin the basic functioning of society and the economy. Proper governance of CI security management remains a crucial challenge. This study aims to construct a knowledge graph for modeling CI protection. While the previous research has focused on threat intelligence modeling and open knowledge bases, they miss considering the defense side. Accordingly, we propose a knowledge graph for critical infrastructure protection, CIPKG, that extends the management ontology to include the defense side. It addresses the cross-industry and cross-time information gaps that occur in the process of CI protection management, making it more comprehensive in structure than the existing knowledge graph. We employ simplified Structured Threat Information Expression as attack ontology and design a new ontology for the defense side, which could combine with the existing threat ontology to form the CI protection knowledge graph. To dynamically extract information from emerging knowledge, we employ a Bi-directional Long Short-Term Memory and Conditional Random Field model with pre-trained cybersecurity domain-specific Bidirectional Encoder Representations from Transformers to recognize the named entities from CI regulations and standards. To associate the threat part with the management portion of the knowledge graph, we adopt the Knowledge Graph Bidirectional Encoder Representations from Transformer model to capture the semantic information and predict the relationship between threat and management. After information extraction and relation prediction, we build a knowledge graph with 529,360 nodes and about 3,335,000 edges.","2023-12","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","43","","","","","","","","","","English","","","","WOS:001071260800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Critical infrastructure; Knowledge graph; Named entity recognition; Ontology; Relation prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RIAZWH9K","journalArticle","2023","Chen, TS; Mo, LF","Swin-Fusion: Swin-Transformer with Feature Fusion for Human Action Recognition","NEURAL PROCESSING LETTERS","","1370-4621","10.1007/s11063-023-11367-1","","Humanaction recognition based on still images is one of themost challenging computer vision tasks. In the past decade, convolutional neural networks (CNNs) have developed rapidly and achieved good performance in human action recognition tasks based on still images. Due to the absence of the remote perception ability of CNNs, it is challenging to have a global structural understanding of human behavior and the overall relationship between the behavior and the environment. Recently, transformer-based models have been making a splash in computer vision, even reaching SOTA in several vision tasks. We explore the transformer's capability in human action recognition based on still images and add a simple but effective feature fusion module based on the Swin-Transformer model. More specifically, we propose a newtransformer-basedmodel for behavioral feature extraction that uses a pre-trained SwinTransformer as the backbone network. Swin-Transformer's distinctive hierarchical structure, combined with the feature fusion module, is used to extract and fuse multi-scale behavioral information. Extensive experiments were conducted on five still image-based human action recognition datasets, including the Li's action dataset, the Stanford-40 dataset, the PPMI-24 dataset, the AUC-V1 dataset, and the AUC-V2 dataset. Results indicate that our proposed Swin-Fusion model achieves better behavior recognition than previously improved CNNbased models by sharing and reusing feature maps of different scales at multiple stages, without modifying the original backbone training method and with only increasing training resources by 1.6%. The code and models will be available at https://github.com/ cts4444/ Swin-Fusion.","2023-12","2025-02-26 20:43:27","2025-02-26 20:43:27","","11109-11130","","8","55","","","","","","","","","","English","","","","WOS:001033645700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Action recognition; Feature pyramid; Image classification; NETWORK; Swin-Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZCVH6T43","journalArticle","2023","Zheng, FJ; Lin, S; Zhou, W; Huang, H","A Lightweight Dual-Branch Swin Transformer for Remote Sensing Scene Classification","REMOTE SENSING","","2072-4292","10.3390/rs15112865","","The main challenge of scene classification is to understand the semantic context information of high-resolution remote sensing images. Although vision transformer (ViT)-based methods have been explored to boost the long-range dependencies of high-resolution remote sensing images, the connectivity between neighboring windows is still limited. Meanwhile, ViT-based methods commonly contain a large number of parameters, resulting in a huge computational consumption. In this paper, a novel lightweight dual-branch swin transformer (LDBST) method for remote sensing scene classification is proposed, and the discriminative ability of scene features is increased through combining a ViT branch and convolutional neural network (CNN) branch. First, based on the hierarchical swin transformer model, LDBST divides the input features of each stage into two parts, which are then separately fed into the two branches. For the ViT branch, a dual multilayer perceptron structure with a depthwise convolutional layer, termed Conv-MLP, is integrated into the branch to boost the connections with neighboring windows. Then, a simple-structured CNN branch with maximum pooling preserves the strong features of the scene feature map. Specifically, the CNN branch lightens the LDBST, by avoiding complex multi-head attention and multilayer perceptron computations. To obtain better feature representation, LDBST was pretrained on the large-scale remote scene classification images of the MLRSN and RSD46-WHU datasets. These two pretrained weights were fine-tuned on target scene classification datasets. The experimental results showed that the proposed LDBST method was more effective than some other advanced remote sensing scene classification methods.","2023-05-31","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","11","15","","","","","","","","","","English","","","","WOS:001005659800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","convolutional neural networks (CNNs); remote sensing scene classification; transfer learning; vision transformer (ViT)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6PIJ6ML2","journalArticle","2023","Ma, JH; Dan, JP","Long-Term Structural State Trend Forecasting Based on an FFT-Informer Model","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13042553","","Machine learning has been widely applied in structural health monitoring. While most existing methods, which are limited to forecasting structural state evolution of large infrastructures. forecast the structural state in a step-by-step manner, extracting feature of structural state trends and the negative effects of data collection under abnormal conditions are big challenges. To address these issues, a long-term structural state trend forecasting method based on long sequence time-series forecasting (LSTF) with an improved Informer model integrated with Fast Fourier transform (FFT) is proposed, named the FFT-Informer model. In this method, by using FFT, structural state trend features are represented by extracting amplitude and phase of a certain period of data sequence. Structural state trend, a long sequence, can be forecasted in a one-forward operation by the Informer model that can achieve high inference speed and accuracy of prediction based on the Transformer model. Furthermore, a Hampel filter that filters the abnormal deviation of the data sequence is integrated into the Multi-head ProbSparse self-attention in the Informer model to improve forecasting accuracy by reducing the effect of abnormal data points. Experimental results on two classical data sets show that the FFT-Informer model achieves high and stable accuracy and outperforms the comparative models in forecasting accuracy. It indicates that this model can effectively forecast the long-term state trend change of a structure and is proposed to be applied to structural state trend forecasting and early damage warning.","2023-02","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","4","13","","","","","","","","","","English","","","","WOS:000938253200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","FEATURE-EXTRACTION; FFT; FFT-Informer; Informer model; LOAD; structural health monitoring; time series forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2CFAEU2L","journalArticle","2023","Hadwan, M; Alsayadi, HA; AL-Hagree, S","An End-to-End Transformer-Based Automatic Speech Recognition for Qur?an Reciters","CMC-COMPUTERS MATERIALS & CONTINUA","","1546-2218","10.32604/cmc.2023.033457","","The attention-based encoder-decoder technique, known as the trans-former, is used to enhance the performance of end-to-end automatic speech recognition (ASR). This research focuses on applying ASR end-toend transformer-based models for the Arabic language, as the researchers' community pays little attention to it. The Muslims Holy Qur'an book is written using Arabic diacritized text. In this paper, an end-to-end transformer model to building a robust Qur'an vs. recognition is proposed. The acoustic model was built using the transformer-based model as deep learning by the PyTorch framework. A multi-head attention mechanism is utilized to represent the encoder and decoder in the acoustic model. A Mel filter bank is used for feature extraction. To build a language model (LM), the Recurrent Neural Network (RNN) and Long short-term memory (LSTM) were used to train an n-gram word-based LM. As a part of this research, a new dataset of Qur'an verses and their associated transcripts were collected and processed for training and evaluating the proposed model, consisting of 10 h of .wav recitations performed by 60 reciters. The experimental results showed that the proposed end-to-end transformer-based model achieved a significant low character error rate (CER) of 1.98% and a word error rate (WER) of 6.16%. We have achieved state-of-the-art end-to-end transformer-based recognition for Qur'an reciters.","2023","2025-02-26 20:43:27","2025-02-26 20:43:27","","3471-3487","","2","74","","","","","","","","","","English","","","","WOS:000897528400010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","ALGORITHM; Attention-based encoder-decoder; diacritized arabic text; FEATURE-SELECTION; LEARNING APPROACH; long short-term memory; OPTIMIZATION; qur?an reciters recognition; RECITATION; recurrent neural network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4VP3MAYN","journalArticle","2023","Li, QL; Wang, Y; Shao, YD; Li, L; Hao, H","A comparative study on the most effective machine learning model for blast loading prediction: From GBDT to Transformer","ENGINEERING STRUCTURES","","0141-0296","10.1016/j.engstruct.2022.115310","","In this paper, we present a rigorous comparative study to assess and identify the most effective machine learning model for blast loading prediction. Blast loads are known to produce catastrophic effects including structural collapse and personnel fatality. Accurate and efficient prediction of these extreme loads using empirical methods and numerical solvers remains a challenging problem. Machine learning provides a promising alternative solution, which has been increasingly used in various engineering applications. However, there is seldom any analysis or justification of the selection of machine learning method that would lead to the best performance for such applications. For example, most existing machine learning-based approaches for blast loading prediction utilise the classic multi-layer perceptron (MLP) network with no justifications of their suitability and efficiency nor attempts of leveraging other state-of-the-art neural network architectures. In this study, four well-known machine learning models, including one ensemble tree method and three neural networks of different types, are investigated to demonstrate the effectiveness of different machine learning methods for blast loading prediction. It is showcased using BLEVE (boiling liquid expanding vapour explosion) pressure prediction that the Transformer model achieves the best performance, reaching a relative error of 3.5% and R2 0.997 that outperforms the existing MLP approach (relative error 6.0%, R2 0.985) with a clear margin. This study shows that the Transformer network is an effective tool for prediction of blast loading from BLEVE as well as other explosion sources.","2023-02-01","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","276","","","","","","","","","","English","","","","WOS:000902049300004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;26<br/>Total Times Cited:&nbsp;&nbsp;27<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Blast loading; BLEVE; ENERGY; EXPLOSION OVERPRESSURE CALCULATION; Machine learning; Neural network; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GT25S4VN","journalArticle","2021","Sukanya, G; Priyadarshini, J","A Meta Analysis of Attention Models on Legal Judgment Prediction System","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","Artificial Intelligence in legal research is transforming the legal area in manifold ways. Pendency of court cases is a long-lasting problem in the judiciary due to various reasons such as lack of judges, lack of technology in legal services and the legal loopholes. The judicial system has to be more competent and more reliable in providing justice on time. One of the major causes of pending cases is the lack of legal intelligence to assist the litigants. The study in this paper reviews the challenges faced by judgment prediction system due to lengthy case facts using deep learning model. The Legal Judgment prediction system can help lawyers, judges and civilians to predict the win or loss rate, punishment term and applicable law articles for new cases. Besides, the paper reviews current encoding and decoding architecture with attention mechanism of transformer model that can be used for Legal Judgment Prediction system. Natural Language Processing using deep learning is an exploring field and there is a need for research to evaluate the current state of the art at the intersection of good text processing and feature representation with a deep learning model. This paper aims to develop a systematic review of existing methods used in the legal judgment prediction system and about the Hierarchical Attention Neural network model in detail. This can also be used in other applications such as legal document classification, sentimental analysis, news classification, text translation, medical reports and so on.","2021-02","2025-02-26 20:43:27","2025-02-26 20:43:27","","531-538","","2","12","","","","","","","","","","English","","","","WOS:000630189900067","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","hierarchical attention neural network; Legal judgment prediction; NEURAL-NETWORK; text processing; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RUA46WVH","journalArticle","2021","Zhang, XH; Ma, J; Li, YM; Wang, P; Liu, YCA","Few-shot learning of Parkinson's disease speech data with optimal convolution sparse kernel transfer learning","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2021.102850","","The classification of Parkinson's disease speech data is useful and popular. However, the existing public Parkinson's disease(PD) speech datasets are characterized by small sample sizes, and the possible reason is that labeled speech data from PD patients are scarce. To solve the few-shot problem, a PD classification algorithm based on sparse kernel transfer learning combined with simultaneous sample and feature selection is proposed in this paper. Sparse kernel transfer learning is used to extract the effective structural information of PD speech features from public datasets as source domain data, and the fast alternating direction method of multipliers (ADMM) iteration is improved to enhance the information extraction performance. First, features are extracted from a public speech dataset to construct a feature dataset as the source domain. Then, the PD target domain, including the training and test datasets, is encoded by convolution sparse coding, which can extract more indepth information. Next, simultaneous optimization is implemented. To further improve the classification performance, a convolution kernel optimization mechanism is designed. In the experimental section, two representative PD speech datasets are used for verification; the first dataset is a frequently used public dataset, and the second dataset is constructed by the authors. Over ten relevant algorithms are compared with the proposed method. The results show that the proposed algorithm achieves obvious improvements in terms of classification accuracy. The study also found that the improvements are considerable when compared with nontransfer learning approaches, demonstrating that the proposed transfer learning approach is more effective and has an acceptable time cost.","2021-08","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","69","","","","","","","","","","English","","","","WOS:000685656200008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Convolution sparse coding; Few-shot learning; MULTIPLE TYPES; Simultaneous selection; Transfer learning; VOICE RECORDINGS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RGC5UM83","journalArticle","2023","Xiong, ZB; Cai, ZP; Hu, CQ; Takabi, D; Li, W","Towards Neural Network-Based Communication System: Attack and Defense","IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING","","1545-5971","10.1109/TDSC.2022.3203965","","Recent progress has witnessed the excellent success of neural networks in many emerging applications, such as image recognition, text classification, and speech analysis. In order to achieve secure communication, the utilization of neural networks has been realized yet has not raised sufficient research attention. In addition, the existing neural network-based communication system falls short due to its critical security flaws. In this article, we investigate the security vulnerabilities of the existing neural communication system. Based on our analysis, we design two kinds of attack models, including target man-in-the-middle attack and target fraud attack. After that, to improve the security performance of neural communication systems, we develop a new defense mechanism to facilitate two-way secure communication by separating secret key from plaintext and incorporating defensive loss into the training process. Moreover, we show the effectiveness of our proposed neural communication system via theoretical proof. Finally, we implement comprehensive real data experiments to evaluate the performance of our attack and defense methods from the aspects of classification accuracy, communication efficiency and communication qualify, which confirms the advantages of our proposed neural communication system compared with the state-of-the-art.","2023-07","2025-02-26 20:43:27","2025-02-26 20:43:27","","3238-3250","","4","20","","","","","","","","","","English","","","","WOS:001029054600038","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","adversarial examples; deep learning; generative adversarial networks; Secure communication","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S7VTCFAS","journalArticle","2022","Rizhinashvili, D; Sham, AH; Anbarjafari, G","Gender Neutralisation for Unbiased Speech Synthesising","ELECTRONICS","","2079-9292","10.3390/electronics11101594","","Machine learning can encode and amplify negative biases or stereotypes already present in humans, resulting in high-profile cases. There can be multiple sources encoding the negative bias in these algorithms, like errors from human labelling, inaccurate representation of different population groups in training datasets, and chosen model structures and optimization methods. Our paper proposes a novel approach to speech processing that can resolve the gender bias problem by eliminating the gender parameter. Therefore, we devised a system that transforms the input sound (speech of a person) into a neutralized voice to the point where the gender of the speaker becomes indistinguishable by both humans and AI. Wav2Vec based network has been utilised to conduct speech gender recognition to validate the main claim of this research work, which is the neutralisation of gender from the speech. Such a system can be used as a batch pre-processing layer for training models, thus making associated gender bias irrelevant. Further, such a system can also find its application where speaker gender bias by humans is also prominent, as the listener will not be able to judge the gender from speech.","2022-05","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","10","11","","","","","","","","","","English","","","","WOS:000803181100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","emotion recognition; gender bias; responsible AI; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FM2TKLKB","journalArticle","2024","Zhang, HS; Ren, GB","Intelligent leaf disease diagnosis: image algorithms using Swin Transformer and federated learning","VISUAL COMPUTER","","0178-2789","10.1007/s00371-024-03692-w","","In recent years, the international population has surged which has led to increased pressure on food security. Plant diseases are one of the most essential factors affecting food security. Plant diseases often manifest pathological features on plant leaves. This paper combines deep learning with continual learning and federated learning, proposing a federated continual learning comprehensive model based on the Swin Transformer model (SSPW224-LwF-3). Our datasets come from shared datasets and integrate data from other datasets based on a ratio principle of 6:1:3 for the training set, validation set and test set (https://osf.io/v4qfr/?view_only=38b53e39988c4e1e82363031a921f799). Experimental results show that the SSPW224 model achieves an accuracy, precision, recall and F1-score of 97.20%, 95.25%, 94.85% and 94.71% on the test set. It is evident to find out that the SSPW224 model outperforms the other network models in the identification and classification of plant leaf diseases from the data and visualization perspectives. The average accuracy of the SSPW224-LwF-3 model strategy combination proposed in this study reaches the highest 47.06% among 18 combination strategies, with an accuracy of 49.41% and 33.81% for old and new data. The overall performance of this model is optimal. Therefore, the proposed SSPW224-LwF-3 model can achieve efficient, sustainable, and distributed recognition and classification of plant leaf diseases which provides a tool for plant disease identification in smart agriculture.","2024-11-07","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","","","","","","","","","","","English","","","","WOS:001349894900004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Continual learning; Deep learning; Federated learning; Leaf disease; Swin Transformer; SYSTEM; t-SNE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L6AKUMDM","journalArticle","2024","Shi, JL; Zhou, RG; Ren, PJ; Long, ZY","Multi-Dimensional Fusion Attention Mechanism with Vim-like Structure for Mobile Network Design","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14156670","","Recent advancements in mobile neural networks, such as the squeeze-and-excitation (SE) attention mechanism, have significantly improved model performance. However, they often overlook the crucial interaction between location information and channels. The interaction of multiple dimensions in feature engineering is of paramount importance for achieving high-quality results. The Transformer model and its successors, such as Mamba and Vision Mamba, have effectively combined features and linked location information. This approach has transitioned from NLP (natural language processing) to CV (computer vision). This paper introduces a novel attention mechanism for mobile neural networks inspired by the structure of Vim (Vision Mamba). It adopts a ""1 + 3"" architecture to embed multi-dimensional information into channel attention, termed ""Multi-Dimensional Vim-like Attention Mechanism"". The proposed method splits the input into two major branches: the left branch retains the original information for subsequent feature screening, while the right branch divides the channel attention into three one-dimensional feature encoding processes. These processes aggregate features along one channel direction and two spatial directions, simultaneously capturing remote dependencies and preserving precise location information. The resulting feature maps are then combined with the left branch to produce direction-aware, location-sensitive, and channel-aware attention maps. The multi-dimensional Vim-like attention module is simple and can be seamlessly integrated into classical mobile neural networks such as MobileNetV2 and ShuffleNetV2 with minimal computational overhead. Experimental results demonstrate that this attention module adapts well to mobile neural networks with a low parameter count, delivering excellent performance on the CIFAR-100 and MS COCO datasets.","2024-08","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","15","14","","","","","","","","","","English","","","","WOS:001287224100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","attention mechanism; channel fusion; lightweight design; Mamba","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BNG6LYWI","journalArticle","2024","Zhang, HP; Zhou, FX; Wang, DJ; Zhang, XH; Yu, DJ; Guan, LM","LGAFormer: transformer with local and global attention for action detection","JOURNAL OF SUPERCOMPUTING","","0920-8542","10.1007/s11227-024-06138-1","","Temporal action detection is a very important task in video understanding, aiming at predicting the start and end time boundaries of all action instances in an unedited video and their action classification. This task has been widely studied, especially after the transformer has been widely used in the field of vision. However, transformer model brings massive computational resource consumption when processing long sequence input data. At the same time, due to the ambiguity of the video action boundary, many proposal and instance-based methods cannot predict the video boundary accurately. Based on the above two points, we propose LGAFormer: a very concise model that combines the local self-attention mechanism with the global self-attention mechanism, using local self-attention in the shallow layer of the network to process short-range temporal data to model local representations while reducing a large amount of computational consumption, and using global self-attention in the deep layer of the network to model long-range temporal context. This allows our model to achieve a good balance between effectiveness and efficiency. And in terms of detection head, we combine the advantages of the segment feature and instance feature to predict action boundaries more accurately. Thanks to these two points, our method achieves comparable results on all three datasets (THUMOS14, ActivityNet 1.3, and EPIC-Kitchens 100). On THUMOS14, an average mAP of 67.7% was obtained. On ActivityNet 1.3, the best performance is obtained with an average mAP of 36.6%. On EPIC-Kitchens 100, an average mAP of 24.6% was achieved.","2024-08","2025-02-26 20:43:27","2025-02-26 20:43:27","","17952-17979","","12","80","","","","","","","","","","English","","","","WOS:001214867400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;81</p>","","","Action detection; OBJECT DETECTION; Self-attention; Transformer; Video understanding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4P2X4X6S","journalArticle","2024","Constantine, J; Lian, KL; Fan, YF; Xiao, CY; He, ZP","New Power Interface Based on Multi-Dimensional Golden Section Search Algorithm for Power-Hardware-in-the-Loop Applications","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3357970","","Power-Hardware-in-the-Loop (PHIL) is a kind of real-time simulation, capable of exchanging not just low-voltage, low current signals, but the power required by the power device under test (PDuT). PHIL requires a PDuT to be connected to a real-time digital power network simulator via a power interface (PI). There have been quite a few PIs proposed in the past. Among them, the ideal transformer model (ITM) is the most commonly used due to its ease of implementation. Other PIs such as partial circuit duplication and damping impedance can be considered as an extended version of the ITM. These PIs need to follow a strict impedance ratio between PDuT and the rest of the system prior to the PHIL implementation, which could be a tedious and difficult task. This paper proposed a new PI for PHIL based on multi-dimensional golden section search algorithm, which can eliminate such a constraint. The proposed method has been shown to have wider stability regions when PDuT is a passive device or active one such as an inverter based resource. Moreover, dynamic responses of the proposed method are similar to those of the ITM under stable conditions. The validity of the proposed method has been justified with offline simulation and experimental PHIL setups.","2024","2025-02-26 20:43:27","2025-02-26 20:43:27","","14487-14498","","","12","","","","","","","","","","English","","","","WOS:001157973200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","ACCURACY; Circuit stability; DESIGN; Gauss-Seidel; golden section search (GSS); Hardware; Impedance; IMPROVE; power amplifier; power hardware-in-the-loop (PHIL); Power system stability; Real-time simulation; Real-time systems; Sensors; SIMULATION; STABILITY; Stability analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U9TG7ZMR","journalArticle","2022","Sivakumar, S; Rajalakshmi, R","Context-aware sentiment analysis with attention-enhanced features from bidirectional transformers","SOCIAL NETWORK ANALYSIS AND MINING","","1869-5450","10.1007/s13278-022-00910-y","","Sentiment analysis is a means of excerpting subjective information from client reviews. The existing shallow model lacks in addressing multiple relation/meaning of a word in a review. To address the above issue and to find an effective contextual word embedding, we have performed a thorough analysis on the existing language model, viz., Universal Language Model Fine-tuning, Embeddings from Language Models and Bidirectional Encoder Representations from Transformers (BERT). Based on the analysis, we have proposed a transfer learning-based bidirectional transformer model. We have conducted several experiments with the different transfer learning-based bidirectional transformer models to find a robust classifier for contextual embedding. In these various transfer learning approaches, the attention-extracted features are fed into different classifiers, viz., support vector machine (SVM), logistic regression (LR), long short-term memory (LSTM) and bidirectional gated recurrent unit (BGRU). BERT is a multi-head, multilayered and bidirectional transformer that finds deep contextual words existing in a review by exhibiting different patterns in different layers. In the proposed architecture, the attention-extracted deep contextual features from BERT are fed into the BGRU through transfer learning to have better contextual classification. With the proposed attention-extracted BERT-bidirectional gated recurrent unit (i.e., AeBERT-BGRU), we have obtained an F-1 score of 95.57, 86.66 and 80.29% for IMDB, Polarity and OLID dataset (weighted), which is a significant improvement when compared to state-of-the-art methods.","2022-12","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","1","12","","","","","","","","","","English","","","","WOS:000837696400003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","Bidirectional encoder representation for transformer (BERT); Bidirectional transformer; CLASSIFICATION; Offensive language identification dataset (OLID); Social media network (SMN)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TIHRLJQP","journalArticle","2024","Yu, YS; Qiu, XY; Hu, FC; He, RH; Zhang, LK","An End-to-End Speech Separation Method Based on Features of Two Domains","JOURNAL OF VIBRATION ENGINEERING & TECHNOLOGIES","","2523-3920","10.1007/s42417-023-01271-2","","PurposeThe current mainstream methods for single-channel speech separation generally use a feature extraction process like the short-time Fourier transform and rely on long input sequences. Thus, they do not fully utilize the information of speech features and cause signal delays in speech separation.MethodsTo achieve better performance with a lightweight model, a fully convolution end-to-end audio separation network is proposed based on the features of two domains, i.e. temporal domain channel domain. It considers not only the temporal correlation of speech signals, but also the correlation between channels in the signal feature map. At first, the end-to-end network uses a convolution process with no overlapping segments to sample and encode the speech waveform. Subsequently, it calculates the mask by convolving the encoded feature space in both time series and inter-channel dimensions. Finally, it decodes the masked feature space to restructure the waveform.ResultsThe proposed end-to-end speech separation method makes full use of the feature space information of speech signals. Meanwhile, the separation module introduces residual structure and dilation convolution, which improves separation accuracy and computational speed with fewer parameters. The experiments show that compared with the base Conv-TasNet, the proposed model improves the SI-SNR (scale-invariant source-to-noise ratio) metric by 3.1 dB on the WSJ0-Mix2 dataset.ConclusionThis paper proposes an improved speech separation algorithm. Compared with Conv-TasNet, the performance of speech separation is improved. At the same time, the algorithm inherits the lightweight property of Conv-TasNet. In the task of separating speech signals mixed with a random signal-to-noise ratio (SNR) between -5 and 5 dB, the proposed algorithm achieves a relatively high accuracy.","2024-08","2025-02-26 20:43:27","2025-02-26 20:43:27","","7325-7334","","6","12","","","","","","","","","","English","","","","WOS:001159602800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","Convolutional neural network; End to end; Speech separation; Two domains","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZVWEEIMT","journalArticle","2024","Argolo, F; Ramos, WHD; Mota, NB; Lopes-Rocha, AC; Andrade, JC; van de Bilt, MT; de Jesus, LP; Jafet, A; Cecchi, G; Gattaz, WF; Corcoran, CM; Ara, A; Loch, AA","Natural language processing in at-risk mental states: enhancing the assessment of thought disorders and psychotic traits with semantic dynamics and graph theory","BRAZILIAN JOURNAL OF PSYCHIATRY","","1516-4446","10.47626/1516-4446-2023-3419","","Objective: Verbal communication contains key information for mental health assessment. Researchers have linked psychopathology phenomena to certain counterparts in natural language processing. We characterized subtle impairments in the early stages of psychosis, developing new analysis techniques, which led to a comprehensive map associating features of natural language processing with the full range of clinical presentation. Methods: We used natural language processing to assess spontaneous and elicited speech by 60 individuals with at-risk mental states and 73 controls who were screened from 4,500 quota-sampled Portuguese speaking residents of Sao Paulo, Brazil. Psychotic symptoms were independently assessed with the Structured Interview for Psychosis-Risk Syndromes. Speech features (e.g., sentiments and semantic coherence), including novel ones, were correlated with psychotic traits (Spearman's-r) and at-risk mental state status (general linear models and machine-learning Results: Natural language processing features were informative for classification, presenting a balanced accuracy of 86%. Features such as semantic laminarity (as perseveration), semantic recurrence time (as circumstantiality), and average centrality in word repetition graphs carried the most information and were directly correlated with psychotic symptoms. Grammatical tagging (e.g., use of adjectives) was the most relevant standard measure. Conclusion: Subtle speech impairments can be detected by sensitive methods and can be used in at-risk mental states screening. We have outlined a blueprint for speech-based evaluation, pairing features to standard psychometric items for thought disorder.","2024","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","46","","","","","","","","","","English","","","","WOS:001381049500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","ADABOOST; ALGORITHM; at-risk mental states; HEALTH-CARE; INTERVIEW; machine learning; natural language processing; PRODROMAL SYNDROMES; Psychosis; RELIABILITY; screening; semantics; SPEECH; SYNTAX; VALIDATION; VALIDITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RTCG5YKQ","journalArticle","2023","Favaro, A; Tsai, YT; Butala, A; Thebaud, T; Villalba, J; Dehak, N; Moro-Velázquez, L","Interpretable speech features vs. DNN embeddings: What to use in the automatic assessment of Parkinson's disease in multi-lingual scenarios","COMPUTERS IN BIOLOGY AND MEDICINE","","0010-4825","10.1016/j.compbiomed.2023.107559","","Speech-based approaches for assessing Parkinson's Disease (PD) often rely on feature extraction for automatic classification or detection. While many studies prioritize accuracy by using non-interpretable embeddings from Deep Neural Networks, this work aims to explore the predictive capabilities and language robustness of both feature types in a systematic fashion. As interpretable features, prosodic, linguistic, and cognitive descriptors were adopted, while x-vectors, Wav2Vec 2.0, HuBERT, and TRILLsson representations were used as non-interpretable features. Mono-lingual, multi-lingual, and cross-lingual machine learning experiments were conducted leveraging six data sets comprising speech recordings from various languages: American English, Castilian Spanish, Colombian Spanish, Italian, German, and Czech. For interpretable feature-based models, the mean of the best F1-scores obtained from each language was 81% in mono-lingual, 81% in multi-lingual, and 71% in cross-lingual experiments. For non-interpretable feature-based models, instead, they were 85% in mono-lingual, 88% in multi-lingual, and 79% in cross-lingual experiments. Firstly, models based on non interpretable features outperformed interpretable ones, especially in cross-lingual experiments. Specifically, TRILLsson provided the most stable and accurate results across tasks and data sets. Conversely, the two types of features adopted showed some level of language robustness in multi-lingual and cross-lingual experiments. Overall, these results suggest that interpretable feature-based models can be used by clinicians to evaluate the deterioration of the speech of patients with PD, while non-interpretable feature-based models can be leveraged to achieve higher detection accuracy.","2023-11","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","166","","","","","","","","","","English","","","","WOS:001098252900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;109</p>","","","ACCURACY; ARTICULATION; CONNECTED SPEECH; Deep learning; DIAGNOSIS; DISORDERS; INDIVIDUALS; Interpretable features; Machine learning; Parkinson's disease; PROGRESSION; RELIABILITY; Speech; VARIABILITY; X-VECTORS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DQVRFAPA","journalArticle","2022","Chan, JCS; Stout, JC; Shirbin, CA; Vogel, AP","Listener Detection of Objectively Validated Acoustic Features of Speech in Huntington's Disease","JOURNAL OF HUNTINGTONS DISEASE","","1879-6397","10.3233/JHD-210501","","Background: Subtle progressive changes in speech motor function and cognition begin prior to diagnosis of Huntington's disease (HD). Objective: To determine the nature of listener-rated speech differences in premanifest and early-stage HD (i.e., PreHD and EarlyHD), compared to neurologically healthy controls. Methods: We administered a speech battery to 60 adults (16 people with PreHD, 14 with EarlyHD, and 30 neurologically healthy controls), and conducted a cognitive test of processing speed/visual attention, the Symbol Digit Modalities Test (SDMT) on participants with HD. Voice recordings were rated by expert listeners and analyzed for acoustic and perceptual speech features. Results: Listeners perceived subtle differences in the speech of PreHD compared to controls, including abnormal pitch level and speech rate, reduced loudness and loudness inflection, altered voice quality, hypernasality, imprecise articulation, and reduced naturalness of speech. Listeners detected abnormal speech rate in PreHD compared to healthy speakers on a reading task, which correlated with slower speech rate from acoustic analysis and a lower cognitive performance score. In early-stage HD, continuous speech was characterized by longer pauses, a higher proportion of silence, and slower rate. Conclusion: Differences in speech and voice acoustic features are detectable in PreHD by expert listeners and align with some acoustically-derived objective speech measures. Slower speech rate in PreHD suggests altered oral motor control and/or subtle cognitive deficits that begin prior to diagnosis. Speakers with EarlyHD exhibited more silences compared to the PreHD and control groups, raising the likelihood of a link between speech and cognition that is not yet well characterized in HD.","2022","2025-02-26 20:43:27","2025-02-26 20:43:27","","71-79","","1","11","","","","","","","","","","English","","","","WOS:000763895500007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Acoustics; BIOMARKERS; cognition; DEPRESSION; dysarthria; IMPAIRMENT; LANGUAGE PRODUCTION; PERCEPTUAL EVALUATION; perceptual rating; PERFORMANCE; PREMANIFEST; RELIABILITY; SENSITIVITY; speech; speech analytics; VOICE QUALITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H9BFAXK3","journalArticle","2024","Liss, J; Berisha, V","Operationalizing Clinical Speech Analytics: Moving From Features to Measures for Real-World Clinical Impact","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2024_JSLHR-24-00039","","Objective: This research note advocates for a methodological shift in clinical speech analytics, emphasizing the transition from high-dimensional speech feature representations to clinically validated speech measures designed to operationalize clinically relevant constructs of interest. The aim is to enhance model generalizability and clinical applicability in real-world settings. Method: We outline the challenges of using conventional supervised machine learning models in clinical speech analytics, particularly their limited generalizability and interpretability. We propose a new framework focusing on speech measures that are closely tied to specific speech constructs and have undergone rigorous validation. This research note discusses a case study involving the development of a measure for articulatory precision in amyotrophic lateral sclerosis (ALS), detailing the process from ideation through Food and Drug Administration (FDA) breakthrough status designation. Results: The case study demonstrates how the operationalization of the articulatory precision construct into a quantifiable measure yields robust, clinically meaningful results. The measure's validation followed the V3 framework (verification, analytical validation, and clinical validation), showing high correlation with clinical status and speech intelligibility. The practical application of these measures is exemplified in a clinical trial and designation by the FDA as a breakthrough status device, underscoring their real-world impact. Conclusions: Transitioning from speech features to speech measures offers a more targeted approach for developing speech analytics tools in clinical settings. This shift ensures that models are not only technically sound but also clinically relevant and interpretable, thereby bridging the gap between laboratory research and practical health care applications. We encourage further exploration and adoption of this approach for developing interpretable speech representations tailored to specific clinical needs.","2024-11","2025-02-26 20:43:27","2025-02-26 20:43:27","","4226-4232","","11","67","","","","","","","","","","English","","","","WOS:001355394400007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZFQNRU7S","journalArticle","2023","Mewada, H; Al-Asad, JF; Almalki, FA; Khan, AH; Almujally, NA; El-Nakla, S; Naith, Q","Gaussian-Filtered High-Frequency-Feature Trained Optimized BiLSTM Network for Spoofed-Speech Classification","SENSORS","","1424-8220","10.3390/s23146637","","Voice-controlled devices are in demand due to their hands-free controls. However, using voice-controlled devices in sensitive scenarios like smartphone applications and financial transactions requires protection against fraudulent attacks referred to as ""speech spoofing"". The algorithms used in spoof attacks are practically unknown; hence, further analysis and development of spoof-detection models for improving spoof classification are required. A study of the spoofed-speech spectrum suggests that high-frequency features are able to discriminate genuine speech from spoofed speech well. Typically, linear or triangular filter banks are used to obtain high-frequency features. However, a Gaussian filter can extract more global information than a triangular filter. In addition, MFCC features are preferable among other speech features because of their lower covariance. Therefore, in this study, the use of a Gaussian filter is proposed for the extraction of inverted MFCC (iMFCC) features, providing high-frequency features. Complementary features are integrated with iMFCC to strengthen the features that aid in the discrimination of spoof speech. Deep learning has been proven to be efficient in classification applications, but the selection of its hyper-parameters and architecture is crucial and directly affects performance. Therefore, a Bayesian algorithm is used to optimize the BiLSTM network. Thus, in this study, we build a high-frequency-based optimized BiLSTM network to classify the spoofed-speech signal, and we present an extensive investigation using the ASVSpoof 2017 dataset. The optimized BiLSTM model is successfully trained with the least epoch and achieved a 99.58% validation accuracy. The proposed algorithm achieved a 6.58% EER on the evaluation dataset, with a relative improvement of 78% on a baseline spoof-identification system.","2023-07","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","14","23","","","","","","","","","","English","","","","WOS:001071181200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","anti-spoofing; ASVspoof; ATTACK DETECTION; convolutional neural network; genuine speech detection; Q TRANSFORM; SPEAKER VERIFICATION; voice conversion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IAUJNXL8","journalArticle","2021","Zhong, QH; Dai, RN; Zhang, H; Zhu, YS; Zhou, GF","Text-independent speaker recognition based on adaptive course learning loss and deep residual network","EURASIP JOURNAL ON ADVANCES IN SIGNAL PROCESSING","","1687-6180","10.1186/s13634-021-00762-2","","Text-independent speaker recognition is widely used in identity recognition that has a wide spectrum of applications, such as criminal investigation, payment certification, and interest-based customer services. In order to improve the recognition ability of log filter bank feature vectors, a method of text-independent speaker recognition based on deep residual networks model was proposed in this paper. The deep residual network was composed of a residual network (ResNet) and a convolutional attention statistics pooling (CASP) layer. The CASP layer could aggregate frame-level features from the ResNet into an utterance-level features. Extracting speech features for each speaker using deep residual networks was a promising direction to explore, and a straightforward solution was to train the discriminative feature extraction network by using a margin-based loss function. However, a margin-based loss function often has certain limitations, such as the margins between different categories were set to be the same and fixed. Thus, we used an adaptive curriculum learning loss (ACLL) to address the problem and introduce two different margin-based losses for this problem, i.e., AM-Softmax and AAM-Softmax. The proposed method was applied to a large-scale VoxCeleb2 dataset for extensive text-independent speaker recognition experiments, and average equal error rate (EER) could achieve 1.76% on VoxCeleb1 test dataset, 1.91% on VoxCeleb1-E test dataset, and 3.24% on VoxCeleb1-H test dataset. Compared with related speaker recognition methods, EER was improved by 1.11% on VoxCeleb1 test dataset, 1.04% on VoxCeleb1-E test dataset, and 1.69% on VoxCeleb1-H test dataset.","2021-07-23","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","1","2021","","","","","","","","","","English","","","","WOS:000679331700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Adaptive curriculum learning loss; Convolutional attention statistics pooling; Deep residual network; IDENTIFICATION; Speaker recognition; Text-independent; VERIFICATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VZGQ3UYE","journalArticle","2023","Yasmin, S; Irsik, VC; Johnsrude, IS; Herrmann, B","The effects of speech masking on neural tracking of acoustic and semantic features of natural speech","NEUROPSYCHOLOGIA","","0028-3932","10.1016/j.neuropsychologia.2023.108584","","Listening environments contain background sounds that mask speech and lead to communication challenges. Sensitivity to slow acoustic fluctuations in speech can help segregate speech from background noise. Semantic context can also facilitate speech perception in noise, for example, by enabling prediction of upcoming words. However, not much is known about how different degrees of background masking affect the neural processing of acoustic and semantic features during naturalistic speech listening. In the current electroencephalography (EEG) study, participants listened to engaging, spoken stories masked at different levels of multi-talker babble to investigate how neural activity in response to acoustic and semantic features changes with acoustic challenges, and how such effects relate to speech intelligibility. The pattern of neural response amplitudes associated with both acoustic and semantic speech features across masking levels was U-shaped, such that amplitudes were largest for moderate masking levels. This U-shape may be due to increased attentional focus when speech comprehension is challenging, but manageable. The latency of the neural responses increased linearly with increasing background masking, and neural latency change associated with acoustic processing most closely mirrored the changes in speech intelligibility. Finally, tracking responses related to semantic dissimilarity remained robust until severe speech masking (-3 dB SNR). The current study reveals that neural responses to acoustic features are highly sensitive to background masking and decreasing speech intelligibility, whereas neural responses to semantic features are relatively robust, suggesting that individuals track the meaning of the story well even in moderate background sound.","2023-07-29","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","186","","","","","","","","","","English","","","","WOS:001011629700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;127</p>","","","Acoustic processing; Auditory perception; COMPREHENSION; EVENT-RELATED POTENTIALS; FUNDAMENTAL-FREQUENCY; HEARING-LOSS; INTELLIGIBILITY; N400; Neural tracking; PASS NOISE MASKING; PERCEPTION; RECALL; Semantic processing; Speech processing; WORD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YG2A5HX3","journalArticle","2025","Gu, J; Tian, FZ; Oh, I","RAMIS: Increasing robustness and accuracy in medical image segmentation with hybrid CNN-transformer synergy","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2024.129009","","Hybrid architectures based on Convolutional Neural Network (CNN) and Vision Transformer (ViT) have become an important research direction in medical image segmentation in recent years. However, the currently popular hybrid architectures weaken the decision making process within the Transformer model, the way in which the output of the Transformer is post-processed by the upsampling of the convolution stack makes it difficult to restore the blurred boundaries of the target area. To improve the feature learning capability by addressing these issues, we propose RAMIS, a novel hybrid architecture for general medical image segmentation. RAMIS develops implicit neural representation and self-distillation to simultaneously obtain the super-resolution details and core features of the image as input to the Transformer encoder. Meanwhile, RAMIS explores an unsupervised learning CNN to obtain the initial input to the Transformer decoder, which not only explicitly considers the correlation within different samples, reduces the constraints on small datasets, but also fully leverages the potential of Transformer's cross-attention for optimizing segmentation results. RAMIS designs a multi-resolution interaction network to post-process the Transformer output and solves the problem of blurred segmentation boundaries by combining super-resolution image. We extensively evaluate RAMIS on five datasets from three typical publicly available medical image segmentation datasets. Extensive experimental results demonstrate the general applicability and superior performance of the proposed method. The code and pre-trained models are available on our website https://ramis.netlify.app.","2025-02-14","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","618","","","","","","","","","","English","","","","WOS:001397525000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;113</p>","","","CLASSIFICATION; FUSION NETWORK; Hybrid models; Implicit representation; LESION SEGMENTATION; Medical image segmentation; Multi-resolution network; NET; Self-distillation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QNCSF4QT","journalArticle","2025","Singh, P; Singh, S","ChestX-Transcribe: a multimodal transformer for automated radiology report generation from chest x-rays","FRONTIERS IN DIGITAL HEALTH","","2673-253X","10.3389/fdgth.2025.1535168","","Radiology departments are under increasing pressure to meet the demand for timely and accurate diagnostics, especially with chest x-rays, a key modality for pulmonary condition assessment. Producing comprehensive and accurate radiological reports is a time-consuming process prone to errors, particularly in high-volume clinical environments. Automated report generation plays a crucial role in alleviating radiologists' workload, improving diagnostic accuracy, and ensuring consistency. This paper introduces ChestX-Transcribe, a multimodal transformer model that combines the Swin Transformer for extracting high-resolution visual features with DistilGPT for generating clinically relevant, semantically rich medical reports. Trained on the Indiana University Chest x-ray dataset, ChestX-Transcribe demonstrates state-of-the-art performance across BLEU, ROUGE, and METEOR metrics, outperforming prior models in producing clinically meaningful reports. However, the reliance on the Indiana University dataset introduces potential limitations, including selection bias, as the dataset is collected from specific hospitals within the Indiana Network for Patient Care. This may result in underrepresentation of certain demographics or conditions not prevalent in those healthcare settings, potentially skewing model predictions when applied to more diverse populations or different clinical environments. Additionally, the ethical implications of handling sensitive medical data, including patient privacy and data security, are considered. Despite these challenges, ChestX-Transcribe shows promising potential for enhancing real-world radiology workflows by automating the creation of medical reports, reducing diagnostic errors, and improving efficiency. The findings highlight the transformative potential of multimodal transformers in healthcare, with future work focusing on improving model generalizability and optimizing clinical integration.","2025-01-21","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","7","","","","","","","","","","English","","","","WOS:001412051400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","DistilGPT; medical report generation; multimodal transformers; radiology workflow; swin transformer; vision-language models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GWJBIVIW","journalArticle","2024","He, YX; Chen, W; Huang, Z; Wang, QP","MoMFormer: Mixture of modality transformer model for vegetation extraction under shadow conditions","ECOLOGICAL INFORMATICS","","1574-9541","10.1016/j.ecoinf.2024.102818","","Accurate estimation of fractional vegetation coverage (FVC) is essential for assessing the ecological environment and acquiring ecological information. However, under natural lighting conditions, shadows in vegetation scenes can easily lead to confusion between shadowed vegetation and shadowed soil, leading to misclassification and omission errors. This issue limits the precision of both vegetation extraction and FVC estimation. To address this challenge, this study introduces a novel deep learning model, the Mixture of Modality Transformer (MoMFormer), which is specifically designed to mitigate shadow interference in vegetation extraction. Our model uses the Swin-transformer V2 as a feature extractor, effectively capturing vegetation features from a dual-modality (regular-exposure RGB and high dynamic range HDR) dataset. A dynamic aggregation module (DAM) is integrated to adaptively blend the most relevant vegetation features. We selected several state-of-the-art (SOTA) methods and conducted extensive experiments using a self-annotated dataset featuring diverse vegetation-soil scenes and compare our model with several state-of-the-art methods. The results demonstrate that MoMFormer achieves an accuracy of 89.43 % on the HDR-RGB dual-modality dataset, with an FVC accuracy of 87.57 %, outperforming other algorithms and demonstrating high vegetation extraction accuracy and adaptability under natural lighting conditions. This research offers new insights into accurate vegetation information extraction in naturally lit environments with shadows, providing robust technical support for high-precision validation of vegetation coverage products and algorithms based on multimodal data. The code and datasets used in this study are publicly available at https://github.com/hhhxiaohe/MoMFormer.","2024-11","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","83","","","","","","","","","","English","","","","WOS:001315555900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","COVER ESTIMATION; Deep learning; NETWORK; ROBUST; SEGMENTATION; Shadow; Vegetation extraction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J344QH5X","journalArticle","2024","Dhote, A; Javed, M; Doermann, DS","Swin-chart: An efficient approach for chart classification","PATTERN RECOGNITION LETTERS","","0167-8655","10.1016/j.patrec.2024.08.012","","Charts are a visualization tool used in scientific documents to facilitate easy comprehension of complex relationships underlying data and experiments. Researchers use various chart types to convey scientific information, so the problem of data extraction and subsequent chart understanding becomes very challenging. Many studies have been taken up in the literature to address the problem of chart mining, whose motivation is to facilitate the editing of existing charts, carry out extrapolative studies, and provide a deeper understanding of the underlying data. The first step towards chart understanding is chart classification, for which traditional ML and CNN-based deep learning models have been used in the literature. In this paper, we propose SwinChart, a Swin transformer-based deep learning approach for chart classification, which generalizes well across multiple datasets with a wide range of chart categories. Swin-Chart comprises a pre-trained Swin Transformer, a finetuning component, and a weight averaging component. The proposed approach is tested on a five-chart image benchmark dataset. We observed that the Swin-Chart model outperformers existing state-of-the-art models on all the datasets. Furthermore, we also provide an ablation study of the Swin-Chart model with all five datasets to understand the importance of various sub-parts such as the back-bone Swin transformer model, the value of several best weights selected for the weight averaging component, and the presence of the weight averaging component itself. The Swin-Chart model also received first position in the chart classification task on the latest dataset in the CHART Infographics competition at ICDAR 2023- chartinfo.github.io.","2024-09","2025-02-26 20:43:27","2025-02-26 20:43:27","","203-209","","","185","","","","","","","","","","English","","","","WOS:001306910300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","Chart classification; Deep learning; INFORMATION; Scientific documents; Swin transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X2IDKMPJ","journalArticle","2024","Çalik, SS; Küçükmanisa, A; Kilimci, ZH","A novel framework for mispronunciation detection of Arabic phonemes using audio-oriented transformer models","APPLIED ACOUSTICS","","0003-682X","10.1016/j.apacoust.2023.109711","","Computer-Aided Language Learning (CALL) is experiencing notable growth in contemporary times due to the indispensability of acquiring proficiency in various languages for effective communication across diverse linguistic contexts. Within the domain of CALL, the inclusion of mispronunciation detection serves as an intrinsic component aimed at automatically pinpointing errors made by non-native speakers. In this research endeavor, a pioneering framework is put forth to address the task of detecting mispronunciations in Arabic phonemes through the utilization of audio-centric transformer models. To our current understanding, this represents the inaugural endeavor to comprehensively ascertain the mispronunciations of Arabic phonemes by employing audio-focused transformer models, including Squeezed and Efficient Wav2Vec (SEW), Hidden-Unit BERT (HUBERT), WAV2VEC, UNI-SPEECH. In order to demonstrate the effectiveness of the proposed model, a comprehensive evaluation is conducted on a set of 29 Arabic phonemes, including 8 hafiz sounds, uttered by 11 distinct individuals. For experimental purposes, two distinct versions of the dataset are utilized, incorporating additional voice samples obtained from the YouTube platform. The extensive experimental findings substantiate that employing the UNI-SPEECH transformer model yields notable classification outcomes in the context of Arabic phoneme mispronunciation detection. The systematic comparison of audio-centric transformer models adds valuable insights to the existing scholarly discourse and offers clarity regarding their effectiveness and appropriateness in the domain of Arabic phoneme mispronunciation detection. Additionally, the comprehensive comparative analysis of these transformer models unveils their respective advantages, constraints, and avenues for enhancement, thereby guiding future investigations in this realm.","2024-01","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","215","","","","","","","","","","English","","","","WOS:001115084500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","Arabic pronunciation detection; Audio transformers; Computer aided language learning; HUBERT; UniSpeech; Wav2Vec","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"332TVVLU","journalArticle","2023","Shamas, M; El Hajj, W; Hajj, H; Shaban, K","Metadial: A Meta-learning Approach for Arabic Dialogue Generation","ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING","","2375-4699","10.1145/3590960","","Dialogue generation is the automatic generation of a text response, given a user's input. Dialogue generation for low-resource languages has been a challenging tasks for researchers. However, the advancements in deep learning models have made developing conversational agents that perform the tasks of dialogue generation not only possible, but also effective and helpful in many applications spanning a variety of domains. Nevertheless, work on conversational bots for low-resource languages such as the Arabic language is still limited due to various challenges, including the language structure, vocabulary, and the scarcity of its data resources. Meta-learning has been introduced before in the natural language processing (NLP) realm and showed significant improvements in many tasks; however, it has rarely been used in natural language generation (NLG) tasks and never in Arabic NLG. In this work, we propose a meta-learning approach for Arabic dialogue generation for fast adaptation on low-resource domains, namely, Arabic. We start by using existing pre-trained models; we then meta-learn the initial parameters on high-resource dataset before finetuning the parameters on the target tasks. We prove that the proposed model that employs meta-learning techniques improves generalization and enables fast adaptation of the transformer model on low-resource NLG tasks. We report gains in the BLEU-4 and improvements in Semantic textual Similarity (STS) metrics when compared to the existing state-of-the-art approach. We also do a further study on the effectiveness of the meta-learning algorithms on the response generation of the models.","2023-06","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","6","22","","","","","","","","","","English","","","","WOS:001018562700018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Arabic Natural LanguageGeneration; model-agnostic meta-learning; Reptile; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DNLW2QJQ","journalArticle","2023","Bani-Almarjeh, M; Kurdy, MB","Arabic abstractive text summarization using RNN-based and transformer-based architectures","INFORMATION PROCESSING & MANAGEMENT","","0306-4573","10.1016/j.ipm.2022.103227","","Recently, the Transformer model architecture and the pre-trained Transformer-based language models have shown impressive performance when used in solving both natural language un-derstanding and text generation tasks. Nevertheless, there is little research done on using these models for text generation in Arabic. This research aims at leveraging and comparing the per-formance of different model architectures, including RNN-based and Transformer-based ones, and different pre-trained language models, including mBERT, AraBERT, AraGPT2, and AraT5 for Arabic abstractive summarization. We first built an Arabic summarization dataset of 84,764 high-quality text-summary pairs. To use mBERT and AraBERT in the context of text summarization, we employed a BERT2BERT-based encoder-decoder model where we initialized both the encoder and decoder with the respective model weights. The proposed models have been tested using ROUGE metrics and manual human evaluation. We also compared their performance on out-of-domain data. Our pre-trained Transformer-based models give a large improvement in performance with-79% less data. We found that AraT5 scores-3 ROUGE higher than a BERT2BERT-based model that is initialized with AraBERT, indicating that an encoder-decoder pre-trained Transformer is more suitable for summarizing Arabic text. Also, both of these two models perform better than AraGPT2 by a clear margin, which we found to produce summaries with high readability but with relatively lesser quality. On the other hand, we found that both AraT5 and AraGPT2 are better at summarizing out-of-domain text. We released our models and dataset publicly1,.2","2023-03","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","2","60","","","","","","","","","","English","","","","WOS:000916459700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Deep learning; Natural language processing; Text summarization; Transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R4TQEJVS","journalArticle","2024","Zhang, J; Fang, ZJ; Sun, H; Wang, Z","Adaptive Semantic-Enhanced Transformer for Image Captioning","IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS","","2162-237X","10.1109/TNNLS.2022.3185320","","In the research on image captioning, rich semantic information is very important for generating critical caption words as guiding information. However, semantic information from offline object detectors involves many semantic objects that do not appear in the caption, thereby bringing noise into the decoding process. To produce more accurate semantic guiding information and further optimize the decoding process, we propose an end-to-end adaptive semantic-enhanced transformer (AS-Transformer) model for image captioning. For semantic enhancement information extraction, we propose a constrained weaklysupervised learning (CWSL) module, which reconstructs the semantic object's probability distribution detected by the multiple instances learning (MIL) through a joint loss function. These strengthened semantic objects from the reconstructed probability distribution can better depict the semantic meaning of images. Also, for semantic enhancement decoding, we propose an adaptive gated mechanism (AGM) module to adjust the attention between visual and semantic information adaptively for the more accurate generation of caption words. Through the joint control of the CWSL module and AGM module, our proposed model constructs a complete adaptive enhancement mechanism from encoding to decoding and obtains visual context that is more suitable for captions. Experiments on the public Microsoft Common Objects in COntext (MSCOCO) and Flickr30K datasets illustrate that our proposed AS-Transformer can adaptively obtain effective semantic information and adjust the attention weights between semantic and visual information automatically, which achieves more accurate captions compared with semantic enhancement methods and outperforms state-of-the-art methods.","2024-02","2025-02-26 20:43:27","2025-02-26 20:43:27","","1785-1796","","2","35","","","","","","","","","","English","","","","WOS:000824712700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;24<br/>Total Times Cited:&nbsp;&nbsp;24<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","Adaptation models; Adaptive gated mechanism (AGM); adaptive semantic-enhanced transformer (AS-Transformer); ATTENTION; constrained weakly supervised learning; Decoding; Detectors; image captioning; Image reconstruction; Semantics; Transformers; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y2FSIKMR","journalArticle","2021","Park, H; Kim, K; Park, S; Choi, J","Medical Image Captioning Model to Convey More Details: Methodological Comparison of Feature Difference Generation","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2021.3124564","","The steadily increasing number of medical images places a tremendous burden on doctors, who toned to read and write reports. If an image captioning model could generate drafts of the reports from the corresponding images, the workload of doctors would be reduced, thereby saving time and expenses. The aim of this study was to develop a chest x-ray image captioning model that considers the differences between patient images and normal images, and uses hierarchical long short-term memory (LSTM) or a transformer as a decoder to generate reports. We investigated which feature representation method was the most appropriate for capturing the differences. The feature representations differed in terms of whether global average pooling was used for the visual feature vectors and how the feature difference vectors were generated. Experiments were conducted on two datasets using the proposed models and recent captioning models (X-LAN and X-Transformer). BLEU, METEOR, ROUGE-L, and CIDEr were used as evaluation metrics. The best model for most metric scores was the multi-difference non-average-pooling transformer model, which uses the transformer decoder, does not use global average pooling for the visual feature vectors, and applies the element-wise product. The transformer decoder was found to be more suitable than hierarchical LSTM. Furthermore, for models that do not condense features with global average pooling, the element-wise product was observed to be more effective than subtraction in expressing the feature differences.","2021","2025-02-26 20:43:27","2025-02-26 20:43:27","","150560-150568","","","9","","","","","","","","","","English","","","","WOS:000717754700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Analytical models; Chest x-ray; Decoding; deep learning; feature differences; Feature extraction; Medical diagnostic imaging; medical image captioning; Transformers; Visualization; X-ray imaging","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TWWKTB44","journalArticle","2024","Esen, AT; Mete, AL; Capraz, N; Erol Stenstad, A","Discrimination of Speech Content in Unipolar Depression and Bipolar Mania: A Computer-Based Analysis with ""General Inquirer""","TURK PSIKIYATRI DERGISI","","1300-2163","10.5080/u","","Objective: Speech disorders in mental illnesses are usually chronic and associated with poorer outcome. Recently, different types of speech features in mental illnesses can be examined by computer technology. The aim of our study is to examine the content of speech in depression and mania and to investigate the themes that differentiate the diagnostic groups. Method: 30 patients diagnosed with depression, 30 patients diagnosed with bipolar disorder manic episode and 30 healthy control were included in the study. All participants were performed with the Structured Clinical Interview for DSM-IV Axis I Disorders. The participants were asked to speak free for ten minutes and then their speech content was analyzed with the ""General Inquirer"" computer program. This program analyzes the participants' use of a total of 4919 words in the Harvard Psychosocial Dictionary, which are categorized in 83 themes on topics related to psychosocial, emotion, behavior, thought, natural and cultural environment. Results: The diagnostic groups were identified by speech content categories with an accuracy rate of 81%. Patients in mania and depression groups were clustered in the same direction in discriminant analysis by the themes of speech content. ''self"" and ''academic"" themes were the most discriminative categories between the patient and control groups. Conclusion: The content of speech in mania and depression is different from individuals without mental disorders and that computer-assisted analysis tools can distinguish diagnostic groups from each other and from healthy group. Future studies in which structural, vocal and content features of speech are evaluated together and used more advanced computer technologies will contribute to the literature.","2024-11-29","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","","","","","","","","","","","English","","","","WOS:001398496200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Bipolar Disorder; Depression; DISORDER; General Inquirer; Language; LINGUISTIC ANALYSIS; Linguistics; RATING-SCALE; RELIABILITY; SCHIZOPHRENIA; Speech; VALIDITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M5KP53X5","journalArticle","2024","Aziz, D; Sztahó, D","Automatic cross- and multi-lingual recognition of dysphonia by ensemble classification using deep speaker embedding models","EXPERT SYSTEMS","","0266-4720","10.1111/exsy.13660","","Machine Learning (ML) algorithms have demonstrated remarkable performance in dysphonia detection using speech samples. However, their efficacy often diminishes when tested on languages different from the training data, raising questions about their suitability in clinical settings. This study aims to develop a robust method for cross- and multi-lingual dysphonia detection that overcomes the limitation of language dependency in existing ML methods. We propose an innovative approach that leverages speech embeddings from speaker verification models, especially ECAPA and x-vector and employs a majority voting ensemble classifier. We utilize speech features extracted from ECAPA and x-vector embeddings to train three distinct classifiers. The significant advantage of these embedding models lies in their capability to capture speaker characteristics in a language-independent manner, forming fixed-dimensional feature spaces. Additionally, we investigate the impact of generating synthetic data within the embedding feature space using the Synthetic Minority Oversampling Technique (SMOTE). Our experimental results unveil the effectiveness of the proposed method for dysphonia detection. Compared to results obtained from x-vector embeddings, ECAPA consistently demonstrates superior performance in distinguishing between healthy and dysphonic speech, achieving accuracy values of 93.33% and 96.55% in both cross-lingual and multi-lingual scenarios, respectively. This highlights the remarkable capabilities of speaker verification models, especially ECAPA, in capturing language-independent features that enhance overall detection performance. The proposed method effectively addresses the challenges of language dependency in dysphonia detection. ECAPA embeddings, combined with majority voting ensemble classifiers, show significant potential for improving the accuracy and reliability of dysphonia detection in cross- and multi-lingual scenarios.","2024-10","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","10","41","","","","","","","","","","English","","","","WOS:001244384800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","cross-lingual; dysphonia; speaker embeddings; speech; voice pathology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FDB9KCWF","journalArticle","2025","Guo, JT; Du, HS; Hao, XX; Zhang, MH","CFET: A Cross-Fusion Enhanced Transformer for Visible-infrared person re-identification","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2025.126645","","Visible-infrared person re-identification (VI-ReID) aims to match pedestrian images captured by different cameras (visible cameras and infrared cameras). However, the large discrepancy between visible and infrared modalities can significantly affect the accuracy of VI-ReID. To better attenuate the influence of modality discrepancy, we design a Squeeze-Enhanced Transformer (SE Transformer) for VI-ReID, which consists of squeeze-enhanced Transformer blocks and is utilized for extracting discriminative features of pedestrians. Moreover, a multi-granularity feature enhancement module (MGFEM) is designed to perform feature enhancement by extracting coarse-grained and fine-grained features of specific modalities, and a channel interaction fusion module (CIFM) is designed to mitigate the influence of modality discrepancy by interactively fusing features of different modalities. Finally, a Cross-Fusion Enhanced Transformer model (CFET) for VI-ReID is designed by us, which uses the SE Transformer as the backbone and configures two multi-granularity feature enhancement modules and a channel interaction fusion module. In particular, we also design an alternating training strategy (ATS), which first uses the visible images to generate grayscale images, and then trains our CFET to improve its generalization ability using the grayscale images with infrared images and the visible images with infrared images alternately. Extensive experiments on two benchmark datasets indicate that our CFET reaches the current advanced level, achieving rank-1/mAP accuracy of 87.07%/83.66% on the RegDB dataset, and 69.59%/67.71% on the SYSU-MM01 dataset.","2025-05-01","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","271","","","","","","","","","","English","","","","WOS:001423853900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Feature enhancement; Feature fusion; Squeeze-Enhanced Transformer; Visible-infrared person re-identification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"46A79UEP","journalArticle","2024","Nasser, AA; Akhloufi, MA","A Hybrid Deep Learning Architecture for Apple Foliar Disease Detection","COMPUTERS","","2073-431X","10.3390/computers13050116","","Incorrectly diagnosing plant diseases can lead to various undesirable outcomes. This includes the potential for the misuse of unsuitable herbicides, resulting in harm to both plants and the environment. Examining plant diseases visually is a complex and challenging procedure that demands considerable time and resources. Moreover, it necessitates keen observational skills from agronomists and plant pathologists. Precise identification of plant diseases is crucial to enhance crop yields, ultimately guaranteeing the quality and quantity of production. The latest progress in deep learning (DL) models has demonstrated encouraging outcomes in the identification and classification of plant diseases. In the context of this study, we introduce a novel hybrid deep learning architecture named ""CTPlantNet"". This architecture employs convolutional neural network (CNN) models and a vision transformer model to efficiently classify plant foliar diseases, contributing to the advancement of disease classification methods in the field of plant pathology research. This study utilizes two open-access datasets. The first one is the Plant Pathology 2020-FGVC-7 dataset, comprising a total of 3526 images depicting apple leaves and divided into four distinct classes: healthy, scab, rust, and multiple. The second dataset is Plant Pathology 2021-FGVC-8, containing 18,632 images classified into six categories: healthy, scab, rust, powdery mildew, frog eye spot, and complex. The proposed architecture demonstrated remarkable performance across both datasets, outperforming state-of-the-art models with an accuracy (ACC) of 98.28% for Plant Pathology 2020-FGVC-7 and 95.96% for Plant Pathology 2021-FGVC-8.","2024-05","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","5","13","","","","","","","","","","English","","","","WOS:001232222200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","apple foliar disease; CLASSIFICATION; computer-aided detection; convolutional neural networks; deep learning; ensemble learning; multi-classification; vision transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NLLIBL7C","journalArticle","2024","Yan, J; Lin, T; Zhao, S","Migration Learning and Multi-View Training for Low-Resource Machine Translation Migration Learning and Multi-View Training","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","This paper discusses the main challenges and solution strategies of low-resource machine translation, and proposes a novel translation method combining migration learning and multi-view training. In a low-resource environment, neural machine translation models are prone to problems such as insufficient generalization performance, inaccurate translation of long sentences, difficulty in processing unregistered words, and inaccurate translation of domain-specific terms due to their heavy reliance on massively parallel corpora. Migration learning gradually adapts to the translation tasks of low-resource languages in the process of fine-tuning by borrowing the general translation knowledge of high-resource languages and utilizing pre-training models such as BERT, XLM-R, and so on. Multi-perspective training, on the other hand, emphasizes the integration of source and target language features from multiple levels, such as word level, syntax and semantics, in order to enhance the model's comprehension and translation ability under limited data conditions. In the experiments, the study designed an experimental scheme containing pre- training model selection, multi-perspective feature construction, and migration learning and multi-perspective fusion, and compared the performance with randomly initialized Transformer model, pre-training-only model, and traditional statistical machine translation model. The experiments demonstrate that the model with multi-view training strategy significantly outperforms the baseline model in evaluation metrics such as BLEU, TER, and ChrF, and exhibits stronger robustness and accuracy in processing complex language structures and domain-specific terminology.","2024-05","2025-02-26 20:43:27","2025-02-26 20:43:27","","719-728","","5","15","","","","","","","","","","English","","","","WOS:001315627600072","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","continual pretraining; Low-resource machine translation; migration learning; multi-view training; multidimensional linguistic feature integration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GU4S5Z3N","journalArticle","2024","Yang, TP; Ling, TZ; Sun, BY; Liang, ZD; Xu, F; Huang, XS; Xie, LH; He, YH; Li, LY; He, FC; Wang, Y; Chang, C","Introducing π-HelixNovo for practical large-scale de novo peptide sequencing","BRIEFINGS IN BIOINFORMATICS","","1467-5463","10.1093/bib/bbae021","","De novo peptide sequencing is a promising approach for novel peptide discovery, highlighting the performance improvements for the state-of-the-art models. The quality of mass spectra often varies due to unexpected missing of certain ions, presenting a significant challenge in de novo peptide sequencing. Here, we use a novel concept of complementary spectra to enhance ion information of the experimental spectrum and demonstrate it through conceptual and practical analyses. Afterward, we design suitable encoders to encode the experimental spectrum and the corresponding complementary spectrum and propose a de novo sequencing model pi-HelixNovo based on the Transformer architecture. We first demonstrated that pi-HelixNovo outperforms other state-of-the-art models using a series of comparative experiments. Then, we utilized pi-HelixNovo to de novo gut metaproteome peptides for the first time. The results show pi-HelixNovo increases the identification coverage and accuracy of gut metaproteome and enhances the taxonomic resolution of gut metaproteome. We finally trained a powerful pi-HelixNovo utilizing a larger training dataset, and as expected, pi-HelixNovo achieves unprecedented performance, even for peptide-spectrum matches with never-before-seen peptide sequences. We also use the powerful pi-HelixNovo to identify antibody peptides and multi-enzyme cleavage peptides, and pi-HelixNovo is highly robust in these applications. Our results demonstrate the effectivity of the complementary spectrum and take a significant step forward in de novo peptide sequencing.","2024-01-22","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","2","25","","","","","","","","","","English","","","","WOS:001177227400007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","antibody and multi-enzyme cleavage peptide; complementary spectrum; DATABASE; de novo peptide sequencing; DISSOCIATION; gut metaproteome; IDENTIFICATION; pi-HelixNovo; SEARCH; SPECTRA; STRATEGY; TANDEM-MASS-SPECTROMETRY; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EYQFH6U2","journalArticle","2024","Hong, WJ; Huang, ZC; Wang, A; Liu, YX; Cai, JC; Su, H","SeaIceNet: Sea Ice Recognition via Global-Local Transformer in Optical Remote Sensing Images","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2024.3493121","","The recognition of sea ice is of great significance for reflecting climate change and ensuring the safety of ship navigation. Recently, many deep-learning-based methods have been proposed and applied to segment and recognize sea ice regions. However, there are huge differences in sea ice size and irregular edge profiles, which bring challenges to the existing sea ice recognition. In this article, a global-local Transformer network, called SeaIceNet, is proposed for sea ice recognition in optical remote sensing images. In SeaIceNet, a dual global-attention head (DGAH) is proposed to capture global information. On this basis, a global-local feature fusion (GLFF) mechanism is designed to fuse global structural correlation features and local spatial detail features. Furthermore, a detail-guided decoder is developed to retain more high-resolution detail information during feature reconstruction for improving the performance of sea ice recognition. Extensive experiments on several sea ice datasets demonstrated that the proposed SeaIceNet has better performance than the existing methods in multiple evaluation indicators. Moreover, it excels in addressing challenges associated with sea ice recognition in optical remote sensing images, including the difficulty in accurately identifying irregular frozen ponds in complex environments, the broken and unclear boundaries between sea and thin ice that hinder precise segmentation, and the loss of high-resolution spatial details during model learning that complicates refinement.","2024","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","62","","","","","","","","","","English","","","","WOS:001358693100031","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Accuracy; Climate change; Data mining; Deep learning; Feature extraction; Ice; Image segmentation; Integrated optics; Optical imaging; Optical sensors; Remote sensing; Sea ice; sea ice recognition; SEGMENTATION; semantic segmentation; SYNTHETIC-APERTURE RADAR; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AMS6PSJ9","journalArticle","2024","Lombardo, G; Trimigno, G; Pellegrino, M; Cagnoni, S","Language Models Fine-Tuning for Automatic Format Reconstruction of SEC Financial Filings","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3370444","","The analysis of financial reports is a crucial task for investors and regulators, especially the mandatory annual reports (10-K) required by the SEC (Securities and Exchange Commission) that provide crucial information about a public company in the American stock market. Although SEC suggests a specific document format to standardize and simplify the analysis, in recent years, several companies have introduced their own format and organization of the contents, making human-based and automatic knowledge extraction inherently more difficult. In this research work, we investigate different Neural language models based on Transformer networks (Bidirectional recurrence-based, Autoregressive-based, and Autoencoders-based approaches) to automatically reconstruct an SEC-like format of the documents as a multi-class classification task with 18 classes at the sentence level. In particular, we propose a Bidirectional fine-tuning procedure to specialize pre-trained language models on this task. We propose and make the resulting novel transformer model, named SEC-former, publicly available to deal with this task. We evaluate SEC-former in three different scenarios: 1) in terms of topic detection performances; 2) in terms of document similarity (TF-IDF Bag-of-words and Doc2Vec) achieved with respect to original and trustable financial reports since this operation is leveraged for portfolio optimization tasks; and 3) testing the model in a real use-case scenario related to a public company that does not respect the SEC format but provides a human-supervised reference to reconstruct it.","2024","2025-02-26 20:43:27","2025-02-26 20:43:27","","31249-31261","","","12","","","","","","","","","","English","","","","WOS:001176095400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","deep learning; document reconstruction; PREDICTION; SEC filings; stock market; topic detection; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6RTQCFNP","journalArticle","2023","Choi, HS; Kim, JS; Whangbo, TK; Eun, SJ","Improved Detection of Urolithiasis Using High-Resolution Computed Tomography Images by a Vision Transformer Model","INTERNATIONAL NEUROUROLOGY JOURNAL","","2093-4777","10.5213/inj.2346292.146","","Purpose: Urinary stones cause lateral abdominal pain and are a prevalent condition among younger age groups. The diagnosis typically involves assessing symptoms, conducting physical examinations, performing urine tests, and utilizing radiological imaging. Artificial intelligence models have demonstrated remarkable capabilities in detecting stones. However, due to insufficient datasets, the performance of these models has not reached a level suitable for practical application. Consequently, this study introduces a vision transformer (ViT)-based pipeline for detecting urinary stones, using computed tomography images with augmentation. Methods: The super-resolution convolutional neural network (SRCNN) model was employed to enhance the resolution of a given dataset, followed by data augmentation using CycleGAN. Subsequently, the ViT model facilitated the detection and classification of urinary tract stones. The model's performance was evaluated using accuracy, precision, and recall as metrics. Results: The deep learning model based on ViT showed superior performance compared to other existing models. Furthermore, the performance increased with the size of the backbone model. Conclusions: The study proposes a way to utilize medical data to improve the diagnosis of urinary tract stones. SRCNN was used for data preprocessing to enhance resolution, while CycleGAN was utilized for data augmentation. The ViT model was utilized for stone detection, and its performance was validated through metrics such as accuracy, sensitivity, specificity, and the F1 score. It is anticipated that this research will aid in the early diagnosis and treatment of urinary tract stones, thereby improving the efficiency of medical personnel.","2023-11","2025-02-26 20:43:27","2025-02-26 20:43:27","","S99-S103","","","27","","","","","","","","","","English","","","","WOS:001111259500007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","Artificial intelligence; Deep learning; Machine learning; Ureteral calculi; Urolithiasis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ASNKDRJ2","journalArticle","2023","Gao, ZP; Yan, JC; Zhai, GT; Zhang, JY; Yang, XK","Robust Mesh Representation Learning via Efficient Local Structure-Aware Anisotropic Convolution","IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS","","2162-237X","10.1109/TNNLS.2022.3151609","","Mesh is a type of data structure commonly used for 3-D shapes. Representation learning for 3-D meshes is essential in many computer vision and graphics applications. The recent success of convolutional neural networks (CNNs) for structured data (e.g., images) suggests the value of adapting insights from CNN for 3-D shapes. However, 3-D shape data are irregular since each node's neighbors are unordered. Various graph neural networks for 3-D shapes have been developed with isotropic filters or predefined local coordinate systems to overcome the node inconsistency on graphs. However, isotropic filters or predefined local coordinate systems limit the representation power. In this article, we propose a local structure-aware anisotropic convolutional operation (LSA-Conv) that learns adaptive weighting matrices for each template's node according to its neighboring structure and performs shared anisotropic filters. In fact, the learnable weighting matrix is similar to the attention matrix in the random synthesizer--a new Transformer model for natural language processing (NLP). Since the learnable weighting matrices require large amounts of parameters for high-resolution 3-D shapes, we introduce a matrix factorization technique to notably reduce the parameter size, denoted as LSA-small. Furthermore, a residual connection with a linear transformation is introduced to improve the performance of our LSA-Conv. Comprehensive experiments demonstrate that our model produces significant improvement in 3-D shape reconstruction compared to state-of-the-art methods.","2023-11","2025-02-26 20:43:27","2025-02-26 20:43:27","","8566-8578","","11","34","","","","","","","","","","English","","","","WOS:000764879200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","3-D mesh; 3-D morpable model; Convolution; Faces; graph convolutional network (GCN); representation learning; Representation learning; Shape; Solid modeling; Spirals; Topology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NI9KEMRB","journalArticle","2021","Zhang, LN; Liu, JW; Song, ZY; Zuo, X","Universal transformer Hawkes process with adaptive recursive iteration","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2021.104416","","Asynchronous events sequences are widely distributed in the natural world and human activities, such as earthquakes records, users' activities in social media, and so on. How to distill the information from these seemingly disorganized data is a persistent topic that researchers focus on. One of the most useful models is the point process model, and on the basis, the researchers obtain many noticeable results. Moreover, in recent years, point process models on the foundation of neural networks, especially recurrent neural networks (RNN) are proposed and compare with the traditional models, their performance is greatly improved. Enlighten by transformer model, which can learn sequence data efficiently without recurrent and convolutional structure, transformer Hawkes process comes out, and achieves state-of-the-art performance. However, there is some research proving that the re-introduction of recursive calculations in transformer can further improve transformer's performance. Thus, we come out with a new kind of transformer Hawkes process model, universal transformer Hawkes process (UTHP), which contains both recursive mechanism and self-attention mechanism, and to improve the local perception ability of the model, we also introduce convolutional neural network (CNN) in the position-wise-feed-forward part. We conduct experiments on several datasets to validate the effectiveness of UTHP and explore the changes after the introduction of the recursive mechanism. These experiments on multiple datasets demonstrate that the performance of our proposed new model has a certain improvement compared with the previous state-of-the-art models.","2021-10","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","105","","","","","","","","","","English","","","","WOS:000701281200014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Convolutional neural network; Hawkes process; Recursive calculation; Self-attention mechanism; Universal transformer Hawkes process","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N9W7NUM3","journalArticle","2023","Henry, F; Parsi, A; Glavin, M; Jones, E","Experimental Investigation of Acoustic Features to Optimize Intelligibility in Cochlear Implants","SENSORS","","1424-8220","10.3390/s23177553","","Although cochlear implants work well for people with hearing impairment in quiet conditions, it is well-known that they are not as effective in noisy environments. Noise reduction algorithms based on machine learning allied with appropriate speech features can be used to address this problem. The purpose of this study is to investigate the importance of acoustic features in such algorithms. Acoustic features are extracted from speech and noise mixtures and used in conjunction with the ideal binary mask to train a deep neural network to estimate masks for speech synthesis to produce enhanced speech. The intelligibility of this speech is objectively measured using metrics such as Short-time Objective Intelligibility (STOI), Hit Rate minus False Alarm Rate (HIT-FA) and Normalized Covariance Measure (NCM) for both simulated normal-hearing and hearing-impaired scenarios. A wide range of existing features is experimentally evaluated, including features that have not been traditionally applied in this application. The results demonstrate that frequency domain features perform best. In particular, Gammatone features performed best for normal hearing over a range of signal-to-noise ratios and noise types (STOI = 0.7826). Mel spectrogram features exhibited the best overall performance for hearing impairment (NCM = 0.7314). There is a stronger correlation between STOI and NCM than HIT-FA and NCM, suggesting that the former is a better predictor of intelligibility for hearing-impaired listeners. The results of this study may be useful in the design of adaptive intelligibility enhancement systems for cochlear implants based on both the noise level and the nature of the noise (stationary or non-stationary).","2023-09","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","17","23","","","","","","","","","","English","","","","WOS:001062784700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;82</p>","","","acoustic features; ALGORITHM; cochlear implant (CI); DISCRETE WAVELET COEFFICIENTS; IMPROVE; machine learning (ML); MASKING; neural network (NN); NEURAL-NETWORKS; NOISE; noise reduction (NR); PERCEPTION; RECOGNITION; SEPARATION; SPEECH ENHANCEMENT; speech enhancement (SE); speech intelligibility (SI)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NSHIEN9D","journalArticle","2022","Jeancolas, L; Mangone, G; Petrovska-Delacrétaz, D; Benali, H; Benkelfat, BE; Arnulf, I; Corvol, JC; Vidailhet, M; Lehéricy, S","Voice characteristics from isolated rapid eye movement sleep behavior disorder to early Parkinson's disease","PARKINSONISM & RELATED DISORDERS","","1353-8020","10.1016/j.parkreldis.2022.01.003","","Background: Speech disorders are amongst the first symptoms to appear in Parkinson's disease (PD). Objectives: We aimed to characterize PD voice signature from the prodromal stage (isolated rapid eye movement sleep behavior disorder, iRBD) to early PD using an automated acoustic analysis and compare male and female patients. We carried out supervised learning classifications to automatically detect patients using voice only. Methods: Speech samples were acquired in 256 French speakers (117 participants with early PD, 41 with iRBD, and 98 healthy controls), with a professional quality microphone, a computer microphone and their own telephone. High-level features related to prosody, phonation, speech fluency and rhythm abilities were extracted. Group analyses were performed to determine the most discriminant features, as well as the impact of sex, vocal tasks, and microphone type. These speech features were used as inputs of a support vector machine and were combined with classifiers using low-level features. Results: PD related impairments were found in prosody, pause durations and rhythmic abilities, from the prodromal stage. These alterations were more pronounced in men than in women. Early PD detection was achieved with a balanced accuracy of 89% in males and 70% in females. Participants with iRBD were detected with a balanced accuracy of 63% (reaching 70% in the subgroup with mild motor symptoms). Conclusion: This study provides new insight in the characterization of sex-dependent early PD speech impairments, and demonstrates the valuable benefit of including automated voice analysis in future diagnostic procedures of prodromal PD.","2022-02","2025-02-26 20:43:27","2025-02-26 20:43:27","","86-91","","","95","","","","","","","","","","English","","","","WOS:000749847700016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Acoustic analysis; GENDER; IMPAIRMENT; Parkinson 's disease; REM sleep behavior disorder; SPEECH; Speech disorders; Supervised classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PJ2W3SWP","journalArticle","2022","Yasmin, G; Das, AK; Nayak, J; Vimal, S; Dutta, S","A rough set theory and deep learning-based predictive system for gender recognition using audio speech","SOFT COMPUTING","","1432-7643","10.1007/s00500-022-07074-z","","Speech is one of the most delicate medium through which gender of the speakers can easily be identified. Though the related research has shown very good progress in machine learning, but recently, deep learning has imparted a very good research area to explore the deficiency of gender discrimination using traditional machine learning techniques. In deep learning techniques, the speech features are automatically generated by the reinforcement learning from the raw data which have more discriminating power than the human-generated features. But in some practical situations like gender recognition, it is observed that combination of both types of features sometimes provides comparatively better performance. In the proposed work, we have initially extracted and selected some informative and precise acoustic features relevant to gender recognition using entropy-based information theory and Rough Set Theory (RST). Next, the audio speech signals are directly fed into the deep neural network model consisting of Convolution Neural Network (CNN) and Gated Recurrent Unit network (GRUN) for extracting features useful for gender recognition. The RST selects precise and informative features, CNN extracts the locally encoded important features, and GRUN reduces the vanishing gradient and exploding gradient problems. Finally, a hybrid gender recognition system is developed combining both generated feature vectors. The developed model has been tested with five bench mark and a simulated dataset to evaluate its performance, and it is observed that combined feature vector provides more effective gender recognition system specially when transgender is considered as a gender type together with male and female.","2022-04-20","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","","","","","","","","","","","English","","","","WOS:000784866700005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Acoustic features; ALGORITHM; Deep neural network; Feature selection; INFORMATION; Information theory; Machine learning; NEURAL-NETWORKS; Rough set theory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T26XF5CV","journalArticle","2022","Wang, J; Liu, B","Intelligent Evaluation Algorithm of English Writing Based on Semantic Analysis","COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE","","1687-5265","10.1155/2022/8955638","","In order to solve the intelligent evaluation of English writing, this paper proposes a method based on the English semantic neural network algorithm. This paper first briefly analyzes the research background of the English semantic analysis system, then expounds on the relevant technologies of the English distance similarity algorithm, semantic analysis intelligent algorithm structure, word analysis algorithm, sentence part of speech analysis algorithm, sentence semantic analysis algorithm, and neural network algorithm, and finally expounds the database and method implementation of the English semantic analysis system, so as to provide guarantee for the design of the English semantic analysis system. The experimental results show that the recognition accuracy of the BRF network for English characters can reach 96.35%, which is 7.79% higher than that of the BP network; the AUC of the BRF network reaches 0.89, which is closer to 1 compared with 0.72 of the BP network. The test results are in good agreement with the antinoise curve test results of the figure. It is proved that the English semantic neural network algorithm can effectively improve the accuracy of English translation and further improve the efficiency of the system.","2022-10-05","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","2022","","","","","","","","","","English","","","","WOS:000884396600002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SZKCCLLF","journalArticle","2022","Tracey, B; Patel, S; Zhang, Y; Chappie, K; Volfson, D; Parisi, F; Adans-Dester, C; Bertacchi, F; Bonato, P; Wacnik, P","Voice Biomarkers of Recovery From Acute Respiratory Illness","IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS","","2168-2194","10.1109/JBHI.2021.3137050","","Voice analysis is an emerging technology which has the potential to provide low-cost, at-home monitoring of symptoms associated with a variety of health conditions. While voice has received significant attention for monitoring neurological disease, few studies have focused on voice changes related to flu-like symptoms. Herein, we investigate the relationship between changes in acoustic features of voice and self-reported symptoms during recovery from a flu-like illness in a cohort of 29 subjects. Acoustic features were automatically extracted from ""sick"" and ""well"" visit data collected in the laboratory setting, and feature down-selection was used to identify those that change significantly between visits. The selected acoustic features were extracted from at-home data and used to construct a combined distance metric that correlated with self-reported symptoms (0.63 rank correlation). Changes in self-reported symptoms corresponding to 10% of the ordinal scale used in the study were detected with an area under the curve of 0.72. The results show that acoustic features derived from voice recordings may provide an objective measure for diagnosing and monitoring symptoms of respiratory illnesses.","2022-06","2025-02-26 20:43:27","2025-02-26 20:43:27","","2787-2795","","6","26","","","","","","","","","","English","","","","WOS:000805811400041","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","ACOUSTIC MEASURES; Acoustics; biomedical acoustics; Biomedical signal processing; Feature extraction; INDEX; Measurement; Monitoring; Nose; Power measurement; Protocols; SPEECH; speech analysis; wearable sensors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HNN4WPD8","journalArticle","2023","Rafi, BSM; Sankala, S; Murty, KSR","Relative Significance of Speech Sounds in Speaker Verification Systems","CIRCUITS SYSTEMS AND SIGNAL PROCESSING","","0278-081X","10.1007/s00034-023-02360-z","","Automatic speaker verification (ASV) is the task of authenticating claimed identity of a speaker from his/her voice characteristics. State-of-the-art ASV systems rely on capturing the voice signature of a speaker in a fixed-dimensional embedding. Recent studies reported that the performance of the ASV system improves when phonetic information obtained from a phoneme recognizer is appended to the frame-level speech representations. This work aims at analyzing the relative significance of various phonetic classes in extracting the speaker discriminative embeddings. We use the temporal attention mechanism to analyze the importance of different phonetic classes in speaker verification. It is observed that vowels, fricatives, and nasals receive relatively higher attention in the speaker verification task. This observation is in accordance with the subjective studies reported earlier, which signify the speaker discriminative characteristics of vowels and nasals. In the process, we demonstrate the efficiency of self-supervised phonetic information in extracting robust speaker embeddings. The proposed self-supervised phonetic attentive ASV system achieved a relative improvement of 29.2% over the baseline x-vector system and 19.3% over its supervised counterpart.","2023-09","2025-02-26 20:43:27","2025-02-26 20:43:27","","5412-5427","","9","42","","","","","","","","","","English","","","","WOS:000969185100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Phonetic information; Self-supervised learning; Speech analysis; Temporal attention","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WYYABT26","journalArticle","2021","Gowda, DN; Bollepalli, B; Kadiri, SR; Alku, P","Formant Tracking Using Quasi-Closed Phase Forward-Backward Linear Prediction Analysis and Deep Neural Networks","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2021.3126280","","Formant tracking is investigated in this study by using trackers based on dynamic programming (DP) and deep neural nets (DNNs). Using the DP approach, six formant estimation methods were first compared. The six methods include linear prediction (LP) algorithms, weighted LP algorithms and the recently developed quasi-closed phase forward-backward (QCP-FB) method. QCP-FB gave the best performance in the comparison. Therefore, a novel formant tracking approach, which combines benefits of deep learning and signal processing based on QCP-FB, was proposed. In this approach, the formants predicted by a DNN-based tracker from a speech frame are refined using the peaks of the all-pole spectrum computed by QCP-FB from the same frame. Results show that the proposed DNN-based tracker performed better both in detection rate and estimation error for the lowest three formants compared to reference formant trackers. Compared to the popular Wavesurfer, for example, the proposed tracker gave a reduction of 29%, 48%, and 35% in the estimation error for the lowest three formants, respectively.","2021","2025-02-26 20:43:27","2025-02-26 20:43:27","","151631-151640","","","9","","","","","","","","","","English","","","","WOS:000719550300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Autocorrelation; Computational modeling; deep neural net; dynamic programming; Estimation; formant tracking; linear prediction; Prediction algorithms; Predictive models; Signal processing algorithms; SPEECH; Speech analysis; Video recording","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"27UENZAK","journalArticle","2025","Do, MT; Ha, MH; Nguyen, DC; Chen, OTC","Toward improving precision and complexity of transformer-based cost-sensitive learning models for plant disease detection","FRONTIERS IN COMPUTER SCIENCE","","2624-9898","10.3389/fcomp.2024.1480481","","Early and accurate detection of plant diseases is crucial for making informed decisions to increase the yield and quality of crops through the decision of appropriate treatments. This study introduces an automated system for early disease detection in plants that enhanced a lightweight model based on the robust machine learning algorithm. In particular, we introduced a transformer module, a fusion of the SPP and C3TR modules, to synthesize features in various sizes and handle uneven input image sizes. The proposed model combined with transformer-based long-term dependency modeling and convolution-based visual feature extraction to improve object detection performance. To optimize a model to a lightweight version, we integrated the proposed transformer model with the Ghost module. Such an integration acted as regular convolutional layers that subsequently substituted for the original layers to cut computational costs. Furthermore, we adopted the SIoU loss function, a modified version of CIoU, applied to the YOLOv8s model, demonstrating a substantial improvement in accuracy. We implemented quantization to the YOLOv8 model using ONNX Runtime to enhance to facilitate real-time disease detection on strawberries. Through an experiment with our dataset, the proposed model demonstrated mAP@.5 characteristics of 80.30%, marking an 8% improvement compared to the original YOLOv8 model. In addition, the parameters and complexity were reduced to approximately one-third of the initial model. These findings demonstrate notable improvements in accuracy and complexity reduction, making it suitable for detecting strawberry diseases in diverse conditions.","2025-01-22","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","6","","","","","","","","","","English","","","","WOS:001412999300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","android application; DNN; Ghost Conv; pre-trained; quantization; SIoU loss function; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X7JM5AF2","journalArticle","2023","Rukhsar, S; Tiwari, AK","Lightweight convolution transformer for cross-patient seizure detection in multi-channel EEG signals","COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE","","0169-2607","10.1016/j.cmpb.2023.107856","","Background: Epilepsy is a neurological illness affecting the brain that makes people more likely to experience frequent, spontaneous seizures. There has to be an accurate automated method for measuring seizures frequency and severity to assess the efficacy of pharmacological therapy for epilepsy. The drug quantities are often derived from patient reports which may cause significant issues owing to inadequate or inaccurate descriptions of seizures and their frequencies.Methods and materials: This study proposes a novel deep learning architecture-based Lightweight Convolution Transformer (LCT). The Transformer model is able to learn spatial and temporal correlated information simultaneously from the multi-channel electroencephalogram (EEG) signal to detect seizures at smaller segment lengths. In the proposed work, the lack of translation equivariance and localization of ViT is reduced using convolution tokenization, and rich information from the Transformer encoder is extracted by sequence pooling instead of the learnable class token. Results: Extensive experimental results demonstrate that the proposed model on cross-patient learning can effectively detect seizures from the raw EEG signals. The accuracy and F1-score of seizure detection in the cross-patient case on the CHB-MIT dataset are 96.31% and 96.32%, respectively, at 0.5 sec segment length. In addition, the performance metrics show that the inclusion of inductive biases and attention-based pooling in the model enhances the performance and reduces the number of Transformer encoder layers, which significantly reduces the computational complexity. In this research, we provide a novel approach to enhance efficiency and simplify the architecture for multi-channel automated seizure detection.","2023-12","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","242","","","","","","","","","","English","","","","WOS:001094887200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","CLASSIFICATION; Convolutional neural network; Electroencephalogram; Epilepsy; Seizure detection; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WLRKCDFD","journalArticle","2023","Zhang, YZ; Wang, TY; You, Y; Wang, DC; Gao, JL; Liang, TG","A transformer-based image detection method for grassland situation of alpine meadows","COMPUTERS AND ELECTRONICS IN AGRICULTURE","","0168-1699","10.1016/j.compag.2023.107919","","As a vital role in climate regulation, water conservation, and maintenance of ecological balance, the alpine meadow grassland is facing the threat of degradation. Detecting grassland topography, phytomass, and grassland damage are important for improving the alpine meadow situation. This study reports a Transformer-CNN method for detecting alpine meadows situations using UnmannedAerial Vehicle (UAV) -based RGB (Red, Green, and Blue) data. This method combines Oriented FAST and Rotated BRIEF (ORB) and brute force feature matching to complete image stitching and then uses the proposed model Am-mask to complete the image segmentation task. The result shows that ORB feature matching is more stable and fast than SIFT and SURF for alpine meadow image stitching. In addition, Transformer has great application potential in grassland image detection and introducing task prefix and sparse in pre-training enhances the model's robustness. The AP value of the Am-mask model with Transformer was as high as 95.4%, about 10% higher than that of the original CNN models. In the experiment with unstitched images, the average precision of the eight trials was 95.16%, the average recall was 95.13%, and the average F1 value was 95.14%. For stitched images, the average precision, recall, and F1 value of the eight trials were 91.83%, 91.81%, and 91.82%, respectively. It was proved that the proposed method could save the inference cost of the model under the condition of ensuring the detection effect. This study may contribute to grassland environmental protection in alpine meadows.","2023-07","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","210","","","","","","","","","","English","","","","WOS:001009343100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Alpine meadow; Deep learning; Image segmentation; Image stitching; LIDAR; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BFRT7TTK","journalArticle","2022","Picek, L; Sulc, M; Patel, Y; Matas, J","Plant recognition by AI: Deep neural nets, transformers, and kNN in deep embeddings","FRONTIERS IN PLANT SCIENCE","","1664-462X","10.3389/fpls.2022.787527","","The article reviews and benchmarks machine learning methods for automatic image-based plant species recognition and proposes a novel retrieval-based method for recognition by nearest neighbor classification in a deep embedding space. The image retrieval method relies on a model trained via the Recall@k surrogate loss. State-of-the-art approaches to image classification, based on Convolutional Neural Networks (CNN) and Vision Transformers (ViT), are benchmarked and compared with the proposed image retrieval-based method. The impact of performance-enhancing techniques, e.g., class prior adaptation, image augmentations, learning rate scheduling, and loss functions, is studied. The evaluation is carried out on the PlantCLEF 2017, the ExpertLifeCLEF 2018, and the iNaturalist 2018 Datasets-the largest publicly available datasets for plant recognition. The evaluation of CNN and ViT classifiers shows a gradual improvement in classification accuracy. The current state-of-the-art Vision Transformer model, ViT-Large/16, achieves 91.15% and 83.54% accuracy on the PlantCLEF 2017 and ExpertLifeCLEF 2018 test sets, respectively; the best CNN model (ResNeSt-269e) error rate dropped by 22.91% and 28.34%. Apart from that, additional tricks increased the performance for the ViT-Base/32 by 3.72% on ExpertLifeCLEF 2018 and by 4.67% on PlantCLEF 2017. The retrieval approach achieved superior performance in all measured scenarios with accuracy margins of 0.28%, 4.13%, and 10.25% on ExpertLifeCLEF 2018, PlantCLEF 2017, and iNat2018-Plantae, respectively.","2022-09-27","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","13","","","","","","","","","","English","","","","WOS:000868264700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","classification; computer vision; FEATURES; fine-grained; IDENTIFICATION; machine learning; plant; recognition; SHAPE; species; species recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G7Q8SL6P","journalArticle","2023","Cheng, JX","Acquisition of English liaison among Chinese EFL learners from the perspective of language transfer","HELIYON","","2405-8440","10.1016/j.heliyon.2023.e20418","","This study aimed to investigate the acquisition of liaison in English by Chinese-speaking learners. Ten second-year postgraduate students of non-English majors in Tongji University, China, were invited to take part in an experiment. They were asked to prepare recordings of a set of English materials, including phrases, dialogues, and a talking topic, before and after a self-study training on liaison. To examine every type of liaison in their speech, the study analysed the recordings using the speech analysis software Praat. The results showed that before the training, the students negatively transferred the native language (L1) pattern to the target second language (L2). This kind of negative transfer of L1 Chinese to the acquisition of liaison in L2 English could be explained by the differences between English and Chinese syllables. After the training, the students showed substantial improvement in phrase and dialogue reading. The findings are expected to help both teachers and students gain a better understanding of liaison and the differences between English and Chinese syllables, thus contributing to English teaching and learning.","2023-10","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","10","9","","","","","","","","","","English","","","","WOS:001085995000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","Chinese EFL learners; English and Chinese syllables; liaison; negative transfer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6H898822","journalArticle","2022","Martínez-Nicolás, I; Llorente, TE; Ivanova, O; Martínez-Sánchez, F; Meilán, JJG","Many Changes in Speech through Aging Are Actually a Consequence of Cognitive Changes","INTERNATIONAL JOURNAL OF ENVIRONMENTAL RESEARCH AND PUBLIC HEALTH","","1660-4601","10.3390/ijerph19042137","","Background: During aging, changes in human speech may arise because of the neurophysiological deterioration associated with age, or as the result of an impairment in the cognitive processes underlying speech production. Some speech parameters show specific alterations under the presence of dementia. The objective of our study is to identify which of these parameters change because of age, cognitive state, or the interaction of both. Methods: The sample includes 400 people over 55 years old, who were divided into four groups, according to their age. The cognitive state of the participants was assessed through the MMSE test and three ranks were stablished. Gender was also considered in the analysis. Results: Certain temporal, fluency, rhythm, amplitude and voice quality parameters were found to be related to the cognitive state, while disturbance parameters changed due to age. Frequency parameters were exclusively influenced by gender. Conclusions: Understanding how speech parameters are specifically affected by age, cognitive state, or the interaction of both, is determinant to advance in the use of speech as a clinical marker for the detection of cognitive impairments.","2022-02","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","4","19","","","","","","","","","","English","","","","WOS:000769121500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","aging voice; APHASIA; cognitive impairment; cognitive state; DEMENTIA; DEPRESSION; DISEASE; IMPAIRMENT; MEMORY; MILD; MINI-MENTAL-STATE; MMSE; RETRIEVAL; speech analysis; TEST BATTERY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KVURJHZX","journalArticle","2023","Tsujikawa, M; Kajikawa, Y","Low-Complexity and Accurate Noise Suppression Based on an a Priori SNR Model for Robust Speech Recognition on Embedded Systems and Its Evaluation in a Car Environment","IEICE TRANSACTIONS ON FUNDAMENTALS OF ELECTRONICS COMMUNICATIONS AND COMPUTER SCIENCES","","0916-8508","10.1587/transfun.2022EAP1130","","In this paper, we propose a low-complexity and accurate noise suppression based on an a priori SNR (Speech to Noise Ratio) model for greater robustness w.r.t. short-term noise-fluctuation. The a priori SNR, the ratio of speech spectra and noise spectra in the spectral domain, represents the difference between speech features and noise features in the feature domain, including the mel-cepstral domain and the logarithmic power spectral domain. This is because logarithmic operations are used for domain conversions. Therefore, an a priori SNR model can easily be expressed in terms of the difference between the speech model and the noise model, which are modeled by the Gaussian mixture models, and it can be generated with low computational cost. By using a priori SNRs accurately estimated on the basis of an a priori SNR model, it is possible to calculate accurate coefficients of noise suppression filters taking into account the variance of noise, without serious increase in computational cost over that of a conventional model-based Wiener filter (MBW). We have conducted in-car speech recognition evaluation using the CENSREC-2 database, and a comparison of the proposed method with a conventional MBW showed that the recognition error rate for all noise environments was reduced by 9%, and that, notably, that for audio-noise environments was reduced by 11%. We show that the proposed method can be processed with low levels of computational and memory resources through implementation on a digital signal processor.","2023-09","2025-02-26 20:43:27","2025-02-26 20:43:27","","1224-1233","","9","E106A","","","","","","","","","","English","","","","WOS:001100161200018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","a priori SNR model; embedded system; ENHANCEMENT; model-based noise suppres-sion; noise-robust speech recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KAVDDEBC","journalArticle","2023","Cummins, N; Dineley, J; Conde, P; Matcham, F; Siddi, S; Lamers, F; Carr, E; Lavelle, G; Leightley, D; White, KM; Oetzmann, C; Campbell, EL; Simblett, S; Bruce, S; Haro, JM; Penninx, BWJH; Ranjan, Y; Rashid, Z; Stewart, C; Folarin, AA; Bailón, R; Schuller, BW; Wykes, T; Vairavan, S; Dobson, RJB; Narayan, VA; RADAR-CNS Consortium; Hotopf, M","Multilingual markers of depression in remotely collected speech samples: A preliminary analysis","JOURNAL OF AFFECTIVE DISORDERS","","0165-0327","10.1016/j.jad.2023.08.097","","Background: Speech contains neuromuscular, physiological and cognitive components, and so is a potential biomarker of mental disorders. Previous studies indicate that speaking rate and pausing are associated with major depressive disorder (MDD). However, results are inconclusive as many studies are small and underpow-ered and do not include clinical samples. These studies have also been unilingual and use speech collected in controlled settings. If speech markers are to help understand the onset and progress of MDD, we need to uncover markers that are robust to language and establish the strength of associations in real-world data.Methods: We collected speech data in 585 participants with a history of MDD in the United Kingdom, Spain, and Netherlands as part of the RADAR-MDD study. Participants recorded their speech via smartphones every two weeks for 18 months. Linear mixed models were used to estimate the strength of specific markers of depression from a set of 28 speech features.Results: Increased depressive symptoms were associated with speech rate, articulation rate and intensity of speech elicited from a scripted task. These features had consistently stronger effect sizes than pauses.Limitations: Our findings are derived at the cohort level so may have limited impact on identifying intra-individual speech changes associated with changes in symptom severity. The analysis of features averaged over the entire recording may have underestimated the importance of some features.Conclusions: Participants with more severe depressive symptoms spoke more slowly and quietly. Our findings are from a real-world, multilingual, clinical dataset so represent a step-change in the usefulness of speech as a digital phenotype of MDD.","2023-11-15","2025-02-26 20:43:27","2025-02-26 20:43:27","","128-136","","","341","","","","","","","","","","English","","","","WOS:001078299700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Digital phenotypes; In-the-wild; Major depressive disorder; SELF-REPORT; SEVERITY; Speaking rate; Speech; SYMPTOMS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3E2HEECZ","journalArticle","2023","Eren, E; Demiroglu, C","Deep learning-based speaker-adaptive postfiltering with limited adaptation data for embedded text-to-speech synthesis systems","COMPUTER SPEECH AND LANGUAGE","","0885-2308","10.1016/j.csl.2023.101520","","End-to-end (e2e) speech synthesis systems have become popular with the recent introduc-tion of text-to-spectrogram conversion systems, such as Tacotron, that use encoder-decoder-based neural architectures. Even though those sequence-to-sequence systems can produce mel-spectrograms from the letters without a text processing frontend, they require substantial amounts of well-manipulated, labeled audio data that have high SNR and minimum amounts of artifacts. These data requirements make it difficult to build end-to-end systems from scratch, especially for low-resource languages. Moreover, most of the e2e systems are not designed for devices with tiny memory and CPU resources. Here, we investigate using a traditional deep neural network (DNN) for acoustic modeling together with a postfilter that improves the speech features produced by the network. The proposed architectures were trained with the relatively noisy, multi-speaker, Wall Street Journal (WSJ) database and tested with unseen speakers. The thin postfilter layer was adapted with minimal data to the target speaker for testing. We inves-tigated several postfilter architectures and compared them with both objective and subjective tests. Fully-connected and transformer-based architectures performed the best in subjective tests. The novel adversarial transformer-based architecture with adaptive discriminator loss performed the best in the objective tests. Moreover, it was faster than the other architectures both in training and inference. Thus, our proposed lightweight transformer-based postfilter architecture significantly improved speech quality and efficiently adapted to new speakers with few shots of data and a hundred training iterations, making it computationally efficient and suitable for scalability.","2023-06","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","81","","","","","","","","","","English","","","","WOS:000978850300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","Adversarial training; Deep learning; GLOBAL VARIANCE; Postfilter; Speaker adaptation; Speech synthesis; Transformer; VOCODER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CU84CZ6W","journalArticle","2024","Rehman, MU; Shafique, A; Azhar, QU; Jamal, SS; Gheraibia, Y; Usman, AB","Voice disorder detection using machine learning algorithms: An application in speech and language pathology","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2024.108047","","The healthcare industry is currently seeing a significant rise in the use of mobile devices. These devices not only provide ways for communication and sharing of multimedia information, such as clinical notes and medical records, but also offer new possibilities for people to detect, monitor, and manage their health from anywhere at any time. Digital health technologies have the potential to improve patient care by making it more efficient, effective, and cost-effective. Utilizing digital devices and technologies can have a positive impact on many health conditions. This research focuses on dysphonia, a change in the sound of the voice that affects around one-third of individuals at some point in their lives. Voice disorders are becoming more common, despite being often overlooked. Mobile healthcare systems can provide quick and efficient assistance for detecting voice disorders. To make these systems reliable and accurate, it is important to develop an algorithm that can classify intelligently healthy and pathological voices. To achieve this task, we utilized a combination of several datasets such as Saarbruecken voice dataset (SVD), the Massachusetts Eye and Ear Infirmary database (MEEI), and a few private datasets of various voices (healthy and pathological) Additionally, we applied multiple machine learning algorithms, including decision tree, random forest, and support vector machine, to evaluate and determine the most effective algorithm among them for the detection of voice disorders. The experimental analyses are performed in terms of sensitivity, accuracy, receiver operating characteristic area, specificity, F -score and recall. The results demonstrated that the support vector machine algorithm, depending on the features selected by using appropriate feature selection methods, proved to be the most accurate in detecting voice diseases.","2024-07","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","133","","","","","","","","","","English","","","","WOS:001179768600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;80</p>","","","CLASSIFICATION; FEATURES; IDENTIFICATION; Intelligent systems; INTERNET; Speech features; Support vector machine; SUPPORT VECTOR MACHINES; SYSTEM; THINGS; Voice signals","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"25V2P4KM","journalArticle","2022","Sivaraman, A; Kim, M","Efficient Personalized Speech Enhancement Through Self-Supervised Learning","IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING","","1932-4553","10.1109/JSTSP.2022.3181782","","This work presents self-supervised learning methods for monaural speaker-specific (i.e., personalized) speech enhancement models. While general-purpose models must broadly address many speakers, personalized models can adapt to a particular speaker's voice, expecting to solve a narrower problem. Hence, personalization can achieve more optimal performance in addition to reducing computational complexity. However, naive personalization methods can inconveniently require clean speech from the target user, e.g., due to subpar recording conditions. To this end, we pose personalization as either a zero-shot task, in which no clean speech of the target speaker is used, or a few-shot learning task, which is to minimize the duration of the clean speech used for transfer learning. With this paper, we propose self-supervised learning methods as a solution to both zero- and few-shot personalization tasks. The proposed methods learn the personalized speech features from unlabeled data (i.e., in-the-wild noisy recordings from the target user) rather than from the clean sources. We investigate three different self-supervised learning mechanisms. We set up a pseudo speech enhancement problem as a pretext task, which pretrains the models to estimate noisy speech as if it were the clean target. Contrastive learning and data purification methods regularize the loss function of the pseudo enhancement problem, overcoming the limitations of learning from unlabeled data. We assess our methods by personalizing the well-known ConvTasNet architecture to twenty different target speakers. The results show that self-supervision-based personalization improves the original ConvTasNet's enhancement quality with fewer model parameters and less clean data from the target user.","2022-10","2025-02-26 20:43:27","2025-02-26 20:43:27","","1342-1356","","6","16","","","","","","","","","","English","","","","WOS:000870301500018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Adaptation models; Data efficiency; Data models; model complexity; NEURAL-NETWORKS; Noise measurement; personalized speech enhancement; Recording; self-supervised learning; Speech enhancement; Task analysis; Training","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TCKCU5MR","journalArticle","2024","Liu, XT; Zhao, HR","Analyzing watershed system state through runoff complexity and driver interactions using multiscale entropy and deep learning","ECOLOGICAL INDICATORS","","1470-160X","10.1016/j.ecolind.2024.112779","","Quantifying watershed state is crucial for ecological management and sustainable development. Traditional methods, often based on multiple indicators and subjective weighting, struggle to objectively and comprehensively capture the inherent complexity of watershed ecosystems. Runoff, a key hydrological component, reflects watershed functioning, but most studies focus solely on runoff volume, limiting the ability to link runoff dynamics with surface conditions and broader system processes. This study introduced a novel approach that uses runoff complexity to represent watershed system-level state, bridging the gap between runoff dynamics and ecosystem functioning. The Hydrological Refined Composite Multiscale Entropy (Hydro_RCMFE) method was developed to quantify runoff complexity across various time scales. Combined with the Hydrological Complexity Transformer Model (HydroC_Trans) and Shapley Additive Explanations (SHAP), this method explored interactions between runoff complexity and influencing factors. It was applied to the Yanhe Watershed in China's Loess Plateau, known for severe soil erosion and large-scale ecological restoration. The results revealed significant fluctuations in runoff complexity after 2005. Vegetation cover from the Grain for Green Program enhanced self-organization, buffering climatic variability while introducing instability. Urbanization further amplified runoff complexity, while landscape factors, such as aggregation and hydrological connectivity, had spatially and temporally varied effects, highlighting the need for tailored management strategies. Upstream, efforts should enhance climate resilience, increase vegetation cover-particularly grasslands-and improve landscape aggregation. Midstream and downstream strategies should prioritize optimizing hydrological connectivity, limiting impervious surface expansion, and restoring ecological functions.","2024-11","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","168","","","","","","","","","","English","","","","WOS:001349701000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","ENVIRONMENT; Influencing factors; Refined composite multiscale fuzzy entropy; Runoff complexity; SUSTAINABILITY; TIME-SERIES DATA; Transformer; Watershed state","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XI9E9ALP","journalArticle","2024","Xie, FY; Wang, Y; Wang, G; Sun, EG; Fan, QY; Song, MH","Fault Diagnosis of Rolling Bearings in Agricultural Machines Using SVD-EDS-GST and ResViT","AGRICULTURE-BASEL","","2077-0472","10.3390/agriculture14081286","","In the complex and harsh environment of agriculture, rolling bearings, as the key transmission components in agricultural machinery, are very prone to failure, so research on the intelligent fault diagnosis of agricultural machinery components is critical. Therefore, this paper proposes a new method based on SVD-EDS-GST and ResNet-Vision Transformer (ResViT) for the fault diagnosis of rolling bearings in agricultural machines. Firstly, an experimental platform for rolling bearing failure in agricultural machinery is built, and one-dimensional vibration signals are obtained using acceleration sensors. Next, the signal is preprocessed for noise reduction using singular value decomposition (SVD) combined with the energy difference spectrum (EDS) to solve for the interference of complex noise and redundant components in the vibration signal. Secondly, generalized S-transform (GST) is used to process vibration signals into images. Then, the ResViT model is proposed, where the ResNet34 network is used to replace the image chunking mechanism in the original Vision Transformer model for feature extraction. Finally, an improved Vision Transformer (ViT) is utilized to synthesize global and local information for fault classification. The experimental results show that the proposed method's average accuracy in rolling bearing fault classification for agricultural machinery reaches 99.08%. In addition, compared with SVD-EDS-GST-CNN, SVD-EDS-GST-LSTM, STFT-ViT, GST-ViT, and SVD-EDS-GST-ViT, the accuracy rate was improved by 3.5%, 3.84%, 4.8%, 8.02%, and 0.56%, and the standard deviation was also minimized.","2024-08","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","8","14","","","","","","","","","","English","","","","WOS:001305103300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","agricultural machinery rolling bearing; fault diagnosis; GST; ResViT; SVD-EDS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9RHK5ZXS","journalArticle","2024","Chen, ZQ; Zheng, KX; Shen, JH; Lin, YW; Feng, Y; Xu, JS","Sample Point Classification of Abdominal ECG Through CNN-Transformer Model Enables Efficient Fetal Heart Rate Detection","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2023.3338710","","Monitoring fetal heart rate (FHR) is essential for the early detection of fetal distress and ensuring safe delivery. Direct invasive fetal electrocardiography (FECG) provides reliable FHR signals but is limited to use during labor. Noninvasive fetal heart monitoring can be achieved through abdominal electrocardiography (AECG), where fetal heartbeat waveforms are captured from electrodes placed on maternal abdomen. However, accurately locating fetal R-peaks and obtaining FHRs remain challenging due to interference from uterine contractions and maternal heartbeats. To address this challenge, we proposed an end-to-end fetal R-peak detection method based on sample point classification. Inspired by semantic segmentation in image analysis, we utilized an encoder-decoder model to classify each point in the 1-D AECG signal. The model captures the global contextual information of fetal heartbeat waveforms by combining convolutional neural networks (CNNs) and transformer, resulting in a high-precision classification of each sample point in the AECG signal. Moreover, to mitigate the impact of misclassified points on fetal R-peak detection, we proposed a postprocessing method based on the periodicity of heartbeats. The effectiveness of the proposed method is validated on two AECG databases, achieving satisfactory results with an average F1-score of 98.91%. These findings demonstrate the potential application of long-term fetal monitoring using portable devices. The code is publicly available at https://github.com/ZJUT-CBS/FR-Net.","2024","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","73","","","","","","","","","","English","","","","WOS:001132683400206","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;15</p>","","","Abdominal ECG (AECG); DEPENDENT SELLMEIER EQUATION; ELECTROOPTIC PROPERTIES; fetal heart rate (FHR); fetal R-peak detection; INDEX; sample point classification; SENSOR; TEMPERATURE-DEPENDENCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HAM8WMM5","journalArticle","2024","Tiwari, D; Nagpal, B; Bhati, BS; Gupta, M; Suanpang, P; Butdisuwan, S; Nanthaamornphong, A","SPSO-EFVM: A Particle Swarm Optimization-Based Ensemble Fusion Voting Model for Sentence-Level Sentiment Analysis","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3363158","","Sentiment analysis has received incremental growth in recent years for emerging applications, including human-robot integration, social platforms monitoring, and decision-support systems. Several neural or transformer model-based solutions have been provided in the field of sentiment analysis that relies on the decision of a single classifier or neural model. These are erroneous to encode contextual information into appropriate dialogues and increase extra computational cost and time. Hence, we proposed a compact and parameter-effective Particle Swarm Optimization-based Ensemble Fusion Voting Model (PSO-EFVM) that exploited the combined properties of four ensemble techniques, namely Adaptive-Boost, Gradient-Boost, Random-Forest, and Extremely-Randomized Tree with Particle Swarm Optimization (PSO)-based hyperparameter selection. The proposed model is investigated on five cross-domain datasets after applying the foremost initialization and feature extraction using Information Gain (IG). It employs adaptive and gradient learning to incorporate the automatic attribute selection with the arbitrary loss function optimization. In short, a generalized two-block composite classifier is designed to perform context compositionality and sentiment classification. A population-based meta-heuristic optimization PSO is applied to each base ensemble learner that calculates weights for the best parameter selection. Comprehensive investigations of different domains reveal the superiority of the proposed PSO-EFVM over established baselines and the latest state-of-the-art models.","2024","2025-02-26 20:43:27","2025-02-26 20:43:27","","23707-23724","","","12","","","","","","","","","","English","","","","WOS:001164028000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","adaptive-boosting; Analytical models; Bagging; CLASSIFICATION; Computational modeling; ensemble learning; Ensemble learning; Feature extraction; Gradient methods; gradient-boosting; LEXICON; Natural language processing; particle swarm optimization; Particle swarm optimization; Random processes; sentiment analysis; Sentiment analysis; Support vector machines; Training","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TVJZJB3B","journalArticle","2023","Deng, HM; Wang, WQ; Liu, M","Deep Learning Enabled Task-Oriented Semantic Communication for Memory-Limited Devices","MOBILE NETWORKS & APPLICATIONS","","1383-469X","10.1007/s11036-023-02267-8","","In recent years, numerous achievements have been made in the field of deep learning, particularly in text processing. In the wave of intelligence, people's demand for intelligent communication is becoming increasingly higher. Therefore, we consider utilizing deep learning models to design and optimize transceiver of semantic communication system. The research of semantic communication is in a booming stage, but there are still few applications in multi-user scenario. In general, the parameters of the semantic communication system transceiver based on the deep learning model are very large. Therefore, we study the multi-user semantic communication system based on the ALBERT model. The goal of the proposed semantic communication system is to intelligently and correctly send the corresponding text classification to the receiver. The channel state information (CSI) is very important for information transmission. Considering the multi-antenna multi-user uplink scenario, we adopt the conditional generative adversarial network (cGAN) model to estimate CSI and apply it to the proposed semantic communication system. In order to reduce the influence of channel estimation on the delay of communication system, we quantify the pilot at the receiver. The simulation results show that the performance of the semantic communication system proposed in this paper is better than that of the semantic communication system based on Transformer model and the traditional semantic communication system in the intelligent text classification task. Moreover, in the case of low signal-to-noise ratio, traditional communication is difficult to complete intelligent tasks.","2023-08","2025-02-26 20:43:27","2025-02-26 20:43:27","","1519-1530","","4","28","","","","","","","","","","English","","","","WOS:001118761400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","ALBERT; BLIND CHANNEL ESTIMATION; cGAN; Channel estimation; Deep learning; DESIGN; INTERNET; Multi-user communication; NETWORKS; Semantic communication; SYSTEMS; TRANSMISSION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CSDSMMAI","journalArticle","2023","Liu, Y; Wu, LJ","Intrusion Detection Model Based on Improved Transformer","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13106251","","This paper proposes an enhanced Transformer-based intrusion detection model to tackle the challenges of lengthy training time, inaccurate detection of overlapping classes, and poor performance in multi-class classification of current intrusion detection models. Specifically, the proposed model includes the following: (i) A data processing strategy that initially reduces the data dimension using a stacked auto-encoder to speed up training. In addition, a novel under-sampling method based on the KNN principle is introduced, along with the Borderline-SMOTE over-sampling method, for hybrid data sampling that balances the dataset while addressing the issue of low detection accuracy in overlapping data classes. (ii) An improved position encoding method for the Transformer model that effectively learns the dependencies between features by embedding the position information of features, resulting in better classification accuracy. (iii) A two-stage learning strategy in which the model first performs rough binary prediction (determining whether it is an illegal intrusion) and then inputs the prediction value and original features together for further multi-class prediction (predicting the intrusion category), addressing the issue of low accuracy in multi-class classification. Experimental results on the official NSL-KDD test set demonstrate that the proposed model achieves an accuracy of 88.7% and an F1-score of 88.2% in binary classification and an accuracy of 84.1% and an F1-score of 83.8% in multi-class classification. Compared to existing intrusion detection models, our model exhibits higher accuracy and F1-score and trains faster than other models.","2023-05-19","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","10","13","","","","","","","","","","English","","","","WOS:000995634800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","auto-encoder; deep learning; intrusion detection; NSL-KDD; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TCUFRAZN","journalArticle","2022","Lange, L; Adel, H; Strötgen, J; Klakow, D","CLIN-X: pre-trained language models and a study on cross-task transfer for concept extraction in the clinical domain","BIOINFORMATICS","","1367-4803","10.1093/bioinformatics/btac297","","Motivation: The field of natural language processing (NLP) has recently seen a large change toward using pre-trained language models for solving almost any task. Despite showing great improvements in benchmark datasets for various tasks, these models often perform sub-optimal in non-standard domains like the clinical domain where a large gap between pre-training documents and target documents is observed. In this article, we aim at closing this gap with domain-specific training of the language model and we investigate its effect on a diverse set of downstream tasks and settings. Results: We introduce the pre-trained CLIN-X (Clinical XLM-R) language models and show how CLIN-X outperforms other pre-trained transformer models by a large margin for 10 clinical concept extraction tasks from two languages. In addition, we demonstrate how the transformer model can be further improved with our proposed task- and language-agnostic model architecture based on ensembles over random splits and cross-sentence context. Our studies in low-resource and transfer settings reveal stable model performance despite a lack of annotated data with improvements of up to 47 F-1 points when only 250 labeled sentences are available. Our results highlight the importance of specialized language models, such as CLIN-X, for concept extraction in non-standard domains, but also show that our task-agnostic model architecture is robust across the tested tasks and languages so that domain- or task-specific adaptations are not required.","2022-06-15","2025-02-26 20:43:27","2025-02-26 20:43:27","","3267-3274","","12","38","","","","","","","","","","English","","","","WOS:000796690500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","INFORMATION EXTRACTION; SHARED TASK","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z9Q6C9AX","journalArticle","2025","Qin, Y; Yu, FF","An End-To-End Speech Recognition Model for the North Shaanxi Dialect: Design and Evaluation","SENSORS","","1424-8220","10.3390/s25020341","","The coal mining industry in Northern Shaanxi is robust, with a prevalent use of the local dialect, known as ""Shapu"", characterized by a distinct Northern Shaanxi accent. This study addresses the practical need for speech recognition in this dialect. We propose an end-to-end speech recognition model for the North Shaanxi dialect, leveraging the Conformer architecture. To tailor the model to the coal mining context, we developed a specialized corpus reflecting the phonetic characteristics of the dialect and its usage in the industry. We investigated feature extraction techniques suitable for the North Shaanxi dialect, focusing on the unique pronunciation of initial consonants and vowels. A preprocessing module was designed to accommodate the dialect's rapid speech tempo and polyphonic nature, enhancing recognition performance. To enhance the decoder's text generation capability, we replaced the Conformer decoder with a Transformer architecture. Additionally, to mitigate the computational demands of the model, we incorporated Connectionist Temporal Classification (CTC) joint training for optimization. The experimental results on our self-established voice dataset for the Northern Shaanxi coal mining industry demonstrate that the proposed Conformer-Transformer-CTC model achieves a 9.2% and 10.3% reduction in the word error rate compared to the standalone Conformer and Transformer models, respectively, confirming the advancement of our method. The next step will involve researching how to improve the performance of dialect speech recognition by integrating external language models and extracting pronunciation features of different dialects, thereby achieving better recognition results.","2025-01","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","2","25","","","","","","","","","","English","","","","WOS:001405241800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","coal mining industry; Conformer model; Connectionist Temporal Classification (CTC); dialect speech recognition; end to end; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5UDPAYZX","journalArticle","2024","Sukanya, G; Priyadarshini, J","Hybrid CNN: An Empirical Analysis of Machine Learning Models for Predicting Legal Judgments","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","Artificial Intelligence with NLP has revolutionized the legal industry, which was previously under-digitized, and it's eager to adopt digital technologies for increased efficiency. Case backlog issues, exacerbated by population growth, can be alleviated by AI's potential in decision prediction for laypeople, litigants, and adjudicators. Legal judgment prediction (LJP) is viewed as a text classification cum prediction problem, with encoding models crucial for accurate textual representation and downstream tasks. These models capture syntax, semantics, and context, varying in performance based on the task and dataset. Selecting the right model, whether traditional ML or DL, using different evaluation metrics, is complex. This paper addresses the above research gap by reviewing 12 cutting-edge ML models and 10 DL models with two embedding methods on real-time Madras High Court criminal cases from Manupatra. The comprehensive comparison of classifier models on real-time case documents provides insights for researchers to innovate despite challenges and limitations. Evaluation metrics like accuracy, F1 score, precision, and recall show that Support Vector Machines (SVM), Logistic Regression, and SGD with Doc2Vec (D2V) encoding and shallow neural networks perform well. Although Transformers process longer input sequences with parallel word analysis and self-attention layers, they have weaknesses on real-time datasets. This article proposes a novel hybrid CNN with a transformer model to predict binary judgments, outperforming traditional ML and DL models in precision, recall, and accuracy. Finally, we summarise the most important ramifications, potential research avenues, and difficulties facing the legal research field.","2024-07","2025-02-26 20:43:27","2025-02-26 20:43:27","","1279-1289","","7","15","","","","","","","","","","English","","","","WOS:001283558500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","CNN; Doc2vec; encoding; Legal judgment prediction; SGD; SVM; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RC8CLTVZ","journalArticle","2025","Santhirasekaram, A; Winkler, M; Rockall, A; Glocker, B","Robust prostate disease classification using transformers with discrete representations","INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY","","1861-6410","10.1007/s11548-024-03153-8","","Purpose: Automated prostate disease classification on multi-parametric MRI has recently shown promising results with the use of convolutional neural networks (CNNs). The vision transformer (ViT) is a convolutional free architecture which only exploits the self-attention mechanism and has surpassed CNNs in some natural imaging classification tasks. However, these models are not very robust to textural shifts in the input space. In MRI, we often have to deal with textural shift arising from varying acquisition protocols. Here, we focus on the ability of models to generalise well to new magnet strengths for MRI.Method: We propose a new framework to improve the robustness of vision transformer-based models for disease classification by constructing discrete representations of the data using vector quantisation. We sample a subset of the discrete representations to form the input into a transformer-based model. We use cross-attention in our transformer model to combine the discrete representations of T2-weighted and apparent diffusion coefficient (ADC) images.Results: We analyse the robustness of our model by training on a 1.5 T scanner and test on a 3 T scanner and vice versa. Our approach achieves SOTA performance for classification of lesions on prostate MRI and outperforms various other CNN and transformer-based models in terms of robustness to domain shift and perturbations in the input space.Conclusion: We develop a method to improve the robustness of transformer-based disease classification of prostate lesions on MRI using discrete representations of the T2-weighted and ADC images.","2025-01","2025-02-26 20:43:27","2025-02-26 20:43:27","","11-20","","1","20","","","","","","","","","","English","","","","WOS:001220914300002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Biomedical imaging; Computer-aided diagnosis; Machine learning; Neural networks; Robustness; SMOTE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6FW7HS24","journalArticle","2023","Song, LY; Li, YY; Xu, JC","Dynamic Job-Shop Scheduling Based on Transformer and Deep Reinforcement Learning","PROCESSES","","2227-9717","10.3390/pr11123434","","The dynamic job-shop scheduling problem is a complex and uncertain task that involves optimizing production planning and resource allocation in a dynamic production environment. Traditional methods are limited in effectively handling dynamic events and quickly generating scheduling solutions; in order to solve this problem, this paper proposes a solution by transforming the dynamic job-shop scheduling problem into a Markov decision process and leveraging deep reinforcement learning techniques. The proposed framework introduces several innovative components, which make full use of human domain knowledge and machine computing power, to realize the goal of man-machine collaborative decision-making. Firstly, we utilize disjunctive graphs as the state representation, capturing the complex relationships between various elements of the scheduling problem. Secondly, we select a set of dispatching rules through data envelopment analysis to form the action space, allowing for flexible and efficient scheduling decisions. Thirdly, the transformer model is employed as the feature extraction module, enabling effective capturing of state relationships and improving the representation power. Moreover, the framework incorporates the dueling double deep Q-network with prioritized experience replay, mapping each state to the most appropriate dispatching rule. Additionally, a dynamic target strategy with an elite mechanism is proposed. Through extensive experiments conducted on multiple examples, our proposed framework consistently outperformed traditional dispatching rules, genetic algorithms, and other reinforcement learning methods, achieving improvements of 15.98%, 17.98%, and 13.84%, respectively. These results validate the effectiveness and superiority of our approach in addressing dynamic job-shop scheduling problems.","2023-12","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","12","11","","","","","","","","","","English","","","","WOS:001131355200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","deep reinforcement learning; dispatching rules; dynamic job-shop scheduling problem; Markov decision process; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7QHLT9WA","journalArticle","2023","Hu, K; Zhu, YD; Zhou, TX; Zhang, Y; Cao, CH; Xiao, F; Gao, XP","DSC-Net: A Novel Interactive Two-Stream Network by Combining Transformer and CNN for Ultrasound Image Segmentation","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2023.3322993","","Ultrasound imaging is one of the most widely used medical imaging techniques for visualizing human tissue due to its economical, convenient, practical, and safe advantages. Automatic segmentation of regions of interest (ROIs) in ultrasound images is of great significance in improving the clinical efficiency of ultrasound images and the accuracy of disease diagnosis. However, this task has been challenging due to speckle noise, low contrast, and blurred boundaries in ultrasound images. To address these problems, this article proposes an interactive two-stream network based on detail screening and compensation called DSC-Net for ultrasound image segmentation. Unlike previous ultrasound image segmentation methods, our DSC-Net combines the transformer and convolutional neural network (CNN) to perform accurate ultrasound image segmentation. Specifically, DSC-Net uses a transformer stream to obtain multiscale detailed features and a CNN stream to extract body features with less noise. Then, the body features guide multiscale detailed features to filter out noise through the detail screening module. The filtered detail features are applied to the detail compensation module to supplement rich details for the CNN stream. With such interactions, DSC-Net ensures that more noise-free details are extracted. Extensive experiments on three datasets, including two publicly available datasets and one private dataset, demonstrate that the proposed DSC-Net achieves higher performance and superior robustness than state-of-the-art ultrasound image segmentation methods. Our code is publicly available at https://github.com/MLMIP/DSC-Net.","2023","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","72","","","","","","","","","","English","","","","WOS:001090941700007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Convolutional neural network (CNN); deep learning; interactive two-stream network; transformer model; ultrasound image segmentation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K6WVBWNX","journalArticle","2022","Yang, Y; An, YZ; Hu, JT; Pan, LY","Tri-RAT: optimizing the attention scores for image captioning","INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL","","2192-6611","10.1007/s13735-022-00260-7","","Attention mechanisms and grid features are widely used in current visual language tasks like image captioning. The attention scores are the key factor to the success of the attention mechanism. However, the connection between attention scores in different layers is not strong enough since Transformer is a hierarchical structure. Additionally, geometric information is inevitably lost when grid features are flattened to be fed into a transformer model. Therefore, bias scores about geometric position information should be added to the attention scores. Considering that there are three different kinds of attention modules in the transformer architecture, we build three independent paths (residual attention paths, RAPs) to propagate the attention scores from the previous layer as a prior for attention computation. This operation is like a residual connection between attention scores, which can enhance the connection and make each attention layer obtain a global comprehension. Then, we replace the traditional attention module with a novel residual attention with relative position module in the encoder to incorporate relative position scores with attention scores. Residual attention may increase the internal covariate shifts. To optimize the data distribution, we introduce residual attention with layer normalization on query vectors module in the decoder. Finally, we build our Residual Attention Transformer with three RAPs (Tri-RAT) for the image captioning task. The proposed model achieves competitive performance on the MSCOCO benchmark with all the state-of-the-art models. We gain 135.8% CIDEr on MS COCO ""Karpathy"" offline test split and 135.3% CIDEr on the online testing server.","2022-12","2025-02-26 20:43:27","2025-02-26 20:43:27","","705-715","","4","11","","","","","","","","","","English","","","","WOS:000864588700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Attention mechanism; Image captioning; Layer normalization; Relative position information; Residual attention; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FIGM7CJS","journalArticle","2021","Richter-Pechanski, P; Geis, NA; Kiriakou, C; Schwab, DM; Dieterich, C","Automatic extraction of 12 cardiovascular concepts from German discharge letters using pre-trained language models","DIGITAL HEALTH","","2055-2076","10.1177/20552076211057662","","Objective A vast amount of medical data is still stored in unstructured text documents. We present an automated method of information extraction from German unstructured clinical routine data from the cardiology domain enabling their usage in state-of-the-art data-driven deep learning projects. Methods We evaluated pre-trained language models to extract a set of 12 cardiovascular concepts in German discharge letters. We compared three bidirectional encoder representations from transformers pre-trained on different corpora and fine-tuned them on the task of cardiovascular concept extraction using 204 discharge letters manually annotated by cardiologists at the University Hospital Heidelberg. We compared our results with traditional machine learning methods based on a long short-term memory network and a conditional random field. Results Our best performing model, based on publicly available German pre-trained bidirectional encoder representations from the transformer model, achieved a token-wise micro-average F1-score of 86% and outperformed the baseline by at least 6%. Moreover, this approach achieved the best trade-off between precision (positive predictive value) and recall (sensitivity). Conclusion Our results show the applicability of state-of-the-art deep learning methods using pre-trained language models for the task of cardiovascular concept extraction using limited training data. This minimizes annotation efforts, which are currently the bottleneck of any application of data-driven deep learning projects in the clinical domain for German and many other European languages.","2021-11","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","7","","","","","","","","","","English","","","","WOS:000724518900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","bidirectional encoder representations from transformer; Deep learning; fine-tuning; IDENTIFICATION; INFORMATION EXTRACTION; medical information extraction; natural language processing; pre-trained language models; REGULAR EXPRESSIONS; TEXT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4J3EYMY3","journalArticle","2022","Fernández-Peña, ACR","The aesthetics of isochrony and literal synchrony in voice-over translation","TRADUMATICA-TRADUCCIO I TECNOLOGIES DE LA INFORMACIO I LA COMUNICACIO","","1578-7559","10.5565/rev/tradumatica.301","","Voice-over translation is characterised by some technical synchronic features (isochrony, literal synchrony, action synchrony, kinetic synchrony, content synchrony and character synchrony). From these, isochrony and literal synchrony contribute to the illusion of authenticity and realism with what is called sound bites (a time span in the target version in which we only hear the original voice, and which can occur at the beginning and/or at the end of the speaker's intervention). In our study, after analysing a corpus made up of different voiced-over programmes using speech analysis software and a spreadsheet, we have seen that the average duration of sound bites differs from that stated by the scholarly tradition both in terms of seconds and number of words. In addition, we also analysed samples that show no literal synchrony to see how and whether the rendition success of those parts could be affected. The results confirm that sound bites and literal synchrony are aesthetic enhancers which provide voice-over with an authenticity feel that makes it, for some scholars, the most faithful and reliable audiovisual translation mode.","2022-12","2025-02-26 20:43:27","2025-02-26 20:43:27","","1-33","","20","","","","","","","","","","","English","","","","WOS:000932679600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","isochrony; literal synchrony; sound bites; SPANISH; synchrony; voice-over","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H985IEAK","journalArticle","2022","Takara, T; Eto, R","Speech analysis-synthesis system using genetic algorithm and Fujisaki model and its application to coarticulation","ACOUSTICAL SCIENCE AND TECHNOLOGY","","1346-3969","10.1250/ast.43.219","","We propose a new analysis and synthesis system of speech using the genetic algorithm (GA) for the analysis and the Fujisaki's generative model of speech (Fujisaki model) for the synthesis. This system is a functional model to simulate human acquisition of speech through the process of imitation of spoken words. We represent the coarticulation effect using the Fujisaki model. We model the trial-and-error and emergent process of speech imitation using the GA. In our system, we regard ""command'' in the Fujisaki model as an articulatory gesture and detect it from the spectral sequence using the GA. In other words, the original phonemic target is inversely estimated automatically as the command in the Fujisaki model from the phonemically ambiguous speech spectrum caused by coarticulation. We evaluated the system by listening tests using synthesized speech. We also show that the system can represent the phenomenon of ""predicted sound,'' which is a type of flush-lag effect unconsciously heard as a result of the normalization of coarticulation, by comparing the predicted sound with the inversely estimated sound.","2022","2025-02-26 20:43:27","2025-02-26 20:43:27","","219-227","","4","43","","","","","","","","","","English","","","","WOS:000810973600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","Acquisition of spoken word; Coarticulation; Fujisaki model; Genetic algorithm; Vowel space parameter","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XZ7KWQRL","journalArticle","2024","Anidjar, OH; Marbel, R; Yozevitch, R","Harnessing the power of Wav2Vec2 and CNNs for Robust Speaker Identification on the VoxCeleb and LibriSpeech Datasets","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.124671","","Speaker identification, a cornerstone of speech processing, involves associating individuals with spoken segments within a known speaker pool. This paper presents a significant AI contribution: an innovative framework tailored for closed-set speaker identification. It concurrently emphasizes its practical engineering application in the realm of speech analysis. This paper introduces a pioneering AI framework with substantial neural network architecture enhancements, particularly focusing on optimizing the Log-Softmax function-a linchpin for speaker attribution. Additionally, we seamlessly incorporate cutting-edge data augmentation techniques into the Wav2Vec2 framework. These innovations push the boundaries of current Speaker Identification methodologies. Empirical validation demonstrates our framework's efficacy, yielding a remarkable relative improvement of up to 3.16% in top-1% accuracy compared to the state-of-the-art. This research sets a new benchmark, surpassing existing standards and unlocking the full potential of closed-set Speaker Identification functions. In addition, the methodology presented in this paper serves as a catalyst for advancing Speaker Identification methodologies in engineering applications, underlining the transformative potential of AI-driven innovations in this domain.","2024-12-01","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","255","","","","","","","","","","English","","","","WOS:001268523900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","CNN; DEEP; FEATURES; LibriSpeech; Speaker diarization; Speaker identification; Speech recognition; VoxCeleb","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AT8MDJHW","journalArticle","2023","Ochi, K; Inoue, K; Lala, D; Kawahara, T; Kumazaki, H","Effect of attentive listening robot on pleasure and arousal change in psychiatric daycare","ADVANCED ROBOTICS","","0169-1864","10.1080/01691864.2023.2257264","","In this paper, we investigate the usefulness of an attentive-listening robot in psychiatric daycare, an outpatient treatment program for the rehabilitation of psychiatric disorders. The robot was developed based on counseling techniques, such as repeating words that the user has said. It can also generate backchannels as a listening behavior during user utterance. Conversation experiments have been conducted to evaluate whether the robot can provide effective activities in this setting. The robot attentively listened to 18 daycare attendees talking about their recent memorable events for up to 3 min. The results showed that the conversation increased self-rated arousal. The impressions of the robot showed that talking with the robot was more conversable than with strangers and more useful as a talking partner than a friend. The subjects also had a positive impression about whether they would keep the robot in their homes. A linear regression analysis indicates that the frequency of the robot's assessment responses and backchannels positively affect pleasure improvement. The findings may pave the way for utilizing this kind of robots that people can talk to easily without hesitation or excessive consideration.","2023-11-02","2025-02-26 20:43:27","2025-02-26 20:43:27","","1382-1391","","21","37","","","","","","","","","","English","","","","WOS:001080181600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","attentive listening; Communicative robot; EMOTIONAL VALENCE; INDIVIDUALS; mental health; psychiatric daycare; SCHIZOPHRENIA; speech analysis; THERAPY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H8FFDUZN","journalArticle","2021","Asgari, M; Chen, L; Fombonne, E","Quantifying Voice Characteristics for Detecting Autism","FRONTIERS IN PSYCHOLOGY","","1664-1078","10.3389/fpsyg.2021.665096","","The presence of prosodic anomalies in autistic is recognized by experienced clinicians but their quantitative analysis is a cumbersome task beyond the scope of typical pen and pencil assessment. This paper proposes an automatic approach allowing to tease apart various aspects of prosodic abnormalities and to translate them into fine-grained, automated, and quantifiable measurements. Using a harmonic model (HM) of voiced signal, we isolated the harmonic content of speech and computed a set of quantities related to harmonic content. Employing these measures, along with standard speech measures such as loudness, we successfully trained machine learning models for distinguishing individuals with autism from those with typical development (TD). We evaluated our models empirically on a task of detecting autism on a sample of 118 youth (90 diagnosed with autism and 28 controls; mean age: 10.9 years) and demonstrated that these models perform significantly better than a chance model. Voice and speech analyses could be incorporated as novel outcome measures for treatment research and used for early detection of autism in preverbal infants or toddlers at risk of autism.","2021-09-07","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","12","","","","","","","","","","English","","","","WOS:000697286400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","autism spectrum disorder; CHILDREN; COMMUNICATION; FUNDAMENTAL-FREQUENCY; harmonic model; machine learning; MODEL; prosody; SPECTRUM; SPEECH; speech analysis; voice","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HEBCBFTD","journalArticle","2024","Raveau, MP; Fuentes-Bravo, C; Fernandez, MA; Couyoumdjian, JP; del Solar, MJ","""It's not the what but (also) the how"": characterizing left-wing populism in political texts","FRONTIERS IN POLITICAL SCIENCE","","2673-3145","10.3389/fpos.2024.1435712","","Despite all the elasticity and even ambiguity surrounding the concept of populism, the existing paradigms converge in the recognition of a populist rhetoric. By using Natural Language Processing (NLP) tools we propose a set of linguistic and discursive markers to identify populist markers in Presidential speeches. The performance of these markers is subsequently tested against the Global Populism Database (GPD). We set-up a multinomial regression model to study the predictive power of these markers on the GPD populist score, focusing on left-wing populist leaders in Spanish-speaking countries in Latin America. We are thus able to characterize (left-wing) populism as a style of communication, as well as to understand what is behind this rhetoric. Our results show that ingroup and emotional content are more present in populist speeches. We also find a positive relation between populism and the use future tense and conditional connectors, which suggest an intention to manipulate the audience. These results have implications both for the current understanding of (left-wing) populist rhetoric and for the conceptualization of populism itself.","2024-08-08","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","6","","","","","","","","","","English","","","","WOS:001295578400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;94</p>","","","DISCOURSE; INDEX; Latin America; LATIN-AMERICA; linguistics; natural language processing; populism; speech analysis; STYLE; SYNTACTIC COMPLEXITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HD4PFVZX","journalArticle","2023","Moskovkin, LV","Models of Speech Ontogenesis in Russian Monolinguals and Russian-German Bilinguals","NAUCHNYI DIALOG","","2225-756X","10.24224/2227-1295-2023-12-10-85-103","","The aim of the article is to examine models of speech ontogenesis in Russian monolinguals living in Russia and Russian -German bilinguals living in Germany. The study uses deviations from literary language norms in transcriptions of oral speech from 42 monolinguals and 48 bilinguals, supplemented by speech analysis data reflected in printed sources. Research methods include surveys, interviews, reading phonetically representative texts and picture stories, analysis of deviations from literary language norms, and synthesis of speech data. Two models of speech ontogenesis for monolinguals and four models for bilinguals are described. It is shown that the process of speech ontogenesis proceeds differently among Russian language speakers depending on a) whether it occurs in Russia or abroad, b) which variety of Russian language the speaker uses, c) at what age the foreign speaker of Russian language begins to actively use the language of the majority. It is established that the most important factor preventing the loss of elements of the Russian language in the diaspora is mastery of literary language norms. The dependence of the appearance of interference from the German language on the model of speech ontogenesis is determined.","2023","2025-02-26 20:43:27","2025-02-26 20:43:27","","85-103","","10","12","","","","","","","","","","English","","","","WOS:001162867200018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","factors of speech development; literary language; models of speech on-togenesis; ontolinguistics; speech ontogenesis; vernacular","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7PE3IW5P","journalArticle","2023","Rostovtsev, EA; Sidorchuk, IV","Models of Speech Ontogenesis in Russian Monolinguals and Russian-German Bilinguals","NAUCHNYI DIALOG","","2225-756X","","","The aim of the article is to examine models of speech ontogenesis in Russian monolinguals living in Russia and Russian-German bilinguals living in Germany. The study uses deviations from literary language norms in transcriptions of oral speech from 42 monolinguals and 48 bilinguals, supplemented by speech analysis data reflected in printed sources. Research methods include surveys, interviews, reading phonetically representative texts and picture stories, analysis of deviations from literary language norms, and synthesis of speech data. Two models of speech ontogenesis for monolinguals and four models for bilinguals are described. It is shown that the process of speech ontogenesis proceeds differently among Russian language speakers depending on a) whether it occurs in Russia or abroad, b) which variety of Russian language the speaker uses, c) at what age the foreign speaker of Russian language begins to actively use the language of the majority. It is established that the most important factor preventing the loss of elements of the Russian language in the diaspora is mastery of literary language norms. The dependence of the appearance of interference from the German language on the model of speech ontogenesis is determined.","2023","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","10","12","","","","","","","","","","English","","","","WOS:001162867200024","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","factors of speech development; literary language; models of speech ontogenesis; ontolinguistics; speech ontogenesis; vernacular","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IGI6B88T","journalArticle","2025","Song, XG; Tan, YP; Pang, XC; Zhang, L; Lu, XF; Hei, XH","Spatial and channel enhanced self-attention network for efficient single image super-resolution","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2024.129258","","In recent years, the widespread adoption of the swin transformer model in computer vision has significantly enhanced the quality of super-resolution reconstructions. However, existing single-image super-resolution models, while effective in capturing spatial details, often overlook interactions across channels, limiting their ability to fully leverage the depth of feature information. This deficiency hampers their performance, leading to suboptimal reconstruction quality, as the models cannot adequately capture global dependencies across both spatial and channel dimensions. Consequently, these models tend to produce less accurate high- frequency details, which are critical for enhancing image clarity and preserving fine structures. To address this issue, we introduce the Spatial and Channel Enhanced Self-Attention Network (SCESN), designed to integrate both spatial and channel attention mechanisms, thereby enhancing feature utilization and delivering superior reconstruction performance. In this work, a global self-attention module (GSM) was designed to perform deep feature extraction by utilizing global contextual information in the images. Specifically, the GSM incorporates spatial self-attention block (SSB), channel self-attention block (CSB), and spatial and channel enhanced blocks (SCEB). SCEB boosts the interaction between spatial information from SSBs and channel information from CSBs, thereby maximizing feature utilization and enhancing network performance. Moreover, efficient convolution blocks are integrated to efficiently enhance the model's deep spatial feature extraction capabilities. Quantitative evaluations across multiple test sets, along with visual comparisons, demonstrate that the proposed method achieves superior reconstruction results with fewer parameters compared to existing methodologies.","2025-03-01","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","620","","","","","","","","","","English","","","","WOS:001412471600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Image super-resolution; INTERPOLATION; Lightweight network; Self-attention mechanism; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XU2XVMNW","journalArticle","2025","Santos, LFT; Gattass, M; Rodriguez, C; Hurtado, J; Miranda, F; Michelon, D; Ribeiro, R","Improving generalization through self-supervised learning using generative pre-training transformer for natural gas segmentation","COMPUTERS & GEOSCIENCES","","0098-3004","10.1016/j.cageo.2024.105809","","Seismic reflection is an essential geophysical method for subsurface mapping in the oil and gas industry, used to deduce the position and extension of potential gas accumulations through the processing and interpretation of data. However, interpreting seismic reflection data presents inherent ambiguity, as similar signatures may arise from geological scenarios with distinct physical properties. Furthermore, seismic interpretation is costly and labor-intensive, complicating the generation of extensive labeled datasets useful for conventional AI-assisted solutions. The emergence of self-supervised learning techniques has gained significant attention in the AI community, enabling the pre-training of deep neural networks without annotated data. This paper proposes a two-stage method for segmenting natural gas regions in seismic reflection images by using a generative pre-training transformer model for feature extraction and a recurrent neural network for per-seismic trace analysis. In the first stage, we pre-train the feature extractor in a self-supervised fashion under a seismic image reconstruction task. In the second stage, using the pre-trained feature extractor, we train the recurrent neural network for the segmentation of natural gas accumulations in 1D seismic image traces. We conducted quantitative and qualitative experiments on a private dataset to demonstrate how our self-supervised learning methodology helps achieve better gains in model generalization. The increase, which can reach up to 20%, in the F1-Score metric corroborates the latter. Thus, an improvement in generalization corresponds to an increase in success rates in drilling new wells.","2025-02","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","196","","","","","","","","","","English","","","","WOS:001389521900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Deep neural network; Generative pretraining transformer (GPT); Natural gas accumulation; Self-supervised learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2P8GK6IN","journalArticle","2024","Benamer, K; Hamid, A; di Schio, ER; Mokhefi, A; Melati, R; Valdiserri, P","Magnetic and Thermal Behavior of a Planar Toroidal Transformer","ENERGIES","","1996-1073","10.3390/en17112454","","This paper presents a study on the magnetic and thermal behaviors of a planar toroidal transformer, comprising two planar toroidal coils. In our configuration, the primary coil consists of twenty turns, while the secondary coil consists of ten turns. This design combines the advantages of both toroidal and planar transformers: it employs flat coils, akin to those utilized in planar transformers, while retaining a toroidal shape for its magnetic core. This combination enables leveraging the distinctive characteristics of both transformer types. This study delves into electromagnetic and thermal behaviors. Electromagnetic behavior is elucidated through Maxwell's equations, offering insights into the distribution of magnetic fields, potentials, and electric current densities. Fluid flow is modeled via the Navier-Stokes equations. By coupling these equation sets, a more comprehensive and accurate portrayal of the thermal phenomena surrounding electrical equipment is attained. Such research is invaluable in the design and optimization of electrical systems, empowering engineers to forecast and manage thermal effects more efficiently. Consequently, this aids in enhancing the reliability, durability, and performance optimization of electrical equipment. The mathematical model was solved using the finite element method integrated into the COMSOL Multiphysics software v. 6.0. The COMSOL Multiphysics simulation showed correct behavior of potential, electric field, current density, and uniformly distributed temperature. In addition, this planar toroidal coil transformer model offers many advantages, such as small dimensions, high resonance frequency, and high operating reliability. This study made it possible to identify the range of its optimal functioning.","2024-06","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","11","17","","","","","","","","","","English","","","","WOS:001245487300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","CFD; dimensioning; fly-back converter; inductive elements; INTEGRATED INDUCTOR; integration; planar transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QFU2PK38","journalArticle","2024","Qi, H; Wang, WJ; Shi, YT; Wang, XH","AD-DUNet: A dual-branch encoder approach by combining axial Transformer with cascaded dilated convolutions for liver and hepatic tumor segmentation","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2024.106397","","Liver cancer remains a significant health concern, and accurate segmentation in CT scans is crucial for diagnosis and treatment. Deep learning -based auxiliary diagnosis techniques, especially utilizing U-shaped structures, are widely employed in medical image segmentation. However, traditional methods that utilize Convolutional Neural Networks (CNNs) generally have limitations in modeling long-range dependencies. Inspired by the success of Transformers in various vision tasks, approaches that combine Transformers with CNNs have been spurred. However, many existing hybrid CNN -Transformer models are prone to yielding poor performance on relative small-scale medical image datasets when trained from scratch. Moreover, some of these methods involve additional fusion modules customized, which introduce extra workload and parameters to the model. To address these limitations, we propose AD-DUNet, a hybrid CNN -Transformer model for liver and hepatic tumor segmentation, which comprises a dual -branch encoder and a residual decoder. The Transformer -based encoder, utilizing Axial Transformer (AT) blocks, efficiently captures long-range dependencies across the entire image, while the CNN -based encoder, constructed with cascaded dilated convolutions (CDC) blocks, extracts fine-grained local features. The two encoders synergize in the shared residual decoder, eliminating the need for additional fusion modules. The extensive experiments conducted on the LiTS2017 and 3DIRCAD datasets demonstrate the superiority of AD-DUNet over existing models. Remarkably, our approach achieves state-ofthe-art results without relying on pre -trained weights, showcasing its efficiency with low complexity and 4.24M parameters.","2024-09","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","95","","","","","","","","","","English","","","","WOS:001238321400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","Convolutional neural network; Deep learning; Dual-branch encoder; Medical image segmentation; NET; NETWORK; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7VD7MMHX","journalArticle","2024","Shen, LY; Lang, BH; Song, ZX","Object Detection for Remote Sensing Based on the Enhanced YOLOv8 With WBiFPN","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3487492","","To address the challenges of object detection in complex remote sensing imagery, where the YOLO backbone network struggles with adaptive learning of feature distributions, leading to insufficient multi-scale feature learning capabilities and low detection accuracy for small and occluded objects, the lightweight Enhanced YOLOv8 with WBiFPN (Weighted Bidirectional Feature Pyramid Network) model is introduced in this paper. This model is designed to enhance multi-scale feature learning performance. It incorporates a feature fusion network based on WBiFPN and introduces the EMA (Efficient Multi-Scale Attention Module) to strengthen the representation of semantic and spatial information, thereby deepening the integration of multi-scale features. The model integrates RepConv (Re-parameterized Convolution) and ConvNeXt C2f in the shallow layers of the backbone network to optimize feature extraction, while the deeper layers include a BoT (Bottleneck Transformer Model) to further enhance multi-scale feature extraction capabilities. To reduce model parameters and computational complexity, the neck network employs a simplified Slim-Neck structure. Experimental results demonstrate that the Enhanced YOLOv8 model exhibits superior performance. Compared to the YOLOv8-n/s/m/l/x series models, the proposed model achieves mean Average Precision (mAP@0.5) of 94.8%, 91.6%, and 82.0% on the NWPU VHR-10, DIOR, and DOTA datasets, respectively, representing improvements of 3.2%, 2.5%, and 2.5%. The average inference speeds are 82 fps, 79 fps, and 76 fps, meeting the real-time requirements of inference. Furthermore, the Enhanced YOLOv8 model outperforms other mainstream models in detection performance.","2024","2025-02-26 20:43:27","2025-02-26 20:43:27","","158239-158257","","","12","","","","","","","","","","English","","","","WOS:001346700600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","ATTENTION; attention mechanism; feature extraction; NETWORK; Object detection; remote sensing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9UK3JZR3","journalArticle","2023","Geng, P; Lu, XQ; Hu, CY; Liu, H; Lyu, L","Focusing Fine-Grained Action by Self-Attention-Enhanced Graph Neural Networks With Contrastive Learning","IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY","","1051-8215","10.1109/TCSVT.2023.3248782","","With the aid of graph convolution neural network and transformer model, human action recognition has achieved significant performance based on skeleton data. However, the majority of existing works rarely focus on identifying fine-grained motion information (i.e., ""read"", ""write"", etc.). Furthermore, they tend to explore correlations between joints and bones ignoring the angular information. Consequently, the recognition accuracy for fine-grained actions with most models is still less desired. To address this issue, we first attempt to bring angular information as a complement to familiar joint and bone information, while learning the potential dependencies of the three kinds of information using graph neural networks. Based on this, we propose a self-attention-enhanced graph neural network (SAE-GNN), which consists of a kernel-unified graph convolution (KUGC) module and an enhanced attention graph convolution (EAGC) module. The KUGC module is devised to effectively extract rich features in the skeleton information. The EAGC consisting of a multi-scale enhanced graph convolution block and a multi-headed self-attention block is designed to learn the potential high-level semantic information in the features. Besides, we introduce contrastive learning in the two blocks to enhance feature representation by maximizing their mutual information. We conduct extensive experiments on four publicly available datasets, and results show that our model outperforms state-of-the-art methods in recognizing fine-grained actions.","2023-09","2025-02-26 20:43:27","2025-02-26 20:43:27","","4754-4768","","9","33","","","","","","","","","","English","","","","WOS:001063316800025","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;16<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","attention mechanism; Bones; contrastive learning; Convolution; CONVOLUTION NETWORK; Correlation; Data mining; Feature extraction; graph neural network; Graph neural networks; HUMAN ACTION RECOGNITION; Joints; Skeleton-based action recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QMSMQS9J","journalArticle","2023","Zhao, L; Wu, ZH; Dai, HX; Liu, ZL; Hu, XT; Zhang, T; Zhu, DJ; Liu, TM","A generic framework for embedding human brain function with temporally correlated autoencoder","MEDICAL IMAGE ANALYSIS","","1361-8415","10.1016/j.media.2023.102892","","Learning an effective and compact representation of human brain function from high-dimensional fMRI data is crucial for studying the brain's functional organization. Traditional representation methods such as independent component analysis (ICA) and sparse dictionary learning (SDL) mainly rely on matrix decomposition which represents the brain function as spatial brain networks and the corresponding temporal patterns. The correspondence of those brain networks across individuals are built by viewing them as one-hot vectors and then performing the matching. However, those one-hot vectors do not encode the regularity and/or variability of different brains very well, and thus are limited in effectively representing the functional brain activities across individuals and among different time points. To address this problem, in this paper, we formulate the human brain functional representation as an embedding problem, and propose a novel embedding framework based on the Transformer model to encode the brain function in a compact, stereotyped and comparable latent space where the brain activities are represented as dense embedding vectors. We evaluate the proposed embedding framework on the publicly available Human Connectome Project (HCP) task fMRI dataset. The experiments on brain state prediction task indicate the effectiveness and generalizability of the learned embedding. We also explore the interpretability of the learned embedding from both spatial and temporal perspective. In general, our approach provides novel insights on representing the regularity and variability of human brain function in a general, comparable, and stereotyped latent space.","2023-10","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","89","","","","","","","","","","English","","","","WOS:001055882900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","ARCHITECTURE; Brain function representation; COMPONENT ANALYSIS; CONNECTIVITY; Embedding regularity/variability; FMRI; FRONTOPARIETAL; NETWORKS; SPARSE REPRESENTATION; Temporally correlated autoencoder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AFAWUBWG","journalArticle","2023","Li, QL; Wang, Y; Li, L; Hao, H; Wang, RH; Li, JD","Prediction of BLEVE loads on structures using machine learning and CFD","PROCESS SAFETY AND ENVIRONMENTAL PROTECTION","","0957-5820","10.1016/j.psep.2023.02.008","","Boiling Liquid Expanding Vapour Explosions (BLEVEs) are driven by complex fluid dynamics with expanded vapour and flashed liquid. They may generate strong shock waves that lead to catastrophic consequences to personnel and structures in the vicinity. Despite the great interest in safety management and intensive research efforts, reliable and efficient prediction of BLEVE loads on structures is still challenging in practice. Computational Fluid Dynamics (CFD), based on complex physics formulas, can provide more accurate predictions of BLEVE loads than the traditional empirical and TNT-equivalency approaches, but suffers from high computational costs. Data-driven machine learning models offer efficient surrogates but conventional models, including commonly used multi-layer perceptron (MLP), are suboptimal especially for explosions of complex geometry and in complex environment. In this study, a novel machine learning approach, based on the state-of-the-art Transformer neural networks, is developed for BLEVE loads prediction on an idealised structure in the vicinity of BLEVE. Through extensive experiments and rigorous evaluation, it is shown that Transformer can effectively model the structure-wave interaction, yielding accurate pressure and impulse predictions with less than 14% relative errors, which outperforms widely used MLP (20% error) significantly. The developed Transformer model is applied to predict critical parameters of BLEVE loads, including arrive time, rise time and duration. The results demonstrate that Transformer can produce an accurate pressure-time history, yielding a comprehensive characterisation of BLEVE loads on structures.","2023-03","2025-02-26 20:43:27","2025-02-26 20:43:27","","914-925","","","171","","","","","","","","","","English","","","","WOS:000931971000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;21<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Blast wave; BLAST WAVE; BLEVE; CFD; Gas explosion; GAS EXPLOSION; Interaction with structures; Machine learning; Neural networks; NUMERICAL-SIMULATION; SCALE BLEVE; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BCPYW8G2","journalArticle","2022","Chen, XB; Zhang, HJ; Zhao, F; Cai, YF; Wang, H; Ye, QL","Vehicle Trajectory Prediction Based on Intention-Aware Non-Autoregressive Transformer With Multi-Attention Learning for Internet of Vehicles","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2022.3192056","","As a core function of autonomous driving (AD) and the Internet of Vehicles (IoV), accurately predicting the trajectory of vehicles can significantly improve traffic safety and reduce crash injuries. In this article, we propose an intention-aware non-autoregressive Transformer model with multi-attention learning for multimodal vehicle trajectory prediction. We first present social attention learning (SAL) where graph attention is properly integrated with the Transformer encoder so as to model the social interaction between vehicles. Then, the social and temporal dependency across consecutive frames is captured by temporal attention learning (TAL). The above social and temporal attention modules can be interleaved and stacked to achieve the coupled modeling and thus extract abundant features from trajectory data. To implement precise prediction as well as efficient inference, we further put forward an intention-aware decoder query generation approach to produce multiple possible trajectories concurrently. Finally, cross-attention learning (CAL) is devised to make full use of the encoded features, therefore, yielding future predictions. The proposed model is evaluated on two large-scale vehicle trajectory datasets and the experimental results verify that our algorithm achieves better performance compared with some state-of-the-art models. The root-mean-square error (RMSE) of the predicted trajectory over 5-s time horizon for the next generation simulation (NGSIM) and HighD datasets is 3.43 and 1.10 m, respectively.","2022","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","71","","","","","","","","","","English","","","","WOS:000833791900028","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;47<br/>Total Times Cited:&nbsp;&nbsp;48<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Behavioral sciences; Correlation; Decoding; Feature extraction; MODEL; Multimodal prediction; Predictive models; social interaction; temporal dependency; Trajectory; transformer architecture; Transformers; vehicle trajectory prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3S64TSTW","journalArticle","2021","Kuzmina, J; Vincela, Z","TECHNOLOGY-ENHANCED COURSE IN ENGLISH THEORETICAL GRAMMAR AND PHONETICS AT THE TERTIARY LEVEL","BALTIC JOURNAL OF ENGLISH LANGUAGE LITERATURE AND CULTURE","","1691-9971","10.22364/BJELLC.11.2021.06","","The advancement of technologies and the recently forced lockdown by Covid-19 are bringing changes to the organisation of the learning process by accelerating the introduction of e-learning to create a learner-centred technology-based approach to English studies, thus stepping towards digital humanities. These trends initiated the institutional project Mobile and Desktop Software Integration in Bachelor and Master Study Programmes. The present study, using a questionnaire, elicits university students' attitudes to the mobile applications and speech analysis software-based seminar activities in Moodle e-course in accordance with the blended learning model selected for the studies of theoretical grammar and phonetics. It is a cross-sectional, focused, and exploratory case study, comprising a description of factors, contributing to the problem of blended learning model selection. The yielded data demonstrate that students do not possess extensive prior experience with the use of software and mobile applications to study English grammar and phonetics. After completing seminar tasks, they favourably account for the integrated blended learning materials and consider that those facilitate their learning process.","2021","2025-02-26 20:43:27","2025-02-26 20:43:27","","79-97","","","11","","","","","","","","","","English","","","","WOS:000690761200006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","blended learning; digital tools; learning management system (LMS); PRONUNCIATION; theoretical grammar and phonetics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KTYJL8SK","journalArticle","2021","Xie, LP; Lu, CH; Liu, ZE; Zhu, YW; Song, WZ","A method of generating car sounds based on granular synthesis algorithm","NOISE CONTROL ENGINEERING JOURNAL","","0736-2501","","","The active sound generation technique for automobiles, where car sounds can be synthesized by means of electronic sound production, is one of the effective methods to achieve the target sound. A method for active sound generation of automobile based on the granular synthesis algorithm is put forward here to avoid the broadband beating phenomena that occur due to the mismatch of parameters of sound granular signals. The comparison of the function expression of sound signal and Hilbert transformation is performed based on the principle of overlap and add: moreover, those parameters (phase, frequency and amplitude) of sound signals are interpolated by means of the Hermite interpolation algorithm which can ensure the continuity of the phase, frequency and amplitude curves. Thus, the transition audio is constructed by means of the sound signal function here to splice the adjacent sound granules. Our simulations show that our method can be applied to solve the current broadband beating issue for splicing sound granules and achieve natural continuity of synthesized car sounds. The subjective test results also indicate that our transition audio can produce high quality audio restitution. (C) 2022 Institute of Noise Control Engineering.","2021-07-01","2025-02-26 20:43:27","2025-02-26 20:43:27","","384-393","","4","70","","","","","","","","","","English","","","","WOS:000830664500002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","SPEECH ANALYSIS SYNTHESIS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JHPKPJAG","journalArticle","2022","Blom, E; Boerma, T; Karaca, F; de Jong, J; Küntay, AC","Grammatical development in both languages of bilingual Turkish-Dutch children with and without Developmental Language Disorder","FRONTIERS IN COMMUNICATION","","2297-900X","10.3389/fcomm.2022.1059427","","IntroductionTo guarantee a reliable diagnosis of Developmental Language Disorder (DLD) in bilingual children, evaluating both languages is recommended. However, little is known about how DLD impacts the heritage language, and it is largely unknown whether bilingual children with DLD develop the heritage language at the same pace as their peers with typical development (TD). MethodsFor this longitudinal study that focused on children's grammatical development, we analyzed semi-spontaneous speech samples of 10 Turkish-Dutch children with DLD (bi-DLD) and 10 Turkish-Dutch children with typical development (bi-TD). Children were 5 or 6 years old at the first wave of data collection, and there were three waves of longitudinal data collection with 1-year intervals. In addition, data from 20 monolingual Dutch controls were analyzed (10 mono-DLD, 10 mono-TD). Results and discussionResults indicate that heritage language assessment can inform clinical diagnosis. In the case of Turkish spoken in the Netherlands, short sentences, the absence of the genitive suffix in simple constructions and avoidance of complex constructions that require possessive marking could potentially be clinical markers of DLD. Accusative case errors are also relatively frequent in bilingual Turkish-Dutch children with DLD, but these are less promising as a clinical marker because previous research suggests that omission and substitution of accusative case can be part of the input to Turkish heritage language learners. In Dutch, frequent omission of grammatical morphemes in the verbal domain coupled with a limited amount of overregularization errors could indicate that a child is at risk for DLD, both in bilingual and monolingual contexts. Cross-linguistic comparisons of error types in Turkish and Dutch confirm that, regardless of typological differences, children with DLD use short sentences, avoid complex structures, and omit grammatical morphemes. Longitudinal analyses revealed that children with DLD can develop the heritage language at the same pace as TD children, even if this language is not supported at school. Strong intergenerational transmission and heritage language maintenance among Turkish migrants in the Netherlands may be key.","2022-12-15","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","7","","","","","","","","","","English","","","","WOS:000904811100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;81</p>","","","ACQUISITION; bilingualism; clinical markers; cross-linguistic comparison; ENGLISH; error types; grammatical morphemes; heritage language; IMMIGRANT CHILDREN; IMPAIRMENT; language impairment; longitudinal design; MONOLINGUAL DUTCH; MORPHOLOGY; NONWORD REPETITION; SPEAKING CHILDREN; TENSE; VERB AGREEMENT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QD3SLNUI","journalArticle","2021","Sherman, JC; Henderson, CR; Flynn, S; Gair, JW; Lust, B","Language Decline Characterizes Amnestic Mild Cognitive Impairment Independent of Cognitive Decline","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2021_JSLHR-20-00503","","Purpose: This research investigated the nature of cognitive decline in prodromal Alzheimer's disease (AD), particularly in mild cognitive impairment, amnestic type (aMCI). We assessed language in aMCI as compared with healthy aging (HA) and healthy young (HY) with new psycholinguistic assessment of complex sentences, and we tested the degree to which deficits on this language measure relate to performance in other general cognitive domains such as memory. Method: Sixty-one individuals with aMCI were compared with 24 HA and 10 HY adults on a psycholinguistic measure of complex sentence production (relative clauses). In addition, HA, HY, and a subset of the aMCI participants (n = 22) were also tested on a multidomain cognitive screen, the Addenbrooke's Cognitive Examination-Revised (ACE-R), and on a verbal working memory Brown-Peterson (BP) test. General and generalized linear mixed models were used to test psycholinguistic results and to test whether ACE-R and BP performance predicted performance on the psycho -linguistic test similarly in the aMCI and HA groups. Results: On the psycholinguistic measure, sentence imitation was significantly deficited in aMCI in comparison with that in HA and HY. Experimental factorial designs revealed that individuals with aMCI had particular difficulty repeating sentences that especially challenged syntax-semantics integration. As expected, the aMCI group also performed significantly below the HY and HA groups on the ACE-R. Neither the ACE-R Memory subtest nor the BP total scores predicted performance on the psycholinguistic task for either the aMCI or the HA group. However, the ACE-R total score significantly predicted psycholinguistic task performance, with increased ACE-R performance predicting increased psycholinguistic task performance only for the HA group, not for the aMCI group. Conclusions: Results suggest a selective deterioration in language in aMCI, specifically a weakening of syntax- semantics integration in complex sentence processing, and a general independence of this language deficit and memory decline. Results cohere with previous assessments of the nature of difficulty in complex sentence formation in aMCI. We argue that clinical screening for prodromal AD can be strengthened by supplementary testing of language, as well as memory, and extended evaluation of strength of their relation.","2021-11","2025-02-26 20:43:27","2025-02-26 20:43:27","","4287-4307","","11","64","","","","","","","","","","English","","","","WOS:000718136100014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;114</p>","","","COMPREHENSION; DATA SET UDS; DEMENTIA; EARLY ALZHEIMERS-DISEASE; MINI-MENTAL-STATE; SEMANTIC MEMORY; SPONTANEOUS SPEECH; VALIDATION; VERBAL FLUENCY PERFORMANCE; WORKING-MEMORY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7HIUJLIV","journalArticle","2021","Laguarta, J; Subirana, B","Longitudinal Speech Biomarkers for Automated Alzheimer's Detection","FRONTIERS IN COMPUTER SCIENCE","","2624-9898","10.3389/fcomp.2021.624694","","We introduce a novel audio processing architecture, the Open Voice Brain Model (OVBM), improving detection accuracy for Alzheimer's (AD) longitudinal discrimination from spontaneous speech. We also outline the OVBM design methodology leading us to such architecture, which in general can incorporate multimodal biomarkers and target simultaneously several diseases and other AI tasks. Key in our methodology is the use of multiple biomarkers complementing each other, and when two of them uniquely identify different subjects in a target disease we say they are orthogonal. We illustrate the OBVM design methodology by introducing sixteen biomarkers, three of which are orthogonal, demonstrating simultaneous above state-of-the-art discrimination for two apparently unrelated diseases such as AD and COVID-19. Depending on the context, throughout the paper we use OVBM indistinctly to refer to the specific architecture or to the broader design methodology. Inspired by research conducted at the MIT Center for Brain Minds and Machines (CBMM), OVBM combines biomarker implementations of the four modules of intelligence: The brain OS chunks and overlaps audio samples and aggregates biomarker features from the sensory stream and cognitive core creating a multi-modal graph neural network of symbolic compositional models for the target task. In this paper we apply the OVBM design methodology to the automated diagnostic of Alzheimer's Dementia (AD) patients, achieving above state-of-the-art accuracy of 93.8% using only raw audio, while extracting a personalized subject saliency map designed to longitudinally track relative disease progression using multiple biomarkers, 16 in the reported AD task. The ultimate aim is to help medical practice by detecting onset and treatment impact so that intervention options can be longitudinally tested. Using the OBVM design methodology, we introduce a novel lung and respiratory tract biomarker created using 200,000+ cough samples to pre-train a model discriminating cough cultural origin. Transfer Learning is subsequently used to incorporate features from this model into various other biomarker-based OVBM architectures. This biomarker yields consistent improvements in AD detection in all the starting OBVM biomarker architecture combinations we tried. This cough dataset sets a new benchmark as the largest audio health dataset with 30,000+ subjects participating in April 2020, demonstrating for the first time cough cultural bias.","2021-04-08","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","3","","","","","","","","","","English","","","","WOS:000705962900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;91</p>","","","AI diagnostics; brain model; COGNITIVE IMPAIRMENT; COUGH; COVID-19; DEMENTIA; DISEASE; DYSPHAGIA; explainable speech recognition; graph neural-networks; multimodal deep learning; SCALE; SUBSTANCE-P; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6NVXSQPE","journalArticle","2025","Imaezue, GC","Transfer effects of recursive self-feedback on connected speech production in patients with chronic nonfluent aphasia: Preliminary results","APHASIOLOGY","","0268-7038","10.1080/02687038.2024.2351010","","BackgroundPersons with nonfluent aphasia (PWNA) have deficits with online feedback for speech error detection and correction which have debilitating effects on language relearning in learned and novel contexts. Previous studies have shown that aphasia treatments that combine PWNA's offline self-feedback and external feedback from speech-language pathologists (SLPs) improve language production in learned and novel contexts. However, it remains unclear whether PWNA can use their offline self-feedback alone during treatments that generalizes to improvement in connected speech production. Here, we examine generalization effects of recursive self-feedback on PWNA's connected speech production. Recursive self-feedback utilizes offline self-feedback loops alone to help PWNA optimize their error monitoring and correction abilities for language production in learned and novel contexts.MethodA crossover design was used to investigate generalization effects of two treatments on connected speech production in four PWNA. These treatments comprised script production with recursive self-feedback and script production with external feedback. Employing a mobile health approach, treatments were remotely administered to participants within the comfort of their homes. Practice of both treatment blocks occurred intensively over two hours per day, five days per week, spanning two to three weeks. Each treatment block featured pretreatment and posttreatment assessment phases, with the sequencing of treatment blocks evenly counterbalanced across all participants. Following the initial treatment block, a two-week period devoid of treatment preceded the commencement of the second treatment block. Untrained narrative elicitation tasks were utilized to prompt connected speech production samples from all participants during the assessment phases of each treatment block. Effect sizes per participant were computed using within-case standard mean difference analysis.ResultsPWNA exhibited variability in performance, showing improvement in microlinguistic measures of connected speech following both script production with recursive self-feedback and script production with external feedback. Particularly, script production with recursive self-feedback demonstrated marginally superior enhancement in connected speech measures compared to its counterpart.ConclusionThe study provides preliminary evidence for generalization effects of recursive self-feedback training and external feedback training on PWNA's connected speech production. Further research is required to corroborate the findings and to implement recursive self-feedback procedures optimized specifically for spontaneous speech.","2025-03-04","2025-02-26 20:43:27","2025-02-26 20:43:27","","346-362","","3","39","","","","","","","","","","English","","","","WOS:001222428500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","connected speech production; DISCOURSE; ERRORFUL THERAPY; ERRORLESS; INFORMATIVENESS; LANGUAGE; MEMORY; Nonfluent aphasia; PEOPLE; QUANTITATIVE-ANALYSIS; recursive self-feedback; REHABILITATION; Self-feedback","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A4S6JLNY","journalArticle","2023","Kasture, N; Jain, P","Automatic recognition of disordered children's speech signal in dyadic interaction using deep learning models","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-023-17461-9","","Children suffering with spontaneous speech impairment or inappropriate communication abilities like disordered speech or delayed speech face challenges when involved in conversations. One of the motivating reasons for this work is to use the potential of deep learning models along with an effective feature extractor to automate the detection of specific language impairment (SLI) in children. Clinicians or speech pathologists use standard assessment tools that are time consuming as well as prone to various behavioural factors which can compromise the timely identification of the SLI in children. Moreover, the scarcity of annotated disordered children's speech adds to the complexity of training the reliable SLI detection model. The recent work focuses mainly on the utterance of vowels, scanning the acoustic features or the texture of the children's speech signals to detect the SLI. This work seeks to evaluate different components of children's speech like vowels, consonants and sentences to diagnose healthy and disordered speech. Speech samples are collected from Indian children in the age-group of 5-15 years speaking a secondary language English. The proposed method makes use of a combination of mel frequency cepstral co-efficients and i-vectors as a feature vector to identify SLI and distinguish it from mispronunciations due to second language usage. Moreover, analysis of variance (ANOVA) test has been implemented to choose the most significant MFCC and i-vector features. Finally, the selected features are given as input to pretrained models like VGG-16, MobileNet-v2, ResNet-50 and ResNet-101. Eventually, we study and evaluate the effect of parameters like age and model used on different parameters of speech like vowels, consonants, 3-word, 4-word and 5-word sentences in the dataset to diagnose healthy and disordered speech samples. 5-fold cross validation (CV) has been used to compensate for the limited size of dataset and achieve robust results. The experimental results show that with the proposed implementation method highest accuracy of 98.70% can be achieved on the vowels component in identifying the disordered children speech signals using MobileNet-v2 model.","2023-11-03","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","","","","","","","","","","","English","","","","WOS:001098545500010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Children's speech signal; Convolutional neural network; Deep learning; DIAGNOSTIC-ACCURACY; Disordered speech detection; LANGUAGE IMPAIRMENT; REPETITION; Specific language impairment; TASKS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PBKXL4VW","journalArticle","2025","Baqué, L; Machuca, MJ","Assessing informativeness in Spanish-speaking individuals with primary progressive aphasia","APHASIOLOGY","","0268-7038","10.1080/02687038.2024.2343457","","BackgroundPrimary progressive aphasia (PPA) is a neurodegenerative disorder associated with atrophy of the frontotemporal region. It is primarily characterized by language impairments that become accentuated over time, often leading to isolation and social exclusion. There are three main subtypes, the semantic (svPPA), non-fluent (nfvPPA), and logopenic (lvPPA) variants, each presenting distinct language deficits, as captured by standard assessment batteries. However, such assessments often fail to adequately identify functional communication (dis)abilities in everyday life, which is crucial for effective diagnosis and treatment. One understudied aspect of communication is informativeness, the conveyance of an appropriate amount of information in an efficient fashion.AimThis study aimed to identify the unique features of each variant of PPA that distinguish it from healthy controls, and the dissimilarity across PPA groups, in terms of the effectiveness and efficiency with which Spanish-speaking individuals with PPA conveyed information.Methods and proceduresThirty-two Spanish-speaking patients with one of the three variants of PPA and 11 healthy individuals were audio-recorded performing a picture description task. The resulting recordings were transcribed, and the contents labelled according to whether they constituted relevant or off-topic content, each type of content being further divided into subcategories. In total, 51 parameters related to the (1) overall amount of speech and number of correct information units, (2) amount of relevant content, (3) completeness of the content, and (4) off-topic information were considered. Nonparametric analyses were conducted to assess the divergence from heathy controls of each PPA group, and the dissimilarity across PPA groups.Outcomes and resultsResults revealed disruptions in informativeness in all PPA variants compared to controls, with lvPPA characterized by inadequate content and a high concentration of off-topic elements, nfvPPA by inadequate content but efficient delivery, and svPPA by inadequate content delivered inefficiently.ConclusionsThis study revealed that all three variants of PPA are characterized by reduced informativeness, although each exhibits unique patterns in communicative efficiency and the presence of off-topic information. By assessing the total amount of relevant speech, efficiency in conveying content, and the presence of off-topic elements, this research enhances our understanding of the distinct communication impairments characterizing lvPPA, nfvPPA, and svPPA, and provides valuable insights that can be applied to developing tailored remedial strategies.","2025-02-01","2025-02-26 20:43:27","2025-02-26 20:43:27","","285-319","","2","39","","","","","","","","","","English","","","","WOS:001206627800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;83</p>","","","Aphasia; APRAXIA; COMPLEXITY; CONNECTED SPEECH; CONVERSATION; DISCOURSE; EFFICIENCY; IMPAIRMENTS; informativeness; LEXICAL DIVERSITY; PATHOLOGY; picture description; PPA; SPEECH PRODUCTION; spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B4TYZ44U","journalArticle","2022","Siriboonpipattana, W; Nickels, L; Bastiaanse, R","Characteristics of Thai Agrammatic speech","APHASIOLOGY","","0268-7038","10.1080/02687038.2021.1924356","","Background Agrammatic speech is characterized by reduced speech rate, reduced utterance length and lack of grammatical complexity, with grammatical morphemes often omitted or substituted. At the word level, verbs have been argued to be particularly vulnerable: agrammatic speakers produce fewer verbs or use a less diverse range of verbs than unimpaired speakers and the use of finite verbs is compromised. However, this description is based on agrammatic narrative speech from languages that express Tense, Aspect and Agreement through verb inflection. To date, a few studies have described narrative speech in a language without verb inflection (e.g., Standard Indonesian). Thai is another language that does not use verb inflection but uses constructions with serial verbs. Another typical feature of Thai, which has not been investigated in agrammatic speakers, is the use of particles to express politeness, although agrammatic speakers of Standard Indonesian have an impaired use of (different) particles but produce the passive construction (which is a way to express politeness) to a normal extent. Aim The current study aimed to characterize Thai agrammatic speech and to analyse the use of verbs and polite particles. Methods Nine Thai agrammatic and nine non-brain-damaged (NBD) speakers participated in the study. Narrative speech was elicited in a semi-standardized interview and by picture description. First, the presence of general features of agrammatic speech were investigated in Thai: reduced speech rate and utterance length, and lack of grammatical complexity. This was followed by an in-depth analysis of verb and particle production. Results As in other languages, Thai agrammatic speakers talked slowly and with short utterances. However, the use of embedded sentences was normal. They produced fewer verbs, more specifically, their production of the serial verb construction was seriously impaired. Remarkably, the use of polite particles was spared, in fact, the agrammatic speakers produced more of these particles than the NBD speakers, although this may have been influenced by the context. Conclusions Thai agrammatic speech resembles that of other languages in terms of speech rate and utterance length. Interestingly, the specific features of Thai that were investigated, serial verbs and polite particles, both showed different patterns to normal, and merit further investigation in the future.","2022-08-03","2025-02-26 20:43:27","2025-02-26 20:43:27","","962-981","","8","36","","","","","","","","","","English","","","","WOS:000673150500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","ADULTS; Agrammatism; AGREEMENT; APHASIA; COMPREHENSION; ENGLISH; FEATURES; particles; serial verbs; SPEAKERS; spontaneous speech; TENSE; Thai; TIME REFERENCE; VERB","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DBK93VA5","journalArticle","2024","Luniewska, M; Krysztofiak, M; Haman, E","Parental report of vocabulary in 3-to 6-year-old Polish children: Reliable but not valid","INTERNATIONAL JOURNAL OF LANGUAGE & COMMUNICATION DISORDERS","","1368-2822","10.1111/1460-6984.13101","","BackgroundFor over 30 years, parental reports have been used to study the vocabulary of children under 4 years of age. Research exploring parental checklists as a measure of vocabulary in older children is very limited. Typically, authors of parental checklists report the reliability of the developed tools but do not explore validity in terms of the agreement between parental assessments and the children's actual word knowledge.AimsWe aimed to explore the reliability and validity of a parental checklist for assessing vocabulary in children aged between 3 and 6 years. Furthermore, we aimed to evaluate the agreement between indirect (parental checklist) and direct (picture naming and picture recognition tasks) assessments of children's vocabulary.Methods and ProceduresA group of 94 typically developing monolingual Polish-speaking children aged between 3 and 6 years were first directly tested onsite with picture naming and picture recognition tasks (Cross-Linguistic Lexical Tasks). Subsequently, the participants' parents completed an online checklist containing the same set of 128 items and marked all the words that they had ever heard in their child's spontaneous speech.Outcomes and ResultsThe parental checklist demonstrated very high internal consistency. The scores of the parental checklist and vocabulary tasks were moderately correlated. We compared the total number of words marked by parents and the number of items correctly identified by children in the picture naming and picture recognition tasks. In picture naming, we found no difference between the children's scores and the number of words selected by parents. However, parents selected significantly fewer words than children correctly recognised in the picture recognition task. When data were analysed at the level of individual items (i.e., whether parents selected exactly the same items that children answered correctly), we found that the level of agreement was low. The level of agreement correlated negatively with the children's vocabulary; that is, the more words a child knew, the lower the agreement between the direct measure and the parental checklist.Conclusions and ImplicationsParental checklists should be used with caution in children aged between 3 and 6 years, especially if the assessed children have a large vocabulary and if item analysis is planned. Such checklists may be of more use in younger children or in children with limited vocabulary.","2024-11","2025-02-26 20:43:27","2025-02-26 20:43:27","","2483-2496","","6","59","","","","","","","","","","English","","","","WOS:001287318700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","assessment; children; COMPREHENSION; LANGUAGES; parents; PREDICTIVE-VALIDITY; preschool; psychometrics; SIZE; vocabulary; WORDS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YWZCCBXE","journalArticle","2022","Meier, EL; Kelly, CR; Hillis, AE","Dissociable language and executive control deficits and recovery in post-stroke aphasia: An exploratory observational and case series study","NEUROPSYCHOLOGIA","","0028-3932","10.1016/j.neuropsychologia.2022.108270","","A growing body of evidence indicates many, but not all, individuals with post-stroke aphasia experience executive dysfunction. Relationships between language and executive function skills are often reported in the literature, but the degree of interdependence between these abilities remains largely unanswered. Therefore, in this study, we investigated the extent to which language and executive control deficits dissociated in 1) acute stroke and 2) longitudinal aphasia recovery. Twenty-three individuals admitted to Johns Hopkins Hospital with a new left hemisphere stroke completed the Western Aphasia Battery-Revised (WAB-R), several additional language measures (of naming, semantics, spontaneous speech, and oral reading), and three non-linguistic cognitive tasks from the NIH Toolbox (i.e., Pattern Comparison Processing Speed Test, Flanker Inhibitory Control and Attention Test, and Dimensional Change Card Sort Test). Two participants with aphasia (PWA) with temporoparietal lesions, one of whom (PWA1) had greater temporal but less frontal and superior parietal damage than the other (PWA2), also completed testing at subacute (three months post-onset) and early chronic (six months post-onset) time points. In aim 1, principal component analysis on the acute test data (excluding the WAB-R) revealed language and non-linguistic executive control tasks largely loaded onto separate components. Both components were significant predictors of acute aphasia severity per the WAB-R Aphasia Quotient (AQ). Crucially, executive dysfunction explained an additional 17% of the variance in AQ beyond the explanatory power of language impairments alone. In aim 2, both case patients exhibited language and executive control deficits at the acute post-stroke stage. A dissociation was observed in longitudinal recovery of these patients. By the early chronic time point, PWA1 exhibited improved (but persistent) deficits in several language domains and recovered executive control. In contrast, PWA2 demonstrated mostly recovered language but persistent executive dysfunction. Greater damage to language and attention networks in these respective patients may explain the observed behavioral patterns. These results demonstrate that language and executive control can dissociate (at least to a degree), but both contribute to early post-stroke presentation of aphasia and likely influence longitudinal aphasia recovery.","2022-07-29","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","172","","","","","","","","","","English","","","","WOS:000813336700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;165</p>","","","ANTERIOR TEMPORAL INVOLVEMENT; Aphasia; BETWEEN-SESSION; BRAIN NETWORKS; Case series; Dissociation; Executive control; FUNCTIONAL CONNECTIVITY; INDIVIDUAL-DIFFERENCES; NIH TOOLBOX; SESSION INTRAINDIVIDUAL VARIABILITY; Stroke recovery; TASK-PERFORMANCE; TOOLBOX COGNITION BATTERY; WORD RETRIEVAL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HJHQRMXS","journalArticle","2023","Knight, JL; Barker, MS; Edwards, TJ; Barnby, JM; Richards, LJ; Robinson, GA","Mirror movements and callosal dysgenesis in a family with a DCC mutation: Neuropsychological and neuroimaging outcomes","CORTEX","","0010-9452","10.1016/j.cortex.2023.01.008","","Corpus callosum dysgenesis is a congenital abnormality whereby the corpus callosum fails to develop normally, and has been associated with a range of neuropsychological out-comes. One specific finding in some individuals with corpus callosum dysgenesis is ""congenital mirror movement disorder"", which is the presence of involuntary movements on one side of the body that mimic voluntary movements of the other side. Mirror movements have also been associated with mutations in the deleted in colorectal carci-noma (DCC) gene. The current study aims to comprehensively document the neuropsy-chological outcomes and neuroanatomical mapping of a family (a mother, daughter and son) with known DCC mutations. All three family members experience mirror movements, and the son additionally has partial agenesis of the corpus callosum (pACC). All family members underwent extensive neuropsychological testing, spanning general intellectual functioning, memory, language, literacy, numeracy, psychomotor speed, visuospatial perception, praxis and motor functioning, executive functioning, attention, verbal/ nonverbal fluency, and social cognition. The mother and daughter had impaired memory for faces, and reduced spontaneous speech, and the daughter demonstrated scattered impairments in attention and executive functioning, but their neuropsychological abilities were largely within normal limits. By contrast, the son showed areas of significant impairment across multiple domains including reduced psychomotor speed, fine motor dexterity and general intellectual functioning, and he was profoundly impaired across areas of executive functioning and attention. Reductions in his verbal/non-verbal fluency, with relatively intact core language, resembled dynamic frontal aphasia. His relative strengths included aspects of memory and he demonstrated largely sound theory of mind. Neuroimaging revealed an asymmetric sigmoid bundle in the son, connecting, via the callosal remnant, the left frontal cortex with contralateral parieto-occipital cortex. Overall, this study documents a range of neuropsychological and neuroanatomical outcomes within one family with DCC mutations and mirror movements, including one with more severe consequences and pACC.(c) 2023 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).","2023-04","2025-02-26 20:43:27","2025-02-26 20:43:27","","38-50","","","161","","","","","","","","","","English","","","","WOS:000972582800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;94</p>","","","AGE; APHASIA; CHILDREN; COMPREHENSION; Corpus callosum dysgenesis; CORPUS-CALLOSUM; DCC genetic Mutation; DISORDERS; FLUENCY; INDIVIDUALS; ISOLATED AGENESIS; Mirror movements; Neuropsychological outcomes; NORMATIVE DATA; Partial ACC","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HMNBMV29","journalArticle","2024","Ottarsdottir, E; Ghavidel, FZ; Tveiten, OV; Specht, K; Wehling, E","Predictors of self-reported word-finding difficulties in glioma patients - a longitudinal study","APHASIOLOGY","","0268-7038","10.1080/02687038.2024.2335594","","BackgroundWord-finding difficulties are a common self-reported concern in glioma patients known to negatively affect social participation and life satisfaction. Discrepancies between self-reported difficulties and performance on objective tests have been reported, but studies are seldom conducted longitudinally.AimsThe aim of the present study was to examine the occurrence of self-reported word-finding difficulties before and during the first year after glioma surgery. In addition, we investigated whether self-reported word-finding difficulties were predicted by standardized language tests and psychological distress.Methods and proceduresTwenty-three patients with gliomas (grade 1-3) were assessed pre-surgery, at six and twelve months follow-up. Self-reported word-finding difficulties were addressed with the item I am able to find the right word(s) to say what I mean, from the Functional Assessment of Cancer Therapy - Brain (FACT-Br). Confrontation naming was tested with the Boston Naming Test (BNT), word production with a semantic fluency test and word knowledge with a vocabulary test. Self-reported measures of psychological distress were assessed with the Hospital Anxiety and Depression Scale (HADS). Ordinal regression models were used to examine predictors of self-reported word-finding difficulties.Outcomes and resultsWord-finding difficulties were reported by 68% of the patients pre-surgery, increasing to 90% and 85% at the following assessments. Significant changes were observed in the magnitude of reported concerns between pre-surgery assessment and six months follow-up. Regression analyses demonstated that self-reported word-finding difficulties were predicted by psychological distress and vocabulary pre-surgery and vocabulary at six months follow-up, whereas confrontation naming and semantic fluency did not become significant in any of the assessments.ConclusionOur results indicate that self-reported word-finding difficulties occurred in a high percentage of glioma patients throughout the first year of illness. Patients reported increased difficulties after surgery that were not predicted by confrontation naming or semantic fluency but by vocabulary performance. The results imply further that psychological distress is a factor that should be taken into account. Self-reported function is an important supplement to objective testing and can provide indications about mental health status and the patients` perspective on language related challenges in everyday life.","2024-12-01","2025-02-26 20:43:27","2025-02-26 20:43:27","","1940-1956","","12","38","","","","","","","","","","English","","","","WOS:001199978700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","brain tumor; BRAIN-TUMORS; CANCER-PATIENTS; DEPRESSION SCALE; HOSPITAL ANXIETY; LANGUAGE; longitudinal study; LOW-GRADE GLIOMA; OUTCOMES; patient-reported data; psychological distress; PSYCHOLOGICAL DISTRESS; RESECTION; SPONTANEOUS SPEECH; Word-finding difficulties","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LVAMHPLC","journalArticle","2024","Feng, YN; Goldberg, EE; Kupperman, M; Zhang, XT; Lin, YZ; Ke, RA","CovTransformer: A transformer model for SARS-CoV-2 lineage frequency forecasting","VIRUS EVOLUTION","","2057-1577","10.1093/ve/veae086","","With hundreds of SARS-CoV-2 lineages circulating in the global population, there is an ongoing need for predicting and forecasting lineage frequencies and thus identifying rapidly expanding lineages. Accurate prediction would allow for more focused experimental efforts to understand pathogenicity of future dominating lineages and characterize the extent of their immune escape. Here, we first show that the inherent noise and biases in lineage frequency data make a commonly-used regression-based approach unreliable. To address this weakness, we constructed a machine learning model for SARS-CoV-2 lineage frequency forecasting, called CovTransformer, based on the transformer architecture. We designed our model to navigate challenges such as a limited amount of data with high levels of noise and bias. We first trained and tested the model using data from the UK and the USA, and then tested the generalization ability of the model to many other countries and US states. Remarkably, the trained model makes accurate predictions two months into the future with high levels of accuracy both globally (in 31 countries with high levels of sequencing effort) and at the US-state level. Our model performed substantially better than a widely used forecasting tool, the multinomial regression model implemented in Nextstrain, demonstrating its utility in SARS-CoV-2 monitoring. Assuming a newly emerged lineage is identified and assigned, our test using retrospective data shows that our model is able to identify the dominating lineages 7 weeks in advance on average before they became dominant. Overall, our work demonstrates that transformer models represent a promising approach for SARS-CoV-2 forecasting and pandemic monitoring.","2024-12-07","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","1","10","","","","","","","","","","English","","","","WOS:001373560000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","DISEASE; machine learning; SARS-CoV-2; time series; viral lineage frequency forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M7FUR2A4","journalArticle","2025","Vindas, Y; Roux, E; Guepie, BK; Almar, M; Delachartre, P","An asymmetric heuristic for trained ternary quantization based on the statistics of the weights: An application to medical signal classification","PATTERN RECOGNITION LETTERS","","0167-8655","10.1016/j.patrec.2024.11.016","","One of the main challenges in the field of deep learning and embedded systems is the mismatch between the memory, computational and energy resources required by the former for good performance and the resource capabilities offered by the latter. It is therefore important to find a good trade-off between performance and computational resources used. In this study, we propose a novel ternarization heuristic based on the statistics of the weights, in addition to asymmetric pruning. Our approach involves the computation of two asymmetric thresholds based on the mean and standard deviation of the weights. This allows us to distinguish between positive and negative values prior to ternarization. Two hyperparameters are introduced into these thresholds, which permit the user to control the trade-off between compression and classification performance. Following thresholding, ternarization is carried out in accordance with the methodology of trained ternary quantization (TTQ). The efficacy of the method is evaluated on three datasets, two of which are medical: a cerebral emboli (HITS) dataset, an epileptic seizure recognition (ESR) dataset, and the MNIST dataset. Two types of deep learning models were tested: 2D convolutional neural networks (CNNs) and 1D CNN-transformers. The results demonstrate that our approach, aTTQ, achieves a superior trade-off between classification performance and compression rate compared with TTQ, for all the models and datasets. In fact, our method is capable of reducing the memory requirements of a 1D CNN-transformer model for the ESR dataset by over 21% compared to TTQ, while maintaining a Matthews correlation coefficient of 95%. The code is available at: https://github.com/yamilvindas/aTTQ.","2025-02","2025-02-26 20:43:27","2025-02-26 20:43:27","","37-45","","","188","","","","","","","","","","English","","","","WOS:001380525400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Model compression; Model pruning; Model quantization; Signal classification; Transcranial doppler","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GR9Q5EV9","journalArticle","2025","Hosny, M; Elshenhab, AM; Maged, A","Explainable AI-based method for brain abnormality diagnostics using MRI","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2024.107184","","Detecting brain abnormalities using magnetic resonance imaging (MRI) is a vital frontier in neurological research. Therefore, accurate methods are essential for guiding neurologists in diagnosing enigmatic disorders such as Alzheimer's disease (AD) and brain tumors. These methods aid in the early detection and treatment of these formidable conditions. However, traditional techniques often suffer from high computational complexity and efficiency. Additionally, existing detection models lack the ability to explain their predictions, rendering them untrustworthy for clinicians. This study presents an explainable framework for automatic brain abnormality detection in MRI images. The methodology includes a robust preprocessing pipeline that ameliorates image relevance through image thresholding, morphological operations and adaptive edge detection using the AutoCanny algorithm. AutoCanny method automatically adjusts thresholds to ensure effective edge detection across different images. Then, the MRI images are fed to efficient vision transformer model (EfficientViT) for classification. EfficientViT features a memory-efficient sandwich layout, cascaded group attention module and optimized parameter reallocation. These innovations collectively enhanced the model efficiency in terms of memory usage, computational complexity and parameter optimization. Moreover, gradient-based Shapley additive explanations is employed to explain the EfficientViT model predictions. EfficientViT achieved the highest accuracy of 99.24%, 97.1%, 99.5% and 98.87% on the AD, Tumor1, Tumor2 and merged datasets, respectively. Furthermore, the proposed model outperformed longstanding deep learning techniques. These findings have significant implications for uncovering hidden information associated with brain abnormality as well as improving the diagnostic process and treatment planning. Our model can aid neurologists in the validation of manual MRI neurological disorders screenings.","2025-02","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","100","","","","","","","","","","English","","","","WOS:001358322500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","ARTIFICIAL-INTELLIGENCE; AutoCanny; AUTOMATED DETECTION; Brain abnormality detection; Efficient vision transformer; Explainable artificial intelligence; IMAGES; Magnetic resonance imaging; MODEL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R5SVKIMW","journalArticle","2024","Adegun, A; Viriri, S; Tapamo, JR","Automated classification of remote sensing satellite images using deep learning based vision transformer","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-024-05818-y","","Automatic classification of remote sensing images using machine learning techniques is challenging due to the complex features of the images. The images are characterized by features such as multi-resolution, heterogeneous appearance and multi-spectral channels. Deep learning methods have achieved promising results in the analysis of remote sensing satellite images in the recent past. However, deep learning methods based on convolutional neural networks (CNN) experience difficulties in the analysis of intrinsic objects from satellite images. These techniques have not achieved optimum performance in the analysis of remote sensing satellite images due to their complex features, such as coarse resolution, cloud masking, varied sizes of embedded objects and appearance. The receptive fields in convolutional operations are not able to establish long-range dependencies and lack global contextual connectivity for effective feature extraction. To address this problem, we propose an improved deep learning-based vision transformer model for the efficient analysis of remote sensing images. The proposed model incorporates a multi-head local self-attention mechanism with patch shifting procedure to provide both local and global context for effective extraction of multi-scale and multi-resolution spatial features of remote sensing images. The proposed model is also enhanced by fine-tuning the hyper-parameters by introducing dropout modules and a decay linear learning rate scheduler. This approach leverages local self-attention for learning and extraction of the complex features in satellite images. Four distinct remote sensing image datasets, namely RSSCN, EuroSat, UC Merced (UCM) and SIRI-WHU, were subjected to experiments and analysis. The results show some improvement in the proposed vision transformer on the CNN-based methods.","2024-12","2025-02-26 20:43:27","2025-02-26 20:43:27","","13018-13037","","24","54","","","","","","","","","","English","","","","WOS:001334490300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;92</p>","","","BENCHMARK; Deep learning; INVARIANT; Local self attention; NETWORKS; OBJECT DETECTION; Remote sensing; SCENE CLASSIFICATION; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UZPBXMRG","journalArticle","2024","Dia, M; Khodabandelou, G; Othmani, A","Paying attention to uncertainty: A stochastic multimodal transformers for post-traumatic stress disorder detection using video","COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE","","0169-2607","10.1016/j.cmpb.2024.108439","","Background and Objectives: Post-traumatic stress disorder is a debilitating psychological condition that can manifest following exposure to traumatic events. It affects individuals from diverse backgrounds and is associated with various symptoms, including intrusive thoughts, nightmares, hyperarousal, and avoidance behaviors. Methods: To address this challenge this study proposes a decision support system powered by a novel multimodal deep learning approach, based on a stochastic Transformer and video data. This Transformer has the ability to take advantage of its stochastic activation function and layers that allow it to learn sparse representations of the inputs. The method leverages a combination of low-level features extracted using three modalities, including Mel-frequency cepstral coefficients extracted from audio recordings, Facial Action Units captured from facial expressions, and textual data obtained from the audio transcription. By considering these modalities, our proposed model captures a comprehensive range of information related to post-traumatic stress disorder symptoms, including vocal cues, facial expressions, and linguistic content. Results: The deep learning model was trained and evaluated on the eDAIC dataset, which consists of clinical interviews with individuals with and without post-traumatic disorder. The model achieved state-of-the-art results, demonstrating its effectiveness in accurately detecting PTSD, showing an impressive Root Mean Square Error of 1.98, and a Concordance Correlation Coefficient of 0.722, signifying the model's superior performance compared to existing approaches. Conclusion: This work introduces a new method for post-traumatic stress disorder detection from videos by utilizing a multimodal stochastic Transformer model. The model makes use of a variety of modalities, such as text, audio, and visual data, to gather comprehensive and varied information in order to make the detection.","2024-12","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","257","","","","","","","","","","English","","","","WOS:001336371100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Decision support systems; Deep learning; Multimodal fusion; Post-traumatic stress disorder; PTSD; Transformer; TRAUMA; Video analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3255Z8HQ","journalArticle","2024","Wu, SQ; Liu, BS; Zhang, XY; Shao, XW; Lin, CN","MTrans: M-Transformer and Knowledge Graph-Based Network for Predicting Drug-Drug Interactions","ELECTRONICS","","2079-9292","10.3390/electronics13152935","","The combined use of multiple medications is common in treatment, which may lead to severe drug-drug interactions (DDIs). Deep learning methods have been widely used to predict DDIs in recent years. However, current models need help to fully understand the characteristics of drugs and the relationships between these characteristics, resulting in inaccurate and inefficient feature representations. Beyond that, existing studies predominantly focus on analyzing a single DDIs, failing to explore multiple similar DDIs simultaneously, thus limiting the discovery of common mechanisms underlying DDIs. To address these limitations, this research proposes a method based on M-Transformer and knowledge graph for predicting DDIs, comprising a dual-pathway approach and neural network. In the first pathway, we leverage the interpretability of the transformer to capture the intricate relationships between drug features using the multi-head attention mechanism, identifying and discarding redundant information to obtain a more refined and information-dense drug representation. However, due to the potential difficulty for a single transformer model to understand features from multiple semantic spaces, we adopted M-Transformer to understand the structural and pharmacological information of the drug as well as the connections between them. In the second pathway, we constructed a drug-drug interaction knowledge graph (DDIKG) using drug representation vectors obtained from M-Transformer as nodes and DDI types as edges. Subsequently, drug edges with similar interactions were aggregated using a graph neural network (GNN). This facilitates the exploration and extraction of shared mechanisms underlying drug-drug interactions. Extensive experiments demonstrate that our MTrans model accurately predicts DDIs and outperforms state-of-the-art models.","2024-08","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","15","13","","","","","","","","","","English","","","","WOS:001287192800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","ADULTS; drug-drug interactions; GNN; knowledge graph; PRESCRIPTION; transformer-encoder; UNITED-STATES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9VWK47V6","journalArticle","2024","Kishiyama, B; Lee, Y; Yang, J","Improving VulRepair's Perfect Prediction by Leveraging the LION Optimizer","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14135750","","In current software applications, numerous vulnerabilities may be present. Attackers attempt to exploit these vulnerabilities, leading to security breaches, unauthorized entry, data theft, or the incapacitation of computer systems. Instead of addressing software or hardware vulnerabilities at a later stage, it is better to address them immediately or during the development phase. Tools such as AIBugHunter provide solutions designed to tackle software issues by predicting, categorizing, and fixing coding vulnerabilities. Essentially, developers can see where their code is susceptible to attacks and obtain details about the nature and severity of these vulnerabilities. AIBugHunter incorporates VulRepair to detect and repair vulnerabilities. VulRepair currently predicts patches for vulnerable functions at 44%. To be truly effective, this number needs to be increased. This study examines VulRepair to see whether the 44% perfect prediction can be increased. VulRepair is based on T5 and uses both natural language and programming languages during its pretraining phase, along with byte pair encoding. T5 is a text-to-text transfer transformer model with an encoder and decoder as part of its neural network. It outperforms other models such as VRepair and CodeBERT. However, the hyperparameters may not be optimized due to the development of new optimizers. We reviewed a deep neural network (DNN) optimizer developed by Google in 2023. This optimizer, the Evolved Sign Momentum (LION), is available in PyTorch. We applied LION to VulRepair and tested its influence on the hyperparameters. After adjusting the hyperparameters, we obtained a 56% perfect prediction, which exceeds the value of the VulRepair report of 44%. This means that VulRepair can repair more vulnerabilities and avoid more attacks. As far as we know, our approach utilizing an alternative to AdamW, the standard optimizer, has not been previously applied to enhance VulRepair and similar models.","2024-07","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","13","14","","","","","","","","","","English","","","","WOS:001269551700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","AdamW; LION optimizer; software vulnerabilities; T5 transformer; VulRepair","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9J6JX35N","journalArticle","2024","Chaurasia, R; Ghose, U","XDeMo: a novel deep learning framework for DNA motif mining using transformer models","NETWORK MODELING AND ANALYSIS IN HEALTH INFORMATICS AND BIOINFORMATICS","","2192-6662","10.1007/s13721-024-00463-4","","Motivation: Recognizing and studying DNA patterns is crucial for improving knowledge of illnesses, cell function, and gene control. Motifs determine which transcription factor a protein may bind to, leading to a better unraveling of gene expression. Advancements in the fields of deep learning and high-throughput sequencing have made possible the exploration of motif discovery anew, with greater accuracy and performance. Methodology: In this paper, a novel deep learning framework (XDeMo - Transformer-based Deep Motifs) for DNA motif mining using Transformer models is proposed. Furthermore, a hybrid encoding scheme is also introduced, called 'blended' encoding specifically designed for use with deep learning transformer models that are trained using DNA sequences. Results: Our proposed transformer-based framework for DNA motif discovery augmented by blended encoding outperforms many state-of-the-art deep learning models on many baseline performance metrics when trained on the standard datasets. Our models demonstrated robust performance in predicting motifs with high discriminative power, precision, recall, and F1 score. Conclusion: The model's ability to capture intricate sequence patterns and long-range dependencies led to the discovery of biologically meaningful motifs that were verified from known transcription factor binding motif databases. This shows that our novel framework can be effectively used to find DNA motifs and therefore, aid in further downstream analyses for biomedical and biotechnological applications. XDeMo's practical implications span the realms of gene regulation research, genomics tool development, molecular biology, and diagnostic applications. It offers a robust foundation for further advancements in genomic analysis, with the potential to accelerate discoveries in gene regulation and the development of novel therapeutic strategies.","2024-05-13","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","1","13","","","","","","","","","","English","","","","WOS:001221352800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","ARCHITECTURES; BINDING; Blended encoding; ChIP-seq; Deep learning; DNA motif; GENOME; Transcriptional factor; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2X2B5PA6","journalArticle","2024","Malik, U; Visani, M; Sidere, N; Coustaty, M; Joseph, A","Experimental study of rehearsal-based incremental classification of document streams","INTERNATIONAL JOURNAL ON DOCUMENT ANALYSIS AND RECOGNITION","","1433-2833","10.1007/s10032-024-00467-w","","This research work proposes a novel protocol for rehearsal-based incremental learning models for the classification of business document streams using deep learning and, in particular, transformer-based natural language processing techniques. When implementing a rehearsal-based incremental classification model, the questions raised most often for parameterizing the model relate to the number of instances from ""old"" classes (learned in previous training iterations) which need to be kept in memory and the optimal number of new classes to be learned at each iteration. In this paper, we propose an incremental learning protocol that involves training incremental models using a weight-sharing strategy between transformer model layers across incremental training iterations. We provide a thorough experimental study that enables us to determine optimal ranges for various parameters in the context of incremental classification of business document streams. We also study the effect of the order in which the classes are presented to the model for learning and the effects of class imbalance on the model's performances. Our results reveal no significant difference in the performances of our incrementally trained model and its statically trained counterpart after all training iterations (especially when, in the presence of class imbalance, the most represented classes are learned first). In addition, our proposed approach shows an improvement of 1.55% and 3.66% over a baseline model on two business documents dataset. Based on this experimental study, we provide a list of recommendations for researchers and developers for training rehearsal-based incremental classification models for business document streams. Our protocol can be further re-used for other final applications.","2024-12","2025-02-26 20:43:27","2025-02-26 20:43:27","","629-653","","4","27","","","","","","","","","","English","","","","WOS:001220388600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Deep learning; Document classification; Incremental learning; Natural language processing; Rehearsal-based incremental learning; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BQ6RQW3L","journalArticle","2023","Zhang, XB; Li, HS; Li, JZ; Zhou, XH","OrthoDETR: A Streamlined Transformer-Based Approach for Precision Detection of Orthopedic Medical Devices","ALGORITHMS","","1999-4893","10.3390/a16120550","","The rapid and accurate detection of orthopedic medical devices is pivotal in enhancing health care delivery, particularly by improving workflow efficiency. Despite advancements in medical imaging technology, current detection models often fail to meet the unique requirements of orthopedic device detection. To address this gap, we introduce OrthoDETR, a Transformer-based object detection model specifically designed and optimized for orthopedic medical devices. OrthoDETR is an evolution of the DETR (Detection Transformer) model, with several key modifications to better serve orthopedic applications. We replace the ResNet backbone with the MLP-Mixer, improve the multi-head self-attention mechanism, and refine the loss function for more accurate detections. In our comparative study, OrthoDETR outperformed other models, achieving an AP50 score of 0.897, an AP50:95 score of 0.864, an AR50:95 score of 0.895, and a frame per second (FPS) rate of 26. This represents a significant improvement over the DETR model, which achieved an AP50 score of 0.852, an AP50:95 score of 0.842, an AR50:95 score of 0.862, and an FPS rate of 20. OrthoDETR not only accelerates the detection process but also maintains an acceptable performance trade-off. The real-world impact of this model is substantial. By facilitating the precise and quick detection of orthopedic devices, OrthoDETR can potentially revolutionize the management of orthopedic workflows, improving patient care, and enhancing the efficiency of healthcare systems. This paper underlines the significance of specialized object detection models in orthopedics and sets the stage for further research in this direction.","2023-12","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","12","16","","","","","","","","","","English","","","","WOS:001131259000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","DETR; MLP-Mixer; multi-head self-attention mechanism; orthopedic medical devices; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3IHJHLZT","journalArticle","2023","Wen, JH; Gan, HT; Yang, Z; Zhou, R; Zhao, J; Ye, ZW","Mutual-DTI: A mutual interaction feature-based neural network for drug-target protein interaction prediction","MATHEMATICAL BIOSCIENCES AND ENGINEERING","","1551-0018","10.3934/mbe.2023469","","The prediction of drug-target protein interaction (DTI) is a crucial task in the development of new drugs in modern medicine. Accurately identifying DTI through computer simulations can significantly reduce development time and costs. In recent years, many sequence-based DTI prediction methods have been proposed, and introducing attention mechanisms has improved their forecasting performance. However, these methods have some shortcomings. For example, inappropriate dataset partitioning during data preprocessing can lead to overly optimistic prediction results. Additionally, only single non-covalent intermolecular interactions are considered in the DTI simulation, ignoring the complex interactions between their internal atoms and amino acids. In this paper, we propose a network model called Mutual-DTI that predicts DTI based on the interaction properties of sequences and a Transformer model. We use multi-head attention to extract the long-distance interdependent features of the sequence and introduce a module to extract the sequence's mutual interaction features in mining complex reaction processes of atoms and amino acids. We evaluate the experiments on two benchmark datasets, and the results show that Mutual-DTI outperforms the latest baseline significantly. In addition, we conduct ablation experiments on a label-inversion dataset that is split more rigorously. The results show that there is a significant improvement in the evaluation metrics after introducing the extracted sequence interaction feature module. This suggests that Mutual-DTI may contribute to modern medical drug development research. The experimental results show the effectiveness of our approach. The code for Mutual-DTI can be downloaded from https://github.com/a610lab/Mutual-DTI.","2023","2025-02-26 20:43:27","2025-02-26 20:43:27","","10610-10625","","6","20","","","","","","","","","","English","","","","WOS:000976059300011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","CHEMOGENOMICS; drug discovery; drug-target protein interaction; KERNELS; mutual interaction features","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"787DAEPR","journalArticle","2022","Islam, MR; Nahiduzzaman, M; Goni, MOF; Sayeed, A; Anower, MS; Ahsan, M; Haider, J","Explainable Transformer-Based Deep Learning Model for the Detection of Malaria Parasites from Blood Cell Images","SENSORS","","1424-8220","10.3390/s22124358","","Malaria is a life-threatening disease caused by female anopheles mosquito bites. Various plasmodium parasites spread in the victim's blood cells and keep their life in a critical situation. If not treated at the early stage, malaria can cause even death. Microscopy is a familiar process for diagnosing malaria, collecting the victim's blood samples, and counting the parasite and red blood cells. However, the microscopy process is time-consuming and can produce an erroneous result in some cases. With the recent success of machine learning and deep learning in medical diagnosis, it is quite possible to minimize diagnosis costs and improve overall detection accuracy compared with the traditional microscopy method. This paper proposes a multiheaded attention-based transformer model to diagnose the malaria parasite from blood cell images. To demonstrate the effectiveness of the proposed model, the gradient-weighted class activation map (Grad-CAM) technique was implemented to identify which parts of an image the proposed model paid much more attention to compared with the remaining parts by generating a heatmap image. The proposed model achieved a testing accuracy, precision, recall, f1-score, and AUC score of 96.41%, 96.99%, 95.88%, 96.44%, and 99.11%, respectively, for the original malaria parasite dataset and 99.25%, 99.08%, 99.42%, 99.25%, and 99.99%, respectively, for the modified dataset. Various hyperparameters were also finetuned to obtain optimum results, which were also compared with state-of-the-art (SOTA) methods for malaria parasite detection, and the proposed method outperformed the existing methods.","2022-06","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","12","22","","","","","","","","","","English","","","","WOS:000818357200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;20<br/>Total Times Cited:&nbsp;&nbsp;20<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","CNN; deep learning; grad-cam visualization; image analysis; malaria parasite; transformer-based model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EAZ2D34R","journalArticle","2022","Dampier, W; Link, RW; Earl, JP; Collins, M; De Souza, DR; Koser, K; Nonnemacher, MR; Wigdahl, B","HIV- Bidirectional Encoder Representations From Transformers: A Set of Pretrained Transformers for Accelerating HIV Deep Learning Tasks","FRONTIERS IN VIROLOGY","","2673-818X","10.3389/fviro.2022.880618","","The human immunodeficiency virus type 1 (HIV-1) is a global health threat that is characterized by extensive genetic diversity both within and between patients, rapid mutation to evade immune controls and antiretroviral therapies, and latent cellular and tissue reservoirs that stymie cure efforts. Viral genomic sequencing has proven effective at surveilling these phenotypes. However, rapid, accurate, and explainable prediction techniques lag our sequencing ability. Modern natural language processing libraries, like the Hugging Face transformers library, have both advanced the technical field and brought much-needed standardization of prediction tasks. Herein, the application of this toolset to an array of classification tasks useful to HIV-1 biology was explored: protease inhibitor resistance, coreceptor utilization, and body-site identification. HIV-Bidirectional Encoder Representations from Transformers (BERT), a protein-based transformer model fine-tuned on HIV-1 genomic sequences, was able to achieve accuracies of 88%, 92%, and 89% on the respective tasks, making it competitive with leading models capable of only one of these tasks. This model was also evaluated using a data augmentation strategy when mutations of known function were introduced. The HIV-BERT model produced results that agreed in directionality 10- to 1000-fold better than traditional machine learning models, indicating an improved ability to generalize biological knowledge to unseen sequences. The HIV-BERT model, trained task-specific models, and the datasets used to construct them have been released to the Hugging Face repository to accelerate research in this field.","2022-05-18","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","2","","","","","","","","","","English","","","","WOS:001086845800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","BRAIN; compartmentalization; coreceptor tropism; deep learning; DIVERSITY; drug resistance; DRUG-RESISTANCE; ENVELOPE V3; EVOLUTION; genetic variation; HIV-1; INDIVIDUALS; MEMORY GENOMES; MUTATIONS; natural language processing; PHENOTYPE; PREDICTION; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RFG9JLZ8","journalArticle","2022","Lesniewska, E; Olak, J","Analysis of the Operation of Cascade Current Transformers for Measurements of Short-Circuit Currents with a Non-Periodic Component with a Large Time Constant of Its Decay","ENERGIES","","1996-1073","10.3390/en15082925","","Simulations of emergency states and tests of resistance of electrical devices to emergencies are performed in specialized high-power laboratories, the so-called short-circuit laboratories. For most electrical power devices, such measurements are required by international standards. The basic equipment of short-circuit testing laboratories consists of current transformers for measuring short-circuit currents. These transformers should not only enable the accurate conversion of sinusoidal currents-which is typical for conventional current transformers, but also asymmetrical short-circuit currents containing an aperiodic component, which classic current transformers cannot reproduce. Therefore, manufacturers and designers try to meet the market demands and design these special class 0.2 current transformers. To meet the high technical requirements, the field-circuit method with three-dimensional space-time analysis of electromagnetic fields was used during design, considering physical phenomena in ferromagnetic cores (i.e., hysteresis and eddy current losses) and the load of the secondary winding of the current transformer by the measurement system. The article presents simulations of secondary currents for the short-circuit current transformer model, and the results were confirmed by measurements and oscillograms of the currents flowing in the windings of the real model. The prototype of the designed short-circuit transformer meets the IEC/EN standard requirements. When measuring harmonic currents, the transformation errors meet the requirements of class 0.2. During the short-circuit current waveforms, the maximum instantaneous peak error does not exceed 1% of the error for all the subsequent maxima of the current waveform during the specified transient switching cycle. In comparison, the standard allows this error to be 10%.","2022-04","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","8","15","","","","","","","","","","English","","","","WOS:000785503100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","cascade current transformers; COMPENSATION; CORES; FIELD; finite element method; short-circuit current measurements; transient state","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8SDLDKYW","journalArticle","2021","Qing, YH; Liu, WY; Feng, LY; Gao, WJ","Improved Transformer Net for Hyperspectral Image Classification","REMOTE SENSING","","2072-4292","10.3390/rs13112216","","In recent years, deep learning has been successfully applied to hyperspectral image classification (HSI) problems, with several convolutional neural network (CNN) based models achieving an appealing classification performance. However, due to the multi-band nature and the data redundancy of the hyperspectral data, the CNN model underperforms in such a continuous data domain. Thus, in this article, we propose an end-to-end transformer model entitled SAT Net that is appropriate for HSI classification and relies on the self-attention mechanism. The proposed model uses the spectral attention mechanism and the self-attention mechanism to extract the spectral-spatial features of the HSI image, respectively. Initially, the original HSI data are remapped into multiple vectors containing a series of planar 2D patches after passing through the spectral attention module. On each vector, we perform linear transformation compression to obtain the sequence vector length. During this process, we add the position-coding vector and the learnable-embedding vector to manage capturing the continuous spectrum relationship in the HSI at a long distance. Then, we employ several multiple multi-head self-attention modules to extract the image features and complete the proposed network with a residual network structure to solve the gradient dispersion and over-fitting problems. Finally, we employ a multilayer perceptron for the HSI classification. We evaluate SAT Net on three publicly available hyperspectral datasets and challenge our classification performance against five current classification methods employing several metrics, i.e., overall and average classification accuracy and Kappa coefficient. Our trials demonstrate that SAT Net attains a competitive classification highlighting that a Self-Attention Transformer network and is appealing for HSI classification.","2021-06","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","11","13","","","","","","","","","","English","","","","WOS:000660609000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;122<br/>Total Times Cited:&nbsp;&nbsp;125<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","ATTENTION NETWORK; AUTOENCODER; CNN; deep learning; DOMAIN; hyperspectral image (HSI) classification; long-distance dependence; REPRESENTATION; RESIDUAL NETWORK; self-attention; SPECTRAL-SPATIAL CLASSIFICATION; SVM; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7JCDUALX","journalArticle","2025","Ding, SJY; He, KF; Wang, QN; Zhang, WF","Enhanced High-Frequency Spatial Feature Networks for Hyperspectral Images Classification","IEEE GEOSCIENCE AND REMOTE SENSING LETTERS","","1545-598X","10.1109/LGRS.2024.3519776","","The efficient extraction of spatial-spectral features is crucial for hyperspectral images (HSIs) classification, especially the spatial features are essential to improve the classification accuracy. Both the convolutional neural network (CNN) and transformers frameworks can effectively represent high-level global and local semantic features, which have significant potential for HSIs classification field. We proposed an enhanced high-frequency spatial feature (EH-FS2) method for HSIs classification. First, we connected two networks, CNN and transformer, as a shallow-deep feature extractor to rapidly extract multiscale spectral-spatial features by CAB attention module. This module not only realizes the efficient association of local and global features but also emphasizes the important spatial location information. Then, we added a local deep convolutional (L-D-ConvFFN) to the GLS(2)FFN module to effectively compensate for the loss of high-frequency spatial information by the self-attention mechanism as a low-pass filter and enhance the capability of perceiving high-frequency spatial details. The experiments were validated on the Salinas (SAs), Pavia University (PU), and WHU-Hi-LongKou datasets, and the classification performance outperforms several state-of-the-art approaches. The experiments have shown that the EH-FS2 method can better distinguish the features between different classes, especially for the enhancement and recovery of high-frequency spatial features with significant advantages. Furthermore, it can also be proved that the generalization of the HSI classification problem to the advanced semantic classification problem is validated.","2025","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","22","","","","","","","","","","English","","","","WOS:001385596300005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","Computational modeling; Convolution; Convolutional neural network (CNN); Convolutional neural networks; Data mining; Feature extraction; hyperspectral images (HSIs) classification; Hyperspectral imaging; Kernel; semantic features; Semantics; spatial-spectral features; Three-dimensional displays; transformer model; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5UZLJDB7","journalArticle","2025","Wang, ML; Chen, JQ; Liu, YQ","Optimized Deep Learning Model for Predicting Liver Metastasis in Colorectal Cancer Patients","SYMMETRY-BASEL","","2073-8994","10.3390/sym17010103","","Colorectal cancer is a leading type of cancer worldwide and a major contributor to cancer fatalities, and liver metastasis is the most likely distant metastasis in colorectal cancer patients. Classifying and predicting whether liver metastasis occurs in colorectal cancer patients can help doctors timely determine the progress of the disease and form a more reasonable treatment plan, which results in a better prognosis for patients. In this paper, using the Surveillance, Epidemiology, and End Results database, selecting both symmetric and asymmetric features, we extracted the disease-related data of 40,870 patients who were pathologically diagnosed with colorectal cancer from 2010 to 2015 and classified and modeled whether the patients developed liver metastasis to show the symmetry of this study. A total of six deep learning models were utilized, and hyperparameter optimization was performed on the models using the Crested Porcupine Optimizer. The best-performing model was selected and model interpretation was performed to explore the features that affect whether patients develop liver metastasis. Among the six deep learning models selected, the FT-Transformer model, which was hyperparameter optimized by the Crested Porcupine Optimizer, performed the best, with an accuracy of 0.945, with a 95% confidence interval (CI) of [0.942, 0.952], and an AUC of 0.949, with a 95% CI of [0.942, 0.957]. This study can help doctors make medical decisions, detect patients with liver metastases of colorectal cancer earlier, monitor the indicators that have a significant impact on the occurrence of liver metastasis in patients, and use timely surgical treatment, radiotherapy, chemotherapy, and other corresponding therapeutic interventions to improve the survival rate of patients.","2025-01","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","1","17","","","","","","","","","","English","","","","WOS:001405326800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","CLASSIFICATION; colorectal cancer; Crested Porcupine Optimizer; deep learning; FEATURE-SELECTION; FT-Transformer; liver metastasis; MACHINE; model interpretation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G9ZGRFCI","journalArticle","2025","Wu, F; Yao, HY; Zhao, ZD; Zhao, XB; Zang, YZ; Wang, HY","ESTMST-ST: An End-to-End Soft Threshold and Multiloss Self-Distillation Based Swin Transformer for Underwater Acoustic Signal Recognition","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2024.3520860","","Underwater acoustic signal recognition (UASR) is significant for marine life and ecological environment protection. However, 2-D fixed-parameter inputs are inadequate for adapting to the variable underwater acoustic environment, and learnable-parameter inputs with inductive bias priors in transformers lead to difficulties in model convergence. Additionally, the differing optimization objectives between noise reduction and recognition methods can cause signal distortion, hindering recognition accuracy. To address these issues, this article proposes an innovative end-to-end soft threshold Swin Transformer model based on a multiloss self-distillation training strategy (ESTMST-ST) for robust recognition of weak underwater acoustic targets. Building on the previously proposed time-frequency Swin Transformer (TFST), we design a learnable dual filter module (LDFM) that decomposes underwater acoustic signals in the frequency direction, with parameters obtained through model training. To improve the model's antinoise performance, we incorporate a soft threshold strategy within TFST to reduce nonstationary interference in underwater acoustic signals. For enhanced robustness and training efficiency, we introduce a self-distillation training strategy with four specific loss functions in selected stage in TFST. Using publicly available datasets, ShipsEar and DeepShip, we conduct three experiments: fixed signal-to-noise ratio (SNR) UASR, multi-SNR UASR, and model generalization ability tests. The experimental results demonstrate that ESTMST-ST achieves superior performance (at least a 1.6 improvement in ${F}1$ scores and a 2.2 improvement in kappa coefficients) compared to five state-of-the-art methods across two open-source datasets.","2025","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","63","","","","","","","","","","English","","","","WOS:001389581000019","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Band-pass filters; Feature extraction; Frequency modulation; Gabor filters; Learnable dual filter; Low-pass filters; Robustness; self-knowledge distillation (SKD); soft threshold; Swin Transformer; Time-frequency analysis; Training; Transformers; Underwater acoustics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4XKJ84BJ","journalArticle","2025","Qiu, XH; Shao, SY; Wang, HY; Tan, XY","Bio-K-Transformer: A pre-trained transformer-based sequence-to-sequence model for adverse drug reactions prediction","COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE","","0169-2607","10.1016/j.cmpb.2024.108524","","Background and Objective: Adverse drug reactions (ADRs) pose a serious threat to patient health, potentially resulting in severe consequences, including mortality. Accurate prediction of ADRs before drug market release is crucial for early prevention. Traditional ADR detection, relying on clinical trials and voluntary reporting, has inherent limitations. Clinical trials face challenges in capturing rare and long-term reactions due to scale and time constraints, while voluntary reporting tends to neglect mild and common reactions. Consequently, drugs on the market may carry unknown risks, leading to an increasing demand for more accurate predictions of ADRs before their commercial release. This study aims to develop a more accurate prediction model for ADRs prior to drug market release. Methods: We frame the ADR prediction task as a sequence-to-sequence problem and propose the Bio-KTransformer, which integrates the transformer model with pre-trained models ( i.e. , Bio_ClinicalBERT and K-bert), to forecast potential ADRs. We enhance the attention mechanism of the Transformer encoder structure and adjust embedding layers to model diverse relationships between drug adverse reactions. Additionally, we employ a masking technique to handle target data. Experimental findings demonstrate a notable improvement in predicting potential adverse reactions, achieving a predictive accuracy of 90.08%. It significantly exceeds current state-of-the-art baseline models and even the fine-tuned Llama-3.1-8B and Llama3-Aloe-8B-Alpha model, while being cost-effective. The results highlight the model's efficacy in identifying potential adverse reactions with high precision, sensitivity, and specificity. Conclusion: The Bio-K-Transformer significantly enhances the prediction of ADRs, offering a cost-effective method with strong potential for improving pre-market safety evaluations of pharmaceuticals.","2025-03","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","260","","","","","","","","","","English","","","","WOS:001385190600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","Adverse drug reactions; Diagonal-masked; Sequence-to-sequence model; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P352RFP3","journalArticle","2024","Imran, M; Akram, MU; Tiwana, MI; Salam, AA; Greco, D","Two-dimensional hybrid incremental learning (2DHIL) framework for semantic segmentation of skin tissues","IMAGE AND VISION COMPUTING","","0262-8856","10.1016/j.imavis.2024.105098","","This study aims to enhance the robustness and generalization capability of a deep learning transformer model used for segmenting skin carcinomas and tissues through the introduction of incremental learning. Deep learning AI models demonstrate their claimed performance only for tasks and data types for which they are specifically trained. Their performance is severely challenged for the test cases which are not similar to training data thus questioning their robustness and ability to generalize. Moreover, these models require an enormous amount of annotated data for training to achieve desired performance. The availability of large annotated data, particularly for medical applications, is itself a challenge. Despite efforts to alleviate this limitation through techniques like data augmentation, transfer learning, and few-shot training, the challenge persists. To address this, we propose refining the models incrementally as new classes are discovered and more data becomes available, emulating the human learning process. However, deep learning models face the challenge of catastrophic forgetting during incremental training. Therefore, we introduce a two-dimensional hybrid incremental learning framework for segmenting non-melanoma skin cancers and tissues from histopathology images. Our approach involves progressively adding new classes and introducing data of varying specifications to introduce adaptability in the models. We also employ a combination of loss functions to facilitate new learning and mitigate catastrophic forgetting. Our extended experiments demonstrate significant improvements, with an F1 score reaching 91.78, mIoU of 93.00, and an average accuracy of 95%. These findings highlight the effectiveness of our incremental learning strategy in enhancing the robustness and generalization of deep learning segmentation models while mitigating catastrophic forgetting.","2024-08","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","148","","","","","","","","","","English","","","","WOS:001250626300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","AI; Computational histopathology; Continual learning; Incremental learning; Incremental semantic segmentation; Knowledge distillation; Mutual distillation loss; Non-melanoma skin cancer; Segformer; Skin cancer; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CRTAAAP2","journalArticle","2024","Sun, YZ; Pang, SC; Zhang, YG","Fluid identification with Graph Transformer using well logging data","PHYSICS OF FLUIDS","","1070-6631","10.1063/5.0211182","","The prediction of fluid through well logging is a cornerstone in guiding exploratory efforts in the energy sector. Comprehending the fluid composition beneath the surface empowers exploration teams to effectively gauge the extent, reserves, and caliber of oil and gas resources. This leads to enhanced strategies in exploration and the judicious use of resources. We introduce an innovative machine learning framework named ""Graph Transformer"" for predicting fluid. This model melds graph convolutional layers with a Transformer module. It excels in decoding spatial and temporal patterns within well logging data, thus unraveling complex geological dependencies by factoring in the interconnectedness of various data points. Additionally, it features a Positional Encoding module to enhance understanding of sequential data points in terms of depth, thereby overcoming the limitations of sequence independence. The Transformer's Multi-Head Self-Attention mechanism is pivotal in discerning and integrating spatial and temporal interconnections across various depths, elevating its capability to represent geological structures. Initially, the model harnesses key well log data like Density, Acoustic, Gamma-ray, and Compensated Neutron Logs for extracting geological features. These insights are then processed through the Graph Transformer to establish relationship between fluid characteristics and logging parameters. Furthermore, we compare this model with other leading models using precision, recall, and accuracy metrics. Experimental findings affirm the model's high accuracy in predicting fluid within intricate geological settings. Its exceptional adaptability makes it apt for various geological conditions and logging tools. Thus, our Graph Transformer model stands out as a sophisticated, efficient machine learning solution in the realm of well logging fluid prediction, offering geologists and engineers precise tools for exploration and development.","2024-06","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","6","36","","","","","","","","","","English","","","","WOS:001239606400006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","LITHOLOGY; PREDICTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DDEJMLJS","journalArticle","2024","Han, XH; Yamawaki, K; Jiang, HY","Coupled image and kernel prior learning for high-generalized super-resolution","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2024.127500","","Deep convolution neural networks (DCNNs) have demonstrated great success on single image super resolution, where most existing methods aim to construct a deep model in an fully -supervised way using large amount of synthetic image pairs under ideal degradation assumption. The super -resolution performance would be significantly degraded for the low -resolution images captured under uncontrolled imaging conditions with complicated degradation procedures. To handle the above limitations, this work proposes a high -generalized image super -resolution framework by synergistically learning the latent image and the degradation process to achieve the specific priors for an under -studying observation in an unsupervised manner. Specifically, we incorporate dual branches of networks to configure our framework, where one is structured with both convolution and transformer blocks to learn local -to -global prior to generate high -quality image while the other aims to learn the kernel prior with a simple convolution -based architecture. The kernel prior subnet is pretrained to enhance the stability of the joint optimization for the overall unsupervised learning procedure. With the estimated degradation kernel and target image, we produce the approximated low -resolution version with a convolution -based degradation block to formulate the loss function for the specific learning. Moreover, to pursue visually plausible image generation, we further incorporate a perceptual loss by leveraging a pre -trained discriminator in Gan -based SR model. Extensive experiments on several benchmark datasets have demonstrated the effectiveness of our proposed high -generalized super -resolution model, manifesting superiority over both supervised and unsupervised state-of-the-art SR models.","2024-05-28","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","583","","","","","","","","","","English","","","","WOS:001216688200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","Deep image prior; High-generalization; Image super-resolution; Kernel prior learning; Local-to-global prior learning; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q3JJQ2D3","journalArticle","2024","Al-Thani, MG; Sheng, ZY; Cao, YT; Yang, Y","Traffic Transformer: Transformer-based framework for temporal traffic accident prediction","AIMS MATHEMATICS","","2473-6988","10.3934/math.2024617","","Reliable prediction of traffic accidents is crucial for the identification of potential hazards in advance, formulation of effective preventative measures, and reduction of accident incidence. Existing neural network -based models generally suffer from a limited field of perception and poor long-term dependency capturing abilities, which severely restrict their performance. To address the inherent shortcomings of current traffic prediction models, we propose the Traffic Transformer for multidimensional, multi -step traffic accident prediction. Initially, raw datasets chronicling sporadic traffic accidents are transformed into multivariate, regularly sampled sequences that are amenable to sequential modeling through a temporal discretization process. Subsequently, Traffic Transformer captures and learns the hidden relationships between any elements of the input sequence, constructing accurate prediction for multiple forthcoming intervals of traffic accidents. Our proposed Traffic Transformer employs the sophisticated multi -head attention mechanism in lieu of the widely used recurrent architecture. This significant shift enhances the model's ability to capture long-range dependencies within time series data. Moreover, it facilitates a more flexible and comprehensive learning of diverse hidden patterns within the sequences. It also offers the versatility of convenient extension and transference to other diverse time series forecasting tasks, demonstrating robust potential for further development in this field. Extensive comparative experiments conducted on a real -world dataset from Qatar demonstrate that our proposed Traffic Transformer model significantly outperforms existing mainstream time series forecasting models across all evaluation metrics and forecast horizons. Notably, its Mean Absolute Percentage Error reaches a minimal value of only 4.43%, which is substantially lower than the error rates observed in other models. This remarkable performance underscores the Traffic Transformer's state-of-the-art level of in predictive accuracy.","2024","2025-02-26 20:43:27","2025-02-26 20:43:27","","12610-12629","","5","9","","","","","","","","","","English","","","","WOS:001196673100003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","attention mechanism; deep learning; NETWORK; neural network; traffic accident prediction; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BATHEVZL","journalArticle","2024","Ou, ZL; Lu, XQ; Gu, Y","HCS-Net: Multi-level deformation strategy combined with quadruple attention for image registration","COMPUTERS IN BIOLOGY AND MEDICINE","","0010-4825","10.1016/j.compbiomed.2023.107832","","Background and objective: Non-rigid image registration plays a significant role in computer-aided diagnosis and surgical navigation for brain diseases. Registration methods that utilize convolutional neural networks (CNNs) have shown excellent accuracy when applied to brain magnetic resonance images (MRI). However, CNNs have limitations in understanding long-range spatial relationships in images, which makes it challenging to incorporate contextual information. And in intricate image registration tasks, it is difficult to achieve a satisfactory dense prediction field, resulting in poor registration performance.Methods: This paper proposes a multi-level deformable unsupervised registration model that combines Trans-former and CNN to achieve non-rigid registration of brain MRI. Firstly, utilizing a dual encoder structure to establish the dependency relationship between the global features of two images and to merge features of varying scales, as well as to preserve the relative spatial position information of feature maps at different scales. Then the proposed multi-level deformation strategy utilizes different deformable fields of varying resolutions generated by the decoding structure to progressively deform the moving image. Ultimately, the proposed quadruple attention module is incorporated into the decoding structure to merge feature information from various directions and emphasize the spatial features in the dominant channels.Results: The experimental results on multiple brain MR datasets demonstrate that the promising network could provide accurate registration and is comparable to state-of-the-art methods.Conclusion: The proposed registration model can generate superior deformable fields and achieve more precise registration effects, enhancing the auxiliary role of medical image registration in various fields and advancing the development of computer-aided diagnosis, surgical navigation, and related domains.","2024-01","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","168","","","","","","","","","","English","","","","WOS:001138979200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Encoder-decoder architecture; Feature fusion; Medical images; Non-rigid registration; SURGERY; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VAI838Z6","journalArticle","2023","Shi, DP; Zhao, JY; Wang, ZH; Zhao, H; Wang, JB; Lian, YB; Burke, AF","Spatial-Temporal Self-Attention Transformer Networks for Battery State of Charge Estimation","ELECTRONICS","","2079-9292","10.3390/electronics12122598","","Over the past ten years, breakthroughs in battery technology have dramatically propelled the evolution of electric vehicle (EV) technologies. For EV applications, accurately estimating the state-of-charge (SOC) is critical for ensuring safe operation and prolonging the lifespan of batteries, particularly under complex loading scenarios. Despite progress in this area, modeling and forecasting the evaluation of multiphysics and multiscale electrochemical systems under realistic conditions using first-principles and atomistic calculations remains challenging. This study proposes a solution by designing a specialized Transformer-based network architecture, called Bidirectional Encoder Representations from Transformers for Batteries (BERTtery), which only uses time-resolved battery data (i.e., current, voltage, and temperature) as an input to estimate SOC. To enhance the Transformer model's generalization, it was trained and tested under a wide range of working conditions, including diverse aging conditions (ranging from 100% to 80% of the nominal capacity) and varying temperature windows (from 35 & DEG;C to -5 & DEG;C). To ensure the model's effectiveness, a rigorous test of its performance was conducted at the pack level, which allows for the translation of cell-level predictions into real-life problems with hundreds of cells in-series conditions possible. The best models achieve a root mean square error (RMSE) of less than 0.5 test error and approximately 0.1% average percentage error (APE), with maximum absolute errors (MAE) of 2% on the test dataset, accurately estimating SOC under dynamic operating and aging conditions with widely varying operational profiles. These results demonstrate the power of the self-attention Transformer-based model to predict the behavior of complex multiphysics and multiscale battery systems.","2023-06","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","12","12","","","","","","","","","","English","","","","WOS:001017057300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;23<br/>Total Times Cited:&nbsp;&nbsp;24<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","deep learning; electric vehicle; estimation; LITHIUM-ION BATTERIES; lithium-ion battery; MODEL; OF-CHARGE; OPEN-CIRCUIT VOLTAGE; SCALE; SOC; SOC ESTIMATION; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K7IZQ2LL","journalArticle","2023","Sadhukhan, B; Chakraborty, S; Mukherjee, S; Samanta, RK","Climatic and seismic data-driven deep learning model for earthquake magnitude prediction","FRONTIERS IN EARTH SCIENCE","","2296-6463","10.3389/feart.2023.1082832","","The effects of global warming are felt not only in the Earth's climate but also in the geology of the planet. Modest variations in stress and pore-fluid pressure brought on by temperature variations, precipitation, air pressure, and snow coverage are hypothesized to influence seismicity on local and regional scales. Earthquakes can be anticipated by intelligently evaluating historical climatic datasets and earthquake catalogs that have been collected all over the world. This study attempts to predict the magnitude of the next probable earthquake by evaluating climate data along with eight mathematically calculated seismic parameters. Global temperature has been selected as the only climatic variable for this research, as it substantially affects the planet's ecosystem and civilization. Three popular deep neural network models, namely, long short-term memory (LSTM), bidirectional long short-term memory (Bi-LSTM), and transformer models, were used to predict the magnitude of the next earthquakes in three seismic regions: Japan, Indonesia, and the Hindu-Kush Karakoram Himalayan (HKKH) region. Several well-known metrics, such as the mean absolute error (MAE), mean squared error (MSE), log-cosh loss, and mean squared logarithmic error (MSLE), have been used to analyse these models. All models eventually settle on a small value for these cost functions, demonstrating the accuracy of these models in predicting earthquake magnitudes. These approaches produce significant and encouraging results when used to predict earthquake magnitude at diverse places, opening the way for the ultimate robust prediction mechanism that has not yet been created.","2023-02-20","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","11","","","","","","","","","","English","","","","WOS:000943996100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;109</p>","","","ALASKA; ANOMALIES; bidirectional long short-term memory (Bi-LSTM); climate change; COMPLETENESS; earthquake prediction; global temperature anomaly; JAPAN; LSTM-long short-term memory; MAJOR EARTHQUAKES; NEURAL-NETWORK; PRECIPITATION; PRECURSORS; SEA-LEVEL RISE; TIME; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R5FAV8NI","journalArticle","2025","Yu, CY; Liu, XG; Wang, YF; Liu, Y; Feng, WT; Deng, X; Tang, CW; Lv, JC","GPT-NAS: Neural Architecture Search Meets Generative Pre-Trained Transformer Model","BIG DATA MINING AND ANALYTICS","","2096-0654","10.26599/BDMA.2024.9020036","","The pursuit of optimal neural network architectures is foundational to the progression of Neural Architecture Search (NAS). However, the existing NAS methods suffer from the following problem using traditional search strategies, i.e., when facing a large and complex search space, it is difficult to mine more effective architectures within a reasonable time, resulting in inferior search results. This research introduces the Generative Pre-trained Transformer NAS (GPT-NAS), an innovative approach designed to overcome the limitations which are inherent in traditional NAS strategies. This approach improves search efficiency and obtains better architectures by integrating GPT model into the search process. Specifically, we design a reconstruction strategy that utilizes the trained GPT to reorganize the architectures obtained from the search. In addition, to equip the GPT model with the design capabilities of neural architecture, we propose the use of the GPT model for training on a neural architecture dataset. For each architecture, the structural information of its previous layers is utilized to predict the next layer of structure, iteratively traversing the entire architecture. In this way, the GPT model can efficiently learn the key features required for neural architectures. Extensive experimental validation shows that our GPT-NAS approach beats both manually constructed neural architectures and automatically generated architectures by NAS. In addition, we validate the superiority of introducing the GPT model in several ways, and find that the accuracy of the neural architecture on the image dataset obtained from the search after introducing the GPT model is improved by up to about 9%.","2025-02","2025-02-26 20:43:27","2025-02-26 20:43:27","","45-64","","1","8","","","","","","","","","","English","","","","WOS:001382536500008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Computer architecture; Data models; Encoding; evolutionary algorithm; Generative Pre-trained Transformer (GPT) model; image classification; Neural Architecture Search (NAS); Neural networks; Optimization; Search problems; Training","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7NGVHKRW","journalArticle","2024","Tan, ML; Si, X; Teng, SC; Wu, XM; Tao, X","Comparative Analysis of TPA-LSTM and Transformer Models for Forecasting GEO Radiation Belt Electron Fluxes","SPACE WEATHER-THE INTERNATIONAL JOURNAL OF RESEARCH AND APPLICATIONS","","1542-7390","10.1029/2024SW004119","","The geosynchronous orbit (GEO) is a region filled with energetic electrons and it hosts hundreds of satellites. Electron fluxes at GEO can change sharply within hours, making high-time-resolution prediction crucial. In this study, we develop and compare two neural networks for persistent high-time-resolution prediction: long short-term memory with temporal pattern attention (TPA-LSTM) and Transformer. Unlike most previous models, which only output electron fluxes, our models output the same parameters as the inputs, including magnetic local time, solar wind speed, solar wind dynamic pressure, AE, Kp, Dst, the north-south component of the interplanetary magnetic field, and electron flux data from GOES-15. The models are trained on approximately six years of data (2012-2016) and validated using about one year of data (2017-2018). We compare the TPA-LSTM and Transformer models using > ${ >} $0.8 MeV electron fluxes and find that while the Transformer model performs slightly better, the difference is not statistically significant. Considering the Transformer's higher computational cost, we use the TPA-LSTM model to develop prediction models for electron fluxes of 275, 475, > ${ >} $0.8 MeV, and > ${ >} $2 MeV with a 5-min resolution at GEO, up to 3 days. The prediction efficiencies (PE) for 275, 475, > ${ >} $0.8 and > ${ >} $2 MeV electron fluxes based on about one year of test data (2018-2019) are 0.799, 0.831, 0.849, 0.881 (1-day prediction); and 0.551, 0.618, 0.663 and 0.710 (3-day prediction), respectively. Our high-time-resolution persistent models should be useful for both protecting satellites at GEO and serving as boundary conditions for physics-based radiation belt models.","2024-11","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","11","22","","","","","","","","","","English","","","","WOS:001369541900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","ACCELERATION; CHORUS WAVE; GEOSYNCHRONOUS ORBIT; INJECTION; LOSSES; QUANTITATIVE PREDICTION; RELATIVISTIC ELECTRONS; SIMULATION; SOLAR-CYCLE; STORM RECOVERY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q44J75FQ","journalArticle","2025","Malik, MGA; Saeed, A; Shehzad, K; Iqbal, M","DEF-SwinE2NET: Dual enhanced features guided with multi-model fusion for brain tumor classification using preprocessing optimization","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2024.107079","","Brain tumors exhibit significant variability in shape, size, and location, making it difficult to achieve consistent and accurate classification. It requires advanced algorithms for handling diverse tumor presentations. To solve this issue, we propose a Dual-Enhanced Features Scheme (DEFS) with a Swin-Transformer model based on the EfficientNetV2S to improve the classification and reuse parameters. In DEFS, the dense-block with dilation enables to uncovering of hidden details and spatial relationships across varying scales in the model which are typically obscured by traditional convolutional-layers. This module is particularly crucial in medical imaging, where tumors and anomalies can present in various sizes and shapes. Further, the dual-attention mechanism in the enhanced Featured scheme enhances the explainability and interpretability of the model by using spatial and channel-wise information. Additionally, the Swin-Transformer-block improves the model's capabilities to capture global patterns in brain-tumor images, which is highly advantageous in medical-imaging where the location and extent of abnormalities, such as tumors, can vary significantly. To strengthen the proposed DEF-SwinE2NET, we used EfficientNetV2S as a baseline-model due to its effectiveness and accurate classification compared to its predecessors. We evaluated DEFSwinE2NET using three benchmark datasets: two were sourced from Kaggle and one from a Figshare repositories. Several preprocessing-steps were applied to enhance the MRI-images before training including image cropping, median-filter noise-reduction, contrast-limited adaptive histogram equalization (CLAHE) for local-contrast enhancement, Laplacian-edge enhancement to highlight critical features, and data augmentation to improve model robustness and generalization. The DEF-SwinE2NET model achieves remarkable results with an accuracy of 99.43 %, a sensitivity of 99.39 %, and an F1-score of 99.41 %.","2025-02","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","100","","","","","","","","","","English","","","","WOS:001347028800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Attention mechanism; Deep learning; EficientNetV2; IMAGES; MODEL; MRI imaging; Swin Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CVKP2QWP","journalArticle","2025","Lu, YZ; Wang, H; Niu, JY; Lu, ZG; Liu, C; Feng, NS","Jump motion intention recognition and brain activity analysis based on EEG signals and Vision Transformer model","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2024.107001","","The lower limb exoskeleton can help the human jump movement and expand jump ability. However, recognizing jump motion intention promptly and accurately is a challenge. The electroencephalography (EEG) signal has the potential to recognize jump motion early due to accompanying motor intention generation. This paper proposes a method based on Vision Transformer to extract spatial-spectral-temporal information from multi-channel EEG signals to recognize jump motion intentions including pre-jump, off-ground, and post-jump. Artifacts of EEG signals are removed by filtering and independent component analysis. The movement-related cortical potential, time-frequency, source localization, and functional connectivity analyses are performed to analyze the changes in brain activity during jump, which can explore motion control mechanism of the brain and provide physiological basis for the construction of the recognition method. The EEG features in time domain and frequency domain are reduced dimensionally by channel, feature, and frequency band selections. The proposed model based on multi-head self-attention architecture extracts spatial information from sequence composed of multi-channel temporal and spectral fusion features. The recognition performance of the proposed model outperforms those of comparison models, and the average recognition accuracy and kappa coefficient are 88.797% and 0.8325, respectively. The classification performance of temporal and spectral fusion features is higher than that of temporal features, especially spectral features. The brain networks constructed by attention coefficients focus on the connectivity differences among tasks and cannot reflect the physiological significance of EEG signals. Finally, the proposed method is validated on the open access BCI competition IV Dataset 2a of EEG signals.","2025-02","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","100","","","","","","","","","","English","","","","WOS:001335035400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Brain-computer interface; CORTICAL POTENTIALS; Electroencephalography; INITIATION; Motor execution; Self-attention architecture; Sensorimotor rhythm; Source localization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GKY4MN2S","journalArticle","2024","Huang, Y; Fu, G; Ren, WC; Tu, XG; Feng, ZL; Liu, BK; Liu, JH; Zhou, C; Liu, Y; Zhang, XQ","Low-light images enhancement via a dense transformer network","DIGITAL SIGNAL PROCESSING","","1051-2004","10.1016/j.dsp.2024.104467","","This paper proposes a dense network composed of an improved Transformer network, which successfully restores low -light images to high -quality normal -light images, alleviating issues such as low brightness, high noise, and missing critical information in low -light images. The entire network architecture is based on the improved Transformer network and builds a dense network with a combination of long and short connections. While retaining the self -attention mechanism of the Transformer network, it achieves multi -level fusion and utilization of shallow and deep features, providing the network with rich image features and enabling the restoration of lowlight images to high -quality normal -light images. Additionally, a spatial -domain and frequency -domain combined loss function is designed, considering both pixel -level and frequency domain losses, effectively constraining the image restoration process and avoiding spectral biases. Lastly, a multi -scale hybrid gate feedforward network is designed to replace the traditional feedforward network in the Transformer, facilitating feature selection and forward propagation. These designs effectively enhance the richness of meaningful image features, alleviate spectral biases, and improve the visual quality of low -light images. Experimental results demonstrate the superiority of our method over state-of-the-art networks on various typical image enhancement datasets. Taking the most commonly used low -light dataset LOLv1 as an example, our method achieves improvements of 1.3% and 3.07% in PSNR and SSIM, respectively, compared to the best -performing network, showing favorable qualitative and quantitative evaluation results. The proposed method effectively addresses the issue of insufficiently realistic results in low -light image restoration, providing a reliable reference for practical applications.","2024-05","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","148","","","","","","","","","","English","","","","WOS:001218145400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","Dense network; Frequency domain loss; Low-light enhancement; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N7BWVD63","journalArticle","2024","Zhu, TY; Ding, DR; Wang, F; Liang, W; Wang, B","A novel full-convolution UNet-transformer for medical image segmentation","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2023.105772","","The Transformer-based methods are still unable to effectively model local contexts although they make up for the deficiency of remote information dependencies for approaches based on small kernel CNNs. To overcome such a shortage, this paper proposes a novel full-convolution UNet Transformer model, FC-UNETTR, for medical image segmentation. First, a novel global-local attention module is proposed by utilizing multiple small kernels of different sizes for depth-wise convolutions to expand the receptive field of the network model, increase the remote dependence of semantic information in the encoder stage, and also improve the feature extraction capability of the network for fuzzy edges. Then, a reparametrized feedforward network is developed to further improve the local information extraction and mitigate the coupling between feature maps such that the relationship between feature map channels can be better revealed. Furthermore, the skip connection and decoder are redesigned by constructing a dense multiscale module instead of traditional ResNet modules to mitigate semantic bias. Benefiting from the above improvements, the constructed FC-UNETTR without pre-training demonstrates a strong capability to extract local features and capture long-range dependencies of images in medical image segmentation. Experiments show that FC-UNETTR achieves an excellent performance of 85.67% for DSC and 7.82 for HD metrics on the Synapse dataset with fewer model parameters compared with state-of-the-art networks. Furthermore, DSC reaches 92.46% and 94.76% on the ACDC dataset and the private dataset of oral graft bone, respectively, outperforming some of the latest medical image segmentation models..","2024-03","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","89","","","","","","","","","","English","","","","WOS:001135726500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Depth-wise convolutions; Global-local attention modules; Image segmentation; Medical images; Reparametrized feedforward networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6Q582YGV","journalArticle","2024","Xu, CC; Chen, G","Interpretable transformer-based model for probabilistic short-term forecasting of residential net load","INTERNATIONAL JOURNAL OF ELECTRICAL POWER & ENERGY SYSTEMS","","0142-0615","10.1016/j.ijepes.2023.109515","","Short-term residential load forecasting is of great significance for the demand-side energy management of the grid and the home energy management of resident customers. The massive penetration of distributed renewable energy, especially small-scale solar photovoltaic (PV), in the residential sector urgently requires us to move from traditional load forecasting to net load forecasting. In recent years, deep learning techniques that can improve model forecasting performance have developed rapidly in the field of residential load forecasting. However, the opaque nature of deep learning makes its practical application very difficult. This paper proposes a Transformer-based probabilistic residential net load forecasting method that utilizes quantile regression to quantify uncertainty in future load demand. Meanwhile, to improve the interpretability of deep learning model, local variable selection network is developed to automatically select relevant features and provide feature -level explanations. Additionally, interpretable sparse self-attention mechanism is proposed to extract long-term temporal dependencies. Numerical experiments are carried out with data from real household smart meters. The results show that the proposed model outperforms other state-of-the-art forecasting models. In terms of point forecasting, compared with the most common deep time series forecasting model LSTM, the proposed model decreases by 21.3%, 27.3% and 20.9% On three point forecasting performance metrics. Compared with Vanilla Transformer, the proposed InterFormer decreases by 9.9%, 10.5% and 9.0% On three point forecasting performance metrics. In terms of probabilistic forecasting, compared with LSTM and Vanilla Transformer, the average pinball loss of the proposed model decreases by 26.2% and 17.0%, respectively. Additionally, and most importantly, our model provides users with explanations in terms of feature importance and temporal patterns.","2024-01","2025-02-26 20:43:27","2025-02-26 20:43:27","","","","","155","","","","","","","","","","English","","","","WOS:001097168900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Attention mechanism; Interpretable deep learning; Probabilistic short-term forecasting; Residential net load forecasting; SEQUENCE; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IQM7X47T","journalArticle","2023","Yuan, YH; Xia, GZ; Zhang, XM; Zhou, C","Synthesis-Style Auto-Correlation-Based Transformer: A Learner on Ionospheric TEC Series Forecasting","SPACE WEATHER-THE INTERNATIONAL JOURNAL OF RESEARCH AND APPLICATIONS","","1542-7390","10.1029/2023SW003472","","Accurate 1-day global total electron content (TEC) forecasting is essential for ionospheric monitoring and satellite communications. However, it faces challenges due to limited data and difficulty in modeling long-term dependencies. This study develops a highly accurate model for 1-day global TEC forecasting. We utilized generative TEC data augmentation based on the International Global Navigation Satellite Service (IGS) data set from 1998 to 2017 to enhance the model's prediction ability. Our model takes the TEC sequence of the previous 2 days as input and predicts the global TEC value for each hourly step of the next day. We compared the performance of our model with 1-day predicted ionospheric products provided by both the Center for Orbit Determination in Europe (C1PG) and Beihang University (B1PG). We proposed a two-step framework: (a) a time series generative model to produce realistic synthetic TEC data for training, and (b) an auto-correlation-based transformer model designed to capture long-range dependencies in the TEC sequence. Experiments demonstrate that our model significantly improves 1-day forecast accuracy over prior approaches. On the 2018 benchmark data set, the global root mean squared error (RMSE) of our model is reduced to 1.17 TEC units (TECU), while the RMSE of the C1PG model is 2.07 TECU. Reliability is higher in middle and high latitudes but lower in low latitudes (RMSE < 2.5 TECU), indicating room for improvement. This study highlights the potential of using data augmentation and auto-correlation-based transformer models trained on synthetic data to achieve high-quality 1-day global TEC forecasting.","2023-10","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","10","21","","","","","","","","","","English","","","","WOS:001093979000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","auto-correlation-based transformer; data augmentation; ionospheric total electron content; prediction; variational autoencoder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L5Y6NLJS","journalArticle","2023","Zhong, H; Zuo, YH; Wang, RZ; Zhang, L; Ouyang, XS","Accurate Electromagnetic Force Analysis of Offshore Wind Power Transformer Windings Based on Fractional Order Lumped Parameter Model","SYMMETRY-BASEL","","2073-8994","10.3390/sym15091768","","Accurate calculation of the electromagnetic force distribution of transformer windings under different loads and fault conditions is of great significance for transformer maintenance, condition evaluation and life prediction. Due to the influence of offshore wind power systems, offshore wind power transformers have high harmonic content and large changes in load rates, which can easily cause the coil destabilization, winding deformation or even damage because of the uneven distribution of the electromagnetic force. To improve the accuracy of electromagnetic force calculation, this paper proposes a fractional order numerical method. First, a three-dimensional axisymmetric transformer model and a symmetrical lumped parameter equivalent circuit model are established, respectively, based on field-circuit coupling. Second, the fractional order approximation of circuit components is realized by using the improved Oustaloup filter. In the fractional order model, the transformer is replaced by the lumped parameter equivalent circuit model. Third, as in the calculation process for integer order electromagnetic force, the integer order current has a large error, and the current waveform does not match the actual power frequency. The fractional order current and electromagnetic force at the 0.9 order are closer to the rated value. Finally, the effects of different load rates, three-phase short circuits and harmonic conditions are studied with the fractional order model. Compared with the traditional integer order finite element electromagnetic model, the fractional order equivalent circuit model established in this paper is more accurate and suitable for electromagnetic force calculation. The proposed method is significant for the structural design and state detection of transformers and also could be applied in the analysis of other dry-type transformers.","2023-09","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","9","15","","","","","","","","","","English","","","","WOS:001077919500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","electromagnetic force; finite element method; fractional order; offshore wind power transformer; parameter circuit","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FQZP4K5I","journalArticle","2023","Demirezen, MU; Yilmaz, O; Ince, E","New models developed for detection of misconceptions in physics with artificial intelligence","NEURAL COMPUTING & APPLICATIONS","","0941-0643","10.1007/s00521-023-08414-2","","Students' misconceptions of various topics in physics have been investigated by many researchers. The detection of misconceptions is very difficult and takes a long time as a human being. Our aim in the study carried out is to determine the misconceptions of the students regarding the concept of the atom by machine instead of humans. This study proposes two novel methods: the Transformers model and the fastText algorithm, to classify the students' answers. Since there is currently no Turkish language model for physics-related questions or the physics domain, we trained a transformer model from scratch for this domain using transfer learning and domain adaptation techniques. In the second part of this research, we proposed an unsupervised learning approach to accurately understand and identify the reasons behind the misconceptions. For this purpose, we utilized sentence transformers to obtain vector representation of the sentences with transformer-based denoising autoencoder training. We then used two clustering algorithms: an agglomerative one and a density-based one, to group similar sentences in a high-dimensional vector space. Again, for the first time, the unsupervised transformer-based denoising autoencoder training of the sentence transformers was employed for the Turkish language to provide domain adaptation for sentence transformers. Finally, we compared the human performance (experts' opinions) and the proposed method results for both the classification and the clustering tasks according to the kappa metric. According to our results, we managed to distinguish misconceptions with a high accuracy of between 0.97 and 1.00 with our proposed methodology.","2023-04","2025-02-26 20:43:28","2025-02-26 20:43:28","","9225-9251","","12","35","","","","","","","","","","English","","","","WOS:000951853900004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;82</p>","","","Artificial intelligence; ATOMS; CHEMISTRY; CONCEPTIONS; Deep learning; ESSAYS; FEEDBACK; GUIDANCE; KAPPA; LEARN; Natural language processing; ONLINE; Physics misconceptions; Transformer; TSDAE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZFFLBES7","journalArticle","2022","Li, TY; Wang, C; Wu, F; Zhang, H; Tian, SR; Fu, QY; Xu, L","Built-Up Area Extraction from GF-3 SAR Data Based on a Dual-Attention Transformer Model","REMOTE SENSING","","2072-4292","10.3390/rs14174182","","Built-up area (BA) extraction using synthetic aperture radar (SAR) data has emerged as a potential method in urban research. Currently, typical deep-learning-based BA extractors show high false-alarm rates in the layover areas and subsurface bedrock, which ignore the surrounding information and cannot be directly applied to large-scale BA mapping. To solve the above problems, a novel transformer-based BA extraction framework for SAR images is proposed. Inspired by SegFormer, we designed a BA extractor with multi-level dual-attention transformer encoders. First, the hybrid dilated convolution (HDC) patch-embedding module keeps the surrounding information of the input patches. Second, the channel self-attention module is designed for dual-attention transformer encoders and global modeling. The multi-level structure is employed to produce the coarse-to-fine semantic feature map of BAs. About 1100 scenes of Gaofen-3 (GF-3) data and 200 scenes of Sentinel-1 data were used in the experiment. Compared to UNet, PSPNet, and SegFormer, our model achieved an 85.35% mean intersection over union (mIoU) and 94.75% mean average precision (mAP) on the test set. The proposed framework achieved the best results in both mountainous and plain terrains. The experiments using Sentinel-1 shows that the proposed method has a good generalization ability with different SAR data sources. Finally, the BA map of China for 2020 was obtained with an overall accuracy of about 86%, which shows high consistency with the global urban footprint. The above experiments proved the effectiveness and robustness of the proposed framework in large-scale BA mapping.","2022-09","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","17","14","","","","","","","","","","English","","","","WOS:000851925800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","built-up areas; DECOMPOSITION; deep learning; gaofen-3 data; SAR; TANDEM-X; transformer; URBAN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NT76KLEW","journalArticle","2022","Cao, BQ; Zhong, WS; Xie, X; Zhang, LL; Qing, YY","A Multi-modal Feature Fusion-based Approach for Mobile Application Classification and Recommendation","JOURNAL OF INTERNET TECHNOLOGY","","1607-9264","10.53106/160792642022112306023","","With the rapid growth of the number and type of mobile applications, it becomes challenging to accurately classify and recommend mobile applications according to users' individual requirements. The existing mobile application classification and recommendation methods, for one thing, do not take into account the correlation between large-scale data and model. For another, they also do not fully exploit the multi-modal, fine-grained interaction features with high-order and low -order in mobile application. To tackle this problem, we propose a mobile application classification and recommendation method based on multi-modal feature fusion. The method firstly extracts the image and description features of the mobile application using an ""involution residual network + pre-trained language representation"" model (i.e. the TRedBert model). Afterwards, these features are fused by using the attention mechanism in the transformer model. Then, the method classifies the mobile applications based on the fused features through a softmax classifier. Finally, the method extracts the high-order and low-order embedding features of the mobile app with a bi-linear feature interaction model (FiBiNET) based on the classification results of the mobile app, by combining the Hadamard product and inner product to achieve fine-grained high-order and low-order feature interaction, to update the mobile app representation and complete the recommendation task. The multiple sets of comparison experiments are performed on Kaggle's real dataset, i.e., 365K IOS Apps Dataset. And the experimental results demonstrated that the proposed approach outperforms other methods in terms of Macro F1, Accuracy, AUC and Logloss.","2022","2025-02-26 20:43:28","2025-02-26 20:43:28","","1417-1427","","6","23","","","","","","","","","","English","","","","WOS:000891321800024","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Attention mechanism; Bi-linear feature interaction; Mobile applications; Multi-modal feature fusion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4E5SUSYB","journalArticle","2025","Madni, HA; Umer, RM; Zottin, S; Marr, C; Foresti, GL","FL-W3S: Cross-domain federated learning for weakly supervised semantic segmentation of white blood cells","INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS","","1386-5056","10.1016/j.ijmedinf.2025.105806","","Background: Segmentation models for clinical data experience severe performance degradation when trained on a single client from one domain and distributed to other clients from different domain. Federated Learning (FL) provides a solution by enabling multi-party collaborative learning without compromising the confidentiality of clients' private data. Methods: In this paper, we propose a cross-domain FL method for Weakly Supervised Semantic Segmentation (FL-W3S) of white blood cells in microscopic images. We perform model training on multiple clients with different data distributions to obtain a global aggregated model using only image-level class labels for semantic segmentation of white blood cells. A multi-class token transformer model learns the relationship between patch tokens and class tokens during collaborative learning and generates class-specific localization maps for mask predictions. To rectify the localization maps, we use patch-level pairwise affinity obtained from patch-to-patch transformer attention. Results: We evaluate performance of the proposed semantic segmentation method on two different datasets of white blood cells from different domains. Our experimental results show that for two datasets, there is 2.56% and 1.39% increase in performance of the proposed method over existing state-of-the-art methods. Conclusion: The combination of federated learning for collaborative model training while preserving data privacy, alongside white blood cell segmentation techniques for precise cell identification, enhances diagnostic accuracy and personalized treatment strategies in clinical applications, particularly in hematology and pathology. More specifically, it involves isolating white blood cell from blood smear for further analysis such as automated blood cell counting, morphological analysis, cell classification, disease diagnosis and monitoring.","2025-03","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","195","","","","","","","","","","English","","","","WOS:001409621800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Federated learning; Transformer attention; Weakly supervised semantic segmentation; White blood cell","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TYMM46F2","journalArticle","2024","Wang, SY; Jia, Z; Li, Y; Yang, QQ","Research on fault diagnosis for three-phase rectifier device in direct current transmission system based on continuous wavelet transform and vision transformer","MEASUREMENT SCIENCE AND TECHNOLOGY","","0957-0233","10.1088/1361-6501/ad7e3f","","As a core component of photovoltaic power generation systems, the three-phase rectifier device plays a crucial role, and its failure can potentially reduce energy conversion efficiency and output quality. Presently, the performance of fault time-domain signal diagnosis methods based on three-phase rectifier circuits is challenging to enhance. This paper proposes a novel fault detection method for three-phase rectifier devices based on Vision Transformer, referred to as CWT-ViT, to address this issue. This method transforms time-domain fault signals into images through Continuous Wavelet Transform (CWT), subsequently inputting these images into a Vision Transformer model. Relying on its powerful self-attention mechanism and fully connected layers, it realizes the extraction and learning of rectifier device image features. A Simulink simulation model of a three-phase bridge controllable rectifier circuit is established for fault injection to collect fault signals. Fault diagnosis experiments demonstrate that the proposed diagnostic method achieves a prediction accuracy of 98.6%, maintaining a relatively high precision level. In comparison to four excellent classification models currently available: AlexNet, RepVGG, ResNet, and GoogLeNet, the proposed method demonstrates superior diagnostic performance. Additionally, this paper conducts ablation experiments to meticulously analyze the impact of each module in the fault diagnosis process. This research achieves more precise and efficient fault diagnosis in photovoltaic power generation systems, thereby reducing downtime and maintenance costs for actual equipment and enhancing the stability of photovoltaic power generation systems. This research provides an innovative, intelligent solution for the intelligent operations and maintenance of photovoltaic power generation.","2024-12-01","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","12","35","","","","","","","","","","English","","","","WOS:001326858700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","attention mechanism; CLASSIFICATION; continuous wavelet transform; fault diagnosis; three-phase rectifier device; transform","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8BFEE23W","journalArticle","2024","Xing, ZQ; Pan, YQ; Yang, YT; Yuan, XL; Liang, YM; Huang, ZZ","Transfer learning integrating similarity analysis for short-term and long-term building energy consumption prediction","APPLIED ENERGY","","0306-2619","10.1016/j.apenergy.2024.123276","","Currently, building energy consumption prediction models are usually based on a large amount of historical operational data in high demands of building operating hours and monitoring systems. However, many buildings may lack operational data due to relatively limited monitoring systems, causing the failure to use data-driven methods to characterize the energy profile. In this context, transfer learning is a promising method to establish the knowledge transfer between many high-quality building operation datasets and a small amount of target building data, and to help predict energy consumption in the target building. This paper studies the possibility of employing transfer learning to achieve both short and long-term building energy consumption prediction. Firstly, a similarity analysis method, based on variable modal decomposition and dynamic time warping, is proposed for identifying the source buildings with the most similar energy features to the target building. Then, transfer learning for long-term prediction air-conditioning energy consumption is developed with weather parameters generated by the Morphing method as inputs. For the short-term single-step prediction, the proposed model CVRMSE improves 81.3% (AEC) and 77.4% (EEC), respectively, compared to the prediction model that does not implement the transfer learning strategy and directly uses the target BEC data. As for the short-term multi-step prediction, the proposed model CV-RMSE improves 62.0% (AEC) and 65.5% (EEC), respectively. For the longterm prediction, the average CV-RMSE for the whole year is 6.62% and 11.15% for the proposed and directly target domain-based model, respectively. The proposed method explores the practicality of transfer learning in building energy forecasting, contributing to the use of existing building operation data for energy management at different timespan.","2024-07-01","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","365","","","","","","","","","","English","","","","WOS:001234777400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","Building energy consumption predictions; Deep learning; Similarity analysis; Transfer learning; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GC5ADYGF","journalArticle","2024","Li, C; Xiao, KY; Sun, L; Tang, R; Dong, XC; Qiao, BC; Xu, DH","CNN-Transformers for mineral prospectivity mapping in the Maodeng-Baiyinchagan area, Southern Great Xing'an Range","ORE GEOLOGY REVIEWS","","0169-1368","10.1016/j.oregeorev.2024.106007","","There have been recent breakthroughs in exploration for Sn and Ag mineral resources in the Southern Great Xing'an Range, making this region a world-class Sn and Ag metallogenic area. However, the thick surface cover and concealed deposits have made exploration challenging, severely limiting the effectiveness of traditional exploration methods. The utilization of deep learning techniques in conjunction with multi-source geoscience datasets for comprehensive metallogenic prognosis has emerged as a novel means of geological prospecting. In this study, a comprehensive geological data collection for the Maodeng-Baiyinchagan area was systematically conducted to form a multi-disciplinary geoscience information database. The convolutional neural network (CNN) method was applied for extracting and predicting ore-forming anomalous information. Addressing the issue that CNNs in practical applications focus predominantly on computing short-distance local dependencies and struggle with long-distance dependencies, thereby neglecting the interrelationships of different parts globally and reducing the capability to capture global features, we innovatively integrated the Transformer method. This method effectively captures global feature representations, ensuring that both local and global key information are captured for ore-forming prediction and delineating prospective exploration areas. The results show that the CNN-Transformer model, capturing both local and global features, outperforms the CNN model with an accuracy of 0.92. The mineral prospectivity mapping by the model effectively correlate multi-disciplinary geoscientific data with known locations of deposits, significantly enhancing the precision of potential exploration areas for mineral deposits.","2024-04","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","167","","","","","","","","","","English","","","","WOS:001224062800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;97</p>","","","CLASSIFICATION; CNN -Transformer; COMPOSITIONAL DATA-ANALYSIS; CONSTRAINTS; CONVOLUTIONAL NEURAL-NETWORKS; GEOCHEMISTRY; Maodeng -Baiyinchagan area; Metallogenic factor; METALLOGENY; Mineral prospectivity mapping; NE CHINA; POLYMETALLIC DEPOSIT; PREDICTION; VOLCANIC-ROCKS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I79W3SQP","journalArticle","2024","Liu, Z; Wang, H; Zhang, C; Zhang, S","A Text Summarization Approach to Enhance Global and Local Information Awareness of Transformer","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3449280","","In the field of abstract text summarization, architectures based on encoder-decoder frameworks are widely applied to sequence-to-sequence generation tasks and can effectively handle sequences of unlimited length. Subsequently, the transformer model use a global attention mechanism, allowing encodings at different distances to mutually interact, greatly enhancing the model's contextual awareness. However, this context-awareness is global, requiring the model to additionally learn to extract different levels of information to increase understanding. We improve the structure of the model to introduce prior knowledge so that it can learn from the global and local information and enhance the model's understanding ability. This paper proposes global information-aware encoding and local information-aware encoding, which enhance the understanding of documents from coarse-grained and fine-grained perspectives respectively. Global encoding adds an extra feature to the encoder stage and performs attention with the document, generating a global summary encoding of the entire document to guide the generation of the summary content. Local encoding is to perform local convolution on the features extracted by the encoder, use prior knowledge to extract local features of the document and enable the model to quickly extract local detail information. Experiments show that the improved model proposed in this paper has higher rouge scores than the baseline model on the LCSTS and CSL datasets, and also has advantages over some mainstream models. The generated summaries are more accurate and informative. The code is available on github. url: https://github.com/keptupp/A-text-summarization-approach-to-enhance-global-and-local-information-awareness-of-transformer.","2024","2025-02-26 20:43:28","2025-02-26 20:43:28","","118744-118755","","","12","","","","","","","","","","English","","","","WOS:001303405000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","cnn; Data mining; Data models; Decoding; Encoding; Feature extraction; Long short term memory; lstm; Text summarization; Text-summarization; transformer; Transformers; vit","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z4WLFQ3V","journalArticle","2023","Vuyyuru, VA; Krishna, GV; Mary, SSC; Kayalvili, S; Alsubayhay, AMS","A Transformer-CNN Hybrid Model for Cognitive Behavioral Therapy in Psychological Assessment and Intervention for Enhanced Diagnostic Accuracy and Treatment Efficiency","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","The use of Cognitive Behavioral Therapy (CBT) as a method for psychological assessment and intervention has shown to be quite successful. However, by utilizing advancements in artificial intelligence and natural language processing techniques, the diagnostic precision and therapeutic efficacy of CBT can be significantly improved. For CBT in psychological evaluation and intervention, we suggest a unique Transformer CNN hybrid model in this work. The hybrid model combines the strengths of the Transformer and Convolutional Neural Network (CNN) architectures. While the CNN model successfully extracts local and global features from the input sequences, the Transformer model accurately captures the contextual dependencies and semantic linkages in the text data. It intends to enhance the model's comprehension and interpretation of the complex linguistic patterns involved in psychological evaluation and intervention by merging these two algorithms. On a sizable collection of clinical text data, which includes patient narratives, treatment transcripts, and diagnostic reports, we undertake comprehensive experiments. The proposed Trans-CNN hybrid model outperformed all other methods with an impressive accuracy of 97%. In diagnosing psychiatric problems, the model shows improved diagnosis accuracy and offers more effective therapy advice. Our hybrid model's automatic real-time monitoring and feedback capabilities also make it possible for prompt intervention and customized care during therapy sessions. By giving doctors a formidable tool for precise evaluation and efficient intervention, the suggested approach has the potential to revolutionize the field of CBT and enhance patient outcomes for mental health. In order to improve the diagnostic precision and therapeutic efficacy of CBT in psychological evaluation and intervention, this work provides a transformational strategy that combines the advantages of the Transformer and CNN architectures.","2023-07","2025-02-26 20:43:28","2025-02-26 20:43:28","","594-602","","7","14","","","","","","","","","","English","","","","WOS:001047152400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","CBT; CNN; diagnostic accuracy; intervention; NLP; psychological assessment; Transformer; treatment efficiency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5T57QHZR","journalArticle","2023","Lv, PY; Ma, LS; Li, QM; Du, F","ShapeFormer: A Shape-Enhanced Vision Transformer Model for Optical Remote Sensing Image Landslide Detection","IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING","","1939-1404","10.1109/JSTARS.2023.3253769","","Landslides pose a serious threat to human life, safety, and natural resources. Remote sensing images can be used to effectively monitor landslides at a large scale, which is of great significance for pre-disaster warning and post-disaster assistance. In recent years, deep learning-based methods have made great progress in the field of remote sensing image landslide detection. In remote sensing images, landslides display a variety of scales and shapes. In this article, to better extract and keep the multiscale shape information of landslides, a shape-enhanced vision transformer (ShapeFormer) model is proposed. For the feature extraction, a pyramid vision transformer (PVT) model is introduced, which directly models the global information of local elements at different scales. To learn the shape information of different landslides, a shape feature extraction branch is designed, which uses the adjacent feature maps at different scales in the PVT model to improve the boundary information. After the feature extraction step, a decoder with deconvolutional layers follows, which combines the multiple features and gradually recovers the original resolution of the combined features. A softmax layer is connected with the combined features to acquire the final pixel-wise result. The proposed ShapeFormer model was tested on two public datasets-the Bijie dataset and the Nepal dataset-which have different spectral and spatial characteristics. The results, when compared with those of some of the state-of-the-art methods, show the potential of the proposed method for use with multisource optical remote sensing data for landslide detection.","2023","2025-02-26 20:43:28","2025-02-26 20:43:28","","2681-2689","","","16","","","","","","","","","","English","","","","WOS:000967330500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;30<br/>Total Times Cited:&nbsp;&nbsp;30<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","Feature extraction; Index Terms; Landslide detection; Optical imaging; Optical sensors; RECOGNITION; Remote sensing; remote sensing image; Shape; Terrain factors; Transformers; vision transformer (ViT)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZDQSC8WG","journalArticle","2025","Lee, S; Shim, J; Lee, J; Chae, SH; Lee, C; Cho, KH","Temporal fusion transformer model for predicting differential pressure in reverse osmosis process","JOURNAL OF WATER PROCESS ENGINEERING","","2214-7144","10.1016/j.jwpe.2024.106914","","Reverse osmosis (RO) is an advanced water treatment technology that effectively removes a broad spectrum of pollutants from water. A critical aspect in assessing the integrity of RO membranes and maintaining filtration systems is the differential pressure (DP). Conventional methods for predicting DP, which often depend on sensors or programmable logic controllers, encounter limitations due to the complexity of process conditions and variability in operational data. This study seeks to improve DP prediction in industrial RO processes through the application of deep learning models. We implemented a state-of-the-art temporal fusion transformer (TFT) model that effectively differentiates between static and dynamic variables. The TFT-based model demonstrated superior performance with an R-2 value exceeding 0.9813, significantly outperforming the long short-term memory (LSTM) model, which achieved an R-2 value >0.9364. This enhancement in prediction accuracy indicates that transformer-based algorithms, by concentrating on key features, can surpass more complex neural networks in regression tasks. Notably, the TFT model adeptly managed static variables-typically problematic for time-series models-alongside dynamic variables. The effectiveness of the model in incorporating static inputs, such as process numbers and cleaning injection status, was confirmed by R-2 values of 0.9813 with the static encoder and 0.8980 without it. Furthermore, we evaluated the reliability of the model by examining the relative importance of input features through an attention map. The adaptability and interpretability of this approach confer substantial benefits, enhancing energy efficiency and operational performance in various industrial settings.","2025-02","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","70","","","","","","","","","","English","","","","WOS:001411014500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","DESIGN; Differential pressure; FEED; LOAD; Optimization; PLANTS; Reverse osmosis process; RO; SYSTEMS; Temporal fusion transformer; Water treatment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F38CLKPT","journalArticle","2024","Zhang, T; Bi, YG; Xuan, CZ","Convolutional transformer attention network with few-shot learning for grassland degradation monitoring using UAV hyperspectral imagery","INTERNATIONAL JOURNAL OF REMOTE SENSING","","0143-1161","10.1080/01431161.2024.2326042","","In recent years, the desertification of grasslands has increased due to various factors, including both global warming and human activities. It is an essential basis for grassland degradation monitoring to monitor the dynamic change of desert grassland vegetation communities and distribution statistics. Although unmanned aerial vehicle (UAV) remote sensing images have allowed us to achieve dynamic real-time grassland monitoring, the distribution of desert grassland ground objects can be random and narrow, thus increasing the difficulty of sample labelling of remote sensing imagery. Therefore, to reduce the number of samples required for the model, this research proposes a convolutional transformer attention network (CTAN) to identify desert grassland ground objects and validate it on a self-collected desert grassland dataset. The network utilizes the transformer model to enhance its learning of global pixels so that it suppresses the transmission of background pixels within the network. Furthermore, the edge convolution module is designed to strengthen the network's learning for edge pixels, improving its identification effect. The results show that the network provides 97.22% of overall accuracy (OA), 94.35% of average accuracy (AA), and 0.9398 of Kappa for ground object recognition in desert grassland. The model improves OA by 2.36-9.85% points compared to methods in the same field and 0.8-6.35% points compared to methods in hyperspectral imagery classification. The experimental results show the superior performance of the CTAN model for recognizing desert grassland objects, which helps the management and restoration of desert grasslands.","2024-03-18","2025-02-26 20:43:28","2025-02-26 20:43:28","","2109-2135","","6","45","","","","","","","","","","English","","","","WOS:001184031200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","CLASSIFICATION; classification and identification; Desert steppe; DESERT STEPPE; DIVERSITY; few-shot learning; hyperspectral remote sensing; INNER-MONGOLIA; PATTERNS; PLANT; unmanned aerial vehicle; VEGETATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IBTKMW8M","journalArticle","2024","Shi, CP; Shi, KJ; Zhu, F; Zeng, ZX; Wang, LG","Multihead Global Attention and Spatial Spectral Information Fusion for Remote Sensing Image Compression","IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING","","1939-1404","10.1109/JSTARS.2024.3417690","","In recent years, convolutional neural network (CNN) based methods have been widely used in remote sensing image compression tasks. However, CNN is commonly used to extract local information and does not fully utilize global contextual information. The transformer model can effectively extract the latent contextual information in remote sensing images due to its multihead self-attention mechanisms. Due to the multiscale local features and global low-frequency information of remote sensing images, existing deep-learning-based compression methods have not effectively combined CNN and transformer. In order to overcome the limitations of the above methods, a multihead global attention and spatial spectral information fusion network (MGSSNet) is proposed for remote sensing image compression. First, a spatial spectral information fusion attention module (SSIF-AM) is constructed to obtain multiscale local information. Second, a multihead global attention module (MHG-AM) is proposed to capture rich global context information. Third, a local global collaboration module is developed to explore the correlation between the multiscale local features obtained by SSIF-AM and the global visual features obtained by MHG-AM, and to efficiently model the intrinsic relationships between them to achieve effective feature fusion. Experimental results show that compared with advanced compression models, the proposed MGSSNet method achieves better compression performance. In addition, using reconstructed images obtained by different compression methods for classification tasks has proven that the proposed method can help achieve better classification performance, indicating that the proposed compression method can more fully preserve important information in the image.","2024","2025-02-26 20:43:28","2025-02-26 20:43:28","","999-1015","","","17","","","","","","","","","","English","","","","WOS:001270275700003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Attention network; compression; Computational modeling; Convolutional neural networks; deep learning; Entropy; Feature extraction; Image coding; Image reconstruction; Remote sensing; remote sensing images; variational autoencoder (VAE)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DDCUITS4","journalArticle","2023","Cosma, A; Catruna, A; Radoi, E","Exploring Self-Supervised Vision Transformers for Gait Recognition in the Wild","SENSORS","","1424-8220","10.3390/s23052680","","The manner of walking (gait) is a powerful biometric that is used as a unique fingerprinting method, allowing unobtrusive behavioral analytics to be performed at a distance without subject cooperation. As opposed to more traditional biometric authentication methods, gait analysis does not require explicit cooperation of the subject and can be performed in low-resolution settings, without requiring the subject's face to be unobstructed/clearly visible. Most current approaches are developed in a controlled setting, with clean, gold-standard annotated data, which powered the development of neural architectures for recognition and classification. Only recently has gait analysis ventured into using more diverse, large-scale, and realistic datasets to pretrained networks in a self-supervised manner. Self-supervised training regime enables learning diverse and robust gait representations without expensive manual human annotations. Prompted by the ubiquitous use of the transformer model in all areas of deep learning, including computer vision, in this work, we explore the use of five different vision transformer architectures directly applied to self-supervised gait recognition. We adapt and pretrain the simple ViT, CaiT, CrossFormer, Token2Token, and TwinsSVT on two different large-scale gait datasets: GREW and DenseGait. We provide extensive results for zero-shot and fine-tuning on two benchmark gait recognition datasets, CASIA-B and FVG, and explore the relationship between the amount of spatial and temporal gait information used by the visual transformer. Our results show that in designing transformer models for processing motion, using a hierarchical approach (i.e., CrossFormer models) on finer-grained movement fairs comparatively better than previous whole-skeleton approaches.","2023-03","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","5","23","","","","","","","","","","English","","","","WOS:000948150600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","biometric authentication; contrastive learning; gait recognition; pose estimation; self-supervised learning; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"II33D3YG","journalArticle","2022","Ezziane, H; Houassine, H; Moulahoum, S; Chaouche, MS","A Novel Method to Identification Type, Location, and Extent of Transformer Winding Faults Based on FRA and SMOTE-SVM","RUSSIAN JOURNAL OF NONDESTRUCTIVE TESTING","","1061-8309","10.1134/S1061830922050047","","Currently, the adoption of artificial intelligence is an inevitable necessity in diagnosing electrical systems failures, also, frequency response analysis FRA is widely used as a tool for diagnostic mechanical and electrical faults in power transformers, in this paper, a new methodology was proposed based on machine learning and advanced diagnostic technique FRA for detecting the type, location and severity of transformer fault. The method was applied and test it on three common actual defects (viz. axial displacement (AD), radial displacement (RD), and short circuit (SC)) that have been applied practically to an actual transformer winding at various locations and with different levels. Initially, the proposed approach is based on the collection and interpretation of the frequency response analysis (FRA) data of the winding faults to construct a database that can confine all possible cases of the fault and this has been tried with AD fault. After that, before classification, the problem of imbalance in the databases is addressed. Therefore, a support vector machine (SVM) classifier combined with SMOTE data preprocessing algorithm has been suggested to solve the imbalance problem. The performance of the suggested methodology was evaluated using experimental data collected from the winding transformer model. Where the results prove the ability of the proposed method to detect the type, locate and severity of the fault with high accuracy than other methods, which may effectively contribute to the development of machine learning reliance for the diagnosis of the power transformer faults.","2022-05","2025-02-26 20:43:28","2025-02-26 20:43:28","","391-404","","5","58","","","","","","","","","","English","","","","WOS:000852410500006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","CLASSIFICATION; frequency response analysis (FRA); FREQUENCY-RESPONSE; power transformer; STATISTICAL APPROACH; support vector machine (SVM); synthetic minority over-sampling technique (SMOTE)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TYXIKE2I","journalArticle","2022","Althobaiti, MJ","A Simple Yet Robust Algorithm for Automatic Extraction of Parallel Sentences: A Case Study on Arabic-English Wikipedia Articles","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2021.3137830","","Parallel corpora are vital components in several applications of Natural Language Processing (NLP), particularly in machine translation. In this paper, we present a novel method for automatically creating parallel sentences from comparable corpora. The method requires a bilingual dictionary as well as an adequate word-vectorisation method. We use Arabic and English Wikipedia as a comparable corpus to apply our proposed method and construct a parallel corpus between Arabic and English. The created Arabic-English corpus consists of 105,010 parallel sentences with a total number of 4.6M words. During our study, we compared two methods of word vectorisation, word embedding and term frequency-inverse document frequency, in terms of their usefulness in computing similarities between well-formed and syntactically ill-formed sentences. We also quantitatively and qualitatively examined the parallel corpus produced by our proposed method and compared it with other available Arabic-English parallel corpora counterparts: GlobalVoices, TED, and Wiki-OPUS. We explored the main advantages and shortcomings of these corpora when used for NLP applications, such as word semantic similarity identification and Neural Machine Translation (NMT). The word semantic similarity models trained on our parallel corpus outperformed models trained on other corpora in the task of English non-similar word identification. Our parallel corpus also proved competitive when building Arabic-English NMT systems, yielding results comparable to those of the automatically created Wiki-OPUS corpus and of the manually created TED corpus, while achieving results superior to the smaller GlobalVoices corpus.","2022","2025-02-26 20:43:28","2025-02-26 20:43:28","","401-420","","","10","","","","","","","","","","English","","","","WOS:000739478700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;81</p>","","","Automatic creation of parallel corpus; automatic sentence alignment; Computational modeling; deep learning; Dictionaries; Encyclopedias; Internet; LINKAGE; Machine translation; neural machine translation; Online services; Semantics; transformer model; word embedding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XUZUKS3S","journalArticle","2022","Ke, SY; Neeley-Tass, ES; Barnes, M; Hanson, CL; Giraud-Carrier, C; Snell, Q","COVID-19 Health Beliefs Regarding Mask Wearing and Vaccinations on Twitter: Deep Learning Approach","JMIR INFODEMIOLOGY","","2564-1891","10.2196/37861","","Background: Amid the global COVID-19 pandemic, a worldwide infodemic also emerged with large amounts of COVID-19-related information and misinformation spreading through social media channels. Various organizations, including the World Health Organization (WHO) and the Centers for Disease Control and Prevention (CDC), and other prominent individuals issued high-profile advice on preventing the further spread of COVID-19. Objective: The purpose of this study is to leverage machine learning and Twitter data from the pandemic period to explore health beliefs regarding mask wearing and vaccines and the influence of high-profile cues to action. Methods: A total of 646,885,238 COVID-19-related English tweets were filtered, creating a mask-wearing data set and a vaccine data set. Researchers manually categorized a training sample of 3500 tweets for each data set according to their relevance to Health Belief Model (HBM) constructs and used coded tweets to train machine learning models for classifying each tweet in the data sets. Results: In total, 5 models were trained for both the mask-related and vaccine-related data sets using the XLNet transformer model, with each model achieving at least 81% classification accuracy. Health beliefs regarding perceived benefits and barriers were most pronounced for both mask wearing and immunization; however, the strength of those beliefs appeared to vary in response to high-profile cues to action. Conclusions: During both the COVID-19 pandemic and the infodemic, health beliefs related to perceived benefits and barriers observed through Twitter using a big data machine learning approach varied over time and in response to high-profile cues to action from prominent organizations and individuals.","2022","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","2","2","","","","","","","","","","English","","","","WOS:001147613500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","content analysis; COVID-19; deep learning; health belief; Health Belief Model; infodemic; infodemiology; machine learning; mask; misinformation; OUTBREAK; Twitter; vaccination; VACCINE; vaccine data set","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FJRJJ72E","journalArticle","2022","Sun, P; Wu, XS; Cai, J; Wang, XN; Zhang, XC; Liang, Y; Xiong, Q; Rong, EG","Eddy current loss analysis and frequency optimization design of double-sided LCC-IPT system in seawater environment","SCIENCE CHINA-TECHNOLOGICAL SCIENCES","","1674-7321","10.1007/s11431-021-1917-1","","Inductive power transfer system can generate eddy current when operating in seawater medium. On the one hand, it can cause eddy current loss, and reduce operating efficiency of the system. On the other hand, it can change parameters of the system and increase difficulty of system design. To grasp the influence mechanism of seawater on the inductive power transfer system, firstly, an equivalent circuit model of double-sided inductor-capacitor-capacitor (LCC) inductive power transfer system in seawater environment was established based on loosely-coupled transformer model of eddy current. Then, based on Maxwell's equations, the distribution function of the magnetic field and electric current density along radium direction of the coupling coils in seawater medium was obtained by analytical calculation. Besides, in combination with Biot-Savart law, expression of the eddy current loss in transfer direction was derived, and based on which expression of the equivalent of the eddy current loss on the coupling coils was got. Thus the equivalent resistance of the eddy current on the coupling coils in a seawater environment could be predicated, and the optimal operating frequency of the inductive power transfer system could be further optimized. Finally, a prototype of inductive power transfer system was established, which gave the experimental results, and verified the correctness of theoretical analysis, and the experiments showed that: in air medium, the transfer distance was 100 mm, the transfer power was 3.3 kW, and the transfer efficiency was 92.6%; while, in seawater medium, the transfer efficiency was 87%. Eddy current losses mainly caused the reduction in efficiency, and the experimental results of eddy current loss were consistent with the simulation results.","2022-02","2025-02-26 20:43:28","2025-02-26 20:43:28","","407-418","","2","65","","","","","","","","","","English","","","","WOS:000702803600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;16</p>","","","Biot-Savart law; eddy current loss; inductive power transfer; seawater","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FPU7MQE8","journalArticle","2025","Küçük, DB; Imak, A; Özçelik, STA; Çelebi, A; Türkoglu, M; Sengur, A; Koundal, D","Hybrid CNN-Transformer Model for Accurate Impacted Tooth Detection in Panoramic Radiographs","DIAGNOSTICS","","2075-4418","10.3390/diagnostics15030244","","Background/Objectives: The integration of digital imaging technologies in dentistry has revolutionized diagnostic and treatment practices, with panoramic radiographs playing a crucial role in detecting impacted teeth. Manual interpretation of these images is time consuming and error prone, highlighting the need for automated, accurate solutions. This study proposes an artificial intelligence (AI)-based model for detecting impacted teeth in panoramic radiographs, aiming to enhance accuracy and reliability. Methods: The proposed model combines YOLO (You Only Look Once) and RT-DETR (Real-Time Detection Transformer) models to leverage their strengths in real-time object detection and learning long-range dependencies, respectively. The integration is further optimized with the Weighted Boxes Fusion (WBF) algorithm, where WBF parameters are tuned using Bayesian optimization. A dataset of 407 labeled panoramic radiographs was used to evaluate the model's performance. Results: The model achieved a mean average precision (mAP) of 98.3% and an F1 score of 96%, significantly outperforming individual models and other combinations. The results were expressed through key performance metrics, such as mAP and F1 scores, which highlight the model's balance between precision and recall. Visual and numerical analyses demonstrated superior performance, with enhanced sensitivity and minimized false positive rates. Conclusions: This study presents a scalable and reliable AI-based solution for detecting impacted teeth in panoramic radiographs, offering substantial improvements in diagnostic accuracy and efficiency. The proposed model has potential for widespread application in clinical dentistry, reducing manual workload and error rates. Future research will focus on expanding the dataset and further refining the model's generalizability.","2025-02","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","3","15","","","","","","","","","","English","","","","WOS:001419505700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","DEEP; impacted tooth detection; SINUSITIS; super resolution; TEETH; transformer; Weighted Boxes Fusion; YOLO","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BRAWSQY6","journalArticle","2024","Li, QY; Xie, WJ; Wang, YS; Qin, KW; Huang, M; Liu, TB; Chen, ZFY; Chen, L; Teng, L; Fang, YX; Ye, LH; Chen, ZY; Zhang, J; Li, AM; Yang, W; Liu, SD","A Deep Learning Application of Capsule Endoscopic Gastric Structure Recognition Based on a Transformer Model","JOURNAL OF CLINICAL GASTROENTEROLOGY","","0192-0790","10.1097/MCG.0000000000001972","","Background:Gastric structure recognition systems have become increasingly necessary for the accurate diagnosis of gastric lesions in capsule endoscopy. Deep learning, especially using transformer models, has shown great potential in the recognition of gastrointestinal (GI) images according to self-attention. This study aims to establish an identification model of capsule endoscopy gastric structures to improve the clinical applicability of deep learning to endoscopic image recognition.Methods:A total of 3343 wireless capsule endoscopy videos collected at Nanfang Hospital between 2011 and 2021 were used for unsupervised pretraining, while 2433 were for training and 118 were for validation. Fifteen upper GI structures were selected for quantifying the examination quality. We also conducted a comparison of the classification performance between the artificial intelligence model and endoscopists by the accuracy, sensitivity, specificity, and positive and negative predictive values.Results:The transformer-based AI model reached a relatively high level of diagnostic accuracy in gastric structure recognition. Regarding the performance of identifying 15 upper GI structures, the AI model achieved a macroaverage accuracy of 99.6% (95% CI: 99.5-99.7), a macroaverage sensitivity of 96.4% (95% CI: 95.3-97.5), and a macroaverage specificity of 99.8% (95% CI: 99.7-99.9) and achieved a high level of interobserver agreement with endoscopists.Conclusions:The transformer-based AI model can accurately evaluate the gastric structure information of capsule endoscopy with the same performance as that of endoscopists, which will provide tremendous help for doctors in making a diagnosis from a large number of images and improve the efficiency of examination.","2024-10","2025-02-26 20:43:28","2025-02-26 20:43:28","","937-943","","9","58","","","","","","","","","","English","","","","WOS:001309080700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","artificial intelligence; capsule endoscopy; EUROPEAN-SOCIETY; GASTROINTESTINAL ENDOSCOPY; gastrointestinal structures recognition; transformer-based model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PTB75ZZH","journalArticle","2024","Jiang, B; Wang, KM","Railway accident causation prediction with improved transformer model based on lexical information and contextual relationships","KNOWLEDGE-BASED SYSTEMS","","0950-7051","10.1016/j.knosys.2024.111897","","The railway system is a prime example of a safety -critical system. Predicting the causes of railway accidents holds immense significance in enhancing railway transportation safety. Previous approaches to railway causation analysis have encountered huge challenges regarding data processing and analytical capabilities. To address this concern, this paper proposes an innovative deep model framework based on the Transformer architecture that utilizes historical data on railway equipment accidents to predict the causes behind such incidents. Firstly, this paper proposes the utilization of Convolutional Block Attention in the domain of text processing, serving as a lexical encoder to augment word semantics acquisition in accident texts. Subsequently, in order to address the deficiency of traditional Transformers that lack positional representation information, we propose incorporating a BiGRU (Bidirectional Gated Recurrent Unit) as a contextual positional information encoder to capture contextual positional information in railway accident data effectively. Finally, considering that accident data reports are discrete tabular data, this study suggests employing cue word techniques for preprocessing accident data to alleviate the model 's learning burden. We applied the proposed model to the FRA (Federal Railroad Administration) dataset. The results demonstrate that our model surpasses the current state-of-the-art language models, exhibiting superior performance compared to the optimal model with a notable improvement of 3.56%, 0.42%, and 0.76% in Precision, Recall, and F1 -score, respectively. Furthermore, our model accurately predicts accident categories prone to misjudgment even when trained on limited data, outperforming existing language models. The study findings will contribute to the prevention and management of railway accidents.","2024-07-19","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","296","","","","","","","","","","English","","","","WOS:001244597400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Causal analysis; Data analysis; Deep learning; Natural language processing; Railway safety","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2T66TZRB","journalArticle","2024","Yang, SP; Huang, HY; Huang, YS; Jin, XG","Facial action units detection using temporal context and feature reassignment","COMPUTER ANIMATION AND VIRTUAL WORLDS","","1546-4261","10.1002/cav.2246","","Facial action units (AUs) encode the activations of facial muscle groups, playing a crucial role in expression analysis and facial animation. However, current deep learning AU detection methods primarily focus on single-image analysis, which limits the exploitation of rich temporal context for robust outcomes. Moreover, the scale of available datasets remains limited, leading models trained on these datasets to tend to suffer from overfitting issues. This paper proposes a novel AU detection method integrating spatial and temporal data with inter-subject feature reassignment for accurate and robust AU predictions. Our method first extracts regional features from facial images. Then, to effectively capture both the temporal context and identity-independent features, we introduce a temporal feature combination and feature reassignment (TC&FR) module, which transforms single-image features into a cohesive temporal sequence and fuses features across multiple subjects. This transformation encourages the model to utilize identity-independent features and temporal context, thus ensuring robust prediction outcomes. Experimental results demonstrate the enhancements brought by the proposed modules and the state-of-the-art (SOTA) results achieved by our method. We introduce a novel automatic detection method for facial action units (AUs) that leverages both spatial and temporal data, enhancing accuracy and robustness in expression analysis and facial animation. Our approach utilizes a Temporal feature Combination and Feature Reassignment (TC&FR) module to transform and fuse features across multiple subjects and temporal sequences. Moreover, by integrating a Regional Attention (RA) encoder and a transformer model, our method refines the extraction and processing of regional features, ensuring more precise identification and analysis of AUs. This integration not only harnesses identity-independent features but also maximizes the temporal context, significantly improving the reliability of AU predictions. image","2024-05","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","3","35","","","","","","","","","","English","","","","WOS:001226339200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","action units; facial AU detection; temporal context modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8P6BJHG4","journalArticle","2024","Lv, JF; Yu, ZL; Zhang, HC; Sun, GH; Muhl, P; Liu, JX","Transformer Based Long-Term Prognostics for Dynamic Operating PEM Fuel Cells","IEEE TRANSACTIONS ON TRANSPORTATION ELECTRIFICATION","","2332-7782","10.1109/TTE.2023.3266803","","Proton exchange membrane fuel cells (PEMFCs) are considered clean alternative energy that has been widely used in many fields. However, the large-scale commercialization of PEMFCs is still limited by their durability performance. Prognostics and health management (PHM) are considered helpful solutions to improve the durability of PEMFCs with degradation prediction and health-based control and maintenance methods. The long-term PEMFC prognostic task, as a primary component in PHM, has received extensive attention from both academia and industry. Recently, the combination of deep neural networks and PEMFC prognostics has expressed a broad research perspective. The deep-learning-based methods, such as convolutional neural network (CNN), echo state network (ESN), and recurrent neural network (RNN) family methods, have been well studied by many researchers and have shown satisfactory performance in degradation prediction. However, the long-term prediction performance is still limited by the model structure and accumulative errors. This article focuses on the degradation of the PEMFC, and a transformer-based PEMFC prognostic framework is proposed to predict the long-term degradation of the PEMFC system. The transformer model is applied, for the first time, to predict the degradation of the PEMFC, and a series-attention mechanism is proposed to replace the self-attention mechanism in the Vanilla transformer which could improve the health indicator (HI) prediction performance. Finally, the PEMFC dynamic durability test data is utilized to evaluate the performance of the proposed framework in both multistep-ahead prediction and long-term prognostic conditions, and the experimental results illustrate the feasibility and effectiveness of the proposed method.","2024-03","2025-02-26 20:43:28","2025-02-26 20:43:28","","1747-1757","","1","10","","","","","","","","","","English","","","","WOS:001192150400137","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Degradation; Degradation prediction; PREDICTION; Predictive models; Prognostics and health management; proton exchange membrane fuel cell (PEMFC); Recurrent neural networks; self-attention; Task analysis; transformer; Transformers; Vehicle dynamics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HQ4MMJLS","journalArticle","2024","Li, GH; Bai, PH; Liang, C; Luo, JW","Node-adaptive graph Transformer with structural encoding for accurate and robust lncRNA-disease association prediction","BMC GENOMICS","","1471-2164","10.1186/s12864-024-09998-2","","BackgroundLong noncoding RNAs (lncRNAs) are integral to a plethora of critical cellular biological processes, including the regulation of gene expression, cell differentiation, and the development of tumors and cancers. Predicting the relationships between lncRNAs and diseases can contribute to a better understanding of the pathogenic mechanisms of disease and provide strong support for the development of advanced treatment methods.ResultsTherefore, we present an innovative Node-Adaptive Graph Transformer model for predicting unknown LncRNA-Disease Associations, named NAGTLDA. First, we utilize the node-adaptive feature smoothing (NAFS) method to learn the local feature information of nodes and encode the structural information of the fusion similarity network of diseases and lncRNAs using Structural Deep Network Embedding (SDNE). Next, the Transformer module is used to capture potential association information between the network nodes. Finally, we employ a Transformer module with two multi-headed attention layers for learning global-level embedding fusion. Network structure coding is added as the structural inductive bias of the network to compensate for the missing message-passing mechanism in Transformer. NAGTLDA achieved an average AUC of 0.9531 and AUPR of 0.9537 significantly higher than state-of-the-art methods in 5-fold cross validation. We perform case studies on 4 diseases; 55 out of 60 associations between lncRNAs and diseases have been validated in the literatures. The results demonstrate the enormous potential of the graph Transformer structure to incorporate graph structural information for uncovering lncRNA-disease unknown correlations.ConclusionsOur proposed NAGTLDA model can serve as a highly efficient computational method for predicting biological information associations.","2024-01-18","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","1","25","","","","","","","","","","English","","","","WOS:001144648700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;80</p>","","","DATABASE; lncRNA-disease associations; LONG NONCODING RNAS; NCRNA; NEURAL-NETWORK; Node-adaptive feature smoothing; PRINCIPLES; Structural deep network embedding; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9Y8VI3AZ","journalArticle","2024","Okubo, I; Sugiura, K; Matsutani, H","A Cost-Efficient FPGA-Based CNN-Transformer Using Neural ODE","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3480977","","Transformer has been adopted to image recognition tasks and shown to outperform CNNs and RNNs while it suffers from high training cost and computational complexity. To address these issues, a hybrid approach has become a recent research trend, which replaces a part of ResNet with an MHSA (Multi-Head Self-Attention). In this paper, we propose a lightweight hybrid model which uses Neural ODE (Ordinary Differential Equation) as a backbone instead of ResNet so that we can increase the number of iterations of building blocks while reusing the same parameters, mitigating the increase in parameter size per iteration. The proposed model is deployed on a modest-sized FPGA device for edge computing. The model is further quantized by QAT (Quantization Aware Training) scheme to reduce FPGA resource utilization while suppressing the accuracy loss. The quantized model achieves 79.68% top-1 accuracy for STL10 dataset that contains 96x96 pixel images. The weights of the feature extraction network are stored on-chip to minimize the memory transfer overhead, allowing faster inference. By eliminating the overhead of memory transfers, inference can be executed seamlessly, leading to accelerated inference. The proposed FPGA implementation accelerates the backbone and MHSA parts by 34.01x , and achieves an overall 9.85x speedup when taking into account the software pre- and post-processing. The FPGA acceleration leads to 7.10x better energy efficiency compared to the ARM Cortex-A53 CPU. The proposed lightweight Transformer model is demonstrated on Xilinx ZCU104 board for the image recognition of 96x96 pixel images in this paper and can be applied to different image sizes by modifying the pre-processing layer.","2024","2025-02-26 20:43:28","2025-02-26 20:43:28","","155773-155788","","","12","","","","","","","","","","English","","","","WOS:001346082500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Accuracy; Artificial intelligence; Attention mechanisms; Computational modeling; Costs; Field programmable gate arrays; Load modeling; machine learning; Mathematical models; Quantization (signal); tiny machine learning; Training; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3HCQE4X9","journalArticle","2023","Wang, YJ; Luo, FR; Yang, X; Wang, QS; Sun, YC; Tian, SK; Feng, P; Huang, P; Xiao, HL","The Swin-Transformer network based on focal loss is used to identify images of pathological subtypes of lung adenocarcinoma with high similarity and class imbalance","JOURNAL OF CANCER RESEARCH AND CLINICAL ONCOLOGY","","0171-5216","10.1007/s00432-023-04795-y","","PurposeThe classification of primary lung adenocarcinoma is complex and varied. Different subtypes of lung adenocarcinoma have different treatment methods and different prognosis. In this study, we collected 11 datasets comprising subtypes of lung cancer and proposed FL-STNet model to provide the assistance for improving clinical problems of pathologic classification in primary adenocarcinoma of lung.MethodsSamples were collected from 360 patients diagnosed with lung adenocarcinoma and other subtypes of lung diseases. In addition, an auxiliary diagnosis algorithm based on Swin-Transformer, which used Focal Loss for function in training, was developed. Meanwhile, the diagnostic accuracy of the Swin-Transformer was compared to pathologists.ResultsThe Swin-Transformer captures not only information in the overall tissue structure but also the local tissue details in the images of lung cancer pathology. Furthermore, training FL-STNet with the Focal Loss function can further balance the difference in the amount of data between different subtypes, improving recognition accuracy. The average classification accuracy, F1, and AUC of the proposed FL-STNet reached 85.71%, 86.57%, and 0.9903. The average accuracy of the FL-STNet was higher by 17% and 34%, respectively, than in the senior pathologist and junior pathologist group.ConclusionThe first deep learning based on an 11-category classifier was developed for classifying lung adenocarcinoma subtypes based on WSI histopathology. Aiming at the deficiencies of the current CNN and Vit, FL-STNet model is proposed in this study by introducing Focal Loss and combining the advantages of Swin-Transformer model.","2023-09","2025-02-26 20:43:28","2025-02-26 20:43:28","","8581-8592","","11","149","","","","","","","","","","English","","","","WOS:000978738200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","ASSOCIATION; Category imbalance; Deep learning; Histopathology; IASLC/ATS/ERS CLASSIFICATION; IMPACT; Lung adenocarcinoma; Subtype","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MKBLRAGD","journalArticle","2023","Xue, ZS; Zhang, XL; Shi, TX; Xiong, DY","DetTrans: A Lightweight Framework to Detect and Translate Noisy Inputs Simultaneously","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2023.3284513","","Neural machine translation (NMT) systems trained on clean data usually suffer from performance degradation when translating noisy inputs. Existing works attempt to improve the robustness of NMT normally via data augmentation, where synthetic noisy data are mixed with original clean data, either for training NMT with the standard NMT loss alone, or for tuning auxiliary tasks in a multi-task learning manner. Typical auxiliary tasks include detecting and correcting noises, exploiting noisy outputs for contrastive learning etc. The aforementioned two auxiliary tasks are generally designed independently, and the modules for detecting and correcting noises are heavyweight. In this article, we propose a new framework, DetTransNet (Detector-Translator Network), aiming to detect positions of noises in the input and translate the input simultaneously. The newly introduced noise detector module is essentially a lightweight binary classifier built upon the final layer of the encoder of the original Transformer model for the translation task, which is to identify at which position of the input has potential noise. The module has a very few parameters. In order to help the model capture the relationship between clean instances and their noisy counterparts, an extra loss is further introduced to enhance the interaction between clean and noisy data. In this way, we combine noise detection and contrastive learning together. As the model is able to identify and locate noises, a heuristic method is proposed to correct detected noises, in order to achieve better translations. Experiments show that DetTransNet is robust to four types of noises (deletion, insertion, swapping, keyboard), and obtain a substantial improvement of up to 1.6 BLEU points across different datasets.","2023","2025-02-26 20:43:28","2025-02-26 20:43:28","","3696-3705","","","31","","","","","","","","","","English","","","","WOS:001089305500024","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Detectors; Machine translation; Neural machine translation; Noise measurement; robust translation; Robustness; Task analysis; Training; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S6RVQZV2","journalArticle","2023","Sharma, H; Srivastava, S","A Framework for Image Captioning Based on Relation Network and Multilevel Attention Mechanism","NEURAL PROCESSING LETTERS","","1370-4621","10.1007/s11063-022-11106-y","","Understanding different semantic concepts, such as objects and their relationships in an image, and integrating them to produce a natural language description is the goal of the image captioning task. Thus, it needs an algorithm to understand the visual content of a given image and translates it into a sequence of output words. In this paper, a local relation network is designed over the objects and image regions which not only discovers the relationship between the object and the image regions but also generates significant context-based features corresponding to every region in the image. Inspired by transformer model, we have employed a multilevel attention comprising of self-attention and guided attention to focus on a given image region and its related image regions, thus enhancing the image representation capability of the proposed method. Finally, a variant of traditional long-short term memory, which uses an attention mechanism, is employed which focuses on relevant contextual information, spatial locations, and deep visual features. With these measures, the proposed model encodes an image in an improved way, which gives the model significant cues and thus leads to improved caption generation. Extensive experiments have been performed on three benchmark datasets: Flickr30k, MSCOCO, and Nocaps. On Flickr30k, the obtained evaluation scores are 31.2 BLEU@4, 23.5 METEOR, 51.5 ROUGE, 65.6 CIDEr and 17.2 SPICE. On MSCOCO, the proposed model has attained 42.4 BLEU@4, 29.4 METEOR, 59.7 ROUGE, 125.7 CIDEr and 23.2 SPICE. The overall CIDEr score on Nocaps dataset achieved by the proposed model is 114.3. The above scores clearly show the superiority of the proposed method over the existing methods.","2023-10","2025-02-26 20:43:28","2025-02-26 20:43:28","","5693-5715","","5","55","","","","","","","","","","English","","","","WOS:000900062100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;77</p>","","","Attention; Encoder-decoder; Relation network; Semantic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LR5U5M6E","journalArticle","2022","Liu, MZ; Wei, YJ","An Improvement to Conformer-Based Model for High-Accuracy Speech Feature Extraction and Learning","ENTROPY","","1099-4300","10.3390/e24070866","","Owing to the loss of effective information and incomplete feature extraction caused by the convolution and pooling operations in a convolution subsampling network, the accuracy and speed of current speech processing architectures based on the conformer model are influenced because the shallow features of speech signals are not completely extracted. To solve these problems, in this study, we researched a method that used a capsule network to improve the accuracy of feature extraction in a conformer-based model, and then, we proposed a new end-to-end model architecture for speech recognition. First, to improve the accuracy of speech feature extraction, a capsule network with a dynamic routing mechanism was introduced into the conformer model; thus, the structural information in speech was preserved, and it was input to the conformer blocks via sequestered vectors; the learning ability of the conformed-based model was significantly enhanced using dynamic weight updating. Second, a residual network was added to the capsule blocks, thus, the mapping ability of our model was improved and the training difficulty was reduced. Furthermore, the bi-transformer model was adopted in the decoding network to promote the consistency of the hypotheses in different directions through bidirectional modeling. Finally, the effectiveness and robustness of the proposed model were verified against different types of recognition models by performing multiple sets of experiments. The experimental results demonstrated that our speech recognition model achieved a lower word error rate without a language model because of the higher accuracy of speech feature extraction and learning using our model architecture with a capsule network. Furthermore, our model architecture benefited from the advantage of the capsule network and the conformer encoder, and also has potential for other speech-related applications.","2022-07","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","7","24","","","","","","","","","","English","","","","WOS:000832094200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","bi-transformer; capsule network; Chinese speech recognition; conformer; end-to-end; NETWORKS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VACA9IM5","journalArticle","2022","Wang, L; He, YG; Li, L; Liu, XY; Zhao, YY","A novel approach to ultra-short-term multi-step wind power predictions based on encoder-decoder architecture in natural language processing","JOURNAL OF CLEANER PRODUCTION","","0959-6526","10.1016/j.jclepro.2022.131723","","Accurate wind power predictions (WPPs) are highly significant to the safety, stability, and economic operation of power systems. The reported encoder--decoder architectures have demonstrated clear advantages over traditional methods in multi-step WPP tasks. However, the reported frameworks still have defects involving insufficient information mining abilities and low computing efficiencies. To address these shortcomings, this study proposed three improved encoder-decoder architectures, sequence-to-sequence bidirectional gated recurrent unit (SBIGRU), attention-based sequence-to-sequence Bi-GRU (ASBIGRU) and Transformer, in natural language processing for multi-step WPP. Data, including numerical weather predictions and wind powers, from 12 wind farms located in 12 different regions of China were used to validate our proposed models. The correlations between the datasets from multiple wind farms were analyzed using Pearson's correlation coefficient method to demonstrate the feasibility of our proposed models even without considering the spatial correlations. We adopted an effective strategy combining manual experience and machine grid searches to define the hyper-parameters needed to optimize the performance of our proposed models. The prediction accuracies and computational efficiencies of the reported and proposed models were compared experimentally. For prediction accuracy, the experimental results showed that, compared with existing models, Transformer, ASBIGRU and SBIGRU reduced the root mean square error by 3.21%, 1.06% and 0.88% in 16-step-ahead predictions, respectively. Furthermore, for computational efficiency, the training time of the existing model at a wind farm is 3.57 times that of Transformer. This confirmed that the Transformer model performs better in terms of prediction accuracy and computational efficiency. Our work illustrates the potential of Transformer for large-scale wind farm applications.","2022-06-20","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","354","","","","","","","","","","English","","","","WOS:000793423700003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;32<br/>Total Times Cited:&nbsp;&nbsp;32<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Encoder-decoder architecture; Hyper-parameter setting; NETWORK; NWP; Transformer; Wind power prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4USUJS3W","journalArticle","2022","Ma, C; Zhang, YT; Guo, JY; Hu, YX; Geng, XR; Li, FF; Lei, B; Ding, CBA","End-to-End Method With Transformer for 3-D Detection of Oil Tank From Single SAR Image","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2021.3127986","","In recent years, deep learning has been successfully applied in the field of synthetic aperture radar (SAR) image object detection. However, unlike ships and tanks targets, the oil tank targets in SAR image are usually dense and compact with more overlaps and discrete scattering centers, which greatly increases the difficulty of extracting location and structural parameters. Most of the existing methods transfer the methods suitable for natural image to the SAR image field, without considering the unique characteristics of SAR image. Therefore, in this article, we propose an improved model based on the end-to-end transformer network, which is the first model introducing transformer network to 3-D detection of oil tank targets from single SAR image. We input the incidence angle into the transformer model as a priori token. Then, we propose a feature description operator (FDO) based on the scattering centers that are used as an aid to improve the precision of predictions. In addition, we also propose a cylinder IOU as a more suitable evaluation metric for 3-D detection of oil tank. Finally, we evaluate our model on an SAR image dataset that contains SAR images from RADARSAT-2, TerraSAR-X, and GF-3 with different incidence angles. Our experiments demonstrate that our proposed model achieves the AP of 77.6% compared with 60.8% of baseline, which proves the effectiveness of the introduction of observation conditions, cylinder IOU loss (CI Loss), and the FDO based on the scattering centers in our model and is appealing for 3-D detection of oil tank.","2022","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","60","","","","","","","","","","English","","","","WOS:000757891700018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","3-D detection of oil tank; cylinder intersection over union (IOU) (cylinder IOU); feature description operator (FDO); priori token; single SAR image; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YKLX3JK3","journalArticle","2022","Park, S; Kim, G; Oh, Y; Seo, JB; Lee, SM; Kim, JH; Moon, S; Lim, JK; Ye, JC","Multi-task vision transformer using low-level chest X-ray feature corpus for COVID-19 diagnosis and severity quantification","MEDICAL IMAGE ANALYSIS","","1361-8415","10.1016/j.media.2021.102299","","Developing a robust algorithm to diagnose and quantify the severity of the novel coronavirus disease 2019 (COVID-19) using Chest X-ray (CXR) requires a large number of well-curated COVID-19 datasets, which is difficult to collect under the global COVID-19 pandemic. On the other hand, CXR data with other findings are abundant. This situation is ideally suited for the Vision Transformer (ViT) architecture, where a lot of unlabeled data can be used through structural modeling by the self-attention mechanism. However, the use of existing ViT may not be optimal, as the feature embedding by direct patch flattening or ResNet backbone in the standard ViT is not intended for CXR. To address this problem, here we propose a novel Multi-task ViT that leverages low-level CXR feature corpus obtained from a backbone network that extracts common CXR findings. Specifically, the backbone network is first trained with large public datasets to detect common abnormal findings such as consolidation, opacity, edema, etc. Then, the embedded features from the backbone network are used as corpora for a versatile Transformer model for both the diagnosis and the severity quantification of COVID-19. We evaluate our model on various external test datasets from totally different institutions to evaluate the generalization capability. The experimental results confirm that our model can achieve state-of-the-art performance in both diagnosis and severity quantification tasks with outstanding generalization capability, which are sine qua non of widespread deployment. (c) 2021 Elsevier B.V. All rights reserved.","2022-01","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","75","","","","","","","","","","English","","","","WOS:000744256900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;64<br/>Total Times Cited:&nbsp;&nbsp;67<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Chest X-ray; Coronavirus disease-19; Multi-task learning; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J9J6X8E4","journalArticle","2021","Aloysius, N; Geetha, M; Nedungadi, P","Incorporating Relative Position Information in Transformer-Based Sign Language Recognition and Translation","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2021.3122921","","Recent advancements in machine translation tasks, with the advent of attention mechanisms and Transformer networks, have accelerated the research in Sign Language Translation (SLT), a spatio-temporal vision translation task. Fundamentally, Transformers are unaware of the sequential orderings in input, and therefore position-information should be explicitly fed into them. The sequence learning capability of Transformers is heavily dependent on this ordering information. Compared to the existing Transformer models for SLT that use baseline version with sinusoidal position embedding, this work focuses on incorporating a new positioning scheme into the Transformer networks, in the context of SLT. This is the first work in SLT that explores the positioning scheme of Transformers for optimizing translation scores. The study proposes Gated Recurrent Unit (GRU)-Relative Sign Transformer (RST) for jointly learning Continuous Sign Language Recognition (CSLR) and translation. This model significantly improves the video translation quality. In this approach, GRU acts as the relative position encoder and RST is the Transformer model with relative position incorporated in the Multi-Head Attention (MHA). The evaluation was done on the RWTH-PHOENIX-2014T benchmark dataset. This study reports state-of-the-art Bilingual Evaluation Understudy (BLEU-4) score of 22.4 and Recall-Oriented Understudy for Gisting Evaluation (ROUGE) score of 48.55 for SLT, with GRU-RST. The best Word Error Rate (WER) obtained with this approach is 23.5. A detailed study of the position encoding schemes of Transformers is presented. Further, we analyze the translation performance under various combinations of the positioning schemes.","2021","2025-02-26 20:43:28","2025-02-26 20:43:28","","145929-145942","","","9","","","","","","","","","","English","","","","WOS:000714190500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Annotations; Assistive technologies; Computational modeling; Gesture recognition; Phoenix 2014T; relative position encoding; sign language translation; Streaming media; Task analysis; transformers; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PNHWJV5L","journalArticle","2024","Imran, M; Akram, MU; Tiwana, MI; Salam, AA; Hassan, T; Greco, D","Two-dimensional hybrid incremental learning (2DHIL) framework for semantic segmentation of skin tissues","IMAGE AND VISION COMPUTING","","0262-8856","10.1016/j.imavis.2024.105147","","This study aims to enhance the robustness and generalization capability of a deep learning transformer model used for segmenting skin carcinomas and tissues through the introduction of incremental learning. Deep learning AI models demonstrate their claimed performance only for tasks and data types for which they are specifically trained. Their performance is severely challenged for the test cases which are not similar to training data thus questioning their robustness and ability to generalize. Moreover, these models require an enormous amount of annotated data for training to achieve desired performance. The availability of large annotated data, particularly for medical applications, is itself a challenge. Despite efforts to alleviate this limitation through techniques like data augmentation, transfer learning, and few-shot training, the challenge persists. To address this, we propose refining the models incrementally as new classes are discovered and more data becomes available, emulating the human learning process. However, deep learning models face the challenge of catastrophic forgetting during incremental training. Therefore, we introduce a two-dimensional hybrid incremental learning framework for segmenting non-melanoma skin cancers and tissues from histopathology images. Our approach involves progressively adding new classes and introducing data of varying specifications to introduce adaptability in the models. We also employ a combination of loss functions to facilitate new learning and mitigate catastrophic forgetting. Our extended experiments demonstrate significant improvements, with an F1 score reaching 91.78, mIoU of 93.00, and an average accuracy of 95%. These findings highlight the effectiveness of our incremental learning strategy in enhancing the robustness and generalization of deep learning segmentation models while mitigating catastrophic forgetting.","2024-08","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","148","","","","","","","","","","English","","","","WOS:001271462100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","AI; Computational histopathology; Continual learning; Incremental learning; Incremental semantic segmentation; Knowledge distillation; Mutual distillation loss; Non-melanoma skin cancer; Segformer; Skin cancer; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T9L5XBXE","journalArticle","2024","Wang, JZ; Shimizu, K; Yoshie, O","Transformer Connections: Improving Segmentation in Blurred Near-Infrared Blood Vessel Image in Different Depth","IEEJ TRANSACTIONS ON ELECTRICAL AND ELECTRONIC ENGINEERING","","1931-4973","10.1002/tee.24146","","High-fidelity segmentation of blood vessels plays a pivotal role in numerous biomedical applications, such as injection assistance, cancer detection, various surgeries, and vein authentication. Near-infrared (NIR) transillumination imaging is an effective and safe method to visualize the subcutaneous blood vessel network. However, such images are severely blurred because of the light scattering in body tissues. Inspired by the Vision Transformer model, this paper proposes a novel deep learning network known as transformer connection (TRC)-Unet to capture global blurred and local clear correlations while using multi-layer attention. Our method mainly consists of two blocks, thereby aiming to remap skip connection information flow and fuse different domain features. Specifically, the TRC extracts global blurred information from multiple layers and suppresses scattering to increase the clarity of vessel features. Transformer feature fusion eliminates the domain gap between the highly semantic feature maps of the convolutional neural network backbone and the adaptive self-attention maps of TRCs. Benefiting from the long-range dependencies of transformers, we achieved competitive results in relation to various competing methods on different data sets, including retinal vessel segmentation, simulated blur image segmentation, and real NIR blood vessel image segmentation. Moreover, our method remarkably improved the segmentation results of simulated blur image data sets and a real NIR vessel image data set. The quantitative results of ablation studies and visualizations are also reported to demonstrate the superiority of the TRC-Unet design. (c) 2024 The Author(s). IEEJ Transactions on Electrical and Electronic Engineering published by Institute of Electrical Engineers of Japan and Wiley Periodicals LLC.","2024-11","2025-02-26 20:43:28","2025-02-26 20:43:28","","1828-1841","","11","19","","","","","","","","","","English","","","","WOS:001253931200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","artificial intelligence; feature fusion; image blur; medical imaging; near-infrared transillumination; NETWORK; SCATTERED-LIGHT; transformer connection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NQ2CWRZK","journalArticle","2024","Zeng, F; Ren, XT; Wu, Q","A fault diagnosis method for motor vibration signals incorporating Swin transformer with locally sensitive hash attention","MEASUREMENT SCIENCE AND TECHNOLOGY","","0957-0233","10.1088/1361-6501/ad1cc4","","Identification of motor vibration signals is one of the important tasks in motor fault diagnosis and predictive maintenance, and wavelet time-frequency diagram is a commonly used signal analysis method to extract the frequency and time characteristics of signals. In this paper, a method based on local sensitive hashing (LSH)-Swin transformer network is proposed for identifying the wavelet time-frequency diagrams of motor vibration signals to analyze the fault types. The traditional Swin transformer model converges slowly due to the smoothing of the attention distribution when dealing with data with sparse features, while the method proposed in this paper reduces the smoothing of the computed attention and enables the network to learn the key features better by introducing locally-sensitive hash attention in the network model, dividing the sequences in the input attention into multiple hash buckets, calculating the attention weights of only some of the vectors with a high degree of hash similarity, and by sampling discrete samples with the use of the Gumbel Softmax. The experimental results show that the method proposed in this paper has better recognition accuracy and higher computational efficiency compared with the traditional network when processing wavelet time-frequency maps of motor vibration signals, and its validation accuracy reaches 99.7%, the number of parameters also has a decrease of about 13%, and the training network to reach converged epochs is also faster. The method in this paper can provide an effective solution for the analysis and processing of motor vibration signals, and has certain application value in practical engineering.","2024-04-01","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","4","35","","","","","","","","","","English","","","","WOS:001148726900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","BEARING; ELEMENT; Gumbel Softmax; HILBERT; locally sensitive hash; motor fault diagnosis; Swin transformer; time-frequency diagram","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B5LRPZJD","journalArticle","2024","Suneera, CM; Prakash, J; Alaparthi, VS","Predicting semantic category of answers for question answering systems using transformers: a transfer learning approach","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-024-18609-x","","A question-answering (QA) system is a key application in the field of natural language processing (NLP) that provides relevant answers to user queries written in natural language. In factoid QA using knowledge bases, predicting the semantic category of answers, such as location, person, or numerical values, helps to reduce the search spaces and is an essential step in formal query construction for answer retrieval. However, finding the semantics in sequence data like questions is challenging. In this regard, Recursive neural networks based deep learning methods have been applied. But, they are inefficient in handling long-term dependencies. Recently, pre-trained language models employing transformers are proven effective and can generate context-dependent embedding for words and sentences from their encoders with attention mechanisms. However, to train an efficient transformer model for semantic category prediction requires a large dataset and high computational resources. Therefore, in this work, we employ a transfer learning approach using pre-trained transformer models by efficiently adapting them to predict the semantic category of answers from input questions. Here, embeddings from the encoders of the text-to-text transfer transformer (T5) model have been leveraged to obtain an efficient question representation and to train the classification model which is named as QcT5. Along with QcT5, an extensive experimental study on other recent transformer models - BERT, RoBERTa, DeBERTa, and XLNet, is conducted, and their performance is analyzed in various fine-tuning settings. Experimental results indicate that the QcT5 model significantly improves the performance compared to the selected state-of-the-art methods by achieving an f1-score of 98.7%, 89.9% on TREC-6, and TREC-50 datasets respectively.","2024-02-24","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","","","","","","","","","","","English","","","","WOS:001167880700013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","ATTENTION; CLASSIFICATION; Deep learning; Natural language processing; Question classification; Transfer learning; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LT7DKE2J","journalArticle","2024","Lee, S; Lee, M","MetaSwin: a unified meta vision transformer model for medical image segmentation","PEERJ COMPUTER SCIENCE","","2376-5992","10.7717/peerj-cs.1762","","Transformers have demonstrated significant promise for computer vision tasks. Particularly noteworthy is SwinUNETR, a model that employs vision transformers, which has made remarkable advancements in improving the process of segmenting medical images. Nevertheless, the efficacy of training process of SwinUNETR has been constrained by an extended training duration, a limitation primarily attributable to the integration of the attention mechanism within the architecture. In this article, to address this limitation, we introduce a novel framework, called the MetaSwin model. Drawing inspiration from the MetaFormer concept that uses other token mix operations, we propose a transformative modification by substituting attention-based components within SwinUNETR with a straightforward yet impactful spatial pooling operation. Additionally, we incorporate of Squeeze-and-Excitation (SE) blocks after each MetaSwin block of the encoder and into the decoder, which aims at segmentation performance. We evaluate our proposed MetaSwin model on two distinct medical datasets, namely BraTS 2023 and MICCAI 2015 BTCV, and conduct a comprehensive comparison with the two baselines, i.e., SwinUNETR and SwinUNETR+SE models. Our results emphasize the effectiveness of MetaSwin, showcasing its competitive edge against the baselines, utilizing a simple pooling operation and efficient SE blocks. MetaSwin's consistent and superior performance on the BTCV dataset, in comparison to SwinUNETR, is particularly significant. For instance, with a model size of 24, MetaSwin outperforms SwinUNETR's 76.58% Dice score using fewer parameters (15,407,384 vs 15,703,304) and a substantially reduced training time (300 vs 467 mins), achieving an improved Dice score of 79.12%. This research highlights the essential contribution of a simplified transformer framework, incorporating basic elements such as pooling and SE blocks, thus emphasizing their potential to guide the progression of medical segmentation models, without relying on complex attentionbased mechanisms.","2024-01-03","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","10","","","","","","","","","","English","","","","WOS:001140571000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Medical image segmentation; MRI; Spatial pooling; Transformer; Vision transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5J397JBA","journalArticle","2023","Goud, A; Garg, B","A novel framework for aspect based sentiment analysis using a hybrid BERT (HybBERT) model","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-023-17647-1","","Sentiment analysis has turned out to be a pivotal technique for fetching insights from data in textual form, and the prominent method that has emerged is aspect-based sentiment analysis, i.e., the ABSA. ABSA follows a dissection of textural content in order to associate emotions with its distinct elements. This paper reveals the efficacy of the ABSA model while exploring the different methodologies for tackling the intricate scenarios of ABSA, majorly escalating its importance. Lying amid the spectrum of techniques, transformer-based models like BERT, RoBERTa, and DistillBERT have gained substantial traction in sentiment analysis, text extraction, and natural language processing (NLP). Numerous research endeavours have covered the most important of these transformer models to enhance ABSA performance. To successfully bridge this gap between theory and practice, we brought into consideration a hybrid BERT model, which was termed HyBERT. This model blends the strengths of BERT, RoBERTa, and DistilBERT. Using data from the comprehensive Hugging Face dataset, our study meticulously processes the shared information to identify traits related to ABSA. It represents an extensive evaluation of multiple models within the ABSA framework. Each model's performance has been scrutinised and benchmarked against other models. The assessment encompasses a spectrum of evaluation metrics, which include accuracy, precision, recall, and F1-score, that provide a holistic view of performance. Our research aims to provide an important revelation: it reflects the remarkable advancement in ABSA performance, and the outcome reveals the importance of a hybrid transformer model that takes the approach beyond the depths of sentiment analysis.","2023-11-21","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","","","","","","","","","","","English","","","","WOS:001106086000004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Aspect Based Sentiment Analysis; BERT; DistilBERT Model; HybBERT; LSTM; Performance Evaluation; RoBERTa","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3PJ3JLSD","journalArticle","2025","Zhao, J; Yu, KX; Miao, Y; Wang, YS; Ma, Y; Zhang, JW; Zhao, JJ; Qiang, Y; Pei, B","Frequency domain nuances guided parallel transformer model for industrial anomaly localization","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2024.109852","","Unsupervised visual anomaly localization research has garnered significant attention in industrial component surface quality inspection tasks, particularly in realistic scenarios characterized by extreme imbalance between positive and negative samples. While several existing approaches endeavor to design hybrid architectures of convolutional neural networks (CNNs) and vision transformers (ViTs) to enhance the performance capability of unsupervised models, their overall effectiveness remains unstable. In this paper, we introduce a novel approach known as frequency domain nuances mining (FDNM), presenting a parallel transformer framework for anomaly localization. This framework leverages the inductive bias property of CNNs for local spatial understanding and the advantageous ViTs for global representation learning, enabling simultaneous capture of local correlations and global information. To further enhance the model's discriminative ability for subtle differences, we propose a frequency domain decoupling mechanism that exploits the frequency domain properties of images to improve model interpretability. Specifically, multi-granularity differences among frequency domain components serve as prior embeddings in FDNM, augmenting the potential feature representation of local details and global semantics. Furthermore, we synergistically train frequency domain invariant sampling loss and focal loss to balance the differential representation of features in the cross-frequency domain, leading to amore stable training process and more accurate anomaly localization results. Experiments conducted on the challenging 15-class industrial anomaly detection dataset validate the superiority of the proposed method. The image-level area under the receiver operating characteristic curve (AUROC), pixel-level AUROC and average precision (AP) scores of FDNM reach 99.0%, 98.7% and 68.7%, respectively, demonstrating comparable performance to state-of-the-art methods.","2025-02-15","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","142","","","","","","","","","","English","","","","WOS:001391660500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","Anomaly localization; Deep learning; Frequency domain decoupling; Industrial manufacturing; Unsupervised learning; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9JSR53PZ","journalArticle","2024","Wang, B; Zhang, MM; Ding, P; Yang, T; Jin, YH; Xu, YY","User re-identification via human mobility trajectories with siamese transformer networks","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-023-05234-8","","People are keen to share their geospatial locations to access social activities or services via mobile internet, which provides a new perspective for us to understand human mobility. However, the collection of individual mobility data arouses great concern about privacy among the public. Specifically, anonymized mobility records can be used to imply the routine behavior of individuals such that people can be re-identified even if they share footprints with different accounts or platforms. In this context, this study explored the probability of re-identifying anonymized users with advanced deep learning techniques, only leveraging their trajectories collected during a long time period. Such a user re-identification task realizes the identification of anonymous users by mining the characteristics of anonymous trajectories. Prevailing methods adopt deep sequential learning models, such as recurrent neural networks (RNNs), to capture the inherent similarity between any two trajectories, replacing classic statistical models. Despite that, RNN-like models usually fail in learning effective knowledge from longer sequences, such as one's visited locations in one week. To this end, we propose a novel model based on the Siamese Transformer network. The entire model comprises a discriminant module and retrieval module. The discriminant module uses the Transformer model to detect the characteristics of the trajectory and employs an improved attention mechanism to achieve similarity measurement between trajectories. The retrieval module helps the model deal with the matching between the anonymous trajectory and user by constructing a mapping relationship between users and locations. Extensive experiments on four real-world location-based social network datasets demonstrated that our method outperforms existing methods.","2024-01","2025-02-26 20:43:28","2025-02-26 20:43:28","","815-834","","1","54","","","","","","","","","","English","","","","WOS:001129312900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","Human mobility; Siamese network; Transformer; User re-identification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9R2KU7ZY","journalArticle","2023","Zhou, CD; Zhao, JH; Wang, HM; Yan, SN","Analysis of Core Loss Characteristics of Linear Phase-Shifting Transformer","ENERGY REPORTS","","2352-4847","10.1016/j.egyr.2023.05.125","","Linear phase-shifting transformer, as a new type of phase-shifting transformer, has the advantages of shifting phase at any angle, good expansibility, and easy modularization compared with the traditional core column phase-shifting transformer. To calculate the output performance such as the efficiency of linear phase-shifting transformer, the loss of linear phase-shifting transformer should be studied. The loss of linear phase-shifting transformer includes copper loss and core loss. Among them, the core loss has an important impact on linear phase-shifting transformer performance parameters such as efficiency and temperature rise, but there is a lack of relevant research at present. In this paper, based on the traditional separation model of ferromagnetic materials, a calculation method for linear phase-shifting transformer core loss is proposed. In this method, the loss coefficient of the linear phase-shifting transformer iron loss model is calculated by the least square method based on the calculation and analysis of the magnetic field law of the core by the time-step finite element method, and the loss coefficient is further modified by considering the influence of local hysteresis loop, non-sinusoidal magnetic field, and harmonic magnetic field. The linear phase-shifting transformer model based on finite element field-road coupling simulation is established, a lowpower experimental prototype is designed, and a multi-stack inverter system platform is built. The theoretical calculation is verified by simulation and experiment. Simulation and experimental results demonstrate the accuracy of the core loss calculation method presented in this paper. (c) 2023 The Author(s). Published by Elsevier Ltd. This is an open access article under theCCBY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).","2023-10","2025-02-26 20:43:28","2025-02-26 20:43:28","","702-711","","","9","","","","","","","","","","English","","","","WOS:001124237300078","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","Core loss; Finite element; IRON LOSSES; Linear phase-shifting transformer; Loss of separation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZYA4P7R9","journalArticle","2023","Li, BL; Wang, J; Guo, ZF; Li, Y","Automatic detection of schizophrenia based on spatial-temporal feature mapping and LeViT with EEG signals","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2023.119969","","Electroencephalography (EEG) signals, which record brain activity, are known to be very useful in diagnosing brain-related conditions. However, manual examination of these EEG signals has various limitations, including reliance on physician experience and subjectivity of assessment. Therefore, an automatic EEG recognition system would be useful to assist neurologists in the early screening and diagnosis of schizophrenia. In this study, we proposed a novel EEG data mapping method that eliminated the process of manual feature design and pioneered the use of Vision Transformer as feature extractor and classifier for early identification of schizophrenia. First, the raw EEG data were pre-processed, including artifact removal and normalization. Then, we mapped 1D EEG sequences into 3D picture form based on EEG acquisition electrode distribution maps and different brain lobe partitions while preserving the temporal and spatial nature of EEG data. Afterward, we used a lightweight Vision Transformer model LeViT for recognition, which has an architecture combining convolutional layers and attention mechanisms that facilitate learning spatial-temporal features in the mapped 3D pictures. Finally, we conducted extensive experiments on two evaluation criteria: subject-dependent and subject-independent. Considering the generalization of the model, we used ten-fold cross-validation and leave -one-subject-out cross-validation to evaluate the performance of the model, respectively. The average accuracy for subject-independent is 98.99% and the average accuracy for subject-dependent is 85.04%. The results show that the proposed framework may serve as a diagnostic tool to assist clinicians in the detection of EEG pathology for early treatment.","2023-08-15","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","224","","","","","","","","","","English","","","","WOS:000968781100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","CLASSIFICATION; Classification method; Deep learning; EEG signals; Schizophrenia; SYSTEM; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"62D8B89P","journalArticle","2023","Esenboga, B; Demirdelen, T","Soft-Switching Smart Transformer Design and Application for Photovoltaic Integrated Smart City Power Distribution","SUSTAINABILITY","","2071-1050","10.3390/su15010032","","Smart city power distributions have become promising technologies to meet the demand for energy in developed countries. However, increase in smart grids causes several power quality problems on the smart grid, in particular, current and voltage harmonic distortions, sudden voltage sag and swells, fault current, and isolation deterioration. Smart transformers are potential solutions to improve the power quality on the electric grid. They present energy efficiency, ensure grid reliability and power flow control, voltage regulation, bidirectional power flow, fault current limiting, harmonic blocking, and galvanic isolation. Therefore, this paper offers an optimal selection of a three-stage (AC-DC-DC-AC) smart transformer model and power control strategy for solar PV power plant integrated smart grids. The topology of the rectifier, isolated bidirectional converter, and inverter has soft-switching features. This enables low conduction loss, low electromagnetic interference (EMI), high efficiency, achievable zero-voltage switching for converters, and zero-current switching for electrical auxiliary systems. Operation strategies of the proposed ST, PWM control, voltage, and current control between converters, including a medium-voltage (MV) high-frequency transformer to realize a 10 kVA, 450 Vdc to 220 Vdc, or 220 Vac ST, are presented. Significantly, the ST prototype achieves 96.7% conversion efficiency thanks to its control strategy, even under unstable power generation conditions from the solar PV plant. Experimental results obtained on the 344 Vac 10.4 A load current validates the dv/dt rate 6.8 kV/us. The dynamic and experimental results of the proposed bidirectional smart transformer demonstrate the success in preventing power quality problems for photovoltaic integrated smart city power distribution.","2023-01","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","1","15","","","","","","","","","","English","","","","WOS:000908535500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","CASCADED MULTILEVEL CONVERTER; DC-DC CONVERTER; DUAL-ACTIVE-BRIDGE; LINK; power distribution; power quality; smart city; smart transformer; solar PV; SOLID-STATE TRANSFORMER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KZ36XLP7","journalArticle","2022","Xie, J; Zhang, J; Sun, JY; Ma, Z; Qin, LN; Li, GL; Zhou, HH; Zhan, Y","A Transformer-Based Approach Combining Deep Learning Network and Spatial-Temporal Information for Raw EEG Classification","IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING","","1534-4320","10.1109/TNSRE.2022.3194600","","The attention mechanism of the Transformer has the advantage of extracting feature correlation in the long-sequence data and visualizing the model. As time-series data, the spatial and temporal dependencies of the EEG signals between the time points and the different channels contain important information for accurate classification. So far, Transformer-based approaches have not been widely explored in motor-imagery EEG classification and visualization, especially lacking general models based on cross-individual validation. Taking advantage of the Transformer model and the spatial-temporal characteristics of the EEG signals, we designed Transformer-based models for classifications of motor imagery EEG based on the PhysioNet dataset. With 3s EEG data, our models obtained the best classification accuracy of 83.31%, 74.44%, and 64.22% on two-, three-, and four-class motor-imagery tasks in cross-individual validation, which outperformed other state-of-the-art models by 0.88%, 2.11%, and 1.06%. The inclusion of the positional embedding modules in the Transformer could improve the EEG classification performance. Furthermore, the visualization results of attention weights provided insights into the working mechanism of the Transformer-based networks during motor imagery tasks. The topography of the attention weights revealed a pattern of event-related desynchronization (ERD) which was consistent with the results from the spectral analysis of Mu and beta rhythm over the sensorimotor areas. Together, our deep learning methods not only provide novel and powerful tools for classifying and understanding EEG data but also have broad applications for brain-computer interface (BCI) systems.","2022","2025-02-26 20:43:28","2025-02-26 20:43:28","","2126-2136","","","30","","","","","","","","","","English","","","","WOS:000836657700004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;101<br/>Total Times Cited:&nbsp;&nbsp;102<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","attention mechanism; Brain modeling; brain-computer interface (BCI); CNN; Data models; Deep learning; EEG classification; Electroencephalography; Feature extraction; Motor imagery (MI); Task analysis; transformer; Transformers; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NIMT7HUE","journalArticle","2024","Zeng, CY; Li, K; Wang, ZF","ENFformer: Long-short term representation of electric network frequency for audio detection","KNOWLEDGE-BASED SYSTEMS","","0950-7051","10.1016/j.knosys.2024.111938","","Detecting digital audio tampering is essential for ensuring judicial fairness and societal security. Traditional methods, primarily based on Electric Network Frequency (ENF), have been limited by their reliance on singular, static features, which overlook critical temporal dynamics inherent in ENF data. This results in suboptimal detection accuracy. Addressing these limitations, this paper introduces a novel transformer model, ENFformer, designed for the detection of digital audio tampering by leveraging both short and long-term temporal features of ENF data. Initially, the ENFformer model extracts traditional zero -order and first -order phase features using discrete Fourier transforms ( DFT 0 and DFT 1 ), along with frequency features obtained through the Hilbert transform. These features are processed using a frame -based algorithm to develop their temporal counterparts. To enhance feature extraction, the model employs a two -layer one-dimensional Convolutional Long Short -Term Memory (ConvLSTM) network to assimilate short-term temporal features, followed by a Bidirectional Long Short -Term Memory (BiLSTM) network for long-term feature integration. A branch attention mechanism then synergizes these long-term features, which are further refined by a transformer module for accurate tampered audio identification. Our empirical evaluations on the Carioca and ENF-EDIT1 databases demonstrate that ENFformer achieves detection accuracies of 97.33% and 93.50% respectively, surpassing existing state-of-theart methods. These results confirm the effectiveness of our approach, which significantly advances the field of digital audio tampering detection by incorporating a comprehensive analysis of temporal information in ENF features. The source code of this study is publicly available at https://github.com/CCNUZFW/ENFformer.","2024-08-03","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","297","","","","","","","","","","English","","","","WOS:001247522200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","Audio tampering detection; AUTHENTICITY; BiLSTM; Electric network frequency; Feature fusion; IDENTIFICATION; RECORDINGS; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FBU3DES8","journalArticle","2024","Zisser, M; Aran, D","Transformer-based time-to-event prediction for chronic kidney disease deterioration","JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION","","1067-5027","10.1093/jamia/ocae025","","Objective Deep-learning techniques, particularly the Transformer model, have shown great potential in enhancing the prediction performance of longitudinal health records. Previous methods focused on fixed-time risk prediction, however, time-to-event prediction is often more appropriate for clinical scenarios. Here, we present STRAFE, a generalizable survival analysis Transformer-based architecture for electronic health records.Materials and Methods The input for STRAFE is a sequence of visits with SNOMED-CT codes in OMOP-CDM format. A Transformer-based architecture was developed to calculate probabilities of the occurrence of the event in each of 48 months. Performance was evaluated using a real-world claims dataset of over 130 000 individuals with stage 3 chronic kidney disease (CKD).Results STRAFE showed improved mean absolute error (MAE) compared to other time-to-event algorithms in predicting the time to deterioration to stage 5 CKD. Additionally, STRAFE showed an improved area under the receiver operating curve compared to binary outcome algorithms. We show that STRAFE predictions can improve the positive predictive value of high-risk patients by 3-fold. Finally, we suggest a novel visualization approach to predictions on a per-patient basis.Discussion Time-to-event predictions are the most appropriate approach for clinical predictions. Our deep-learning algorithm outperformed not only other time-to-event prediction algorithms but also fixed-time algorithms, possibly due to its ability to train on censored data. We demonstrated possible clinical usage by identifying the highest-risk patients.Conclusions The ability to accurately identify patients at high risk and prioritize their needs can result in improved health outcomes, reduced costs, and more efficient use of resources.","2024-04-03","2025-02-26 20:43:28","2025-02-26 20:43:28","","980-990","","4","31","","","","","","","","","","English","","","","WOS:001160703300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","chronic kidney disease; clinical data; deep-learning; SURVIVAL; survival analysis; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NDKFRQ68","journalArticle","2022","Shilyashki, G; Pfützner, H; Bengtsson, C; Huber, E","Time-averaged and instantaneous magnetic loss characteristics of different products of electrical steel for frequencies of 16 2/3 Hz up to 500 Hz","IET ELECTRIC POWER APPLICATIONS","","1751-8660","10.1049/elp2.12173","","Traditionally, products of electrical SiFe steel are focussed on applications for frequencies of 50-Hz. However, the recent developments of electric drive systems yielded a strong extension of the range from f = 16 2/3 Hz up to ca. 500 Hz. In spite of high industrial relevance, the literature offers the corresponding data on the material's magnetic energy losses in very rare ways. This paper reports a first comparative, multi-parametric study on eight different steel products that comprise non-oriented steels (NO), grain-oriented steels (GO) and scribed grain-oriented steels (SGO). Consistently at IEC-standardized samples, they were analysed for the whole frequency range that was split into low frequency (LF) and medium frequency (MF), with 80 Hz as the border. Data is presented on time-averaged total losses P, on the corresponding hysteresis losses P-H and eddy current losses P-E. LF proved to be governed by P-H and MF rather by P-E, however, with strong variations. Further, instantaneous magnetization power functions p(phi) were determined for basic insights into the involved temporal developments of energy dissipation. GO-steels yielded profiles close to rectified co-sinus functions that can be fully attributed to dissipative losses. On the other hand, p(t) of NO-steels and SGO-steels prove to include negative segments that reflect potential energy power, in the course of alignments of atomic moments in instants of high induction. Examples of industrial relevance of the accumulated data are steel production technology, product categorization, failure tracing and energy conversion.","2022-05","2025-02-26 20:43:28","2025-02-26 20:43:28","","525-535","","5","16","","","","","","","","","","English","","","","WOS:000747865600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","eddy current effects; grain orientation; hysteresis losses; instantaneous losses; instantaneous power; magnetization power; silicon iron; TRANSFORMER MODEL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ETBZVR3A","journalArticle","2025","Khambhawala, A; Lee, CH; Pahari, S; Nancarrow, P; Jabbar, NA; El-Halwagi, MM; Kwon, JSI","Advanced transformer models for structure-property relationship predictions of ionic liquid melting points","CHEMICAL ENGINEERING JOURNAL","","1385-8947","10.1016/j.cej.2024.158578","","Ionic liquids (ILs), recognized for their low melting points and distinct properties, have emerged as eco-friendly alternatives to volatile organic compounds and are increasingly used in fields like green chemistry, electrochemical devices, and pharmaceuticals. However, predicting the melting points of ILs poses a significant challenge due to their complex non-linear intermolecular interactions. Traditional methods, like molecular dynamics simulations require high computational time and costs along with the need for specialized force fields, which have given the rise to quantitative structure property relationship models. These models offer quick predictions but often fall short in accuracy and generalizability due to them needing special formulations or additions to account for the presence of different functional groups, thus struggling to fully capture the nuances of ionic liquid behavior. This limits their predictive effectiveness across varied IL systems. To address these challenges, we developed an encoder-based transformer model tailored for accurately predicting the melting points of ILs. Leveraging advanced attention mechanisms originally devised for natural language processing, this model discerns the contextual relationships among atoms within molecules. Specifically, we initially pre-trained the model on an extensive dataset of 1.8 billion molecules, followed by finetuning on a targeted dataset of ILs. This dualphase training has allowed the model to capture complex chemical patterns and dependencies. In this work, our model achieved a remarkable R2 score of 0.98 and a mean absolute error of 10.3 K, demonstrating its superior predictive accuracy over conventional ML models. This performance not only underscores the capability of model in enhancing the practical use of ILs across industries but also demonstrates its capacity to generalize across diverse chemical datasets.","2025-01-01","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","503","","","","","","","","","","English","","","","WOS:001390564000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","(QSPR); DATABASE; DESCRIPTORS; Ionic liquids; Melting point; NEURAL-NETWORK; QSPR CORRELATION; Quantitative strutcure property relationship; TEMPERATURE; Transformer; WORMLIKE MICELLES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I5RI77TY","journalArticle","2024","Giesa, N; Sekutowicz, M; Rubarth, K; Spies, CD; Balzer, F; Haufe, S; Boie, SD","Applying a transformer architecture to intraoperative temporal dynamics improves the prediction of postoperative delirium","COMMUNICATIONS MEDICINE","","2730-664X","10.1038/s43856-024-00681-x","","BackgroundPatients who experienced postoperative delirium (POD) are at higher risk of poor outcomes like dementia or death. Previous machine learning models predicting POD mostly relied on time-aggregated features. We aimed to assess the potential of temporal patterns in clinical parameters during surgeries to predict POD.MethodsLong short-term memory (LSTM) and transformer models, directly consuming time series, were compared to multi-layer perceptrons (MLPs) trained on time-aggregated features. We also fitted hybrid models, fusing either LSTM or transformer models with MLPs. Univariate Spearman's rank correlations and linear mixed-effect models establish the importance of individual features that we compared to transformers' attention weights.ResultsBest performance is achieved by a transformer architecture ingesting 30 min of intraoperative parameter sequences. Systolic invasive blood pressure and given opioids mark the most important input variables, in line with univariate feature importances.ConclusionsIntraoperative temporal dynamics of clinical parameters, exploited by a transformer architecture named TRAPOD, are critical for the accurate prediction of POD. Delirium manifests as confusion and a lack of awareness. Postoperative delirium is a severe medical complication that can occur after surgery. Currently, there is no specialized medical treatment available, but early detection can be useful to implement preventative measures. In this study, we applied various computational models to clinical data such as repeated blood pressure recordings. Data recorded during the first half of surgeries were most predictive for postoperative delirium. This information could be used to better focus preventative measures after surgery, such as transferring vulnerable patients to quieter wards facilitating recovery. Giesa et al. train and evaluate multiple deep learning architectures on multivariable clinical time series for the prediction of postoperative delirium (POD). An adapted transformer model named as TRAPOD performs best, making use of temporal intraoperative dynamics.","2024-11-27","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","1","4","","","","","","","","","","English","","","","WOS:001365237500002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;108</p>","","","MODELS; RISK; TESTS; VALIDATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6RX2S379","journalArticle","2024","Jia, GJ; Zhang, X; Shen, YJ; Huang, ND","Intermittent multivariate time series spindle thermal error prediction under wide environmental temperature ranges and diverse scenario conditions","INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY","","0268-3768","10.1007/s00170-024-13652-2","","As the integration of mechanical engineering and deep learning fields becomes increasingly intertwined, the application of experimental thermal error modeling in intelligent manufacturing has gained significant importance. In this paper, the issue of spindle thermal error is treated as a multivariate time series problem due to the thermal transfer characteristics. This study aims to address the challenge of modeling intermittent multivariate time series spindle thermal errors under a wide range of environmental temperatures and various operational scenarios. To tackle this challenge, a substantial volume of experimental data, capable of effectively reflecting the patterns of spindle thermal error variations, was collected through experiments conducted at multiple speeds and under various operational scenarios. Subsequently, the acquired thermal error data underwent intermittent multivariate time series transformation (IMTS) to suit the serialized deep learning model. The study introduces the Crossformer model into the field of thermal error modeling for the first time, which is a variant of the Transformer model. The Crossformer model exhibits remarkable adaptability to temporal aspects while effectively maintaining its focus on data features. Ultimately, this study resulted in the development of the IMTS-CrossformerR experimental thermal error model. Throughout the research, a comprehensive examination of various models was undertaken, including two traditional Transformer models and other thermal error deep learning and machine learning models. The results indicate that the proposed model outperforms its counterparts across multiple model metrics and predictive capabilities. Particularly noteworthy is its substantial improvement in the range (+/- 5) ratio of residual fluctuations reaching 95.7%, a key engineering metric.","2024-06","2025-02-26 20:43:28","2025-02-26 20:43:28","","4625-4643","","9-10","132","","","","","","","","","","English","","","","WOS:001207628600005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","COMPENSATION; Deep learning; Diverse scenario conditions; Experimental model; Spindle thermal error; Time serialization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4FUFRGTG","journalArticle","2024","Paul, S; Gupta, A; Moorthi, SM; Dhar, D","C-LiSA: A Hierarchical Hybrid Transformer Model Using Orthogonal Cross Attention for Satellite Image Cloud Segmentation","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2024.3394929","","Clouds in optical satellite images are a major concern since their presence hinders the ability to carry out accurate analysis as well as processing. Therefore, deriving accurate pixel-wise cloud masks is a key task in optical remote sensing. Several traditional as well as deep-learning algorithms have emerged to address this problem. However, the task of deriving accurate cloud masks from a variety of satellite images remains elusive due to the presence of confusing spectral signatures and changes in the properties of imaging sensors. In this article, we introduce a deep-learning model based on a hybrid transformer architecture for effective cloud mask generation named C-LiSA - cloud segmentation via the Lipschitz stable attention network. We propose two key attention mechanisms - dual orthogonal self-attention (DOSA) for handling confusing spectral signatures, and the hierarchical cross-channel attention (HC2A) model for effectively highlighting cloud-specific features during the cloud segmentation process. To validate the effectiveness of these mechanisms, we carry out theoretical and empirical Lipschitz stability analysis. We design the whole setup under an adversarial setting in the presence of Lov & aacute;sz-Softmax loss. We demonstrate both qualitative and quantitative outcomes for multiple satellite image datasets including Landsat-8, Sentinel-2, and Cartosat-2S. Our comparative study shows that the proposed model performs better compared to other state-of-the-art methods while providing better generalization across different datasets. We also showcase ablation studies to endorse our choices corresponding to different architectural elements and objective functions.","2024","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","62","","","","","","","","","","English","","","","WOS:001227320500019","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Cloud segmentation; Clouds; cross-attention; DETECTION ALGORITHM; Feature extraction; hybrid transformer; Image segmentation; Lipschitz stability; orthogonal attention; Remote sensing; Satellite images; SHADOW; Task analysis; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3F5X88Z6","journalArticle","2024","Tat, O; Aydogan, I","Discovering Hidden Patterns: Applying Topic Modeling in Qualitative Research","JOURNAL OF MEASUREMENT AND EVALUATION IN EDUCATION AND PSYCHOLOGY-EPOD","","1309-6575","10.21031/epod.1539694","","In qualitative studies, researchers must devote a significant amount of time and effort to extracting meaningful themes from large sets of texts and examining the links between themes, which are frequently done manually. The availability of natural language models has enabled the application of a wide range of techniques to automatically detecting hierarchy, linkages, and latent themes in texts. This paper aims to investigate the coherence of the topics acquired from the analysis with the predefined themes, as well as the hierarchy between topics, the similarity, and the proximity-distance between topics by means of the topic model based on BERTopic using unstructured qualitative data. This paper aims to investigate the coherence of the topics acquired from the analysis with the predefined themes, as well as the hierarchy between topics, the similarity, and the proximity-distance between topics by means of the topic model based on BERTopic using unstructured qualitative data. The qualitative data for this study was gathered from 106 students engaged in a university-run pedagogical formation certificate program. In BERTopic procedure, the paraphrase-multilingual-MiniLM-L12-v2 model was used as the sentence transformer model, UMAP was used as the dimension reduction method, and HDBSCAN algorithm as the clustering method. It was found that BERTopic successfully identified six topics corresponding to the six predicted themes in unstructured texts. Moreover, 74% of the texts containing some certain themes could be classified accurately. The algorithm effectively discerned which themes were analogous and which had significant distinctions from others. It was concluded that BERTopic is a procedure which is capable of identifying themes that researchers may not notice, depending on the data density in qualitative data analysis, and has the potential to enable qualitative research to reach more detailed findings.","2024","2025-02-26 20:43:28","2025-02-26 20:43:28","","247-259","","3","15","","","","","","","","","","English","","","","WOS:001356202700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","BERTopic; natural language processing; topic modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LF4AQHZT","journalArticle","2023","Yang, LQ; Fomel, S; Wang, SD; Chen, XH; Chen, W; Saad, OM; Chen, YK","Porosity and permeability prediction using a transformer and periodic long short-term network","GEOPHYSICS","","0016-8033","10.1190/GEO2022-0150.1","","Effective reservoir parameter prediction is important for subsur-face characterization and understanding fluid migration. However, conventional methods for obtaining porosity and permeability are based on either core measurements or mathematical/petrophysical modeling, which are expensive or inefficient. In this study, we develop a reliable and low-cost deep learning (DL) framework for reservoir permeability and porosity prediction from real log-ging data at different regions. We leverage an advanced learning architecture (i.e., the transformer model) and design a new regres-sion network (RPTransformer) that is sensitive to the depth period change of the logging data. The RPTransformer is composed of 1D convolutional, long short-term memory (LSTM), and trans-former layers. First, we use a 1D convolutional layer for the first layer of the network to extract significant features from the logging data. Then, the nonlinear mapping relationships between logging data and reservoir parameters are established using several LSTM layers with a period parameter. Afterward, we use the encoder in the vision transformer with the self-attention mecha-nism to further extract logging data features. The developed net-work is a data-driven supervised learning framework and indicates highly accurate and robust prediction results when applied to dif-ferent geographic regions. To demonstrate the reliable prediction performance of our network, we compare it with several classic machine learning and state-of-the-art DL methods, e.g., random forest, multilayer LSTM, and long short-term time-series network (LSTNet). More importantly, we find the generalization and un-certainty of the network in real-world applications through com-prehensive numerical experiments.","2023-01","2025-02-26 20:43:28","2025-02-26 20:43:28","","WA293-WA308","","1","88","","","","","","","","","","English","","","","WOS:000996181600005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;20<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","ALGORITHM; ARCHITECTURE; ARTIFICIAL NEURAL-NETWORK; FIELD; LOGS; MODEL; RESERVOIR; SANDSTONE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NQGP7MJA","journalArticle","2022","Habets, PC; van IJzendoorn, DGP; Vinkers, CH; Härmark, L; de Vries, LC; Otte, WM","Development and validation of a machine-learning algorithm to predict the relevance of scientific articles within the field of teratology","REPRODUCTIVE TOXICOLOGY","","0890-6238","10.1016/j.reprotox.2022.09.001","","The Dutch Teratology Information Service Lareb counsels healthcare professionals and patients about medication use during pregnancy and lactation. To keep the evidence up to date, employees perform a standardized weekly PubMed query where relevant literature is identified manually. We aimed to develop an accurate machinelearning algorithm to predict the relevance of PubMed entries, thereby reducing the labor-intensive task of manually screening the articles. We fine-tuned a pre-trained natural language processing transformer model to identify relevant entries. We split 15,540 labeled entries into case-control-balanced train, validation, and test datasets. Additionally, we externally validated the model prospectively with 1288 labeled entries obtained from weekly queries after developing the model. This dataset was also independently labeled by a team of six experienced human raters to evaluate our model's performance. The validation of our machine learning model on the retrospectively collected outheld dataset obtained an area under the sensitivity-versus-specificity curve of 89.3 % (CI: 88.2- 90.4). In the prospective external validation of the model, our model classified relevant literature with a sensitivity versus specificity curve area of 87.4 % (CI: 85.0-89.8). Our model achieved a higher sensitivity than the human raters' team without sacrificing too much specificity. The team of human raters showed weak to moderate levels of agreement in their article classifications (kappa range 0.40-0.64). The human selection of the latest relevant literature is indispensable to keep the teratology information up to date. We show that automatic preselection of relevant abstracts using machine learning is possible without sacrificing the selection performance.","2022-10","2025-02-26 20:43:28","2025-02-26 20:43:28","","150-154","","","113","","","","","","","","","","English","","","","WOS:000864455200002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;12</p>","","","Deep learning; Literature screening; Pharmacovigilance; TIS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"43B5AY5A","journalArticle","2024","Hu, QY; Zhang, Q; Lu, H; Wu, S; Zhou, YX; Huang, QY; Chen, HX; Chen, YC; Ni, Z","Contactless Arterial Blood Pressure Waveform Monitoring with mmWave Radar","PROCEEDINGS OF THE ACM ON INTERACTIVE MOBILE WEARABLE AND UBIQUITOUS TECHNOLOGIES-IMWUT","","2474-9567","10.1145/3699781","","Arterial blood pressure waveform (ABPW) offers comprehensive insights into cardiovascular health compared to discrete blood pressure measurements. However, accurately estimating shapes and pressure values of ABPW points in a beat-to-beat manner poses significant challenges. Current ABPW monitoring methods require invasive procedures or continuous skin contact, which are inconvenient and unsatisfactory. Thus, we propose WaveBP, the first contactless ABPW monitoring system utilizing a commercial mmWave radar, driven by the understanding that cardiac information serves as an implicit bridge between mmWave signals and ABPW based on a hemodynamics analysis model. To preserve waveform details, we design a hybrid Transformer model called mmFormer, incorporated with spatially-informed shortcuts. mmFormer enables consistent sequence-to-sequence transformations while accommodating different levels of personalization efforts. To mitigate the inherent instability of mmWave signals, we develop a beamforming-based data augmentation approach that has been empirically and theoretically proven to enhance robustness with multiple spatial observations. Additionally, we introduce a cross-modality knowledge transfer framework to fuse knowledge from cardiac modalities (ECG/PPG) with vibrations captured in mmWave reflections, improving accuracy without requiring extra deployment overhead. Extensive evaluations conducted on 43 subjects using a leave-one-subject-out setup validate that WaveBP achieves a high waveform correlation of 0.903 and exhibits a low (mean +/- standard deviation) error of point-level measurements at (-0.14 +/- 7.48) mmHg, which could be further reduced by subject-specific specialization. WaveBP demonstrates remarkable performance under challenging scenarios and exhibits potential for detailed cardiac estimations, as evidenced by our case studies on relative cardiac output estimation and cardiac abnormality detection.","2024-12","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","4","8","","","","","","","","","","English","","","","WOS:001386280200004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","Arterial blood pressure waveform; contactless sensing; mmWave; neural network; PULSE TRANSIT-TIME","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K6N8BKID","journalArticle","2024","Yazdanpanah, O; Park, M; Chang, MW; Chae, Y","Mastering seismic time series response predictions using an attention-Mamba transformer model for bridge bearings and piers across varied testing conditions","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-79195-4","","This research introduces an advanced method for predicting seismic responses and hysteresis curves of instrumented bridge piers and bearings under various loading conditions, leaning solely on a single deep learning architecture and the same hyperparameters tuning. Test specimens are subjected to ground accelerations including vertical seismic loads and axial forces. To accurately capture peak values, particularly on the negative side of the hysteresis loop (unloading region), the model employs a stacked deep architecture. A key component to overcome the challenges is the self-attention-Mamba-driven transformer layer, which enhances the model's ability to capture long-range dependencies in seismic data. This layer works in conjunction with other deep learning techniques to ensure robust and precise predictions. Implemented with Python's Keras functional API, the model processes inputs like ground accelerations, actuator loads, effective height, moment of inertia, and superstructure mass. The model is evaluated with a dataset of 95 real-time hybrid simulation (RTHS) tests for lead rubber bearings, 29 RTHS tests for bridge piers, and 17 cyclic tests (10 fast and 7 slow). Extensive hyperparameter tuning demonstrates the model's proficiency to capture hysteresis and residual deformations accurately. Achieving an impressive correlation with experimentally measured values, ranging from 88.1 to 98.9%, and a reasonable dissipated energy error ratio are notable. The deep learning model reduces the need for additional tests, offering time and cost savings, and provides rapid, and accurate insights into bridge behavior. This supports timely and precise bridge design and aids decision-makers during emergencies.","2024-11-29","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","1","14","","","","","","","","","","English","","","","WOS:001367889000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Attention-Mamba transformer; Bidirectional CuDNNLSTM network; Bridge piers and bearings; CNN; Hybrid loss and activation function; Seismic response prediction; SLOW","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C5YKXTFW","journalArticle","2024","Zheng, XF; Tomiura, Y","A BERT-based pretraining model for extracting molecular structural information from a SMILES sequence","JOURNAL OF CHEMINFORMATICS","","1758-2946","10.1186/s13321-024-00848-7","","Among the various molecular properties and their combinations, it is a costly process to obtain the desired molecular properties through theory or experiment. Using machine learning to analyze molecular structure features and to predict molecular properties is a potentially efficient alternative for accelerating the prediction of molecular properties. In this study, we analyze molecular properties through the molecular structure from the perspective of machine learning. We use SMILES sequences as inputs to an artificial neural network in extracting molecular structural features and predicting molecular properties. A SMILES sequence comprises symbols representing molecular structures. To address the problem that a SMILES sequence is different from actual molecular structural data, we propose a pretraining model for a SMILES sequence based on the BERT model, which is widely used in natural language processing, such that the model learns to extract the molecular structural information contained in the SMILES sequence. In an experiment, we first pretrain the proposed model with 100,000 SMILES sequences and then use the pretrained model to predict molecular properties on 22 data sets and the odor characteristics of molecules (98 types of odor descriptor). The experimental results show that our proposed pretraining model effectively improves the performance of molecular property predictionScientific contribution The 2-encoder pretraining is proposed by focusing on the lower dependency of symbols to the contextual environment in a SMILES than one in a natural language sentence and the corresponding of one compound to multiple SMILES sequences. The model pretrained with 2-encoder shows higher robustness in tasks of molecular properties prediction compared to BERT which is adept at natural language.","2024-06-19","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","1","16","","","","","","","","","","English","","","","WOS:001250356600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","ADMET molecular properties prediction; BERT; Odor descriptors; Pretraining; SMILES; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2XI7RTNR","journalArticle","2024","Xu, J; Ma, B; Chen, WW; Shan, CW","AsdinNorm: A Single-Source Domain Generalization Method for the Remaining Useful Life Prediction of Bearings","LUBRICANTS","","2075-4442","10.3390/lubricants12050175","","The remaining useful life (RUL) of bearings is vital for the manipulation and maintenance of industrial machines. The existing domain adaptive methods have achieved major achievements in predicting RUL to tackle the problem of data distribution discrepancy between training and testing sets. However, they are powerless when the target bearing data are not available or unknown for model training. To address this issue, we propose a single-source domain generalization method for RUL prediction of unknown bearings, termed as the adaptive stage division and parallel reversible instance normalization model. First, we develop the instance normalization of the vibration data from bearings to increase data distribution diversity. Then, we propose an adaptive threshold-based degradation point identification method to divide the healthy and degradation stages of the run-to-failure vibration data. Next, the data from degradation stages are selected as training sets to facilitate the RUL prediction of the model. Finally, we combine instance normalization and instance denormalization of the bearing data into a unified GRU-based RUL prediction network for the purpose of leveraging the distribution bias in instance normalization and improving the generalization performance of the model. We use two public datasets to verify the proposed method. The experimental results demonstrate that, in the IEEE PHM Challenge 2012 dataset experiments, the prediction accuracy of our model with the average RMSE value is 1.44, which is 11% superior to that of the suboptimal comparison model (Transformer model). It proves that our model trained on one-bearing data achieves state-of-the-art performance in terms of prediction accuracy on multiple bearings.","2024-05","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","5","12","","","","","","","","","","English","","","","WOS:001232874400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","adaptive threshold; reversible instance normalization; RUL prediction; stage division","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HQ8MI35J","journalArticle","2024","Bergman, N; Yitzhaky, Y; Halachmi, I","Biometric identification of dairy cows via real-time facial recognition","ANIMAL","","1751-7311","10.1016/j.animal.2024.101079","","Biometrics methods, which currently identify humans, can potentially identify dairy cows. Given that animal movements cannot be easily controlled, identification accuracy and system robustness are challenging when deploying an animal biometrics recognition system on a real farm. Our proposed method performs multiple -cow face detection and face classification from videos by adjusting recent state-ofthe-art deep -learning methods. As part of this study, a system was designed and installed at four meters above a feeding zone at the Volcani Institute's dairy farm. Two datasets were acquired and annotated, one for facial detection and the second for facial classification of 77 cows. We achieved for facial detection a mean average precision (at Intersection over Union of 0.5) of 97.8% using the YOLOv5 algorithm, and facial classification accuracy of 96.3% using a Vision -Transformer model with a unique loss -function borrowed from human facial recognition. Our combined system can process video frames with 10 cows' faces, localize their faces, and correctly classify their identities in less than 20 ms per frame. Thus, up to 50 frames per second video files can be processed with our system in real-time at a dairy farm. Our method efficiently performs real-time facial detection and recognition on multiple cow faces using deep neural networks, achieving a high precision in real-time operation. These qualities can make the proposed system a valuable tool for an automatic biometric cow recognition on farms. (c) 2024 The Author(s). Published by Elsevier B.V. on behalf of The Animal Consortium. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).","2024-03","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","3","18","","","","","","","","","","English","","","","WOS:001197006500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","ACCURACY; CATTLE; Computer vision; Deep learning; Farm management; Feeding behaviour; FEEDING-BEHAVIOR; Real-time monitoring","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GWBB58PB","journalArticle","2024","Li, HX; Cai, ZY; Wang, JY; Tang, JN; Ding, WP; Lin, CT; Shi, Y","FedTP: Federated Learning by Transformer Personalization","IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS","","2162-237X","10.1109/TNNLS.2023.3269062","","Federated learning is an emerging learning paradigm where multiple clients collaboratively train a machine learning model in a privacy-preserving manner. Personalized federated learning extends this paradigm to overcome heterogeneity across clients by learning personalized models. Recently, there have been some initial attempts to apply Transformers to federated learning. However, the impacts of federated learning algorithms on self-attention have not yet been studied. This paper investigates this relationship and reveals that federated averaging algorithms actually have a negative impact on self-attention where there is data heterogeneity. These impacts limit the capabilities of the Transformer model in federated learning settings. Based on this, we propose FedTP, a novel Transformer-based federated learning framework that learns personalized self-attention for each client while aggregating the other parameters among the clients. Instead of using a vanilla personalization mechanism that maintains personalized self-attention layers of each client locally, we develop a learn-to-personalize mechanism to further encourage the cooperation among clients and to increase the scablability and generalization of FedTP. Specifically, the learn-to-personalize is realized by learning a hypernetwork on the server that outputs the personalized projection matrices of self-attention layers to generate client-wise queries, keys and values. Furthermore, we present the generalization bound for FedTP with the learn-to-personalize mechanism. Notably, FedTP offers a convenient environment for performing a range of image and language tasks using the same federated network architecture - all of which benefit from Transformer personalization. Extensive experiments verify that FedTP with the learn-to-personalize mechanism yields state-of-the-art performance in non-IID scenarios. Our code is available online https://github.com/zhyczy/FedTP.","2024-10","2025-02-26 20:43:28","2025-02-26 20:43:28","","13426-13440","","10","35","","","","","","","","","","English","","","","WOS:001005747100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;25<br/>Total Times Cited:&nbsp;&nbsp;25<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","Hypernetworks; learn-to-personalize; personalized federated learning; self-attention; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JCVJI8N6","journalArticle","2023","Yuan, DS; Yin, ZG; Wang, SH; Duan, NN; Zhang, YQ","Research on multiple transient modeling scheme for full-cycle design of the 12-pulse PSR rectifier","COMPEL-THE INTERNATIONAL JOURNAL FOR COMPUTATION AND MATHEMATICS IN ELECTRICAL AND ELECTRONIC ENGINEERING","","0332-1649","10.1108/COMPEL-01-2022-0061","","PurposeThis paper aims to propose a novel multiple transient modeling scheme for the 12-pulse phase-shifting reactor (PSR) rectifier to enhance the efficiency of full-cycle design evaluation. Design/methodology/approachThe detailed time-domain method is adopted to model the rectifier at the behavioral layer. The diode bridges/transformer model at the architecture layer is established by using the switch function and Park transformation. The frequency domain model at the functional layer is derived with the time-varying Fourier decomposition and frequency-shifting. At the component layer, the magneto-thermal characteristics of the rectifier are analyzed with field-circuit and magnetic-thermal coupling methods. A computer-aided design program integrating multiple modeling is also developed for industrial product design. FindingsThe function layer modeling is preferred in the initial design stage, making up for the lack of modeling accuracy at the architectural layer and the lack of modeling rapidity at the behavioral layer. The component modeling is irreplaceable for the detailed evaluation in the latter design stage. The multiple modeling scheme based on the four-layer modeling helps the designers achieve high-quality products with a short development cycle. Originality/valueThe singular transient modeling cannot cover the needs of different stages in the full-cycle design evaluation. This paper fills this gap with a novel multiple modeling scheme. Meanwhile, the proposed multiple modeling scheme and developed computer-aided design program provide a great convenience for full cycle design evaluation of the 12-pulse PSR rectifier.","2023-01-12","2025-02-26 20:43:28","2025-02-26 20:43:28","","271-283","","1","42","","","","","","","","","","English","","","","WOS:000906111700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","Coupled circuit field; Dynamic phasor; Electromagnetic fields; Equivalent circuit model; Field circuit models; Finite element analysis; Multiple modeling; Phase-shifting reactor; Power electronic devices modeling; TRANSFORMER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IY95K2PG","journalArticle","2021","Shrivastava, AD; Kell, DB","FragNet, a Contrastive Learning-Based Transformer Model for Clustering, Interpreting, Visualizing, and Navigating Chemical Space","MOLECULES","","1420-3049","10.3390/molecules26072065","","The question of molecular similarity is core in cheminformatics and is usually assessed via a pairwise comparison based on vectors of properties or molecular fingerprints. We recently exploited variational autoencoders to embed 6M molecules in a chemical space, such that their (Euclidean) distance within the latent space so formed could be assessed within the framework of the entire molecular set. However, the standard objective function used did not seek to manipulate the latent space so as to cluster the molecules based on any perceived similarity. Using a set of some 160,000 molecules of biological relevance, we here bring together three modern elements of deep learning to create a novel and disentangled latent space, viz transformers, contrastive learning, and an embedded autoencoder. The effective dimensionality of the latent space was varied such that clear separation of individual types of molecules could be observed within individual dimensions of the latent space. The capacity of the network was such that many dimensions were not populated at all. As before, we assessed the utility of the representation by comparing clozapine with its near neighbors, and we also did the same for various antibiotics related to flucloxacillin. Transformers, especially when as here coupled with contrastive learning, effectively provide one-shot learning and lead to a successful and disentangled representation of molecular latent spaces that at once uses the entire training set in their construction while allowing ""similar"" molecules to cluster together in an effective and interpretable way.","2021-04","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","7","26","","","","","","","","","","English","","","","WOS:000638740200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;20<br/>Total Times Cited:&nbsp;&nbsp;24<br/>Cited Reference Count:&nbsp;&nbsp;184</p>","","","ACTIVE SHAPE MODELS; artificial intelligence; attention; BIOLOGY; chemical space; cheminformatics; deep learning; DESIGN; generative methods; MARKETED DRUGS; MOLECULAR FINGERPRINTS; neural networks; NEURAL-NETWORKS; REPRESENTATION; SIZE; STRUCTURAL SIMILARITIES; SYSTEM; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T9HZ39FR","journalArticle","2024","Granata, F; Zhu, SL; Di Nunno, F","Advanced streamflow forecasting for Central European Rivers: The Cutting-Edge Kolmogorov-Arnold networks compared to Transformers","JOURNAL OF HYDROLOGY","","0022-1694","10.1016/j.jhydrol.2024.132175","","Accurate streamflow forecasting is crucial for effective water resource management, flood mitigation, and maintaining ecological balance, especially in Central Europe's major rivers. This study investigates the performance of two advanced deep learning algorithms-Kolmogorov-Arnold Network (KAN) and Transformers-using long-term hydrological data from four key rivers: the Rhine, Danube, Elbe, and Oder. These rivers, characterized by varying flow regimes and significant human and climatic impacts, serve as vital arteries for both commerce and ecosystems. The dataset comprises historical daily streamflow data, alongside derived input parameters such as moving averages and flow rate changes, used to predict short-term (1 to 7 days) river discharges. The KAN model, leveraging learnable spline-based activation functions, was developed to enhance accuracy and interpretability in capturing complex hydrological patterns. In contrast, the Transformer model uses advanced attention mechanisms, which excel in handling sequential data with long-range dependencies. Results show that the KAN model significantly outperforms the Transformer in short-term forecasts (up to 3 days). For 1-day forecasts, the KAN achieved R2 values of 0.975 for the Rhine, 0.956 for the Danube, 0.992 for the Elbe, and 0.969 for the Oder, with MAPE values ranging from 3.20 % to 8.09 %. At the 3-day horizon, the KAN's R2 values remained high, demonstrating its robustness. However, as the forecasting horizon extends to 7 days, the performance of both models converges. These findings underscore the methodological novelty of KAN, which provides enhanced short-term predictive capabilities compared to existing methods, offering valuable insights for improving water resource management strategies in complex hydrological settings.","2024-12","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","645","","","","","","","","","","English","","","","WOS:001339543400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Central Europe; Deep Learning; FLOODS; Kolmogorov-Arnold Networks; Streamflow forecasting; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FHM2RYIV","journalArticle","2024","Variyar, VVS; Sowmya, V; Sivanpillai, R; Brown, GK","A multi-branch dual attention segmentation network for epiphyte drone images","IMAGE AND VISION COMPUTING","","0262-8856","10.1016/j.imavis.2024.105099","","Acquiring images of epiphytes growing on trees using Unmanned Aerial Vehicles (UAVs) enables botanists to efficiently collect data on these important plant species. Despite the advantages offered by UAVs, challenges such as complex backgrounds, uneven lighting inside the tree canopy, and accessibility issues hinder the acquisition of quality images, resulting in acquiring images datasets of heterogenous quality. AI/Deep Learning algorithms can be used to segment target plants in these images for selecting sampling locations. Existing DL models require large volume of data for training, and they tend to prioritize local features over global ones, impacting segmentation accuracy, particularly on smaller, heterogeneous quality image datasets. To overcome these limitations, we propose a multi-branch dual attention segmentation network designed to effectively handle small datasets with heterogeneous quality. The proposed network incorporates dedicated branches for extracting both global and local features, utilizing spatial and channel attention mechanisms to focus on important regions. Through a fusion process and a decoder with crossed fusion technique, this network effectively combines and enhances features from multiple branches, resulting in improved segmentation performance. Output obtained from the trained model demonstrated major improvements in predicting the boundary regions and class labels, even in close-range, low-light, and zoomed/cropped images. The average Intersection over Union (IoU) scores of the trained model was 5% higher for images acquired close range, 48% higher for images in low-light conditions, and 68% higher for zoomed/cropped images when compared to those obtained from TransUnet, a state-of-the-art vision transformer model trained on epiphyte dataset. The proposed network can be used for segmenting epiphytes in images of heterogeneous quality as well as identifying targets in images acquired in domains such as agriculture and forestry.","2024-08","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","148","","","","","","","","","","English","","","","WOS:001252037300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Dual attention; Low samples; Mixed quality; Multi-branch network; NET; UAV image segmentation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K9L7UFAB","journalArticle","2024","Liu, B; Chen, XH; Zhou, DW; Wang, P; Wang, RR","Text guided zero-shot scene classification of high spatial resolution remote sensing images","JOURNAL OF APPLIED REMOTE SENSING","","1931-3195","10.1117/1.JRS.18.014525","",". Recently, high spatial resolution remote sensing image scene classification has had a wide range of applications and has become one of the hotspots in the field of remote sensing research. Due to the complexity of the scenes in remote sensing images, it is impossible to annotate all ground object classes at once. To adapt to different application scenarios, high spatial resolution remote sensing image scene classification models need to have zero-shot generalization ability for unseen classes. To improve the zero-shot generalization ability of classification models, the existing methods often start from the perspective of image features, thus ignoring the high-order semantic information in the scene. In fact, the association between higher-order semantic information in the scene is very important for the generalization ability of the classification model. People often use image information and its corresponding higher-order semantic information to complete remote sensing image scene understanding. Therefore, this work proposes a text guided remote sensing image pre-training model for zero-shot classification of high spatial resolution remote sensing image scenes. First, the transformer model is used to extract the embedded features of text and remote sensing images. Then, based on the aligned text and remote sensing image data, a contrast learning method is used to train the model to learn the correspondence between text and image features. After the model training is completed, the nearest neighbor method is used to complete zero-shot classification on the target data. The effectiveness of the proposed method was verified on three remote sensing image scene classification benchmark datasets.","2024-01-01","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","1","18","","","","","","","","","","English","","","","WOS:001271750200032","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","contrast learning; high resolution remote sensing images; NETWORKS; scene classification; text guidance; zero-shot classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DHKZ4WKS","journalArticle","2023","Felsch, M; Meyer, O; Schlickenrieder, A; Engels, P; Schönewolf, J; Zöllner, F; Heinrich-Weltzien, R; Hesenius, M; Hickel, R; Gruhn, V; Kühnisch, J","Detection and localization of caries and hypomineralization on dental photographs with a vision transformer model","NPJ DIGITAL MEDICINE","","2398-6352","10.1038/s41746-023-00944-2","","Caries and molar-incisor hypomineralization (MIH) are among the most prevalent diseases worldwide and need to be reliably diagnosed. The use of dental photographs and artificial intelligence (AI) methods may potentially contribute to realizing accurate and automated diagnostic visual examinations in the future. Therefore, the present study aimed to develop an AI-based algorithm that can detect, classify and localize caries and MIH. This study included an image set of 18,179 anonymous photographs. Pixelwise image labeling was achieved by trained and calibrated annotators using the Computer Vision Annotation Tool (CVAT). All annotations were made according to standard methods and were independently checked by an experienced dentist. The entire image set was divided into training (N = 16,679), validation (N = 500) and test sets (N = 1000). The AI-based algorithm was trained and finetuned over 250 epochs by using image augmentation and adapting a vision transformer network (SegFormer-B5). Statistics included the determination of the intersection over union (IoU), average precision (AP) and accuracy (ACC). The overall diagnostic performance in terms of IoU, AP and ACC were 0.959, 0.977 and 0.978 for the finetuned model, respectively. The corresponding data for the most relevant caries classes of non-cavitations (0.630, 0.813 and 0.990) and dentin cavities (0.692, 0.830, and 0.997) were found to be high. MIH-related demarcated opacity (0.672, 0.827, and 0.993) and atypical restoration (0.829, 0.902, and 0.999) showed similar results. Here, we report that the model achieves excellent precision for pixelwise detection and localization of caries and MIH. Nevertheless, the model needs to be further improved and externally validated.","2023-10-25","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","1","6","","","","","","","","","","English","","","","WOS:001087108900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","SCORING SYSTEM UNIVISS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"STIRTSM4","journalArticle","2023","Kim, S; Yoon, J; Kwon, O","Biomedical Relation Extraction Using Dependency Graph and Decoder-Enhanced Transformer Model","BIOENGINEERING-BASEL","","2306-5354","10.3390/bioengineering10050586","","The identification of drug-drug and chemical-protein interactions is essential for understanding unpredictable changes in the pharmacological effects of drugs and mechanisms of diseases and developing therapeutic drugs. In this study, we extract drug-related interactions from the DDI (Drug-Drug Interaction) Extraction-2013 Shared Task dataset and the BioCreative ChemProt (Chemical-Protein) dataset using various transfer transformers. We propose BERTGAT that uses a graph attention network (GAT) to take into account the local structure of sentences and embedding features of nodes under the self-attention scheme and investigate whether incorporating syntactic structure can help relation extraction. In addition, we suggest T5(slim_dec), which adapts the autoregressive generation task of the T5 (text-to-text transfer transformer) to the relation classification problem by removing the self-attention layer in the decoder block. Furthermore, we evaluated the potential of biomedical relation extraction of GPT-3 (Generative Pre-trained Transformer) using GPT-3 variant models. As a result, T5(slim_dec), which is a model with a tailored decoder designed for classification problems within the T5 architecture, demonstrated very promising performances for both tasks. We achieved an accuracy of 91.15% in the DDI dataset and an accuracy of 94.29% for the CPR (Chemical-Protein Relation) class group in ChemProt dataset. However, BERTGAT did not show a significant performance improvement in the aspect of relation extraction. We demonstrated that transformer-based approaches focused only on relationships between words are implicitly eligible to understand language well without additional knowledge such as structural information.","2023-05-12","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","5","10","","","","","","","","","","English","","","","WOS:000994275800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","ChemProt; CPR (chemical-protein relation); DDI (drug-drug interaction); GAT (graph-attention network); relation extraction; self-attention; T5 (text-to-text transfer transformer); transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AMRYCFBY","journalArticle","2023","Chen, Z; Yang, ZW; Zhu, LW; Chen, W; Tamura, T; Ono, N; Altaf-Ul-Amin, M; Kanaya, S; Huang, M","Automated Sleep Staging via Parallel Frequency-Cut Attention","IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING","","1534-4320","10.1109/TNSRE.2023.3243589","","Stage-based sleep screening is a widely-used tool in both healthcare and neuroscientific research, as it allows for the accurate assessment of sleep patterns and stages. In this paper, we propose a novel framework that is based on authoritative guidance in sleep medicine and is designed to automatically capture the time-frequency characteristics of sleep electroencephalogram (EEG) signals in order to make staging decisions. Our framework consists of two main phases: a feature extraction process that partitions the input EEG spectrograms into a sequence of time-frequency patches, and a staging phase that searches for correlations between the extracted features and the defining characteristics of sleep stages. To model the staging phase, we utilize a Transformer model with an attention-based module, which allows for the extraction of global contextual relevance among time-frequency patches and the use of this relevance for staging decisions. The proposed method is validated on the large-scale Sleep Heart Health Study dataset and achieves new state-of-the-art results for the wake, N2, and N3 stages, with respective F1 scores of 0.93, 0.88, and 0.87 using only EEG signals. Our method also demonstrates high inter-rater reliability, with a kappa score of 0.80. Moreover, we provide visualizations of the correspondence between sleep staging decisions and features extracted by our method, which enhances the interpretability of the proposal. Overall, our work represents a significant contribution to the field of automated sleep staging and has important implications for both healthcare and neuroscience research.","2023","2025-02-26 20:43:28","2025-02-26 20:43:28","","1974-1985","","","31","","","","","","","","","","English","","","","WOS:000970750400004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","Brain modeling; CLASSIFICATION; EEG; Electroencephalography; Feature extraction; model interpretability; Sleep; Sleep staging; Spectrogram; SYSTEM; Time-frequency analysis; time-frequency patch; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8HC87INP","journalArticle","2025","Arhiliuc, C; Guns, R; Daelemans, W; Engels, TCE","Journal article classification using abstracts: a comparison of classical and transformer-based machine learning methods","SCIENTOMETRICS","","0138-9130","10.1007/s11192-024-05217-7","","In this article we analyze the performance of existing models to classify journal articles into disciplines from a predefined classification scheme (i.e., supervised learning), based on their abstract. The first part analyzes scenarios with ample labeled data, comparing the performance of the Support Vector Machine algorithm (SVM) combined with TF-IDF and with SPECTER embeddings (Cohan et al. SPECTER: Document-level representation learning using citation-informed transformers, https://doi.org/10.48550/arXiv.2004.07180, 2020) and Bidirectional Encoder Representations from Transformers (BERT) models. The second part employes Generative Pre-trained Transformer model 3.5 turbo (GPT-3.5-turbo) for the zero- and few-shot learning situations. Through the use of GPT-3.5-turbo we examine how different characterizations of disciplines (such as names, descriptions, and examples) affect the model's ability to classify articles. The data set comprises journal articles published in 2022 and indexed in the Web of Science, with subject categories aligned to a modified version of the OECD Fields of Research and Development (FoRD) classification scheme. We find that BERT models surpass the SVM + TF-IDF baseline and SVM + SPECTER in all areas. For all disciplinary areas except Humanities, we observe minimal variation among the models fine-tuned on larger datasets, and greater variability with smaller training datasets. The GPT 3.5-turbo results show significant fluctuations across disciplines, influenced by the clarity of their definition and their distinctiveness as research topics compared to other fields. Although the two approaches are not directly comparable, we conclude that the classification models show promising results in their specific scenarios, with variations across disciplines.","2025-01","2025-02-26 20:43:28","2025-02-26 20:43:28","","313-342","","1","130","","","","","","","","","","English","","","","WOS:001383468800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","AFFILIATIONS; BERT classification; Classification OECD FoRD; DISCIPLINARY DIVERSITY; Paper-level classification; PUBLICATIONS; SCIENCE; WEB; WoS articles classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XJ3VLRA4","journalArticle","2024","Qin, XY; Zhang, L; Liu, M; Liu, GZ","PRFold-TNN: Protein Fold Recognition With an Ensemble Feature Selection Method Using PageRank Algorithm Based on Transformer","IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS","","1545-5963","10.1109/TCBB.2024.3414497","","Understanding the tertiary structures of proteins is of great benefit to function in many aspects of human life. Protein fold recognition is a vital and salient means to know protein structure. Until now, researchers have successively proposed a variety of methods to realize protein fold recognition, but the novel and effective computational method is still needed to handle this problem with the continuous updating of protein structure databases. In this study, we develop a new protein structure dataset named AT and propose the PRFold-TNN model for protein fold recognition. First, different types of feature extraction methods including AAC, HMM, HMM-Bigram and ACC are selected to extract corresponding features for protein sequences. Then an ensemble feature selection method based on PageRank algorithm integrating various tree-based algorithms is used to screen the fusion features. Ultimately, the classifier based on the Transformer model achieves the final prediction. Experiments show that the prediction accuracy is 86.27% on the AT dataset and 88.91% on the independent test set, indicating that the model can demonstrate superior performance and generalization ability in the problem of protein fold recognition. Furthermore, we also carry out research on the DD, EDD and TG benchmark datasets, and make them achieve prediction accuracy of 88.41%, 97.91% and 95.16%, which are at least 3.0%, 0.8% and 2.5% higher than those of the state-of-the-art methods. It can be concluded that the PRFold-TNN model is more prominent.","2024-11","2025-02-26 20:43:28","2025-02-26 20:43:28","","1740-1751","","6","21","","","","","","","","","","English","","","","WOS:001375991100013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","Amino acids; ASTRAL; CLASSIFICATION; ensemble feature selection method; Feature extraction; Hidden Markov models; NMR; PageRank algorithm; PREDICTION; Prediction algorithms; Predictive models; PROBABILITIES; protein fold recognition; Protein sequence; SCORING MATRIX; transformer; Vectors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SSKULW3F","journalArticle","2024","Hinterwimmer, F; Guenther, M; Consalvo, S; Neumann, J; Gersing, A; Woertler, K; von Eisenhart-Rothe, R; Burgkart, R; Rueckert, D","Impact of metadata in multimodal classification of bone tumours","BMC MUSCULOSKELETAL DISORDERS","","1471-2474","10.1186/s12891-024-07934-9","","The accurate classification of bone tumours is crucial for guiding clinical decisions regarding treatment and follow-up. However, differentiating between various tumour types is challenging due to the rarity of certain entities, high intra-class variability, and limited training data in clinical practice. This study proposes a multimodal deep learning model that integrates clinical metadata and X-ray imaging to improve the classification of primary bone tumours. The dataset comprises 1,785 radiographs from 804 patients collected between 2000 and 2020, including metadata such as age, affected bone site, tumour position, and gender. Ten tumour types were selected, with histopathology or tumour board decisions serving as the reference standard.MethodsOur model is based on the NesT image classification model and a multilayer perceptron with a joint fusion architecture. Descriptive statistics included incidence and percentage ratios for discrete parameters, and mean, standard deviation, median, and interquartile range for continuous parameters.ResultsThe mean age of the patients was 33.62 +/- 18.60 years, with 54.73% being male. Our multimodal deep learning model achieved 69.7% accuracy in classifying primary bone tumours, outperforming the Vision Transformer model by five percentage points. SHAP values indicated that age had the most substantial influence among the considered metadata.ConclusionThe joint fusion approach developed in this study, integrating clinical metadata and imaging data, outperformed state-of-the-art models in classifying primary bone tumours. The use of SHAP values provided insights into the impact of different metadata on the model's performance, highlighting the significant role of age. This approach has potential implications for improving diagnostic accuracy and understanding the influence of clinical factors in tumour classification.","2024-10-19","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","1","25","","","","","","","","","","English","","","","WOS:001339540500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Bone neoplasm; Classification; Deep learning; DIAGNOSIS; Metadata; Radiography; SARCOMA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HV6JWYKK","journalArticle","2025","Sharma, V; Tripathi, AK; Mittal, H; Nkenyereye, L","SoyaTrans: A novel transformer model for fine-grained visual classification of soybean leaf disease diagnosis","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.125385","","Plant leaf disease detection has a considerable influence on the safety of crop quality. However, distinguishing different symptoms in leaves is a challenging task. Newfangled CNN architectures have a ""moving window""feature that extracts local information of the image only and fails to capture global features. Additionally, CNN architectures take the whole image as an input which lacks in identifying the small lesions that result in poor classification. Therefore, a novel robust model, the SoyaTrans network, is designed by pairing CNN architecture with swin transformers which efficiently work on real field images. In this, a new random shifting is introduced in comparison to cyclic shift which enhances the classification performance while reducing the computational complexity. Moreover, the proposed SoyaTrans model ensembles the capabilities of conventional CNN with a swin transformer network that efficiently detects diseases on different types of crops. Furthermore, this paper presents a new soybean plant leaf disease dataset that is collected from real fields to overcome the challenge of a limited soybean leaf dataset. Experimental results of the proposed model are compared against the ten stateof-the-art methods in terms of five parameters, namely parameters, accuracy, precision, recall, and F1-score. In addition, the efficacy of the proposed model is validated on four publicly available datasets namely, Embrapa, Plant Village, AI2018, and PlantDoc. The proposed model surpassed all the ten state-of-the-art models, even under complicated backdrops, with an accuracy of 98.00%, 97.00%, 76.00%, and 92.00% on plantvillage, AI2018, PlantDoc, and Embrapa dataset with the least computational complexity of 5.2 million parameters. Lastly, the proposed model achieved 94.00% accuracy on the newly presented soybean leaf dataset.","2025-01-15","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","260","","","","","","","","","","English","","","","WOS:001318143500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Convolutional neural network; Random shifting; Soybean plant disease; Swin transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XIIUIMRY","journalArticle","2024","Tan, JL; Pitawela, D; Chinnaratha, MA; Beany, A; Aguila, EJ; Chen, HT; Carneiro, G; Singh, R","Exploring vision transformers for classifying early Barrett's dysplasia in endoscopic images: A pilot study on white-light and narrow-band imaging","JGH OPEN","","2397-9070","10.1002/jgh3.70030","","Background and Aim: Various deep learning models, based on convolutional neuralnetwork (CNN), have been shown to improve the detection of early esophageal neo-plasia in Barrett's esophagus. Vision transformer (ViT), derived from natural languageprocessing, has emerged as the new state-of-the-art for image recognition, out-performing predecessors such as CNN. This pilot study explores the use of ViT toclassify the presence or absence of early esophageal neoplasia in endoscopic imagesof Barrett's esophagus. Methods: A BO dataset of 1918 images of Barrett's esophagus from 267 uniquepatients was used. The images were classified as dysplastic (D-BO) or non-dysplastic(ND-BO). A pretrained vision transformer model, ViTBase16, was used to developour classifier models. Three ViT models were developed for comparison based onimaging modality: white-light imaging (WLI), narrow-band imaging (NBI), and com-bined modalities. Performance of each model was evaluated based on accuracy, sensi-tivity, specificity, confusion matrices, and receiver operating characteristic curves. Results: The ViT models demonstrated the following performance: WLI-ViT(Accuracy: 92%, Sensitivity: 82%, Specificity: 95%), NBI-ViT (Accuracy: 99%, Sen-sitivity: 97%, Specificity: 99%), and combined modalities-ViT (Accuracy: 93%, Sen-sitivity: 87%, Specificity: 95%). Combined modalities-ViT showed greater accuracy(94%vs90%) and sensitivity (80%vs70%) compared with WLI-ViT when classify-ing WLI images on a subgroup testing set. Conclusion: ViT exhibited high accuracy in classifying the presence or absence ofEON in endoscopic images of Barrett's esophagus. ViT has the potential to be widelyapplicable to other endoscopic diagnoses of gastrointestinal diseases.","2024-09","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","9","8","","","","","","","","","","English","","","","WOS:001320138000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","artificial intelligence; Barrett's esophagus; CONVOLUTIONAL NEURAL-NETWORKS; DIAGNOSIS; dysplasia; esophageal adenocarcinoma; ESOPHAGUS; MANAGEMENT; NEOPLASIA; SOCIETY; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IWFHKXVT","journalArticle","2024","Zhang, XY; Tian, SB; Liang, X; Zheng, MH; Behdad, S","Early Prediction of Human Intention for Human-Robot Collaboration Using Transformer Network","JOURNAL OF COMPUTING AND INFORMATION SCIENCE IN ENGINEERING","","1530-9827","10.1115/1.4064258","","Human intention prediction plays a critical role in human-robot collaboration, as it helps robots improve efficiency and safety by accurately anticipating human intentions and proactively assisting with tasks. While current applications often focus on predicting intent once human action is completed, recognizing human intent in advance has received less attention. This study aims to equip robots with the capability to forecast human intent before completing an action, i.e., early intent prediction. To achieve this objective, we first extract features from human motion trajectories by analyzing changes in human joint distances. These features are then utilized in a Hidden Markov Model (HMM) to determine the state transition times from uncertain intent to certain intent. Second, we propose two models including a Transformer and a Bi-LSTM for classifying motion intentions. Then, we design a human-robot collaboration experiment in which the operator reaches multiple targets while the robot moves continuously following a predetermined path. The data collected through the experiment were divided into two groups: full-length data and partial data before state transitions detected by the HMM. Finally, the effectiveness of the suggested framework for predicting intentions is assessed using two different datasets, particularly in a scenario when motion trajectories are similar but underlying intentions vary. The results indicate that using partial data prior to the motion completion yields better accuracy compared to using full-length data. Specifically, the transformer model exhibits a 2% improvement in accuracy, while the Bi-LSTM model demonstrates a 6% increase in accuracy.","2024-05-01","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","5","24","","","","","","","","","","English","","","","WOS:001215285700012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","artificial intelligence; early prediction; hidden Markov model; HIDDEN MARKOV MODEL; human intent recognition; human-robot collaboration; manufacturing; manufacturing automation; RECOGNITION; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JE5MFQHI","journalArticle","2024","Pham, VN; Ba, QHD; Le, DAT; Nguyen, QM; Van, DD; Nguyen, L","A Low-Cost Deep-Learning-Based System for Grading Cashew Nuts","COMPUTERS","","2073-431X","10.3390/computers13030071","","Most of the cashew nuts in the world are produced in the developing countries. Hence, there is a need to have a low-cost system to automatically grade cashew nuts, especially in small-scale farms, to improve mechanization and automation in agriculture, helping reduce the price of the products. To address this issue, in this work we first propose a low-cost grading system for cashew nuts by using the off-the-shelf equipment. The most important but complicated part of the system is its ""eye"", which is required to detect and classify the nuts into different grades. To this end, we propose to exploit advantages of both the YOLOv8 and Transformer models and combine them in one single model. More specifically, we develop a module called SC3T that can be employed to integrate into the backbone of the YOLOv8 architecture. In the SC3T module, a Transformer block is dexterously integrated into along with the C3TR module. More importantly, the classifier is not only efficient but also compact, which can be implemented in an embedded device of our developed cashew nut grading system. The proposed classifier, called the YOLOv8-Transformer model, can enable our developed grading system, through a low-cost camera, to correctly detect and accurately classify the cashew nuts into four quality grades. In our grading system, we also developed an actuation mechanism to efficiently sort the nuts according to the classification results, getting the products ready for packaging. To verify the effectiveness of the proposed classifier, we collected a dataset from our sorting system, and trained and tested the model. The obtained results demonstrate that our proposed approach outperforms all the baseline methods given the collected image data.","2024-03","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","3","13","","","","","","","","","","English","","","","WOS:001191757500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","cashew nut; classification; digital agriculture; FRUIT; low-cost system; NETWORK; precision agriculture; smart agriculture; Transformer; YOLOv8","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7KZWDVFQ","journalArticle","2024","Aftiss, A; Lamsiyah, S; El Alaoui, SO; Schommer, C","BioMDSum: An Effective Hybrid Biomedical Multi-Document Summarization Method Based on PageRank and Longformer Encoder-Decoder","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3514915","","Biomedical multi-document summarization (BioMDSum) involves automatically generating concise and informative summaries from collections of related biomedical documents. While extractive summarization methods have shown promise, they often produce incoherent summaries. Onethe other hand, fully abstractive methods yield coherent summaries but demand extensive training datasets and computational resources due to the typically lengthy nature of biomedical documents. Toeaddress these challenges, wepropose a hybrid summarization method that combines the strengths of both approaches. The proposed method consists of two main phases: (i) an extractive summarization phase that uses k-means clustering to group similar sentences based on their cosine similarity between embeddings generated by the sentence-BERT model, followed by the PageRank algorithm for sentence scoring and selection; and (ii) an abstractive summarization phase that fine-tunes a Longform Encoder-Decoder (LED) transformer model to generate a concise and coherent summary from the sentences selected during the extractive phase. We conducted several experiments on the standard biomedical multi-document summarization datasets Cochrane and MS<^>2. The results demonstrate that the proposed method is competitive and outperforms recent state-of-the-art systems based on ROUGE evaluation measures. Specifically, our model achieved ROUGE-1, ROUGE-2, ROUGE-L, BERTScore, and METEOR scores of 29.41%, 6.57%, 18.31%, 85.95%, and 22.15% on the Cochrane dataset, and 28.79%, 8.22%, 17.93%, 85.51%, and 25.17% on the MS<^>2 dataset, respectively. Furthermore, aneablation analysis shows that integrating extractive and abstractive phases in our hybrid summarization method enhances the overall performance of the proposed approach.","2024","2025-02-26 20:43:28","2025-02-26 20:43:28","","188013-188031","","","12","","","","","","","","","","English","","","","WOS:001380685100029","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;87</p>","","","Biomedical multi-document summarization; hybrid summarization; K-means clustering; longformer encoder-decoder; PageRank algorithm; sentence-BERT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N4FYR45P","journalArticle","2024","Jayanthi, S; Devi, SP","AutoRhythmAI: A Hybrid Machine and Deep Learning Approach for Automated Diagnosis of Arrhythmias","CMC-COMPUTERS MATERIALS & CONTINUA","","1546-2218","10.32604/cmc.2024.045975","","In healthcare, the persistent challenge of arrhythmias, a leading cause of global mortality, has sparked extensive research into the automation of detection using machine learning (ML) algorithms. However, traditional ML and AutoML approaches have revealed their limitations, notably regarding feature generalization and automation efficiency. This glaring research gap has motivated the development of AutoRhythmAI, an innovative solution that integrates both machine and deep learning to revolutionize the diagnosis of arrhythmias. Our approach encompasses two distinct pipelines tailored for binary-class and multi-class arrhythmia detection, effectively bridging the gap between data preprocessing and model selection. To validate our system, we have rigorously tested AutoRhythmAI using a multimodal dataset, surpassing the accuracy achieved using a single dataset and underscoring the robustness of our methodology. In the first pipeline, we employ signal filtering and ML algorithms for preprocessing, followed by data balancing and split for training. The second pipeline is dedicated to feature extraction and classification, utilizing deep learning models. Notably, we introduce the 'RRI-convoluted transformer model' as a novel addition for binary-class arrhythmias. An ensemble-based approach then amalgamates all models, considering their respective weights, resulting in an optimal model pipeline. In our study, the VGGRes Model achieved impressive results in multi-class arrhythmia detection, with an accuracy of 97.39% and firm performance in precision (82.13%), recall (31.91%), and F1-score (82.61%). In the binary-class task, the proposed model achieved an outstanding accuracy of 96.60%. These results highlight the effectiveness of our approach in improving arrhythmia detection, with notably high accuracy and well-balanced performance metrics.","2024","2025-02-26 20:43:28","2025-02-26 20:43:28","","2137-2158","","2","78","","","","","","","","","","English","","","","WOS:001199394600016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","arrhythmias; Automated machine learning; deep learning; neural networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TLE5M4SW","journalArticle","2024","Zhao, ZJ; Yu, H; Wu, H; Zhang, XB","Bio-inspired affordance learning for 6-DoF robotic grasping: A transformer-based global feature encoding approach","NEURAL NETWORKS","","0893-6080","10.1016/j.neunet.2023.12.005","","The 6-Degree-of-Freedom (6-DoF) robotic grasping is a fundamental task in robot manipulation, aimed at detecting graspable points and corresponding parameters in a 3D space, i.e affordance learning, and then a robot executes grasp actions with the detected affordances. Existing research works on affordance learning predominantly focus on learning local features directly for each grid in a voxel scene or each point in a point cloud scene, subsequently filtering the most promising candidate for execution. Contrarily, cognitive models of grasping highlight the significance of global descriptors, such as size, shape, and orientation, in grasping. These global descriptors indicate a grasp path closely tied to actions. Inspired by this, we propose a novel bio-inspired neural network that explicitly incorporates global feature encoding. In particular, our method utilizes a Truncated Signed Distance Function (TSDF) as input, and employs the recently proposed Transformer model to encode the global features of a scene directly. With the effective global representation, we then use deconvolution modules to decode multiple local features to generate graspable candidates. In addition, to integrate global and local features, we propose using a skip-connection module to merge lower -layer global features with higher-layer local features. Our approach, when tested on a recently proposed pile and packed grasping dataset for a decluttering task, surpassed state-of-the-art local feature learning methods by approximately 5% in terms of success and declutter rates. We also evaluated its running time and generalization ability, further demonstrating its superiority. We deployed our model on a Franka Panda robot arm, with real-world results aligning well with simulation data. This underscores our approach's effectiveness for generalization and real-world applications.","2024-03","2025-02-26 20:43:28","2025-02-26 20:43:28","","332-342","","","171","","","","","","","","","","English","","","","WOS:001143894200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","6-DoF robotic grasping; Affordance learning; Bio-inspired neural network; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JIPBUYPE","journalArticle","2023","Yang, HX; Wang, RS","Self-Supervised Learning for 3-D Point Clouds Based on a Masked Linear Autoencoder","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2023.3337088","","Motivated by the success of a masked autoencoder in 3-D point-cloud-based learning, this study proposes an innovative framework for self-supervised learning (SSL) on 3-D point clouds with linear complexity. In the proposed framework, every input point cloud is divided into multiple point patches, which are randomly masked at different ratios. Then, unmasked point patches are then fed to an improved transformer model, which uses an advanced linear self-attention mechanism autoencoder to learn high-level features. The pretraining objective is to recover the masked patches under the guidance of the unmasked point patches' features obtained by the designed transformer. Furthermore, a linear self-attention mechanism is designed to use three projection matrices to decompose the original scaled dot-product attention into smaller parts, using the properties of low-rank and linear decomposition to reduce the time complexity from quadratic to linear. The results of extensive experiments demonstrate that the proposed pretrained model can achieve high accuracy of 93.6% and 84.77% on the ModelNet40 and ScanObjectNN datasets, respectively, at a masking ratio of 40%. In addition, the results show that the proposed method, which uses a linear self-attention mechanism, can enhance the computational efficiency by significantly reducing the inference time and minimizing the storage memory requirements for query, key, and value (Q, K, and V) matrices compared with the existing methods. Finally, the results indicate that the proposed method can achieve state-of-the-art performance on the classification ModelNet40 dataset.","2023","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","61","","","","","","","","","","English","","","","WOS:001178217500002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Data models; Memory management; NETWORK; Point cloud; Point cloud compression; self-attention mechanism; self-supervised learning g(SSL); Standards; Task analysis; Three-dimensional displays; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A92BCC2N","journalArticle","2023","Hernandez, I; Nie, WW","The AI-IP: Minimizing the guesswork of personality scale item development through artificial intelligence","PERSONNEL PSYCHOLOGY","","0031-5826","10.1111/peps.12543","","We propose a framework for integrating various modern natural language processing (NLP) models to assist researchers with developing valid psychological scales. Transformer-based deep neural networks offer state-of-the-art performance on various natural language tasks. This project adapts the transformer model GPT-2 to learn the structure of personality items, and generate the largest openly available pool of personality items, consisting of one million new items. We then use that artificial intelligence-based item pool (AI-IP) to provide a subset of potential scale items for measuring a desired construct. To better recommend construct-related items, we train a paired neural network-based classification BERT model to predict the observed correlation between personality items using only their text. We also demonstrate how zero-shot models can help balance desired content domains within the scale. In combination with the Al-IP, these models narrow the large item pool to items most correlated with a set of initial items. We demonstrate the ability of this multimodel framework to develop longer cohesive scales from a small set of construct-relevant items. We found reliability, validity, and fit equivalent for AI-assisted scales compared to scales developed and optimized by traditional methods. By leveraging neural networks' ability to generate text relevant to a given topic and infer semantic similarity, this project demonstrates how to support creative and open-ended elements of the scale development process to increase the likelihood of one's initial scale being valid, and minimize the need to modify and revalidate the scale.","2023-12","2025-02-26 20:43:28","2025-02-26 20:43:28","","1011-1035","","4","76","","","","","","","","","","English","","","","WOS:000869552500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","artificial intelligence; BANDWIDTH; big data; FIT INDEXES; machine learning; MODEL; personality; personality assessment; technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DTMHMGY9","journalArticle","2022","Zhang, CY; Zhou, QL; Qiao, M; Tang, K; Xu, LQ; Liu, FD","Re_Trans: Combined Retrieval and Transformer Model for Source Code Summarization","ENTROPY","","1099-4300","10.3390/e24101372","","Source code summarization (SCS) is a natural language description of source code functionality. It can help developers understand programs and maintain software efficiently. Retrieval-based methods generate SCS by reorganizing terms selected from source code or use SCS of similar code snippets. Generative methods generate SCS via attentional encoder-decoder architecture. However, a generative method can generate SCS for any code, but sometimes the accuracy is still far from expectation (due to the lack of numerous high-quality training sets). A retrieval-based method is considered to have a higher accurac, but usually fails to generate SCS for a source code in the absence of a similar candidate in the database. In order to effectively combine the advantages of retrieval-based methods and generative methods, we propose a new method: Re_Trans. For a given code, we first utilize the retrieval-based method to obtain its most similar code with regard to sematic and corresponding SCS (S_RM). Then, we input the given code and similar code into the trained discriminator. If the discriminator outputs onr, we take S_RM as the result; otherwise, we utilize the generate model, transformer, to generate the given code' SCS. Particularly, we use AST-augmented (AbstractSyntax Tree) and code sequence-augmented information to make the source code semantic extraction more complete. Furthermore, we build a new SCS retrieval library through the public dataset. We evaluate our method on a dataset of 2.1 million Java code-comment pairs, and experimental results show improvement over the state-of-the-art (SOTA) benchmarks, which demonstrates the effectiveness and efficiency of our method.","2022-10","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","10","24","","","","","","","","","","English","","","","WOS:000872417600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","deep learning; information retrieval; program analysis; source code summarization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NZH62Z3H","journalArticle","2025","Fan, GR; Li, LJ; Zhao, Y; Shi, H; Zhang, XY; Dong, ZS","Zero-Shot Rolling Bearing Fault Diagnosis Based on Attribute Description","ELECTRONICS","","2079-9292","10.3390/electronics14030452","","Traditional fault diagnosis methods for rolling bearings rely on nemerous labeled samples, which are difficult to obtain in engineering applications. Moreover, when unseen fault categories appear in the test set, these models fail to achieve accurate diagnoses, as the fault categories are not represented in the training data. To address these challenges, a zero-shot fault diagnosis model for rolling bearings is proposed, which realizes knowledge transfer from seen to unseen categories by constructing attribute information, thereby reducing the dependence on labeled samples. First, an attribute method Discrete Label Embedding Method (DLEM) based on word embedding and envelope analysis is designed to generate fault attributes. Fault features are extracted using the Swin Transformer model. Then, the attributes and features are input into the constructed model Distribution Consistency and Multi-modal Cross Alignment Variational Autoencoder (DCMCA-VAE), which is built on Convolutional Residual SE-Attention Variational Autoencoder (CRS-VAE). CRS-VAE replaces fully connected layers with convolutional layers and incorporates residual connections with the Squeeze-and-Excitation Joint Attention Mechanism (SE-JAM) for improved feature extraction. The DCMCA-VAE also incorporates a reconstruction alignment module with the proposed distribution consistency loss LWT and multi-modal cross alignment loss function LMCA. The reconstruction alignment module is used to generate high-quality features with distinguishing information between different categories for classification. In the face of multiple noisy datasets, this model can effectively distinguish unseen categories and has stronger robustness than other models. The model can achieve 100% classification accuracy on the SQ dataset, and more than 85% on the CWRU dataset when unseen and seen categories appear simultaneously with noise interference.","2025-02","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","3","14","","","","","","","","","","English","","","","WOS:001418480500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","attribute description; deep learning; fault diagnosis; generative model; variational autoencoder (VAE); zero-shot classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SYKQLLQ4","journalArticle","2024","Le, Z; Liang, Y; Hu, XK; Qiu, TR; Xu, P","A Risk Stratification Study of Ultrasound Images of Thyroid Nodules Based on Improved DETR","INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY","","0899-9457","10.1002/ima.23219","","The Chinese Thyroid Imaging Reporting and Data System (C-TIRADS) standard is based on the Chinese current medical context. However, at present, there is a lack of C-TIRADS-based automatic computer-aided diagnosis system for thyroid nodule ultrasound images, and the existing algorithms for detecting and recognizing thyroid nodules are basically for the dichotomous classification of benign and malignant. We used the DETR (detection transformer) model as a baseline model and carried out model enhancements to address the shortcomings of unsatisfactory classification accuracy and difficulty in detecting small thyroid nodules in the DETR model. First, to investigate the method of acquiring multi-scale features of thyroid nodule ultrasound images, we choose TResNet-L as the feature extraction network and introduce multi-scale feature information and group convolution, thereby enhancing the model's multi-label classification accuracy. Second, a parallel decoder architecture for multi-label thyroid nodule ultrasound image classification is designed to enhance the learning of correlation between pathological feature class labels, aiming to improve the multi-label classification accuracy of the detection model. Third, the loss function of the detection model is improved. We propose a linear combination of Smooth L1-Loss and CIoU Loss as the model's bounding box loss function and asymmetric loss as the model's multi-label classification loss function, aiming to further improve the detection model's detection accuracy for small thyroid nodules. The experiment results show that the improved DETR model achieves an AP of 92.4% and 81.6% with IoU thresholds of 0.5 and 0.75, respectively.","2024-11","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","6","34","","","","","","","","","","English","","","","WOS:001368764400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","C-TIRADS; computer-aided diagnosis; multi-label object detection; thyroid nodule ultrasound images","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VI248HWV","journalArticle","2024","Shefa, FR; Sifat, FH; Uddin, J; Ahmad, Z; Kim, JM; Kibria, MG","Deep Learning and IoT-Based Ankle-Foot Orthosis for Enhanced Gait Optimization","HEALTHCARE","","2227-9032","10.3390/healthcare12222273","","Background/Objectives: This paper proposes a method for managing gait imbalances by integrating the Internet of Things (IoT) and machine learning technologies. Ankle-foot orthosis (AFO) devices are crucial medical braces that align the lower leg, ankle, and foot, offering essential support for individuals with gait imbalances by assisting weak or paralyzed muscles. This research aims to revolutionize medical orthotics through IoT and machine learning, providing a sophisticated solution for managing gait issues and enhancing patient care with personalized, data-driven insights. Methods: The smart ankle-foot orthosis (AFO) is equipped with a surface electromyography (sEMG) sensor to measure muscle activity and an Inertial Measurement Unit (IMU) sensor to monitor gait movements. Data from these sensors are transmitted to the cloud via fog computing for analysis, aiming to identify distinct walking phases, whether normal or aberrant. This involves preprocessing the data and analyzing it using various machine learning methods, such as Random Forest, Decision Tree, Support Vector Machine (SVM), Artificial Neural Network (ANN), Long Short-Term Memory (LSTM), and Transformer models. Results: The Transformer model demonstrates exceptional performance in classifying walking phases based on sensor data, achieving an accuracy of 98.97%. With this preprocessed data, the model can accurately predict and measure improvements in patients' walking patterns, highlighting its effectiveness in distinguishing between normal and aberrant phases during gait analysis. Conclusions: These predictive capabilities enable tailored recommendations regarding the duration and intensity of ankle-foot orthosis (AFO) usage based on individual recovery needs. The analysis results are sent to the physician's device for validation and regular monitoring. Upon approval, the comprehensive report is made accessible to the patient, ensuring continuous progress tracking and timely adjustments to the treatment plan.","2024-11","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","22","12","","","","","","","","","","English","","","","WOS:001365382900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","ankle-foot orthosis; good health and well-being; healthcare; Internet of Things; machine learning; wearable device","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FPBQDWSY","journalArticle","2024","Zhao, JY; Wang, ZH","Specialized convolutional transformer networks for estimating battery health via transfer learning","ENERGY STORAGE MATERIALS","","2405-8297","10.1016/j.ensm.2024.103668","","Despite continuous advancements, modeling and predicting nonlinear, multiscale, and multiphysics battery systems, which feature inherently inhomogeneous cascades of scales, remains challenging. Deep learning offers a promising alternative by automatically extracting high-dimensional features, enhancing predictions for complex battery systems. However, existing methods fall short in achieving accurate real-time responses due to high training costs and limited generalization. To address this, we developed specialized deep neural networks for health status estimation using transfer learning. Specifically, our method employs a specialized Transformer model for time series prediction with a multi-head probsparse self-attention mechanism to conserve computational resources and improve estimation efficiency. Additionally, one-dimensional (1-D) convolution captures underlying degradation patterns for state of health (SOH) estimation. Transfer learning enables real-time SOH estimation using only charging features and labeled capacities from previous cycles. The proposed method was validated using two datasets, each with different battery chemistries and charge-discharge configurations: 77 lithium iron phosphate (LFP) batteries (nominal capacity 1.1 Ah) and 30 nickel cobalt aluminum (NCA) batteries (nominal capacity 3.5 Ah). We transferred knowledge from 57 LFP batteries to 20 same-batch batteries, achieving an RMSE of 0.247%, an R2 of 99.8%, a WMAPE of 0.223%, and an MAE of 0.202%. Additionally, we applied the transfer learning model trained on the LFP batteries to a dataset of 30 NCA batteries, achieving an RMSE of 0.687%, an R2 of 96.8%, a WMAPE of 0.443%, and an MAE of 0.523%. Overall, the proposed specialized network architectures have demonstrated remarkable power in achieving accurate predictions, fast training, and enhanced generalization.","2024-08","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","71","","","","","","","","","","English","","","","WOS:001286067600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Battery; Convolution; Health; MANAGEMENT; PREDICTION; STATE; Transfer learning; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BKPA6V62","journalArticle","2024","Ai, HZ; Han, D; Wang, XZ; Liu, QY; Wang, Y; Li, MY; Zhu, P","Early fire detection technology based on improved transformers in aircraft cargo compartments","JOURNAL OF SAFETY SCIENCE AND RESILIENCE","","2096-7527","10.1016/j.jnlssr.2024.03.003","","The implementation of early and accurate detection of aircraft cargo compartment fire is of great significance to ensure flight safety. The current airborne fire detection technology mostly relies on single-parameter smoke detection using infrared light. This often results in a high false alarm rate in complex air transportation environments. The traditional deep learning model struggles to effectively address the issue of long-term dependency in multivariate fire information. This paper proposes a multi-technology collaborative fire detection method based on an improved transformers model. Dual-wavelength optical sensors, flue gas analyzers, and other equipment are used to carry out multi-technology collaborative detection methods and characterize various feature dimensions of fire to improve detection accuracy. The improved Transformer model which integrates the self-attention mechanism and position encoding mechanism is applied to the problem of long-time series modeling of fire information from a global perspective, which effectively solves the problem of gradient disappearance and gradient explosion in traditional RNN (recurrent neural network) and CNN (convolutional neural network). Two different multi-head self-attention mechanisms are used to classify and model multivariate fire information, respectively, which solves the problem of confusing time series modeling and classification modeling in dealing with multivariate classification tasks by a single attention mechanism. Finally, the output results of the two models are fused through the gate mechanism. The research results show that, compared with the traditional single-feature detection technology, the multi-technology collaborative fire detection method can better capture fire information. Compared with the traditional deep learning model, the multivariate fire prediction model constructed by the improved Transformer can better detect fires, and the accuracy rate is 0.995.","2024-06","2025-02-26 20:43:28","2025-02-26 20:43:28","","194-203","","2","5","","","","","","","","","","English","","","","WOS:001229009200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Aircraft cargo compartment; Attention mechanism; Deep learning; Fire detection; Multi-source data fusion; SENSOR","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2CX7BLKG","journalArticle","2024","D'Agostino, D; Ilievski, I; Shoemaker, CA","Learning active subspaces and discovering important features with Gaussian radial basis functions neural networks","NEURAL NETWORKS","","0893-6080","10.1016/j.neunet.2024.106335","","Providing a model that achieves a strong predictive performance and is simultaneously interpretable by humans is one of the most difficult challenges in machine learning research due to the conflicting nature of these two objectives. To address this challenge, we propose a modification of the radial basis function neural network model by equipping its Gaussian kernel with a learnable precision matrix. We show that precious information is contained in the spectrum of the precision matrix that can be extracted once the training of the model is completed. In particular, the eigenvectors explain the directions of maximum sensitivity of the model revealing the active subspace and suggesting potential applications for supervised dimensionality reduction. At the same time, the eigenvectors highlight the relationship in terms of absolute variation between the input and the latent variables, thereby allowing us to extract a ranking of the input variables based on their importance to the prediction task enhancing the model interpretability. We conducted numerical experiments for regression, classification, and feature selection tasks, comparing our model against popular machine learning models, the state-of-the-art deep learning-based embedding feature selection techniques, and a transformer model for tabular data. Our results demonstrate that the proposed model does not only yield an attractive prediction performance compared to the competitors but also provides meaningful and interpretable results that potentially could assist the decision-making process in real-world applications. A PyTorch implementation of the model is available on GitHub at the following link. 1","2024-08","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","176","","","","","","","","","","English","","","","WOS:001265842500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;85</p>","","","Active subspace; APPROXIMATION; DIMENSION REDUCTION; Dimensionality reduction; Explainable AI; EXPLAINABLE ARTIFICIAL-INTELLIGENCE; Feature selection; MODEL; OPTIMIZATION; PREDICTION; Radial Basis Function Neural Networks; RECOGNITION; REGRESSION; Supervised learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QYNYNA5H","journalArticle","2024","Huo, H; Li, BJ","MgMViT: Multi-Granularity and Multi-Scale Vision Transformer for Efficient Action Recognition","ELECTRONICS","","2079-9292","10.3390/electronics13050948","","Nowadays, the field of video-based action recognition is rapidly developing. Although Vision Transformers (ViT) have made great progress in static image processing, they are not yet fully optimized for dynamic video applications. Convolutional Neural Networks (CNN) and related models perform exceptionally well in video action recognition. However, there are still some issues that cannot be ignored, such as high computational costs and large memory consumption. In the face of these issues, current research focuses on finding effective methods to improve model performance and overcome current limits. Therefore, we present a unique Vision Transformer model based on multi-granularity and multi-scale fusion to accomplish efficient action recognition, which is designed for action recognition in videos to effectively reduce computational costs and memory usage. Firstly, we devise a multi-scale, multi-granularity module that integrates with Transformer blocks. Secondly, a hierarchical structure is utilized to manage information at various scales, and we introduce multi-granularity on top of multi-scale, which allows for a selective choice of the number of tokens to enter the next computational step, thereby reducing redundant tokens. Thirdly, a coarse-fine granularity fusion layer is introduced to reduce the sequence length of tokens with lower information content. The above two mechanisms are combined to optimize the allocation of resources in the model, further emphasizing critical information and reducing redundancy, thereby minimizing computational costs. To assess our proposed approach, comprehensive experiments are conducted by using benchmark datasets in the action recognition domain. The experimental results demonstrate that our method has achieved state-of-the-art performance in terms of accuracy and efficiency.","2024-03","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","5","13","","","","","","","","","","English","","","","WOS:001182670400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","action recognition; efficiency; multi-granularity multi-scale fusion; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6U9V4UG6","journalArticle","2024","Qi, N; Piao, Y; Zhang, H; Wang, Q; Wang, Y","Seizure prediction based on improved vision transformer model for EEG channel optimization","COMPUTER METHODS IN BIOMECHANICS AND BIOMEDICAL ENGINEERING","","1025-5842","10.1080/10255842.2024.2326097","","Epileptic seizures are unpredictable events caused by abnormal discharges of a patient's brain cells. Extensive research has been conducted to develop seizure prediction algorithms based on long-term continuous electroencephalogram (EEG) signals. This paper describes a patient-specific seizure prediction method that can serve as a basis for the design of lightweight, wearable and effective seizure-prediction devices. We aim to achieve two objectives using this method. The first aim is to extract robust feature representations from multichannel EEG signals, and the second aim is to reduce the number of channels used for prediction by selecting an optimal set of channels from multichannel EEG signals while ensuring good prediction performance. We design a seizure-prediction algorithm based on a vision transformer (ViT) model. The algorithm selects channels that play a key role in seizure prediction from 22 channels of EEG signals. First, we perform a time-frequency analysis of processed time-series signals to obtain EEG spectrograms. We then segment the spectrograms of multiple channels into many non-overlapping patches of the same size, which are input into the channel selection layer of the proposed model, named Sel-JPM-ViT, enabling it to select channels. Application of the Sel-JPM-ViT model to the Boston Children's Hospital-Massachusetts Institute of Technology scalp EEG dataset yields results using only three to six channels of EEG signals that are slightly better that the results obtained using 22 channels of EEG signals. Overall, the Sel-JPM-ViT model exhibits an average classification accuracy of 93.65%, an average sensitivity of 94.70% and an average specificity of 92.78%.","2024-03-01","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","","","","","","","","","","","English","","","","WOS:001180467100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","channel selection; EEG; EPILEPSY; seizure prediction; SELECTION; ViT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TIP7E3W2","journalArticle","2024","Meng, LW; Wang, J; Meng, R; Yang, Y; Xiao, L","A Multiscale Grouping Transformer With CLIP Latents for Remote Sensing Image Captioning","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2024.3385500","","Recent progress has shown that integrating multiscale visual features with advanced Transformer architectures is a promising approach for remote sensing image captioning (RSIC). However, the lack of local modeling ability in self-attention may potentially lead to inaccurate contextual information. Moreover, the scarcity of trainable image-caption pairs poses challenges in effectively harnessing the semantic alignment between images and texts. To mitigate these issues, we propose a Multiscale Grouping Transformer with CLIP latents (MG-Transformer) for RSIC. First of all, a CLIP image embedding and a set of region features are extracted within a multilevel feature extraction (MFE) module. To achieve a comprehensive image representation, a semantic correlation (SC) module is designed to integrate the image embedding and region features with an attention gate. Subsequently, the integrated image features are fed into a Transformer model. The Transformer encoder utilizes dilated convolutions (DCs) with different dilation rates to obtain multiscale visual features. To enhance the local modeling ability of the self-attention mechanism in the encoder, we introduce a global grouping attention (GGA) mechanism. This mechanism incorporates a grouping operation into self-attention, allowing each attention head to focus on different contextual information. The Transformer decoder then adopts the meshed cross-attention mechanism to establish relationships between various scales of visual features and text features. This facilitates the generation of captions for images by the decoder. Experimental results on three RSIC datasets demonstrate the superiority of the proposed MG-Transformer. The code will be publicly available at https://github.com/One-paper-luck/MG-Transformer.","2024","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","62","","","","","","","","","","English","","","","WOS:001205808000019","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","Contrastive language-image pre-training (CLIP); Correlation; Decoding; Feature extraction; grouping; Logic gates; multiscale; NETWORKS; remote sensing image captioning (RSIC); Semantics; transformer; Transformers; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UUQY7RBJ","journalArticle","2023","Liao, LP; Zhu, K; Luo, JZ; Cai, J","LogBASA: Log Anomaly Detection Based on System Behavior Analysis and Global Semantic Awareness","INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS","","0884-8173","10.1155/2023/3777826","","System log anomaly detection is important for ensuring stable system operation and achieving rapid fault diagnosis. System log sequences include data on the execution paths and time stamps of system tasks in addition to a large amount of semantic information, which enhances the reliability and effectiveness of anomaly detection. At the same time, considering the correlation between system log sequences can effectively improve fault diagnosis efficiency. However, the existing system log anomaly detection methods mostly consider only the sequence patterns or semantic information on the logs, so their anomaly detection results show a high rate of missed and false alarms. To solve these problems, this paper proposed an unsupervised log anomaly detection model (LogBASA) based on the system behavior analysis and global semantic awareness, aiming to decrease the leakage rate and increase the log sequence anomaly detection accuracy. First, a system log knowledge graph was constructed based on massive, unstructured, and multilevel system log data to represent log sequence patterns, which facilitates subsequent anomaly detection and localization. Then, a self-attention encoder-decoder transformer model was developed for log spatiotemporal association analysis. This model combines semantic mapping and spatiotemporal features of log sequences to analyze system behavior and log semantics in multiple dimensions. Furthermore, a system log anomaly detection method that combines adaptive spatial boundary delineation and sequence reconstruction objective functions was proposed. This method uses special words to characterize the log sequence states, delineates anomaly boundaries automatically, and reconstructs log sequences through unsupervised training for anomaly detection. Finally, the proposed method was verified by numerous experiments on three real datasets. The results indicate that the proposed method can achieve an accuracy rate of 99.3%, 95.1%, and 97.2% on HDFS, BGL, and Thunderbird datasets, which proves the effectiveness and superiority of the LogBASA model.","2023-09-20","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","2023","","","","","","","","","","English","","","","WOS:001073269600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","SUPPORT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BJ75DE2S","journalArticle","2023","Wang, HR; Guo, XY; Song, KW; Sun, MY; Shao, YB; Xue, SF; Zhang, HW; Zhang, TY","OCTFormer: An Efficient Hierarchical Transformer Network Specialized for Retinal Optical Coherence Tomography Image Recognition","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2023.3329106","","Diabetic retinopathy (DR) is a common complication of diabetes and one of the main causes of blindness in humans, which can be prevented by early-stage detection and treatment. Clinically, ophthalmologists use optical coherence tomography (OCT) image analysis as a basis for diagnosing DR. The existing medical resources can no longer meet the needs of the escalating patient population. Therefore, deep-learning technology has become a mainstream solution for medical image analysis. Vision transformer (ViT), a new neural network structure, has demonstrated great performance in analyzing images. However, due to the lack of inductive bias and prohibition of input image changes in size, ViT cannot avoid over-fitting problems on small datasets and limits the model to biological tissue characteristics. Thus, we propose an OCT multihead self-attention (OMHSA) block that especially calculates OCT image information based on a hybrid CNN-Transformer strategy. Compared to traditional MHSA, OMHSA integrates local information extraction differences into the calculation of self-attention and adds local information to the transformer model without relying on a multibranch network establishment. We built a neural network architecture (OCTFormer) by stacking convolutional layers and OMHSA blocks repeatedly in each stage. Similar to CNN, OCTFormer allows input size change at each stage to achieve a hierarchical structure effect. The model diagnosis effectiveness on the collected retinal OCT dataset was evaluated, and the accuracy reached 98.60%, surpassing the state-of-the-art (SOTA) model. The OCTFormer deployment to mobile terminals through knowledge distillation technology was shown, which presented a reference for deploying transformer models to actual clinical environments.","2023","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","72","","","","","","","","","","English","","","","WOS:001111852400013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Computer-aided diagnosis; deep learning; image classification; MACULAR EDEMA; MECHANISMS; optical coherence tomography (OCT); vision transformer (ViT)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2KVV34F8","journalArticle","2022","Chen, XY; Li, RJ; Yu, YY; Shen, YW; Li, WY; Zhang, Y; Zhang, ZY","POViT: Vision Transformer for Multi-Objective Design and Characterization of Photonic Crystal Nanocavities","NANOMATERIALS","","2079-4991","10.3390/nano12244401","","We study a new technique for solving the fundamental challenge in nanophotonic design: fast and accurate characterization of nanoscale photonic devices with minimal human intervention. Much like the fusion between Artificial Intelligence and Electronic Design Automation (EDA), many efforts have been made to apply deep neural networks (DNN) such as convolutional neural networks to prototype and characterize next-gen optoelectronic devices commonly found in Photonic Integrated Circuits. However, state-of-the-art DNN models are still far from being directly applicable in the real world: e.g., DNN-produced correlation coefficients between target and predicted physical quantities are about 80%, which is much lower than what it takes to generate reliable and reproducible nanophotonic designs. Recently, attention-based transformer models have attracted extensive interests and been widely used in Computer Vision and Natural Language Processing. In this work, we for the first time propose a Transformer model (POViT) to efficiently design and simulate photonic crystal nanocavities with multiple objectives under consideration. Unlike the standard Vision Transformer, our model takes photonic crystals as input data and changes the activation layer from GELU to an absolute-value function. Extensive experiments show that POViT significantly improves results reported by previous models: correlation coefficients are increased by over 12% (i.e., to 92.0%) and prediction errors are reduced by an order of magnitude, among several key metric improvements. Our work has the potential to drive the expansion of EDA to fully automated photonic design (i.e., PDA). The complete dataset and code will be released to promote research in the interdisciplinary field of materials science/physics and computer science.","2022-12","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","24","12","","","","","","","","","","English","","","","WOS:000904440600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","deep learning; lasers; nanophotonics; OPTIMIZATION; photonic crystals; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q2W355R4","journalArticle","2022","Bozuyla, M; Özçift, A","Developing a fake news identification model with advanced deep language transformers for Turkish COVID-19 misinformation data","TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES","","1300-0632","10.3906/elk-2106-55","","The massive use of social media causes rapid information dissemination that amplifies harmful messages such as fake news. Fake-news is misleading information presented as factual news that is generally used to manipulate public opinion. In particular, fake news related to COVID-19 is defined as 'infodemic' by World Health Organization. An infodemic is a misleading information that causes confusion which may harm health. There is a high volume of misinformation about COVID-19 that causes panic and high stress. Therefore, the importance of development of COVID-19 related fake news identification model is clear and it is particularly important for Turkish language from COVID-19 fake news identification point of view. In this article, we propose an advanced deep language transformer model to identify the truth of Turkish COVID-19 news from social media. For this aim, we first generated Turkish COVID-19 news from various sources as a benchmark dataset. Then we utilized five conventional machine learning algorithms (i.e. Naive Bayes, Random Forest, K-Nearest Neighbor, Support Vector Machine, Logistic Regression) on top of several language preprocessing tasks. As a next step, we used novel deep learning algorithms such as Long Short -Term Memory, Bi-directional Long-Short-Term-Memory, Convolutional Neural Networks, Gated Recurrent Unit and Bi-directional Gated Recurrent Unit. For further evaluation, we made use of deep learning based language transformers, i.e. Bi-directional Encoder Representations from Transformers and its variations, to improve efficiency of the proposed approach. From the obtained results, we observed that neural transformers, in particular Turkish dedicated transformer BerTURK, is able to identify COVID-19 fake news in 98.5% accuracy.","2022","2025-02-26 20:43:28","2025-02-26 20:43:28","","908-926","","3","30","","","","","","","","","","English","","","","WOS:000774599800026","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","BerTURK; COVID-19; fake news; Infodemic; language transformers; machine learning; SCIENCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KFURUCDW","journalArticle","2021","Gao, Y; Ruan, YJ","Interpretable deep learning model for building energy consumption prediction based on attention mechanism","ENERGY AND BUILDINGS","","0378-7788","10.1016/j.enbuild.2021.111379","","An effective and accurate building energy consumption prediction model is an important means to effectively use building management systems and improve energy efficiency. To cope with the development and changes in digital data, data-driven models, especially deep learning models, have been applied for the prediction of energy consumption and have achieved good accuracy. However, as a deep learning model that can process high-dimensional data, the model often lacks interpretability, which limits the further application and promotion of the model. This paper proposes three interpretable encoder and decoder models based on long short-term memory (LSTM) and self-attention. Attention based on hidden layer states and feature-based attention improves the interpretability of the deep learning models. A case study of one office building is discussed to demonstrate the proposed method and models. Firstly, the addition in future real weather information yields only a 0.54% improvement in the MAPE. The visualization of the model attention weights improves the interpretability of the model at the hidden state level and feature level. For the hidden state of different time steps, the LSTM network will focus on the hidden state of the last time step because it contains more information. The Transformer model gives almost equal attention weight to each day in the coding sequence. For the interpretable results at the feature level, daily max temperature, mean temperature, min temperature, and dew point temperature are the four most important features. The four characteristics of pressure, wind speed-related features, and holidays have the lowest average weights. (c) 2021 Elsevier B.V. All rights reserved.","2021-12-01","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","252","","","","","","","","","","English","","","","WOS:000709411400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;74<br/>Total Times Cited:&nbsp;&nbsp;76<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Attention; Building energy forecasting; Encoder and decoder; Interpretable deep learning model; NEURAL-NETWORKS; SHORT-TERM; STRATEGY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3B4EUMSX","journalArticle","2025","Wu, ZY; Zhang, YD; Lu, T; Zhao, KH; Wang, JM","Contour-texture preservation transformer for face super-resolution","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2025.129549","","In the field of computer vision, face super-resolution (FSR) technology is an important tool for enhancing the performance of basic tasks such as face recognition and video surveillance. However, when faced with complex face images, existing FSR methods often rely on the Transformer model to improve image quality through its powerful global modeling capabilities. Yet, they tend to be slightly insufficient in local feature extraction due to a lack of adequate local detail capture capabilities. To alleviate these problems, we propose a novel contour- texture preservation Transformer (CTP) method for FSR. This method consists of two key components: the multi-scale attention enhancement block (MSAEB), which captures and fuses image features of different scales to improve the detail level of feature representation, and provides high-quality input for the contour-texture Transformer enhancement block (CTTEB). Additionally, CTTEB integrates convolution operations to enhance local feature extraction and improve feature expression. The feed-forward network (FFN) we introduced ensures the full fusion of global and local information. By combining MSAEB and CTTEB into a residual progressive attention group (RPAG), the network gradually extracts and fuses multi-scale features, ultimately achieving dual preservation of contour structure and texture details. Experiments show that our method achieves the best results on LFW, FFHQ, CelebA, and Helen, with a 0.32 dB increase in PSNR, a 0.0126 increase in SSIM, and a 0.0056 increase in FSIM over the second-best model. Experiments on real-world datasets SCface and Chokepoint confirm that the CTP method excels in both FSR reconstruction and face recognition, verifying its effectiveness.","2025-04-14","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","626","","","","","","","","","","English","","","","WOS:001424329200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","Contour structure; Face recognition; Face super-resolution; GENERATIVE ADVERSARIAL NETWORK; HALLUCINATION; IMAGE SUPERRESOLUTION; Texture details","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YVYF4EW6","journalArticle","2025","Bhushan, K; Singh, S; Kumar, K; Kumar, P","Deep learning based automated vein recognition using swin transformer and super graph glue model","KNOWLEDGE-BASED SYSTEMS","","0950-7051","10.1016/j.knosys.2024.112929","","Finger vein recognition is a secure and emerging biometric modality, including applications from automated portals at immigration checkpoints to most contributive amenities like pay-by-finger and accessing PC. Its reliability makes it integral in embedded systems, including ATMs and access control systems. Despite recent breakthroughs in finger vein verification, current methods are completely reliant on domain expertise and lack the scalability required to identify finger vein features from raw photos. The swin transformer (SwinT) and the super graph glue model are used in this study to develop a deep learning-based automatic vein recognition solution. The finger vein images were initially gathered from three publicly available datasets: the finger vein dataset, Published_database_FV_USM, and HKPU dataset. Then, pre-processing is applied based on the determined quality of data from the dataset. The extended rolling guidance filter (ExRoLL) is used for filtering, and the contrast-limited adaptive histogram equalization (CLAHE) approach is used for contrast enhancement. The osprey depthwise separable swin transformer model (ODSwiT) was then utilized to extract features such as Mean, Contrast, Energy, Smoothness, and vein pattern. The osprey optimization algorithm (OspA) was utilized to optimize the network model's hyperparameters. Finally, using the super graph glue (SGG) model, match the retrieved features from both training and testing. By matching the traits, the suggested technique determines whether the user is a real individual or an imposter. The suggested model has a high accuracy of 0.98113 % for finger vein, 0.99085 % for Published_database_FV_USM, and 0.984 % for HKPU Dataset when compared to current models.","2025-02-15","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","310","","","","","","","","","","English","","","","WOS:001397545700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","CLAHE; Finger vein recognition; FINGER-VEIN; FUSION; Guidance filter; Super graph glue; Swin transformer; Vein pattern","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8GH7EERL","journalArticle","2024","Le, NT; Truong, TL; Deelertpaiboon, S; Srisiri, W; Pongsachareonnont, PF; Suwajanakorn, D; Mavichak, A; Itthipanichpong, R; Asdornwised, W; Benjapolakul, W; Chaitusaney, S; Kaewplung, P","ViT-AMD: A New Deep Learning Model for Age-Related Macular Degeneration Diagnosis From Fundus Images","INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS","","0884-8173","10.1155/2024/3026500","","Age-related macular degeneration (AMD) diagnosis using fundus images is one of the critical missions of the eye-care screening program in many countries. Various proposed deep learning models have been studied for this research interest, which aim to achieve the mission and outperform human-based approaches. However, research efforts are still required for the improvement of model classification accuracy, sensitivity, and specificity values. In this study, we proposed the model named as ViT-AMD, which is based on the latest Vision Transformer (ViT) structure, to diagnosis a fundus image as normal, dry AMD, or wet AMD types. Unlike convolution neural network models, ViT consists of the attention map layers, which show more effective performance for image classification task. Our training process is based on the 5-fold cross-validation and transfer learning techniques using Chula-AMD dataset at the Department of Ophthalmology, the King Chulalongkorn Memorial Hospital, Bangkok. Furthermore, we also test the performance of trained model using an independent image datasets. The results showed that for the 3-classes AMD classification (normal vs. dry AMD vs. wet AMD) on the Chula-AMD dataset, the averaged accuracy, precision, sensitivity, and specificity of our trained model are about 93.40%, 92.15%, 91.27%, and 96.57%, respectively. For result testing on independent datasets, the averaged accuracy, precision, sensitivity, and specificity of trained model are about 74,20%, 75.35%, 74.13%, and 87.07%, respectively. Compared with the results from the baseline CNN-based model (DenseNet201), the trained ViT-AMD model has outperformed significantly. In conclusion, the ViT-AMD model have proved their usefulness to assist the ophthalmologist to diagnosis the AMD disease.","2024-11-15","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","2024","","","","","","","","","","English","","","","WOS:001362656600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","5-fold cross-validation; age-related macular degeneration (AMD); POPULATION; PREVALENCE; retinal fundus image; transfer learning; Vision Transformer model (ViT)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UDS3PHXH","journalArticle","2025","Zhang, X; Lin, MJ; Hong, Y; Xiao, H; Chen, CM; Chen, HW","MSFT: A multi-scale feature-based transformer model for arrhythmia classification","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2024.106968","","Electrocardiogram (ECG) stands as a pivotal non-invasive technique utilized for the diagnosis of heart diseases. Deep learning methodologies are progressively being employed to effectively classify cardiovascular diseases based on ECG signals. Nonetheless, developing a precise and efficacious arrhythmia classification system remains a formidable challenge. In response, this paper proposed the Multi-Scale Feature-based Transformer (MSFT) model for the major types of arrhythmia classification. In the model, we employed a multi-branch convolutional layer structure to extract features that encompass the optimal receptive field. To improve the ability of the model in sensing the location of the time series, we introduced both absolute and relative position encoding methods. Particularly, biased relative position encoding (B-RPE) was innovatively embedded into the probsparse multihead attention (PS-MHA) structure, allowing the model to balance inference capability and inference speed. For empirical validation, ECG records are drawn from the esteemed MIT-BIH arrhythmia database, a publicly accessible and authoritative source. We discretized the ECG records into fixed-length segments using the continuous-time data streaming segmentation approach. Simultaneously, the overlapping window technique was strategically employed to redress the distribution imbalance within sample categories. The experimental outcomes across various evaluation metrics unequivocally validated the remarkable superiority of our methodology. Specifically, a macro-averaged accuracy of 99.40 %(+0.03 %), precision of 99.40 %(+0.03 %), sensitivity of 99.40 %(+0.03 %), specificity of 99.85 %(+0.01 %), and the F1 score of 99.40 %(+0.03 %). Furthermore, the model introduced in this study presents a significant methodological paradigm that can be extended to analogous bio-signal studies.","2025-02","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","100","","","","","","","","","","English","","","","WOS:001331311000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Arrhythmia; Classification; CONVOLUTIONAL NEURAL-NETWORK; ECG; Electrocardiogram (ECG); Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DGK4TDBZ","journalArticle","2024","Zhang, KY; Wu, F; Zhang, GW; Liu, JW; Li, M","BVA-Transformer: Image-text multimodal classification and dialogue model architecture based on Blip and visual attention mechanism","DISPLAYS","","0141-9382","10.1016/j.displa.2024.102710","","Multimodal tasks have become a hot research direction in recent years. The emergence of large-scale models has gradually elevated the extensive multimodal tasks, achieving remarkable achievements. However, when it comes to fusing multiple modalities for multimodal tasks, how to better integrate multimodal features is still a problem worth exploring. In tasks such as sentiment analysis targeting a wide range of social media content, the use of features derived solely from the [CLS] token may lead to insufficient information. This paper proposes BVA-Transformer model architecture for image -text multimodal classification and dialogue, which incorporates the EF-CaTrBERT method for feature fusion and introduces BLIP for the transformation of images to the textual space. This enables the fusion of images and text in the same information space, avoiding issues of information redundancy and conflict compared to traditional feature fusion methods. In addition, we proposed a Global Features Encoder (GFE) module based on visual attention in the BVA-Transformer, which can provide more global and targeted auxiliary features for the [CLS] token. This enables the model to utilize more feature information in classification tasks under this feature fusion method and dynamically select information to focus on. We also introduced the Trv structure from EVA-02 in the Decoder part of BVA-Transformer, investigating its impact on the model performance. Furthermore, we designed a three -stage training to further enhance the model's performance. Experimental results demonstrate that BVA-Transformer achieves high -quality classification while generating dialogue sentences. Compared to existing multimodal classification models on our validation dataset, it exhibits excellent performance.","2024-07","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","83","","","","","","","","","","English","","","","WOS:001229981200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","Bert; BLIP; Dialogue; Sentiment classification; Transformer; Visual attention mechanism","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VN9Q6B4F","journalArticle","2024","Hossain, MM; Hossain, MS; Hossain, MS; Mridha, MF; Safran, M; Alfarhood, S","TransNet: Deep Attentional Hybrid Transformer for Arabic Posts Classification","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3441323","","Sentiment analysis is important for comprehending attitudes and emotions, and popular social media platform X (formally Twitter) is useful in this context. For sentiment analysis of English texts, several approaches are available but the Arabic language calls for more specialized study because of its unique qualities and subtleties. This paper presents TransNet, a Deep Attentional Hybrid Transformer model designed to classify asthma-related Arabic social media messages. TransNet combines the sequential learning capabilities of Gated Recurrent Units (GRUs) and Long Short-Term Memory Networks (LSTMs) with the resilient attention mechanisms of Transformers. The model can extract complex patterns and relationships from textual input efficiently. We use label encoding and upsampling approaches to rectify the intrinsic class imbalance in our Kaggle dataset. We also expand the dataset containing Arabic asthma-related tweets with new data, namely by substituting synonyms to add variety to the training set. To better capture the subtleties of the Arabic language, we further improve text representation by adding a pre-trained Bidirectional Encoder Representations from Transformers (BERT) tokenizer. A rigorous collection of baseline models, including Transformer+LSTM, Transformer+GRU, Transformer+CNN, and Transformer+GRU-CNN, are used to assess TransNet's performance. TransNet demonstrates its supremacy with an F1 score of 97.86% and an excellent accuracy of 97.87% in the empirical data. We use Local Interpretable Model-agnostic Explanations (LIME), which helps to understand the mechanism of the model and also ensures that our forecasts are clear and comprehensible. According to our study, TransNet performs better than conventional models in categorizing Arabic asthma postings on social media and gives useful insights.","2024","2025-02-26 20:43:28","2025-02-26 20:43:28","","111070-111096","","","12","","","","","","","","","","English","","","","WOS:001297271800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","Arabic text classification; hybrid transformer; MACHINE; MODEL; NEURAL-NETWORK; sentiment analysis; SENTIMENT ANALYSIS; transformer; TransNet","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VTLAC324","journalArticle","2023","Li, ZR; Silamu, W; Feng, SR; Yan, GH","Focal cross transformer: multi-view brain tumor segmentation model based on cross window and focal self-attention","FRONTIERS IN NEUROSCIENCE","","1662-453X","10.3389/fnins.2023.1192867","","IntroductionRecently, the Transformer model and its variants have been a great success in terms of computer vision, and have surpassed the performance of convolutional neural networks (CNN). The key to the success of Transformer vision is the acquisition of short-term and long-term visual dependencies through self-attention mechanisms; this technology can efficiently learn global and remote semantic information interactions. However, there are certain challenges associated with the use of Transformers. The computational cost of the global self-attention mechanism increases quadratically, thus hindering the application of Transformers for high-resolution images. MethodsIn view of this, this paper proposes a multi-view brain tumor segmentation model based on cross windows and focal self-attention which represents a novel mechanism to enlarge the receptive field by parallel cross windows and improve global dependence by using local fine-grained and global coarse-grained interactions. First, the receiving field is increased by parallelizing the self-attention of horizontal and vertical fringes in the cross window, thus achieving strong modeling capability while limiting the computational cost. Second, the focus on self-attention with regards to local fine-grained and global coarse-grained interactions enables the model to capture short-term and long-term visual dependencies in an efficient manner. ResultsFinally, the performance of the model on Brats2021 verification set is as follows: dice Similarity Score of 87.28, 87.35 and 93.28%; Hausdorff Distance (95%) of 4.58 mm, 5.26 mm, 3.78 mm for the enhancing tumor, tumor core and whole tumor, respectively. DiscussionIn summary, the model proposed in this paper has achieved excellent performance while limiting the computational cost.","2023-05-12","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","17","","","","","","","","","","English","","","","WOS:000994840200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","brain tumor segmentation; CNN; cross window; focal self-attention; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VRCXT43I","journalArticle","2023","Sun, WZ; He, GY; Wang, Q; Yu, F","Numerical Study and Parameter Prediction in Hydrodynamic Performance of Self-Propelled Wiggling Hydrofoils","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3339823","","Fish employ their bodies and caudal fins to generate a counter-propagating traveling wave, which, in conjunction with the surrounding fluid dynamics, results in a propulsion pattern that is both rapid and efficient. From a mathematical perspective, these waves can be represented as traveling waves. This study focuses on simulating the kinematic state of a NACA65-010 self-propelled hydrofoil, operating under low Reynolds number uniform incoming flow, utilizing the immersed boundary method. Additionally, we investigate the alterations in the fish's swimming performance when it actively oscillates by observing the hydrodynamic performance of the model under various oscillation parameters. To streamline the numerical simulation process, we employ the long short-term memory network (LSTM), time-sequential convolutional network (TCN), and transformer model to predict the lift and thrust coefficients of the self-propelled hydrofoil. The outcomes demonstrate that both the trailing edge amplitude and vibration frequency significantly influence the model's propulsion performance, enabling the hydrofoil to generate countercurrent thrust at low Reynolds numbers. Moreover, the average lift and thrust of the self-propelled hydrofoil exhibit gradual increases over time during the forward motion. The LSTM prediction model exhibits superior accuracy and goodness of fit in forecasting the hydrodynamic parameters, with an average absolute error of lift and thrust coefficients below 0.19 and a goodness-of-fit exceeding 0.968. Furthermore, the implementation of this model reduces the overall computational burden of the experimental process by 25%. Through the exploration of oscillation parameters' impact on hydrodynamic performance, this research sheds light on the underlying mechanisms of fish's active swimming. Furthermore, the utilization of deep learning techniques alleviates the computational costs and memory requirements associated with traditional computational fluid dynamics (CFD) methods","2023","2025-02-26 20:43:28","2025-02-26 20:43:28","","139187-139200","","","11","","","","","","","","","","English","","","","WOS:001126110600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","FLOWS; IMMERSED BOUNDARY; immersed boundary method; KINEMATICS; parameter prediction; propulsion effectiveness; Self-propelled hydrofoils","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"85ERB22D","journalArticle","2024","Chen, SY; Wang, H; Zhang, HJ; Peng, CL; Li, Y; Wang, B","A novel method of swin transformer with time-frequency characteristics for ECG-based arrhythmia detection","FRONTIERS IN CARDIOVASCULAR MEDICINE","","2297-055X","10.3389/fcvm.2024.1401143","","Introduction Arrhythmia is an important indication of underlying cardiovascular diseases (CVD) and is prevalent worldwide. Accurate diagnosis of arrhythmia is crucial for timely and effective treatment. Electrocardiogram (ECG) plays a key role in the diagnosis of arrhythmia. With the continuous development of deep learning and machine learning processes in the clinical field, ECG processing algorithms have significantly advanced the field with timely and accurate diagnosis of arrhythmia.Methods In this study, we combined the wavelet time-frequency maps with the novel Swin Transformer deep learning model for the automatic detection of cardiac arrhythmias. In specific practice, we used the MIT-BIH arrhythmia dataset, and to improve the signal quality, we removed the high-frequency noise, artifacts, electromyographic noise and respiratory motion effects in the ECG signals by the wavelet thresholding method; we used the complex Morlet wavelet for the feature extraction, and plotted wavelet time-frequency maps to visualise the time-frequency information of the ECG; we introduced the Swin Transformer model for classification and achieve high classification accuracy of ECG signals through hierarchical construction and self attention mechanism, and combines windowed multi-head self-attention (W-MSA) and shifted window-based multi-head self-attention (SW-MSA) to comprehensively utilise the local and global information.Results To enhance the confidence of the experimental results, we evaluated the performance using intra-patient and inter-patient paradigm analyses, and the model classification accuracies reached 99.34% and 98.37%, respectively, which are better than the currently available detection methods.Discussion The results reveal that our proposed method is superior to currently available methods for detecting arrhythmia ECG. This provides a new idea for ECG based arrhythmia diagnosis.","2024-06-07","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","11","","","","","","","","","","English","","","","WOS:001250871600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","arrhythmia; CLASSIFICATION; deep learning; electrocardiogram; ELECTROCARDIOGRAM; STROKE; swin transformer; wavelet time-frequency map","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YHAE76X5","journalArticle","2024","Wu, J; Dai, TY; Guan, PY; Liu, S; Gou, FF; Taherkordi, A; Li, YS; Li, TY","FedAPT: Joint Adaptive Parameter Freezing and Resource Allocation for Communication-Efficient Federated Vehicular Networks","IEEE INTERNET OF THINGS JOURNAL","","2327-4662","10.1109/JIOT.2024.3367946","","Telematics technology development offers vehicles a range of intelligent and convenient functions, including navigation and mapping services, intelligent driving assistance, and intelligent traffic management. However, since these functions deal with sensitive information like vehicle location and driving habits, it is crucial to address concerns regarding information security and privacy protection. Federated learning (FL) is highly suitable for addressing such problems due to its characteristics, in which a client does not need to share private data and upload model parameters to a parameter server (PS) via the network. This results in the establishment of a federated vehicle network (FVN). As a distributed paradigm, the efficiency of communication is crucial in FL as it impacts all aspects of the FVN. This article introduces a parameter freezing algorithm based on historical information to reduce the data transferred between the client and the PS in each round of communication, thus minimizing the communication overhead of FL. Additionally, we propose using a particle swarm algorithm to allocate network bandwidth to each vehicle based on the packet sizes sent by each vehicle (i.e., the nonfreezing parameters) to minimize the communication latency in each FL round. Furthermore, due to the high time complexity of the particle swarm algorithm, we employ it to generate training data for training a transformer model with fast response and sufficient accuracy, thereby accelerating the bandwidth allocation process. Through extensive experiments, we prove the feasibility of our approach and its efficiency in improving communication in FL.","2024-06-01","2025-02-26 20:43:28","2025-02-26 20:43:28","","19520-19536","","11","11","","","","","","","","","","English","","","","WOS:001285460000064","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Bandwidth; Communication efficiency; Data models; Federated learning; federated learning (FL); OPTIMIZATION; parameter freezing; Particle swarm optimization; particle swarm optimization (PSO); Resource management; Servers; Training; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R3WXU9FV","journalArticle","2024","Lee, S; Hong, J; Liu, L; Choi, W","TS-Fastformer: Fast Transformer for Time-series Forecasting","ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY","","2157-6904","10.1145/3630637","","Many real-world applications require precise and fast time-series forecasting. Recent trends in time-series forecasting models are shifting from LSTM-based models to Transformer-based models. However, the Transformer-based model has a limited ability to represent sequential relationships in time-series data. In addition, the transformer-based model suffers from slow training and inference speed due to the bottleneck incurred by a deep encoder and step-by-step decoder inference. To address these problems, we propose a time-series forecasting optimized Transformer model, called TS-Fastformer. TS-Fastformer introduces three new optimizations: First, we propose a Sub Window Tokenizer for compressing input in a simple manner. The Sub Window Tokenizer reduces the length of input sequences to mitigate the complexity of self-attention and enables both single and multi-sequence learning. Second, we propose Time-series Pre-trained Encoder to extract effective representations through pre-training. This optimization enables TS-Fastformer to capture both seasonal and trend representations as well as to mitigate bottlenecks of conventional transformer models. Third, we propose the Past Attention Decoder to forecast target by incorporating past long short-term dependency patterns. Furthermore, Past Attention Decoder achieves high performance improvement by removing a trend distribution that changes over a long period. We evaluate the efficiency of our model with extensive experiments using seven real-world datasets and compare our model to six representative time-series forecasting approaches. The results show that the proposed TS-Fastformer reduces MSE by 10.1% compared to state-of-the-art model and demonstrates 21.6% faster training time compared to the existing fastest transformer, respectively.","2024-04","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","2","15","","","","","","","","","","English","","","","WOS:001208775700005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Deep learning; time-series forecasting; time-series representation; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DN9AL755","journalArticle","2024","Li, Y; Liu, ZB; Jia, Z; Zhao, W; Wang, K; Qin, XS","Fault Diagnosis Strategy for Flight Control Rudder Circuit Based on SHAP Interpretable Analysis Optimization Transformer With Attention Mechanism","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2024.3470041","","Research on the explanation of the reasons for the output classification results of intelligent diagnostic algorithms is still in its infancy, and interpreting the operation process of intelligent algorithms can help users trust and accept such methods. In this article, we take the intelligent algorithm-based fault diagnosis of the rudder control circuit of an airplane flight control system as an example and carry out research on the interpretability of the diagnostic algorithm based on the Shapley additive explanation (SHAP). The transformer feature capture module is designed in the diagnostic model, which establishes the dependency of the fault timing signals in the time perspective by embedding the attention mechanism and guarantees the ability to classify the dataset with less differentiation. In addition, given the characteristics of circuit data with multiple classes and similar features, this article optimizes the model by designing a new loss function called anomaly data feature enhancement loss (ADFE Loss) in a targeted manner. The loss function can amplify the fault data so that the model can converge faster, thus improving the accuracy and efficiency of fault diagnosis. Based on SHAP, the diagnostic process of the transformer model was analyzed in terms of local and global interpretability, which led to the streamlining of some features and optimization of the model. The results show that the optimized model can maintain a smoother and more accurate diagnostic process in a shorter number of iterations while reducing the consumption of computational resources. Meanwhile, the proposed diagnostic strategy also exhibits better noise robustness.","2024","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","73","","","","","","","","","","English","","","","WOS:001338112400004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Accuracy; Analytical models; Atmospheric modeling; Circuit faults; Computational modeling; Data models; Diagnostics; Fault diagnosis; Integrated circuit modeling; interpretability study; LOOP; Predictive models; rudder controller circuit; Shapley additive explanation (SHAP); SYSTEM; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DPMAE8YL","journalArticle","2024","Zhang, Q; He, Y; Zhang, YL; Lu, JG; Zhang, LF; Huo, TB; Tang, JP; Fang, YM; Zhang, YH","A Graph-Transformer Method for Landslide Susceptibility Mapping","IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING","","1939-1404","10.1109/JSTARS.2024.3437751","","Landslide susceptibility mapping (LSM) is of great significance for regional land resource planning and disaster prevention and reduction. The machine learning (ML) method has been widely used in the field of LSM. However, the existing LSM model fails to consider the correlation between landslide and disaster-prone environment (DPE) and lacks global information, resulting in a high false alarm rate of LSM. Therefore, we propose an LSM method with graph-transformer that considers the DPE characteristics and global information. First, correlation analysis and importance analysis are employed on nine landslide contributing factors, and the landslide dataset is generated by combining remote sensing image interpretation and field verification. Second, a graph constrained by environment similarity relationship is constructed to realize the correlation between landslide and DPE. Then, the transformer module is introduced to construct a graph-transformer model that considers the global information. Finally, the LSM is generated and analyzed, and the accuracy of the proposed model is compared and evaluated. The experimental results show that the environment similarity relationship graph effectively improves the accuracy of the models and weakens the influence of environmental differences on the models. Compared with graph convolutional network, graph sample and aggregate, and graph attention network models, the area under the curve (AUC) value of the proposed model is more than 2.05% higher under the environment similarity relationship. In addition, the AUC value of the proposed model is more than 8.8% higher than that of traditional ML models. In conclusion, our proposed model framework can get better evaluation results than most existing methods, and its results can provide effective ways and key technical support for landslide disaster investigation and control.","2024","2025-02-26 20:43:28","2025-02-26 20:43:28","","14556-14574","","","17","","","","","","","","","","English","","","","WOS:001301018500017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","ENSEMBLE; Environment similarity relationship; graph; landslide susceptibility mapping (LSM); transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YRERSF7N","journalArticle","2023","Wei, XK; Wang, GJ; Schmalz, B; Hagan, DFT; Duan, Z","Evaluation of Transformer model and Self-Attention mechanism in the Yangtze River basin runoff prediction","JOURNAL OF HYDROLOGY-REGIONAL STUDIES","","2214-5818","10.1016/j.ejrh.2023.101438","","Study region: In the Yangtze River basin of China.Study focus: We applied a recently popular deep learning (DL) algorithm, Transformer (TSF), and two commonly used DL methods, Long-Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU), to evaluate the performance of TSF in predicting runoff in the Yangtze River basin. We also add the main structure of TSF, Self-Attention (SA), to the LSTM and GRU models, namely LSTM-SA and GRU-SA, to investigate whether the inclusion of the SA mechanism can improve the prediction capability. Seven climatic observations (mean temperature, maximum temperature, precipitation, etc.) are the input data in our study. The whole dataset was divided into training, validation and test datasets. In addition, we investigated the relationship between model per-formance and input time steps.New hydrological insights for the region: Our experimental results show that the GRU has the best performance with the fewest parameters while the TSF has the worst performance due to the lack of sufficient data. GRU and the LSTM models are better than TSF for runoff prediction when the training samples are limited (such as the model parameters being ten times larger than the samples). Furthermore, the SA mechanism improves the prediction accuracy when added to the LSTM and the GRU structures. Different input time steps (5 d, 10 d, 15 d, 20 d, 25 d and 30 d) are used to train the DL models with different prediction lengths to understand their relationship with model performance, showing that an appropriate input time step can significantly improve the model performance.","2023-06","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","47","","","","","","","","","","English","","","","WOS:001043860100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;21<br/>Total Times Cited:&nbsp;&nbsp;23<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","CHINA; EXTREMES; GRU; LSTM; Runoff prediction; Self-Attention; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZLFWMGBD","journalArticle","2023","Fang, LY; Kuang, Y; Liu, Q; Yang, Y; Yue, J","Rethinking Remote Sensing Pretrained Model: Instance-Aware Visual Prompting for Remote Sensing Scene Classification","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2023.3336283","","Large-scale pretrained models, such as vision transformers (ViTs), have made significant progress in remote sensing (RS) scene classification tasks. For a new scene classification task, it is popular to fully fine-tune the pretrained model parameters to avoid training from scratch. Although such an approach achieves satisfactory results, it will lead to heavy computation and storage burden, which limits the transferability of large pretrained models to different RS scene classification tasks. To address this challenge, we propose a parameter-efficient tuning approach called as the instance-aware visual prompting (IVP), which is the first work to explore the prompting in the field of RS scene classification. The proposed IVP adaptively generates prompts based on the complex background and highly variable characteristics of RS images and updates only a few parameters to transfer the pretrained RS transformer model to different scene classification tasks. Specifically, instead of adapting the entire model parameters, we introduce some instance-specific prompt vectors into the input space. Then, considering the significant variability in RS images, we introduce an instance-level prompt generation module to generate specific prompts for each RS image by aggregating contextual information from the input. Finally, these prompt vectors will calibrate the pretrained features to encode instance-specific information. Extensive experiments on three RS scene classification datasets demonstrate the superiority of IVP over other fine-tuning methods. For example, when updating just 1.1% parameters, the Swin transformer (Swin-T) model achieves about 1.83% and 1.42% improvement compared with the full fine-tuning method on NWPU-19 and NWPU-28, respectively.","2023","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","61","","","","","","","","","","English","","","","WOS:001122847500002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Computational modeling; Feature extraction; Image processing; instance-aware prompting; pretrained model; Remote sensing; remote sensing (RS) scene classification; REPRESENTATION; SCALE; Scene classification; SET; Task analysis; transfer learning; Tuning; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3MJVVB7B","journalArticle","2021","Mo, LZ; Wei, JL; Huang, QB; Cai, Y; Liu, QG; Zhang, XM; Li, Q","Incorporating sentimental trend into gated mechanism based transformer network for story ending generation","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2021.01.040","","Story ending generation is a challenging and under-explored task, which aims at generating a coherent, reasonable, and logical story ending given a context. Previous studies mainly focus on utilizing the contextual information and commonsense knowledge to generate story endings. However, there are still some issues must be addressed in the story endings generation processing, such as sentimental consistency and interference from secondary information. In this paper, we propose a Gated Mechanism based Transformer Network (GMTF). The GMTF model utilizes the sentimental trend to make story ending generation more sentimentally consistent with the context. For a given story context, we utilize a sentiment analysis tool VADER to obtain the sentimental trend. Then, the sentimental information and contextual information are input jointly into the transformer network to capture the key clues. Furthermore, the gated mechanism is applied to filter irrelative information and the weights of attention layers for encoder and decoder are shared to make the most of the contextual clues. The experimental results on ROCStories dataset demonstrate that the proposed method achieves 27.03% on BLEU-1, 7.62% on BLEU-2, 1.71 on Grammar, and 1.31 on Logicality, respectively. Specifically, our model outperforms the state-of-the-art model IE+MSA by 0.23%, 0.22%, 1.78%, 5.64%, respectively and the Transformer model by 3.06%, 1.05%, 5.55%, 48.86%, respectively. Both automatic and manual evaluations show that our model can generate more reasonable and appropriate story endings compared with the related well-established approaches. (c) 2021 Elsevier B.V. All rights reserved.","2021-09-17","2025-02-26 20:43:28","2025-02-26 20:43:28","","453-464","","","453","","","","","","","","","","English","","","","WOS:000663418700004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","Gated mechanism; KNOWLEDGE; Sentiment trend; Story ending generation; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RVBIIJQL","journalArticle","2025","Madhushanka, GWTI; Jayasinghe, MTR; Rajapakse, RA","Multiple-Day-Ahead Flood Prediction in the South Asian Tropical Zone Using Deep Learning","JOURNAL OF HYDROLOGIC ENGINEERING","","1084-0699","10.1061/JHYEFF.HEENG-6296","","A reliable and accurate flood forecasting procedure is crucial due to the hazardous nature of such disasters. Despite the growing interest in machine learning models over traditional methods for enhanced accuracy, there is a notable gap in guidelines for selecting the best-suited learning algorithm for flood forecasting. Furthermore, there is a lack of deep learning-based flood simulation studies in the South Asian Tropical Zone. This research addresses these gaps by investigating the viability of artificial neural network (ANN), long short-term memory (LSTM), bidirectional LSTM (BLSTM), two-dimensional (2D) convolutional LSTM (ConvLSTM2D), and transformer models for multiple-day-ahead flood simulation. A forecasting window of 3 days was selected for the task, focusing on the lower reaches of the Mahaweli catchment in Sri Lanka, which is heavily affected by the Northeast Monsoon. Observed rainfall data from three nearby rain gauges and historical discharges from the target river gauge serve as input features for the models. Unlike previous studies that used limited data sets, this study utilizes daily data spanning 28 years in order to examine the behavior of the transformer handling an extensive hydrological data set. The study finds that the ANN model performed the worst, with a mean Nash-Sutcliffe efficiency (NSE) of 0.67, while the transformer model showed superior performance, especially in multiday forecasts, with a mean NSE of 0.72 and a mean root-mean square error of 32.52, showcasing the effectiveness of handling this extensive data set.","2025-02-01","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","1","30","","","","","","","","","","English","","","","WOS:001378420400010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Artificial neural network; EXTREMES; Flood forecasting; Long short-term memory (LSTM); Mahaweli catchment; MODEL; MULTIVARIATE IMPUTATION; South Asian tropical region; STREAMFLOW; SUMMER MONSOON; TEMPERATURE; Transformer; TRENDS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IPWES4US","journalArticle","2024","Shih, DH; Chung, F; Wu, TW; Huang, SY; Shih, MH","Advanced Trans-EEGNet Deep Learning Model for Hypoxic-Ischemic Encephalopathy Severity Grading","MATHEMATICS","","2227-7390","10.3390/math12243915","","Hypoxic-ischemic encephalopathy (HIE) is a brain injury condition that poses a significant risk to newborns, potentially causing varying degrees of damage to the central nervous system. Its clinical manifestations include respiratory distress, cardiac dysfunction, hypotension, muscle weakness, seizures, and coma. As HIE represents a progressive brain injury, early identification of the extent of the damage and the implementation of appropriate treatment are crucial for reducing mortality and improving outcomes. HIE patients may face long-term complications such as cerebral palsy, epilepsy, vision loss, and developmental delays. Therefore, prompt identification and treatment of hypoxic-ischemic symptoms can help reduce the risk of severe sequelae in patients. Currently, hypothermia therapy is one of the most effective treatments for HIE patients. However, not all newborns with HIE are suitable for this therapy, making rapid and accurate assessment of the extent of brain injury critical for treatment. Among HIE patients, hypothermia therapy has shown better efficacy in those diagnosed with moderate to severe HIE within 6 h of birth, establishing this time frame as the golden period for treatment. During this golden period, an accurate assessment of HIE severity is essential for formulating appropriate treatment strategies and predicting long-term outcomes for the affected infants. This study proposes a method for addressing data imbalance and noise interference through data preprocessing techniques, including filtering and SMOTE. It then employs EEGNet, a deep learning model specifically designed for EEG classification, combined with a Transformer model featuring an attention mechanism that excels at capturing long-term sequential features to construct the Trans-EEGNet model. This model outperforms previous methods in computation time and feature extraction, enabling rapid classification and assessment of HIE severity in newborns.","2024-12","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","24","12","","","","","","","","","","English","","","","WOS:001384729500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","deep learning; electroencephalogram (EEG); neonatal hypoxic-ischemic encephalopathy (HIE); OUTCOMES; PREDICTION; SYSTEM; TEMPORAL INFORMATION; THERAPEUTIC HYPOTHERMIA; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R96DYWTW","journalArticle","2024","Lacroix, K; Gholamiangonabadi, D; Trejos, AL; Grolinger, K","Deep Transfer Learning for Detection of Upper and Lower Body Movements: Transformer With Convolutional Neural Network","IEEE SENSORS JOURNAL","","1530-437X","10.1109/JSEN.2024.3451291","","When humans repeat the same motion, the tendons, muscles, and nerves can be damaged, causing repetitive stress injuries (RSIs). If the repetitive motions that lead to RSI are recognized early, actions can be taken to prevent these injuries. As human activity recognition (HAR) aims to identify activities employing wearable or environment sensors, HAR is the first step toward identifying repetitive motions. Deep learning models, such as convolutional neural networks (CNNs), have seen great success in recognizing activities for participants whose data are used in the model training; however, their accuracy drops for new participants as people move in different ways. Moreover, most studies focus on lower body movement, while upper body movements are the main cause of RSI. On the other hand, in recent years, transformers have been dominating natural language processing (NLP) and have the potential to improve modeling in other domains involving sequential data such as HAR. Consequently, this article combines a transformer and CNN (Trans-CNN) for the recognition of upper and lower body movements. Transfer learning was employed to personalize the generic model for the target participant. The experiments demonstrate that the generic Trans-CNN outperforms the standalone Trans-CNN. The accuracy of the generic Trans-CNN for both upper and lower body movements improved from 69.6% to 92.4% when personalization was introduced. All models, irrespective of the algorithm, have more difficulty recognizing the upper body than lower body movements. Nevertheless, the proposed personalized approach for the detection of upper and lower body movements represents significant progress toward RSI prevention.","2024-10-15","2025-02-26 20:43:28","2025-02-26 20:43:28","","33778-33790","","20","24","","","","","","","","","","English","","","","WOS:001338604800092","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Accuracy; Convolutional neural network (CNN); Convolutional neural networks; Data models; deep learning; Feature extraction; Human activity recognition; HUMAN ACTIVITY RECOGNITION; human activity recognition (HAR); personalized models; Sensors; SENSORS; transfer learning; transformer model; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YDACFD3A","journalArticle","2023","Zhou, ZL; Yeung, W; Gravel, N; Salcedo, M; Soleymani, S; Li, S; Kannan, N","Phosformer: an explainable transformer model for protein kinase-specific phosphorylation predictions","BIOINFORMATICS","","1367-4803","10.1093/bioinformatics/btad046","","Motivation: The human genome encodes over 500 distinct protein kinases which regulate nearly all cellular processes by the specific phosphorylation of protein substrates. While advances in mass spectrometry and proteomics studies have identified thousands of phosphorylation sites across species, information on the specific kinases that phosphorylate these sites is currently lacking for the vast majority of phosphosites. Recently, there has been a major focus on the development of computational models for predicting kinase-substrate associations. However, most current models only allow predictions on a subset of well-studied kinases. Furthermore, the utilization of hand-curated features and imbalances in training and testing datasets pose unique challenges in the development of accurate predictive models for kinase-specific phosphorylation prediction. Motivated by the recent development of universal protein language models which automatically generate context-aware features from primary sequence information, we sought to develop a unified framework for kinase-specific phosphosite prediction, allowing for greater investigative utility and enabling substrate predictions at the whole kinome level. Results: We present a deep learning model for kinase-specific phosphosite prediction, termed Phosformer, which predicts the probability of phosphorylation given an arbitrary pair of unaligned kinase and substrate peptide sequences. We demonstrate that Phosformer implicitly learns evolutionary and functional features during training, removing the need for feature curation and engineering. Further analyses reveal that Phosformer also learns substrate specificity motifs and is able to distinguish between functionally distinct kinase families. Benchmarks indicate that Phosformer exhibits significant improvements compared to the state-of-the-art models, while also presenting a more generalized, unified, and interpretable predictive framework. Availability and implementation: Code and data are available at https://github.com/esbgkannan/phosformer. Contact: nkannan@uga.edu or shengli@virginia.edu Supplementary information: Supplementary data are available at Bioinformatics online.","2023-02-03","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","2","39","","","","","","","","","","English","","","","WOS:001186530400004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","CANCER; INFORMATION; POSTTRANSLATIONAL MODIFICATIONS; SITES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CL24PTEX","journalArticle","2022","Pang, L; Sun, JJ; Chi, YC; Yang, YW; Zhang, FL; Zhang, L","CD-TransUNet: A Hybrid Transformer Network for the Change Detection of Urban Buildings Using L-Band SAR Images","SUSTAINABILITY","","2071-1050","10.3390/su14169847","","The change detection of urban buildings is currently a hotspot in the research area of remote sensing, which plays a vital role in urban planning, disaster assessments and surface dynamic monitoring. SAR images have unique characteristics compared with traditional optical images, mainly including abundant image information and large data volume. However, the majority of currently used SAR images for the detection of changes in buildings have the problems of missing the detection of small buildings and poor edge segmentation. Therefore, this paper proposes a new approach based on deep learning for changing building detection, which we called CD-TransUNet. It should be noted that CD-TransUNet is an end-to-end encoding-decoding hybrid Transformer model that combines the UNet and Transformer. Additionally, to enhance the precision of feature extraction and to reduce the computational complexity, the CD-TransUNet integrates coordinate attention (CA), atrous spatial pyramid pooling (ASPP) and depthwise separable convolution (DSC). In addition, by sending the differential images to the input layer, the CD-TransUNet can focus more on building changes over a large scale while ignoring the changes in other land types. At last, we verify the effectiveness of the proposed method using a pair of ALOS-2(L-band) acquisitions, and the comparative experimental results obtained from other baseline models show that the precision of the CD-TransUNet is much higher and the Kappa value can reach 0.795. Furthermore, the low missed alarms and the accurate building edge reflect that the proposed method is more appropriate for building changing detection tasks.","2022-08","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","16","14","","","","","","","","","","English","","","","WOS:000846625500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","CLASSIFICATION; L-band SAR image; lightweight network; Transformer; UNet; urban building change detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M9BQUWYW","journalArticle","2021","He, JZ; You, HF; Sandström, E; Nittinger, E; Bjerrum, EJ; Tyrchan, C; Czechtizky, W; Engkvist, O","Molecular optimization by capturing chemist's intuition using deep neural networks","JOURNAL OF CHEMINFORMATICS","","1758-2946","10.1186/s13321-021-00497-0","","A main challenge in drug discovery is finding molecules with a desirable balance of multiple properties. Here, we focus on the task of molecular optimization, where the goal is to optimize a given starting molecule towards desirable properties. This task can be framed as a machine translation problem in natural language processing, where in our case, a molecule is translated into a molecule with optimized properties based on the SMILES representation. Typically, chemists would use their intuition to suggest chemical transformations for the starting molecule being optimized. A widely used strategy is the concept of matched molecular pairs where two molecules differ by a single transformation. We seek to capture the chemist's intuition from matched molecular pairs using machine translation models. Specifically, the sequence-to-sequence model with attention mechanism, and the Transformer model are employed to generate molecules with desirable properties. As a proof of concept, three ADMET properties are optimized simultaneously: logD, solubility, and clearance, which are important properties of a drug. Since desirable properties often vary from project to project, the user-specified desirable property changes are incorporated into the input as an additional condition together with the starting molecules being optimized. Thus, the models can be guided to generate molecules satisfying the desirable properties. Additionally, we compare the two machine translation models based on the SMILES representation, with a graph-to-graph translation model HierG2G, which has shown the state-of-the-art performance in molecular optimization. Our results show that the Transformer can generate more molecules with desirable properties by making small modifications to the given starting molecules, which can be intuitive to chemists. A further enrichment of diverse molecules can be achieved by using an ensemble of models.","2021-03-20","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","1","13","","","","","","","","","","English","","","","WOS:000630861600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;52<br/>Total Times Cited:&nbsp;&nbsp;54<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","ADMET; DESIGN; GENERATION; Matched molecular pairs; MODEL; Molecular optimization; PAIRS; Recurrent neural networks; Seq2seq; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JT8UJITC","journalArticle","2025","Feng, Z; Yan, BC; Shen, XD; Zhang, FS; Tariq, Z; Ouyang, WQ; Han, ZL","A hybrid CNN-transformer surrogate model for the multi-objective robust optimization of geological carbon sequestration","ADVANCES IN WATER RESOURCES","","0309-1708","10.1016/j.advwatres.2025.104897","","The optimization of well controls over time constitutes an essential step in the design of cost-effective and safe geological carbon sequestration (GCS) projects. However, the computational expense of these optimization problems, due to the extensive number of simulation evaluations, presents significant challenges for real-time decision-making. In this paper, we propose a hybrid CNN-Transformer surrogate model to accelerate the well control optimization in GCS applications. The surrogate model encompasses a Convolution Neural Network (CNN) encoder to compress high-dimensional geological parameters, a Transformer processor to learn global patterns inherent in the well controls over time, and a CNN decoder to map the latent variables to the target solution variables. The surrogate model is trained to predict the spatiotemporal evolution of CO2 saturation and pressure within 3D heterogeneous permeability fields under dynamic CO2 injection rates. Results demonstrate that the surrogate model exhibits satisfactory performance in the context of prediction accuracy, computation efficiency, data scalability, and out-of-distribution generalizability. The surrogate model is further integrated with Multi-Objective Robust Optimization (MORO). Pareto optimal well controls are determined based on Non- dominated Sorting-based Genetic Algorithm II (NSGA-II), which maximize the storage efficiency and minimize the induced over-pressurization across an ensemble of uncertain geological realizations. The surrogate-based MORO reduces computational time by 99.99 % compared to simulation-based optimization. The proposed workflow not only highlights the feasibility of applying the CNN-Transformer model for complex subsurface flow systems but also provides a practical solution for real-time decision-making in GCS projects.","2025-02","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","196","","","","","","","","","","English","","","","WOS:001416746900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","BRINE EXTRACTION; CAPACITY ESTIMATION; CAPROCK; CO2 STORAGE EFFICIENCY; Deep learning; Geological carbon sequestration; INVERSION; MULTIPHASE FLOW; Optimization; RESERVOIR; Surrogate model; Transformers; WELL PLACEMENT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T3FCHL6D","journalArticle","2024","Hu, WY; Zhang, CL; Luo, LJ; Jiang, SH","Integrated Method of Future Capacity and RUL Prediction for Lithium-Ion Batteries Based on CEEMD-Transformer-LSTM Model","ENERGY SCIENCE & ENGINEERING","","2050-0505","10.1002/ese3.1952","","Accurately predict the remaining useful life (RUL) of lithium-ion batteries for energy storage is of critical significance to ensure the safety and reliability of electric vehicles, which can offer efficient early warning signals in a timely manner. Considering nonlinear changes in the aging trajectory of lithium-ion batteries, a method for predicting the RUL of lithium-ion batteries was proposed in this study based on a complementary ensemble empirical mode decomposition (CEEMD) as well as transformer and long short-term memory (LSTM) neural network dual-drive machine learning model. First, the CEEMD algorithm was adopted to decompose the raw aging data of lithium-ion batteries into intrinsic mode function (IMF) sequences and residual sequence, where the number of modal layers was produced by the proposed posterior feedback entropy and relevance (PFER) method. Second, prediction models of LSTM and transformer neural networks were established to predict IMF and residual sequences. Simultaneously, the sparrow search algorithm (SSA) was used to obtain the optimal value of the hyperparameter learning rate for the RUL prediction model. Finally, the predicted IMF and residual sequences were combined to comprehensively calculate the future lifespan aging trajectory of lithium-ion batteries. The aging data of two groups of lithium-ion batteries were obtained from the CALCE at the University of Maryland as well as the laboratory at AQNU University to verify the proposed method. Experimental results demonstrated that the proposed method can effectively predict the RUL of lithium-ion batteries; moreover, it exhibited better robustness and generalization ability.","2024-11","2025-02-26 20:43:28","2025-02-26 20:43:28","","5272-5286","","11","12","","","","","","","","","","English","","","","WOS:001354155900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","CHARGE ESTIMATION; complementary ensemble empirical mode decomposition; EXTENDED KALMAN FILTER; lithium-ion battery; long short-term memory model; PARTICLE FILTER; remaining useful life (RUL) prediction; STATE; Transformer model; USEFUL LIFE PREDICTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LBIDBWAJ","journalArticle","2024","Zhao, H; Yuan, RS; Zheng, WC; Zhang, ZY; Wang, CJ; Li, L","PST-Transformer: A Two-Stage Model for 3-D Driving Pose Estimation","IEEE INTERNET OF THINGS JOURNAL","","2327-4662","10.1109/JIOT.2024.3425483","","Driver monitoring systems are becoming more common in modern cars, and they are crucial as autonomous vehicles depend on the driver's continued attention. The increasing application of the deep learning techniques in in-car driver monitoring systems can be attributed to their success in estimating the human body position. In the 3-D human posture estimation, recent transformer-based methods have demonstrated remarkable effectiveness. However, as the number of joints increases, the computing cost to generate the joint-to-joint affinity matrix grows quadratically. To this end, this research develops a pretrained spatial-temporal transformer (PST-Transformer) model to facilitate the issue. In the pretrained phase, a masking module is used to randomly mask the joints. An autoencoder is employed to rebuild the distorted 2-D poses. During the training process, a temporal downsampling approach is advised to cut down on the duplicate data. To forecast the 3-D driving poses, an aggregator is paired with the fine tuned pretrained encoder. Prior to extracting 3-D spatial and temporal characteristics, the encoder in the PST-Transformer could learn the 2-D spatial-temporal relationships. To test the suggested approach, a new driving posture data set named human driving in vehicle (HDIV) is also created, which includes a variety of driving behaviors. Extensive experiments on the HDIV and the widely used Human3.6M data set show that our technique beats the state-of-the-art methods in terms of accuracy and computing complexity.","2024-10-01","2025-02-26 20:43:28","2025-02-26 20:43:28","","32272-32283","","19","11","","","","","","","","","","English","","","","WOS:001322588600036","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","3-D driving pose estimation; Computational modeling; human driving in vehicle (HDIV) data set; masking strategy; Predictive models; pretrained spatial-temporal Transformer (PST-Transformer); Solid modeling; Task analysis; temporal downsampling method; Three-dimensional displays; Transformers; Vehicles","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H3JZ8VCU","journalArticle","2024","Wang, WP; Chen, ZX; Zheng, ZY; Wang, H; Luo, JX","MTA Fuzzer: A low-repetition rate Modbus TCP fuzzing method based on Transformer and Mutation Target Adaptation","COMPUTERS & SECURITY","","0167-4048","10.1016/j.cose.2024.103973","","The widespread application of industrial control systems has driven the development of industrial control protocols. However, traditional industrial control protocols suffer from issues such as a lack of security mechanisms, resulting in the existence of many dangerous vulnerabilities in industrial control systems. Fuzzing, as a commonly used technique for vulnerability discovery, has its own set of issues, including low testing efficiency, lack of adaptive capability, and high repetition rate of generated test cases. To solve the existing problems, we propose a low-repetition rate Modbus TCP fuzzing method based on Transformer and Mutation Target Adaptation. Firstly, the syntactic features of the industrial control protocol Modbus TCP are learned by using a simplified Transformer model. The model effectively reduces the training and generation time without decreasing the acceptance rate of test cases; Secondly, in the test case generation phase, in order to improve the mutation efficiency of test cases, the byte mutation probability adaptive strategy is introduced to replace the greedy strategy of Transformer. This strategy can dynamically adjust the mutation probability of each byte in the newly generated test cases, so as to improve the abnormal rate and reduce the repetition rate of test cases; Finally, the mutation results are selected by the mutation byte adaptive selection strategy, which not only improves the mutation adaptivity, but also maintains the diversity of mutations. The experimental results indicate that, compared to traditional methods, our approach has improved acceptance rates and abnormal rates by at least 10%. In comparison to AI-based fuzzing methods, our approach maintains a similar acceptance rate while increasing the abnormal rate by 3% to 25%.","2024-09","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","144","","","","","","","","","","English","","","","WOS:001267870100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Adaptive; Fuzzing; Low-repetition rate; Modbus TCP; SECURITY; THEORETIC APPROACH; Transformer; Vulnerability mining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S4VGDMT9","journalArticle","2024","Li, ZC; Chen, JY; Gao, TT; Zhang, WJ; Chen, DW; Gu, Y","Cross-scenario capacity estimation for lithium-ion batteries via knowledge query domain mixing-up network","FRONTIERS IN ENERGY RESEARCH","","2296-598X","10.3389/fenrg.2024.1353651","","Introduction: Deep learning has demonstrated exceptional prowess in estimating battery capacity. However, its effectiveness is often compromised by performance degradation under a consequence of varying operational conditions and diverse charging/discharging protocols. Methods: To tackle this issue, we introduce the Knowledge Query Domain Mixing-up Network (KQDMN), a domain adaptation-based solution adept at leveraging both domain-specific and invariant knowledge. This innovation enriches the informational content of domain features by segregating the functions of feature extraction and domain alignment, enhancing the efficacy of KQDMN in utilizing diverse knowledge types. Moreover, to identify time-deteriorating features in battery time series data, we employ convolutional operations. These operations are pivotal in extracting multi-scale features from the battery's characteristic curves. Inspired by the Transformer model, we have developed a set of knowledge queries that integrate these multi-scale features seamlessly, thereby enabling extensive global feature extraction. To ensure the retention of domain-specific information, we have instituted two independent feature extraction pathways. Pursuing domain-invariant knowledge, this study introduces cross-attention as a mechanism to connect two domain spaces, effectively diminishing the disparity between source and target distributions. Results and Discussion: This approach is crucial for accurately estimating capacity in batteries with diverse performance characteristics. The practicality and robustness of the proposed method are validated using the MIT battery aging dataset, yielding highly satisfactory outcomes. The Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and Coefficient of Determination (R 2) for our capacity estimation process are 0.19%, 0.23%, and 0.997, respectively, highlighting the precision and reliability of our approach.","2024-02-07","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","12","","","","","","","","","","English","","","","WOS:001164820900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","capacity estimation; cross attention; domain adaptation; ELECTROCHEMICAL MODEL; lithium-ion battery; OF-HEALTH ESTIMATION; STATE; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D97DBB2Y","journalArticle","2024","Baniata, LH; Kang, S","Switch-Transformer Sentiment Analysis Model for Arabic Dialects That Utilizes a Mixture of Experts Mechanism","MATHEMATICS","","2227-7390","10.3390/math12020242","","In recent years, models such as the transformer have demonstrated impressive capabilities in the realm of natural language processing. However, these models are known for their complexity and the substantial training they require. Furthermore, the self-attention mechanism within the transformer, designed to capture semantic relationships among words in sequences, faces challenges when dealing with short sequences. This limitation hinders its effectiveness in five-polarity Arabic sentiment analysis (SA) tasks. The switch-transformer model has surfaced as a potential substitute. Nevertheless, when employing one-task learning for their training, these models frequently face challenges in presenting exceptional performances and encounter issues when producing resilient latent feature representations, particularly in the context of small-size datasets. This challenge is particularly prominent in the case of the Arabic dialect, which is recognized as a low-resource language. In response to these constraints, this research introduces a novel method for the sentiment analysis of Arabic text. This approach leverages multi-task learning (MTL) in combination with the switch-transformer shared encoder to enhance model adaptability and refine sentence representations. By integrating a mixture of experts (MoE) technique that breaks down the problem into smaller, more manageable sub-problems, the model becomes skilled in managing extended sequences and intricate input-output relationships, thereby benefiting both five-point and three-polarity Arabic sentiment analysis tasks. The proposed model effectively identifies sentiment in Arabic dialect sentences. The empirical results underscore its exceptional performance, with accuracy rates reaching 84.02% for the HARD dataset, 67.89% for the BRAD dataset, and 83.91% for the LABR dataset, as demonstrated by the evaluations conducted on these datasets.","2024-01","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","2","12","","","","","","","","","","English","","","","WOS:001150908900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","Arabic dialects; CONVOLUTIONAL NEURAL-NETWORK; five-polarity; HIERARCHICAL CLASSIFIERS; MACHINE TRANSLATION; mixture of experts (MoE) mechanism; MTL; sentiment analysis (SA); switch transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"82SLT67X","journalArticle","2023","Hu, MM; Zhang, K; You, RB; Tu, BB","AuthConFormer: Sensor-based Continuous Authentication of Smartphone Users Using A Convolutional Transformer","COMPUTERS & SECURITY","","0167-4048","10.1016/j.cose.2023.103122","","To prevent the leakage of personal information on smartphones, a method that can authenticate the smartphone user's identity throughout the session is essential. Sensor-based continuous authentication is a promising potential approach that uses behavioral biometrics to authenticate smartphone user's identity. Recent studies on continuous authentication have achieved encouraging progress. However, they suffer two limitations: 1) weak capability of capturing smartphone user's behavioral patterns from biometric data sequences with time correlation because these methods don't consider the long-range dependencies between the behavioral biometric data sequences; 2) poor performance under a high authentication frequency. To solve these issues, we present AuthConFormer, a novel continuous authentication system based on a proposed convolutional transformer, which is suitable for running on the mobile phone CPUs. The proposed convolutional transformer applies an inverted residual block instead of linear projection in the pure transformer to perform the query, key and value embeddings, respectively. Compared with the pure transformer, the proposed convolutional transformer requires less computation, and can make full use of the contextual information of 2D feature maps. We perform several experiments to evaluate the performance and effectiveness of the AuthConFormer on three public datasets. Experimental results show that the proposed AuthConFormer can achieve the mean values of 1.06% EER, 1.25% EER and 1.19% EER on three public datasets with a high authentication frequency (one authentication every 0.6s), respectively. Besides, the convolutional transformer model pre-trained on the HMOG dataset exhibits good cross-domain generalization capability on the BrainRun dataset.","2023-04","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","127","","","","","","","","","","English","","","","WOS:000936574100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","Behavioral biometrics; BIOMETRICS; Continuous authentication; Convolutional transformer; Cross -domain generalization capability; Feature extraction; NETWORKS; Self -attention mechanism","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6L4Y82Z9","journalArticle","2023","Varam, D; Mitra, R; Mkadmi, M; Riyas, RA; Abuhani, DA; Dhou, S; Alzaatreh, A","Wireless Capsule Endoscopy Image Classification: An Explainable AI Approach","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3319068","","Deep Learning has contributed significantly to the advances made in the fields of Medical Imaging and Computer Aided Diagnosis (CAD). Although a variety of Deep Learning (DL) models exist for the purposes of image classification in the medical domain, more analysis needs to be conducted on their decision-making processes. For this reason, several novel Explainable AI (XAI) techniques have been proposed in recent years to better understand DL models. Currently, medical professionals rely on visual inspections to diagnose potential diseases in endoscopic imaging in the preliminary stages. However, we believe that the use of automated systems can enhance both the efficiency for such diagnoses. The aim of this study is to increase the reliability of model predictions within the field of endoscopic imaging by implementing several transfer learning models on a balanced subset of Kvasir-capsule, a Wireless Capsule Endoscopy imaging dataset. This subset includes the top 9 classes of the dataset for training and testing. The results obtained were an F1-score of 97% +/- 1% for the Vision Transformer model, although other models such as MobileNetv3Large and ResNet152v2 were also able to achieve F1-scores of over 90%. These are currently the highest-reported metrics on this data, improving upon prior studies done on the same dataset. The heatmaps of several XAI techniques, including GradCAM, GradCAM++, LayersCAM, LIME, and SHAP have been presented in image form and evaluated according to their highlighted regions of importance. This is in an effort to better understand the decisions of the top-performing DL models and look beyond their black-box nature.","2023","2025-02-26 20:43:28","2025-02-26 20:43:28","","105262-105280","","","11","","","","","","","","","","English","","","","WOS:001081607200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","Analytical models; Artificial intelligence; Classification algorithms; Deep learning; Endoscopes; explainable AI; Feature extraction; gastrointestinal diseases; Gastrointestinal tract; machine learning; Machine learning; Solid modeling; vision transformer; wireless capsule endoscopy; Wireless communication","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8PUTASUP","journalArticle","2025","Wang, BC; Alzheimers Dis Neuroimaging Initiative","ViT transfer learning for fMRI (VTFF): A highway to achieve superior performance for multi-classification of cognitive decline","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2025.107557","","Early detection of cognitive impairment is a pivotal interdisciplinary research area in contemporary cognitive neuroscience. Researchers employ multimodal data, including brain morphology, function, and connectomics, utilizing techniques such as image recognition, topological analysis, causal inference, and artificial intelligence to achieve precise early prediction of cognitive decline. The advent of the Transformer model has significantly improved the processing of time-series signals. However, integrating fMRI BOLD signal analysis with attention mechanisms to develop an efficient, highly generalizable model remains a challenging task. Inspired by the ViT model from the field of image classification, this study proposes two strategies-TS-wise and ROI-wise-to integrate the four-dimensional fMRI BOLD signals into the patch embedding layer of the ViT model. Using neural imaging data from 1,798 individuals with varying degrees of cognitive impairment from the ADNI2 database, we calculated the cross-attention between time frames and brain regions. This attention was then aggregated into the class token through multiple Transformer layers, forming an intrinsic semantic representation of cognitive impairment across multimodal brain regions. The results demonstrate that the transfer learning ViT model (VTFF) achieves 84.2 % accuracy in multi-class classification of fMRI data, with a relatively balanced confusion matrix, indicating no significant classification bias. Layer-wise visualization of attention revealed significant associations between cognitive impairment and specific cortical regions, such as MT, MST, Pol2, and Area 2. These findings align with previous connectomics studies, but the VTFF model offers a simpler and more intuitive approach. It bypasses the need for thresholding and topological analysis by directly feeding the fMRI BOLD signals into the model's input layer, thus preserving the signal's effective components.","2025-06","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","104","","","","","","","","","","English","","","","WOS:001409995200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","ALZHEIMER-DISEASE; Alzheimer's Disease; Attention; Cognitive Impairment; DYNAMICS; Transfer Learning; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DNSWKPE7","journalArticle","2025","Zhao, CD; Tu, JC; Zhang, XX; Xu, JP; Ostergaard, PA","Predict-then-optimise based day-ahead scheduling towards demand response and hybrid renewable generation for wastewater treatment","APPLIED ENERGY","","0306-2619","10.1016/j.apenergy.2025.125434","","Promoting a 100% renewable energy system requires intelligent scheduling strategies, yet the challenge remains on the prediction and optimisation of variable renewable energy supply and demand. This study proposes a Predict-then-optimise paradigm to explore day-ahead scheduling strategies for high renewable energy systems and demonstrates its application in a grid-connected biogas-solar-wind-storage system with load shifting for wastewater treatment plants. The scheduling strategy aims to maximise energy prosumption and minimise operation costs. Demand response is enabled by the wastewater pre-treatment reservoir, battery storage, and biogas storage, all mathematically modelled in this study. The Temporal Convolutional Network- based Transformer model is applied to forecast uncertain variable renewable energy generation and wastewater flow for the upcoming day. Then budget uncertainty sets are constructed based on forecast errors for robust optimisation. A case from Sichuan, China is analysed to explore the practicality and effectiveness of the proposed framework. The results indicate that the robustness of the model increases the day-head scheduling operational cost and decreases the self-sufficiency ratio. Wastewater pre-treatment reservoir scheduling can effectively shift the demand load, promoting cost reduction and system prosumption; besides, pre-treatment reservoir, battery storage and biogas storage have substitution and combination effects on demand response, can reduce daily operating costs by 20%-50%. The influence of a defined allowable sale ratio, seasons, and weather conditions are also discussed. Overall, the proposed predict-then-optimise framework is an effective solution for the upcoming day's decision-making.","2025-04-15","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","384","","","","","","","","","","English","","","","WOS:001422951000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","BIOGAS; Day-ahead scheduling; Deep learning; ELECTRICITY; ENERGY RECOVERY; FEASIBILITY; Hybrid renewable generation; HYDROGEN-PRODUCTION; Load-shifting; MODEL; Predict-then-optimise; TREATMENT-PLANT; Wastewater treatment; WWTPS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z5G7TIW2","journalArticle","2024","Kasaragod, AK; Thomas, J; Oommen, T; Williams, R; Paheding, S; Angulo, AR; Ewing, J; Cole, M; Jayakumar, P","Predicting USCS soil texture classes utilizing soil spectra and deep learning","JOURNAL OF SOILS AND SEDIMENTS","","1439-0108","10.1007/s11368-024-03921-8","","PurposeSoil texture identification is vital for various agricultural and engineering applications but generally involves rigorous laboratory work, especially for estimating USCS (Unified Soil Classification System) soil texture classes. Soil texture influences soil water storage capacity, soil fertility, compaction characteristics, and soil strength. Soil spectroscopy offers a reliable approach that is non-destructive, rapid, and cost-effective to estimate several soil properties including texture. For engineering applications, the USCS soil texture classes are preferred, but very few studies have focussed on estimating USCS soil texture using soil spectroscopy or remote sensing data in general.MethodsTwo large soil spectral libraries (SSLs), viz., Kellog Soil Spectral Library (KSSL) and Open-source Soil Spectral Library (OSSL), as well as three deep learning algorithms (VGG-16, ResNet-16, and Swin transformers), were used in this study to predict six USCS soil texture classes and three USCS soil texture groups. The USCS soil texture classes and groups were derived by grouping clay, sand, and silt fractions that are closely associated with the corresponding USCS soil texture classes.ResultsThe results indicate that the Swin transformer model performed the best with an accuracy of 67% for six USCS soil texture class predictions and 81% for three USCS soil texture group predictions. Cohen's kappa value implies a moderate agreement (0.55) for soil texture class predictions and a substantial agreement (0.64) for soil texture group predictions.ConclusionThe proposed methodology offers a novel approach for USCS soil texture class predictions utilizing SSLs and deep learning techniques.","2024-11","2025-02-26 20:43:28","2025-02-26 20:43:28","","3594-3609","","11","24","","","","","","","","","","English","","","","WOS:001337231100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","CLASSIFICATION; CLAY; Convolutional Neural Network; Deep learning; LIBRARY; MOISTURE; ORGANIC-CARBON; Soil spectral library; Soil spectroscopy; Swin transformer; USCS soil texture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U463K74I","journalArticle","2024","Abdallah, M; Younis, S; Wu, SB; Ding, XL","Automated deformation detection and interpretation using InSAR data and a multi-task ViT model","INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION","","1569-8432","10.1016/j.jag.2024.103758","","Many geological hazards are associated with ground deformations. Prompt and accurate detection and interpretation of ground deformation is therefore vital to geohazard mitigation. Multitemporal Interferometric Synthetic Aperture Radar (MT-InSAR) is an effective geodetic technique for monitoring ground deformation. However, accurate computation and interpretation of deformation using InSAR are often hindered by various errors and a lack of expert knowledge. We present a new advanced deep learning model based on a multi -task vision transformer (MT-ViT) to automatically detect, locate, and interpret deformation using single interferograms. To address the issue of limited training data in InSAR applications, the proposed model utilizes pretrained weights from optical images and transfers them to a simulated InSAR dataset. Then real interferograms are used to fine -tune the weights in the network. An overall loss function is designed, which considers the classification and localization losses in the model. The effectiveness of the proposed model is demonstrated using both simulated and real InSAR datasets that contain either coseismic or volcanic deformation. The experimental results from the model are also compared with the state -of -the -art convolutional neural network (CNN) based techniques. The results show significant improvement in both the accuracy of the results and the computational efficiency over the CNN-based approaches. The MT-ViT model achieved 99.4 % classification accuracy, 54.1 % mean intersection over union (IOU), and 0.9 km localization accuracy. A comprehensive evaluation of the hyperparameters in training the MT-ViT model was carried out, which will inform future research in this direction. The research results highlight the promising capabilities of MT-ViT in near real -time deformation monitoring and automated deformation interpretation.","2024-04","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","128","","","","","","","","","","English","","","","WOS:001219167200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Deformation detection and interpretation; InSAR; Machine learning; Vision transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ISIFIRP8","journalArticle","2023","Chen, LE; Wang, H; Kong, H; Yang, WK; Ren, MW","PTC-Net: Point-Wise Transformer With Sparse Convolution Network for Place Recognition","IEEE ROBOTICS AND AUTOMATION LETTERS","","2377-3766","10.1109/LRA.2023.3267693","","In the point-cloud-based place recognition area, the existing hybrid architectures combining both convolutional networks and transformers have shown promising performance. They mainly apply the voxel-wise transformer after the sparse convolution (SPConv). However, they can induce information loss by the sparse voxelization and further result in loss propagation to the transformer, significantly degrading the performance of the network, especially in outdoor scenes with complex geometric structures and multiple small objects. To address this issue, we propose a novel Point-wise Transformer with sparse Convolution (PTC). Specifically, SPConv is applied to the sparsely voxelized point cloud to extract local features, which are then converted to the point-based representation via a feature transformation unit (FTU). As such, our PTC can apply a transformer model based on the point-wise representation rather than on the voxel-wise one. To enhance the ability to capture long-range features and reduce the computational complexity of the transformer, we propose a two-step transformer, each with different grouping strategies. Meanwhile, in both steps, the attention matrix is computed with much fewer points by grouping a single point cloud into different attention domains. The experiments show that the PTC-Net can achieve state-of-the-art (SOTA) performance, with an improvement of 3.6% on average recall@1. Furthermore, to demonstrate the effectiveness of the PTC, we introduce an extremely light-weight version, PTC-Net-L, with only one PTC layer and half initial channel dimensions, also achieving SOTA performance in terms of the average recall rate and running time with only 0.08 M parameters.","2023-06","2025-02-26 20:43:28","2025-02-26 20:43:28","","3414-3421","","6","8","","","","","","","","","","English","","","","WOS:000979962100020","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Aggregates; Convolution; Feature extraction; global descriptor; Place recognition; Point cloud compression; sparse convolution; Spatial resolution; Three-dimensional displays; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9E9JLLF6","journalArticle","2022","Zhao, L; Liu, XY; Ren, HE; Xue, LJX","Thermal Infrared Tracking Method Based on Efficient Global Information Perception","SENSORS","","1424-8220","10.3390/s22197408","","To solve the insufficient ability of the current Thermal InfraRed (TIR) tracking methods to resist occlusion and interference from similar targets, we propose a TIR tracking method based on efficient global information perception. In order to efficiently obtain the global semantic information of images, we use the Transformer structure for feature extraction and fusion. In the feature extraction process, the Focal Transformer structure is used to improve the efficiency of remote information modeling, which is highly similar to the human attention mechanism. The feature fusion process supplements the relative position encoding to the standard Transformer structure, which allows the model to continuously consider the influence of positional relationships during the learning process. It can also generalize to capture the different positional information for different input sequences. Thus, it makes the Transformer structure model the semantic information contained in images more efficiently. To further improve the tracking accuracy and robustness, the heterogeneous bi-prediction head is utilized in the object prediction process. The fully connected sub-network is responsible for the classification prediction of the foreground or background. The convolutional sub-network is responsible for the regression prediction of the object bounding box. In order to alleviate the contradiction between the vast demand for training data of the Transformer model and the insufficient scale of the TIR tracking dataset, the LaSOT-TIR dataset is generated with the generative adversarial network for network training. Our method achieves the best performance compared with other state-of-the-art trackers on the VOT2015-TIR, VOT2017-TIR, PTB-TIR and LSOTB-TIR datasets, and performs outstandingly especially when dealing with severe occlusion or interference from similar objects.","2022-10","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","19","22","","","","","","","","","","English","","","","WOS:000868103500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","NETWORKS; object tracking; Thermal InfraRed; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H7R2V8BK","journalArticle","2022","Li, J; Zhu, JM; Li, C; Chen, X; Yang, B","CGTF: Convolution-Guided Transformer for Infrared and Visible Image Fusion","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2022.3175055","","Deep learning has been successfully applied to infrared and visible image fusion due to its powerful ability of feature representation. Existing most deep learning-based infrared and visible image fusion methods mainly utilize pure convolution model or pure transformer model, which leads to that the fused image cannot preserve long-range dependences (global context) and local features simultaneously. To this end, we propose a convolution-guided transformer framework for infrared and visible image fusion (CGTF), which aims to combine the local features of convolutional network and the long-range dependence features of transformer to produce satisfactory fused image. In CGTF, the local features are calculated by convolution feature extraction module (CFEM), and then, the local features are used to guide the transformer feature extraction module (TFEM) to capture the long-range dependences of the image, which can overcome not only the lack of long-range dependences that exist in convolutional fusion methods but also the deficiency of local feature that exists in transformer models. Moreover, the convolution-guided transformer fusion framework can consider the inherent relationship of local feature and long-range dependences due to the alternate use of CFEM and transformer module. In addition, to strengthen local feature propagation, we employ dense connections among CFEMs. Ablation experiments demonstrate the effectiveness of convolution-guided transformer fusion framework and loss function. We employ two datasets to compare our method with other nine methods, which include three traditional methods, five deep learning-based methods, and one transformer-based method. Qualitative and quantitative experiments demonstrate the advantages of our method.","2022","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","71","","","","","","","","","","English","","","","WOS:000800198900013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;92<br/>Total Times Cited:&nbsp;&nbsp;94<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Convolution; Convolutional neural networks; Deep learning; Feature extraction; Fuses; Image fusion; infrared image; NETWORK; transformer; Transformers; visible image","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LKBI2D4A","journalArticle","2024","Liu, JT; Bian, YC; Lawson, K; Shen, CP","Probing the limit of hydrologic predictability with the Transformer network","JOURNAL OF HYDROLOGY","","0022-1694","10.1016/j.jhydrol.2024.131389","","For a number of years since their introduction to hydrology, recurrent neural networks like long short-term memory (LSTM) networks have proven remarkably difficult to surpass in terms of daily hydrograph metrics on community -shared benchmarks. Outside of hydrology, Transformers have now become the model of choice for sequential prediction tasks, making it a curious architecture to investigate for application to hydrology. Here, we first show that a vanilla (basic) Transformer architecture is not competitive against LSTM on the widely benchmarked CAMELS streamflow dataset, and lagged especially prominently for the high -flow metrics, perhaps due to the lack of memory mechanisms. However, a recurrence -free variant of the Transformer model obtained mixed comparisons with LSTM, producing very slightly higher Kling -Gupta efficiency coefficients (KGE), along with other metrics. The lack of advantages for the vanilla Transformer network is linked to the nature of hydrologic processes. Additionally, similar to LSTM, the Transformer can also merge multiple meteorological forcing datasets to improve model performance. Therefore, the modified Transformer represents a rare competitive architecture to LSTM in rigorous benchmarks. Valuable lessons were learned: (1) the basic Transformer architecture is not suitable for hydrologic modeling; (2) the recurrence -free modification is beneficial, so future work should continue to test such modifications; and (3) the performance of state-of-the-art models may be close to the prediction limits of the dataset. As a non -recurrent model, the Transformer may bear scale advantages for learning from bigger datasets and storing knowledge. This work lays the groundwork for future explorations into pretraining models, serving as a foundational benchmark that underscores the potential benefits in hydrology.","2024-06","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","637","","","","","","","","","","English","","","","WOS:001248573900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","CAMELS; DATASET; Deep learning; Long short-term memory; MODEL; REGIONS; Streamflow; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2AFJUL4T","journalArticle","2023","Hernandez-Torres, SI; Hennessey, RP; Snider, EJ","Performance Comparison of Object Detection Networks for Shrapnel Identification in Ultrasound Images","BIOENGINEERING-BASEL","","2306-5354","10.3390/bioengineering10070807","","Ultrasound imaging is a critical tool for triaging and diagnosing subjects but only if images can be properly interpreted. Unfortunately, in remote or military medicine situations, the expertise to interpret images can be lacking. Machine-learning image interpretation models that are explainable to the end user and deployable in real time with ultrasound equipment have the potential to solve this problem. We have previously shown how a YOLOv3 (You Only Look Once) object detection algorithm can be used for tracking shrapnel, artery, vein, and nerve fiber bundle features in a tissue phantom. However, real-time implementation of an object detection model requires optimizing model inference time. Here, we compare the performance of five different object detection deep-learning models with varying architectures and trainable parameters to determine which model is most suitable for this shrapnel-tracking ultrasound image application. We used a dataset of more than 16,000 ultrasound images from gelatin tissue phantoms containing artery, vein, nerve fiber, and shrapnel features for training and evaluating each model. Every object detection model surpassed 0.85 mean average precision except for the detection transformer model. Overall, the YOLOv7tiny model had the higher mean average precision and quickest inference time, making it the obvious model choice for this ultrasound imaging application. Other object detection models were overfitting the data as was determined by lower testing performance compared with higher training performance. In summary, the YOLOv7tiny object detection model had the best mean average precision and inference time and was selected as optimal for this application. Next steps will implement this object detection algorithm for real-time applications, an important next step in translating AI models for emergency and military medicine.","2023-07","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","7","10","","","","","","","","","","English","","","","WOS:001037931000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","artificial intelligence; deep learning; image interpretation; machine learning; neurovascular; object detection; shrapnel; ultrasound imaging","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XL8E2Q7C","journalArticle","2025","Zhu, J; Li, YL; Yang, CL; Cai, HS; Li, XW; Hu, B","Transformer-based fusion model for mild depression recognition with EEG and pupil area signals","MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING","","0140-0118","10.1007/s11517-024-03269-8","","Early detection and treatment are crucial for the prevention and treatment of depression; compared with major depression, current researches pay less attention to mild depression. Meanwhile, analysis of multimodal biosignals such as EEG, eye movement data, and magnetic resonance imaging provides reliable technical means for the quantitative analysis of depression. However, how to effectively capture relevant and complementary information between multimodal data so as to achieve efficient and accurate depression recognition remains a challenge. This paper proposes a novel Transformer-based fusion model using EEG and pupil area signals for mild depression recognition. We first introduce CSP into the Transformer to construct single-modal models of EEG and pupil data and then utilize attention bottleneck to construct a mid-fusion model to facilitate information exchange between the two modalities; this strategy enables the model to learn the most relevant and complementary information for each modality and only share the necessary information, which improves the model accuracy while reducing the computational cost. Experimental results show that the accuracy of the EEG and pupil area signals of single-modal models we constructed is 89.75% and 84.17%, the precision is 92.04% and 95.21%, the recall is 89.5% and 71%, the specificity is 90% and 97.33%, the F1 score is 89.41% and 78.44%, respectively, and the accuracy of mid-fusion model can reach 93.25%. Our study demonstrates that the Transformer model can learn the long-term time-dependent relationship between EEG and pupil area signals, providing an idea for designing a reliable multimodal fusion model for mild depression recognition based on EEG and pupil area signals.","2025-02-06","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","","","","","","","","","","","","English","","","","WOS:001415152500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Attention; EEG; Mild depression; Pupil area signal; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UEMUB5IB","journalArticle","2024","Jiang, HL; Wu, RG; Zhang, YG; Li, MA; Lian, H; Fan, YK; Yang, WQ; Zhou, P","Classification Model of Grassland Desertification Based on Deep Learning","SUSTAINABILITY","","2071-1050","10.3390/su16198307","","Grasslands are one of the most important ecosystems on earth, and the impact of grassland desertification on the earth's environment and ecosystem cannot be ignored. Accurately distinguishing grassland desertification types has important application value. The appropriate grazing strategies can be implemented based on these distinctions. Grassland conservation measures can be tailored accordingly. This contributes to further protecting and restoring grassland vegetation. This project takes color images labeled with the desertification types of grasslands as the research object, uses the currently popular deep learning model as the classification tool, and then establishes a color image-based grassland desertification classification model based on the feature extraction network, based on the Vision Transformer model, by comparing the various deep learning image classification models. The experimental results show that, despite the complex structure and large number of parameters of the grassland desertification classification model obtained in this project, the test accuracy rate reaches 88.72% and the training loss is only 0.0319. Compared with the popular classification models such as VGG16, ResNet50, ResNet101, DenseNet101, DenseNet169, and DenseNet201, and so on, the Vision Transformer demonstrates clear advantages in classification accuracy, fitting ability, and generalization capacity. By integrating with deep learning technology, the model can be applied to grassland management and ecological restoration. Mobile devices can be used to conveniently capture image data, and information can be processed quickly. This provides efficient tools for grazing managers, environmental scientists, and conservation organizations. These tools assist in quickly assessing the extent of grassland desertification, optimizing grassland management and conservation decisions. Furthermore, strong technical support is offered for the ecological restoration and sustainable management of desertification grasslands.","2024-10","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","19","16","","","","","","","","","","English","","","","WOS:001332908100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","CHINA; color image; deep learning; feature extraction; grassland desertification; image classification; LANDSAT IMAGES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6ZWGVGVZ","journalArticle","2024","Maurya, R; Pandey, NN; Karnati, M; Sahu, G","Breaking Barriers in Cancer Diagnosis: Super-Light Compact Convolution Transformer for Colon and Lung Cancer Detection","INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY","","0899-9457","10.1002/ima.23154","","According to the World Health Organization, lung and colon cancers are known for their high mortality rates which necessitate the diagnosis of these cancers at an early stage. However, the limited availability of data such as histopathology images used for diagnosis of these cancers, poses a significant challenge while developing computer-aided detection system. This makes it necessary to keep a check on the number of parameters in the artificial intelligence (AI) model used for the detection of these cancers considering the limited availability of the data. In this work, a customised compact and efficient convolution transformer architecture, termed, C3-Transformer has been proposed for the diagnosis of colon and lung cancers using histopathological images. The proposed C3-Transformer relies on convolutional tokenisation and sequence pooling approach to keep a check on the number of parameters and to combine the advantage of convolution neural network with the advantages of transformer model. The novelty of the proposed method lies in efficient classification of colon and lung cancers using the proposed C3-Transformer architecture. The performance of the proposed method has been evaluated on the 'LC25000' dataset. Experimental results shows that the proposed method has been able to achieve average classification accuracy, precision and recall value of 99.30%, 0.9941 and 0.9950, in classifying the five different classes of colon and lung cancer with only 0.0316 million parameters. Thus, the present computer-aided detection system developed using proposed C3-Transformer can efficiently detect the colon and lung cancers using histopathology images with high detection accuracy.","2024-09","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","5","34","","","","","","","","","","English","","","","WOS:001288421700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","colon cancer; convolution neural network; deep learning; lung cancer; transformer; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RZ62U9DW","journalArticle","2024","Wu, HF; Chen, WF; Liu, ZB; Chen, TS; Chen, ZG; Lin, L","Contrastive Transformer Learning With Proximity Data Generation for Text-Based Person Search","IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY","","1051-8215","10.1109/TCSVT.2023.3329220","","Given a descriptive text query, text-based person search (TBPS) aims to retrieve the best-matched target person from an image gallery. Such a cross-modal retrieval task is quite challenging due to significant modality gap, fine-grained differences and insufficiency of annotated data. To better align the two modalities, most existing works focus on introducing sophisticated network structures and auxiliary tasks, which are complex and hard to implement. In this paper, we propose a simple yet effective dual Transformer model for text-based person search. By exploiting a hardness-aware contrastive learning strategy, our model achieves state-of-the-art performance without any special design for local feature alignment or side information. Moreover, we propose a proximity data generation (PDG) module to automatically produce more diverse data for cross-modal training. The PDG module first introduces an automatic generation algorithm based on a text-to-image diffusion model, which generates new text-image pair samples in the proximity space of original ones. Then it combines approximate text generation and feature-level mixup during training to further strengthen the data diversity. The PDG module can largely guarantee the reasonability of the generated samples that are directly used for training without any human inspection for noise rejection. It improves the performance of our model significantly, providing a feasible solution to the data insufficiency problem faced by such fine-grained visual-linguistic tasks. Extensive experiments on two popular datasets of the TBPS task (i.e., CUHK-PEDES and ICFG-PEDES) show that the proposed approach outperforms state-of-the-art approaches evidently, e.g., improving by 3.88%, 4.02%, 2.92% in terms of Top1, Top5, Top10 on CUHK-PEDES.","2024-08","2025-02-26 20:43:28","2025-02-26 20:43:28","","7005-7016","","8","34","","","","","","","","","","English","","","","WOS:001327614800033","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","contrastive learning; proximity data generation; Text-based person search; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NHLFAFLW","journalArticle","2024","Do, NQ; Selamat, A; Fujita, H; Krejcar, O","An integrated model based on deep learning classifiers and pre-trained transformer for phishing URL detection","FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE","","0167-739X","10.1016/j.future.2024.06.031","","The unique nature of website URLs has made phishing detection a challenging task. Unlike natural language, URLs have an unstructured nature with non-linear and sophisticated correlations. Therefore, they should be handled as both natural language and unstructured data sequences. However, the current solutions for phishing URL detection only focused on a single aspect of web page URLs. In this concern, this paper proposes an integrated model based on DL classifiers and pre-trained transformer to examine both the unique nature and the natural language structure of URL sequences simultaneously. The proposed model consists of three modules: RasNet (Keras-ResNet), ras-Res Net ), TCMA (TCN-MHSA), TC N- M HS A ), and MPNet (Masked and Permuted Pre-training for Language Understanding). Considering the unique nature of the input data, RasNet combines two Keras embedding techniques to obtain the feature representations of URLs and then fuses them using a Residual Network (ResNet) to balance the weight distribution among the character-level and word-level information. Additionally, TCMA integrates the Temporal Convolutional Network (TCN) with the Multi-Head Self-Attention (MHSA) mechanism to optimize feature extraction and improve classification accuracy. Concurrently, MPNet joins the advantages and eliminates the drawbacks of Masked Language Modelling and Permuted Language Modelling to examine the nature language structure of web page URLs. The proposed model was trained and tested on four different datasets, including Ebbu2017, PhishCrawl, 420K-PD, and 1M-PD. The experimental results indicated that the proposed solution outperformed other models in classifying malicious URLs with the highest detection rate of 99.71% on the 1M-PD dataset, improving the performance accuracy of the state-of-the-art approaches by 1.37% to 2.01%.","2024-12","2025-02-26 20:43:28","2025-02-26 20:43:28","","269-285","","","161","","","","","","","","","","English","","","","WOS:001280731500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Attention mechanism; CONVOLUTIONAL NEURAL-NETWORK; FEATURES; Phishing detection; Residual network; Temporal convolutional network; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9NL6NR9L","journalArticle","2024","Ding, X; Peng, R; Chen, XP; Huang, Y; Bian, J; Zheng, ZB","Do Code Summarization Models Process Too Much Information? Function Signature May Be All That Is Needed","ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY","","1049-331X","10.1145/3652156","","With the fast development of large software projects, automatic code summarization techniques, which summarize the main functionalities of a piece of code using natural languages as comments, play essential roles in helping developers understand and maintain large software projects. Many research efforts have been devoted to building automatic code summarization approaches. Typical code summarization approaches are based on deep learning models. They transform the task into a sequence-to-sequence task, which inputs source code and outputs summarizations in natural languages. All code summarization models impose different input size limits, such as 50 to 10,000, for the input source code. However, how the input size limit affects the performance of code summarization models still remains under-explored. In this article, we first conduct an empirical study to investigate the impacts of different input size limits on the quality of generated code comments. To our surprise, experiments on multiple models and datasets reveal that setting a low input size limit, such as 20, does not necessarily reduce the quality of generated comments. Based on this finding, we further propose to use function signatures instead of full source code to summarize the main functionalities first and then input the function signatures into code summarization models. Experiments and statistical results show that inputs with signatures are, on average, more than 2 percentage points better than inputs without signatures and thus demonstrate the effectiveness of involving function signatures in code summarization. We also invite programmers to do a questionnaire to evaluate the quality of code summaries generated by two inputs with different truncation levels. The results show that function signatures generate, on average, 9.2% more high-quality comments than full code.","2024-07","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","6","33","","","","","","","","","","English","","","","WOS:001283366800021","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;80</p>","","","Code summarization; empirical study; function signature; TRANSFORMER MODEL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CSC9PDTT","journalArticle","2024","Chen, MM; Xiang, Y; Xiong, CX","Synthesis and Restoration of Traditional Ethnic Musical Instrument Timbres Based on Time-Frequency Analysis","TRAITEMENT DU SIGNAL","","0765-0019","10.18280/ts.410247","","With the advent of the digital age, the preservation and restoration of the timbres of traditional ethnic musical instruments have emerged as significant areas of study in musicology and signal processing. Music serves not only as a bridge between history and culture but also plays an irreplaceable role in expressing ethnic characteristics and emotions. The timbres of traditional ethnic musical instruments, owing to their unique musical expressiveness and cultural value, have attracted widespread attention from both the academic and industrial sectors. However, many valuable timbre recordings are facing threats of damage and disappearance due to limitations in old recording technologies and preservation conditions. Moreover, existing timbre processing technologies still require improvements in separation accuracy, synthesis authenticity, and restoration naturalness. This study aims to achieve efficient separation, authentic synthesis, and natural restoration of the sounds of traditional ethnic musical instruments through advanced signal processing methods. Initially, this paper discusses a sound separation technique for traditional ethnic musical instruments based on time-frequency analysis, addressing the issue of insufficient resolution in complex audio signals. Subsequently, it proposes a timbre synthesis method based on the Transformer deep learning model, which can understand and reproduce the delicate timbral characteristics of musical instruments. Finally, addressing the continuity issue in timbre restoration, this paper introduces an innovative restoration technique to enhance the quality of damaged audio restoration and auditory consistency. Through the application of these methods, this study not only contributes to the protection and restoration of traditional timbres but also advances related audio processing technologies.","2024-04","2025-02-26 20:43:28","2025-02-26 20:43:28","","1063-1072","","2","41","","","","","","","","","","English","","","","WOS:001262216900046","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;17</p>","","","signal processing; timbre restoration; timbre separation; timbre synthesis; time-frequency analysis; traditional ethnic musical instruments; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MPZWZXP8","journalArticle","2024","Halvoník, D; Kapusta, J","Large Language Models and Rule-Based Approaches in Domain-Specific Communication","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3436902","","Currently, we are once again experiencing a frenzy related to artificial intelligence. Generative Pre-trained Transformers (GPT) models are highly effective at various natural language processing tasks. Different varieties of GPT models are widely used these days to improve productivity. Graphic departments generate art designs, developers engineer intricate software solutions, leveraging services predicated on the GPT framework, and many other industries are also following the lead and implementing these new sets of tools in their workflow. However, there are areas in natural language processing where a simple solution is often more suitable and effective than current Large Language Models. In this article, we decided to analyze and compare the practical use of one of the more popular GPT solutions, J-Large, and the simple rule-based model we implemented. We integrated these two models into the internal information system of a private company focused on communication with customers in the gaming industry. Both models were trained on the same dataset provided as a log of conversational interactions for the last two years in the given system. We observed that GPT models exhibited superior performance in terms of comprehensibility and adequacy. The rule-based models showed noticeable proficiency in handling domain-specific tasks, mainly when fed with datasets extracted from the historical communication between users and a specialized domain system, such as a customer care department. As a result, with a sufficiently tailored and specific dataset at their disposal, rule-based models can effectively outpace GPT models in performing domain-specific tasks.","2024","2025-02-26 20:43:28","2025-02-26 20:43:28","","107046-107058","","","12","","","","","","","","","","English","","","","WOS:001288232000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Artificial intelligence; Biological system modeling; Chatbot; Chatbots; Companies; Data models; generative pre-trained transformers; large language models; Large language models; rule-based model; Task analysis; Training; transformer model; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JAD2B7M8","journalArticle","2024","Li, Y; Wang, QY; Jia, KD","Enhancing Image Description Generation through Deep Reinforcement Learning: Fusing Multiple Visual Features and Reward Mechanisms","CMC-COMPUTERS MATERIALS & CONTINUA","","1546-2218","10.32604/cmc.2024.047822","","Image description task is the intersection of computer vision and natural language processing, and it has important prospects, including helping computers understand images and obtaining information for the visually impaired. This study presents an innovative approach employing deep reinforcement learning to enhance the accuracy of natural language descriptions of images. Our method focuses on refining the reward function in deep reinforcement learning, facilitating the generation of precise descriptions by aligning visual and textual features more closely. Our approach comprises three key architectures. Firstly, it utilizes Residual Network 101 (ResNet-101) and Faster Region -based Convolutional Neural Network (Faster R-CNN) to extract average and local image features, respectively, followed by the implementation of a dual attention mechanism for intricate feature fusion. Secondly, the Transformer model is engaged to derive contextual semantic features from textual data. Finally, the generation of descriptive text is executed through a two-layer long short -term memory network (LSTM), directed by the value and reward functions. Compared with the image description method that relies on deep learning, the score of Bilingual Evaluation Understudy (BLEU-1) is 0.762, which is 1.6% higher, and the score of BLEU-4 is 0.299. Consensus-based Image Description Evaluation (CIDEr) scored 0.998, Recall-Oriented Understudy for Gisting Evaluation (ROUGE) scored 0.552, the latter improved by 0.36%. These results not only attest to the viability of our approach but also highlight its superiority in the realm of image description. Future research can explore the integration of our method with other artificial intelligence (AI) domains, such as emotional AI, to create more nuanced and context-aware systems.","2024","2025-02-26 20:43:28","2025-02-26 20:43:28","","2469-2489","","2","78","","","","","","","","","","English","","","","WOS:001201683900006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","attention mechanism; deep reinforcement learning; Image description","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N8E8CX5K","journalArticle","2024","Yu, SH; Zhang, X; Song, HH","Sparse Mix-Attention Transformer for Multispectral Image and Hyperspectral Image Fusion","REMOTE SENSING","","2072-4292","10.3390/rs16010144","","Multispectral image (MSI) and hyperspectral image (HSI) fusion (MHIF) aims to address the challenge of acquiring high-resolution (HR) HSI images. This field combines a low-resolution (LR) HSI with an HR-MSI to reconstruct HR-HSIs. Existing methods directly utilize transformers to perform feature extraction and fusion. Despite the demonstrated success, there exist two limitations: (1) Employing the entire transformer model for feature extraction and fusion fails to fully harness the potential of the transformer in integrating the spectral information of the HSI and spatial information of the MSI. (2) HSIs have a strong spectral correlation and exhibit sparsity in the spatial domain. Existing transformer-based models do not optimize this physical property, which makes their methods prone to spectral distortion. To accomplish these issues, this paper introduces a novel framework for MHIF called a Sparse Mix-Attention Transformer (SMAformer). Specifically, to fully harness the advantages of the transformer architecture, we propose a Spectral Mix-Attention Block (SMAB), which concatenates the keys and values extracted from LR-HSIs and HR-MSIs to create a new multihead attention module. This design facilitates the extraction of detailed long-range information across spatial and spectral dimensions. Additionally, to address the spatial sparsity inherent in HSIs, we incorporated a sparse mechanism within the core of the SMAB called the Sparse Spectral Mix-Attention Block (SSMAB). In the SSMAB, we compute attention maps from queries and keys and select the K highly correlated values as the sparse-attention map. This approach enables us to achieve a sparse representation of spatial information while eliminating spatially disruptive noise. Extensive experiments conducted on three synthetic benchmark datasets, namely CAVE, Harvard, and Pavia Center, demonstrate that the SMAformer method outperforms state-of-the-art methods.","2024-01","2025-02-26 20:43:28","2025-02-26 20:43:28","","","","1","16","","","","","","","","","","English","","","","WOS:001140624800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","DECOMPOSITION; hyperspectral imaging super resolution; image fusion; MULTIRESOLUTION; remote sensing; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KSX4P4U9","journalArticle","2025","Lu, F; Zhou, D; Chen, HY; Liu, S; Ling, XL; Zhu, L; Gong, TT; Sheng, B; Liao, XF; Jin, H; Li, P; Feng, DD","S2P-Matching: Self-Supervised Patch-Based Matching Using Transformer for Capsule Endoscopic Images Stitching","IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING","","0018-9294","10.1109/TBME.2024.3462502","","The Magnetically Controlled Capsule Endoscopy (MCCE) has a limited shooting range, resulting in capturing numerous fragmented images and an inability to precisely locate and examine the region of interest (ROI) as traditional endoscopy can. Addressing this issue, image stitching around the ROI can be employed to aid in the diagnosis of gastrointestinal (GI) tract conditions. However, MCCE images possess unique characteristics, such as weak texture, close-up shooting, and large angle rotation, presenting challenges to current image-matching methods. In this context, a method named S2P-Matching is proposed for self-supervised patch-based matching in MCCE image stitching. The method involves augmenting the raw data by simulating the capsule endoscopic camera's behavior around the GI tract's ROI. Subsequently, an improved contrast learning encoder is utilized to extract local features, represented as deep feature descriptors. This encoder comprises two branches that extract distinct scale features, which are combined over the channel without manual labeling. The data-driven descriptors are then input into a Transformer model to obtain patch-level matches by learning the globally consented matching priors in the pseudo-ground-truth match pairs. Finally, the patch-level matching is refined and filtered to the pixel-level. The experimental results on real-world MCCE images demonstrate that S2P-Matching provides enhanced accuracy in addressing challenging issues in the GI tract environment with image parallax. The performance improvement can reach up to 203 and 55.8% in terms of NCM (Number of Correct Matches) and SR (Success Rate), respectively. This approach is expected to facilitate the wide adoption of MCCE-based gastrointestinal screening.","2025-02","2025-02-26 20:43:29","2025-02-26 20:43:29","","540-551","","2","72","","","","","","","","","","English","","","","WOS:001405890200024","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","ASIFT; Capsule endoscopy; FEATURES; image stitching; multi-view simulation; patch-level matching; self- supervised contrastive learning; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GFEKDXXD","journalArticle","2024","Zhang, J; Lu, JD; Chen, B; Pan, SF; Jin, LW; Zheng, Y; Pan, M","Vision transformer introduces a new vitality to the classification of renal pathology","BMC NEPHROLOGY","","1471-2369","10.1186/s12882-024-03800-x","","Recent advancements in computer vision within the field of artificial intelligence (AI) have made significant inroads into the medical domain. However, the application of AI for classifying renal pathology remains challenging due to the subtle variations in multiple renal pathological classifications. Vision Transformers (ViT), an adaptation of the Transformer model for image recognition, have demonstrated superior capabilities in capturing global features and providing greater explainability. In our study, we developed a ViT model using a diverse set of stained renal histopathology images to evaluate its effectiveness in classifying renal pathology. A total of 1861 whole slide images (WSI) stained with HE, MASSON, PAS, and PASM were collected from 635 patients. Renal tissue images were then extracted, tiled, and categorized into 14 classes on the basis of renal pathology. We employed the classic ViT model from the Timm library, utilizing images sized 384 x 384 pixels with 16 x 16 pixel patches, to train the classification model. A comparative analysis was conducted to evaluate the performance of the ViT model against traditional convolutional neural network (CNN) models. The results indicated that the ViT model demonstrated superior recognition ability (accuracy: 0.96-0.99). Furthermore, we visualized the identification process of the ViT models to investigate potentially significant pathological ultrastructures. Our study demonstrated that ViT models outperformed CNN models in accurately classifying renal pathology. Additionally, ViT models are able to focus on specific, significant structures within renal histopathology, which could be crucial for identifying novel and meaningful pathological features in the diagnosis and treatment of renal disease.","2024-10-09","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","1","25","","","","","","","","","","English","","","","WOS:001338198100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Artificial Intelligence; Convolutional neural networks; LIVER SEGMENTATION; Renal pathology; Vision transformers; Whole-slide imaging","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ITD6CWIJ","journalArticle","2025","Wen, YJ; Xu, P; Li, ZH; Xu, WT","An illumination-guided dual attention vision transformer for low-light image enhancement","PATTERN RECOGNITION","","0031-3203","10.1016/j.patcog.2024.111033","","Existing Retinex-based low-light image enhancement methods often overlook corruptions hidden in darkness or pattern collapse caused by the lit-up process. Recent deep learning approaches suggest the use of U-shaped networks with Vision in Transformer (VIT) to address these issues. However, most VIT-based methods focus on channel modeling to reduce expensive computational costs, but in which the restored images suffer from spatial illumination inconsistencies, artifacts, and blurriness. To end for this, we propose a novel one-stage Retinex-based Illumination-Guided Dual transformer model (IGDFormer) to lit up low-light images. The model consists of an estimator and a restorer. The estimator generates a light-up feature map and a lit-up image through pure Convolutional Neural Networks (CNNs). The restorer denoises the lit-up image with a U-shaped network equipped with an Illumination-Guided Dual Attention Block (IGDAB). Specifically, IGDAB consists of cascaded channel attention and window attention that achieves cross-channel/spatial modeling. Channel attention alleviates inductive bias through the CNN-Transformer collaborative layer, and window attention introduces spatial domains knowledge by partitioning and shifting. In addition, the light-up features act as values guide the interaction modeling of non-local illumination intensities in both the channel and spatial domains. Extensive experiments were conducted on 5 low-light image enhancement benchmarks and 1 dark object detection benchmark, which demonstrate that the efficacy of our IGDFormer and its superiority in restoring spatial details compared to other state-of-the-art methods. The code is available at https://github.com/YanJieWen/IGDFormer-light-up-dark.","2025-02","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","158","","","","","","","","","","English","","","","WOS:001327213000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Channel-wise attention; Low-light image enhancement; Multi-head Self Attention; One-stage Retinex Theory; Transformer; Window attention","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I8W9MKCJ","journalArticle","2024","Yun, BX; Lei, BY; Chen, JN; Wang, HY; Qiu, S; Shen, W; Li, QL; Wang, Y","SpecTr: Spectral Transformer for Microscopic Hyperspectral Pathology Image Segmentation","IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY","","1051-8215","10.1109/TCSVT.2023.3326196","","Hyperspectral imaging (HSI) unlocks the huge potential to a wide variety of applications relying on high-precision pathology image segmentation, such as computational pathology. It can acquire biochemical properties even invisible to naked eyes from histological specimens. Since 1) spectra contain discriminative and continuous patterns for differentiating tissues/cells, and 2) the discriminability of spectra relies on both fine-grained relations in the high-resolution spectrum and coarse relations in the low-resolution spectrum, the key to achieving high-precision hyperspectral pathology image segmentation is to felicitously model the intra- and inter-scale context especially for spectra. In this paper, we propose a spectral transformer (SpecTr) for hyperspectral pathology image segmentation, which first captures global context for intra-scale spectral features, and subsequently extract coarse and fine-grained discriminative spectral information from inter-scale features, respectively. To learn intra-scale spectral context, we propose a Spectral Attentive Module (SAM). Unlike the existing Transformer model that is designed for modalities such as natural images, our proposed SAM is efficient in capturing sparse and pivotal spectral context while avoiding the heterogeneous underlying distributions and noises of different bands. Besides, to reduce the computational complexity of the HSI segmentation model, we further propose a global-local attention module to effectively learn a condensed spectral feature. Experiments show that HSIs can become a more powerful image modality for understanding microscopic pathology images than RGB images, and the proposed SpecTr outperforms other competing methods for hyperspectral pathology image segmentation, with an improvement of 3% compared with the popular 3D-nnUNet and other transformer-based methods. Our code is available at https://github.com/DeepMed-Lab-ECNU/SpecTr.","2024-06","2025-02-26 20:43:29","2025-02-26 20:43:29","","4610-4624","","6","34","","","","","","","","","","English","","","","WOS:001241605300040","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","ATTENTION; Hyperspectral pathology image; medical image segmentation; microscopy; NETWORKS; optical imaging; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B737J6IJ","journalArticle","2024","Kwong, NW; Chan, YL; Tsang, SH; Huang, ZY; Lam, KM","Deep Learning Approach for No-Reference Screen Content Video Quality Assessment","IEEE TRANSACTIONS ON BROADCASTING","","0018-9316","10.1109/TBC.2024.3374042","","Screen content video (SCV) has drawn much more attention than ever during the COVID-19 period and has evolved from a niche to a mainstream due to the recent proliferation of remote offices, online meetings, shared-screen collaboration, and gaming live streaming. Therefore, quality assessments for screen content media are highly demanded to maintain service quality recently. Although many practical natural scene video quality assessment methods have been proposed and achieved promising results, these methods cannot be applied to the screen content video quality assessment (SCVQA) task directly since the content characteristics of SCV are substantially different from natural scene video. Besides, only one no-reference SCVQA (NR-SCVQA) method, which requires handcrafted features, has been proposed in the literature. Therefore, we propose the first deep learning approach explicitly designed for NR-SCVQA. First, a multi-channel convolutional neural network (CNN) model is used to extract spatial quality features of pictorial and textual regions separately. Since there is no human annotated quality for each screen content frame (SCF), the CNN model is pre-trained in a multi-task self-supervised fashion to extract spatial quality feature representation of SCF. Second, we propose a time-distributed CNN transformer model (TCNNT) to further process all SCF spatial quality feature representations of an SCV and learn spatial and temporal features simultaneously so that high-level spatiotemporal features of SCV can be extracted and used to assess the whole SCV quality. Experimental results demonstrate the robustness and validity of our model, which is closely related to human perception.","2024-06","2025-02-26 20:43:29","2025-02-26 20:43:29","","555-569","","2","70","","","","","","","","","","English","","","","WOS:001193849200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Human visual experience; multi-channel convolutional neural network; multi-task learning; no reference video quality assessment; screen content video quality assessment; self-supervised learning; SIMILARITY; spatiotemporal features","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BDA78XI9","journalArticle","2024","Jin, XN; Wang, ZQ; Ma, JY; Liu, CZ; Bai, XR; Lan, YB","Electronic eye and electronic tongue data fusion combined with a GETNet model for the traceability and detection of Astragalus","JOURNAL OF THE SCIENCE OF FOOD AND AGRICULTURE","","0022-5142","10.1002/jsfa.13450","","BACKGROUND Astragalus is a widely used traditional Chinese medicine material that is easily confused due to its quality, price and other factors derived from different origins. This article describes a novel method for the rapid tracing and detection of Astragalus via the joint application of an electronic tongue (ET) and an electronic eye (EE) combined with a lightweight convoluted neural network (CNN)-transformer model. First, ET and EE systems were employed to measure the taste fingerprints and appearance images, respectively, of different Astragalus samples. Three spectral transform methods - the Markov transition field, short-time Fourier transform and recurrence plot - were utilized to convert the ET signals into 2D spectrograms. Then, the obtained ET spectrograms were fused with the EE image to obtain multimodal information. A lightweight hybrid model, termed GETNet, was designed to achieve pattern recognition for the Astragalus fusion information. The proposed model employed an improved transformer module and an improved Ghost bottleneck as its backbone network, complementarily utilizing the benefits of CNN and transformer architectures for local and global feature representation. Furthermore, the Ghost bottleneck was further optimized using a channel attention technique, which boosted the model's feature extraction effectiveness. RESULTS The experiments indicate that the proposed data fusion strategy based on ET and EE devices has better recognition accuracy than that attained with independent sensing devices. CONCLUSION The proposed method achieved high precision (99.1%) and recall (99.1%) values, providing a novel approach for rapidly identifying the origin of Astragalus, and it holds great promise for applications involving other types of Chinese herbal medicines. (c) 2024 Society of Chemical Industry.","2024-08-15","2025-02-26 20:43:29","2025-02-26 20:43:29","","5930-5943","","10","104","","","","","","","","","","English","","","","WOS:001189100200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Astragalus; data fusion; electronic eye; electronic tongue; traceability and detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4Z8HIN3D","journalArticle","2024","Riya, NJ; Chakraborty, M; Khan, R","Artificial Intelligence-Based Early Detection of Dengue Using CBC Data","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3443299","","Dengue fever is a tropical mosquito-transmitted disease spread through the Aedes mosquito, where the human body works as the primary host. Each year, densely populated countries such as Bangladesh, Thailand, and India, particularly in the Southeast Asian region, experience the majority of dengue outbreaks worldwide. Notably, in 2023, Bangladesh endured an unprecedented dengue outbreak, registering the highest number of cases in over two decades since 2000. This research aims to facilitate early detection of dengue from patients' complete blood count (CBC) medical laboratory reports collected from two hospitals in Dhaka, Bangladesh. The custom-built dataset, comprising 320 samples and 14 hematology features, is used to evaluate diverse artificial intelligence techniques. This dataset documents suspected dengue cases in Bangladesh from May 2023 to October 2023, reflecting a significant outbreak period, including a gender distribution ratio of 5:3 male to female patients. Various preprocessing steps, handling missing values and outliers, one-hot encoding, synthetic oversampling, and removing redundant features, are applied to the employed dataset. Five feature selection methods and diverse machine learning algorithms, along with ensemble learning and transformer-based models, are implemented. The stacking ensemble classifier achieved the highest performance, with an accuracy of 96.88% and an F1 score of 0.9646. The stacking technique has been built using the LightGBM meta-classifier and XGBoost, Logistic Regression, and Multilayer Perceptron base learners. The collected CBC dengue dataset and the implementation codes are available at: https://github.com/mritunjoychk17/Dengue-Prediction-in-Bangladesh-Using-Machine-Learning.","2024","2025-02-26 20:43:29","2025-02-26 20:43:29","","112355-112367","","","12","","","","","","","","","","English","","","","WOS:001298687900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Blood; Complete blood count; Dengue fever; dengue prediction; Diseases; ensemble learning; Ensemble learning; explainable AI; Feature extraction; feature selection; machine learning; Machine learning; Machine learning algorithms; Predictive models; transformer model; Viruses (medical)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2XJJ2V92","journalArticle","2023","Li, J; Ye, JY; Zhang, RX; Wu, Y; Berhane, GS; Deng, HX; Shi, H","CPFTransformer: transformer fusion context pyramid medical image segmentation network","FRONTIERS IN NEUROSCIENCE","","1662-453X","10.3389/fnins.2023.1288366","","IntroductionThe application of U-shaped convolutional neural network (CNN) methods in medical image segmentation tasks has yielded impressive results. However, this structure's single-level context information extraction capability can lead to problems such as boundary blurring, so it needs to be improved. Additionally, the convolution operation's inherent locality restricts its ability to capture global and long-distance semantic information interactions effectively. Conversely, the transformer model excels at capturing global information.MethodsGiven these considerations, this paper presents a transformer fusion context pyramid medical image segmentation network (CPFTransformer). The CPFTransformer utilizes the Swin Transformer to integrate edge perception for segmentation edges. To effectively fuse global and multi-scale context information, we introduce an Edge-Aware module based on a context pyramid, which specifically emphasizes local features like edges and corners. Our approach employs a layered Swin Transformer with a shifted window mechanism as an encoder to extract contextual features. A decoder based on a symmetric Swin Transformer is employed for upsampling operations, thereby restoring the resolution of feature maps. The encoder and decoder are connected by an Edge-Aware module for the extraction of local features such as edges and corners.ResultsExperimental evaluations on the Synapse multi-organ segmentation task and the ACDC dataset demonstrate the effectiveness of our method, yielding a segmentation accuracy of 79.87% (DSC) and 20.83% (HD) in the Synapse multi-organ segmentation task.DiscussionThe method proposed in this paper, which combines the context pyramid mechanism and Transformer, enables fast and accurate automatic segmentation of medical images, thereby significantly enhancing the precision and reliability of medical diagnosis. Furthermore, the approach presented in this study can potentially be extended to image segmentation of other organs in the future.","2023-12-07","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","17","","","","","","","","","","English","","","","WOS:001127749400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","context pyramid fusion network; Edge-Aware module; medical image segmentation; multiscale feature; Swin Transformer; U-NET","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3SCNULZ6","journalArticle","2023","Zheng, QH; Tian, XY; Yu, ZG; Ding, Y; Elhanashi, A; Saponara, S; Kpalma, K","MobileRaT: A Lightweight Radio Transformer Method for Automatic Modulation Classification in Drone Communication Systems","DRONES","","2504-446X","10.3390/drones7100596","","Nowadays, automatic modulation classification (AMC) has become a key component of next-generation drone communication systems, which are crucial for improving communication efficiency in non-cooperative environments. The contradiction between the accuracy and efficiency of current methods hinders the practical application of AMC in drone communication systems. In this paper, we propose a real-time AMC method based on the lightweight mobile radio transformer (MobileRaT). The constructed radio transformer is trained iteratively, accompanied by pruning redundant weights based on information entropy, so it can learn robust modulation knowledge from multimodal signal representations for the AMC task. To the best of our knowledge, this is the first attempt in which the pruning technique and a lightweight transformer model are integrated and applied to processing temporal signals, ensuring AMC accuracy while also improving its inference efficiency. Finally, the experimental results-by comparing MobileRaT with a series of state-of-the-art methods based on two public datasets-have verified its superiority. Two models, MobileRaT-A and MobileRaT-B, were used to process RadioML 2018.01A and RadioML 2016.10A to achieve average AMC accuracies of 65.9% and 62.3% and the highest AMC accuracies of 98.4% and 99.2% at +18 dB and +14 dB, respectively. Ablation studies were conducted to demonstrate the robustness of MobileRaT to hyper-parameters and signal representations. All the experimental results indicate the adaptability of MobileRaT to communication conditions and that MobileRaT can be deployed on the receivers of drones to achieve air-to-air and air-to-ground cognitive communication in less demanding communication scenarios.","2023-10","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","10","7","","","","","","","","","","English","","","","WOS:001094209300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;28<br/>Total Times Cited:&nbsp;&nbsp;31<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","automatic modulation classification (AMC); cognitive radio; deep learning; drone communications; EFFICIENT; lightweight transformer; NETWORK; NOISE; non-cooperative communications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YMEKMIZR","journalArticle","2024","Tang, YH; Zhang, LY; Yuan, Y","Fashion item captioning via grid-relation self-attention and gated-enhanced decoder","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-023-15492-w","","Fashion Item Captioning aims to describe fine-grained item details according to several image angles, which is an advancement of the conventional image captioning task(generating a simple sentence for a single image). Most recent researches are dedicated to describe one image, and less attention is paid to capturing item details from different angles. As a result, they commonly take advantage of formula structure in the general domain rather than taking into account the characteristics of product images in the fashion domain. In this paper, we re-define the fashion captioning task to be Fashion Item Captioning, which is aimed to describe the item angles based on a multi-branch design. Based on this thinking, fashion item captioning still face two challenges. First, existing image captioning methods simply consider the grid features as a set of visual tokens while ignoring the positional relationships among them. And these rich relationships are difficult to be established by such coarse-grained visual representations. To this end, we propose a Grid-relation Self-Attention(GSA), in which three positional relations among grid-level features are captured to strengthen the visual representations from multi perspectives. Second, the attributes of products are usually scattered in images from different angles, which means different angles contribute differently to the sentence caption. Thus, a Gated-Enhanced Decoder(GED) is introduced to dynamically measure the contribution of different views to the target word. Finally, we apply GSA and GED to the vanilla transformer model for the fashion item captioning task. Extensive experiments demonstrate the proposed GSA-GED is effective. More remarkably, GSA-GED achieves competitive performance on Fashion-Gen and FACAD datasets, with the CIDEr-D score being increased from 106.7% to 112.1%, 47.1% to 49.3%, respectively.","2024-01","2025-02-26 20:43:29","2025-02-26 20:43:29","","7631-7655","","3","83","","","","","","","","","","English","","","","WOS:001006598900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","E-Commerce; Fashion; Image captioning; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BB2HTAZV","journalArticle","2023","Chen, ZP; Wang, H; Chen, HA; Wei, T","Continuous motion finger joint angle estimation utilizing hybrid sEMG-FMG modality driven transformer-based deep learning model","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2023.105030","","Continuous motion joint angle estimation plays an important role in human-machine interaction (HMI). How-ever, it is still a challenge to estimate continuous motion finger joint angles (CMFJA) accurately. To improve CMFJA estimation accuracy, we used hybrid surface electromyography-force myography (sEMG-FMG) modality as the decoding scheme since combining two sensing modalities could potentially compensate and correct for single sensing modality, and proposed a biosignals driven convolution neural networks (CNN) and Transformer model (BioCNN-T) to estimate CMFJA motivated by the potential of the Transformer architecture, which extracts local features through CNN, and captures dependencies between global features through Transformer encoder. The metacarpophalangeal joint angles of 6 hand movements commonly used in daily life were selected as estimation objects. The experimental results show that CMFJA estimation by hybrid sEMG-FMG modality can achieve higher accuracy than single modality. And we found that the addition of convolution block before Transformer encoder plays a positive role in improving estimation accuracy and pixel-level fusion is the most suitable among the information fusion strategies appearing in the paper. What's more, compare with the CNN and long short-term memory neural networks (CNN-LSTM), the BioCNN-T has higher accuracy and less computing cost. (Average normalized root mean square error, 0.0456 +/- 0.0030 versus 0.0539 +/- 0.0035; Inference time, 9.12 x 10-6 s versus 3.20 x 10-4 s). To our knowledge, our work is a pioneer in the use of hybrid sEMG-FMG modality and Transformer architecture to estimate CMFJA. The Implications of it have promising potential in flexible and fine-grained HMI.","2023-08","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","85","","","","","","","","","","English","","","","WOS:001001345100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Electromyography; Finger joint angle estimation; Force myography; HAND; Human -machine interaction; KINEMATICS; NETWORK; RECOGNITION; SURFACE ELECTROMYOGRAPHY; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VVH49NSA","journalArticle","2023","Zhang, N","Learning Adversarial Transformer for Symbolic Music Generation","IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS","","2162-237X","10.1109/TNNLS.2020.2990746","","Symbolic music generation is still an unsettled problem facing several challenges. The complete music score is a quite long note sequence, which consists of multiple tracks with recurring elements and their variants at various levels. The transformer model, benefiting from its self-attention has shown advantages in modeling long sequences. There have been some attempts at applying the transformer-based model to music generation. However, previous works train the model using the same strategy as the text generation task, despite the obvious differences between the pattern of texts and musics. These models cannot consistently produce music samples of high quality. In this article, we propose a novel adversarial transformer to generate transformer to generate music pieces with high musicality. The generative adversarial learning and the self-attention networks are combined creatively. The generation of long sequence is guided by the adversarial objectives, which provides a strong regularization to enforce the transformer to focus on learning of the global and local structures. Instead of adopting the time-consuming Monte Carlo (MC) search method that is commonly used in the existing sequence generative models, we propose an effective and convenient method to compute the reward for each generated step (REGS) for the long sequence. The discriminator is trained to optimize the elaborately designed global and local loss objective functions simultaneously, which enables the discriminator to give reliable REGS for the generator. The adversarial objective combined with the teacher forcing objective is used to guide the training of the generator. The proposed model can be used to generate single-track or multitrack music pieces. Experiments show that our model can generate long music pieces with the improved quality compared with the original music transformers.","2023-04","2025-02-26 20:43:29","2025-02-26 20:43:29","","1754-1763","","4","34","","","","","","","","","","English","","","","WOS:000964682100011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;42<br/>Total Times Cited:&nbsp;&nbsp;43<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","Adversarial learning; Bars; Computational modeling; Computer architecture; Generators; Learning systems; long sequence generation; music generation; NEURAL-NETWORKS; self-attention; Task analysis; Training; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YSRH5KTK","journalArticle","2022","Kumagai, Y; Takubo, K; Sato, T; Ishikawa, H; Yamamoto, E; Ishiguro, T; Hatano, S; Toyomasu, Y; Kawada, K; Matsuyama, T; Mochiki, E; Ishida, H; Tada, T","AI analysis and modified type classification for endocytoscopic observation of esophageal lesions","DISEASES OF THE ESOPHAGUS","","1120-8694","10.1093/dote/doac010","","Endocytoscopy (EC) facilitates real-time histological diagnosis of esophageal lesions in vivo. We developed a deep-learning artificial intelligence (AI) system for analysis of EC images and compared its diagnostic ability with that of an expert pathologist and nonexpert endoscopists. Our new AI was based on a vision transformer model (DeiT) and trained using 7983 EC images of the esophagus (2368 malignant and 5615 nonmalignant). The AI evaluated 114 randomly arranged EC pictures (33 ESCC and 81 nonmalignant lesions) from 38 consecutive cases. An expert pathologist and two nonexpert endoscopists also analyzed the same image set according to the modified type classification (adding four EC features of nonmalignant lesions to our previous classification). The area under the curve calculated from the receiver-operating characteristic curve for the AI analysis was 0.92. In per-image analysis, the overall accuracy of the AI, pathologist, and two endoscopists was 91.2%, 91.2%, 85.9%, and 83.3%, respectively. The kappa value between the pathologist and the AI, and between the two endoscopists and the AI showed moderate concordance; that between the pathologist and the two endoscopists showed poor concordance. In per-patient analysis, the overall accuracy of the AI, pathologist, and two endoscopists was 94.7%, 92.1%, 86.8%, and 89.5%, respectively. The modified type classification aided high overall diagnostic accuracy by the pathologist and nonexpert endoscopists. The diagnostic ability of the AI was equal or superior to that of the experienced pathologist. AI is expected to support endoscopists in diagnosing esophageal lesions based on EC images.","2022-09-14","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","9","35","","","","","","","","","","English","","","","WOS:000769668900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","artificial intelligence; ARTIFICIAL-INTELLIGENCE; CELL-CARCINOMA; convolutional neural network; deep learning; endocytoscopy; esophagus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"77FCT5ZW","journalArticle","2025","Acharyya, S; Pervin, N","Enhancing cross-domain recommendations: Leveraging personality-based transfer learning with probabilistic matrix factorization","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.125667","","The conventional method of computing personality scores through extensive questionnaire-based surveys poses practical challenges in real-world scenarios. An alternate route is to predict personality scores from user reviews by analysing various linguistic features such as writing style, word choices, and specific phrases. However, the reviews are domain-dependent and classification models trained on one domain cannot be readily applied to other domains. To mitigate this challenge, we propose a cross-domain recommendation framework called PEMF-CD which leverages a novel mixing strategy to integrate user reviews from multiple domains with common joint embedding space and predict user personality scores using a transformer model. By capturing the underlying semantics and latent representations within the textual data, the transformer architecture can effectively model the linguistic cues to infer users' personality traits, and the learning is transferred across domains. To further enhance the recommendation process, our model integrates personality- wise and rating pattern-based similarities of users into a probabilistic matrix factorization method that fosters user neighbourhoods based on similarity scores among users. Comprehensive experiments were conducted using five real-world datasets from TripAdvisor and Amazon with varied numbers of users, items, and reviews of up to 44,187, 26,386, and 426,791, respectively. The performance has been benchmarked against thirteen baseline algorithms and the experimental results demonstrate a significant improvements of up to 24.72%, 64.28%, 48.79%, and 61% in RMSE, and 55.9%, 76.7%, 67.6%, and 71.5% in MAE fora 90:10 train-test split with Digital Music, Fashion, Magazine Subscriptions and Video Games datasets from Amazon, respectively. Similar results have been observed for the 80:20 train-test split.","2025-03-05","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","263","","","","","","","","","","English","","","","WOS:001359015900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","BEHAVIOR; Cross-domain recommendations; Mixing strategy; Personality-aware recommendations; Probabilistic matrix factorization technique; TRAITS; Transfer learning; Transformers; USERS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HDPWRSKJ","journalArticle","2024","Tahir, NU; Long, Z; Zhang, ZP; Asim, M; Elaffendi, M","PVswin-YOLOv8s: UAV-Based Pedestrian and Vehicle Detection for Traffic Management in Smart Cities Using Improved YOLOv8","DRONES","","2504-446X","10.3390/drones8030084","","In smart cities, effective traffic congestion management hinges on adept pedestrian and vehicle detection. Unmanned Aerial Vehicles (UAVs) offer a solution with mobility, cost-effectiveness, and a wide field of view, and yet, optimizing recognition models is crucial to surmounting challenges posed by small and occluded objects. To address these issues, we utilize the YOLOv8s model and a Swin Transformer block and introduce the PVswin-YOLOv8s model for pedestrian and vehicle detection based on UAVs. Firstly, the backbone network of YOLOv8s incorporates the Swin Transformer model for global feature extraction for small object detection. Secondly, to address the challenge of missed detections, we opt to integrate the CBAM into the neck of the YOLOv8. Both the channel and the spatial attention modules are used in this addition because of how well they extract feature information flow across the network. Finally, we employ Soft-NMS to improve the accuracy of pedestrian and vehicle detection in occlusion situations. Soft-NMS increases performance and manages overlapped boundary boxes well. The proposed network reduced the fraction of small objects overlooked and enhanced model detection performance. Performance comparisons with different YOLO versions ( for example YOLOv3 extremely small, YOLOv5, YOLOv6, and YOLOv7), YOLOv8 variants (YOLOv8n, YOLOv8s, YOLOv8m, and YOLOv8l), and classical object detectors (Faster-RCNN, Cascade R-CNN, RetinaNet, and CenterNet) were used to validate the superiority of the proposed PVswin-YOLOv8s model. The efficiency of the PVswin-YOLOv8s model was confirmed by the experimental findings, which showed a 4.8% increase in average detection accuracy (mAP) compared to YOLOv8s on the VisDrone2019 dataset.","2024-03","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","3","8","","","","","","","","","","English","","","","WOS:001191646500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;27<br/>Total Times Cited:&nbsp;&nbsp;28<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","CBAM; OBJECT DETECTION; pedestrian and vehicle detection; soft-NMS; swin transformer; UAVs; YOLOv8","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"STRQQ836","journalArticle","2024","Dwivedi, K; Dutta, MK; Pandey, JP","EMViT-Net: A novel transformer-based network utilizing CNN and multilayer perceptron for the classification of environmental microorganisms using microscopic images","ECOLOGICAL INFORMATICS","","1574-9541","10.1016/j.ecoinf.2023.102451","","Environmental microbes are certainly present in our surroundings since they are essential to the growth and survival of human advancement. The detailed analysis of environmental microorganisms (EMs) is very important to recognize, understand and make use of microbes as well and prevent damage. Extracting the discriminatory features from a limited-size dataset is very challenging for a deep learning model and a pure transformer-based network cannot achieve good classification results on a limited-size dataset due to the lack of muti-scale features. In this study, a novel vision transformer-based deep neural network is proposed by integrating the transformer with CNN for the classification of EM using microscopic images. The proposed network EMViT-Net has three main modules: a transformer module, a CNN module and a multilayer perceptron module. The transformer model extracted multiscale features to generate more discriminatory information from the images. A new separable convolutional parameter-sharing attention (SCPSA) block is integrated with the CNN module in the core of EMViT-Net, which makes the model robust to capture the local and global features, and simultaneously reduces the computational complexity of the model. The data augmentation is performed to introduce the variability in the dataset and counter the problem of overfitting and data imbalance. After extensive experiments and detailed analysis, it has been determined that the proposed model EMViT-Net outperforms the other existing methods and achieves state-of-the-art results with an accuracy of 71.17% which proves the effectiveness of the model for the classification of environmental microbes.","2024-03","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","79","","","","","","","","","","English","","","","WOS:001156390600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Computer -aided system; Deep learning; Environmental microorganisms classification; Microscopic images; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PPZ8ZD3Z","journalArticle","2023","Wang, LD; Ding, XL; Qiu, X","Mechanism of breast cancer immune microenvironment in prognosis of heart failure","COMPUTERS IN BIOLOGY AND MEDICINE","","0010-4825","10.1016/j.compbiomed.2023.107339","","The treatment of breast cancer can potentially impose a burden on the heart, leading to an increased risk of heart failure. Studies have shown that more than half of breast cancer patients die from non-tumor-related causes, with cardiovascular disease (CVD) being the leading cause of death. However, the underlying mechanism linking breast cancer prognosis and heart failure remains unclear.To investigate this, we conducted an analysis where we compared the differentially expressed genes (DEGs) in early and advanced breast cancer with genes associated with heart failure. This analysis revealed 18 genes that overlapped between the two conditions, with 15 of them being related to immune function. This suggests that immune pathways may play a role in the prognosis of breast cancer patients with heart failure.Using gene expression data from 1260 breast cancer patients, we further examined the impact of these 15 genes on survival time. Additionally, through enrichment analysis, we explored the functions and pathways associated with these genes in relation to breast cancer and heart failure.By constructing a transformer model, we discovered that the expression patterns of these 15 genes can accurately predict the occurrence of heart failure. The model achieved an AUC of 0.86 and an AUPR of 0.91.Moreover, through analysis of single-cell sequencing data from breast cancer patients undergoing PD-1 treatment and experiencing heart failure, we identified a significant number of cell-type-specific genes that were shared between both diseases. This suggests that changes in gene expression in immune cells following breast cancer treatment may be associated with the development of heart failure.","2023-09","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","164","","","","","","","","","","English","","","","WOS:001058700300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","Breast cancer; CARDIOVASCULAR-DISEASE; Cell-specific-gene; CHEMOTHERAPY; CLONAL HEMATOPOIESIS; DATABASE; Heart failure; Immune function; MUTATIONS; PERTUZUMAB; RISK; SURVIVORS; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CQF7MBL2","journalArticle","2023","Zhao, BT; Wang, YJ; Su, KK; Ren, H; Han, XY","Semi-supervised pedestrian re-identification via a teacher-student model with similarity-preserving generative adversarial networks","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-022-03218-8","","This paper describes a pedestrian re-identification algorithm, which was developed by integrating semi-supervised learning and similarity-preserving generative adversarial networks (SPGAN). The pedestrian re-identification task aimed to rapidly capture the same target using different cameras. Importantly, this process can be applied in the field of security. Because real-life environments are complex, the number of detected identities is uncertain, and the cost of manual labeling is high; therefore, it is difficult to apply the re-identification model based on supervised learning in real-life scenarios. To use the existing labeled dataset and a large amount of unlabeled data in the application environment, this report proposes a semi-supervised pedestrian re-identification model, which combines a teacher-student model with SPGAN. SPGAN was used to reduce the difference between the target domain and the source domain by transferring the style of the labeled dataset from the source domain. Additionally, the dataset from the source domain was used after the style transfer to pre-train the model; this enabled the model to adapt more rapidly to the target domain. The teacher-student model and the transformer model were then employed to generate soft pseudo-labels and hard pseudo-labels (via iterative training) and to update the parameters through distillation learning. Thus, it retained the learned features while adapting to the target domain. Experimental results indicated that the maps of the applied method on the Market-to-Duke, Duke-to-Market, Market-to-MSMT, and Duke-to-MSMT domains were 70.2, 79.3, 30.2, and 33.4, respectively.","2023-01","2025-02-26 20:43:29","2025-02-26 20:43:29","","1605-1618","","2","53","","","","","","","","","","English","","","","WOS:000789746500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Deep learning; Pedestrian re-identification; Semi-supervised learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HM5GLB4Y","journalArticle","2022","Jiang, GY; Chen, H; Wang, CY; Xue, PX","Transformer Network Intelligent Flight Situation Awareness Assessment Based on Pilot Visual Gaze and Operation Behavior Data","INTERNATIONAL JOURNAL OF PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE","","0218-0014","10.1142/S0218001422590157","","Situational awareness is the ability of pilots to master flight status, which is of great significance to aviation flight safety and flight effect. According to the information processing model, the pilot's main steps of processing information are feeling, perception and execution. There are many problems in situation awareness analysis guided by visual gaze, such as large analysis deviation and high delay due to various influencing factors and complex characteristics. In order to solve this problem, this paper proposes a situation awareness assessment method based on artificial intelligence neural network and integrating visual gaze and flight control. First, this paper carries out simulated flight training experiments for flight cadets, and collects the data of eye movement, line of sight tracking, flight control and flight parameters of pilot cadets. Then, aiming at the flight subjects, a situation awareness analysis method based on events is established, and the situation awareness state in the experiment is evaluated and analyzed through the flight parameter data. Then, the visual gaze and flight control data are sliced in the unit of situational awareness events, and the data set is constructed. Finally, this paper designs a multi-channel sequence data classification and analysis model based on transformer, in which the situation awareness characteristics of visual gaze and operation behavior are analyzed through the attention mechanism. The experimental results show that the accuracy of situation awareness classification of the designed neural network model to the experimental data set is 96%, and can classify and evaluate the pilot's situation awareness state in 5 s.","2022-04","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","05","36","","","","","","","","","","English","","","","WOS:000796480800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","AVIATION; aviation flight; CNN; flight evaluation; SELF-ATTENTION; sequential data transformer model; Situational awareness","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6IFF684I","journalArticle","2025","Choudhary, R; Deepak, A; Krishnasamy, G; Kumar, V","An optimized bidirectional vision transformer based colorectal cancer detection using histopathological images","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2024.107210","","The high death rate of colorectal cancer has a long-term impact on human life around the world. Early detection of colorectal cancer leads to an increase in the survival rate of the patients. Overfitting issues occurred due to the presence of imbalanced datasets. To resolve the challenges, a novel deep learning-based approach based on an effective optimization strategy with a bidirectional vision transformer model for colorectal cancer detection. Disease classification is performed using two datasets: colorectal histology images and the NCT-CRC-HE-100 K dataset. Initially, the histopathological images from the dataset are trained and pre-processed using a Trimmed Pixel density-based median filter (TPDMF), which removes noise from the input images and enhances the quality of the images. The features of the pre-processed image are extracted using the Capsule Assisted Res2Net (CAR2N) model, and an optimized Bidirectional Vision Transformer (OBVT) model is presented to identify colorectal cancer. Here, the Bi- Long short-term memory (Bi-LSTM) model is used in the Multi-layer perception module of the vision transformer to reduce the complexity of the detection process. The proposed methodology uses a chaotic sequence-based Snake optimization algorithm (Ch-SOA) to tune the hyperparameters in the proposed model. The proposed model can be analyzed using different performance metrics like accuracy, precision, sensitivity, specificity, False negative rate (FNR), and False positive rate (FPR). The proposed model can obtain an accuracy of 97.11458 % for the colorectal histology images dataset and 97.01235 % for the NCT-CRC-HE-100 K dataset. From this analysis, the proposed model can obtain better results than other existing models.","2025-04","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","102","","","","","","","","","","English","","","","WOS:001373093800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Bidirectional long short-term memory; Capsule network; CLASSIFICATION; NEURAL-NETWORKS; Pixel-based median filter; Residual network; Snake optimization algorithm; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JIKB4Y49","journalArticle","2024","Zhuang, QZ; Gao, L; Zhang, F; Ren, XY; Qin, L; Wang, YP","MIVNDN: Ultra-Short-Term Wind Power Prediction Method with MSDBO-ICEEMDAN-VMD-Nons-DCTransformer Net","ELECTRONICS","","2079-9292","10.3390/electronics13234829","","Wind speed, wind direction, humidity, temperature, altitude, and other factors affect wind power generation, and the uncertainty and instability of the above factors bring challenges to the regulation and control of wind power generation, which requires flexible management and scheduling strategies. Therefore, it is crucial to improve the accuracy of ultra-short-term wind power prediction. To solve this problem, this paper proposes an ultra-short-term wind power prediction method with MIVNDN. Firstly, the Spearman's and Kendall's correlation coefficients are integrated to select the appropriate features. Secondly, the multi-strategy dung beetle optimization algorithm (MSDBO) is used to optimize the parameter combinations in the improved complete ensemble empirical mode decomposition with adaptive noise (ICEEMDAN) method, and the optimized decomposition method is used to decompose the historical wind power sequence to obtain a series of intrinsic modal function (IMF) components with different frequency ranges. Then, the high-frequency band IMF components and low-frequency band IMF components are reconstructed using the t-mean test and sample entropy, and the reconstructed high-frequency IMF component is decomposed quadratically using the variational modal decomposition (VMD) to obtain a new set of IMF components. Finally, the Nons-Transformer model is improved by adding dilated causal convolution to its encoder, and the new set of IMF components, as well as the unreconstructed mid-frequency band IMF components and the reconstructed low-frequency IMF, component are used as inputs to the model to obtain the prediction results and perform error analysis. The experimental results show that our proposed model outperforms other single and combined models.","2024-12","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","23","13","","","","","","","","","","English","","","","WOS:001377730000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","combined model; nons-DCTransformer; optimization algorithm; ultra-short-term wind power prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RUGMV87N","journalArticle","2024","Yan, XY; He, XX","Optimal cooperative scheduling strategy of energy storage and electric vehicle based on residential building integrated photovoltaic","JOURNAL OF BUILDING ENGINEERING","","2352-7102","10.1016/j.jobe.2024.110082","","With the development of photovoltaic (PV) power generation technology, more and more families have begun to use solar energy. However, the uncertainty of solar energy production and user electricity demand has brought huge challenges to the development of efficient energy scheduling strategies. To deal with the uncertainty of electricity behavior, Monte Carlo generates the electricity scenario sets based on real data. According to the principle of minimum average distribution error (ADE), the scene with 200 scenes is selected for scheduling. Then, the Transformer model with random error (RE-Trans) is used to predict solar radiation and outdoor temperature. Through verification, it is found that the Mean Absolute Error (MAE) of the former is 0.389 and the Root Mean Square Error (RMSE) is 0.514. The MAE of the latter is 0.212 and RMSE is 0.413. To make effective decisions in the agent with the environment, a Deep Reinforcement Learning model with self-attention mechanism (SAN-DRL) is designed. The model aims to achieve a dynamic balance between electricity costs, carbon emissions and electricity sales income. Through continuous interaction with the environment, the agent finally obtains the optimal disordered charging and discharging behavior of energy storage systems (ESS) and electric vehicle systems (EVs), which greatly improves the utilization of solar energy resources. Finally, through simulation experiments, the proposed method is compared with both the baseline model and the ideal scheduling. The results demonstrate that the proposed method can reduce electricity costs and carbon emissions by 83.72 % and 72.08 %, respectively. Additionally, it achieves a net income of 38.59 CNY.","2024-10-15","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","95","","","","","","","","","","English","","","","WOS:001265428600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","Deep reinforcement learning; Demand response; Energy scheduling; Home energy management systems; Self-attention mechanism; SYSTEMS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EQRSWBE5","journalArticle","2024","Han, L; Abdel-Aty, M; Yu, RJ; Wang, CZ","LSTM plus Transformer Real-Time Crash Risk Evaluation Using Traffic Flow and Risky Driving Behavior Data","IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS","","1524-9050","10.1109/TITS.2024.3438616","","Crash risk evaluation studies mainly established the relationship between the macro traffic status and crashes. However, the impact of risky driving behavior, a significant factor in crashes, has not been thoroughly investigated due to the data collection limitations of fixed detectors. In this study, the risky driving behavior data generated by Connected Vehicle (CV) techniques was introduced along with traffic flow data to develop the crash risk evaluation model. An LSTM + Transformer approach was developed, in which the Transformer could extract the non-aggregated spatial-temporal features of risky driving behaviors and LSTM learn the temporal patterns of traffic flow. An ensemble layer was proposed to integrate the macro traffic status features and micro driving behavior, and automatically fit their weights to optimize crash risk evaluation performance. Data from a Chinese freeway was used for empirical analysis. The results show that the proposed LSTM +Transformer model achieved high model accuracy (77.7%), recall (68.6%), and AUC (0.785), with average improvement of between 5.34%, 15.69%, and 5.97%, respectively, compared to existing LSTM, XGBoost, SVM and Logistic Regression (LR) models. Moreover, utilizing risky driving behavior data by incorporating the macro traffic status has proved to capture the pre-crash traffic flow turbulence more precisely. The model results explained by SHapley Additive exPlanations (SHAP) reveal that higher frequency, longer duration and greater acceleration of risky braking behavior increase the number of road vehicles affected, thereby heightening the crash risks. These findings could help the deployment of proactive traffic management and target CV control strategies to reduce crashes.","2024-11","2025-02-26 20:43:29","2025-02-26 20:43:29","","18383-18395","","11","25","","","","","","","","","","English","","","","WOS:001292788800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","Accidents; Crash risk evaluation; Data models; Detectors; IMPACT; Long short term memory; PREDICTION; proactive traffic management; risky driving behavior; Roads; SAFETY; Traffic control; Transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B69GVYI9","journalArticle","2024","Maheswari, D; Kayalvizhi, M","Design and Numerical Analysis of Double Encoder-Swinnets-A Novel Swin Transformers-Based Diabetic Foot","JOURNAL OF NANOELECTRONICS AND OPTOELECTRONICS","","1555-130X","10.1166/jno.2024.3621","","Thermography is crucial for early diabetic foot (DF) diagnosis and accurate segmentation of ulcer-prone areas. However, existing segmentation methods fall short due to image complexities and ambiguities. Recent advancements in deep learning show promise, but they rely on color images, not thermal ones. This research introduces an automated, robust, and precise diabetic foot segmentation approach using a deep neural network based on U-Nets and modified Swin transformers. The unique attention mechanism known as the axial attention parallel module (A2PM) is combined with the Unet-based Swin transformer model for an efficient segmentation process to extract local foreground features. The combination of the modified Swin Transformer's multi-headed attention networks enhances thermal color information integration, resulting in superior segmentation accuracy. In addition, the proposed model makes use of the stacking dilated convolution (SDC) approach to protect the deep features that could be lost in the up-sampling modules. The feature maps are immediately integrated at the encoder and decoder stages using the shortcut connection (ResConv route) IP: 203 109 20 On: Tue 11 Jun 2024 3:09:49 based on the residually connected convolutional layer. Furhermore, thiResConv path is added serially Copyright: Ame can Scientific Publishers before the encoder and decoder characteristics are combied. The model is tested on 124 diabetic and 100 De vered by Ingenta healthy subjects, evaluating its performance with metrics like DICE, IoU, precision, and recall. The suggested approach outperforms current techniques in an experimental evaluation, achieving 99.5% DICE, 98.9% IoU, 99.33% precision, and 99.56% recall for diabetic thermal ulcer image segmentation.","2024-07","2025-02-26 20:43:29","2025-02-26 20:43:29","","737-746","","7","19","","","","","","","","","","English","","","","WOS:001245664200008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","Deep Learning; Diabetic Foot Ulcer Segmentation; Swin Transformer.; Thermal Image Segmentation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T9RB9Z45","journalArticle","2024","Bo, LX; Xu, J","Enhancing Supply Chain Efficiency Resilience Using Predictive Analytics and Computational Intelligence Techniques","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3507161","","This study addresses critical challenges in supply chain management, particularly focusing on enhancing forecast accuracy and optimizing inventory management. Traditional methods often fall short in accuracy, leading to inventory imbalances and inefficiencies. To overcome these limitations, the study employs a combination of Transformer models for demand forecasting and Particle Swarm Optimization (PSO) for inventory parameter optimization. The methodology involves a comprehensive approach: data collection includes historical sales data and inventory levels, which are preprocessed through cleaning, normalization, and feature extraction. Transformer models are used for predicting demand, leveraging their ability to capture complex patterns in time-series data. PSO is applied to optimize inventory parameters, addressing multi-objective optimization problems in the supply chain. Results from the study indicate significant improvements. The Transformer model achieved a reduction in Mean Absolute Error (MAE) from 15.8 to 8.2 and Root Mean Squared Error (RMSE) from 22.3 to 11.5, demonstrating enhanced forecasting accuracy. The application of PSO led to a 12% reduction in overall operational costs and a 25% improvement in order fulfillment times. Additionally, inventory holding costs decreased by 18%, and transportation costs were reduced by 10%. Integrating Transformer models with PSO presents a robust solution for modern supply chains, offering substantial improvements in efficiency and cost-effectiveness. The study recommends adopting these advanced methodologies for better forecasting and inventory management, and suggests further research into additional machine learning techniques and real-time data integration to enhance supply chain performance.","2024","2025-02-26 20:43:29","2025-02-26 20:43:29","","183451-183465","","","12","","","","","","","","","","English","","","","WOS:001375797900047","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Accuracy; Adaptation models; ALGORITHM; Costs; Data models; inventory management; MACHINE; MANAGEMENT; Optimization; particle swarm optimization (PSO); Predictive analytics; Predictive models; Real-time systems; Supply chain management; supply chain optimization; Supply chains; transformer models; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XD8RZPDP","journalArticle","2023","Yu, MY; Xu, HQ; Zhou, FL; Xu, S; Yin, HL","A Deep-Learning-Based Multimodal Data Fusion Framework for Urban Region Function Recognition","ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION","","2220-9964","10.3390/ijgi12120468","","Accurate and efficient classification maps of urban functional zones (UFZs) are crucial to urban planning, management, and decision making. Due to the complex socioeconomic UFZ properties, it is increasingly challenging to identify urban functional zones by using remote-sensing images (RSIs) alone. Point-of-interest (POI) data and remote-sensing image data play important roles in UFZ extraction. However, many existing methods only use a single type of data or simply combine the two, failing to take full advantage of the complementary advantages between them. Therefore, we designed a deep-learning framework that integrates the above two types of data to identify urban functional areas. In the first part of the complementary feature-learning and fusion module, we use a convolutional neural network (CNN) to extract visual features and social features. Specifically, we extract visual features from RSI data, while POI data are converted into a distance heatmap tensor that is input into the CNN with gated attention mechanisms to extract social features. Then, we use a feature fusion module (FFM) with adaptive weights to fuse the two types of features. The second part is the spatial-relationship-modeling module. We designed a new spatial-relationship-learning network based on a vision transformer model with long- and short-distance attention, which can simultaneously learn the global and local spatial relationships of the urban functional zones. Finally, a feature aggregation module (FGM) utilizes the two spatial relationships efficiently. The experimental results show that the proposed model can fully extract visual features, social features, and spatial relationship features from RSIs and POIs for more accurate UFZ recognition.","2023-12","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","12","12","","","","","","","","","","English","","","","WOS:001131240600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","CLASSIFICATION; COVER; IMAGERY; LAND-USE; MOBILE PHONE; multimodal data fusion; REMOTE; spatial relationship modeling; UFZ map; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JD6NSFEE","journalArticle","2023","Liang, TJ; Sun, N; Wang, Q; Bu, JY; Li, L; Chen, YH; Cao, ML; Ma, J; Liu, T","sEMG-Based End-to-End Continues Prediction of Human Knee Joint Angles Using the Tightly Coupled Convolutional Transformer Model","IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS","","2168-2194","10.1109/JBHI.2023.3304639","","Wearable exoskeleton robots can promote the rehabilitation of patients with physical dysfunction. And improving human-computer interaction performance is a significant challenge for exoskeleton robots. The traditional feature extraction process based on surface Electromyography(sEMG) is complex and requires manual intervention, making real-time performance difficult to guarantee. In this study, we propose an end-to-end method to predict human knee joint angles based on sEMG signals using a tightly coupled convolutional transformer (TCCT) model. We first collected sEMG signals from 5 healthy subjects. Then, the envelope was extracted from the noise-removed sEMG signal and used as the input to the model. Finally, we developed the TCCT model to predict the knee joint angle after 100 ms. For the prediction performance, we used the Root Mean Square Error(RMSE), Pearson Correlation Coefficient(CC), and Adjustment R-2 as metrics to evaluate the error between the actual knee angle and the predicted knee angle. The results show that the model can predict the human knee angle quickly and accurately. The mean RMSE, Adjustment R-2, and (CC) values of the model are 3.79 degrees, 0.96, and 0.98, respectively, which are better than traditional deep learning models such as Informer (4.14, 0.95, 0.98), CNN (5.56, 0.89, 0.96) and CNN-BiLSTM (3.97, 0.95, 0.98). In addition, the prediction time of our proposed model is only 11.67 +/- 0.67 ms, which is less than 100 ms. Therefore, the real-time and accuracy of the model can meet the continuous prediction of human knee joint angle in practice.","2023-11","2025-02-26 20:43:29","2025-02-26 20:43:29","","5272-5280","","11","27","","","","","","","","","","English","","","","WOS:001129955100007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","End-to-End; prediction; surface electromyography (sEMG); tightly coupled convolutional transformer(TCCT)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E3GWFJE7","journalArticle","2023","Lüders, CM; Pietz, T; Maalej, W","On understanding and predicting issue links","REQUIREMENTS ENGINEERING","","0947-3602","10.1007/s00766-023-00406-x","","Stakeholders in software projects use issue trackers like JIRA or Bugzilla to capture and manage issues, including requirements, feature requests, and bugs. To ease issue navigation and structure project knowledge, stakeholders manually connect issues via links of certain types that reflect different dependencies, such as Epic-, Block-, Duplicate-, or Relate- links. Based on a large dataset of 16 JIRA repositories, we study the commonalities and differences in linking practices and link types across the repositories. We then investigate how state-of-the-art machine learning models can predict common link types. We observed significant differences across the repositories and link types, depending on how they are used and by whom. Additionally, we observed several inconsistencies, e.g., in how Duplicate links are used. We found that a transformer model trained on titles and descriptions of linked issues significantly outperforms other optimized models, achieving an encouraging average macro F1- score of 0.64 for predicting nine popular link types across all repositories (weighted F1-score of 0.73). For the specific Subtask- and Epic- links, the model achieves top F1-scores of 0.89 and 0.97, respectively. If we restrict the task to predict the mere existence of links, the average macro F1-score goes up to 0.95. In general, the shorter issue text, possibly indicating precise issues, seems to improve the prediction accuracy with a strong negative correlation of - 0.73. We found that Relate-links often get confused with the other links, which suggests that they are likely used as default links in unclear cases. Our findings particularly on the quality and heterogeinity of issue link data have implications for researching and applying issue link prediction in practice.","2023-12","2025-02-26 20:43:29","2025-02-26 20:43:29","","541-565","","4","28","","","","","","","","","","English","","","","WOS:001068125400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Dependency management; Duplicate detection; Issue management; Issue tracking systems; Mining issue tracker; Transformer models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JKR5XKXK","journalArticle","2023","Li, GQ; Ye, H; Bin, ZJ","High-frequency oscillation mechanism analysis of wind farm-side MMC station considering converter transformer stray capacitance","INTERNATIONAL JOURNAL OF ELECTRICAL POWER & ENERGY SYSTEMS","","0142-0615","10.1016/j.ijepes.2023.109179","","High-frequency oscillation is one of the critical issues threatening the stability of modular multilevel converter (MMC) based high-voltage direct current (HVDC) system. A new 2 kHz high-frequency oscillation has occurred in the wind farm-side MMC station of Rudong wind farm integrated MMC-HVDC project of China during no-load charging process. The mechanism of this high-frequency oscillation is different to previous ones. Apart from the time delay of MMC, the stray capacitance of converter transformer makes a significant contribution to the high-frequency oscillation. This paper investigates the high-frequency oscillation mechanism of wind farm-side MMC station during no-load charging process. First, the harmonic state space (HSS) model of a wind farm-side MMC station is established. In addition to the leakage inductance, the stray capacitance is considered in the converter transformer model. To reveal the significance of the converter transformer stray capacitance in this new high-frequency oscillation, the root loci of the system are calculated with varying stray capacitance. Then, the state variables with high degree of participation in the high-frequency oscillation modes are determined by the participation factor analysis. A reduced-order model suitable for the high-frequency oscillation analysis is further established based on the participation factor analysis results. Next, the high -frequency oscillation mechanism is revealed by impedance analysis. Finally, the effects of system parameters are analyzed by the combination of eigenvalue analysis and impedance analysis. The analysis results are validated by electromagnetic transient simulations.","2023-11","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","153","","","","","","","","","","English","","","","WOS:001016864800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","Eigenvalue analysis; Harmonic state space; High-frequency oscillation; Impedance analysis; IMPEDANCE MODEL; Modular multilevel converter (MMC); Participation factor analysis; RESONANCE; STABILITY ANALYSIS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I5PGDWT6","journalArticle","2022","Tiwari, D; Nagpal, B","KEAHT: A Knowledge-Enriched Attention-Based Hybrid Transformer Model for Social Sentiment Analysis","NEW GENERATION COMPUTING","","0288-3635","10.1007/s00354-022-00182-2","","Social media materialized as an influential platform that allows people to share their views on global and local issues. Sentiment analysis can handle these massive amounts of unstructured reviews and convert them into meaningful opinions. Undoubtedly, COVID-19 originated as the enormous challenge across the world that physically and financially bruted humankind. Meanwhile, farmers' protests shook up the world against three pieces of legislation passed by the Indian government. Hence, an artificial intelligence-based sentiment model is needed for suggesting the right direction toward outbreaks. Although Deep Neural Network (DNN) gained popularity in sentiment analysis applications, these still have a limitation of sequential training, high-dimension feature space, and equal feature importance distribution. In addition, inaccurate polarity scoring and utility-based topic modeling are other challenging aspects of sentiment analysis. It motivates us to propose a Knowledge-Enriched Attention-based Hybrid Transformer (KEAHT) model by enriching the explicit knowledge of Latent Dirichlet Allocation (LDA) topic modeling and lexicalized domain ontology. A pre-trained Bidirectional Encoder Representation from Transformer (BERT) is employed to train within a minimum training corpus. It provides the facility of attention mechanism and can solve complex text problems accurately. A comparative study with existing baselines and recent hybrid models affirms the credibility of the proposed KEAHT in the field of Natural Language Processing (NLP). This model emphasizes artificial intelligence's role in handling the situation of the global pandemic and democratic dispute in a country. Furthermore, two benchmark datasets, namely ""COVID-19-Vaccine-Labelled-Tweets"" and ""Indian-Farmer-Protest-Labelled-Tweets"", are also constructed to accommodate future researchers for outlining the essential facts associated with the outbreaks.","2022-12","2025-02-26 20:43:29","2025-02-26 20:43:29","","1165-1202","","4","40","","","","","","","","","","English","","","","WOS:000823330000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","Bidirectional encoder representation from transformer (BERT); CNN; COVID-19 vaccine; Indian farmer protest; Latent Dirichlet Allocation (LDA); Lexicon approach; LSTM; MACHINE; Social networks; WORD EMBEDDINGS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HVS4S5RM","journalArticle","2022","Chandran, P; Zoss, G; Gross, M; Gotardo, P; Bradley, D","Shape Transformers: Topology-Independent 3D Shape Models Using Transformers","COMPUTER GRAPHICS FORUM","","0167-7055","10.1111/cgf.14468","","Parametric 3D shape models are heavily utilized in computer graphics and vision applications to provide priors on the observed variability of an object's geometry (e.g., for faces). Original models were linear and operated on the entire shape at once. They were later enhanced to provide localized control on different shape parts separately. In deep shape models, nonlinearity was introduced via a sequence of fully-connected layers and activation functions, and locality was introduced in recent models that use mesh convolution networks. As common limitations, these models often dictate, in one way or another, the allowed extent of spatial correlations and also require that a fixed mesh topology be specified ahead of time. To overcome these limitations, we present Shape Transformers, a new nonlinear parametric 3D shape model based on transformer architectures. A key benefit of this new model comes from using the transformer's self-attention mechanism to automatically learn nonlinear spatial correlations for a class of 3D shapes. This is in contrast to global models that correlate everything and local models that dictate the correlation extent. Our transformer 3D shape autoencoder is a better alternative to mesh convolution models, which require specially-crafted convolution, and down/up-sampling operators that can be difficult to design. Our model is also topologically independent: it can be trained once and then evaluated on any mesh topology, unlike most previous methods. We demonstrate the application of our model to different datasets, including 3D faces, 3D hand shapes and full human bodies. Our experiments demonstrate the strong potential of our Shape Transformer model in several applications in computer graphics and vision.","2022-05","2025-02-26 20:43:29","2025-02-26 20:43:29","","195-207","","2","41","","","","","","","","","","English","","","","WOS:000802723900017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","CCS Concepts; center dot Computing methodologies -> Shape modeling; Modeling methodologies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C98D2PQQ","journalArticle","2022","Yuan, CX; Marion, T; Moghaddam, M","Leveraging End-User Data for Enhanced Design Concept Evaluation: A Multimodal Deep Regression Model","JOURNAL OF MECHANICAL DESIGN","","1050-0472","10.1115/1.4052366","","Design concept evaluation is a key process in the new product development process with a significant impact on the product's success and total cost over its life cycle. This paper is motivated by two limitations of the state-of-the-art in concept evaluation: (1) the amount and diversity of user feedback and insights utilized by existing concept evaluation methods such as quality function deployment are limited. (2) Subjective concept evaluation methods require significant manual effort which in turn may limit the number of concepts considered for evaluation. A deep multimodal design evaluation (DMDE) model is proposed in this paper to bridge these gaps by providing designers with an accurate and scalable prediction of new concepts' overall and attribute-level desirability based on large-scale user reviews on existing designs. The attribute-level sentiment intensities of users are first extracted and aggregated from online reviews. A multimodal deep regression model is then developed to predict the overall and attribute-level sentiment values based on the features extracted from orthographic product images via a fine-tuned ResNet-50 model and from product descriptions via a fine-tuned bidirectional encoder representations from transformer model and aggregated using a novel self-attention-based fusion model. The DMDE model adds a data-driven, user-centered loop within the concept development process to better inform the concept evaluation process. Numerical experiments on a large dataset from an online footwear store indicate a promising performance by the DMDE model with 0.001 MSE loss and over 99.1% accuracy.","2022-02-01","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","2","144","","","","","","","","","","English","","","","WOS:000741659500018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;18<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;122</p>","","","AHP; ALTERNATIVES; CONCEPT SELECTION; deep regression; design automation; design evaluation; FUZZY; GROUP DECISION-MAKING; HYBRID APPROACH; image processing; INTELLIGENCE; METHODOLOGY; natural language processing; NETWORK; new product development; PERFORMANCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4CM96VJ2","journalArticle","2024","Nester, CO; Gao, Q; Wang, CL; Katz, MJ; Lipton, RB; Verghese, J; Rabin, LA","""Cognitive"" Criteria in Older Adults With Slow Gait Speed: Implications for Motoric Cognitive Risk Syndrome","JOURNALS OF GERONTOLOGY SERIES A-BIOLOGICAL SCIENCES AND MEDICAL SCIENCES","","1079-5006","10.1093/gerona/glae038","","Background Motoric cognitive risk syndrome (MCR) is a predementia condition that combines slow gait speed and subjective cognitive concerns (SCC). The SCC criterion is presently unstandardized, possibly limiting risk detection. We sought to (a) characterize SCC practices through MCR literature review; (b) investigate the ability of SCC in slow gait individuals in predicting the likelihood of cognitive impairment in a demographically diverse sample of community-dwelling, nondemented older adults.Methods First, we comprehensively reviewed the MCR literature, extracting information regarding SCC measures, items, sources, and cognitive domain. Next, Einstein Aging Study (EAS) participants (N = 278, Mage = 77.22 +/- 4.74, %female = 67, Meducation = 15 +/- 3.61, %non-Hispanic White = 46.3) completed gait, Clinical Dementia Rating Scale (CDR), and SCC assessment at baseline and annual follow-up (Mfollow-up = 3.5). Forty-two participants met slow gait criteria at baseline. Generalized linear mixed-effects models examined baseline SCC to predict cognitive impairment on CDR over follow-up.Results We reviewed all published MCR studies (N = 106) and documented ambiguity in SCC criteria, with a prevalent approach being use of a single self-reported memory item. In EAS, high SCC endorsement on a comprehensive, validated screen significantly affected the rate of cognitive impairment (CDR; beta interaction = 0.039, p = .018) in slow gait individuals.Conclusions An assessment approach that queries across numerous SCC domains was found to predict future decline in clinical dementia status in slow gait older adults. Current SCC practices in MCR, which tend to utilize a single-memory item, may not be the optimal approach. We discuss the implications of SCC criteria validation and standardization to enhance early dementia detection in MCR.","2024-04-01","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","4","79","","","","","","","","","","English","","","","WOS:001186000800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","ALZHEIMERS-DISEASE; COMPLAINTS; DECLINE; DEMENTIA; Early dementia diagnosis; IMPAIRMENT; Preclinical dementia; PREVALENCE; PROGRESSION; SELF; Slow gait; Subjective cognitive concerns; The cognitive change index","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N73YSQRJ","journalArticle","2022","Grunewald, CM; Feldmeier, V; Supprian, T; Albers, P; Giessing, M; Niegisch, G","Cognitive function in patients undergoing cystectomy for bladder cancer - results from a prospective observational study","THERAPEUTIC ADVANCES IN UROLOGY","","1756-2872","10.1177/17562872221087660","","Background: Impaired cognitive function of bladder cancer patients plays a role in coping with the kind of urinary diversion and may impact perioperative morbidity. In this study we therefore aimed to assess the prevalence of mild cognitive impairment in patients undergoing radical cystectomy. Secondary objectives included correlation of common cognition tests, assessment of the admitting physician, and perioperative complication rates. Methods: Patients undergoing radical cystectomy for bladder cancer were prospectively screened by neuropsychological tests including cognition tests [DemTect (Dementia Detection test), MMSE (Mini-Mental State Examination), clock drawing test] prior to surgery. Besides, clinical characteristics and perioperative outcomes were documented. Frequency of mild cognitive impairment as assessed by DemTect was correlated with the results of MMSE and clock drawing test, the occurrence of anxiety and depression, the assessment of the admitting physician, and perioperative complication rates as calculated by Spearman rank correlation coefficient. Comparative analysis (parametric and nonparametric) of patient characteristics (nonpathological versus pathological DemTect suggestive of mild cognitive impairment) was performed. Results: A total of 51 patients (80% male, median age 69 years) were analyzed. DemTect was suspicious of mild cognitive impairment in 27% (14/51) of patients, whereas MMSE and clock drawing test showed pathological results only in 10/51 and 6/51 patients, respectively. We found no correlation between mild cognitive impairment and anxiety/depression status. In all, 5/20 patients (25%) with suspicious DemTect results were considered suitable for a continent diversion neobladder by the admitting physician. Suspicious DemTect results were predictive for higher perioperative complication rates (29% versus 5%). Study limitations include small sample size and missing long-term follow-up. Conclusions: Mild cognitive impairment was observed in more than a quarter of radical cystectomy patients prior to surgery. Preoperative assessment should be supplemented by neuropsychological testing such as the DemTect as mild cognitive impairment is often underestimated and associated with significantly higher perioperative complication rates.","2022-03","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","14","","","","","","","","","","English","","","","WOS:000775515900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","ANXIETY; AWARENESS; bladder cancer; COMPLICATIONS; IMPAIRMENT; mild cognitive impairment; MINI-MENTAL-STATE; radical cystectomy; RADICAL CYSTECTOMY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B7EIMKHL","journalArticle","2025","Lenk, A; Vogt, M; Herrmann, C","An Approach to Predicting Energy Demand Within Automobile Production Using the Temporal Fusion Transformer Model","ENERGIES","","1996-1073","10.3390/en18010002","","The increasing share of renewable energies within energy systems leads to an increase in complexity. The growing complexity is due to the diversity of technologies, ongoing technological innovations, and fluctuating electricity production. To continue to ensure a secure, economical, and needs-based energy supply, additional information is needed to efficiently control these systems. This impacts public and industrial supply systems, such as vehicle factories. This paper examines the influencing factors and the applicability of the Temporal Fusion Transformer (TFT) model for the weekly energy demand forecast at an automobile production site. Seven different TFT models were trained for the weekly forecast of energy demand. Six models predicted the energy demand for electricity, heat, and natural gas. Three models used a rolling day-ahead forecast, and three models predicted the entire week in one step. In the seventh model, the rolling day-ahead forecast was used again, with the three target values being predicted in the same model. The analysis of the models shows that the rolling day-ahead forecasting method with a MAPE of 13% already delivers good results in predicting the electrical energy demand. The prediction accuracy achieved is sufficient to use the model outcomes as a basis for weekly operational planning and energy demand reporting. However, further improvements are still required for use in automated control of the energy system to reduce energy procurement costs. The models for forecasting heat and natural gas demands still show too high deviations, with a MAPE of 62% for heat demand and a MAPE of 39% for natural gas demand. To accurately predict these demands, further factors must be identified to explain the demand.","2025-01","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","1","18","","","","","","","","","","English","","","","WOS:001393596900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;127</p>","","","ALGORITHM; ARMA MODEL; ARTIFICIAL NEURAL-NETWORKS; automotive production; energy; FORECASTING ELECTRICITY CONSUMPTION; INTEGRATION; LOAD; machine learning; prediction; SUPPORT VECTOR MACHINES; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LL5YEBLQ","journalArticle","2024","Niu, XL; Guo, G","An Open-Domain Search Quiz Engine Based on Transformer","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","the volume of information on the Internet continues to grow exponentially, efficient retrieval of relevant data has become a significant challenge. Traditional keyword matching techniques, while useful, often fall short in addressing the complex and varied queries users present. This paper introduces a novel approach to automated question and answer systems by integrating deep learning and natural language processing (NLP) technologies. Specifically, it combines the Transformer model with the HowNet knowledge base to enhance semantic understanding and contextual relevance of responses. The proposed system architecture includes layers for word embedding, Transformer encoding, attention mechanisms, and Bi-directional Long Short- Term Memory (Bi-LSTM) processing, enabling sophisticated semantic matching and implication recognition. Using the BQ Corpus dataset in the banking and finance domain, the system demonstrated substantial improvements in accuracy and F1-score over existing models. The primary contributions of this research are threefold: (1) the introduction of a semantic fusion approach using HowNet for enhanced contextual understanding, (2) the optimization of Transformer-based deep learning techniques for Q&A systems, and (3) a comprehensive evaluation using the BQ Corpus dataset, demonstrating significant improvements in accuracy and F1-score over baseline models. These contributions have important implications for improving the handling of complex and synonym-rich queries in automated Q&A systems. The experimental results highlight that the integrated approach significantly enhances the performance of automated Q&A systems, offering a more efficient and accurate means of information retrieval. This advancement is particularly crucial in the era of big data and Web 3.0, where the ability to quickly and accurately access relevant information is essential for both users and organizations.","2024-09","2025-02-26 20:43:29","2025-02-26 20:43:29","","1011-1020","","9","15","","","","","","","","","","English","","","","WOS:001344153600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","Bi-LSTM; deep learning; Natural language processing; semantic understanding; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G64GJSM5","journalArticle","2024","Li, KK; Yao, J; Leung, CK; Chen, AG","A MENTAL ILLNESS DETECTION MODEL FOR COLLEGE STUDENTS BASED ON BODY BEHAVIOR AND FACIAL EXPRESSION FEATURES","JOURNAL OF MECHANICS IN MEDICINE AND BIOLOGY","","0219-5194","10.1142/S0219519424400438","","Mental illnesses such as depression are typically neurologically related psychological disorders that affect people's mood, thinking and behavior. As the number of students who are concerned about their mental health continues to rise, depression has emerged as a mental health concern that has a significant impact on both students' academic performance and overall lives. To identify depression in students at an earlier stage, the purpose of this study was to provide a potentially unique approach. An approach to the detection of mental illnesses that is based on deep learning networks is proposed in this paper. First, facial expression and physical activity data are utilized for detecting depression. Second, the transformer model is utilized to extract the characteristics of the individual's physical behavior, and the multiregional attention network (MRAN) is utilized to extract the characteristics of the individual's emotions. The information that is obtained from the two modalities is complementary. Finally, at the fusion stage, this work applies the classification prediction of depression and nondepression (normal) at the decision level. This is done to ensure that the respective modal properties that were learned by the two channels are preserved in their entirety. We have demonstrated that our strategy is highly effective by performing experimental validation using a dataset that we developed ourselves. It is possible to identify depression in children at an earlier stage with the help of this effective remedy. It is anticipated that the findings of this study will provide an efficient screening tool for depression to educational institutions and organizations that focus on mental health, hence assisting students in receiving essential assistance and intervention at an earlier stage.","2024-10","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","08","24","","","","","","","","","","English","","","","WOS:001296084000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","deep learning; DEPRESSION; facial expression; feature fusion; Mental illness detection; physical behavior","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UQ64JZN2","journalArticle","2024","Jin, B; Ma, X; Hu, BJ; Zhang, ZK; Lian, ZX; Wang, B","Gesture-mmWAVE: Compact and Accurate Millimeter-Wave Radar-Based Dynamic Gesture Recognition for Embedded Devices","IEEE TRANSACTIONS ON HUMAN-MACHINE SYSTEMS","","2168-2291","10.1109/THMS.2024.3385124","","Dynamic gesture recognition using millimeter-wave radar is a promising contactless mode of human-computer interaction with wide-ranging applications in various fields, such as intelligent homes, automatic driving, and sign language translation. However, the existing models have too many parameters and are unsuitable for embedded devices. To address this issue, we propose a dynamic gesture recognition method (named ""Gesture-mmWAVE"") using millimeter-wave radar based on the multilevel feature fusion (MLFF) and transformer model. We first arrange each frame of the original echo collected by the frequency-modulated continuously modulated millimeter-wave radar in the Chirps x Samples format. Then, we use a 2-D fast Fourier transform to obtain the range-time map and Doppler-time map of gestures while improving the echo signal-to-noise ratio by coherent accumulation. Furthermore, we build an MLFF-transformer network for dynamic gesture recognition. The MLFF-transformer network comprises an MLFF module and a transformer module. The MLFF module employs the residual strategies to fuse the shallow, middle, and deep features and reduce the parameter size of the model using depthwise-separable convolution. The transformer module captures the global features of dynamic gestures and focuses on essential features using the multihead attention mechanism. The experimental results demonstrate that our proposed model achieves an average recognition accuracy of 99.11% on a dataset with 10% random interference. The scale of the proposed model is only 0.42M, which is 25% of that of the MobileNet V3-samll model. Thus, this method has excellent potential for application in embedded devices due to its small parameter size and high recognition accuracy.","2024-06","2025-02-26 20:43:29","2025-02-26 20:43:29","","337-347","","3","54","","","","","","","","","","English","","","","WOS:001214366000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Convolution; Deep learning; depthwise-separable convolution; dynamic gesture recognition; Feature extraction; Gesture recognition; Millimeter wave radar; millimeter-wave radar; multilevel feature fusion (MLFF); Radar; Scattering; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D5PCZ5VM","journalArticle","2024","Yang, L; Cao, JZ; Chen, WN; Wang, H; He, L","An efficient multi-scale transformer for satellite image dehazing","EXPERT SYSTEMS","","0266-4720","10.1111/exsy.13575","","Given the impressive achievement of convolutional neural networks (CNNs) in grasping image priors from extensive datasets, they have been widely utilized for tasks related to image restoration. Recently, there is been significant progress in another category of neural architectures-Transformers. These models have demonstrated remarkable performance in natural language tasks and higher-level vision applications. Despite their ability to address some of CNNs limitations, such as restricted receptive fields and adaptability issues, Transformer models often face difficulties when processing images with a high level of detail. This is because the complexity of the computations required increases significantly with the image's spatial resolution. As a result, their application to most high-resolution image restoration tasks becomes impractical. In our research, we introduce a novel Transformer model, named DehFormer, by implementing specific design modifications in its fundamental components, for example, the multi-head attention and feed-forward network. Specifically, the proposed architecture consists of the three modules, that is, (a) multi-scale feature aggregation network (MSFAN), (b) the gated-Dconv feed-forward network (GFFN), (c) and the multi-Dconv head transposed attention (MDHTA). For the MDHTA module, our objective is to scrutinize the mechanics of scaled dot-product attention through the utilization of per-element product operations, thereby bypassing the need for matrix multiplications and operating directly in the frequency domain for enhanced efficiency. For the GFFN module, which enables only the relevant and valuable information to advance through the network hierarchy, thereby enhancing the efficiency of information flow within the model. Extensive experiments are conducted on the SateHazelk, RS-Haze, and RSID datasets, resulting in performance that significantly exceeds that of existing methods.","2024-08","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","8","41","","","","","","","","","","English","","","","WOS:001187289200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","remote sensing image; satellite image dehazing; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UCC8RY5D","journalArticle","2024","Wang, ZK; Xu, ZF; Cai, C; Wang, XD; Xu, JZ; Shi, KZ; Zhong, XH; Liao, ZQ; Li, Q'","Rolling bearing fault diagnosis method using time-frequency information integration and multi-scale TransFusion network","KNOWLEDGE-BASED SYSTEMS","","0950-7051","10.1016/j.knosys.2023.111344","","Advances in deep learning methods have demonstrated remarkable development in diagnosing faults of rotating machinery. The currently popular deep neural networks suffer from design flaws in their network structure, leading to issues of long-term dependencies in fault diagnosis models built upon conventional deep neural networks. Consequently, such models exhibit insufficient global perceptual capabilities towards fault features. Furthermore, how accurately pre-trained models can diagnose faults is hugely impacted by changes in bearings' working conditions. To tackle the aforementioned issues, this study puts forth a multi-scale TransFusion (MSTF) model for diagnosing faults in rolling bearings under multiple operating conditions. Firstly, a time-frequency symmetric dot pattern transformation technique is designed to transform the original vibration signals into two-dimensional representations. This method can effectively highlight the distinctions between different fault types. Secondly, a multi-scale feature fusion module is established, which fully extracts low-level features from the time-frequency signals and reduces the complexity of the subsequent attention calculations. Meanwhile, relying on the advantages of the Transformer model in capturing global dependencies, the long-range periodic fault information is deeply mined. Finally, multi-head and multi-layer attention are visualized to enhance the interpretability of the model. After analyzing two case studies with both public and experimental datasets, the examination demonstrated that the developed model outperformed other state-of-the-art models. The diagnostic model developed in this study exhibits the ability to accurately diagnose bearing faults across multiple operating conditions while maintaining high robustness to signals contaminated with noise.","2024-01-25","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","284","","","","","","","","","","English","","","","WOS:001156312500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","CONVOLUTIONAL NEURAL-NETWORK; Deep Learning; Fault diagnosis; MACHINERY; Rolling bearings; Time-frequency symmetry dot pattern; TRANSFORM; Transformer neural network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"89EMLF6E","journalArticle","2023","Mazen, FMA; Shaker, Y; Abul Seoud, RA","Forecasting of Solar Power Using GRU-Temporal Fusion Transformer Model and DILATE Loss Function","ENERGIES","","1996-1073","10.3390/en16248105","","Solar power is a clean and sustainable energy source that does not emit greenhouse gases or other atmospheric pollutants. The inherent variability in solar energy due to random fluctuations introduces novel attributes to the power generation and load dynamics of the grid. Consequently, there has been growing attention to developing an accurate forecast model using various machine and deep learning techniques. Temporal attention mechanisms enable the model to concentrate on the critical components of the input sequence at each time step, thereby enhancing the accuracy of the prediction. The suggested GRU-temporal fusion transformer (GRU-TFT) model was trained and validated employing the ""Daily Power Production of Solar Panels"" Kaggle dataset. Furthermore, an innovative loss function termed DILATE is introduced to train the proposed model specifically for multistep and nonstationary time series forecasting. The outcomes have been subjected to a comparative analysis with alternative algorithms, such as neural basis expansion analysis for interpretable time series (N-BEATS), neural hierarchical interpolation for time series (N-HiTS), and extreme gradient boosting (XGBoost), using several evaluation metrics, including the absolute percentage error (MAE), mean square error (MSE), and root mean square error (RMSE). The model presented in this study exhibited significant performance improvements compared with traditional statistical and machine learning techniques. This is evident from the achieved values of MAE, MSE, and RMSE, which were 1.19, 2.08, and 1.44, respectively. In contrast, the machine learning approach utilizing the Holt-Winters method for time series forecasting in additive mode yielded MAE, MSE, and RMSE scores of 4.126, 29.105, and 5.3949, respectively.","2023-12","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","24","16","","","","","","","","","","English","","","","WOS:001130860800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","DILATE; GRU; LSTM; N-BEATS; N-HiTS; NETWORK; PV forecasting; temporal fusion transformer (TFT); XGBoost","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LJG74MUL","journalArticle","2023","Guesmi, M; Chatti, MA; Kadhim, L; Joarder, S; Ain, QU","Semantic Interest Modeling and Content-Based Scientific Publication Recommendation Using Word Embeddings and Sentence Encoders","MULTIMODAL TECHNOLOGIES AND INTERACTION","","2414-4088","10.3390/mti7090091","","The fast growth of data in the academic field has contributed to making recommendation systems for scientific papers more popular. Content-based filtering (CBF), a pivotal technique in recommender systems (RS), holds particular significance in the realm of scientific publication recommendations. In a content-based scientific publication RS, recommendations are composed by observing the features of users and papers. Content-based recommendation encompasses three primary steps, namely, item representation, user modeling, and recommendation generation. A crucial part of generating recommendations is the user modeling process. Nevertheless, this step is often neglected in existing content-based scientific publication RS. Moreover, most existing approaches do not capture the semantics of user models and papers. To address these limitations, in this paper we present a transparent Recommendation and Interest Modeling Application (RIMA), a content-based scientific publication RS that implicitly derives user interest models from their authored papers. To address the semantic issues, RIMA combines word embedding-based keyphrase extraction techniques with knowledge bases to generate semantically-enriched user interest models, and additionally leverages pretrained transformer sentence encoders to represent user models and papers and compute their similarities. The effectiveness of our approach was assessed through an offline evaluation by conducting extensive experiments on various datasets along with user study (N = 22), demonstrating that (a) combining SIFRank and SqueezeBERT as an embedding-based keyphrase extraction method with DBpedia as a knowledge base improved the quality of the user interest modeling step, and (b) using the msmarco-distilbert-base-tas-b sentence transformer model achieved better results in the recommendation generation step.","2023-09","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","9","7","","","","","","","","","","English","","","","WOS:001075166900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;124</p>","","","content-based recommender system; PROFILES; semantic user modeling; sentence encoder; SYSTEM; word embedding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3YXNM56I","journalArticle","2024","Dreo, J; Jug, J; Pavlovcic, T; Ogrin, A; Demsar, A; Aljaz, B; Agatic, F; Marusic, U","Comparative Performance of Five Cognitive Screening Tests in a Large Sample of Seniors","DEMENTIA AND GERIATRIC COGNITIVE DISORDERS","","1420-8008","10.1159/000540225","","Introduction: Recent introductions of disease-modifying treatments for Alzheimer's disease have re-invigorated the cause of early dementia detection. Cognitive ""paper and pencil"" tests represent the bedrock of clinical assessment, because they are cheap, easy to perform, and do not require brain imaging or biological testing. Cognitive tests vary greatly in duration, complexity, sociolinguistic biases, probed cognitive domains, and their specificity and sensitivity of detecting cognitive impairment (CI). Consequently, an ecologically valid head-to-head comparison seems essential for evidence-based dementia screening. Method: We compared five tests: Montreal cognitive assessment (MoCA), Alzheimer's disease assessment scale-cognitive subscale (ADAS), Addenbrooke's cognitive examination (ACE-III), euro-coin handling test (Eurotest), and image identification test (Phototest) on a large sample of seniors (N = 456, 77.9 +/- 8 years, 71% females). Their specificity and sensitivity were estimated in a novel way by contrasting each test's outcome to the majority outcome across the remaining tests (comparative specificity and sensitivity calculation [CSSC]). This obviates the need for an a priori gold standard such as a clinically clear-cut sample of dementia/MCI/controls. We posit that the CSSC results in a more ecologically valid estimation of clinical performance while precluding biases resulting from different dementia/MCI diagnostic criteria and the proficiency in detecting these conditions. Results: There exists a stark trade-off between behavioral test specificity and sensitivity. The test with the highest specificity had the lowest sensitivity, and vice versa. The comparative specificities and sensitivities were, respectively: Phototest (97%, 47%), Eurotest (94%, 55%), ADAS (90%, 68%), ACE-III (72%, 77%), MoCA (55%, 95%). Conclusion: Assuming a CI prevalence of 10%, the shortest (similar to 3 min) and the simplest instrument, the Phototest, was shown to have the best overall performance (accuracy 92%, PPV 66%, NPV 94%).<br />","2024-12","2025-02-26 20:43:29","2025-02-26 20:43:29","","289-298","","6","53","","","","","","","","","","English","","","","WOS:001366211000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","Addenbrooke's cognitive examination; Alzheimer's disease assessment scale-cognitive subscale; BIOMARKERS; Dementia; DEMENTIA; EARLY-DIAGNOSIS; Eurotest; EXAMINATION III; IMPAIRMENT; MOCA; Montreal cognitive assessment; Phototest; PRECLINICAL ALZHEIMERS-DISEASE; PREVALENCE; PRIMARY-CARE; Screening; TRIALS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9PEL4AFA","journalArticle","2025","Huang, YX; Jiao, DL; Huang, XR; Tang, TT; Gui, G","A Hybrid CNN-Transformer Network for Object Detection in Optical Remote Sensing Images: Integrating Local and Global Feature Fusion","IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING","","1939-1404","10.1109/JSTARS.2024.3483253","","Remote sensing images (RSIs) object detection is important in natural disaster management, urban planning and resource exploration. However, due to the large differences between RSIs and natural images (NIs), most of the existing object detectors for NIs cannot be directly used to process RSIs. Most existing models based on convolutional neural networks (CNNs) require additional design of specific attentional modules to relate small targets in RSIs to global positional relationships. In contrast, transformer-based models had to add modules to obtain more detailed information. This imposes additional computational overheads for deployment on edge devices. To solve the above-mentioned problem, we propose a hybrid CNN and transformer model (DConvTrans-LKA) to enhance the model's ability to acquire features and design a fusion of local and global attention mechanisms to fuse local features and global location information. To better fuse the feature and location information extracted by the model, we introduce a feature residual pyramid network to enhance the model's ability to fuse multiscale feature maps. Finally, we conduct experiments in three representative optical RSI datasets (NWPU VHR-10, HRRSD, and DIOR) to verify the effectiveness of our proposed DConvTrans-LKA method. The experimental results show that our proposed method reaches 61.7%, 82.1%, and 61.3% at mAP at 0.5, respectively, further demonstrating the potential of our proposed method in RSI object detection tasks.","2025","2025-02-26 20:43:29","2025-02-26 20:43:29","","241-254","","","18","","","","","","","","","","English","","","","WOS:001409622100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Accuracy; Context modeling; Convolution; Convolutional neural networks; Convolutional neural networks (CNNs); Detectors; Feature extraction; feature fusion; local and global attention (LGA); Nickel; Object detection; optical remote sensing images (RSIs); Remote sensing; TARGET DETECTION; Transformers; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E5HFQESN","journalArticle","2024","Li, YM; Tu, L; Zhang, CL","A State-of-Health Estimation Method for Lithium Batteries Based on Incremental Energy Analysis and Bayesian Transformer","JOURNAL OF ELECTRICAL AND COMPUTER ENGINEERING","","2090-0147","10.1155/2024/5822106","","Lithium-ion batteries (LIBs) have wide-ranging applications in areas such as electric vehicles and mobile devices. Accurate estimation of the state of health (SOH) of batteries is an important aspect of battery state estimation. Battery capacity cannot be precisely measured due to negative factors such as aging effects. To address this issue, this paper proposes a LIB's SOH estimation method based on incremental energy analysis (IEA) and transformer. First, data collected during the constant-current (CC) charging phase of the battery are used to create and analyze the IEA curve. Then, the peaks and areas of the curve are proposed as health characteristics of the LIB. Cosine similarity analysis (CSA) is employed to determine the correlation between each health characteristic and SOH, as well as the correlations between different health characteristics. Finally, an accurate estimation model of battery health was developed using the Bayesian-transformer model by plotting the relationship between health characteristics and battery health. To validate the reliability of the model, comparisons with regression evaluation metrics of other models such as support vector regression (SVR) and recurrent neural network (RNN) are conducted under different charging rates. The conclusion is drawn that this model exhibits an R2 greater than 98%, MAE less than 0.22%, RMSE less than 0.26%, and MAPE less than 0.0026%. Its accuracy is significantly improved compared to the same type of methods, and it can be used for high accuracy estimation of SOH in LIBs. The multistep prediction of a single step adopted by the model can effectively overcome the capacity regeneration problem in the field of SOH estimation, which will inspire future experts and scholars to improve the accuracy of SOH estimation.","2024-07-29","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","2024","","","","","","","","","","English","","","","WOS:001288286200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","ION BATTERIES; MODEL; SOH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LKVWUDVQ","journalArticle","2024","Tan, T; Shull, PB; Hicks, JL; Uhlrich, SD; Chaudhari, AS","Self-Supervised Learning Improves Accuracy and Data Efficiency for IMU-Based Ground Reaction Force Estimation","IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING","","0018-9294","10.1109/TBME.2024.3361888","","Objective: Recent deep learning techniques hold promise to enable IMU-driven kinetic assessment; however, they require large extents of ground reaction force (GRF) data to serve as labels for supervised model training. We thus propose using existing self-supervised learning (SSL) techniques to leverage large IMU datasets to pre-train deep learning models, which can improve the accuracy and data efficiency of IMU-based GRF estimation. Methods: We performed SSL by masking a random portion of the input IMU data and training a transformer model to reconstruct the masked portion. We systematically compared a series of masking ratios across three pre-training datasets that included real IMU data, synthetic IMU data, or a combination of the two. Finally, we built models that used pre-training and labeled data to estimate GRF during three prediction tasks: overground walking, treadmill walking, and drop landing. Results: When using the same amount of labeled data, SSL pre-training significantly improved the accuracy of 3-axis GRF estimation during walking compared to baseline models trained by conventional supervised learning. Fine-tuning SSL model with 1-10% of walking data yielded comparable accuracy to training baseline model with 100% of walking data. The optimal masking ratio for SSL is 6.25-12.5%. Conclusion: SSL leveraged large real and synthetic IMU datasets to increase the accuracy and data efficiency of deep-learning-based GRF estimation, reducing the need for labeled data. Significance: This work, with its open-source code and models, may unlock broader use cases of IMU-driven kinetic assessment by mitigating the scarcity of GRF measurements in practical applications.","2024-07","2025-02-26 20:43:29","2025-02-26 20:43:29","","2095-2104","","7","71","","","","","","","","","","English","","","","WOS:001252776000018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","DISEASE SEVERITY; GAIT; Inertial measurement unit; kinetics; KNEE ADDUCTION MOMENT; machine learning; SSL; VALIDITY; WALKING; wearable sensing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D2DZ227K","journalArticle","2024","Song, L; Gui, XA; Du, JR; Fan, ZM; Li, MW; Guo, LL","A Novel Transfer Learning Approach for State-of-Health Prediction of Lithium-Ion Batteries in the Absence of Run-to-Failure Data","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2024.3450095","","Accurate and reliable state-of-health (SOH) prediction becomes increasingly vital to ensure the safe and reliable operation of lithium-ion batteries (LIBs). The existing data-driven methods for LIBs' SOH prediction are developed with an ideal database, i.e., a huge run-to-failure data with a consistent distribution of training and testing sets. However, due to individual quality differences and complex operating conditions, data distribution shifts among different batteries may be obvious, and the entire life-cycle samples are difficult to collect in real world. Therefore, there exists a distribution discrepancy between source and target domains. Besides, temporal distribution shift may also exist with incomplete target domain, called time covariate shift (TCS). Thus, the model trained with source and incomplete target domains will cause prediction bias in unseen target data. To address such issues, a novel transfer learning (TL) approach using multiple feature alignment transformer (MFA-Transformer) model is conducted for the SOH prediction of LIBs. First, a multilayer feature alignment is performed via encoder-decoder structure of transformer framework, and multikernel maximum mean discrepancy (MK-MMD) is adopted to tackle data distribution discrepancy. Then, a new loss item based on Weibull distribution is utilized to enhance the data alignment effect. Moreover, a shift compensation strategy using shape-based distance (SBD) estimation is designed to dynamically eliminate the prediction bias resulting from TCS. Finally, experiments on two public LIBs datasets validate the effectiveness of the proposed method, which can offer a promising solution for industrial prognostic without entire life-cycle data.","2024","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","73","","","","","","","","","","English","","","","WOS:001317788500022","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","CHARGE ESTIMATION; Data models; Degradation; Distribution discrepancy; Lithium-ion batteries; MODEL; Predictive models; state-of-health (SOH) prediction; Task analysis; temporal covariate shift; Training; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FSKIARGE","journalArticle","2024","Tejaswini, H; Pai, MMM; Pai, RM","Automatic Estuarine Fish Species Classification System Based on Deep Learning Techniques","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3468438","","Fish classification (FC) is crucial in various domains, including fishery management and ecological research. Traditional FC methods rely mainly on morphological criteria such as body shape and patterns. Although these methods are useful, they require expert knowledge and are prone to subjective interpretation. Recent advances in technology and the availability of datasets have allowed deep learning (DL) techniques to be used in fish species classification. These methods automatically extract relevant features from fish images and categorize them into species groupings. Traditional DL models, however, have difficulties capturing long-range dependencies and require fixed input sizes, making them less adaptive when working with images with varying proportions. The Vision Transformer (ViT) addresses these constraints by utilizing the transformer model's self-attention mechanisms. So, in this study, a ViT is used to solve the FC problem. The performance of ViT is assessed against pre-trained models, VGG16, VGG19, DenseNet121, ResNet50v2, InceptionV3, InceptionResNetV2, and Xception. The experiments make use of a curated Estuarine Fish species dataset (EFD). In this study, ViT outperformed state-of-the-art literature by achieving 99.04% and 100% accuracy without and with augmentation, respectively. The presented research is tailored to the task of recognizing estuarine fish species that are useful in the aquaculture domain. Additionally, our research aligns with the objectives of Sustainable Development Goals (SDGs) 2 and 14. This emphasises the broader societal and environmental implications of our work, emphasizing its potential to positively impact food security and aquaculture ecosystem sustainability.","2024","2025-02-26 20:43:29","2025-02-26 20:43:29","","140412-140438","","","12","","","","","","","","","","English","","","","WOS:001329020300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;90</p>","","","Accuracy; Aquaculture; Biological system modeling; Classification algorithms; deep learning; Deep learning; Ecology; estuarine fish dataset; Feature extraction; Fish; fish classification; IDENTIFICATION; IMAGE CLASSIFICATION; Production; RECOGNITION; vision transformers; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9WBLKKU7","journalArticle","2023","Sharma, H; Marinovici, L; Adetola, V; Schaef, HT","Data-driven modeling of power generation for a coal power plant under cycling","ENERGY AND AI","","2666-5468","10.1016/j.egyai.2022.100214","","Increased penetration of renewables for power generation has negatively impacted the dynamics of conventional fossil fuel-based power plants. The power plants operating on the base load are forced to cycle, to adjust to the fluctuating power demands. This results in an inefficient operation of the coal power plants, which leads up to higher operating losses. To overcome such operational challenge associated with cycling and to develop an optimal process control, this work analyzes a set of models for predicting power generation. Moreover, the power generation is intrinsically affected by the state of the power plant components, and therefore our model development also incorporates additional power plant process variables while forecasting the power generation. We present and compare multiple state-of-the-art forecasting data-driven methods for power generation to determine the most adequate and accurate model. We also develop an interpretable attention-based transformer model to explain the importance of process variables during training and forecasting. The trained deep neural network (DNN) LSTM model has good accuracy in predicting gross power generation under various prediction horizons with/without cycling events and outperforms the other models for long-term forecasting. The DNN memory-based models show significant superiority over other state-of-the-art machine learning models for short, medium and long range predictions. The transformer-based model with attention enhances the selection of historical data for multi-horizon forecasting, and also allows to interpret the significance of internal power plant components on the power generation. This newly gained insights can be used by operation engineers to anticipate and monitor the health of power plant equipment during high cycling periods.","2023-01","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","11","","","","","","","","","","English","","","","WOS:001087262100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","Coal power plant cycling; Deep learning; IMPACTS; Interpretable temporal fusion transformer; Long short-term memory; NETWORKS; PREDICTION; SIMULATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5R3TSWNA","journalArticle","2021","Kar, A; Sengupta, M","Design, analysis and experimental validation of a variable frequency silicon carbide-based resonant-converter for welding applications","SADHANA-ACADEMY PROCEEDINGS IN ENGINEERING SCIENCES","","0256-2499","10.1007/s12046-021-01598-0","","This paper proposes a novel, reliable, efficient and cost-effective implementation of partial soft switching in a silicon carbide (SiC)-based variable-frequency phase-modulated resonant transition converter (PMRTC) used in manual metal arc welding (MMAW) applications at a peak power of 1.3 kW. The switching frequency (fsw) of the converter is increased from 100 kHz at no load to around 150 kHz for a rated power of 1.0 kW. Such an approach is not found in the existing literature. At such frequencies, a significant proportion of the output filter inductance is contributed by the inherent self-inductance of the output ""lead cables"". The switching losses in the semiconductor devices are reduced at no-load condition by reduction of the operating frequency. Load regulation is achieved at 150 kHz by implementing phase-shifted PWM technique. Implementation of partial soft switching without using additional components is another significant contribution of this work. The reduced size and weight of the filter inductor in turn reduces the overall size, weight and cost of the system but puts a restriction on the output lead cable length, which is another salient finding of this work. Since at high frequency the transformer model changes, design and finite-element method (FEM)-based simulation of the transformer are also presented in this paper. Loss calculations at 100 and 150 kHz are discussed. The entire converter is fabricated in the laboratory. Experimental and simulated results are found to be in excellent agreement.","2021-04-10","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","2","46","","","","","","","","","","English","","","","WOS:000639109500004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","DC-DC CONVERTER; EMI; FULL ZVS-RANGE; MMAW; PMRTC; REDUCED FILTER REQUIREMENT; SiC-converter; variable-frequency welding; welding converter; ZERO-VOLTAGE; ZVS converter","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZJPNASGP","journalArticle","2022","Dong, Y; Wang, YX; Liu, KK; Hou, TT; Han, XL; Cong, L; Ren, YF; Zhang, QH; Tang, S; Ekström, R; Laukka, EJ; Du, YF; Qiu, CX","Dementia screening in rural-dwelling Chinese older adults: The utility of a smell test and the self-rated AD8","JOURNAL OF THE AMERICAN GERIATRICS SOCIETY","","0002-8614","10.1111/jgs.17586","","Background Olfactory impairment is associated with dementia in clinical settings. We examined the relationship of olfactory identification function with all-cause dementia, Alzheimer's disease (AD), and vascular dementia (VaD) and assessed the discriminative ability of the Sniffin' Sticks Identification Test (SSIT), the self-rated Ascertain Dementia 8-item Questionnaire (AD8), and their combination for dementia detection among rural-dwelling older adults in China. Methods This population-based cross-sectional study included 4481 participants (age >= 65 years; 56.8% women; 38.1% illiteracy) living in rural communities. The 16-item SSIT was performed to assess olfactory identification function. The self-rated AD8 was administered to participants for cognitive status. We diagnosed dementia, AD, and VaD following the international criteria. Data were analyzed with logistic regression models and receiver operating characteristic curve. Results Of the 4481 participants, dementia was diagnosed in 139 persons (3.1%), including 92 with AD and 42 with VaD. The SSIT score (range, 0-16) was associated with multiadjusted odds ratios of 0.83 (95% CI: 0.79-0.88) for dementia, 0.84 (0.79-0.90) for AD, and 0.79 (0.71-0.87) for VaD. The area under the curve for the discrimination between participants with and without dementia was 0.73 (95% CI: 0.69-0.77) for SSIT score <= 8 alone, 0.86 (0.82-0.89) for self-rated AD8 score >= 3 alone, and 0.89 (0.86-0.92) for their combination using a logistic model. Conclusions Olfactory impairment is a clinical marker for all-cause dementia, AD, and VaD. The smell identification test, in combination with the brief self-rated cognitive screening tool, is accurate for screening dementia among rural-dwelling Chinese older adults with no or limited education.","2022-04","2025-02-26 20:43:29","2025-02-26 20:43:29","","1106-1116","","4","70","","","","","","","","","","English","","","","WOS:000727403300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","ACCURACY; ALZHEIMERS-DISEASE; ASSOCIATION; dementia; diagnostic accuracy; DYSFUNCTION; INFORMANT INTERVIEW; MILD COGNITIVE IMPAIRMENT; ODOR IDENTIFICATION; olfaction; OLFACTORY IDENTIFICATION; population-based study; RISK; self-rated ascertain dementia 8-item questionnaire; VASCULAR DEMENTIA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IEBRRAZW","journalArticle","2024","Sun, XY; Zhang, LA; Wang, C; Yang, YY; Wang, H","Dynamic Real-Time Prediction of Reclaimed Water Volumes Using the Improved Transformer Model and Decomposition Integration Technology","SUSTAINABILITY","","2071-1050","10.3390/su16156598","","In recent years, wastewater reuse has become crucial for addressing global freshwater scarcity and promoting sustainable water resource development. Accurate inflow volume predictions are essential for enhancing operational efficiency in water treatment facilities and effective wastewater utilization. Traditional and decomposition integration models often struggle with non-stationary time series, particularly in peak and anomaly sensitivity. To address this challenge, a differential decomposition integration model based on real-time rolling forecasts has been developed. This model uses an initial prediction with a machine learning (ML) model, followed by differential decomposition using Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN). A Time-Aware Outlier-Sensitive Transformer (TS-Transformer) is then applied for integrated predictions. The ML-CEEMDAN-TSTF model demonstrated superior accuracy compared to basic ML models, decomposition integration models, and other Transformer-based models. This hybrid model explicitly incorporates time-scale differentiated information as a feature, improving the model's adaptability to complex environmental data and predictive performance. The TS-Transformer was designed to make the model more sensitive to anomalies and peaks in time series, addressing issues such as anomalous data, uncertainty in water volume data, and suboptimal forecasting accuracy. The results indicated that: (1) the introduction of time-scale differentiated information significantly enhanced model accuracy; (2) ML-CEEMDAN-TSTF demonstrated higher accuracy compared to ML-CEEMDAN-Transformer; (3) the TS-Transformer-based decomposition integration model consistently outperformed those based on LSTM and eXtreme Gradient Boosting (XGBoost). Consequently, this research provides a precise and robust method for predicting reclaimed water volumes, which holds significant implications for research on clean water and water environment management.","2024-08","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","15","16","","","","","","","","","","English","","","","WOS:001287046600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","dynamic real-time forecasting; forecast decomposition and ensemble technique; machine learning; reclaimed water volumes; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ADTKTSEM","journalArticle","2024","Pan, K; Zhang, XG; Chen, LP","Research on the Training and Application Methods of a Lightweight Agricultural Domain-Specific Large Language Model Supporting Mandarin Chinese and Uyghur","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14135764","","In the field of Natural Language Processing (NLP), the lack of support for minority languages, especially Uyghur, the scarcity of Uyghur language corpora in the agricultural domain, and the lightweight nature of large language models remain prominent issues. This study proposes a method for constructing a bilingual (Uyghur and Chinese) lightweight specialized large language model for the agricultural domain. By utilizing a mixed training approach of Uyghur and Chinese, we extracted Chinese corpus text from agricultural-themed books in PDF format using OCR (Optical Character Recognition) technology, converted the Chinese text corpus into a Uyghur corpus using a rapid translation API, and constructed a bilingual mixed vocabulary. We applied the parameterized Transformer model algorithm to train the model for the agricultural domain in both Chinese and Uyghur. Furthermore, we introduced a context detection and fail-safe mechanism for the generated text. The constructed model possesses the ability to support bilingual reasoning in Uyghur and Chinese in the agricultural domain, with higher accuracy and a smaller size that requires less hardware. It (our work) addresses issues such as the scarcity of Uyghur corpora in the agricultural domain, mixed word segmentation and word vector modeling in Uyghur for widespread agricultural languages, model lightweighting and deployment, and the fragmentation of non-relevant texts during knowledge extraction from small-scale corpora. The lightweight design of the model reduces hardware requirements, facilitating deployment in resource-constrained environments. This advancement promotes agricultural intelligence, aids in the development of specific applications and minority languages (such as agriculture and Uyghur), and contributes to rural revitalization.","2024-07","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","13","14","","","","","","","","","","English","","","","WOS:001268266000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","agricultural expertise; Chinese-Uyghur bilingual; knowledge question answering service; large language model; lightweight; NETWORKS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q5SFKT2V","journalArticle","2024","Radman, A; Mohammadimanesh, F; Mahdianpari, M","Wet-ConViT: A Hybrid Convolutional-Transformer Model for Efficient Wetland Classification Using Satellite Data","REMOTE SENSING","","2072-4292","10.3390/rs16142673","","Accurate and efficient classification of wetlands, as one of the most valuable ecological resources, using satellite remote sensing data is essential for effective environmental monitoring and sustainable land management. Deep learning models have recently shown significant promise for identifying wetland land cover; however, they are mostly constrained in practical issues regarding efficiency while gaining high accuracy with limited training ground truth samples. To address these limitations, in this study, a novel deep learning model, namely Wet-ConViT, is designed for the precise mapping of wetlands using multi-source satellite data, combining the strengths of multispectral Sentinel-2 and SAR Sentinel-1 datasets. Both capturing local information of convolution and the long-range feature extraction capabilities of transformers are considered within the proposed architecture. Specifically, the key to Wet-ConViT's foundation is the multi-head convolutional attention (MHCA) module that integrates convolutional operations into a transformer attention mechanism. By leveraging convolutions, MHCA optimizes the efficiency of the original transformer self-attention mechanism. This resulted in high-precision land cover classification accuracy with a minimal computational complexity compared with other state-of-the-art models, including two convolutional neural networks (CNNs), two transformers, and two hybrid CNN-transformer models. In particular, Wet-ConViT demonstrated superior performance for classifying land cover with approximately 95% overall accuracy metrics, excelling the next best model, hybrid CoAtNet, by about 2%. The results highlighted the proposed architecture's high precision and efficiency in terms of parameters, memory usage, and processing time. Wet-ConViT could be useful for practical wetland mapping tasks, where precision and computational efficiency are paramount.","2024-07","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","14","16","","","","","","","","","","English","","","","WOS:001277740300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","BACKSCATTERING; convolutional neural network (CNN); POLARIZATION; SAR; sentinel imagery; transformer; wetland mapping","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UMCKDH6G","journalArticle","2024","Laitsos, V; Vontzos, G; Bargiotas, D; Daskalopulu, A; Tsoukalas, LH","Data-Driven Techniques for Short-Term Electricity Price Forecasting through Novel Deep Learning Approaches with Attention Mechanisms","ENERGIES","","1996-1073","10.3390/en17071625","","The electricity market is constantly evolving, being driven by factors such as market liberalization, the increasing use of renewable energy sources (RESs), and various economic and political influences. These dynamics make it challenging to predict wholesale electricity prices. Accurate short-term forecasting is crucial to maintaining system balance and addressing anomalies such as negative prices and deviations from predictions. This paper investigates short-term electricity price forecasting using historical time series data and employs advanced deep learning algorithms. First, four deep learning models are implemented and proposed, which are a convolutional neural network (CNN) with an integrated attention mechanism, a hybrid CNN followed by a gated recurrent unit model (CNN-GRU) with an attention mechanism, and two ensemble learning models, which are a soft voting ensemble and a stacking ensemble model. Also, the optimized version of a transformer model, the Multi-Head Attention model, is introduced. Finally, the perceptron model is used as a benchmark for comparison. Our results show excellent prediction accuracy, particularly in the hybrid CNN-GRU model with attention, thereby achieving a mean absolute percentage error (MAPE) of 6.333%. The soft voting ensemble model and the Multi-Head Attention model also performed well, with MAPEs of 6.125% and 6.889%, respectively. These findings are significant, as previous studies have not shown high performance with transformer models and attention mechanisms. The presented results offer promising insights for future research in this field.","2024-04","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","7","17","","","","","","","","","","English","","","","WOS:001201046900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","convolutional neural networks (CNN); data analysis; evaluation metrics; hybrid CNN-gated recurrent units with attention; load forecasting; long short-term memory; Multi-Head Attention; perceptron; power sector; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3LEIY4EI","journalArticle","2024","Fang, F; Liang, WY; Cheng, Y; Xu, QL; Lim, JH","Enhancing Representation Learning With Spatial Transformation and Early Convolution for Reinforcement Learning-Based Small Object Detection","IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY","","1051-8215","10.1109/TCSVT.2023.3284453","","Although object detection has achieved significant progress in the past decade, detecting small objects is still far from satisfactory due to the high variability of object scales and complex backgrounds. The common way to enhance small object detection is to use high-resolution (HR) images. However, this method incurs huge computational resources which grow squarely with the resolution of images. To achieve both accuracy and efficiency, we propose a novel reinforcement learning framework that employs an efficient policy network consisting of a Spatial Transformation Network to enhance the state representation learning and a Transformer model with early convolution to improve feature extraction. Our method has two main steps: (1) coarse location query (CLQ), where an RL agent is trained to predict the locations of small objects on low-resolution (LR) (down-sampled version of HR) images; (2) context-sensitive object detection where HR image patches are used to detect objects on the selected coarse locations and LR image patches on background areas (containing no small objects). In this way, we can obtain high detection performance on small objects while avoiding unnecessary computation on background areas. The proposed method has been tested and benchmarked on various datasets. On the Caltech Pedestrians Detection and Web Pedestrians datasets, the proposed method improves the detection accuracy by 2%, while reducing the number of processed pixels. On the Vision meets Drone object detection dataset and the Oil and Gas Storage Tank dataset, the proposed method outperforms the state-of-the-art (SotA) methods. On MS COCO mini-val set, our method outperforms SotA methods on small object detection, while also achieving comparable performance on medium and large objects.","2024-01","2025-02-26 20:43:29","2025-02-26 20:43:29","","315-328","","1","34","","","","","","","","","","English","","","","WOS:001138814400004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","coarse-to-fine framework; Costs; Detectors; Feature extraction; Object detection; Prediction algorithms; reinforcement learning; Small object detection; Training; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UAHM66ZI","journalArticle","2024","Li, XS; Luo, SL; Pan, LM; Wu, ZT","Adapt to small-scale and long-term time series forecasting with enhanced multidimensional correlation","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2023.122203","","Multivariate time series forecasting aims to predict time series data comprising several linked variables or characteristics and is frequently used in stock forecasting, energy forecasting, etc. The tough task is to acquire further historical data to forecast future values while boosting the capacity to mine relationships between and within sequences. The existing methods neglect the weighted influence of various neighbors and relationships on the sequence instance, as well as the semantic information of the instance itself, making the inter-instance correlation measure inaccurate. Meanwhile, the length of the sequence input is limited and the variable features in the multivariate sequence are treated equally, short-term and multi-feature interference cannot be eliminated, causing the learnt time series features to deviate from the real features. In this work, we provide a Multivariate Time Series Forecasting model that emphasizes Relationships between and within sequences (MTSFR). Use the BERT model to characterize the text attributes of instances and construct basic semantic embeddings. Meanwhile, instance-level and relation-level attention are used to model topological relations among different instances. Computes the cross-correlation of multivariate sequences within instances and performs attention weighting for multivariate sequence encoding. And choose the Transformer model to realize the trend prediction of long-term multivariate series. Experimental results show that the F1 value of our approach achieves 68.50% and 74.66% under the CSI300 and S&P500 data sets respectively, both of which are superior to the SOTA technique. Furthermore, the model is suited for small-scale sequence relationship modeling and is effective at handling long-term multivariate sequence forecasting problems.","2024-03-15","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","238","","","","","","","","","","English","","","","WOS:001098252100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","Cross-correlation; Graph neural network; Long time series; PREDICTION; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MNNV4U75","journalArticle","2023","Yang, DR; Lin, Y; Wei, JW; Lin, XW; Zhao, XB; Yao, YB; Tao, T; Liang, B; Lu, SG","Assisting Heart Valve Diseases Diagnosis via Transformer-Based Classification of Heart Sound Signals","ELECTRONICS","","2079-9292","10.3390/electronics12102221","","Background: In computer-aided medical diagnosis or prognosis, the automatic classification of heart valve diseases based on heart sound signals is of great importance since the heart sound signal contains a wealth of information that can reflect the heart status. Traditional binary classification algorithms (normal and abnormal) currently cannot comprehensively assess the heart valve diseases based on analyzing various heart sounds. The differences between heart sound signals are relatively subtle, but the reflected heart conditions differ significantly. Consequently, from a clinical point of view, it is of utmost importance to assist in the diagnosis of heart valve disease through the multiple classification of heart sound signals. Methods: We utilized a Transformer model for the multi-classification of heart sound signals. It has achieved results from four abnormal heart sound signals and the typical type. Results: According to 5-fold cross-validation strategy as well as 10-fold cross-validation strategy, e.g., in 5-fold cross-validation, the proposed method achieved a highest accuracy of 98.74% and a mean AUC of 0.99. Furthermore, the classification accuracy for Aortic Stenosis, Mitral Regurgitation, Mitral Stenosis, Mitral Valve Prolapse, and standard heart sound signals is 98.72%, 98.50%, 98.30%, 98.56%, and 99.61%, respectively. In 10-fold cross-validation, our model obtained the highest accuracy, sensitivity, specificity, precision, and F1 score all at 100%. Conclusion: The results indicate that the framework can precisely classify five classes of heart sound signals. Our method provides an effective tool for the ancillary detection of heart valve diseases in the clinical setting.","2023-05-13","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","10","12","","","","","","","","","","English","","","","WOS:000996670300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","attention mechanism; audio spectrogram; heart sound signal; multi-classification; NETWORK; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JKMH9IQ5","journalArticle","2023","Peng, LT; Zhu, CL; Bian, LH","U-Shape Transformer for Underwater Image Enhancement","IEEE TRANSACTIONS ON IMAGE PROCESSING","","1057-7149","10.1109/TIP.2023.3276332","","The light absorption and scattering of underwater impurities lead to poor underwater imaging quality. The existing data-driven based underwater image enhancement (UIE) techniques suffer from the lack of a large-scale dataset containing various underwater scenes and high-fidelity reference images. Besides, the inconsistent attenuation in different color channels and space areas is not fully considered for boosted enhancement. In this work, we built a large scale underwater image (LSUI) dataset, which covers more abundant underwater scenes and better visual quality reference images than existing underwater datasets. The dataset contains 4279 real-world underwater image groups, in which each raw image's clear reference images, semantic segmentation map and medium transmission map are paired correspondingly. We also reported an U-shape Transformer network where the transformer model is for the first time introduced to the UIE task. The U-shape Transformer is integrated with a channel-wise multi-scale feature fusion transformer (CMSFFT) module and a spatial-wise global feature modeling transformer (SGFMT) module specially designed for UIE task, which reinforce the network's attention to the color channels and space areas with more serious attenuation. Meanwhile, in order to further improve the contrast and saturation, a novel loss function combining RGB, LAB and LCH color spaces is designed following the human vision principle. The extensive experiments on available datasets validate the state-of-the-art performance of the reported technique with more than 2dB superiority. The dataset and demo code are available at https://bianlab.github.io/.","2023","2025-02-26 20:43:29","2025-02-26 20:43:29","","3066-3079","","","32","","","","","","","","","","English","","","","WOS:001001353000005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;205<br/>Total Times Cited:&nbsp;&nbsp;214<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","Attenuation; Circuit faults; Image color analysis; Imaging; multi-color space loss function; Task analysis; transformer; Transformers; underwater image dataset; Underwater image enhancement; Visualization; WATER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HCL27HXB","journalArticle","2025","Ranjbar, I; Ventikos, Y; Arashpour, M","Deep learning-based construction and demolition plastic waste classification by resin type using RGB images","RESOURCES CONSERVATION AND RECYCLING","","0921-3449","10.1016/j.resconrec.2024.107937","","The construction and demolition sector generates a substantial portion of Australia's total waste, with plastics being a key recyclable component. The perceived financial impracticality of sorting and separating waste, coupled with the simplicity of landfilling processes often contribute to mixed material loads sent directly to landfills. Therefore, developing a commercially feasible system that can accurately separate the generated waste is imperative. This paper presents a comprehensive study on using RGB images for deep learning-based construction and demolition plastic waste classification by resin type. A large and specialised dataset of end-of-life plastic waste images is gathered. This dataset comprises four commonly used plastic types in construction projects-ABS, HDPE, PS, and PVC. Leveraging Transfer Learning with models pre-trained on ImageNet, highly accurate models tailored to this classification task are developed in this paper. Advanced Convolutional Neural Network and Vision Transformer-based models, including ResNet, ResNeXt, RegNet, and Swin Transformer, are trained and evaluated on this dataset. Another contribution of this work is Knowledge Distillation from a large, computationally intensive, and accurate model to enhance the accuracy of fast and compact models specifically designed for deployment on edge devices. This study applies Knowledge Distillation by using the output class probabilities of the large, computationally intensive Swin Transformer model to enhance the accuracy of the fast and lightweight MobileNetV3 models. The results demonstrate that RGB images offer a practical alternative to other costly and complex systems for effective plastic identification, due to their availability, low cost, ease of use, simple setups, and robustness to variations in operational conditions.","2025-01","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","212","","","","","","","","","","English","","","","WOS:001333084700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","Deep learning; INDUCED BREAKDOWN SPECTROSCOPY; Knowledge distillation; Plastic waste classification; Polymer classification; Resin type; Transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XKUQ2H6N","journalArticle","2024","Sarhan, AM; Saif, D; Elshennawy, NM","A Manta-Ray Hill Climbing Vision Transformer Model for Predicting Ischemic Stroke Outcome","INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS","","1875-6891","10.1007/s44196-024-00438-3","","An ischemic stroke attack can cause permanent damage to healthy brain tissue, leading to a permanent loss of motor or sensory function. It can also result in disability or death if not diagnosed and treated promptly. Early prediction of the outcome of the first stroke, such as disability or death, can help many patients by administering appropriate medications to save their lives. Additionally, early prediction of a recurrent stroke within 14 days of the initial stroke can contribute to prevent its recurrence. This paper first proposes a modified Manta-Ray Foraging Optimizer (MMRFO) to enhance the characteristics of the MRFO technique. This approach is based on incorporating the Hill Climbing methodology into the original MRFO in order to improve the exploitation phase, which is responsible for locating the promising zone in the search area. The proposed approach is then utilized to determine the appropriate hyperparameters of the Vision Transformer(ViT) model to predict stroke outcomes prior to its occurrence. To transform categorical data to numerical values, an ASCII encoder module is included. In the feature selection step, the Harris Hawk Optimization approach (HHO) is used to identify the most important elements that may define the stroke. A comparative study has been performed to confirm the effectiveness of the proposed methodology. The results demonstrate that the proposed technique with a Vision Transformer achieves superior results compared to state-of-the-art algorithms. The accuracy of the proposed technique was improved to 87% for the first dataset and 83% for the second, which is clearly superior to that of the other models and earlier research.","2024-04-08","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","1","17","","","","","","","","","","English","","","","WOS:001198584000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Harris Hawk optimization; Hill-climbing algorithm; Manta-Ray foraging optimizer; RECURRENCE; RISK; SCORE; Stroke prediction; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G62Z7DCC","journalArticle","2024","Rauf, MA; Khalil, MMY; Wang, WD; Wang, QX; Ul Ghani, MAN; Hassan, J","BCE4ZSR: Bi-encoder empowered by teacher cross-encoder for zero-shot cold-start news recommendation","INFORMATION PROCESSING & MANAGEMENT","","0306-4573","10.1016/j.ipm.2024.103686","","In the realm of news recommendations, the persistent challenge of the cold -start problem continues to impede progress. Existing approaches rely heavily on information exchange between news articles and users to personalize news recommendations and have struggled to adapt to users and news articles without historical interaction data. In this paper, we introduce BCE4ZSR, a novel framework that leverages a rarely utilized zero -shot approach to effectively tackle the cold -start problem in news recommendations. The proposed approach consists of two main steps: First, we generate embeddings for inference with a sentence transformer (a bi-encoder). In the second step, a fine-tuned transformer model is augmented during the training phase to distil the bi-encoder with knowledge from the cross -encoder model using a student-teacher framework. As a result of this synergy, the cross -encoder serves as a teacher, imparting its knowledge to the bi-encoder. The proposed technique can be applied to any neural news recommender system and is empirically evaluated in both cold -start and regular usernews interaction situations. Experiments on real -world benchmark datasets (MIND -small and MIND -large) indicated that BCE4ZSR outperformed the baseline methods in terms of nDCG@k, AUC, and MRR. Specifically, AUC improvement of 1.5%-6% & 2.2%-7.93%; MRR improved by 1%-13.85% & 0.9%-14.72%; nDCG@5 improved by 4.9%-18.79% & 2.1%-16.44%; and nDCG@10 improved by 1.7%-15.18% & 1.9%-14.24% in the cold start and warm user scenarios respectively, proving the superiority of our model compared to baseline methods.","2024-05","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","3","61","","","","","","","","","","English","","","","WOS:001198896400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Bi-encoders; Cold-start problem; Cross-encoder; News recommendation; Zero-shot learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GU4RDH2B","journalArticle","2023","Gao, YP; Gao, L; Li, XY","A Two-Stage Focal Transformer for Human-Robot Collaboration-Based Surface Defect Inspection","JOURNAL OF MANUFACTURING SCIENCE AND ENGINEERING-TRANSACTIONS OF THE ASME","","1087-1357","10.1115/1.4062860","","Human-robot collaboration has become a hotspot in smart manufacturing, and it also has shown the potential for surface defect inspection. The robot can release workload, while human collaboration can help to recheck the uncertain defects. However, the human-robot collaboration-based defect inspection can be hardly realized unless some bottlenecks have been solved, and one of them is that the current methods cannot decide which samples to be rechecked, and the workers can only recheck all of the samples to improve inspection results. To overcome this problem and realize the human-robot collaboration-based surface defect inspection, a two-stage Transformer model with focal loss is proposed. The proposed method divides the traditional inspection process into detection and recognition, designs a collaboration rule to allow workers to collaborate and recheck the defects, and introduces the focal loss into the model to improve the recognition results. With these improvements, the proposed method can collaborate with workers by rechecking the defects and improve surface quality. The experimental results on the public dataset have shown the effectiveness of the proposed method, the accuracies are significantly improved by the human collaboration, which are 1.70%similar to 4.18%. Moreover, the proposed method has been implemented into a human-robot collaboration-based prototype to inspect the carton surface defects, and the results also verify the effectiveness. Meanwhile, the proposed method has a good ability for visualization to find the defect area, and it is also conducive to defect analysis and rechecking.","2023-12-01","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","12","145","","","","","","","","","","English","","","","WOS:001096188900005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","CLASSIFICATION; computer-integrated manufacturing; control and automation; defect rechecking; focal loss; human-robot collaboration; inspection and quality control; NEURAL-NETWORK; PATTERNS; RECOGNITION; surface defect recognition; SYSTEM; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TKV54FL8","journalArticle","2022","Basak, S; Corcoran, P; McDonnell, R; Schukat, M","3D face-model reconstruction from a single image: A feature aggregation approach using hierarchical transformer with weak supervision","NEURAL NETWORKS","","0893-6080","10.1016/j.neunet.2022.09.019","","Convolutional Neural Networks (CNN) have gained popularity as the de-facto model for any computer vision task. However, CNN have drawbacks, i.e. they fail to extract long-range perceptions in images. Due to their ability to capture long-range dependencies, transformer networks are adopted in computer vision applications, where they show state-of-the-art (SOTA) results in popular tasks like image classification, instance segmentation, and object detection. Although they gained ample attention, transformers have not been applied to 3D face reconstruction tasks. In this work, we propose a novel hierarchical transformer model, added to a feature pyramid aggregation structure, to extract the 3D face parameters from a single 2D image. More specifically, we use pre-trained Swin Transformer backbone networks in a hierarchical manner and add the feature fusion module to aggregate the features in multiple stages. We use a semi-supervised training approach and train our model in a supervised way with the 3DMM parameters from a publicly available dataset and unsupervised training with a differential renderer on other parameters like facial keypoints and facial features. We also train our network on a hybrid unsupervised loss and compare the results with other SOTA approaches. When evaluated across two public datasets on face reconstruction and dense 3D face alignment tasks, our method can achieve comparable results to the current SOTA performance and in some instances do better than the SOTA methods. A detailed subjective evaluation also shows that our method performs better than the previous works in realism and occlusion resistance.(c) 2022 Elsevier Ltd. All rights reserved.","2022-12","2025-02-26 20:43:29","2025-02-26 20:43:29","","108-122","","","156","","","","","","","","","","English","","","","WOS:000874642000010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","ALIGNMENT; Face reconstruction; Feature fusion; Hierarchical transformer; Swin Transformer; ViT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UEHVFDWN","journalArticle","2022","Li, XJ","Adoption of Wireless Network and Artificial Intelligence Algorithm in Chinese-English Tense Translation","COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE","","1687-5265","10.1155/2022/1662311","","In order to solve the problem of tense consistency in Chinese-English neural machine translation (NMT) system, a Chinese verb tense annotation model is proposed. Firstly, a neural network is used to build a Chinese tense annotation model. During the translation process, the source tense is passed to the target side through the alignment matrix of the traditional Attention mechanism. The probability of the candidate words inconsistent with the corresponding tense of source words in the candidate translation word set is also reduced. Then, the Chinese-English temporal annotation algorithm is integrated into the MT model, so as to build a Chinese-English translation system with temporal processing function. The essence of the system is that, in the process of translation, Chinese-English temporal annotation algorithm is used to obtain temporal information from Chinese sentences and transfer it to the corresponding English sentences, so as to realize the temporal processing of English sentences and obtain the English sentences corresponding to the tenses of the original Chinese sentences. The experimental results show that the Chinese tense annotation model of bidirectional long short-term memory (LSTM) is more accurate for the prediction of Chinese verb tense, so the improvement effect of NMT model is also the most obvious, especially on the NIST06 test set, where the BLEU value is increased by 1.07%. As the mainstream translation model, the transformer model contains multihead Attention mechanism, which can pay attention to some temporal information and has a certain processing ability for temporal translation. It solves the tense problems encountered in the process of MT and improves the credibility of Chinese-English machine translation (MT).","2022-06-11","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","2022","","","","","","","","","","English","","","","WOS:000815038300009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","RECOVERY; SPEED","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PXVEVR87","journalArticle","2021","Sirrianni, JW; Liu, XQ; Adams, D","Predicting Stance Polarity and Intensity in Cyber Argumentation With Deep Bidirectional Transformers","IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS","","2329-924X","10.1109/TCSS.2021.3056596","","In online deliberation, participants argue in support or opposition to one another's arguments and ideas to advocate their position. Often their stance expressed in their posts is implicit and must be derived from the post's text. Existing stance detection models predict the polarity of the user's stance from the text, but do not consider the stance's intensity. We introduce a new research problem, stance polarity, and intensity prediction in response relationships between posts. This problem seeks to predict both the stance polarity and intensity of a replying post toward its parent post in online deliberation. Using our cyber argumentation platform, we have collected an empirical data set with explicitly labeled stance polarity and intensity relationships. In this work, we create six models: five are adapted from top-performing stance detection models and another novel model that fine-tunes the deep bidirectional transformer model BERT. We train and test these six models on our empirical data set to compare their performance for stance polarity and intensity prediction and stance detection. Our results demonstrate that our method of encoding the stance polarity and intensity labels allows the models to predict stance polarity and intensity without compromising their accuracy for stance detection, making these models more versatile. Our results reveal that a novel split architecture for fine-tuning the BERT model outperforms the other models for stance polarity and intensity prediction by 5% accuracy. This work is the first to train models for predicting both the stance polarity and intensity in one combined task while maintaining good accuracy.","2021-06","2025-02-26 20:43:29","2025-02-26 20:43:29","","655-667","","3","8","","","","","","","","","","English","","","","WOS:000655822700012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","Adaptation models; Bit error rate; Cyber argumentation; Data models; Encoding; MODEL; Predictive models; Social networking (online); stance detection; stance prediction; Task analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HLGGKQ28","journalArticle","2025","Ayana, G; Dese, K; Nemomssa, HD; Murad, H; Wakjira, E; Demlew, G; Yohannes, D; Abdi, KL; Taye, E; Bisrat, F; Tadesse, T; Kidanne, L; Choe, SW; Gidi, NW; Habtamu, B; Kong, JD","Deep learning model meets community-based surveillance of acute flaccid paralysis","INFECTIOUS DISEASE MODELLING","","2468-0427","10.1016/j.idm.2024.12.002","","Acute flaccid paralysis (AFP) case surveillance is pivotal for the early detection of potential poliovirus, particularly in endemic countries such as Ethiopia. The community-based surveillance system implemented in Ethiopia has significantly improved AFP surveillance. However, challenges like delayed detection and disorganized communication persist. This work proposes a simple deep learning model for AFP surveillance, leveraging transfer learning on images collected from Ethiopia's community key informants through mobile phones. The transfer learning approach is implemented using a vision transformer model pretrained on the ImageNet dataset. The proposed model outperformed convolutional neural network-based deep learning models and vision transformer models trained from scratch, achieving superior accuracy, F1-score, precision, recall, and area under the receiver operating characteristic curve (AUC). It emerged as the optimal model, demonstrating the highest average AUC of 0.870 +/- 0.01. Statistical analysis confirmed the significant superiority of the proposed model over alternative approaches (P < 0.001). By bridging community reporting with health system response, this study offers a scalable solution for enhancing AFP surveillance in low-resource settings. The study is limited in terms of the quality of image data collected, necessitating future work on improving data quality. The establishment of a dedicated platform that facilitates data storage, analysis, and future learning can strengthen data quality. Nonetheless, this work represents a significant step toward leveraging artificial intelligence for community-based AFP surveillance from images, with substantial implications for addressing global health challenges and disease eradication strategies.<br /> (c) 2024 The Authors. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).","2025-03","2025-02-26 20:43:29","2025-02-26 20:43:29","","353-364","","1","10","","","","","","","","","","English","","","","WOS:001380121000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Acute flaccid paralysis; Community; Computer vision; Deep learning model; ETHIOPIA; GROUP POLIO PROJECT; Surveillance; Transfer learning; VOLUNTEERS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XXS9398C","journalArticle","2025","Zhao, JY; Han, XB; Wu, YY; Wang, ZH; Burke, AF","Opportunities and challenges in transformer neural networks for battery state estimation: Charge, health, lifetime, and safety","JOURNAL OF ENERGY CHEMISTRY","","2095-4956","10.1016/j.jechem.2024.11.011","","Battery technology plays a crucial role across various sectors, powering devices from smartphones to electric vehicles and supporting grid-scale energy storage. To ensure their safety and efficiency, batteries must be evaluated under diverse operating conditions. Traditional modeling techniques, which often rely on first principles and atomic-level calculations, struggle with practical applications due to incomplete or noisy data. Furthermore, the complexity of battery dynamics, shaped by physical, chemical, and electrochemical interactions, presents substantial challenges for precise and efficient modeling. The Transformer model, originally designed for natural language processing, has proven effective in time-series analysis and forecasting. It adeptly handles the extensive, complex datasets produced during battery cycles, efficiently filtering out noise and identifying critical features without extensive preprocessing. This capability positions Transformers as potent tools for tackling the intricacies of battery data. This review explores the application of customized Transformers in battery state estimation, emphasizing crucial aspects such as charging, health assessment, lifetime prediction, and safety monitoring. It highlights the distinct advantages of Transformer-based models and addresses ongoing challenges and future opportunities in the field. By combining data-driven AI techniques with empirical insights from battery analysis, these pre-trained models can deliver precise diagnostics and comprehensive monitoring, enhancing performance metrics like health monitoring, anomaly detection, and early-warning systems. This integrated approach promises significant improvements in battery technology management and application. (c) 2024 Science Press and Dalian Institute of Chemical Physics, Chinese Academy of Sciences. Published by Elsevier B.V. and Science Press. All rights are reserved, including those for text and data mining, AI training, and similar technologies.","2025-03","2025-02-26 20:43:29","2025-02-26 20:43:29","","463-496","","","102","","","","","","","","","","English","","","","WOS:001377317000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;246</p>","","","Artificial general intelligence; Battery; DATA-DRIVEN; Deep learning; DEEP LEARNING APPROACH; DEGRADATION; DIAGNOSIS; ELECTRIC VEHICLES; ELECTROLYTE; Health; Lifetime; LITHIUM-ION BATTERIES; MODEL; PREDICTION; RUL; Safety; SOC; SOH; SYSTEM; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M363TVNG","journalArticle","2024","Saleem, U; Liu, WJ; Riaz, S; Li, WL; Hussain, GA; Rashid, Z; Arfeen, ZA","TransRUL: A Transformer-Based Multihead Attention Model for Enhanced Prediction of Battery Remaining Useful Life","ENERGIES","","1996-1073","10.3390/en17163976","","The efficient operation of power-electronic-based systems heavily relies on the reliability and longevity of battery-powered systems. An accurate prediction of the remaining useful life (RUL) of batteries is essential for their effective maintenance, reliability, and safety. However, traditional RUL prediction methods and deep learning-based approaches face challenges in managing battery degradation processes, such as achieving robust prediction performance, to ensure scalability and computational efficiency. There is a need to develop adaptable models that can generalize across different battery types that operate in diverse operational environments. To solve these issues, this research work proposes a TransRUL model to enhance battery RUL prediction. The proposed model incorporates advanced approaches of a time series transformer using a dual encoder with integration positional encoding and multi-head attention. This research utilized data collected by the Centre for Advanced Life Cycle Engineering (CALCE) on CS_2-type lithium-ion batteries that spanned four groups that used a sliding window technique to generate features and labels. The experimental results demonstrate that TransRUL obtained superior performance as compared with other methods in terms of the following evaluation metrics: mean absolute error (MAE), root-mean-squared error (RMSE), and R2 values. The efficient computational power of the TransRUL model will facilitate the real-time prediction of the RUL, which is vital for power-electronic-based appliances. This research highlights the potential of the TransRUL model, which significantly enhances the accuracy of battery RUL prediction and additionally improves the management and control of battery-based systems.","2024-08","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","16","17","","","","","","","","","","English","","","","WOS:001305771900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","CALCE data; LITHIUM; lithium-ion battery; multi-head attention; NEURAL-NETWORK; reliability; remaining useful life; safety; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BWKC38MM","journalArticle","2024","Lu, DY; Li, J; Zheng, CH; Liu, JX; Zhang, Q","HGTMDA: A Hypergraph Learning Approach with Improved GCN-Transformer for miRNA-Disease Association Prediction","BIOENGINEERING-BASEL","","2306-5354","10.3390/bioengineering11070680","","Accumulating scientific evidence highlights the pivotal role of miRNA-disease association research in elucidating disease pathogenesis and developing innovative diagnostics. Consequently, accurately identifying disease-associated miRNAs has emerged as a prominent research topic in bioinformatics. Advances in graph neural networks (GNNs) have catalyzed methodological breakthroughs in this field. However, existing methods are often plagued by data noise and struggle to effectively integrate local and global information, which hinders their predictive performance. To address this, we introduce HGTMDA, an innovative hypergraph learning framework that incorporates random walk with restart-based association masking and an enhanced GCN-Transformer model to infer miRNA-disease associations. HGTMDA starts by constructing multiple homogeneous similarity networks. A novel enhancement of our approach is the introduction of a restart-based random walk association masking strategy. By stochastically masking a subset of association data and integrating it with a GCN enhanced by an attention mechanism, this strategy enables better capture of key information, leading to improved information utilization and reduced impact of noisy data. Next, we build an miRNA-disease heterogeneous hypergraph and adopt an improved GCN-Transformer encoder to effectively solve the effective extraction of local and global information. Lastly, we utilize a combined Dice cross-entropy (DCE) loss function to guide the model training and optimize its performance. To evaluate the performance of HGTMDA, comprehensive comparisons were conducted with state-of-the-art methods. Additionally, in-depth case studies on lung cancer and colorectal cancer were performed. The results demonstrate HGTMDA's outstanding performance across various metrics and its exceptional effectiveness in real-world application scenarios, highlighting the advantages and value of this method.","2024-07","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","7","11","","","","","","","","","","English","","","","WOS:001276732700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","GCN-Transformer; hypergraph learning; miRNA-disease association; random walk with restart","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VMF2Q6EB","journalArticle","2024","Lang, XM; Wang, CY","Leakage detection of an acoustic emission pipeline based on an improved transformer network","ENGINEERING RESEARCH EXPRESS","","2631-8695","10.1088/2631-8695/ad4cb2","","Pipeline leakage detection is an integral part of pipeline integrity management. Combining AE (Acoustic Emission) with deep learning is currently the most commonly used method for pipeline leakage detection. However, this approach is usually applicable only to specific situations and requires powerful signal analysis and computational capabilities. To address these issues, this paper proposes an improved Transformer network model for diagnosing faults associated with abnormal working conditions in acoustic emission pipelines. First, the method utilizes the temporal properties of the GRU and the positional coding of the Transformer to capture and feature extract the data point sequence position information to suppress redundant information, and introduces the largest pooling layer into the Transformer model to alleviate the overfitting phenomenon. Second, while retaining the original attention learning mechanism and identity path in the original DRSN, a new soft threshold function is introduced to replace the ReLU activation function with a new threshold function, and a new soft threshold module and adaptive slope module are designed to construct the improved residual shrinkage unit (ASB-STRSBU), which is used to adaptively set the optimal threshold. Finally, pipeline leakage is classified. The experimental results show that the NDRSN model is able to make full use of global and local information when considering leakage signals and can automatically learn and acquire the important parameters of the input features in the spatial and channel domains. By optimizing the GRU improved Transformer network recognition model, the method significantly reduces the model training time and computational resource consumption while maintaining high leakage recognition accuracy. The average accuracy reached 93.97%. This indicates that the method has good robustness in acoustic emission pipeline leakage detection.","2024-06-01","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","2","6","","","","","","","","","","English","","","","WOS:001230727100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","acoustic emission; deep residual shrinkage network; fault diagnosis; GRU; LSTM; MODEL; pipeline leakage; RECOGNITION; transformer network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"28J9SKB9","journalArticle","2024","Peng, X; Chen, ZX; Zhang, JL; Li, Z; Du, WL","A truncated Gaussian distribution based multi-scale segment-wise fusion transformer model for multi-step commodity price forecasting","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2024.108434","","Accurately forecasting commodity price trends is crucial for producers, market participants, and related enterprises to make informed decisions regarding production planning and scheduling. However, achieving high accuracy in multi -step forecasting poses significant challenges due to the unique financial characteristics inherent in commodities. Thus, this paper proposes a novel truncated Gaussian distribution based multi -scale segment -wise fusion Transformer for multi -step commodity price forecasting. First, a multi -scale segment -wise fusion module, which capture the time dependencies from different time granularity, is designed to describe the time -varying trend characteristics of commodity prices. Second, considering the characteristics of price range fluctuation and truncation, a truncated Gaussian distribution is introduced to describe price uncertainty. Last, to evaluate the proposed method's effectiveness, extensive experiments are conducted using real data on energy chemical product prices. The experimental results demonstrate that the proposed method accurately captures price change trends and effectively estimates price uncertainty. Compared to the widely adopted Autoformer, our approach achieves approximately 30% reductions in both root mean square error (RMSE) and mean absolute error (MAE) metrics. Additionally, it exhibits certain advantages over the current state-ofthe-art (SOTA). In the 20 -step and 60 -step multi -step prediction tasks, the proposed method achieves RMSE values of 91.18 and 142.94, respectively, surpassing the current SOTA. The introduced research framework provides valuable insights for decision -makers engaged in analyzing and forecasting commodity markets. The code is available on https://github.com/dean-ob/TGD-MSSF.","2024-07","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","133","","","","","","","","","","English","","","","WOS:001218760200002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Commodity price forecasting; HYBRID; Multi-step prediction; ONE-STEP; Price uncertainty estimation; Time-varying trend characteristics; Truncated Gaussian distribution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P8FXZGAY","journalArticle","2024","Chai, ZQ; Liu, MX; Shi, Q; Zhang, YY; Zuo, ML; He, D","Fine-Grained Urban Village Extraction by Mask Transformer From High-Resolution Satellite Images in Pearl River Delta","IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING","","1939-1404","10.1109/JSTARS.2024.3434487","","Urban renewal has led to the proliferation of informal urban habitats, such as slums, shanty towns, and urban villages (UVs). As an important component of urban renewal, UVs influence urban spatial structure and land use patterns. Therefore, the fine extraction of UV is of great theoretical and practical significance. Existing UV classification techniques mostly employ machine learning and convolutional neural network based models, which struggle to perceive long-range global semantic information. In this article, based on high-resolution remote sensing images, we propose a multiscale mask transformer model for UV (MaskUV). It can extract both local texture features and global features. The multiscale mask transformer module with mask attention can aggregate different levels of pixel and object features, enhancing the model's recognition and generalization abilities. We extracted UV in seven cities in the Pearl River Delta (PRD) using MaskUV and analyzed the spatial pattern and accessibility of UV. Due to the scarcity of fine-grained UV detection datasets, we also provide a novel dataset (UVSet) containing 3415 pairs of 512 x 512 high-resolution UV images and labels, with a spatial resolution of 1 m. Comparative experiments with several UV extraction models demonstrate the effectiveness of MaskUV, achieving an F1 score of 84.39% and an IoU of 73.00% on UVSet. Besides, MaskUV achieves highly accurate detection results in seven cities in the PRD, with average F1 and IoU values of 84.41% and 72.44%, respectively.","2024","2025-02-26 20:43:29","2025-02-26 20:43:29","","13657-13668","","","17","","","","","","","","","","English","","","","WOS:001290233800018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","Buildings; CHINA; Deep learning; DYNAMICS; Feature extraction; INFORMAL SETTLEMENTS; MIGRATION; NETWORK; Pearl River Delta (PRD); remote sensing; Remote sensing; Rivers; SEMANTIC SEGMENTATION; Training; Transformers; Urban areas; urban villages (UVs); urbanization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AXSJJUDH","journalArticle","2024","Zhang, Y; Wang, M; He, JL; Li, NT; Zhou, YP; Huang, HX; Cai, DB; Yin, MH","AestheNet: Revolutionizing Aesthetic Perception Diagnosis in Education With Hybrid Deep Nets","IEEE TRANSACTIONS ON LEARNING TECHNOLOGIES","","1939-1382","10.1109/TLT.2024.3405966","","Diagnosing aesthetic perception plays a crucial role in deepening our understanding of student creativity, emotional expression, and the pursuit of lifelong learning within art education. This task encompasses the evaluation and analysis of students' sensitivity, preference, and capacity to perceive and appreciate beauty across different sensory domains. Currently, this assessment frequently relies on subjective evaluations of student artworks. There are two limitations: 1) the diagnosis is possibly limited by instructors' bias and 2) the heavy workload of instructors for conducting comprehensive assessments. These limitations motivate us to ask: Can we automatically and objectively conduct aesthetic perception diagnosis? To this end, we propose an innovative deep hybrid framework, AestheNet, to automatically evaluate aesthetic perception by analyzing numerous collected student paintings. More especially, we first utilize convolutional neural networks to extract the significant features from the student artworks. Then, we employ the transformer model to capture the intricate relationships among multiple aesthetic perception dimensions for objective diagnosis. Finally, we validate the effectiveness of the framework by creating a new dataset consisting of 2153 paintings drawn by 675 students. These paintings are annotated by human experts from 77 dimensions based on domain expertise. Extensive experiments have shown the effectiveness of AestheNet in aesthetic perception diagnosis. AestheNet is dedicated to overcoming the subjectivity inherent in traditional assessment methods, providing a new, quantifiable, and standardized way to evaluate aesthetic perception. This research not only opens up new perspectives in understanding students' aesthetic development during the art education process but also explores the innovation of using artificial intelligence technologies in the assessment of art education.","2024","2025-02-26 20:43:29","2025-02-26 20:43:29","","2117-2129","","","17","","","","","","","","","","English","","","","WOS:001329034500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;104</p>","","","Aesthetic perception diagnosis; Art; CHILDREN; CLASSIFICATION; convolutional neural network (CNN); CONVOLUTIONAL NEURAL-NETWORKS; Creativity; deep learning; Deep learning; DRAWING PERFORMANCE; Education; lifelong learning; NEUROSCIENCE; Painting; transformer; Transformers; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4QVXKV9J","journalArticle","2024","Mohammed, AAQ; Geng, X; Wang, J; Ali, Z","Driver distraction detection using semi-supervised lightweight vision transformer","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2023.107618","","The continuously increasing number of traffic accidents necessitates addressing distracted driving, which is responsible for numerous fatalities. Enhancing driver behavior recognition, particularly through developing a highly reliable Advanced Driver Assistance System (ADAS), holds substantial potential for cultivating safer transportation systems. Inspired by the success of Convolutional Neural Networks (CNNs), various networks have been proposed to enhance the detection accuracy of distracting behaviors. However, existing models have too many parameters and rely heavily on extensive labeled data, leading to time-consuming labeling and large models. To address these limitations, we propose a distracted behavior detection method based on a lightweight vision transformer trained using pseudo-label-based semi-supervised learning to learn discriminative representations from labeled and unlabeled data while ensuring a small model and speedy inference. Specifically, we create strong and weak augmented versions of the input minibatch and employ a hybrid lightweight transformer model in a teacher-student network. Pseudo-labels are generated from the teacher's predictions on weakly augmented data. The student model aligns with these labels on strongly augmented input, with teacher parameters evolving through exponential moving average. Our method presents a real-time, accurate solution for distracted driver detection, with the potential to significantly enhance road safety by reducing accidents. The effectiveness of the proposed approach is demonstrated through a comparative evaluation against alternative fully-supervised and semi-supervised methods. Furthermore, our method is evaluated in naturalistic driving settings with varying lighting and complex backgrounds. Experiments conducted on two publicly available driver distraction detection datasets show that our method outperforms current state-of-the-art approaches.","2024-03","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","129","","","","","","","","","","English","","","","WOS:001141198700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;80</p>","","","Deep learning; Driver behaviors; Driver distraction detection; Lightweight transformer; RECOGNITION; Semi -supervised learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YUJ4I7X7","journalArticle","2023","Patra, BG; Sun, ZY; Cheng, ZL; Kumar, PKRJ; Altammami, A; Liu, YY; Joly, R; Jedlicka, C; Delgado, D; Pathak, J; Peng, YF; Zhang, YY","Automated classification of lay health articles using natural language processing: a case study on pregnancy health and postpartum depression","FRONTIERS IN PSYCHIATRY","","1664-0640","10.3389/fpsyt.2023.1258887","","ObjectiveEvidence suggests that high-quality health education and effective communication within the framework of social support hold significant potential in preventing postpartum depression. Yet, developing trustworthy and engaging health education and communication materials requires extensive expertise and substantial resources. In light of this, we propose an innovative approach that involves leveraging natural language processing (NLP) to classify publicly accessible lay articles based on their relevance and subject matter to pregnancy and mental health.Materials and methodsWe manually reviewed online lay articles from credible and medically validated sources to create a gold standard corpus. This manual review process categorized the articles based on their pertinence to pregnancy and related subtopics. To streamline and expand the classification procedure for relevance and topics, we employed advanced NLP models such as Random Forest, Bidirectional Encoder Representations from Transformers (BERT), and Generative Pre-trained Transformer model (gpt-3.5-turbo).ResultsThe gold standard corpus included 392 pregnancy-related articles. Our manual review process categorized the reading materials according to lifestyle factors associated with postpartum depression: diet, exercise, mental health, and health literacy. A BERT-based model performed best (F1 = 0.974) in an end-to-end classification of relevance and topics. In a two-step approach, given articles already classified as pregnancy-related, gpt-3.5-turbo performed best (F1 = 0.972) in classifying the above topics.DiscussionUtilizing NLP, we can guide patients to high-quality lay reading materials as cost-effective, readily available health education and communication sources. This approach allows us to scale the information delivery specifically to individuals, enhancing the relevance and impact of the materials provided.","2023-11-20","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","14","","","","","","","","","","English","","","","WOS:001121049200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","health communication; INTERNET; natural language processing; online health information; postpartum depression; pregnancy; STRESS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q8ZIRB3Q","journalArticle","2023","Khan, AR; Reinders, MJT; Khatri, I","Determining epitope specificity of T-cell receptors with transformers","BIOINFORMATICS","","1367-4803","10.1093/bioinformatics/btad632","","T-cell receptors (TCRs) on T cells recognize and bind to epitopes presented by the major histocompatibility complex in case of an infection or cancer. However, the high diversity of TCRs, as well as their unique and complex binding mechanisms underlying epitope recognition, make it difficult to predict the binding between TCRs and epitopes. Here, we present the utility of transformers, a deep learning strategy that incorporates an attention mechanism that learns the informative features, and show that these models pre-trained on a large set of protein sequences outperform current strategies. We compared three pre-trained auto-encoder transformer models (ProtBERT, ProtAlbert, and ProtElectra) and one pre-trained auto-regressive transformer model (ProtXLNet) to predict the binding specificity of TCRs to 25 epitopes from the VDJdb database (human and murine). Two additional modifications were performed to incorporate gene usage of the TCRs in the four transformer models. Of all 12 transformer implementations (four models with three different modifications), a modified version of the ProtXLNet model could predict TCR-epitope pairs with the highest accuracy (weighted F1 score 0.55 simultaneously considering all 25 epitopes). The modification included additional features representing the gene names for the TCRs. We also showed that the basic implementation of transformers outperformed the previously available methods, i.e. TCRGP, TCRdist, and DeepTCR, developed for the same biological problem, especially for the hard-to-classify labels. We show that the proficiency of transformers in attention learning can be made operational in a complex biological setting like TCR binding prediction. Further ingenuity in utilizing the full potential of transformers, either through attention head visualization or introducing additional features, can extend T-cell research avenues. Availability and implementation: Data and code are available on https://github.com/InduKhatri/tcrformer.","2023-11-01","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","11","39","","","","","","","","","","English","","","","WOS:001188936500002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"432NF6HQ","journalArticle","2023","Che, SQ; Lu, JF; Bao, CW; Zhang, CH; Liu, YZ","Multiscale Time-Frequency Sparse Transformer Based on Partly Interpretable Method for Bearing Fault Diagnosis","SHOCK AND VIBRATION","","1070-9622","10.1155/2023/1639287","","Transformer model is being gradually studied and applied in bearing fault diagnosis tasks, which can overcome the feature extraction defects caused by long-term dependencies in convolution neural network (CNN) and recurrent neural network (RNN). To optimize the structure of existing transformer-like methods and improve the diagnostic accuracy, we proposed a novel method based on the multiscale time-frequency sparse transformer (MTFST) in this paper. First, a novel tokenizer based on shot-time Fourier transform (STFT) is designed, which processes the 1D format raw signals into 2D format discrete time-frequency sequences in the embedding space. Second, a sparse self-attention mechanism is designed to eliminate the feature mapping defect in naive self-attention mechanism. Then, the novel encoder-decoder structure is presented, the multiple encoders are employed to extract the hidden feature of different time-frequency sequences obtained by STFT with different window widths, and the decoder is used to remap the deep information and connect to the classifier for discriminating fault types. The proposed method is tested in the XJTU-SY bearing dataset and self-made experiment rig dataset, and the following work is conducted. The influences of hyperparameters on diagnosis accuracy and number of parameters are analysed in detail. The weights of the attention mechanism (AM) are visualized and analysed to study the interpretability, which explains the partly working pattern of the network. In the comparison test with other existing CNN, RNN, and transformer models, the diagnosis accuracy of different methods is statistically analysed, feature vectors are presented via the t-distributed stochastic neighbor embedding (t-SNE) method, and the proposed MTFST obtains the best accuracy and feature distribution form. The results demonstrate the effectiveness and superiority of the proposed method in bearing fault diagnosis.","2023-08-04","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","2023","","","","","","","","","","English","","","","WOS:001046990600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","CONVOLUTIONAL NEURAL-NETWORK; ROTATING MACHINERY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3ERWA3LK","journalArticle","2023","Chen, YW; Yang, XZ; Liu, XA; Han, XS; Zhang, J","Non-invasive triglyceride detection: Using a combination of complementary multivariate photoplethysmogram features","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2023.104662","","Objective: Long-term monitoring and effective management of triglycerides (TG) are crucial to reducing morbidity in patients with cardiovascular diseases. However, frequent invasive TG detection increases patient inconvenience and discomfort. Many efforts have been made to estimate TG based on photoplethysmogram (PPG), but current studies dissatisfy the practical application due to unclear quantitative relationship between PPG features and TG. This study investigated a framework for non-invasive TG detection based on finger PPG signals to quantify the contribution of PPG features to TG estimation. Methods: 58 features for TG detection are extracted from the PPG of 133 cardiovascular patients. The relationship between PPG features and TG is analyzed for quantitative purposes, and the pathological significance of features is further combined to remove irrelevant ones. To improve the accuracy of TG estimation, a complementary feature selection method is proposed that uses the complementary coefficient and feature stability as evaluation indicators to select the optimal feature combination from the mixed features. Finally, the Transformer algorithm strengthens the link between complementary features for TG estimation. Results: Our results demonstrated that many PPG features are moderately correlated with TG, and feature K shows the highest correlation score (r = 0.48). When using a subset of 6 selected PPG features, the performance of TG estimation based on complementary features is significantly better than that using normal mixed features, which combined with the Transformer model reduced MAE and SDE to 0.37 mmol/L and 5.26 mmol/L, respectively, and increased PCC to 0.86. Conclusion: The proposed PPG-based TG detection method clarifies the quantitative relationship between PPG features and TG and provides a new idea for non-invasive TG detection.","2023-05","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","83","","","","","","","","","","English","","","","WOS:000942827400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Complementary features selection; DYSLIPIDEMIA; Features extraction; PULSE; SIGNAL; SYSTEM; TG estimation; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D3AHFUZ3","journalArticle","2022","Mai, DHA; Nguyen, LT; Lee, EY","TSSNote-CyaPromBERT: Development of an integrated platform for highly accurate promoter prediction and visualization of Synechococcus sp. and Synechocystis sp. through a state-of-the-art natural language processing model BERT","FRONTIERS IN GENETICS","","1664-8021","10.3389/fgene.2022.1067562","","Since the introduction of the first transformer model with a unique self-attention mechanism, natural language processing (NLP) models have attained state-of-the-art (SOTA) performance on various tasks. As DNA is the blueprint of life, it can be viewed as an unusual language, with its characteristic lexicon and grammar. Therefore, NLP models may provide insights into the meaning of the sequential structure of DNA. In the current study, we employed and compared the performance of popular SOTA NLP models (i.e., XLNET, BERT, and a variant DNABERT trained on the human genome) to predict and analyze the promoters in freshwater cyanobacterium Synechocystis sp. PCC 6803 and the fastest growing cyanobacterium Synechococcus elongatus sp. UTEX 2973. These freshwater cyanobacteria are promising hosts for phototrophically producing value-added compounds from CO2. Through a custom pipeline, promoters and non-promoters from Synechococcus elongatus sp. UTEX 2973 were used to train the model. The trained model achieved an AUROC score of 0.97 and F1 score of 0.92. During cross-validation with promoters from Synechocystis sp. PCC 6803, the model achieved an AUROC score of 0.96 and F1 score of 0.91. To increase accessibility, we developed an integrated platform (TSSNote-CyaPromBERT) to facilitate large dataset extraction, model training, and promoter prediction from public dRNA-seq datasets. Furthermore, various visualization tools have been incorporated to address the ""black box "" issue of deep learning and feature analysis. The learning transfer ability of large language models may help identify and analyze promoter regions for newly isolated strains with similar lineages.","2022-11-29","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","13","","","","","","","","","","English","","","","WOS:000898156600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","ALIGNMENT; ANNOTATION; CYANOBACTERIA; deep learning; differential RNA sequencing; dRNA-Seq; ESCHERICHIA-COLI; natural language processing; promoter prediction; RECOGNITION; REGIONS; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CUNZNVK5","journalArticle","2022","Wang, ZH; Zhang, J; Zhang, XC; Chen, P; Wang, B","Transformer Model for Functional Near-Infrared Spectroscopy Classification","IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS","","2168-2194","10.1109/JBHI.2022.3140531","","Functional near-infrared spectroscopy (fNIRS) is a promising neuroimaging technology. The fNIRS classification problem has always been the focus of the brain-computer interface (BCI). Inspired by the success of Transformer based on self-attention mechanism in the fields of natural language processing and computer vision, we propose an fNIRS classification network based on Transformer, named fNIRS-T. We explore the spatial-level and channel-level representation of fNIRS signals to improve data utilization and network representation capacity. Besides, a preprocessing module, which consists of one-dimensional average pooling and layer normalization, is designed to replace filtering and baseline correction of data preprocessing. It makes fNIRS-T an end-to-end network, called fNIRS-PreT. Compared with traditional machine learning classifiers, convolutional neural network (CNN), and long short-term memory (LSTM), the proposed models obtain the best accuracy on three open-access datasets. Specifically, in the most extensive ternary classification task (30 subjects) that includes three types of overt movements, fNIRS-T, CNN, and LSTM obtain 75.49%, 72.89%, and 61.94% on test sets, respectively. Compared to traditional classifiers, fNIRS-T is at least 27.41% higher than statistical features and 6.79% higher than well-designed features. In the individual subject experiment of the ternary classification task, fNIRS-T achieves an average subject accuracy of 78.22% and surpasses CNN and LSTM by a large margin of +4.75% and +11.33%. fNIRS-PreT using raw data also achieves competitive performance to fNIRS-T. Therefore, the proposed models improve the performance of fNIRS-based BCI significantly.","2022-06","2025-02-26 20:43:29","2025-02-26 20:43:29","","2559-2569","","6","26","","","","","","","","","","English","","","","WOS:000805811400020","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;31<br/>Total Times Cited:&nbsp;&nbsp;31<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","ACTIVATION; Brain-computer interface (BCI); CEREBRAL-BLOOD; classificat- ion; Convolution; Deep learning; end-to-end; Feature extraction; Functional near-infrared spectroscopy; functional near-infrared spectroscopy (fNIRS); Hemodynamics; OXYGENATION; preprocessing module; self-attention; Task analysis; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CYDSSW3V","journalArticle","2023","Xiao, YQ; Hu, YB; Huang, KY; Alzheimers Dis Neuroimaging","Atrophy of hippocampal subfields relates to memory decline during the pathological progression of Alzheimer's disease","FRONTIERS IN AGING NEUROSCIENCE","","1663-4365","10.3389/fnagi.2023.1287122","","BackgroundIt has been well documented that atrophy of hippocampus and hippocampal subfields is closely linked to cognitive decline in normal aging and patients with mild cognitive impairment (MCI) and Alzheimer's disease (AD). However, evidence is still sparce regarding the atrophy of hippocampus and hippocampal subfields in normal aging adults who later developed MCI or AD.ObjectiveTo examine whether atrophy of hippocampus and hippocampal subfields has occurred in normal aging before a diagnosis of MCI or AD.MethodsWe analyzed structural magnetic resonance imaging (MRI) data of cognitively normal (CN, n = 144), MCI (n = 90), and AD (n = 145) participants obtained from the Alzheimer's Disease Neuroimaging Initiative. The CN participants were categorized into early dementia converters (CN-C) and non-converters (CN-NC) based on their scores of clinical dementia rating after an average of 36.2 months (range: 6-105 months). We extracted the whole hippocampus and hippocampal subfields for each participant using FreeSurfer, and analyzed the differences in volumes of hippocampus and hippocampal subfields between groups. We then examined the associations between volume of hippocampal subfields and delayed recall scores in each group separately.ResultsHippocampus and most of the hippocampal subfields demonstrated significant atrophy during the progression of AD. The CN-C and CN-NC groups differed in the left hippocampus-amygdala transition area (HATA). Furthermore, the volume of presubiculum was significantly correlated with delayed recall scores in the CN-NC and AD groups, but not in the CN-C and MCI groups.ConclusionHippocampal subfield atrophy (i.e., left HATA) had occurred in cognitively normal elderly individuals before clinical symptoms were recognized. Significant associations of presubiculum with delayed recall scores in the CN-NC and AD groups highlight the essential role of the hippocampal subfields in both early dementia detection and AD progression.","2023-12-12","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","15","","","","","","","","","","English","","","","WOS:001129734000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Alzheimer's disease; cognitive decline; early detection; HIGH-RESOLUTION MRI; hippocampal subfields; mild cognitive impairment; MILD COGNITIVE IMPAIRMENT; structural MRI; VOLUME","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JK8WB8W6","journalArticle","2021","Al-Harrasi, AM; Iqbal, E; Tsamakis, K; Lasek, J; Gadelrab, R; Soysal, P; Kohlhoff, E; Tsiptsios, D; Rizos, E; Perera, G; Aarsland, D; Stewart, R; Mueller, C","Motor signs in Alzheimer's disease and vascular dementia: Detection through natural language processing, co-morbid features and relationship to adverse outcomes","EXPERIMENTAL GERONTOLOGY","","0531-5565","10.1016/j.exger.2020.111223","","Background: Motor signs in patients with dementia are associated with a higher risk of cognitive decline, institutionalisation, death and increased health care costs, but prevalences differ between studies. The aims of this study were to employ a natural language processing pipeline to detect motor signs in a patient cohort in routine care; to explore which other difficulties occur co-morbid to motor signs; and whether these, as a group and individually, predict adverse outcomes. Methods: A cohort of 11,106 patients with dementia in Alzheimer's disease, vascular dementia or a combination was assembled from a large dementia care health records database in Southeast London. A natural language processing algorithm was devised in order to establish the presence of motor signs (bradykinesia, Parkinsonian gait, rigidity, tremor) recorded around the time of dementia diagnosis. We examined the co-morbidity profile of patients with these symptoms and used Cox regression models to analyse associations with survival and hospitalisation, adjusting for twenty-four potential confounders. Results: Less than 10% of patients were recorded to display any motor sign, and tremor was most frequently detected. Presence of motor signs was associated with younger age at diagnosis, neuropsychiatric symptoms, poor physical health and higher prescribing of psychotropics. Rigidity was independently associated with a 23% increased mortality risk after adjustment for confounders (p = 0.014). A non-significant trend for a 15% higher risk of hospitalisation was detected in those with a recorded Parkinsonian gait (p = 0.094). Conclusions: With the exception of tremor, motor signs appear to be under-recorded in routine care. They are part of a complex clinical picture and often accompanied by neuropsychiatric and functional difficulties, and thereby associated with adverse outcomes. This underlines the need to establish structured examinations in routine clinical practice via easy-to-use tools.","2021-04","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","146","","","","","","","","","","English","","","","WOS:000620913900004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Alzheimer's disease; DEATH; Dementia; EXTRAPYRAMIDAL SIGNS; HEALTH; LEWY BODIES; MANAGEMENT; MORTALITY; Natural language processing; Parkinsonism; PEOPLE; PREDICTORS; Prevalence rate; Vascular dementia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EV5H4JRB","journalArticle","2022","Karim, HT; Aizenstein, HJ; Mizuno, A; Ly, M; Andreescu, C; Wu, MJ; Hong, CH; Roh, HW; Park, B; Lee, H; Kim, NR; Choi, JW; Seo, SW; Choi, SH; Kim, EJ; Kim, BC; Cheong, JY; Lee, E; Lee, DG; Cho, YH; Moon, SY; Son, SJ","Independent replication of advanced brain age in mild cognitive impairment and dementia: detection of future cognitive dysfunction","MOLECULAR PSYCHIATRY","","1359-4184","10.1038/s41380-022-01728-y","","We previously developed a novel machine-learning-based brain age model that was sensitive to amyloid. We aimed to independently validate it and to demonstrate its utility using independent clinical data. We recruited 650 participants from South Korean memory clinics to undergo magnetic resonance imaging and clinical assessments. We employed a pretrained brain age model that used data from an independent set of largely Caucasian individuals (n = 757) who had no or relatively low levels of amyloid as confirmed by positron emission tomography (PET). We investigated the association between brain age residual and cognitive decline. We found that our pretrained brain age model was able to reliably estimate brain age (mean absolute error = 5.68 years, r(650) = 0.47, age range = 49-89 year) in the sample with 71 participants with subjective cognitive decline (SCD), 375 with mild cognitive impairment (MCI), and 204 with dementia. Greater brain age was associated with greater amyloid and worse cognitive function [Odds Ratio, (95% Confidence Interval {CI}): 1.28 (1.06-1.55), p = 0.030 for amyloid PET positivity; 2.52 (1.76-3.61), p < 0.001 for dementia]. Baseline brain age residual was predictive of future cognitive worsening even after adjusting for apolipoprotein E e4 and amyloid status [Hazard Ratio, (95% CI): 1.94 (1.33-2.81), p = 0.001 for total 336 follow-up sample; 2.31 (1.44-3.71), p = 0.001 for 284 subsample with baseline Clinical Dementia Rating <= 0.5; 2.40 (1.43-4.03), p = 0.001 for 240 subsample with baseline SCD or MCI]. In independent data set, these results replicate our previous findings using this model, which was able to delineate significant differences in brain age according to the diagnostic stages of dementia as well as amyloid deposition status. Brain age models may offer benefits in discriminating and tracking cognitive impairment in older adults.","2022-12","2025-02-26 20:43:29","2025-02-26 20:43:29","","5235-5243","","12","27","","","","","","","","","","English","","","","WOS:000841124300002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","ALZHEIMERS-DISEASE; ATROPHY; GUIDELINES; PREDICTION; SUM; VERSION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K8E8SNI7","journalArticle","2022","Thunell, JA; Jacobson, M; Joe, EB; Zissimopoulos, JM","Medicare's Annual Wellness Visit and diagnoses of dementias and cognitive impairment","ALZHEIMER'S & DEMENTIA: DIAGNOSIS, ASSESSMENT & DISEASE MONITORING","","2352-8729","10.1002/dad2.12357","","IntroductionEarly detection of Alzheimer's disease and related dementias allows clinicians and patients to prepare for future needs and identify treatment options. Medicare's Annual Wellness Visit (AWV) requires detection of cognitive impairment and may increase dementia diagnosis. We estimated the relationship between AWV receipt and incident dementia. MethodsUsing a retrospective cohort of Medicare Fee-For-Service (FFS) beneficiaries enrolled for at least 3 years from 2009 to 2016 and two-stage least squares, we quantified the relationship between AWV and incident diagnosis of cognitive impairment/dementia, and by race/ethnicity. The county-level change in percent of beneficiaries receiving AWVs was used as an instrumental variable to account for unobserved factors associated with individuals' AWV receipt and diagnosis. Sample included 3,333,617 beneficiaries ages 67 years and older, without dementia at the beginning of the study. ResultsBeneficiaries included 2,713,573 White, 251,958 Black, 196,845 Hispanic, 95,719 Asian, 11,727 American Indian/Alaska Native, and 63,795 of other race/ethnicity. Using ordinary least squares, dementia incidence was -0.79 percentage points (95% CI -0.81 to -0.76) lower for persons receiving an AWV compared to no AWV. Using instrumental variables reversed the direction of the effect: AWV receipt increased dementia diagnoses by 0.47 percentage points (95% CI 0.14 to 0.80), 15% over baseline. AWVs increased diagnoses 2.0 percentage points (95% CI 0.05 to 3.94) among Blacks, 0.40 percentage points (95% CI 0.05 to 0.75) among Whites, but est were imprecise for Hispanics and Asians. DiscussionIncreasing AWV take-up and supporting physicians' performance of cognitive assessment may further improve dementia detection in the population and among groups at higher risk of undiagnosed dementia.","2022","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","1","14","","","","","","","","","","English","","","","WOS:000914865700091","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","annual wellness visit; ASSOCIATION; cognitive screening; dementia; detection; disparities; FEE-FOR-SERVICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TID478HE","journalArticle","2025","Navarro, DF; Coiera, E; Hambly, TW; Triplett, Z; Asif, N; Susanto, A; Chowdhury, A; Lorenzo, AA; Dras, M; Berkovsky, S","Expert evaluation of large language models for clinical dialogue summarization","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-84850-x","","We assessed the performance of large language models' summarizing clinical dialogues using computational metrics and human evaluations. The comparison was done between automatically generated and human-produced summaries. We conducted an exploratory evaluation of five language models: one general summarisation model, one fine-tuned for general dialogues, two fine-tuned with anonymized clinical dialogues, and one Large Language Model (ChatGPT). These models were assessed using ROUGE, UniEval metrics, and expert human evaluation was done by clinicians comparing the generated summaries against a clinician generated summary (gold standard). The fine-tuned transformer model scored the highest when evaluated with ROUGE, while ChatGPT scored the lowest overall. However, using UniEval, ChatGPT scored the highest across all the evaluated domains (coherence 0.957, consistency 0.7583, fluency 0.947, and relevance 0.947 and overall score 0.9891). Similar results were obtained when the systems were evaluated by clinicians, with ChatGPT scoring the highest in four domains (coherency 0.573, consistency 0.908, fluency 0.96 and overall clinical use 0.862). Statistical analyses showed differences between ChatGPT and human summaries vs. all other models. These exploratory results indicate that ChatGPT's performance in summarizing clinical dialogues approached the quality of human summaries. The study also found that the ROUGE metrics may not be reliable for evaluating clinical summary generation, whereas UniEval correlated well with human ratings. Large language models may provide a successful path for automating clinical dialogue summarization. Privacy concerns and the restricted nature of health records remain challenges for its integration. Further evaluations using diverse clinical dialogues and multiple initialization seeds are needed to verify the reliability and generalizability of automatically generated summaries.","2025-01-07","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","1","15","","","","","","","","","","English","","","","WOS:001398316700015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Artificial intelligence; Electronic health records; Natural language processing; Primary care","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TAMVMXX3","journalArticle","2024","Wan, Y; Wang, H; Lu, LX; Lan, X; Xu, FF; Li, SL","An Improved Real-Time Detection Transformer Model for the Intelligent Survey of Traffic Safety Facilities","SUSTAINABILITY","","2071-1050","10.3390/su162310172","","The undertaking of traffic safety facility (TSF) surveys represents a significant labor-intensive endeavor, which is not sustainable in the long term. The subject of traffic safety facility recognition (TSFR) is beset with numerous challenges, including those associated with background misclassification, the diminutive dimensions of the targets, the spatial overlap of detection targets, and the failure to identify specific targets. In this study, transformer-based and YOLO (You Only Look Once) series target detection algorithms were employed to construct TSFR models to ensure both recognition accuracy and efficiency. The TSF image dataset, comprising six categories of TSFs in urban areas of three cities, was utilized for this research. The dimensions and intricacies of the Detection Transformer (DETR) family of models are considerably more substantial than those of the YOLO family. YOLO-World and Real-Time Detection Transformer (RT-DETR) models were optimal and comparable for the TSFR task, with the former exhibiting a higher detection efficiency and the latter a higher detection accuracy. The RT-DETR model exhibited a notable reduction in model complexity by 57% in comparison to the DINO (DETR with improved denoising anchor boxes for end-to-end object detection) model while also demonstrating a slight enhancement in recognition accuracy. The incorporation of the RepGFPN (Reparameterized Generalized Feature Pyramid Network) module has markedly enhanced the multi-target detection accuracy of RT-DETR, with a mean average precision (mAP) of 82.3%. The introduction of RepGFPN significantly enhanced the detection rate of traffic rods, traffic sign boards, and water surround barriers and somewhat ameliorated the problem of duplicate detection.","2024-12","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","23","16","","","","","","","","","","English","","","","WOS:001377780600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","NETWORK; OPTIMIZATION; real-time detection transformer; reparameterized generalized feature pyramid network; SIGN RECOGNITION; traffic safety facility asset survey; traffic safety facility recognition; VISION; YOLO","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UC5CI7DM","journalArticle","2024","Ahmed, FS; Aly, S; Liu, XR","EPI-Trans: an effective transformer-based deep learning model for enhancer promoter interaction prediction","BMC BIOINFORMATICS","","1471-2105","10.1186/s12859-024-05784-9","","Background Recognition of enhancer-promoter Interactions (EPIs) is crucial for human development. EPIs in the genome play a key role in regulating transcription. However, experimental approaches for classifying EPIs are too expensive in terms of effort, time, and resources. Therefore, more and more studies are being done on developing computational techniques, particularly using deep learning and other machine learning techniques, to address such problems. Unfortunately, the majority of current computational methods are based on convolutional neural networks, recurrent neural networks, or a combination of them, which don't take into consideration contextual details and the long-range interactions between the enhancer and promoter sequences. A new transformer-based model called EPI-Trans is presented in this study to overcome the aforementioned limitations. The multi-head attention mechanism in the transformer model automatically learns features that represent the long interrelationships between enhancer and promoter sequences. Furthermore, a generic model is created with transferability that can be utilized as a pre-trained model for various cell lines. Moreover, the parameters of the generic model are fine-tuned using a particular cell line dataset to improve performance.Results Based on the results obtained from six benchmark cell lines, the average AUROC for the specific, generic, and best models is 94.2%, 95%, and 95.7%, while the average AUPR is 80.5%, 66.1%, and 79.6% respectively.Conclusions This study proposed a transformer-based deep learning model for EPI prediction. The comparative results on certain cell lines show that EPI-Trans outperforms other cutting-edge techniques and can provide superior performance on the challenge of recognizing EPI.","2024-06-18","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","1","25","","","","","","","","","","English","","","","WOS:001249623000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Enhancer; Enhancer-promoter interaction (EPI) prediction; Promoter; SEQUENCE; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PJBZUGVN","journalArticle","2024","Yang, J; Wei, P; Zheng, NN","Cross Time-Frequency Transformer for Temporal Action Localization","IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY","","1051-8215","10.1109/TCSVT.2023.3326692","","Most modern approaches in temporal action localization (TAL) mainly focus on time domain information, while neglecting the advantages of information from other domains. How to effectively utilize information from different domains and their interactions in a reasonable manner has been an attractive yet challenging issue in TAL. In this paper, we propose a novel cross time-frequency Transformer model (TFFormer) for TAL. A dual-branch network architecture is designed to capture the time and frequency features at multiple scales, using the multi-scale transformer in the time branch and the DB1 Discrete Wavelet Transform (DWT) in the frequency branch. To fuse these features from different domains, we propose a cross time-frequency attention mechanism that includes a time pathway and a frequency pathway, enhancing the interaction between the temporal and frequency features. Furthermore, a gated control mechanism is designed to aggregate features from different scales, characterizing the respective contributions of features at different scales. We also design a new regression loss function for locating the time boundaries. Extensive experiments were carried out on four challenging benchmark datasets, including two third-person datasets and two first-person datasets. The proposed method achieves impressive results on these datasets. Specifically, TFFormer achieves an average mAP of 23.2% on Ego4D and 25.6% on EPIC-Kitchens 100, which outperform previous state-of-the-arts by a large margin. It also obtains competitive results on ActivityNet v1.3 and THUMOS14, with an average mAP of 36.2% and 67.8%. We also conducted extensive ablation studies to validate the effectiveness of each component in the proposed method.","2024-06","2025-02-26 20:43:29","2025-02-26 20:43:29","","4625-4638","","6","34","","","","","","","","","","English","","","","WOS:001241605300035","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","cross time-frequency features; Discrete wavelet transforms; Feature extraction; Location awareness; Logic gates; NETWORK; Task analysis; Temporal action localization; Time-frequency analysis; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RGDNESVX","journalArticle","2024","Halder, A; Gharami, S; Sadhu, P; Singh, PK; Wozniak, M; Ijaz, MF","Implementing vision transformer for classifying 2D biomedical images","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-63094-9","","In recent years, the growth spurt of medical imaging data has led to the development of various machine learning algorithms for various healthcare applications. The MedMNISTv2 dataset, a comprehensive benchmark for 2D biomedical image classification, encompasses diverse medical imaging modalities such as Fundus Camera, Breast Ultrasound, Colon Pathology, Blood Cell Microscope etc. Highly accurate classifications performed on these datasets is crucial for identification of various diseases and determining the course of treatment. This research paper presents a comprehensive analysis of four subsets within the MedMNISTv2 dataset: BloodMNIST, BreastMNIST, PathMNIST and RetinaMNIST. Each of these selected datasets is of diverse data modalities and comes with various sample sizes, and have been selected to analyze the efficiency of the model against diverse data modalities. The study explores the idea of assessing the Vision Transformer Model's ability to capture intricate patterns and features crucial for these medical image classification and thereby transcend the benchmark metrics substantially. The methodology includes pre-processing the input images which is followed by training the ViT-base-patch16-224 model on the mentioned datasets. The performance of the model is assessed using key metrices and by comparing the classification accuracies achieved with the benchmark accuracies. With the assistance of ViT, the new benchmarks achieved for BloodMNIST, BreastMNIST, PathMNIST and RetinaMNIST are 97.90%, 90.38%, 94.62% and 57%, respectively. The study highlights the promise of Vision transformer models in medical image analysis, preparing the way for their adoption and further exploration in healthcare applications, aiming to enhance diagnostic accuracy and assist medical professionals in clinical decision-making.","2024-05-31","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","1","14","","","","","","","","","","English","","","","WOS:001236740000072","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Biomedical image classification; BloodMNIST; BreastMNIST; Deep learning; MedMNISTv2; PathMNIST; RetinaMNIST; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8XEVYV5M","journalArticle","2024","Aghapanah, H; Rasti, R; Kermani, S; Tabesh, F; Banaem, HY; Aliakbar, HP; Sanei, H; Segars, WP","CardSegNet: An adaptive hybrid CNN-vision transformer model for heart region segmentation in cardiac MRI","COMPUTERIZED MEDICAL IMAGING AND GRAPHICS","","0895-6111","10.1016/j.compmedimag.2024.102382","","Cardiovascular MRI (CMRI) is a non-invasive imaging technique adopted for assessing the blood circulatory system's structure and function. Precise image segmentation is required to measure cardiac parameters and diagnose abnormalities through CMRI data. Because of anatomical heterogeneity and image variations, cardiac image segmentation is a challenging task. Quantification of cardiac parameters requires high-performance segmentation of the left ventricle (LV), right ventricle (RV), and left ventricle myocardium from the background. The first proposed solution here is to manually segment the regions, which is a time-consuming and error-prone procedure. In this context, many semi- or fully automatic solutions have been proposed recently, among which deep learning-based methods have revealed high performance in segmenting regions in CMRI data. In this study, a self-adaptive multi attention (SMA) module is introduced to adaptively leverage multiple attention mechanisms for better segmentation. The convolutional-based position and channel attention mechanisms with a patch tokenization-based vision transformer (ViT)-based attention mechanism in a hybrid and end-to-end manner are integrated into the SMA. The CNN- and ViT-based attentions mine the short- and long-range dependencies for more precise segmentation. The SMA module is applied in an encoder-decoder structure with a ResNet50 backbone named CardSegNet. Furthermore, a deep supervision method with multi-loss functions is introduced to the CardSegNet optimizer to reduce overfitting and enhance the model's performance. The proposed model is validated on the ACDC2017 (n=100), M&Ms (n=321), and a local dataset (n=22) using the 10-fold crossvalidation method with promising segmentation results, demonstrating its outperformance versus its counterparts.","2024-07","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","115","","","","","","","","","","English","","","","WOS:001292403400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Cardiac magnetic resonance imaging; Deep learning; Hybrid attention mechanism; Image segmentation; IMAGE SEGMENTATION; NETWORK; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GG66LUVG","journalArticle","2024","Peng, C; Yang, X; Chen, AK; Yu, ZH; Smith, KE; Costa, AB; Flores, MG; Bian, J; Wu, YH","Generative large language models are all-purpose text analytics engines: text-to-text learning is all your need","JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION","","1067-5027","10.1093/jamia/ocae078","","Objective To solve major clinical natural language processing (NLP) tasks using a unified text-to-text learning architecture based on a generative large language model (LLM) via prompt tuning.Methods We formulated 7 key clinical NLP tasks as text-to-text learning and solved them using one unified generative clinical LLM, GatorTronGPT, developed using GPT-3 architecture and trained with up to 20 billion parameters. We adopted soft prompts (ie, trainable vectors) with frozen LLM, where the LLM parameters were not updated (ie, frozen) and only the vectors of soft prompts were updated, known as prompt tuning. We added additional soft prompts as a prefix to the input layer, which were optimized during the prompt tuning. We evaluated the proposed method using 7 clinical NLP tasks and compared them with previous task-specific solutions based on Transformer models.Results and Conclusion The proposed approach achieved state-of-the-art performance for 5 out of 7 major clinical NLP tasks using one unified generative LLM. Our approach outperformed previous task-specific transformer models by similar to 3% for concept extraction and 7% for relation extraction applied to social determinants of health, 3.4% for clinical concept normalization, 3.4%-10% for clinical abbreviation disambiguation, and 5.5%-9% for natural language inference. Our approach also outperformed a previously developed prompt-based machine reading comprehension (MRC) model, GatorTron-MRC, for clinical concept and relation extraction. The proposed approach can deliver the ""one model for all"" promise from training to deployment using a unified generative LLM.","2024-04-17","2025-02-26 20:43:29","2025-02-26 20:43:29","","1892-1903","","9","31","","","","","","","","","","English","","","","WOS:001203800600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","clinical natural language processing; large language model; prompt tuning; text generation; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SDR3S3RC","journalArticle","2024","Chen, ZY; Zheng, YJ; Gee, JC","TransMatch: A Transformer-Based Multilevel Dual-Stream Feature Matching Network for Unsupervised Deformable Image Registration","IEEE TRANSACTIONS ON MEDICAL IMAGING","","0278-0062","10.1109/TMI.2023.3288136","","Feature matching, which refers to establishing the correspondence of regions between two images (usually voxel features), is a crucial prerequisite of feature-based registration. For deformable image registration tasks, traditional feature-based registration methods typically use an iterative matching strategy for interest region matching, where feature selection and matching are explicit, but specific feature selection schemes are often useful in solving application-specific problems and require several minutes for each registration. In the past few years, the feasibility of learning-based methods, such as VoxelMorph and TransMorph, has been proven, and their performance has been shown to be competitive compared to traditional methods. However, these methods are usually single-stream, where the two images to be registered are concatenated into a 2-channel whole, and then the deformation field is output directly. The transformation of image features into interimage matching relationships is implicit. In this paper, we propose a novel end-to-end dual-stream unsupervised framework, named TransMatch, where each image is fed into a separate stream branch, and each branch performs feature extraction independently. Then, we implement explicit multilevel feature matching between image pairs via the query-key matching idea of the self-attention mechanism in the Transformer model. Comprehensive experiments are conducted on three 3D brain MR datasets, LPBA40, IXI, and OASIS, and the results show that the proposed method achieves state-of-the-art performance in several evaluation metrics compared to the commonly utilized registration methods, including SyN, NiftyReg, VoxelMorph, CycleMorph, ViT-V-Net, and TransMorph, demonstrating the effectiveness of our model in deformable medical image registration.","2024-01","2025-02-26 20:43:29","2025-02-26 20:43:29","","15-27","","1","43","","","","","","","","","","English","","","","WOS:001158081600006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;30<br/>Total Times Cited:&nbsp;&nbsp;30<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","brain MRI; Deformable image registration; dual-stream; feature matching; FRAMEWORK; HAMMER; multilevel; transformer; unsupervised deep learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L95764XT","journalArticle","2023","Wei, SM; Meng, SM; Li, QM; Zhou, XK; Qi, LY; Xu, XL","Edge-enabled federated sequential recommendation with knowledge-aware Transformer","FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE","","0167-739X","10.1016/j.future.2023.06.028","","The increasing ubiquity of recommendation systems in modern applications has brought about significant changes in various aspects of our daily lives. However, the emergence of privacy concerns has highlighted the need for innovative solutions to address the challenges faced by traditional recommender systems. In this regard, federated learning provides an approach to address privacy concerns by training global models based on edge data. However, the integration of the existing federated learning framework with the latest recommendation system method remains insufficiently explored. To address this issue, we present edge-enabled federated Sequential Recommendation with Knowledge-aware Transformer (KG-FedTrans4Rec) model that incorporates knowledge graph information into sequential recommendation tasks while applying federated learning for privacy preservation. The KG extraction module and sequential processing module in KG-FedTrans4Rec are designed to capture item-related information and sequence inner relationships simultaneously. We leverage Graph Convolutional Networks (GCNs) to aggregate item-related information and user preferences in the KG extraction module. Furthermore, sequential recommender systems model users' dynamic preferences based on their behaviors to make customized recommendations. In the sequential processing module, we employ replaced token detection and two-stream self-attention strategies to enhance the Transformer-based model. In summary, our proposed KG-FedTrans4Rec model presents a approach to sequential recommendation tasks by incorporating knowledge graph information while preserving user privacy through federated learning. Our experimental results demonstrate the superior performance of our model compared to various recommendation models. This research is expected to make significant contributions to the development of privacy-preserving recommendation systems, which are increasingly essential in modern applications.& COPY; 2023 Elsevier B.V. All rights reserved.","2023-11","2025-02-26 20:43:29","2025-02-26 20:43:29","","610-622","","","148","","","","","","","","","","English","","","","WOS:001043963400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","Federated learning; GCN; Knowledge graph; NETWORK; Sequential recommendation system; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BKJULSQD","journalArticle","2023","Kim, GW; Lee, SW; Son, H; Choi, KW","A Study on 3D Human Pose Estimation Using Through-Wall IR-UWB Radar and Transformer","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3244017","","In this paper, we propose a human pose estimation algorithm for an impulse radio ultra-wideband (IR-UWB) radar based on the transformer-based deep learning model. We have built an IR-UWB radar system with an 8-by-8 multiple-input multiple-output (MIMO) antenna array. The IR-UWB radar system in our paper is advantageous for the through-wall detection application since it operates on a very low frequency range (i.e., 0.45 to 3.55 GHz) compared to other existing works on RF-based human pose estimation. Moreover, the human pose estimation by an IR-UWB radar has not been studied very well in other existing works since all existing works have used a frequency-modulated continuous wave (FMCW) radar or a WiFi device. We propose a 3D-TransPOSE algorithm for the 3D human pose estimation from the IR-UWB radar signals. The proposed algorithm is designed based on the transformer architecture. While the transformer has actively been studied in the natural language processing (NLP) or vision domains, no prior work has applied the transformer model to the RF-based human pose estimation problem. The attention mechanism of the proposed algorithm is able to focus on the relevant time segments of the IR-UWB radar signals for detecting the human pose, eliminating the needs of converting radar signals to a voxelized 3D image. We have gathered a large dataset of IR-UWB radar signals labeled with 3D human skeletons, and shown that the proposed algorithm is able to detect human skeletons with a high accuracy.","2023","2025-02-26 20:43:29","2025-02-26 20:43:29","","15082-15095","","","11","","","","","","","","","","English","","","","WOS:000936259200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;17</p>","","","Antenna arrays; attention; IR-UWB radar; keypoint detection; MIMO; pose estimation; Pose estimation; Radar antennas; Radar imaging; Three-dimensional displays; transformer; Transformers; Ultrawideband technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DLMDRVRY","journalArticle","2024","Daniel, EV; Wiese, LAK; Holt, JK","Assessing Alzheimer's Disease Knowledge and Cognitive Risk Among a Rural Older Afro-Caribbean Cohort","JOURNAL OF COMMUNITY HEALTH NURSING","","0737-0016","10.1080/07370016.2023.2257199","","Purpose: Older, rural Afro-Caribbeans are a growing subset of the Black population who face increased risk for Alzheimer's disease and related dementias (ADRD), but research targeting ADRD is scarce in this group. The purpose of this study was to investigate dementia risk among older Afro-Caribbeans living in a rural area. We also examined age, sex, and years of education, and knowledge about Alzheimer's disease as potential predictors of dementia risk. Design: A pre-post, correlational design was employed. Methods: Cognitive screenings were conducted using Nasreddine's MiniMoCA, with tests of language fluency/orientation/recall, and linear regression analysis. A basic knowledge of Alzheimer's disease survey (BKAD) was also administered. Findings: A total of 55 Afro-Caribbean participants (67.0 +10.8y (M +/- SD), 65.5% with 10y or less of education residing in a rural area within the last 20 years were included.Over 50% of the convenience sample scored in the cognitive risk range. Significant associations were found between Mini-MoCA Total and Language scores and education (p < 0.01). Further, there was a significant change from pretest to posttest in BKAD scores. BKAD pretest and posttest scores were also significantly higher for those without dementia risk based on the Mini-MoCA Total. Conclusion: While the Mini-MoCA showed good reliability in less-educated older Afro-Caribbeans, scores were strongly dependent on years of education. Offering a limited intervention resulted in increased BKAD scores in this Afro-Caribbean sample, and a low BKAD score was associated with a higher dementia risk category. Clinical evidence: This study contributes to the limited but growing body of research about Alzheimer's disease knowledge, cognitive risk, and dementia detection among Afro-Caribbeans. The use of language-neutral cognitive assessments is recommended among rural older immigrants.","2024-01-02","2025-02-26 20:43:29","2025-02-26 20:43:29","","1-10","","1","41","","","","","","","","","","English","","","","WOS:001068012700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","CARE; DEMENTIA; HEALTH DISPARITIES; POPULATION; RESIDENTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P3RASJL6","journalArticle","2022","Varshney, YV; Khan, A","Imagined Speech Classification Using Six Phonetically Distributed Words","FRONTIERS IN SIGNAL PROCESSING","","2673-8198","10.3389/frsip.2022.760643","","Imagined speech can be used to send commands without any muscle movement or emitting audio. The current status of research is in the early stage, and there is a shortage of open-access datasets for imagined speech analysis. We have proposed an openly accessible electroencephalograph (EEG) dataset for six imagined words in this work. We have selected six phonetically distributed, monosyllabic, and emotionally neutral words from W-22 CID word lists. The phonetic distribution of words consisted of the different places of consonants' articulation and different positions of tongue advancement for vowel pronunciation. The selected words were ""could,"" ""yard,"" ""give,"" ""him,"" ""there,"" and ""toe."" The experiment was performed over 15 subjects who performed the overt and imagined speech task for the displayed word. Each word was presented 50 times in random order. EEG signals were recorded during the experiment using a 64-channel EEG acquisition system with a sampling rate of 2,048 Hz. A preliminary analysis of the recorded data is presented by performing the classification of EEGs corresponding to the imagined words. The achieved accuracy is above the chance level for all subjects, which suggests that the recorded EEGs contain distinctive information about the imagined words.","2022-03-25","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","2","","","","","","","","","","English","","","","WOS:001063423600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Brain-Computer interface; COMMUNICATION; EEG; EEG Decoding; Imagined speech; Monosyllabic words; Open access data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BRFN5IJM","journalArticle","2021","Hadiyoso, S; Zakaria, H; Ong, PA; Mengko, TLER","Hemispheric Coherence Analysis of Wide Band EEG Signals for Characterization of Post-Stroke Patients with Dementia","TRAITEMENT DU SIGNAL","","0765-0019","10.18280/ts.380408","","Post-stroke dementia (PSD) is a type of vascular dementia (VaD) that might be occurred in post-stroke patients. Memory, language and behavior tests can be used for the analysis of cognitive impairment caused by PSD. Often a supporting clinical examination such as an electroencephalogram (EEG) is used to support the diagnosis or analyze the characteristic changes that occur in the brain. Conventional analysis or visual inspection of EEG signals can be very difficult, since the nature of the signal tends to be non-stationer. Therefore, this study proposes a quantitative analysis for the characterization of EEG signals in stroke survivors with dementia. It is thought that it has different characteristics with the normal subject so that this study can be used as a reference in supporting dementia detection in post-stroke survivors. The quantitative analysis used in this study is coherence analysis. Coherence analysis was performed on EEG signals recorded from six poststroke patients with dementia and then compared with ten normal healthy subjects. Analysis of coherence between brain areas includes inter and intra-hemispheric coherence. Validation was carried out by using the independent t-test where the confidence level was 95%, indicating that the p-value <0.05 had a significant difference. The test results show that in general the coherence of the electrode pairs in patients with dementia is lower than in the normal healthy group. It is notably, i) In interhemispheric, the C3-C4, T3-T4, and T5-T6 pairs generate significant differences, ii) the highest decrease in intrahemispheric coherence was found in C3T5 with p = 0.0005. The coherence study presented in this paper is expected to be used for early detection of PSD in the future.","2021-08","2025-02-26 20:43:29","2025-02-26 20:43:29","","985-992","","4","38","","","","","","","","","","English","","","","WOS:000703007300008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","ALZHEIMERS-DISEASE; COGNITIVE IMPAIRMENT; coherence; dementia; DIAGNOSIS; EEG; MANAGEMENT; post-stroke; POWER; SPECTRUM; STROKE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EAD9EN9T","journalArticle","2024","Skowronski, K; Galuszka, A; Probierz, E","Polish Speech and Text Emotion Recognition in a Multimodal Emotion Analysis System","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app142210284","","Emotion recognition by social robots is a serious challenge because sometimes people also do not cope with it. It is important to use information about emotions from all possible sources: facial expression, speech, or reactions occurring in the body. Therefore, a multimodal emotion recognition system was introduced, which includes the indicated sources of information and deep learning algorithms for emotion recognition. An important part of this system includes the speech analysis module, which was decided to be divided into two tracks: speech and text. An additional condition is the target language of communication, Polish, for which the number of datasets and methods is very limited. The work shows that emotion recognition using a single source-text or speech-can lead to low accuracy of the recognized emotion. It was therefore decided to compare English and Polish datasets and the latest deep learning methods in speech emotion recognition using Mel spectrograms. The most accurate LSTM models were evaluated on the English set and the Polish nEMO set, demonstrating high efficiency of emotion recognition in the case of Polish data. The conducted research is a key element in the development of a decision-making algorithm for several emotion recognition modules in a multimodal system.","2024-11","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","22","14","","","","","","","","","","English","","","","WOS:001366858400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","mel spectrogram; multimodal emotion recogntion; polish text emotion analysis; social robots; speech emotion recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7QT4T83R","journalArticle","2024","Cavalcanti, JC; da Silva, RR; Eriksson, A; Barbosa, PA","Exploring the performance of automatic speaker recognition using twin speech and deep learning-based artificial neural networks","FRONTIERS IN ARTIFICIAL INTELLIGENCE","","2624-8212","10.3389/frai.2024.1287877","","This study assessed the influence of speaker similarity and sample length on the performance of an automatic speaker recognition (ASR) system utilizing the SpeechBrain toolkit. The dataset comprised recordings from 20 male identical twin speakers engaged in spontaneous dialogues and interviews. Performance evaluations involved comparing identical twins, all speakers in the dataset (including twin pairs), and all speakers excluding twin pairs. Speech samples, ranging from 5 to 30 s, underwent assessment based on equal error rates (EER) and Log cost-likelihood ratios (Cllr). Results highlight the substantial challenge posed by identical twins to the ASR system, leading to a decrease in overall speaker recognition accuracy. Furthermore, analyses based on longer speech samples outperformed those using shorter samples. As sample size increased, standard deviation values for both intra and inter-speaker similarity scores decreased, indicating reduced variability in estimating speaker similarity/dissimilarity levels in longer speech stretches compared to shorter ones. The study also uncovered varying degrees of likeness among identical twins, with certain pairs presenting a greater challenge for ASR systems. These outcomes align with prior research and are discussed within the context of relevant literature.","2024-02-08","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","7","","","","","","","","","","English","","","","WOS:001169098900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","acoustic-phonetics; automatic speaker recognition; forensic phonetics; IMPACT; phonetics; SAMPLE; speech analysis; VERIFICATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3Q9WICFD","journalArticle","2025","Gu, Y; Ying, J; Chen, Q; Yang, H; Wu, JN; Chen, N; Li, YM","Alzheimer's disease recognition based on waveform and spectral speech signal processing","BIOMEDICAL ENGINEERING LETTERS","","2093-9868","10.1007/s13534-024-00444-6","","Alzheimer's disease (AD) is a neurodegenerative disorder with an irreversible progression. Currently, it is diagnosed using invasive and costly methods, such as cerebrospinal fluid analysis, neuroimaging, and neuropsychological assessments. Recent studies indicate that certain changes in language ability can predict early cognitive decline, highlighting the potential of speech analysis in AD recognition. Based on this premise, this study proposes an AD recognition multi-channel network framework, which is referred to as the ADNet. It integrates both time-domain and frequency-domain features of speech signals, using waveform images and log-Mel spectrograms derived from raw speech as data sources. The framework employs inverted residual blocks to enhance the learning of low-level time-domain features and uses gated multi-information units to effectively combine local and global frequency-domain features. The study tests it on a dataset from the Shanghai cognitive screening (SCS) digital neuropsychological assessment. The results show that the method we proposed outperforms existing speech-based methods, achieving an accuracy of 88.57%, a precision of 88.67%, and a recall of 88.64%. This study demonstrates that the proposed framework can effectively distinguish between the AD and normal controls, and it may be useful for developing early recognition tools for AD.","2025-01","2025-02-26 20:43:29","2025-02-26 20:43:29","","261-272","","1","15","","","","","","","","","","English","","","","WOS:001366062800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Alzheimer's disease; Deep learning; DEMENTIA; FEATURES; Speech classification; Speech recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C6QBDPNY","journalArticle","2023","Ciampelli, S; Voppel, AE; de Boer, JN; Koops, S; Sommer, IEC","Combining automatic speech recognition with semantic natural language processing in schizophrenia","PSYCHIATRY RESEARCH","","0165-1781","10.1016/j.psychres.2023.115252","","Natural language processing (NLP) tools are increasingly used to quantify semantic anomalies in schizophrenia. Automatic speech recognition (ASR) technology, if robust enough, could significantly speed up the NLP research process. In this study, we assessed the performance of a state-of-the-art ASR tool and its impact on diagnostic classification accuracy based on a NLP model. We compared ASR to human transcripts quantitatively (Word Error Rate (WER)) and qualitatively by analyzing error type and position. Subsequently, we evaluated the impact of ASR on classification accuracy using semantic similarity measures. Two random forest classifiers were trained with similarity measures derived from automatic and manual transcriptions, and their performance was compared. The ASR tool had a mean WER of 30.4%. Pronouns and words in sentence-final position had the highest WERs. The classification accuracy was 76.7% (sensitivity 70%; specificity 86%) using automated transcriptions and 79.8% (sensitivity 75%; specificity 86%) for manual transcriptions. The difference in performance between the models was not significant. These findings demonstrate that using ASR for semantic analysis is associated with only a small decrease in accuracy in classifying schizophrenia, compared to manual transcripts. Thus, combining ASR technology with semantic NLP models qualifies as a robust and efficient method for diagnosing schizophrenia.","2023-07","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","325","","","","","","","","","","English","","","","WOS:001012329500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Psychosis; PSYCHOSIS; Semantic similarity; Speech analysis; Word error rate","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NEUZJRCM","journalArticle","2024","Li, RJ; Huang, G; Wang, XY; Lawler, K; Goldberg, LR; Roccati, E; St George, RJ; Aiyede, M; King, AE; Bindoff, AD; Vickers, JC; Bai, Q; Alty, J","Smartphone automated motor and speech analysis for early detection of Alzheimer's disease and Parkinson's disease: Validation of TapTalk across 20 different devices","ALZHEIMER'S & DEMENTIA: DIAGNOSIS, ASSESSMENT & DISEASE MONITORING","","2352-8729","10.1002/dad2.70025","","INTRODUCTIONSmartphones are proving useful in assessing movement and speech function in Alzheimer's disease and other neurodegenerative conditions. Valid outcomes across different smartphones are needed before population-level tests are deployed. This study introduces the TapTalk protocol, a novel app designed to capture hand and speech function and validate it in smartphones against gold-standard measures.METHODSTwenty different smartphones collected video data from motor tests and audio data from speech tests. Features were extracted using Google Mediapipe (movement) and Python audio analysis packages (speech). Electromagnetic sensors (60 Hz) and a microphone acquired simultaneous movement and voice data, respectively.RESULTSTapTalk video and audio outcomes were comparable to gold-standard data: 90.3% of video, and 98.3% of audio, data recorded tapping/speech frequencies within +/- 1 Hz of the gold-standard measures.DISCUSSIONValidation of TapTalk across a range of devices is an important step in the development of smartphone-based telemedicine and was achieved in this study.Highlights TapTalk evaluates hand motor and speech functions across a wide range of smartphones. Data showed 90.3% motor and 98.3% speech accuracy within +/-1 Hz of gold standards. Validation advances smartphone-based telemedicine for neurodegenerative diseases.","2024-10","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","4","16","","","","","","","","","","English","","","","WOS:001338141000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","biomarkers; dementia; Mediapipe; motor-cognitive; preclinical","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"USUHD5P3","journalArticle","2023","Lee, CC; Chaspari, T; Provost, EM; Narayanan, SS","An Engineering View on Emotions and Speech: From Analysis and Predictive Models to Responsible Human-Centered Applications","PROCEEDINGS OF THE IEEE","","0018-9219","10.1109/JPROC.2023.3276209","","The substantial growth of Internet-of-Things technology and the ubiquity of smartphone devices has increased the public and industry focus on speech emotion recognition (SER) technologies. Yet, conceptual, technical, and societal challenges restrict the wide adoption of these technologies in various domains, including, healthcare, and education. These challenges are amplified when automated emotion recognition systems are called to function ""in-the-wild"" due to the inherent complexity and subjectivity of human emotion, the difficulty of obtaining reliable labels at high temporal resolution, and the diverse contextual and environmental factors that confound the expression of emotion in real life. In addition, societal and ethical challenges hamper the wide acceptance and adoption of these technologies, with the public raising questions about user privacy, fairness, and explainability. This article briefly reviews the history of affective speech processing, provides an overview of current state-of-the-art approaches to SER, and discusses algorithmic approaches to render these technologies accessible to all, maximizing their benefits and leading to responsible human-centered computing applications.","2023-10","2025-02-26 20:43:29","2025-02-26 20:43:29","","1142-1158","","10","111","","","","","","","","","","English","","","","WOS:001019428100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;244</p>","","","Affect; AUTISM SPECTRUM DISORDER; CLASSIFICATION; CLINICAL DEPRESSION; COMMUNICATION; CULTURAL SPECIFICITY; deep learning; DYADIC INTERACTIONS; emotion; ethics; INDIVIDUAL-DIFFERENCES; PARKINSONS-DISEASE; prosody; real-life monitoring; RECOGNITION; responsible design; speech analysis; VOCAL EXPRESSION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MJH5ZEXB","journalArticle","2024","Dvorak, JD; Boutsen, FR","The Collaboverse: A Collaborative Data-Sharing and Speech Analysis Platform","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2024_JSLHR-23-00286","","Purpose: Collaboration in the field of speech-language pathology occurs across a variety of digital devices and can entail the usage of multiple software tools, systems, file formats, and even programming languages. Unfortunately, gaps between the laboratory, clinic, and classroom can emerge in part because of siloing of data and workflows, as well as the digital divide between users. The purpose of this tutorial is to present the Collaboverse, a web-based collaborative system that unifies these domains, and describe the application of this tool to common tasks in speech-language pathology. In addition, we demonstrate its utility in machine learning (ML) applications. Method: This tutorial outlines key concepts in the digital divide, data management, distributed computing, and ML. It introduces the Collaboverse workspace for researchers, clinicians, and educators in speech-language pathology who wish to improve their collaborative network and leverage advanced computation abilities. It also details an ML approach to prosodic analysis. Conclusions: The Collaboverse shows promise in narrowing the digital divide and is capable of generating clinically relevant data, specifically in the area of prosody, whose computational complexity has limited widespread analysis in research and clinic alike. In addition, it includes an augmentative and alternative communication app allowing visual, nontextual communication.","2024-10","2025-02-26 20:43:29","2025-02-26 20:43:29","","4137-4156","","10","67","","","","","","","","","","English","","","","WOS:001356380400017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;77</p>","","","DIGITAL DIVIDE; GAP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HUEDJIV2","journalArticle","2024","Maghfira, TN; Basaruddin, T; Krisnadhi, AA; Pudjiati, SRR","Attach-SwiNet: Multimodal Attachment Style Classification Model Based on Non-Verbal Signals","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3397608","","Attachment systems, which signify emotional bonds with significant others, play a crucial role in influencing self-development and social interactions. Research on adult attachment in psychology has predominantly utilized questionnaires and interviews, focusing mainly on romantic relationships and parent-child interactions during childhood. Although machine learning approaches in adult attachment research have begun to assess non-verbal behaviors objectively, the connection between these behaviors and attachment styles has not yet been fully explored. This paper presents Attach-SwiNet, a new multimodal model for classifying attachment styles in close relationships among young adults. Our model combines representations of emotions from non-verbal behaviors with subjective responses to categorize attachment styles. It utilizes pre-trained Swin Transformers to analyze emotional cues in facial expression videos and pre-trained ResNet50 to examine speech responses. By integrating the most effective emotion representations from both datasets with rating data from the Experiences in Close Relationships - Relationship Structures (ECR-RS), our model significantly enhances the accuracy of classifying attachment styles. Experimental results show that our approach improves performance over traditional unimodal behavioral data and subjective questionnaire responses by 1.13%.","2024","2025-02-26 20:43:29","2025-02-26 20:43:29","","79151-79165","","","12","","","","","","","","","","English","","","","WOS:001248122800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","ADULT ATTACHMENT; Analytical models; Attachment; Classification algorithms; CLOSE RELATIONSHIPS; emotion; Emotion recognition; facial expression; Feature extraction; Heart rate variability; Hidden Markov models; INTERVIEW; Interviews; machine learning; multimodal; QUALITY; speech; Speech analysis; Transformers; Videos; WORKING MODELS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QHUYYPQ9","journalArticle","2024","Ishikawa, K; Anand, S","Tracking age-related changes in voice and speech production with Landmark-based analysis of speech","JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA","","0001-4966","10.1121/10.0028175","","Voice and speech production change with age, which can lead to potential communication challenges. This study explored the use of Landmark-based analysis of speech (LMBAS), a knowledge-based speech analysis algorithm based on Stevens' Landmark Theory, to describe age-related changes in adult speakers. The speech samples analyzed were sourced from the University of Florida Aging Voice Database, which included recordings of 16 sentences from the Speech Perception in Noise test of Bilger, Rzcezkowski, Nuetzel, and Rabinowitz [J. Acoust. Soc. Am. 65, S98-S98 (1979)] and Bilger, Nuetzel, Rabinowitz, and Rzeczkowski [J. Speech. Lang. Hear. Res. 27, 32-84 (1984)]. These sentences were read in quiet environments by 50 young, 50 middle-aged, and 50 older American English speakers, with an equal distribution of sexes. Acoustic landmarks, specifically, glottal, bursts, and syllabicity landmarks, were extracted using SpeechMark (R), MATLAB Toolbox version 1.1.2. The results showed significant age effect on glottal and burst landmarks. Furthermore, the sex effect was significant for burst and syllabicity landmarks. While the results of LMBAS suggest its potential in detecting age-related changes in speech, increase in syllabicity landmarks with age was unexpected. This finding may suggest the need for further refinement and adjustment of this analytical approach","2024-08","2025-02-26 20:43:29","2025-02-26 20:43:29","","1221-1230","","2","156","","","","","","","","","","English","","","","WOS:001298908600002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","ACOUSTIC CHARACTERISTICS; FREQUENCY-CHARACTERISTICS; FUNDAMENTAL-FREQUENCY; LANGUAGE; PERCEPTION; SPEAKERS; STANDARDIZATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8GMPQQIQ","journalArticle","2024","Ankishan, H; Ulucanlar, H; Akturk, I; Kavak, KA; Bagci, U; Yenigün, BM","Early stage lung cancer detection from speech sounds in natural environments","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2024.106628","","In the diagnosis of early-stage lung cancer, conventional methods often rely on periodic imaging techniques using medical devices. However, recent studies suggest that speech sounds could offer valuable insights into the diagnosis of disease. This study investigates the different characteristics of speech sounds recorded in natural environments between individuals diagnosed with lung cancer and those who are healthy. Using signal processing techniques and a self-supervised contrastive learning approach, we investigate the classification of these speech sounds for the diagnosis of early-stage lung cancer. Our results show that it is possible to utilize naturally recorded speech sounds. Using the Graph Attention Transformer Fine-Tuning Contrastive Learning (GAT-ftCL) model, which leverages graph neural networks to capture complex relationships in data and fine-tunes the learning process through contrastive learning, we achieve an accuracy of 90.90% in distinguishing individuals diagnosed with lung cancer from healthy individuals. Furthermore, the model achieves a remarkable accuracy of 92.85% in specifically identifying individuals with early stage (stage 1) lung cancer within the stage 1 group and healthy individuals. These results underline the diagnostic potential of natural speech sounds, especially in the detection of early-stage lung cancer.","2024-10","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","96","","","","","","","","","","English","","","","WOS:001267722500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","Early-stage lung cancer detection; Relationship between speech patterns and lung cancer; Speech analysis in cancer diagnosis; Voice biomarkers for lung cancer detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EQEBUUF5","journalArticle","2024","do Nascimento, CH; Garcia, VC; Araújo, RD","A Word Sense Disambiguation Method Applied to Natural Language Processing for the Portuguese Language","IEEE OPEN JOURNAL OF THE COMPUTER SOCIETY","","2644-1268","10.1109/OJCS.2024.3396518","","Natural language processing (NLP) and artificial intelligence (AI) have advanced significantly in recent years, enabling the development of various tasks, such as machine translation, text summarization, sentiment analysis, and speech analysis. However, there are still challenges to overcome, such as natural language ambiguity. One of the problems caused by ambiguity is the difficulty of determining the proper meaning of a word in a specific context. For example, the word ""mouse"" can mean a computer peripheral or an animal, depending on the context. This limitation can lead to an incorrect semantic interpretation of the processed sentence. In recent years, language models (LMs) have provided a new impetus to NLP and AI, including in the task of word sense disambiguation (WSD). LMs are capable of learning and generating texts as they are trained on large amounts of data. However, in the Portuguese language, there are still few studies on WSD using LMs. Given this scenario, this article presents a method for WSD for the Portuguese language. To do this, it uses the BERTimbau language model, which is specific to the Portuguese. The results will be evaluated using the metrics established in the literature.","2024","2025-02-26 20:43:29","2025-02-26 20:43:29","","268-277","","","5","","","","","","","","","","English","","","","WOS:001230765700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Artificial intelligence; Computational modeling; Context modeling; Data models; language models; Libraries; natural language processing; Natural language processing; Task analysis; Training; word sense disambiguation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PGST735S","journalArticle","2025","Zhou, ZG; Ye, L; Cai, LH; Wang, L; Wang, YG; Wang, YH; Chen, W; Wang, Y","ConceptThread: Visualizing Threaded Concepts in MOOC Videos","IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS","","1077-2626","10.1109/TVCG.2024.3361001","","Massive Open Online Courses (MOOCs) platforms are becoming increasingly popular in recent years. Online learners need to watch the whole course video on MOOC platforms to learn the underlying new knowledge, which is often tedious and time-consuming due to the lack of a quick overview of the covered knowledge and their structures. In this article, we propose ConceptThread, a visual analytics approach to effectively show the concepts and the relations among them to facilitate effective online learning. Specifically, given that the majority of MOOC videos contain slides, we first leverage video processing and speech analysis techniques, including shot recognition, speech recognition and topic modeling, to extract core knowledge concepts and construct the hierarchical and temporal relations among them. Then, by using a metaphor of thread, we present a novel visualization to intuitively display the concepts based on video sequential flow, and enable learners to perform interactive visual exploration of concepts. We conducted a quantitative study, two case studies, and a user study to extensively evaluate ConceptThread. The results demonstrate the effectiveness and usability of ConceptThread in providing online learners with a quick understanding of the knowledge content of MOOC videos.","2025-02","2025-02-26 20:43:29","2025-02-26 20:43:29","","1354-1370","","2","31","","","","","","","","","","English","","","","WOS:001392823200003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","ANALYTICS; Computer aided instruction; Concept map; Data mining; Data visualization; Education; Electronic learning; MAPS; MOOC summarization; online learning; RETRIEVAL; SYSTEM; TOOL; Videos; Visual analytics; visualization in education","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NL5VR23D","journalArticle","2022","Salis, C; DeDe, G","Sentence Production in a Discourse Context in Latent Aphasia: A Real-Time Study","AMERICAN JOURNAL OF SPEECH-LANGUAGE PATHOLOGY","","1058-0360","10.1044/2022_AJSLP-21-00232","","Purpose: The purpose of this study was to improve our understanding as to which factors determine online, spoken sentence production abilities of adults with latent aphasia in a discourse context. Method: Discourse samples of the story of Cinderella elicited from Aphasia-Bank were analyzed with speech analysis software. Participants comprised people with latent and anomic aphasia as well as neurotypical controls (10 per group). Durations of pauses (silent and filled) were analyzed according to (a) the location they occurred (between or within sentences), (b) the syntactic complexity of sentences (simple, complex), and (c) sentence length (number of words). Statistical comparisons were conducted using mixed-effect models. Results: The two clinical groups (latent and anomic) differed from controls in the duration of pauses, both between and within sentences. Syntactic complexity did not exert an effect on either of the two clinical groups as compared with controls. As compared with controls, both clinical groups paused more before long in comparison with short sentences. Conclusion: Reduction in processing speed, which affects the ability to simultaneously maintain multiple linguistic and other cognitive demands associated with planning and monitoring of utterances, is a major factor that compromises sentence production in spoken discourse in latent aphasia.","2022-05","2025-02-26 20:43:29","2025-02-26 20:43:29","","1284-1296","","3","31","","","","","","","","","","English","","","","WOS:000797209200016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;100</p>","","","ADULT AGE-DIFFERENCES; INFORMATION; LANGUAGE; MEMORY; PAUSES; PLANNING UNITS; PROCESSING-SPEED; PROPOSITIONAL SPEECH; SPEAKERS; STROKE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RVKLQPNH","journalArticle","2021","Md Lazam, NA; Saparon, A","DEVELOPMENT OF ACADEMIC ATTENDANCE SYSTEM USING VOICE VERIFICATION","MALAYSIAN JOURNAL OF COMPUTER SCIENCE","","0127-9084","10.22452/mjcs.sp2021no1.10","","Based on the fact that all Human Voices are different, where every individual's voice contains unique characteristics that can be distinguished from others by using special analysis, voice verification can also be used for biometric recognition of individual. The aim of this project is to develop an automated attendance process captivating and student databases record maintaining using C++ programming and voice verification technique. The Input speech will undergo a series of voice recognition processes. The process starts with Feature extraction to obtain the attribute of voice. The features or specific characteristics for each voice are extracted by linear predictive coding technique (LPC) into feature vectors which later be used in speaker modeling. In speaker modeling stage the feature vectors of each speaker will be then processed by Gaussian Mixture Modeling (GMM) technique to generate speaker models and will be stored in a database. Verification process is done through template matching technique. Based on log-likelihood logic decision (template matching technique) with respect to the FAR (False Acceptance Rate) and FRR (False Rejection Rate), the identity of that speaker is accepted if the match is above the threshold. Once the verification result is accepted, the attendance in MySQL database for that speaker will be auto-updated.","2021","2025-02-26 20:43:29","2025-02-26 20:43:29","","106-120","","","","","","","","","","","","","English","","","","WOS:000733966600010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","attendance database; feature extraction; speaker modeling; Speech analysis; voice recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P5E43BN4","journalArticle","2024","Liu, GJ; Zhang, T; Liu, XN; Hou, XH; Ding, BY; Fu, DH; Pang, ZB","PVR-Vocoder: A Pathological Voice Repair Vocoder for Voice Disorders","IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS","","2168-2194","10.1109/JBHI.2023.3340738","","Vocoder-based speech synthesis has become a promising technique to accommodate the demands of high-quality speech analysis, manipulation, and synthesis. However, most existing works focus on how to synthesize normal human voice with high signal-to-noise ratio, neglecting individuals' pathological voice disorder in speech interaction. In this work, we propose a non-linear voice repair vocoder for pathological vowels and sentences, which takes the pathological speech as input and generates high-quality repaired speech. Our approach is specifically designed to enhance the speech quality and intelligibility for individuals with voice disorders. We employ amplitude modulated-frequency modulated (AM-FM) and Teager energy operation techniques to enhance the quality of pitch and spectral envelope. To tackle the instability and fracture problem of pitch, we present spectral tracking algorithm, which not only avoids dramatic change in the edge of voice, but also reduces the errors of half-pitch. Furthermore, we design a spectral reconstruction algorithm, which can effectively rebuild the spectral structure by energy operation to accomplish spectral envelope repair. The proposed PVR-Vocoder shows exceptional performance in pathological voice intelligibility enhancement according to various quality measures including objective indicators, subjective evaluation, and spectrum observations.","2024-04","2025-02-26 20:43:29","2025-02-26 20:43:29","","2270-2281","","4","28","","","","","","","","","","English","","","","WOS:001197865400044","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","CDC20; Mandarin sentences; multiple vowels; NEURAL-NETWORKS; Nonlinear processing; pathological voice repair","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3IQ38EI9","journalArticle","2025","Rios-Urrego, CD; Escobar-Grisales, D; Orozco-Arroyave, JR","Synchronous Analysis of Speech Production and Lips Movement to Detect Parkinson's Disease Using Deep Learning Methods","DIAGNOSTICS","","2075-4418","10.3390/diagnostics15010073","","Background/Objectives: Parkinson's disease (PD) affects more than 6 million people worldwide. Its accurate diagnosis and monitoring are key factors to reduce its economic burden. Typical approaches consider either speech signals or video recordings of the face to automatically model abnormal patterns in PD patients. Methods: This paper introduces, for the first time, a new methodology that performs the synchronous fusion of information extracted from speech recordings and their corresponding videos of lip movement, namely the bimodal approach. Results: Our results indicate that the introduced method is more accurate and suitable than unimodal approaches or classical asynchronous approaches that combine both sources of information but do not incorporate the underlying temporal information. Conclusions: This study demonstrates that using a synchronous fusion strategy with concatenated projections based on attention mechanisms, i.e., speech-to-lips and lips-to-speech, exceeds previous results reported in the literature. Complementary information between lip movement and speech production is confirmed when advanced fusion strategies are employed. Finally, multimodal approaches, combining visual and speech signals, showed great potential to improve PD classification, generating more confident and robust models for clinical diagnostic support.","2025-01","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","1","15","","","","","","","","","","English","","","","WOS:001393925400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","attention mechanisms; DIAGNOSIS; DISORDERS; fusion methods; lip movement analysis; Parkinson's disease; PROGRESSION; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D2K2BIV2","journalArticle","2023","Yang, L","Unsupervised machine learning and image recognition model application in English part-of-speech feature learning under the open platform environment","SOFT COMPUTING","","1432-7643","10.1007/s00500-023-08206-9","","The traditional English part-of-speech analysis model fails to meet people's actual needs due to the fact that the accuracy and other parameters are not up to standard. Facing large-scale English text data, quickly and accurately obtaining the key information needed and improving the efficiency and accuracy of clustering have always been the focus of attention. However, the inherent characteristics of English text make it impossible to accurately calculate the traditional feature weight calculation method, and its part of speech is difficult to recognize. Moreover, in order to obtain a structure closer to the real data, this paper fuses the norm graph and the k-nearest neighbor graph, proposes a new composition framework, and combines it with two common propagation algorithms to complete the classification task. In addition, in order to obtain the improvement effect of the algorithm, the algorithm is tested on the English text classification corpus data set of the natural language processing open platform, and a control experiment is set to analyze the model performance. Finally, this article combines mathematical statistics to process data and draw corresponding charts.","2023-07","2025-02-26 20:43:29","2025-02-26 20:43:29","","10013-10023","","14","27","","","","","","","","","","English","","","","WOS:000979478500005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;15</p>","","","ATTENTION MECHANISM; Image recognition; Machine learning; Part-of-speech recognition; Unsupervised learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"422AHJNX","journalArticle","2021","Anidjar, OH; Lapidot, I; Hajaj, C; Dvir, A; Gilad, I","Hybrid Speech and Text Analysis Methods for Speaker Change Detection","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2021.3093817","","Speaker Change Detection (SCD) is the task of segmenting an input audio-recording according to speaker interchanges. Nowadays, many applications, such as Speaker Diarization (SD) or automatic vocal transcription, depend on this segmentation task. In this paper, we focus on the essential task of the SD problem, the audio segmenting process, and suggest a solution for the SCD problem, as well as the assignment of clustered speaker labels for the extracted segments, and applying the solution over two datasets: a commercial dataset in Hebrew and the ICSI Meeting Corpus. As such, we propose a hybrid framework for the SCD problem that is learned by textual information and speech signals and the meta-data features that can be extracted from them. Moreover, we demonstrate the negative correlation between an increase in the number of speakers in the training dataset and the influence on the overall diarization system's performance, which is improved using our efficient SCD component. Finally, we show how our proposed hybrid framework remains robust compared to the ICSI Meeting Corpus, as the experimental evaluation's training and testing is based on two languages.","2021","2025-02-26 20:43:29","2025-02-26 20:43:29","","2324-2338","","","29","","","","","","","","","","English","","","","WOS:000675200800003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","Clustering algorithms; D-vectors; DIARIZATION; Encoding; Feature extraction; Mel frequency cepstral coefficient; SEGMENTATION; Speaker change detection; speaker diarization; speaker verification; speech analysis; Speech processing; Task analysis; Training","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E5JP3BWY","journalArticle","2022","Jacques, JCS Jr; Güçlütürk, Y; Pérez, M; Güçlü, U; Andujar, C; Baró, X; Escalante, HJ; Guyon, I; van Gerven, MAJ; van Lier, R; Escalera, S","First Impressions: A Survey on Vision-Based Apparent Personality Trait Analysis","IEEE TRANSACTIONS ON AFFECTIVE COMPUTING","","1949-3045","10.1109/TAFFC.2019.2930058","","Personality analysis has been widely studied in psychology, neuropsychology, and signal processing fields, among others. From the past few years, it also became an attractive research area in visual computing. From the computational point of view, by far speech and text have been the most considered cues of information for analyzing personality. However, recently there has been an increasing interest from the computer vision community in analyzing personality from visual data. Recent computer vision approaches are able to accurately analyze human faces, body postures and behaviors, and use these information to infer apparent personality traits. Because of the overwhelming research interest in this topic, and of the potential impact that this sort of methods could have in society, we present in this paper an up-to-date review of existing vision-based approaches for apparent personality trait recognition. We describe seminal and cutting edge works on the subject, discussing and comparing their distinctive features and limitations. Future venues of research in the field are identified and discussed. Furthermore, aspects on the subjectivity in data labeling/evaluation, as well as current datasets and challenges organized to push the research on the field are reviewed.","2022-01","2025-02-26 20:43:29","2025-02-26 20:43:29","","75-95","","1","13","","","","","","","","","","English","","","","WOS:000766268600007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;40<br/>Total Times Cited:&nbsp;&nbsp;41<br/>Cited Reference Count:&nbsp;&nbsp;123</p>","","","big-five; computer vision; EXTROVERSION; facial expression; firs impressions; gesture; JUDGMENTS; machine learning; multi-modal recognition; nonverbal signals; person perception; Personality computing; RECOGNITION; speech analysis; subjective bias","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y4UDN46E","journalArticle","2021","Zaidi, BF; Selouani, SA; Boudraa, M; Yakoub, MS","Deep neural network architectures for dysarthric speech analysis and recognition","NEURAL COMPUTING & APPLICATIONS","","0941-0643","10.1007/s00521-020-05672-2","","This paper investigates the ability of deep neural networks (DNNs) to improve the automatic recognition of dysarthric speech through the use of convolutional neural networks (CNNs) and long short-term memory (LSTM) neural networks. Dysarthria is one of the most common speech communication disorders associated with neurological impairments that can drastically reduce the intelligibility of speech. The aim of the present study is twofold. First, it compares three different input features for training and testing dysarthric speech recognition systems. These features are the mel-frequency cepstral coefficients (MFCCs), mel-frequency spectral coefficients (MFSCs), and the perceptual linear prediction features (PLPs). Second, the performance of the CNN- and LSTM-based architectures is compared against a state-of-the-art baseline system based on hidden Markov models (HMMs) and Gaussian mixture models (GMMs) to determine the best dysarthric speech recognizer. Experimental results show that the CNN-based system using perceptual linear prediction features provides a recognition rate that can reach 82%, which constitutes relative improvement of 11% and 32% when compared to the performance of LSTM- and GMM-HMM-based systems, respectively.","2021-08","2025-02-26 20:43:29","2025-02-26 20:43:29","","9089-9108","","15","33","","","","","","","","","","English","","","","WOS:000606448600005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;23<br/>Total Times Cited:&nbsp;&nbsp;24<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Convolutional neural network; Deep neural network; Gaussian mixture models; Hidden Markov model; Long short-term memory; Mel-frequency cepstral coefficient; Mel-frequency spectral coefficient; Perceptual linear prediction; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KNP42XY6","journalArticle","2021","Perrotin, O; Feugère, L; D'Alessandro, C","Perceptual equivalence of the Liljencrants-Fant and linear-filter glottal flow models","JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA","","0001-4966","10.1121/10.0005879","","Speech glottal flow has been predominantly described in the time-domain in past decades, the Liljencrants-Fant (LF) model being the most widely used in speech analysis and synthesis, despite its computational complexity. The causal/anti-causal linear model (LFCALM) was later introduced as a digital filter implementation of LF, a mixed-phase spectral model including both anti-causal and causal filters to model the vocal-fold open and closed phases, respectively. To further simplify computation, a causal linear model (LFLM) describes the glottal flow with a fully causal set of filters. After expressing these three models under a single analytic formulation, we assessed here their perceptual consistency, when driven by a single parameter R-d related to voice quality. All possible paired combinations of signals generated using six R-d levels for each model were presented to subjects who were asked whether the two signals in each pair differed. Model pairs LFLM-LFCALM were judged similar when sharing the same R-d value, and LF was considered the same as LFLM and LFCALM given a consistent shift in R-d. Overall, the similarity between these models encourages the use of the simpler and more computationally efficient models LFCALM and LFLM in speech synthesis applications.","2021-08","2025-02-26 20:43:29","2025-02-26 20:43:29","","1273-1285","","2","150","","","","","","","","","","English","","","","WOS:000687205900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","CASCADE; SEPARATION; VOICE QUALITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KXZBYCIL","journalArticle","2023","Northcutt, CG; Zha, SX; Lovegrove, S; Newcombe, R","EgoCom: A Multi-Person Multi-Modal Egocentric Communications Dataset","IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE","","0162-8828","10.1109/TPAMI.2020.3025105","","Multi-modal datasets in artificial intelligence (AI) often capture a third-person perspective, but our embodied human intelligence evolved with sensory input from the egocentric, first-person perspective. Towards embodied AI, we introduce the Egocentric Communications (EgoCom) dataset to advance the state-of-the-art in conversational AI, natural language, audio speech analysis, computer vision, and machine learning. EgoCom is a first-of-its-kind natural conversations dataset containing multi-modal human communication data captured simultaneously from the participants' egocentric perspectives. EgoCom includes 38.5 hours of synchronized embodied stereo audio, egocentric video with 240,000 ground-truth, time-stamped word-level transcriptions and speaker labels from 34 diverse speakers. We study baseline performance on two novel applications that benefit from embodied data: (1) predicting turn-taking in conversations and (2) multi-speaker transcription. For (1), we investigate Bayesian baselines to predict turn-taking within 5 percent of human performance. For (2), we use simultaneous egocentric capture to combine Google speech-to-text outputs, improving global transcription by 79 percent relative to a single perspective. Both applications exploit EgoCom's synchronous multi-perspective data to augment performance of embodied AI tasks.","2023-06-01","2025-02-26 20:43:29","2025-02-26 20:43:29","","6783-6793","","6","45","","","","","","","","","","English","","","","WOS:000982475600012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Artificial intelligence; communication; Computer vision; Education; Egocentric; EgoCom; embodied intelligence; human-centric; multi-modal data; Natural languages; Synchronization; Task analysis; turn-taking; VIDEOS; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JBD3ZDWQ","journalArticle","2023","Faragó, P; Stefaniga, SA; Cordos, CG; Mihaila, LI; Hintea, S; Pestean, AS; Beyer, M; Perju-Dumbrava, L; Ilesan, RR","CNN-Based Identification of Parkinson's Disease from Continuous Speech in Noisy Environments","BIOENGINEERING-BASEL","","2306-5354","10.3390/bioengineering10050531","","Parkinson's disease is a progressive neurodegenerative disorder caused by dopaminergic neuron degeneration. Parkinsonian speech impairment is one of the earliest presentations of the disease and, along with tremor, is suitable for pre-diagnosis. It is defined by hypokinetic dysarthria and accounts for respiratory, phonatory, articulatory, and prosodic manifestations. The topic of this article targets artificial-intelligence-based identification of Parkinson's disease from continuous speech recorded in a noisy environment. The novelty of this work is twofold. First, the proposed assessment workflow performed speech analysis on samples of continuous speech. Second, we analyzed and quantified Wiener filter applicability for speech denoising in the context of Parkinsonian speech identification. We argue that the Parkinsonian features of loudness, intonation, phonation, prosody, and articulation are contained in the speech, speech energy, and Mel spectrograms. Thus, the proposed workflow follows a feature-based speech assessment to determine the feature variation ranges, followed by speech classification using convolutional neural networks. We report the best classification accuracies of 96% on speech energy, 93% on speech, and 92% on Mel spectrograms. We conclude that the Wiener filter improves both feature-based analysis and convolutional-neural-network-based classification performances.","2023-04-26","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","5","10","","","","","","","","","","English","","","","WOS:000995594600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","artificial intelligence; continuous speech; convolutional neural networks; hypokinetic dysarthria; noisy speech; Parkinson's disease; pre-diagnosis; spectrograms; speech assessment; Wiener filter","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N4SKDJLL","journalArticle","2024","Hu, SJ; Xie, XR; Geng, MZ; Jin, ZR; Deng, JJ; Li, GA; Wang, Y; Cui, MY; Wang, TZ; Meng, HL; Liu, XY","Self-Supervised ASR Models and Features for Dysarthric and Elderly Speech Recognition","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2024.3422839","","Self-supervised learning (SSL) based speech foundation models have been applied to a wide range of ASR tasks. However, their application to dysarthric and elderly speech via data-intensive parameter fine-tuning is confronted by in-domain data scarcity and mismatch. To this end, this paper explores a series of approaches to integrate domain fine-tuned SSL pre-trained models and their features into TDNN and Conformer ASR systems for dysarthric and elderly speech recognition. These include: a) input feature fusion between standard acoustic frontends and domain fine-tuned SSL speech representations; b) frame-level joint decoding between TDNN systems separately trained using standard acoustic features alone and those with additional domain fine-tuned SSL features; and c) multi-pass decoding involving the TDNN/Conformer system outputs to be rescored using domain fine-tuned pre-trained ASR models. In addition, fine-tuned SSL speech features are used in acoustic-to-articulatory (A2A) inversion to construct multi-modal ASR systems. Experiments are conducted on four tasks: the English UASpeech and TORGO dysarthric speech corpora; and the English DementiaBank Pitt and Cantonese JCCOCC MoCA elderly speech datasets. The TDNN systems constructed by integrating domain-adapted HuBERT, wav2vec2-conformer or multi-lingual XLSR models and their features consistently outperform the standalone fine-tuned SSL pre-trained models. These systems produced statistically significant WER or CER reductions of 6.53%, 1.90%, 2.04% and 7.97% absolute (24.10%, 23.84%, 10.14% and 31.39% relative) on the four tasks respectively. Consistent improvements in Alzheimer's Disease detection accuracy are also obtained using the DementiaBank Pitt elderly speech recognition outputs.","2024","2025-02-26 20:43:29","2025-02-26 20:43:29","","3561-3575","","","32","","","","","","","","","","English","","","","WOS:001283673700008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;129</p>","","","Acoustics; ADAPTATION; ALZHEIMERS DEMENTIA; Data models; Decoding; DISEASE; DOMAIN; Dysarthric Speech; Elderly Speech; GESTURES; HuBERT; Multi-lingual XLSR; Older adults; Pre-trained ASR System; Speech recognition; Standards; Task analysis; ULTRASOUND; Wav2vec2.0","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6E5ULRSR","journalArticle","2023","Hong, YT; Chen, S; Zhou, F; Chan, AE; Tang, TM","Phonetic entrainment in L2 human-robot interaction: an investigation of children with and without autism spectrum disorder","FRONTIERS IN PSYCHOLOGY","","1664-1078","10.3389/fpsyg.2023.1128976","","Phonetic entrainment is a phenomenon in which people adjust their phonetic features to approach those of their conversation partner. Individuals with Autism Spectrum Disorder (ASD) have been reported to show some deficits in entrainment during their interactions with human interlocutors, though deficits in terms of significant differences from typically developing (TD) controls were not always registered. One reason related to the inconsistencies of whether deficits are detected or not in autistic individuals is that the conversation partner's speech could hardly be controlled, and both the participants and the partners might be adjusting their phonetic features. The variabilities in the speech of conversation partners and various social traits exhibited might make the phonetic entrainment (if any) of the participants less detectable. In this study, we attempted to reduce the variability of the interlocutors by employing a social robot and having it do a goal-directed conversation task with children with and without ASD. Fourteen autistic children and 12 TD children participated the current study in their second language English. Results showed that autistic children showed comparable vowel formants and mean fundamental frequency (f0) entrainment as their TD peers, but they did not entrain their f0 range as the TD group did. These findings suggest that autistic children were capable of exhibiting phonetic entrainment behaviors similar to TD children in vowel formants and f0, particularly in a less complex situation where the speech features and social traits of the interlocutor were controlled. Furthermore, the utilization of a social robot may have increased the interest of these children in phonetic entrainment. On the other hand, entrainment of f0 range was more challenging for these autistic children even in a more controlled situation. This study demonstrates the viability and potential of using human-robot interactions as a novel method to evaluate abilities and deficits in phonetic entrainment in autistic children.","2023-06-19","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","14","","","","","","","","","","English","","","","WOS:001020512700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","ADULTS; ALIGNMENT; autism; BEHAVIOR; children; controlled speech; conversation task; HIGH-FUNCTIONING AUTISM; phonetic entrainment; PITCH; RHYTHM; robot; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CAC7NIZF","journalArticle","2023","Imbalzano, G; Rinaldi, D; Calandra-Buonaura, G; Contin, M; Amato, F; Giannini, G; Sambati, L; Ledda, C; Romagnolo, A; Olmo, G; Cortelli, P; Zibetti, M; Lopiano, L; Artusi, CA","How resistant are levodopa-resistant axial symptoms? Response of freezing, posture, and voice to increasing levodopa intestinal infusion rates in Parkinson disease","EUROPEAN JOURNAL OF NEUROLOGY","","1351-5101","10.1111/ene.15558","","Background and purpose Treatment of freezing of gait (FoG) and other Parkinson disease (PD) axial symptoms is challenging. Systematic assessments of axial symptoms at progressively increasing levodopa doses are lacking. We sought to analyze the resistance to high levodopa doses of FoG, posture, speech, and altered gait features presenting in daily-ON therapeutic condition. Methods We performed a pre-/postinterventional study including patients treated with levodopa/carbidopa intestinal gel infusion (LCIG) with disabling FoG in daily-ON condition. Patients were evaluated at their usual LCIG infusion rate (T1), and 1 h after 1.5x (T2) and 2x (T3) increase of the LCIG infusion rate by quantitative outcome measures. The number of FoG episodes (primary outcome), posture, speech, and gait features were objectively quantified during a standardized test by a blinded rater. Changes in motor symptoms, dyskinesia, and plasma levodopa concentrations were also analyzed. Results We evaluated 16 patients with a mean age of 69 +/- 9.4 years and treated with LCIG for a mean of 2.2 +/- 2.1 years. FoG improved in 83.3% of patients by increasing the levodopa doses. The number of FoG episodes significantly decreased (mean = 2.3 at T1, 1.7 at T2, 1.2 at T3; p = 0.013). Posture and speech features did not show significant changes, whereas stride length (p = 0.049), turn duration (p = 0.001), and turn velocity (p = 0.024) significantly improved on doubling the levodopa infusion rate. Conclusions In a short-term evaluation, the increase of LCIG dose can improve ""dopa-resistant"" FoG and gait issues in most advanced PD patients with overall good control of motor symptoms in the absence of clinically significant dyskinesia.","2023-01","2025-02-26 20:43:29","2025-02-26 20:43:29","","96-106","","1","30","","","","","","","","","","English","","","","WOS:000866123700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","axial symptoms; CLINICAL DIAGNOSTIC-CRITERIA; DEMENTIA; DISORDER; DYSKINESIA RATING-SCALE; freezing of gait; GAIT; GEL; levodopa; ONSET; Parkinson disease; posture; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AJAZNCWU","journalArticle","2024","Ahmad, R; Iqbal, A; Jadoon, MM; Ahmad, N; Javed, Y","XEmoAccent: Embracing Diversity in Cross-Accent Emotion Recognition Using Deep Learning","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3376379","","Speech is a powerful means to expressing thoughts, emotions, and perspectives. However, accurately determining the emotions conveyed through speech remains a challenging task. Existing manual methods for analyzing speech to recognize emotions are prone to errors, limiting our understanding and response to individuals' emotional states. To address diverse accents, an automated system capable of real-time emotion prediction from human speech is needed. This paper introduces a speech emotion recognition (SER) system that leverages supervised learning techniques to tackle cross-accent diversity. Distinctively, the system extracts a comprehensive set of nine speech features-Zero Crossing Rate, Mel Spectrum, Pitch, Root Mean Square values, Mel Frequency Cepstral Coefficients, chroma-stft, and three spectral features (Centroid, Contrast, and Roll-off) for refined speech signal processing and recognition. Seven machine learning models are employed, encompassing Random Forest, Logistic Regression, Decision Tree, Support Vector Machines, Gaussian Naive Bayes, K-Nearest Neighbors, ensemble learning, and four individual, hybrid deep learning models including Long short-term memory (LSTM) and 1-Dimensional Convolutional Neural Network (1D-CNN) with stratified cross-validation. Audio samples from diverse English regions are combined to train the models. The performance evaluation results of conventional machine learning and deep learning models indicate that the Random Forest-based feature selection model achieves the highest accuracy of up to 76% among the conventional machine learning models. Simultaneously, the 1D-CNN model with stratified cross-validation reaches up to 99% accuracy. The proposed framework enhances the cross-accent emotion recognition accuracy up to 86.3%, 89.87%, 90.27%, and 84.96% by margins of 14.71%, 10.15%, 9.6%, and 16.52% respectively.","2024","2025-02-26 20:43:29","2025-02-26 20:43:29","","41125-41142","","","12","","","","","","","","","","English","","","","WOS:001192210900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","1-dimensional convolutional neural networks (1D-CNN); decision tree (DT); deep learning; FEATURES; K-nearest neighbors (KNN); logistic regression (LR); Machine learning; random forest (RF); speech emotion recognition (SER); support vector machines (SVM)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VLDY3SBQ","journalArticle","2023","Lu, C; Zheng, WM; Lian, HL; Zong, Y; Tang, CA; Li, SA; Zhao, Y","Speech Emotion Recognition via an Attentive Time-Frequency Neural Network","IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS","","2329-924X","10.1109/TCSS.2022.3219825","","Spectrogram is commonly used as the input feature of deep neural networks to learn the high(er)-level time- frequency pattern of speech signal for speech emotion recognition (SER). Generally, different emotions correspond to specific energy activations both within frequency bands and time frames on spectrogram, which indicates the frequency and time domains are both essential to represent the emotion for SER. However, recent spectrogram-based works mainly focus on modeling the long-term dependency in time domain, which makes these methods suffer from the following issues: 1) neglecting to model the emotion-related correlations within frequency domain during the time-frequency joint learning and 2) ignoring to capture the specific frequency bands associated with emotions. To cope with the issues, we propose an attentive time-frequency neural network (ATFNN) for SER, including a time-frequency neural network (TFNN) and time-frequency attention. Specifically, aiming at the first issue, we design a TFNN with a frequency-domain encoder (F-Encoder) based on the Transformer encoder and a time-domain encoder (T-Encoder) based on the bidirectional long short-term memory (Bi-LSTM). The F-Encoder and T-Encoder model the correlations within frequency bands and time frames, respectively, and they are embedded into a time-frequency joint learning strategy to obtain the time-frequency patterns of speech emotions. Moreover, to handle the second issue, we adopt the time-frequency attention with a frequency-attention network (F-Attention) and a time-attention network (T-Attention) to focus on the emotion-related long-range dependencies between frequency bands and across time frames, which can enhance the emotional discrimination of speech features. Extensive experimental results on three public emotional databases, i.e., IEMOCAP, ABC, and CASIA, show that our proposed ATFNN outperforms the state-of-the-art methods.","2023-12","2025-02-26 20:43:29","2025-02-26 20:43:29","","3159-3168","","6","10","","","","","","","","","","English","","","","WOS:000896629900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Attention mechanism; FEATURES; spectrogram; speech emotion recognition (SER); time-frequency neural network (TFNN)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J9LTL9K4","journalArticle","2023","Paul, B; Phadikar, S","A novel pre-processing technique of amplitude interpolation for enhancing the classification accuracy of Bengali phonemes","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-022-13594-5","","In linguistics, phonemes are the atomic sound, called word segmentor play an important role to recognize the word properly. A novel approach of seven Bengali vowels and ten diphthongs (a syllable for the pronunciation of two consecutive vowels) phoneme recognition has been proposed in the paper. In the proposed method, before extracting the feature, a novel pre-processing technique using amplitude interpolation method has been developed to align the starting point of all the phonemes of the same class which in turn boosts the recognition rate. Here seven Bengali vowels and ten diphthongs audio clips uttered by twenty persons (ten times each) of different age group and sex have been recorded to create a data set of 3400 audio samples for the proposed experiment. For each class of phonemes and diphthongs one sample (selected by linguistic) have been considered as a benchmark. Then each of the recorded audio clips is interpolated to match with the benchmark clip of the corresponding phoneme by finding the valleys in the amplitude using Lagrange interpolation technique. After that, 19 MFCC (Mel Frequency Cepstral Co-Efficient) speech features have been extracted from each phoneme of the interpolated audio clips and feed to classify using Support Vector Machine (SVM), k- Nearest Neighbour (KNN) and Deep Neural Network (DNN) classifier and the average classification accuracy obtained for vowels and diphthongs are 94.93% and 94.56% respectively. To check the effectiveness of the proposed pre-processing technique same MFCC features have been extracted from the raw recorded phonemes and feed to same classifiers and average accuracy obtained for vowels and diphthongs are 89.21% and 88.56% respectively which shows the effectiveness of the proposed method. It is also to note that best accuracy obtained using the DNN classifier with the accuracy of 98.16% for vowels and 97% for diphthongs.","2023-02","2025-02-26 20:43:29","2025-02-26 20:43:29","","7735-7755","","5","82","","","","","","","","","","English","","","","WOS:000837148800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","CORPUS; Deep neural network; Diphthong; Lagrange interpolation; Mel frequency cepstral coefficient; Phoneme; RECOGNITION; SPEECH; Support vector machine","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DDJP2KHH","journalArticle","2024","Ullah, S; Kim, DH","Multiaccent EMG-to-Speech Optimized Transduction With PerFL and MAML Adaptations","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2024.3449948","","Silent speech voicing enables individuals with speech impairments to communicate solely through facial muscle movements, bypassing the need for vocalization. Typically, electromyography (EMG) is utilized in conjunction with voice signals from individuals with normal speech for training purposes. Existing studies are targeting single accent using a single acquisition device, ignoring multiple accents from diverse ethnic backgrounds which can pose challenges in developing generalized and adaptive solutions. To address this, we propose a comprehensive approach consisting of the following: 1) a multiaccent EMG-to-speech silent voicing dataset; 2) an optimized transduction model (EMG-to-speech features); 3) a model-agnostic meta-learning (MAML) approach to adapt across cross-accented data; and 4) a personalized federated learning (PerFL) solution that utilizes MAML initialization to enhance global model convergence. Our novel transduction model incorporates three key elements: 1) convolution layers with a Squeeze-and-Excitation network to enhance channel-wise interdependencies (feature recalibration); 2) a gating multilayer perceptron to enhance global context awareness by linear projections along channel dimensions; and 3) transformers that learn temporal features across time series (EMG). We validated our novel algorithm using publicly available and proprietary (from our research laboratory) datasets. To simulate real-world conditions, a proprietary dataset was generated using three different biosignal devices, yielding heterogeneous data with 1370 utterances involving eight subjects with three distinct accents. Our proposed transduction model outperformed traditional methods, with 1.3%-3.5% improvements in the word error rate (WER) on the public dataset. Moreover, we studied the impact of two different MAML variants and their impact on PerFL initialization. Detailed results, encompassing various performance metrics such as confusability, accuracy, character-error-rate (CER), and WER, are presented for both public and proprietary datasets.","2024","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","73","","","","","","","","","","English","","","","WOS:001311251000006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","Electromyography (EMG); EMG-to-speech; meta-learning; personalized federated learning (PerFL); SILENT SPEECH; silent speech interface; transformers; voice synthesis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NHIXLTQW","journalArticle","2023","Zhang, BY; Sandaran, SC; Feng, J","The ecological discourse analysis of news discourse based on deep learning from the perspective of ecological philosophy","PLOS ONE","","1932-6203","10.1371/journal.pone.0280190","","Recently, ecological damage and environmental pollution have become increasingly serious. Experts in various fields have started to study related issues from diverse points of view. To prevent the accelerated deterioration of the ecological environment, ecolinguistics emerged. Eco-critical discourse analysis is one of the important parts of ecolinguistics research, that is, it is a critical discourse analysis of the use of language from the perspective of the language's ecological environment. Firstly, an ecological tone and modality system are constructed from an ecological perspective. Under the guidance of the ecological philosophy of ""equality, harmony, and symbiosis"", this study conducts an ecological discourse analysis on the Sino-US trade friction reports, aiming to present the similarities and differences between the two newspapers' trade friction discourses and to reveal the ecological significance of international ecological factors in the discourse. Secondly, this method establishes a vector expression of abstract words based on emotion dictionary resources and introduces emotion polarity and part-of-speech features of words. Then the word vector is formed into the text feature matrix, which is used as the input of the Convolutional Neural Network (CNN) model, and the Back Propagation algorithm is adopted to train the model. Finally, in the light of the trained CNN model, the unlabeled news is predicted, and the experimental results are analyzed. The results reveal that during the training process of Chinese and English datasets, the accuracy of the training set can reach nearly 100%, and the loss rate can be reduced to 0. On the test set, the classification accuracy of Chinese text can reach 83%, while that of English text can reach 90%, and the experimental results are ideal. This study provides an explanatory approach for ecological discourse analysis on the news reports of Sino-US trade frictions and has certain guiding significance for the comparative research on political news reports under different ideologies between China and the United States.","2023-01-25","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","1","18","","","","","","","","","","English","","","","WOS:000945500300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","CLIMATE-CHANGE; ENERGY; MEDIA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SHSWHRI9","journalArticle","2022","Na, YM; Joo, H; Trang, LT; Quan, LDA; Woo, J","Objective speech intelligibility prediction using a deep learning model with continuous speech-evoked cortical auditory responses","FRONTIERS IN NEUROSCIENCE","","1662-453X","10.3389/fnins.2022.906616","","Auditory prostheses provide an opportunity for rehabilitation of hearing-impaired patients. Speech intelligibility can be used to estimate the extent to which the auditory prosthesis improves the user's speech comprehension. Although behavior-based speech intelligibility is the gold standard, precise evaluation is limited due to its subjectiveness. Here, we used a convolutional neural network to predict speech intelligibility from electroencephalography (EEG). Sixty-four-channel EEGs were recorded from 87 adult participants with normal hearing. Sentences spectrally degraded by a 2-, 3-, 4-, 5-, and 8-channel vocoder were used to set relatively low speech intelligibility conditions. A Korean sentence recognition test was used. The speech intelligibility scores were divided into 41 discrete levels ranging from 0 to 100%, with a step of 2.5%. Three scores, namely 30.0, 37.5, and 40.0%, were not collected. The speech features, i.e., the speech temporal envelope (ENV) and phoneme (PH) onset, were used to extract continuous-speech EEGs for speech intelligibility prediction. The deep learning model was trained by a dataset of event-related potentials (ERP), correlation coefficients between the ERPs and ENVs, between the ERPs and PH onset, or between ERPs and the product of the multiplication of PH and ENV (PHENV). The speech intelligibility prediction accuracies were 97.33% (ERP), 99.42% (ENV), 99.55% (PH), and 99.91% (PHENV). The models were interpreted using the occlusion sensitivity approach. While the ENV models' informative electrodes were located in the occipital area, the informative electrodes of the phoneme models, i.e., PH and PHENV, were based on the occlusion sensitivity map located in the language processing area. Of the models tested, the PHENV model obtained the best speech intelligibility prediction accuracy. This model may promote clinical prediction of speech intelligibility with a comfort speech intelligibility test.","2022-08-18","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","16","","","","","","","","","","English","","","","WOS:000853253400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","ALGORITHM; COCHLEAR-IMPLANT USERS; COMPREHENSION; continuous speech; deep-learning; EEG; EEG DATA; ENTRAINMENT; LISTENERS; NEURAL-NETWORK; NOISE; occlusion sensitivity; PERCEPTION; SELECTION; speech intelligibility","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FG43PBJB","journalArticle","2024","Nong, CQ; Zou, H; Zhang, JF; Liu, JH; Shao, PF; Jiang, JW; Xie, J","A MULTI-LEVEL POWER GRID ENHANCED IDENTITY AUTHENTICATION DATA MANAGEMENT PLATFORM BASED ON FILTERING ALGORITHMS","SCALABLE COMPUTING-PRACTICE AND EXPERIENCE","","1895-1767","10.12694/scpe.v25i3.2679","","In response to the optimal extraction of DCT coefficients in facial images, the author proposes a DCT coefficient extraction method based on discriminant analysis. Based on the discriminant analysis of DCT coefficients, the DCT coefficients with high discriminant values are selected as features. Comparing the DPA based discrete cosine coefficient selection method proposed by the author with the traditional Zigzag discrete cosine coefficient selection method, experiments were conducted on the ORL face database and the Yale face database, respectively. The recognition performance on the ORL face database was higher than that on the Yale face database, as the facial image expression and lighting changes in the ORL database were relatively few, making it suitable for extracting key features. In response to the problem that the speech parameter MFCC is greatly affected by noise and can only reflect the static characteristics of speech, the author extracted gamma pass filtering cepstrum coefficients with human auditory characteristics and gamma pass sliding differential cepstrum coefficients that can reflect the dynamic characteristics of speech based on gamma tone filters and sliding differential cepstrum. In the NUST603 speech database, under pure background, the recognition rate based on GFSDCC features reached 89.88%, and the recognition effect based on GFCC features was 87.52%, which is 4.66% and 2.36% higher than that based on MFCC features. In noisy environments, the average recognition rates of speaker recognition systems based on GFCC and GFSDCC are 56.06% and 59.07%, while the average recognition rates of speaker recognition systems based on MFCC speech features are 53.89%, 2.17% and 5.18% higher, respectively. The gain in this recognition effect comes from the characteristics of the auditory model, as the Gammatone filter effectively reflects the noise resistance of the human auditory system.","2024-04-12","2025-02-26 20:43:29","2025-02-26 20:43:29","","1508-1516","","3","25","","","","","","","","","","English","","","","WOS:001206408600019","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","CHALLENGES; Data management; Enhanced identity authentication; Filtering; Multi level","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SZKRGG83","journalArticle","2024","Wang, MS; Ma, HB; Wang, YL; Sun, XH","Design of smart home system speech emotion recognition model based on ensemble deep learning and feature fusion","APPLIED ACOUSTICS","","0003-682X","10.1016/j.apacoust.2024.109886","","In the realm of consumer technology, Artificial Intelligence (AI) -based Speech Emotion Recognition (SER) has rapidly gained traction and integration into smart home systems. Its precision in recognition has become a pivotal factor significantly impacting user experience. However, the intricate task of selecting suitable features has emerged as a daunting challenge due to the variances in speech features induced by emotional nuances. Present research predominantly concentrates on localized speech characteristics, neglecting the broader contextual cues inherent in speech signals. This oversight contributes to relatively diminished accuracy in emotion recognition within smart home systems. To tackle this challenge, this paper introduces an enhanced Speech Emotion Recognition approach named TF-Mix. This methodology enriches emotional prediction from speech by leveraging audio data augmentation and embracing multiple features, thereby achieving superior performance in emotion recognition. To augment the model's adaptability, TF-Mix adeptly amalgamates various feature extraction techniques, encompassing Convolutional Neural Networks (CNNs), Long Short -Term Memory networks (LSTMs), and Transformer architecture. The synergy among these methodologies culminates in the formulation of three distinct architectural models. The primary architecture is founded on a 1 -dimensional Convolutional Neural Network (CNN), closely followed by a Fully Connected Network (FCN). Subsequent architectures, notably BiLSTM-FCN and BiLSTM-Transformer-FCN, retain their respective structures while incorporating CNNs. Moreover, the amalgamation of individual models into an ensemble model, designated as D, via weighted averaging, further amplifies the efficacy of emotion recognition. Experimental outcomes showcase exceptional performance across all four models in the SER task. The ensemble Model D achieves noteworthy accuracy across multiple datasets: 87.513% on RAVDESS, 86.233% on SAVEE, 99.857% on TESS, 82.295% on CREMA-D, and 97.546% on the TOTAL dataset.","2024-03-15","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","","218","","","","","","","","","","English","","","","WOS:001174122800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","Bidirectional long short-term memory network; Convolutional neural network; Data augmentation; Ensemble learning; Feature fusion; FEATURE-EXTRACTION; REPRESENTATION; Smart home; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LEFEBL6M","journalArticle","2024","Kara, I; Mutlu, AI; Miraloglu, K","Comparison of Participation in Online Games and Communication Experiences of School-Age Children Who Do and Do not Stutter: Exploratory Study","FOLIA PHONIATRICA ET LOGOPAEDICA","","1021-7762","10.1159/000535296","","Introduction: Online games provide a socializing environment for children aged 8-10 years, but there is a lack of information in the literature about whether children who stutter access online gaming environments as frequently as their non-affected peers and about their interaction habits. This study aimed to investigate the participation frequency of school-age children who do and do not stutter in online games, the speech characteristics during games, and whether they encountered bullying-like behaviors during games. Methods: A total of 91 children who stutter (F/M = 18/73; age range = 8-13) and 116 children who do not stutter (F/M = 60/56; age range 8-13) participated in this study. Children's participation habits in online, chat-based, multiplayer, games were evaluated with web-based questionnaires. Differences between questionnaire responses were analyzed using the significance test for a difference in two proportions. Results: There was no significant difference between the participation rates of children who do and do not stutter in online games (z = 1.46; p = 0.14), their frequency (p > 0.05) and the time they spent in the game (p > 0.05). It was found that those who stutter preferred to use one-word expressions more than their peers who do not stutter (z = 2.03; p = 0.04), and those who stutter had higher rates of not encountering bullying-like behaviors in online games than those who do not stutter (z = 2.2; p = 0.03). Discussion/Conclusion: Children who do and do not stutter show similar participation habits in online, chat-based, multiplayer games with similar frequency, and duration. Speech features that emerge in online games, and whether these games play a role in providing children who stutter a communication environment where the risk of bullying is reduced and fluency is increased may be the subject of future research.","2024-09","2025-02-26 20:43:29","2025-02-26 20:43:29","","431-439","","5","76","","","","","","","","","","English","","","","WOS:001111194900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","bullying; game; online; speech; stuttering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CU3MQHNP","journalArticle","2023","Park, HY; Lee, YH; Chun, C","Perturbation AUTOVC: Voice Conversion From Perturbation and Autoencoder Loss","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3341434","","AUTOVC is a voice-conversion method that performs self-reconstruction using an autoencoder structure for zero-shot voice conversion. AUTOVC has the advantage of being easy and simple to learn because it only uses the autoencoder loss for learning. However, it performs voice conversion by disentangling speech information from speakers and linguistic information by adjusting the bottleneck dimension; this requires highly meticulous fine tuning of the bottleneck dimension and involves a tradeoff between speech quality and speaker similarity. To address these issues, neural analysis and synthesis (NANSY)-a fully self-supervised learning system that uses perturbations to extract speech features-is proposed. NANSY solves the problem of the adjustment of the bottleneck dimension by utilizing perturbation and exhibits high-reconstruction performance. In this study, we propose perturbation AUTOVC, a voice conversion method that utilizes the structure of AUTOVC and the perturbation of NANSY. The proposed method applies perturbations to speech signals (such as NANSY signals) to solve the problem of the voice conversion method using bottleneck dimensions. Perturbation is applied to remove the speaker-dependent information present in the speech, leaving only the linguistic information, which is then passed through a content encoder and modeled as a content embedding containing only the linguistic information. To obtain speaker information, we used x-vectors, which are extensively used in pretrained speaker recognition. The concatenated linguistic and speaker information extracted from the encoder and additional energy information is used as input to the decoder to perform self-reconstruction. Similar to AUTOVC, it is easy and simple to learn using only the autoencoder loss. For the evaluation, we measured three objective evaluation metrics: character error rate (%), cosine similarity, and short-time objective intelligibility, as well as a subjective evaluation metric: mean opinion score. The experimental results demonstrate that our proposed method outperforms other voice conversion techniques and demonstrated robust performance in zero-shot conversion.","2023","2025-02-26 20:43:29","2025-02-26 20:43:29","","140174-140185","","","11","","","","","","","","","","English","","","","WOS:001131605400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","Autoencoder; information perturbation; NETWORKS; speech signal processing; voice conversion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZMRVX456","journalArticle","2021","Albuquerque, L; Valente, ARS; Teixeira, A; Figueiredo, D; Sa-Couto, P; Oliveira, C","Association between acoustic speech features and non-severe levels of anxiety and depression symptoms across lifespan","PLOS ONE","","1932-6203","10.1371/journal.pone.0248842","","Background Several studies have investigated the acoustic effects of diagnosed anxiety and depression. Anxiety and depression are not characteristics of the typical aging process, but minimal or mild symptoms can appear and evolve with age. However, the knowledge about the association between speech and anxiety or depression is scarce for minimal/mild symptoms, typical of healthy aging. As longevity and aging are still a new phenomenon worldwide, posing also several clinical challenges, it is important to improve our understanding of non-severe mood symptoms' impact on acoustic features across lifetime. The purpose of this study was to determine if variations in acoustic measures of voice are associated with non-severe anxiety or depression symptoms in adult population across lifetime. Methods Two different speech tasks (reading vowels in disyllabic words and describing a picture) were produced by 112 individuals aged 35-97. To assess anxiety and depression symptoms, the Hospital Anxiety Depression Scale (HADS) was used. The association between the segmental and suprasegmental acoustic parameters and HADS scores were analyzed using the linear multiple regression technique. Results The number of participants with presence of anxiety or depression symptoms is low (>7: 26.8% and 10.7%, respectively) and non-severe (HADS-A: 5.4 +/- 2.9 and HADS-D: 4.2 +/- 2.7, respectively). Adults with higher anxiety symptoms did not present significant relationships associated with the acoustic parameters studied. Adults with increased depressive symptoms presented higher vowel duration, longer total pause duration and short total speech duration. Finally, age presented a positive and significant effect only for depressive symptoms, showing that older participants tend to have more depressive symptoms. Conclusions Non-severe depression symptoms can be related to some acoustic parameters and age. Depression symptoms can be explained by acoustic parameters even among individuals without severe symptom levels.","2021-04-08","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","4","16","","","","","","","","","","English","","","","WOS:000639359600027","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;93</p>","","","AGE; DISORDERS; EMOTION; FEAR; FUNDAMENTAL-FREQUENCY; HOSPITAL ANXIETY; PAUSE TIME; PSYCHOMOTOR RETARDATION; VALIDITY; VOCAL INDICATORS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F4GHBZRW","journalArticle","2021","Azadi, H; Akbarzadeh-T, MR; Kobravi, HR; Shoeibi, A","Robust Voice Feature Selection Using Interval Type-2 Fuzzy AHP for Automated Diagnosis of Parkinson's Disease","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2021.3097215","","Goal: Human voice is a promising noninvasive indicator for diagnosing Parkinson's Disease (PD). It is also unique since it can be collected remotely, increasing accessibility to a wide range of underprivileged patients. However, recognizing PD's signature in the human voice is nontrivial since the available features are many, and the signal may be noisy. Methods: A new mechanism based on Interval Type-2 Fuzzy Analytical Hierarchy Process is proposed here for choosing a reduced feature set from 339 dysphonia speech features, based on five criteria of 1) Robustness, 2) Relief, 3) Minimum Redundancy and Maximum Relevance, 4) Gaussian mixture model separation, and 5) Classifier separation ability. A Least Squares Support Vector Machine then categorizes the samples as belonging to either a healthy subject or a patient with PD. The database of 47 subjects with an average age of 67 is obtained from the elderly in nursing homes and Parkinson's specialized clinics. By reducing signal quality similar to a standard phone line, we study the teleoperation prospect of the proposed technique. Results: Ten-fold cross-validation shows an overall accuracy of 95.32%(93.11%) for noiseless(noisy) conditions, with separate analysis for male, female, and both genders populations. Furthermore, Leave-One-Speaker-Out analysis yields an overall accuracy of 93.11%(84.61%) for noiseless(noisy) conditions. Conclusion: The proposed strategy offers viable remote PD diagnosis with higher accuracy for the male population. Significance: The proposed method suggests reduced feature sets that meet differing objectives of simplicity, performance, and robustness. Results could be particularly significant in PD diagnosis in remote areas.","2021","2025-02-26 20:43:29","2025-02-26 20:43:29","","2792-2802","","","29","","","","","","","","","","English","","","","WOS:000692883100004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","ALGORITHMS; Analytical hierarchy process; DISORDERS; DYSPHONIA MEASUREMENTS; Feature extraction; feature selection; Fuzzy sets; Human voice; IMPAIRMENT; interval type-2 fuzzy sets; Parkinson's disease; PATHOLOGY; REGRESSION; SETS; Sociology; speech signal processing; Statistics; Uncertainty","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GH94BXMS","journalArticle","2022","Islam, MR; Akhand, MAH; Kamal, MAS; Yamada, K","Recognition of Emotion with Intensity from Speech Signal Using 3D Transformed Feature and Deep Learning","ELECTRONICS","","2079-9292","10.3390/electronics11152362","","A AbstractSpeech Emotion Recognition (SER), the extraction of emotional features with the appropriate classification from speech signals, has recently received attention for its emerging social applications. Emotional intensity (e.g., Normal, Strong) for a particular emotional expression (e.g., Sad, Angry) has a crucial influence on social activities. A person with intense sadness or anger may fall into severe disruptive action, eventually triggering a suicidal or devastating act. However, existing Deep Learning (DL)-based SER models only consider the categorization of emotion, ignoring the respective emotional intensity, despite its utmost importance. In this study, a novel scheme for Recognition of Emotion with Intensity from Speech (REIS) is developed using the DL model by integrating three speech signal transformation methods, namely Mel-frequency Cepstral Coefficient (MFCC), Short-time Fourier Transform (STFT), and Chroma STFT. The integrated 3D form of transformed features from three individual methods is fed into the DL model. Moreover, under the proposed REIS, both the single and cascaded frameworks with DL models are investigated. A DL model consists of a 3D Convolutional Neural Network (CNN), Time Distribution Flatten (TDF) layer, and Bidirectional Long Short-term Memory (Bi-LSTM) network. The 3D CNN block extracts convolved features from 3D transformed speech features. The convolved features were flattened through the TDF layer and fed into Bi-LSTM to classify emotion with intensity in a single DL framework. The 3D transformed feature is first classified into emotion categories in the cascaded DL framework using a DL model. Then, using a different DL model, the intensity level of the identified categories is determined. The proposed REIS has been evaluated on the Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) benchmark dataset, and the cascaded DL framework is found to be better than the single DL framework. The proposed REIS method has shown remarkable recognition accuracy, outperforming related existing methods.","2022-08","2025-02-26 20:43:29","2025-02-26 20:43:29","","","","15","11","","","","","","","","","","English","","","","WOS:000839187200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","2D CNN; Bidirectional Long Short-term Memory; convolutional neural network; LSTM; MODEL; speech emotion recognition; speech signal transformation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RSFCWGQV","journalArticle","2022","Roy, SK; Nicolson, A; Paliwal, KK","On supervised LPC estimation training targets for augmented Kalman filter-based speech enhancement","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2022.06.004","","The performance of speech coding, speech recognition, and speech enhancement systems that rely on the augmented Kalman filter (AKF) largely depend upon the accuracy of clean speech and noise linear prediction coefficient (LPC) estimation. The formulation of clean speech and noise LPC estimation as a supervised learning task has shown considerable promise as of late. Generally, a deep neural network (DNN) learns to map noisy speech features to a training target that can be used for clean speech and noise LPC estimation. Such training targets fall into four categories: Line spectrum frequency (LSF), LPC power spectrum (LPC-PS), power spectrum (PS), and magnitude spectrum (MS) training targets. The choice of training target can have a significant impact on LPC estimation accuracy. Motivated by this, we perform a comprehensive study of the training targets with the aim of determining which is best for LPC estimation. To this end, we evaluate each training target using a temporal convolutional network (TCN) and a multi-head attention-based network. A large training set constructed from a wide variety of conditions, including real-world non-stationary and coloured noise sources over a range of signal-to-noise ratio (SNR) levels, is used for training. Testing on the NOIZEUS corpus demonstrates that the LPC-PS as the training target produces the lowest clean speech LPC spectral distortion (SD) level. We also construct the augmented Kalman filter (AKF) with the estimated speech and noise LPC parameters of each training target. Subjective AB listening tests and seven objective quality and intelligibility evaluation measures (CSIG, CBAK, COVL, PESQ, STOI, SegSNR, and SI-SDR) revealed that the LPC-PS training target produced enhanced speech at the highest quality and intelligibility amongst the training targets.","2022-07","2025-02-26 20:43:30","2025-02-26 20:43:30","","49-60","","","142","","","","","","","","","","English","","","","WOS:000829662400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","AugmentedKalmanfilter; COLORED-NOISE; DEEP LEARNING APPROACH; HEAD SELF-ATTENTION; Linearpredicationcoefficients; Multi-headattentionnetwork; QUALITY; Speechenhancement; Temporalconvolutionalnetwork; Trainingtargets","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HY8ZE2XT","journalArticle","2021","Kumar, MKP; Kumaraswamy, R","Unsupervised speech separation by detecting speaker changeover points under single channel condition","INTERNATIONAL JOURNAL OF SPEECH TECHNOLOGY","","1381-2416","10.1007/s10772-021-09875-3","","In this paper, we propose a method to separate two speakers from a single channel speech mixture in an unsupervised way by detecting the speaker change over points. In this work, we have taken the combinations of male-female, male-male and female-female speech mixtures. The samples are taken from the TIMIT database. The speech mixture is segmented into frames of 20 ms duration. Speech features like Pitch, short time energy (STE), Mel-frequency cepstral coefficients (MFCC), linear predictive coefficients (LPC), log area ratio (LAR), reflection coefficient (RC), Log Filter Bank Energy (Log FBE) and Fast Fourier Transfor (FFT) spectrum are computed for each frame. Speaker change over points for the combination of male-female speech mixture can be obtained by drawing a mean pitch value line over pitch contour. This gives good values of signal to interference ratio (SIR) as the difference between male and female pitch values is large. For the combination of male-male and female-female speech mixtures, the relation between successive speech frames are obtained by computing the correlation coefficient between the feature vectors (as mentioned above) of successive speech frames. The same relation can also be obtained by taking Euclidean distance between the feature vectors of successive speech frames. In these cases, speaker changeover points are identified by plotting the correlation coefficient/Euclidian distance against each frame number and locating local minima/maxima respectively. Once the speech segments belonging to each speaker are identified using speaker change over points, mask functions for individual speakers are estimated using time-frequency ratio (TFR) of mixed speech signal and recovered speech segments of individual speakers. This will further improve the separation accuracy and the proposed method gives promising results in terms of SIR, signal to artifact ratio (SAR), signal to distortion ratio (SDR), short time objective intelligibility measure and normalized sub band envelope correlation.","2021-12","2025-02-26 20:43:30","2025-02-26 20:43:30","","1101-1112","","4","24","","","","","","","","","","English","","","","WOS:000680794100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","LAR; LogFBE; LPC; MFCC; RC; Single channel; Speaker change over points; Speech separation; STE; TFR","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZTEPI8UF","journalArticle","2021","De Looze, C; Dehsarvi, A; Crosby, L; Vourdanou, A; Coen, RF; Lawlor, BA; Reilly, RB","Cognitive and Structural Correlates of Conversational Speech Timing in Mild Cognitive Impairment and Mild-to-Moderate Alzheimer's Disease: Relevance for Early Detection Approaches","FRONTIERS IN AGING NEUROSCIENCE","","1663-4365","10.3389/fnagi.2021.637404","","Background: Increasing efforts have focused on the establishment of novel biomarkers for the early detection of Alzheimer's disease (AD) and prediction of Mild Cognitive Impairment (MCI)-to-AD conversion. Behavioral changes over the course of healthy ageing, at disease onset and during disease progression, have been recently put forward as promising markers for the detection of MCI and AD. The present study examines whether the temporal characteristics of speech in a collaborative referencing task are associated with cognitive function and the volumes of brain regions involved in speech production and known to be reduced in MCI and AD pathology. We then explore the discriminative ability of the temporal speech measures for the classification of MCI and AD. Method: Individuals with MCI, mild-to-moderate AD and healthy controls (HCs) underwent a structural MRI scan and a battery of neuropsychological tests. They also engaged in a collaborative referencing task with a caregiver. The associations between the conversational speech timing features, cognitive function (domain-specific) and regional brain volumes were examined by means of linear mixed-effect modeling. Genetic programming was used to explore the discriminative ability of the conversational speech features. Results: MCI and mild-to-moderate AD are characterized by a general slowness of speech, attributed to slower speech rate and slower turn-taking in conversational settings. The speech characteristics appear to be reflective of episodic, lexico-semantic, executive functioning and visuospatial deficits and underlying volume reductions in frontal, temporal and cerebellar areas. Conclusion: The implementation of conversational speech timing-based technologies in clinical and community settings may provide additional markers for the early detection of cognitive deficits and structural changes associated with MCI and AD.","2021-04-27","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","","13","","","","","","","","","","English","","","","WOS:000648884900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;114</p>","","","Alzheimer; ASSOCIATION WORKGROUPS; brain volumes; cognitive function; conversation; DIAGNOSTIC GUIDELINES; FUNCTIONAL TOPOGRAPHY; INDIVIDUAL-DIFFERENCES; NARRATIVE DISCOURSE; NATIONAL INSTITUTE; REFERENTIAL COMMUNICATION; SENTENCE COMPREHENSION; speech timing; TEMPORAL-LOBE; WORKING-MEMORY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MPZIYYDW","journalArticle","2021","Hidalgo-De la Guíia, I; Garayzábal-Heinze, E; Gómez-Vilda, P; Martínez-Olalla, R; Palacios-Alonso, D","Acoustic Analysis of Phonation in Children With Smith-Magenis Syndrome","FRONTIERS IN HUMAN NEUROSCIENCE","","1662-5161","10.3389/fnhum.2021.661392","","Complex simultaneous neuropsychophysiological mechanisms are responsible for the processing of the information to be transmitted and for the neuromotor planning of the articulatory organs involved in speech. The nature of this set of mechanisms is closely linked to the clinical state of the subject. Thus, for example, in populations with neurodevelopmental deficits, these underlying neuropsychophysiological procedures are deficient and determine their phonation. Most of these cases with neurodevelopmental deficits are due to a genetic abnormality, as is the case in the population with Smith-Magenis syndrome (SMS). SMS is associated with neurodevelopmental deficits, intellectual disability, and a cohort of characteristic phenotypic features, including voice quality, which does not seem to be in line with the gender, age, and complexion of the diagnosed subject. The phonatory profile and speech features in this syndrome are dysphonia, high f0, excess vocal muscle stiffness, fluency alterations, numerous syllabic simplifications, phoneme omissions, and unintelligibility of speech. This exploratory study investigates whether the neuromotor deficits in children with SMS adversely affect phonation as compared to typically developing children without neuromotor deficits, which has not been previously determined. The authors compare the phonatory performance of a group of children with SMS (N = 12) with a healthy control group of children (N = 12) matched in age, gender, and grouped into two age ranges. The first group ranges from 5 to 7 years old, and the second group goes from 8 to 12 years old. Group differences were determined for two forms of acoustic analysis performed on repeated recordings of the sustained vowel /a/ F1 and F2 extraction and cepstral peak prominence (CPP). It is expected that the results will enlighten the question of the underlying neuromotor aspects of phonation in SMS population. These findings could provide evidence of the susceptibility of phonation of speech to neuromotor disturbances, regardless of their origin.","2021-06-03","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","","15","","","","","","","","","","English","","","","WOS:000662185800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;103</p>","","","cepstral peak prominence; CEPSTRAL PEAK PROMINENCE; children; CONNECTED SPEECH; DYSPHONIC VOICES; INTELLIGIBILITY; MALADAPTIVE BEHAVIOR; ORAL-MOTOR; PARKINSON-DISEASE; phonation stability; Smith-Magenis; speech; SUSTAINED VOWEL; syndrome; VOICE QUALITY; VOWEL ARTICULATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5PKS4WZX","journalArticle","2024","Min, DJ; Kim, DH","Speech Emotion Recognition via Sparse Learning-Based Fusion Model","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3506565","","Speech communication is a powerful tool for conveying intentions and emotions, fostering mutual understanding, and strengthening relationships. In the realm of natural human-computer interaction, speech-emotion recognition plays a crucial role. This process involves three stages: dataset collection, feature extraction, and emotion classification. Collecting speech-emotion recognition datasets is a complex and costly process, leading to limited data volumes and uneven emotional distributions. This scarcity and imbalance pose significant challenges, affecting the accuracy and reliability of emotion recognition. To address these issues, this study introduces a novel model that is more robust and adaptive. We employ the Ranking Magnitude Method (RMM) based on sparse learning. We use the Root Mean Square (RMS) energy and Zero Crossing Rate (ZCR) as temporal features to measure the speech's overall volume and noise intensity. The Mel Frequency Cepstral Coefficient (MFCC) is utilized to extract critical speech features, which are then integrated into a multivariate Long Short-Term Memory-Fully Convolutional Network (LSTM-FCN) model. We analyze the utterance levels using the log-Mel spectrogram for spatial features, processing these patterns through a 2D Convolutional Neural Network Squeeze and Excitation Network (CNN-SEN) model. The core of our method is a Sparse Learning-Based Fusion Model (SLBF), which addresses dataset imbalances by selectively retraining the underperforming nodes. This dynamic adjustment of learning priorities significantly enhances the robustness and accuracy of emotion recognition. Using this approach, our model outperforms state-of-the-art methods for various datasets, achieving impressive accuracy rates of 97.18%, 97.92%, 99.31%, and 96.89% for the EMOVO, RAVDESS, SAVE, and EMO-DB datasets, respectively.","2024","2025-02-26 20:43:30","2025-02-26 20:43:30","","177219-177235","","","12","","","","","","","","","","English","","","","WOS:001370152900008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","2D convolutional neural network squeeze and excitation network; Accuracy; ATTENTION; Brain modeling; Convolutional neural networks; Data models; DATABASES; Deep learning; Emotion recognition; Feature extraction; FEATURES; Hidden Markov models; late fusion; multivariate long short-term memory-fully convolutional network; NETWORK; sparse learning; Speech recognition; Time-domain analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AN8C6PUH","journalArticle","2022","Srinivas, PVVS; Mishra, P","Human Emotion Recognition by Integrating Facial and Speech Features: An Implementation of Multimodal Framework using CNN","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","Emotion recognition plays a prominent role in today's intelligent system applications. Human computer interface, health care, law, and entertainment are a few of the applications where emotion recognition is used. Humans convey their emotions in the form of text, voice, and facial expressions, thus developing a multimodal emotional recognition system playing a crucial role in human-computer or intelligent system communication. The majority of established emotional recognition algorithms only identify emotions in unique data, such as text, audio, or image data. A multimodal system uses information from a variety of sources and fuses the information by using fusion techniques and categories to improve recognition accuracy. In this paper, a multimodal system to recognise emotions was presented that fuses the features from information obtained from heterogenous modalities like audio and video. For audio feature extraction energy, zero crossing rate and Mel-Frequency Cepstral Coefficients (MFCC) techniques are considered. Of these, MFCC produced promising results. For video feature extraction, first the videos are converted to frames and stored in a linear scale space by using a spatial temporal Gaussian Kernel. The features from the images are further extracted by applying a Gaussian weighted function to the second momentum matrix of linear scale space data. The Marginal Fisher Analysis (MFA) fusion method is used to fuse both the audio and video features, and the resulted features are given to the FERCNN model for evaluation. For experimentation, the RAVDESS and CREMAD datasets, which contain audio and video data, are used. Accuracy levels of 95.56, 96.28, and 95.07 on the RAVDESS dataset and accuracies of 80.50, 97.88, and 69.66 on the CREMAD dataset in audio, video, and multimodal modalities are achieved, whose performance is better than the existing multimodal systems.","2022-01","2025-02-26 20:43:30","2025-02-26 20:43:30","","592-603","","1","13","","","","","","","","","","English","","","","WOS:000754705500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","CREMAD; Emotion recognition; FERCNN; fusion; MFA; MFCC; multimodal; RAVDESS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WZDLWIMD","journalArticle","2023","Venkateswarlu, SC; Jeevakala, SR; Kumar, NU; Munaswamy, P; Pendyala, D","Emotion Recognition From Speech and Text using Long Short-Term Memory","ENGINEERING TECHNOLOGY & APPLIED SCIENCE RESEARCH","","2241-4487","10.48084/etasr.6004","","Everyday interactions depend on more than just rational discourse; they also depend on emotional reactions. Having this information is crucial to making any kind of practical or even rational decision, as it can help to better understand one another by sharing our responses and providing recommendations on how they may feel. Several studies have recently begun to focus on emotion detection and labeling, proposing different methods for organizing feelings and detecting emotions in speech. Determining how emotions are conveyed through speech has been given major emphasis in social interactions during the last decade. However, the real efficiency of identification needs to be improved because of the severe lack of data on the primary temporal link of the speech waveform. Currently, a new approach to speech recognition is recommended, which couples structured audio information with long-term neural networks to fully take advantage of the shift in emotional content across phases. In addition to time series characteristics, structural speech features taken from the waveforms are now in charge of maintaining the underlying connection between layers of the actual speech. There are several Long-Short-Term Memory (LSTM) based algorithms for identifying emotional focus over numerous blocks. The proposed method (i) reduced overhead by optimizing the standard forgetting gate, reducing the amount of required processing time, (ii) applied an attention mechanism to both the time and feature dimension in the LSTM's final output to get task-related information, rather than using the output from the prior iteration of the standard technique, and (iii) employed a powerful strategy to locate the spatial characteristics in the final output of the LSTM to gain information, as opposed to using the findings from the prior phase of the regular method. The proposed method achieved an overall classification accuracy of 96.81%.","2023-08","2025-02-26 20:43:30","2025-02-26 20:43:30","","11166-11169","","4","13","","","","","","","","","","English","","","","WOS:001049834500018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;14</p>","","","deep learning; emotion recognition; LSTM; MFCC; speech recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3LZ9C8DS","journalArticle","2023","Wang, Q; Liu, WP; Wang, XM; Chen, XH; Chen, GN; Wu, QX","A Spatial-Temporal Graph Model for Pronunciation Feature Prediction of Chinese Poetry","IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS","","2162-237X","10.1109/TNNLS.2022.3165554","","With the development of artificial intelligence, speech recognition and prediction have become one of the important research domains with wild applications, such as intelligent control, education, individual identification, and emotion analysis. Chinese poetry reading contains rich features of continuous pronunciations, such as mood, emotion, rhythm schemes, lyric reading, and artistic expression. Therefore, the prediction of the pronunciation characteristics of a Chinese poetry reading is the significance for the presentation of high-level machine intelligence and has the potential to create a high-level intelligent system for teaching children to read Tang poetry. Mel frequency cepstral coefficient (MFCC) is currently used to present important speech features. Due to the complexity and high degree of nonlinearity in poetry reading, however, there is a tough challenge facing accurate pronunciation feature prediction, that is, how to model complex spatial correlations and time dynamics, such as rhyme schemes. As for many current methods, they ignore the spatial and temporal characteristics in MFCC presentation. In addition, these methods are subjected to certain limitations on prediction for long-term performance. In order to solve these problems, we propose a novel spatial-temporal graph model (STGM-MHA) based on multihead attention for the purpose of pronunciation feature prediction of Chinese poetry. The STGM-MHA is designed using an encoder-decoder structure. The encoder compresses the data into a hidden space representation, while the decoder reconstructs the hidden space representation as output. In the model, a novel gated recurrent unit (GRU) module (AGRU) based on multihead attention is proposed to extract the spatial and temporal features of MFCC data effectively. The evaluation comparison of our proposed model versus state-of-the-art methods in six datasets reveals the clear advantage of the proposed model.","2023-12","2025-02-26 20:43:30","2025-02-26 20:43:30","","10294-10308","","12","34","","","","","","","","","","English","","","","WOS:000785852100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","AGRU; Analytical models; Chinese poetry; Computational modeling; Data models; DEREVERBERATION; encoder-decoder; Feature extraction; FILTER; graph modeling; Mel frequency cepstral coefficient; Mel frequency cepstral coefficient (MFCC); Predictive models; pronunciation features; RECOGNITION; Rhythm; spatial-temporal graph model (STGM-MHA); TO-SPEECH SYNTHESIS; TRANSLATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3N3KCWKG","journalArticle","2023","Kumar, KA; Iqbal, JLM","Machine learning technique-based emotion classification using speech signals","SOFT COMPUTING","","1432-7643","10.1007/s00500-023-08185-x","","The challenge of identifying the emotional qualities of voice, regardless of the semantic meaning, is known as speech emotion recognition (SER). While people are capable of performing this activity efficiently as a natural aspect of voice communication, the capacity to do so autonomously through programmed technologies is indeed a work in progress. As it offers perspective on human mental processes, emotion identification from speech signals is a frequently investigated topic in the construction of human-computer interface (HCI) models. In HCI, it is frequently necessary to determine the emotion of persons as mental feedback. An attempt is made in this study to distinguish seven different emotions using speech signals: sadness, anger, disgusted, pleased, surprised, enjoyable, and neutrality mood. For the identification of emotion, the suggested method uses a signals preprocessing method based on the randomness measure. The signals are first normalized to reduce noise. Due to the obvious changing length and continual form of voice signals, emotions identification requires both locally and globally information. Local features depict dynamic behavior, while feature points reveal statistic factors such as standard error, median, and lowest and maximum values. The SER system includes several features, including spectrum characteristics, sound quality characteristics, and Teager energy operator-based characteristics. Prosodic features are those that are based on the human perception, such as rhythm and inflection. These characteristics are based on three factors: power, length, and frequency response. From of the heavily processed signals, a features vector is generated that evaluates the random feature for all of the emotional responses. Then, using mutual information (MI), the feature vector is utilized to choose from the entire set. The feature vectors are then categorized using the BOAT method and association rule mining. Experiments were carried out on the TESS dataset for several metrics, and the performance of the suggested method outperformed the state-of-the-art methods.","2023-06","2025-02-26 20:43:30","2025-02-26 20:43:30","","8331-8343","","12","27","","","","","","","","","","English","","","","WOS:000973222100010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Association rule mining; DEEP; Emotion classification; Machine learning techniques; RECOGNITION; Speech features; Speech signals","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MDSQ6UTH","journalArticle","2023","Accou, B; Vanthornhout, J; Van Hamme, H; Francart, T","Decoding of the speech envelope from EEG using the VLAAI deep neural network","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-022-27332-2","","To investigate the processing of speech in the brain, commonly simple linear models are used to establish a relationship between brain signals and speech features. However, these linear models are ill-equipped to model a highly-dynamic, complex non-linear system like the brain, and they often require a substantial amount of subject-specific training data. This work introduces a novel speech decoder architecture: the Very Large Augmented Auditory Inference (VLAAI) network. The VLAAI network outperformed state-of-the-art subject-independent models (median Pearson correlation of 0.19, p < 0.001), yielding an increase over the well-established linear model by 52%. Using ablation techniques, we identified the relative importance of each part of the VLAAI network and found that the non-linear components and output context module influenced model performance the most (10% relative performance increase). Subsequently, the VLAAI network was evaluated on a holdout dataset of 26 subjects and a publicly available unseen dataset to test generalization for unseen subjects and stimuli. No significant difference was found between the default test and the holdout subjects, and between the default test set and the public dataset. The VLAAI network also significantly outperformed all baseline models on the public dataset. We evaluated the effect of training set size by training the VLAAI network on data from 1 up to 80 subjects and evaluated on 26 holdout subjects, revealing a relationship following a hyperbolic tangent function between the number of subjects in the training set and the performance on unseen subjects. Finally, the subject-independent VLAAI network was finetuned for 26 holdout subjects to obtain subject-specific VLAAI models. With 5 minutes of data or more, a significant performance improvement was found, up to 34% (from 0.18 to 0.25 median Pearson correlation) with regards to the subject-independent VLAAI network.","2023-01-16","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","1","13","","","","","","","","","","English","","","","WOS:000993532100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","ENTRAINMENT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HLIPVAQF","journalArticle","2021","Tankus, A; Solomon, L; Aharony, Y; Faust-Socher, A; Strauss, I","Machine learning algorithm for decoding multiple subthalamic spike trains for speech brain-machine interfaces","JOURNAL OF NEURAL ENGINEERING","","1741-2560","10.1088/1741-2552/ac3315","","Objective. The goal of this study is to decode the electrical activity of single neurons in the human subthalamic nucleus (STN) to infer the speech features that a person articulated, heard or imagined. We also aim to evaluate the amount of subthalamic neurons required for high accuracy decoding suitable for real-life speech brain-machine interfaces (BMI). Approach. We intraoperatively recorded single-neuron activity in the STN of 21 neurosurgical patients with Parkinson's disease undergoing implantation of deep brain stimulator while patients produced, perceived or imagined the five monophthongal vowel sounds. Our decoder is based on machine learning algorithms that dynamically learn specific features of the speech-related firing patterns. Main results. In an extensive comparison of algorithms, our sparse decoder ('SpaDe'), based on sparse decomposition of the high dimensional neuronal feature space, outperformed the other algorithms in all three conditions: production, perception and imagery. For speech production, our algorithm, Spade, predicted all vowels correctly (accuracy: 100%; chance level: 20%). For perception accuracy was 96%, and for imagery: 88%. The accuracy of Spade showed a linear behavior in the amount of neurons for the perception data, and even faster for production or imagery. Significance. Our study demonstrates that the information encoded by single neurons in the STN about the production, perception and imagery of speech is suitable for high-accuracy decoding. It is therefore an important step towards BMIs for restoration of speech faculties that bears an enormous potential to alleviate the suffering of completely paralyzed ('locked-in') patients and allow them to communicate again with their environment. Moreover, our research indicates how many subthalamic neurons may be necessary to achieve each level of decoding accuracy, which is of supreme importance for a neurosurgeon planning the implantation of a speech BMI.","2021-12","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","6","18","","","","","","","","","","English","","","","WOS:000722402900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","brain-machine interface; decoding; human neurophysiology; RESTORATION; single unit recordings; speech; subthalamic nucleus; vowels","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T6NMKH5D","journalArticle","2021","Lalitha, S; Gupta, D; Zakariah, M; Alotaibi, YA","Mental Illness Disorder Diagnosis Using Emotion Variation Detection from Continuous English Speech","CMC-COMPUTERS MATERIALS & CONTINUA","","1546-2218","10.32604/cmc.2021.018406","","Automatic recognition of human emotions in a continuous dia-log model remains challenging where a speaker's utterance includes several sentences that may not always carry a single emotion. Limited work with stan-dalone speech emotion recognition (SER) systems proposed for continuous speech only has been reported. In the recent decade, various effective SER systems have been proposed for discrete speech, i.e., short speech phrases. It would be more helpful if these systems could also recognize emotions from continuous speech. However, if these systems are applied directly to test emotions from continuous speech, emotion recognition performance would not be similar to that achieved for discrete speech due to the mismatch between training data (from training speech) and testing data (from continuous speech). The problem may possibly be resolved if an existing SER system for discrete speech is enhanced. Thus, in this work the author's existing effective SER system for multilingual and mixed-lingual discrete speech is enhanced by enriching the cepstral speech feature set with bi-spectral speech features and a unique functional set of Mel frequency cepstral coefficient features derived from a sine filter bank. Data augmentation is applied to combat skewness of the SER system toward certain emotions. Classification using random forest is performed. This enhanced SER system is used to predict emotions from continuous speech with a uniform segmentation method. Due to data scarcity, several audio samples of discrete speech from the SAVEE database that has recordings in a universal language, i.e., English, are concatenated resulting in multi-emotional speech samples. Anger, fear, sad, and neutral emotions, which are vital during the initial investigation of mentally disordered individuals, are selected to build six categories of multi-emotional samples. Experimental results demonstrate the suitability of the proposed method for recognizing emotions from continuous speech as well as from discrete speech.","2021","2025-02-26 20:43:30","2025-02-26 20:43:30","","3217-3238","","3","69","","","","","","","","","","English","","","","WOS:000688411400024","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","bi-spectral; cepstral; COMMUNITY; Continuous speech; DEPRESSION; discrete; emotion; filter bank; mental illness; multi-emotional; RECOGNITION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DUM46MHN","journalArticle","2021","Tursunov, A; Mustageem; Choeh, JY; Kwon, S","Age and Gender Recognition Using a Convolutional Neural Network with a Specially Designed Multi-Attention Module through Speech Spectrograms","SENSORS","","1424-8220","10.3390/s21175892","","Speech signals are being used as a primary input source in human-computer interaction (HCI) to develop several applications, such as automatic speech recognition (ASR), speech emotion recognition (SER), gender, and age recognition. Classifying speakers according to their age and gender is a challenging task in speech processing owing to the disability of the current methods of extracting salient high-level speech features and classification models. To address these problems, we introduce a novel end-to-end age and gender recognition convolutional neural network (CNN) with a specially designed multi-attention module (MAM) from speech signals. Our proposed model uses MAM to extract spatial and temporal salient features from the input data effectively. The MAM mechanism uses a rectangular shape filter as a kernel in convolution layers and comprises two separate time and frequency attention mechanisms. The time attention branch learns to detect temporal cues, whereas the frequency attention module extracts the most relevant features to the target by focusing on the spatial frequency features. The combination of the two extracted spatial and temporal features complements one another and provide high performance in terms of age and gender classification. The proposed age and gender classification system was tested using the Common Voice and locally developed Korean speech recognition datasets. Our suggested model achieved 96%, 73%, and 76% accuracy scores for gender, age, and age-gender classification, respectively, using the Common Voice dataset. The Korean speech recognition dataset results were 97%, 97%, and 90% for gender, age, and age-gender recognition, respectively. The prediction performance of our proposed model, which was obtained in the experiments, demonstrated the superiority and robustness of the tasks regarding age, gender, and age-gender recognition from speech signals.","2021-09","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","17","21","","","","","","","","","","English","","","","WOS:000694455900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;34<br/>Total Times Cited:&nbsp;&nbsp;34<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","age and gender recognition; CLASSIFICATION; CNN; convolutional neural network; DEEP; human-computer interaction; LSTM; multi-attention module; SPEAKER AGE; speech signals","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X8MY9QPL","journalArticle","2021","Shen, ZY; Wei, YT","A high-precision feature extraction network of fatigue speech from air traffic controller radiotelephony based on improved deep learning","ICT EXPRESS","","2405-9595","10.1016/j.icte.2021.01.002","","Air traffic controller (ATC) fatigue is receiving considerable attention in recent studies because it represents a major cause of air traffic incidences. Research has revealed that the presence of fatigue can be detected by analysing speech utterances. However, constructing a complete labelled fatigue data set is very time-consuming. Moreover, a manually constructed speech collection will often contain only little key information to be used effectively in fatigue recognition, while multilevel deep models based on such speech materials often have overfitting problems due to an explosive increase of model parameters. To address these problems, a novel deep learning framework is proposed in this study to integrate active learning (AL) into complex speech features selected from a large set of unlabelled speech data in order to overcome the loss of information. A shallow feature set is first extracted using stacked sparse autoencoder networks, in which fatigue state challenge features from a manually selected speaker set of are exploited as the input vector. A densely connected convolutional autoencoder (DCAE) is then proposed to learn advanced features automatically from spectrograms of the selected data to supplement the fatigue features. The network can be effectively trained using a relatively small number of labelled samples with the help of AL sampling strategies, and the addition of a dense block to the convolutional automatic encoder can decrease the number of parameters and make the model easier to fit. Finally, the two above-mentioned features are combined using multiple kernel learning with a support-vector-machine classifier. A series of comparative experiments using the Civil Aviation Administration of China radiotelephony corpus demonstrates that the proposed method provides a significant improvement in the detection precision compared to current state-of-the-art approaches. (C) 2021 The Korean Institute of Communications and Information Sciences (KICS). Publishing services by Elsevier B.V.","2021-12","2025-02-26 20:43:30","2025-02-26 20:43:30","","403-413","","4","7","","","","","","","","","","English","","","","WOS:000724498300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Active learning; Air traffic control; Dense block; DOMAIN ADAPTATION; Fatigue; Spectrogram; SSAE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NP6PC4RL","journalArticle","2025","Haluts, N; Levy, D; Friedmann, N","Bimodal aphasia and dysgraphia: Phonological output buffer aphasia and orthographic output buffer dysgraphia in spoken and sign language","CORTEX","","0010-9452","10.1016/j.cortex.2024.10.013","","We report a case of crossmodal bilingual aphasia-aphasia in two modalities, spoken and sign language-and dysgraphia in both writing and fingerspelling. The patient, Sunny, was a 42 year-old woman after a left temporo-parietal stroke, a speaker of Hebrew, Romanian, and English and an adult learner, daily user of Israeli Sign language (ISL). We assessed Sunny's spoken and sign languages using a comprehensive test battery of naming, reading, and repetition tasks, and also analysed her spontaneous-speech and sign. Her writing and fingerspelling were assessed using tasks of dictation, naming, and delayed copying. In spoken language production, Sunny showed a classical phonological output buffer (POB) impairment in naming, reading, repetition, and spontaneous production, with phonological errors (transpositions, substitutions, insertions, and omissions) in words and pseudo-words, and whole-unit errors in morphological affixes, function-words, and number-words, with a length effect. Importantly, her error pattern in ISL was remarkably similar in the parallel tasks, with phonological errors in signs and pseudo-signs, affecting all the phonological parameters of the sign (movement, handshape, location, and orientation), and whole-unit errors in morphemes, function-signs, and number-signs. Sunny's impairment was selective to the POB, without phonological input, semantic-conceptual, or syntactic deficits. This shows for the first time how POB impairment, a kind of conduction aphasia, manifests itself in a sign language, and indicates that the POB for sign-language has the same cognitive architecture as the one for spoken language. It may also indicate similar neural underpinnings for spoken and sign languages. In writing, Sunny forms the first case of a selective type of dysgraphia in fingerspelling, orthographic (graphemic) output buffer dysgraphia. In both writing and fingerspelling, she made letter errors (letter transpositions, substitutions, insertions, and omissions), as well as morphological errors and errors in function words, and showed length effect. Sunny's impairment was selective to the orthographic output buffer, whereas her reading, including orthographic input processing, was intact. This suggests that the orthographic output buffer is shared for writing and fingerspelling, at least in a late learner of sign language. The results shed further light on the architecture of phonological and orthographic production. (c) 2024 Elsevier Ltd. All rights are reserved, including those for text and data mining, AI training, and similar technologies.","2025-01","2025-02-26 20:43:30","2025-02-26 20:43:30","","147-180","","","182","","","","","","","","","","English","","","","WOS:001402301000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;223</p>","","","AGRAMMATIC COMPREHENSION; Conduction aphasia; DEEP DYSGRAPHIA; dysgraphia; Fingerspelling; GRAPHEMIC BUFFER; impairment; NEURAL ORGANIZATION; Orthographic output buffer; Phonological output buffer; SELECTIVE IMPAIRMENT; SENTENCE COMPREHENSION; SHORT-TERM-MEMORY; Sign language; UNATTENDED SPEECH; WORD PRODUCTION; WORKING-MEMORY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LZGYZFYB","journalArticle","2023","Chernetchenko, D; Prasolov, P; Aganov, S; Voropai, A; Polishchuk, Y; Lituiev, D; Nayshtetik, E","Effects of Binaural Beat Stimulation in Adults with Stuttering","BRAIN SCIENCES","","2076-3425","10.3390/brainsci13020309","","In recent decades, several studies have demonstrated a link between stuttering and abnormal electroencephalographic (EEG) beta-power in cortex. Effects of exposure to binaural stimuli were studied in adults with stuttering (AWS, n = 6) and fluent participants (n = 6) using EEG, ECG, and speech analysis. During standard reading tasks without stimulation, in controls but not in the AWS group, EEG beta-power was significantly higher in the left hemisphere than in the right hemisphere. After stimulation, the power of the beta-band in AWS participants in the left hemisphere increased 1.54-fold. The average beta-band power within the left frontotemporal area and temporoparietal junction of the cortex after stimulation in AWS participants shows an increase by 1.65-fold and 1.72-fold, respectively. The rate of disfluency dropped significantly immediately after stimulation (median 74.70% of the baseline). Similarly, the speech rate significantly increased immediately after stimulation (median 133.15%). We show for the first time that auditory binaural beat stimulation can improve speech fluency in AWS, and its effect is proportional to boost in EEG beta-band power in left frontotemporal and temporoparietal junction of cortex. Changes in beta-power were detected immediately after exposure and persisted for 10 min. Additionally, these effects were accompanied by a reduction in stress levels.","2023-02","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","2","13","","","","","","","","","","English","","","","WOS:000938916700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","ANXIETY; auditory stimulation; binaural beats; CHILDREN; CORTEX; HEART-RATE; NETWORK; PERFORMANCE; RESPONSES; RHYTHM; SPEECH; stuttering; VOXEL-BASED MORPHOMETRY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BFH4A6LV","journalArticle","2023","Ivantsova, EV","Etiquette formulas in the speech of a dialect language personality of a Siberian old-resident","VESTNIK TOMSKOGO GOSUDARSTVENNOGO UNIVERSITETA FILOLOGIYA-TOMSK STATE UNIVERSITY JOURNAL OF PHILOLOGY","","1998-6645","10.17223/19986645/85/2","","The article aims at analyzing the formulas of speech etiquette as part of the study of the speech culture of dialect speakers of the Middle Ob region. The analysis of these formulas was carried out using the methods of linguopersonology - through the study of the speech of a specific language personality, typical for a given society. The material is the author's archive of discursive recordings of the spontaneous speech of a Siberian peasant woman (about 10,000 printed pages), made over 24 years by the method of inclusion in the speaker's linguistic existence. Information letters addressed to close friends were also used as additional material. The author described the set of speech etiquette formulas included in the lists of the most important etiquette situations of the Russian language, as well as functional features of the formulas; considered the system of etiquette linguistic tools in the discourse of the language personality as part of the etiquette frame that organizes communication ( greeting, introduction, address, farewell), and etiquette inclusions that perform the function of maintaining the rules of communicants' speech behavior (request, gratitude, apology, forgiveness, invitation, wish, congratulations, agreement, disagreement, sympathy, praise). In each case, the variants of designations of one or another inclusion were correlated with different discursive spheres and communicative situations. The system of etiquette formulas of a typical dialect language personality reflects many features of the cultural and linguistic landscape (in the broad sense, including by definition the base of local dialects, oral speech and the speech culture of their speakers, onomastic elements, and a number of other components) of a Siberian old-residents' village. The prevalence of all-Russian formulas of speech etiquette over dialect ones in the studied material indicates the features of the dialect of secondary formation in contrast to native dialects. Linguo-personological discourse analysis allows us to draw conclusions about the specifics of the discourse stylistic stratification: the dominant style is everyday-life speech, with the presence of high style and the absence of official-business style. Some etiquette formulas preserve pagan and Christian motives, which indicates that elements of the traditional worldview of Siberian old-residents are preserved. Etiquette formulas in the discourse of a typical representative of traditional folk speech culture reflect the system of such values of the peasant world as health, food, family, one's own economy, prosperity, and friendly communication.","2023-10","2025-02-26 20:43:30","2025-02-26 20:43:30","","20-42","","","85","","","","","","","","","","English","","","","WOS:001105965200002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","BEHAVIOR; cultural and linguistic landscape; dialect discourse; dialect language personality; folk speech culture; Middle Ob dialects; speech genre of request","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"27KKKSGC","journalArticle","2022","Song, XK; So, WC","The influence of child-based factors and parental inputs on expressive language abilities in children with autism spectrum disorder","AUTISM","","1362-3613","10.1177/13623613211054597","","Studies of language development in children with autism spectrum disorder (ASD) have been primarily focused on the influence of child-based factors such as autism traits, IQ, and initial language skills. Yet the findings of these studies are inconclusive. There has, moreover, been little research compared the relative influences of child-based factors with environmental factors, (e.g. parental inputs). The current study attempts to fill this research gap by examining a range of both child-based factors and parental inputs. We measured the structural language abilities manifested in parent-child interactions over four time points across nine months in 42 Chinese-speaking autistic children (M = 57.42 months, SD = 11.39). Our results showed that children's mean length of utterance (MLU), word types, and word tokens grew rapidly, but their development trajectories varied. Initial expressive language ability was a significant predictor of children's language outcomes, while nonverbal IQ and autism traits did not relate to children's language abilities when controlling for initial expressive language ability. Parents' MLU, word tokens, and word types did not associate with children's structural language abilities. The findings shed lights on the importance of one of the child-based factors in particular, that is, initial expressive language skills, in the language development of autistic children. Lay abstract Language impairment is one of the early signs of Autism Spectrum Disorder (ASD) that alerts parents to take their children for early diagnosis and intervention. Little is known about how children's autism traits, IQ, initial language abilities and parental inputs influence their language abilities. In addition, only a few studies have compared the relative influence of these factors. The present study addressed these issues by examining the structural language in parent-child spontaneous interactions. Forty-two Cantonese (Chinese)-speaking autistic children aged four to eight were recruited. Their expressive language skills grew rapidly more than 9 months, but their development trajectories varied. Initial expressive language ability is the only significant predictor of child language outcomes and language growth trajectories. In contrast, nonverbal cognition, autism traits, and parents' input do not affect language outcomes in children with ASD. Therefore, early language intervention is crucial for autistic children at all severity and IQ levels.","2022-08","2025-02-26 20:43:30","2025-02-26 20:43:30","","1477-1490","","6","26","","","","","","","","","","English","","","","WOS:000713400100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","autism; BRIEF INTELLIGENCE-TEST; FOLLOW-UP; GROWTH; HETEROGENEITY; longitudinal study; multi-level modeling; naturalistic language samples; PREDICTORS; PRESCHOOLERS; PROFILES; SPONTANEOUS SPEECH; VALIDITY; YOUNG-CHILDREN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GJ42Z7G4","journalArticle","2023","Ahmadi, P; Shafiei, B; Ghasisin, L; Husak, RS","The Effects of Using Video-Clip Stimuli in Response Elaboration Training in Persian Speakers with Chronic Broca's Aphasia","APHASIOLOGY","","0268-7038","10.1080/02687038.2022.2076280","","Background The use of pictographic images to elicit spoken language productions is common in aphasia therapy. However, investigations on the treatment effects of using video stimuli are limited. People with aphasia are likely to want to be able to communicate better about content depicted in video-clip segments, especially with the growing popularity of video sharing between friends and family on social media. Aims The aim of this study was to examine the effects of utilising video-clip segments in the provision of Response Elaboration Training (RET; Kearns, 1985) in the Persian language. Specifically, the study addressed four questions: (1) Will the provision of RET with video-clips as the treatment stimuli increase the number of correct information units (CIUs; Nicholas and Brookshire, 1993) Persian speakers with aphasia produce in response to trained stimuli? (2) Will there be an increase in the number of CIUs participants produce in response to untrained stimuli? (3) Will treatment gains be maintained over time? (4) Will the participants exhibit improved scores on the Persian Western Aphasia Battery (Nilipour et al., 2014) from pre- to posttreatment? Methods & Procedures Two participants with moderately severe chronic Broca's aphasia due to a left-hemisphere stroke received treatment three times a week. A single-case multiple-probe design consisting of two consecutive treatment phases, periodic generalisation probes, and three posttreatment follow-up probes (one-week, three-weeks, and six-weeks) was used. Treatment sessions consisted of two rounds of RET applied to 10 video-clip stimuli. Outcomes & Results Participant 1 reached the treatment termination criteria after six therapy sessions in the first phase of treatment and after seven treatment sessions in the second phase. Participant 2 reached the termination criteria for the first and second treatment phases after 12 and eight treatment sessions, respectively. Large positive treatment effects were found for the participants for trained items. Treatment effects were maintained above baseline performance for trained items on all follow-up measures. Generalisation to untrained items was limited. Both participants exhibited an Aphasia Quotient increase posttreatment on the Persian Western Aphasia Battery, with the largest improvement identified on the spontaneous speech subtest. Conclusion Although preliminary, this study provides support for the use of video stimuli in the provision of RET in the Persian language to individuals with chronic Broca's aphasia. The study encourages further exploration on the topic and discusses clinical implications of the research.","2023-07-03","2025-02-26 20:43:30","2025-02-26 20:43:30","","1064-1086","","7","37","","","","","","","","","","English","","","","WOS:000800950600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;82</p>","","","ADULTS; aphasia treatment; aphasia treatment stimuli; APRAXIA; INDIVIDUALS; LANGUAGE; REHABILITATION; Response Elaboration Training; RETRIEVAL; SPEECH TREATMENT; TECHNOLOGY; THERAPY; VALIDATION; video stimuli","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R5AZGH29","journalArticle","2021","Taoka, Y; Kagohashi, K; Mougenot, C","A cross-cultural study of co-design: the impact of power distance on group dynamics in Japan","CODESIGN-INTERNATIONAL JOURNAL OF COCREATION IN DESIGN AND THE ARTS","","1571-0882","10.1080/15710882.2018.1546321","","This study explores the characteristics of collaboration between people with Japanese value orientation in co-design workshops. We define co-design as an approach where designers collaborate with non-designers to design new products or services. This research investigates the effect of culture and value orientation on co-design between designers and non-designers in a Japanese context. Through interviews with four professional designers, we identified that the participation of Japanese non-designers in a co-design workshop might be hindered by the presence of an expert, who is perceived as a person in a higher social position. With 20 subjects, we experimentally investigated the impact of power distance on collaboration. European and Japanese groups of non-designers generated and discussed ideas in two conditions - with or without a professional designer in the group. Through behaviour and speech analysis, we assessed the quality of collaboration within the group. Depending on their power distance score, the contributions of participants were affected differently by the presence of a professional designer. Unlike in the European groups, the presence of a designer in a Japanese group created a hierarchical structure that hindered the participation of non-designers. This work is expected to support the development of co-design methods adapted to their cultural contexts.","2021-01-02","2025-02-26 20:43:30","2025-02-26 20:43:30","","22-49","","1","17","","","","","","","","","","English","","","","WOS:000619287100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Co-design; cultural dimensions; design collaboration; East Asia; power distance; value orientation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X5L6W4NL","journalArticle","2021","Mahar, SA; Mahar, MH; Mahar, JA; Masud, M; Ahmad, M; Jhanjhi, NZ; Razzaq, MA","Superposition of Functional Contours Based Prosodic Feature Extraction for","INTELLIGENT AUTOMATION AND SOFT COMPUTING","","1079-8587","10.32604/iasc.2021.015755","","Speech signal analysis for the extraction of speech elements is viable in natural language applications. Rhythm, intonation, stress, and tone are the elements of prosody. These features are essential in emotional speech, speech to speech, speech recognition, and other applications. The current study attempts to extract the pitch and duration from historical Sindhi sound clips using the functional contours model's superposition. The sampled sound clips contained the speech of 273 undergraduates living in 5 districts of the Sindhi province. Several Python libraries are available for the application of this model. We used these libraries for the extraction of prosodic data from a variety of sound units. The spoken sentences were categorically segmented into words, syllables, and phonemes. A speech analyzer investigated the acoustics of sounds with the power spectral density method. Meanwhile, a speech database was divided into parts contains words of different sizes (ranging from 1-letter to 5-letter words). The results illustrated the production of both minimum and maximum mu sound durations and pitches from the inhabitants of Khairpur and Ghotki districts, respectively. Both districts lie in the upper part of the Sindh province. In addition, the second parameter approach, observed versus obtained, was used to compare outcomes. We observed 5250 and 4850 durations and pitches, respectively.","2021","2025-02-26 20:43:30","2025-02-26 20:43:30","","183-197","","1","29","","","","","","","","","","English","","","","WOS:000655055100012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","duration; GENERATION; Intelligent systems; pitch; prosody extraction; Sindhi speech analysis; SPEECH; speech signal analysis; Superposition of functional contours","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LEFU4WRS","journalArticle","2023","Wu, F; Nägele, M; Cleres, D; Haider, T; Fleisch, E; Ruschitzka, F; Flammer, A; Barata, F","Trends in voice characteristics in patients with heart failure (VENTURE) in Switzerland: Protocol for a longitudinal observational pilot study","PLOS ONE","","1932-6203","10.1371/journal.pone.0283052","","IntroductionHeart Failure (HF) is a major health and economic issue worldwide. HF-related expenses are largely driven by hospital admissions and re-admissions, many of which are potentially preventable. Current self-management programs, however, have failed to reduce hospital admissions. This may be explained by their low predictive power for decompensation and high adherence requirements. Slight alterations in the voice profile may allow to detect decompensation in HF patients at an earlier stage and reduce hospitalizations. This pilot study investigates the potential of voice as a digital biomarker to predict health status deterioration in HF patients. Methods and analysisIn a two-month longitudinal observational study, we collect voice samples and HF-related quality-of-life questionnaires from 35 stable HF patients. Patients use our developed study application installed on a tablet at home during the study period. From the collected data, we use signal processing to extract voice characteristics from the audio samples and associate them with the answers to the questionnaire data. The primary outcome will be the correlation between voice characteristics and HF-related quality-of-life health status. Ethics and disseminationThe study was reviewed and approved by the Cantonal Ethics Committee Zurich (BASEC ID:2022-00912). Results will be published in medical and technical peer-reviewed journals.","2023-04-05","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","4","18","","","","","","","","","","English","","","","WOS:000967987200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","DYSPHONIA SEVERITY; HOSPITALIZED-PATIENTS; INDEX; SPEECH ANALYSIS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZNYWJK2Q","journalArticle","2022","Yildiz-Deger, TF; Cinar, F; Baghaki, S; Demiroz, A; Polat, Z; Kocer, N; Aydin, Y","Comparison of Real-Time Speech Magnetic Resonance Imagings With Perceptual Speech Analysis in Evaluation Velopharyngeal Sphincter Function","JOURNAL OF CRANIOFACIAL SURGERY","","1049-2275","10.1097/SCS.0000000000007940","","Identifying substantial data and their normative values related to velopharyngeal structures in cleft palate patients may have clinical significance, in order to selection of surgical intervention and prediction of postsurgical outcomes. Previous studies are lack of referring certain anatomic locations or distances that may have affect on speech intelligibility, especially in dynamic state. The aim of this study is to investigate effectiveness of magnetic resonance imagings on the velopharyngeal sphincter function and the correlation with speech intelligibility after functional cleft palate repair. Seventeen patients with repaired cleft palate by single surgeon were enrolled in this study. Quantitative velopharyngeal measures from the oblique coronal plane and midsagittal plane in static and dynamic positions were collected. Patients' speech intelligibility was evaluated by using Pittsburgh Weighted Speech Scale and nasalance score was also measured. Correlation analysis methods were used for evaluating relation between MRI gathered measurements and speech intelligibility scores for determining consequential data. Our study shows that the velar knee-posterior pharyngeal wall distance measurement while explosive sound production is the most related data with speech intelligibility. Although future works with more sample number is needed, according to current study the authors think magnetic resonance imagings is a very helpful method in providing reliable information.","2022-03","2025-02-26 20:43:30","2025-02-26 20:43:30","","491-495","","2","33","","","","","","","","","","English","","","","WOS:000762006200072","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","AUDIO; Cleft palate; DIAGNOSIS; INSUFFICIENCY; magnetic resonance imaging; MRI; MUSCLE; SUBMUCOUS CLEFT-PALATE; velopharyngeal insufficiency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RZZ87DMP","journalArticle","2022","Imre, N; Balogh, R; Gosztolya, G; Tóth, L; Hoffmann, I; Várkonyi, T; Lengyel, C; Pákáski, M; Kálmán, J","Temporal Speech Parameters Indicate Early Cognitive Decline in Elderly Patients With Type 2 Diabetes Mellitus","ALZHEIMER DISEASE & ASSOCIATED DISORDERS","","0893-0341","","","Introduction: The earliest signs of cognitive decline include deficits in temporal (time-based) speech characteristics. Type 2 diabetes mellitus (T2DM) patients are more prone to mild cognitive impairment (MCI). The aim of this study was to compare the temporal speech characteristics of elderly (above 50 y) T2DM patients with age-matched nondiabetic subjects. Materials and Methods: A total of 160 individuals were screened, 100 of whom were eligible (T2DM: n = 51; nondiabetic: n= 49). Participants were classified either as having healthy cognition (HC) or showing signs of MCI. Speech recordings were collected through a phone call. Based on automatic speech recognition, 15 temporal parameters were calculated. Results: The HC with T2DM group showed significantly shorter utterance length, higher duration rate of silent pause and total pause, and higher average duration of silent pause and total pause compared with the HC without T2DM group. Regarding the MCI participants, parameters were similar between the T2DM and the nondiabetic subgroups. Conclusions: Temporal speech characteristics of T2DM patients showed early signs of altered cognitive functioning, whereas neuropsychological tests did not detect deterioration. This method is useful for identifying the T2DM patients most at risk for manifest MCI, and could serve as a remote cognitive screening tool.","2022-04","2025-02-26 20:43:30","2025-02-26 20:43:30","","148-155","","2","36","","","","","","","","","","English","","","","WOS:000965467900008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","ALZHEIMER-DISEASE; automatic speech recognition; cognitive dysfunction; cognitive screening; DEMENTIA; early detection; IMPAIRMENT; language functions; MEMORY; mild cognitive impairment; neuropsychology; RISK; speech analysis; temporal speech characteristics; type 2 diabetes mellitus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8YRSWMT5","journalArticle","2021","Ghafoor, KJ; Rawf, KMH; Abdulrahman, AO; Taher, SH","Kurdish Dialect Recognition using 1D CNN","ARO-THE SCIENTIFIC JOURNAL OF KOYA UNIVERSITY","","2307-549X","10.14500/aro.10837","","Dialect recognition (DR) is one of the most attentive topics in the speech analysis area. Machine learning algorithms have been widely used to identify dialects. In this paper, a model that based on three different 1D Convolutional Neural Network (CNN) structures is developed for Kurdish DR. This model is evaluated and CNN structures are compared to each other. The result shows that the proposed model has outperformed the state of the art. The model is evaluated on the experimental data that have been collected by the staff of Department of Computer Science at the University of Halabja. Three dialects are involved in the dataset as the Kurdish language consists of three major dialects, namely Northern Kurdish (Badini variant), Central Kurdish (Sorani variant), and Hawrami. The advantage of the CNN model is not required to concern handcraft as the CNN model is featureless. According to the results, the 1D CNN method can make predictions with an average accuracy of 95.53% on the Kurdish dialect classification. In this study, a new method is proposed to interpret the closeness of the Kurdish dialects using a confusion matrix and a non-metric multi-dimensional visualization technique. The outcome demonstrates that it is straightforward to cluster given Kurdish dialects and linearly isolated from the neighboring dialects.","2021","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","2","9","","","","","","","","","","English","","","","WOS:000708153200002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","ADAPTATION; AUTOMATIC SPEECH RECOGNITION; Convolution neural network; deep learning; dialect recognition; IDENTIFICATION; LANGUAGE; machine learning; MODEL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"56SLH6VH","journalArticle","2021","Smietanka, L; Maka, T","Audio Feature Space Analysis for Emotion Recognition from Spoken Sentences","ARCHIVES OF ACOUSTICS","","0137-5075","10.24425/aoa.2021.136581","","An analysis of low-level feature space for emotion recognition from the speech is presented. The main goal was to determine how the statistical properties computed from contours of low-level features influence the emotion recognition from speech signals. We have conducted several experiments to reduce and tune our initial feature set and to configure the classification stage. In the process of analysis of the audio feature space, we have employed the univariate feature selection using the chi-squared test. Then, in the first stage of classification, a default set of parameters was selected for every classifier. For the classifier that obtained the best results with the default settings, the hyperparameter tuning using cross-validation was exploited. In the result, we compared the classification results for two different languages to find out the difference between emotional states expressed in spoken sentences. The results show that from an initial feature set containing 3198 attributes we have obtained the dimensionality reduction about 80% using feature selection algorithm. The most dominant attributes selected at this stage based on the mel and bark frequency scales filterbanks with its variability described mainly by variance, median absolute deviation and standard and average deviations. Finally, the classification accuracy using tuned SVM classifier was equal to 72.5% and 88.27% for emotional spoken sentences in Polish and German languages, respectively.","2021","2025-02-26 20:43:30","2025-02-26 20:43:30","","271-277","","2","46","","","","","","","","","","English","","","","WOS:000658708400008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","classification; CLASSIFIERS; emotional speech; SPEECH; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EYHK54MK","journalArticle","2022","Tomcic, L; Ederer, A; Grabmann, S; Kick, M; Kriegler, J; Zaeh, MF","Interpreting acoustic emissions to determine the weld depth during laser beam welding","JOURNAL OF LASER APPLICATIONS","","1042-346X","10.2351/7.0000796","","The interpretation of sensor system data is critical for monitoring industrial welding processes and providing reliable information about the condition of the weld seam. Previous investigations have shown that acoustic emissions of frequencies up to several kilohertz during laser beam welding are parameter-dependent and contain valuable information about the process. A microphone was employed to record the acoustic emissions produced when performing deep penetration laser beam welding of copper. Experiments were conducted in which the laser power and the feed rate were varied so as to obtain acoustic data comprising frequencies of up to 1 MHz. The signals were preprocessed and features were extracted using Fourier and wavelet analysis as well as speech analysis techniques. The relationship between the features extracted from the acoustic signal and the weld depth was modeled using Gaussian process regression. The results showed that acoustic emissions during laser beam welding can be used to predict the weld depth without having to rely on process parameters, i.e., the laser power and the feed rate. Overall, 17 features were extracted from acoustic signals, with the zero-crossing rate displaying the highest significance for determining the weld depth. These investigations open up new possibilities of robust quality assurance for laser beam welding applications based on acoustic emissions.","2022-11","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","4","34","","","","","","","","","","English","","","","WOS:000891194300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","acoustics; green laser beam; KEYHOLE; laser beam welding; MACHINE; machine learning; process monitoring; quality assurance; SOUND; weld depth","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E7TBTW9S","journalArticle","2023","Just, SA; Bröcker, AL; Ryazanskaya, G; Nenchev, I; Schneider, M; Bermpohl, F; Heinz, A; Montag, C","Validation of natural language processing methods capturing semantic incoherence in the speech of patients with non-affective psychosis","FRONTIERS IN PSYCHIATRY","","1664-0640","10.3389/fpsyt.2023.1208856","","BackgroundImpairments in speech production are a core symptom of non-affective psychosis (NAP). While traditional clinical ratings of patients' speech involve a subjective human factor, modern methods of natural language processing (NLP) promise an automatic and objective way of analyzing patients' speech. This study aimed to validate NLP methods for analyzing speech production in NAP patients. MethodsSpeech samples from patients with a diagnosis of schizophrenia or schizoaffective disorder were obtained at two measurement points, 6 months apart. Out of N = 71 patients at T-1, speech samples were also available for N = 54 patients at T-2. Global and local models of semantic coherence as well as different word embeddings (word2vec vs. GloVe) were applied to the transcribed speech samples. They were tested and compared regarding their correlation with clinical ratings and external criteria from cross-sectional and longitudinal measurements. ResultsResults did not show differences for global vs. local coherence models and found more significant correlations between word2vec models and clinically relevant outcome variables than for GloVe models. Exploratory analysis of longitudinal data did not yield significant correlation with coherence scores. ConclusionThese results indicate that natural language processing methods need to be critically validated in more studies and carefully selected before clinical application.","2023-07-25","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","","14","","","","","","","","","","English","","","","WOS:001043890600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","artificial intelligence; automated analysis; coherence; formal thought disorder; natural language processing; psychosis; schizophrenia; SCHIZOPHRENIA; speech analysis; THOUGHT-DISORDER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"68DZ6QFY","journalArticle","2024","Tirronen, S; Kadiri, SR; Alku, P","The Effect of the MFCC Frame Length in Automatic Voice Pathology Detection","JOURNAL OF VOICE","","0892-1997","10.1016/j.jvoice.2022.03.021","","Automatic voice pathology detection is a research topic, which has gained increasing interest recently. Although methods based on deep learning are becoming popular, the classical pipeline systems based on a two-stage architecture consisting of a feature extraction stage and a classifier stage are still widely used. In these classical detection systems, frame-wise computation of mel-frequency cepstral coefficients (MFCCs) is the most popular feature extraction method. However, no systematic study has been conducted to investigate the effect of the MFCC frame length on automatic voice pathology detection. In this work, we studied the effect of the MFCC frame length in voice pathology detection using three disorders (hyperkinetic dysphonia, hypokinetic dysphonia and reflux laryngitis) from the Saarbru<euro>cken Voice Disorders (SVD) database. The detection performance was compared between speaker-dependent and speaker-independent scenarios as well as between speaking task-dependent and speaking task-independent scenarios. The Support Vector Machine, which is the most widely used classifier in the study area, was used as the classifier. The results show that the detection accuracy depended on the MFFC frame length in all the scenarios studied. The best detection accuracy was obtained by using a MFFC frame length of 500 ms with a shift of 5 ms.","2024-09","2025-02-26 20:43:30","2025-02-26 20:43:30","","975-982","","5","38","","","","","","","","","","English","","","","WOS:001316708400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","DESIGN; FREQUENCY CEPSTRAL COEFFICIENTS; IDENTIFICATION; MFCC; PARAMETERS; Pathology detection; RECOGNITION; REDUCTION; Speech analysis; SVM; Voice pathology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EHFET8XW","journalArticle","2024","Khan, WA; ul Qudous, H; Farhan, AA","Speech emotion recognition using feature fusion: a hybrid approach to deep learning","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-024-18316-7","","Speech emotion recognition holds significant importance as it enables machines to understand and respond to human emotions, enhancing human-computer interaction and personalized experiences. Accurate identification and interpretation of emotional states from speech signals enable various benefits, including enhanced personalized experiences, effective monitoring of mental health, and improved human-computer interfaces. However, recognizing emotions from speech is a difficult task primarily because there exists a significant disparity between acoustic features and human emotions. Both vocal cues and spoken words play significant roles in determining a person's emotional state. Therefore, in order to accurately identify human emotions from speech, it is essential to extract distinct and meaningful acoustic features. In this paper, we propose a novel approach to infer human emotional states. Human emotional state recognition has a wide range of applications ranging from customer service to mental health. Our proposed approach extracts a set of features from the speech signals, and employs a framework known as deep stride convolutional neural network using bi-directional LSTM. Our proposed model achieved a high accuracy of 95% which is almost 20% higher when compared to the state of the art on the RAVDESS dataset, while also minimizing the loss.","2024-02-19","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","","","","","","","","","","","","English","","","","WOS:001164365200003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Bi-LSTM; Chromagram; Contrast; Deep learning in speech analysis; Deep stride CNN; Feature fusion model; MFCC; MODEL; NEURAL-NETWORKS; Speech emotion recognition; Zero crossing rate","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9HZM8AIX","journalArticle","2021","Fernandes, B; Mannepalli, K","Speech Emotion Recognition Using Deep Learning LSTM for Tamil Language","PERTANIKA JOURNAL OF SCIENCE AND TECHNOLOGY","","0128-7680","10.47836/pjst.29.3.33","","Deep Neural Networks (DNN) are more than just neural networks with several hidden units that gives better results with classification algorithm in automated voice recognition activities. Then spatial correlation was considered in traditional feedforward neural networks and which do not manage speech signal properly to it extend, so recurrent neural networks (RNNs) were implemented. Long Short-Term Memory (LSTM) systems is a unique case of RNNs for speech processing, thus considering long-term dependencies Deep Hierarchical LSTM and BiLSTM is designed with dropout layers to reduce the gradient and long-term learning error in emotional speech analysis. Thus, four different combinations of deep hierarchical learning architecture Deep Hierarchical LSTM and LSTM (DHLL), Deep Hierarchical LSTM and BiLSTM (DHLB), Deep Hierarchical BiLSTM and LSTM (DHBL) and Deep Hierarchical dual BiLSTM (DHBB) is designed with dropout layers to improve the networks. The performance test of all four model were compared in this paper and better efficiency of classification is attained with minimal dataset of Tamil Language. The experimental results show that DHLB reaches the best precision of about 84% in recognition of emotions for Tamil database, however, the DHBL gives 83% of efficiency. Other design layers also show equal performance but less than the above models DHLL & DHBB shows 81% of efficiency for lesser dataset and minimal execution and training time.","2021-07","2025-02-26 20:43:30","2025-02-26 20:43:30","","1915-1936","","3","29","","","","","","","","","","English","","","","WOS:000684256600030","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","BiLSTM; CONVOLUTIONAL NEURAL-NETWORK; DNN; Emotional Recognition; LSTM; RNN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FFHC8Y9B","journalArticle","2024","Wang, ZY; Zhang, QF","Ageing of grammatical advance planning in spoken sentence production: an eye movement study","PSYCHOLOGICAL RESEARCH-PSYCHOLOGISCHE FORSCHUNG","","0340-0727","10.1007/s00426-023-01861-5","","This study used an image-description paradigm with concurrent eye movement recordings to investigate differences of grammatical advance planning between young and older speakers in spoken sentence production. Participants were asked to produce sentences with simple or complex initial phrase structures (IPS) in Experiment 1 while producing individual words in Experiment 2. Young and older speakers showed comparable speaking latencies in sentence production task, whereas older speakers showed longer latencies than young speakers in word production task. Eye movement data showed that compared with young speakers, older speakers had higher fixation percentage on object 1, lower percentage of gaze shift from object 1 to 2, and lower fixation percentage on object 2 in simple IPS sentences, while they showed similar fixation percentage on object 1, similar percentage of gaze shift from object 1 to 2, and lower fixation percentage on object 2 in complex IPS sentences, indicating a decline of grammatical encoding scope presenting on eye movement patterns. Meanwhile, speech analysis showed that older speakers presented longer utterance duration, slower speech rate, and longer and more frequently occurred pauses in articulation, indicating a decline of speech articulation in older speakers. Thus, our study suggests that older speakers experience an ageing effect in the sentences with complex initial phrases due to limited cognitive resources.","2024-03","2025-02-26 20:43:30","2025-02-26 20:43:30","","652-669","","2","88","","","","","","","","","","English","","","","WOS:001045664400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;94</p>","","","ADULT AGE-DIFFERENCES; BRAIN; COMPREHENSION; INDIVIDUAL-DIFFERENCES; INFORMATION; LANGUAGE PRODUCTION; PROCESSING-SPEED; SCOPE; WORKING-MEMORY; WRAP-UP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6ZRQZ8UW","journalArticle","2023","Pataca, CD; Costa, PDP","Hidden Bawls, Whispers, and Yelps: Can Text Convey the Sound of Speech, Beyond Words?","IEEE TRANSACTIONS ON AFFECTIVE COMPUTING","","1949-3045","10.1109/TAFFC.2022.3174721","","Whether a word was bawled, whispered, or yelped, captions will typically represent it in the same way. If they are your only way to access what is being said, subjective nuances expressed in the voice will be lost. Since so much of communication is carried by these nuances, we posit that if captions are to be used as an accurate representation of speech, embedding visual representations of paralinguistic qualities into captions could help readers use them to better understand speech beyond its mere textual content. This paper presents a model for processing vocal prosody (its loudness, pitch, and duration) and mapping it into visual dimensions of typography (respectively, font-weight, baseline shift, and letter-spacing), creating a visual representation of these lost vocal subtleties that can be embedded directly into the typographical form of text. An evaluation was carried out where participants were exposed to this speech-modulated typography and asked to match it to its originating audio, presented between similar alternatives. Participants (n=117) were able to correctly identify the original audios with an average accuracy of 65%, with no significant difference when showing them modulations as animated or static text. Additionally, participants' comments showed their mental models of speech-modulated typography varied widely.","2023-01-01","2025-02-26 20:43:30","2025-02-26 20:43:30","","6-16","","1","14","","","","","","","","","","English","","","","WOS:000966036500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Acoustics; Affective computing; Auditory system; Automobiles; EMOTION; emotion representation; Linguistics; Modulation; speech analysis; Speech recognition; speech visualization; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9CNKRHXF","journalArticle","2022","Dahy, G; Refaey, MAA; Alkhoribi, R; Shoman, M","A speech separation system in video sequence using dilated inception network and U-Net","EGYPTIAN INFORMATICS JOURNAL","","1110-8665","10.1016/j.eij.2022.09.001","","In this paper, an audio-visual model for separating a speech of the target speaker from a combination of other speakers' speeches is proposed. It can be used in speech separation, automatic speech recognition systems (ASR) and also in creating single speaker speech databases. Speech separation is complicated problem using audio information only so visual and auditory signals are combined to complete the sep-aration process. The proposed model consists of four modules, two for audio signal, one for visual feature and the last one used to concatenate the features resulted from the previous three modules to generate the separated signals. Our proposed model improved Short-time objective intelligibility (STOI) with 11%, Perceptual Evaluation of Speech Quality (PESQ) with 24%, and Frequency-weighted Segmental SNR (fwSNRseg) with 16% compared with previous works. It also improved Csig' which is the predicted rating of speech distortion with 13% and 'Covl' which is the predicted rating of overall quality with 18% com-pared with previous audio-visual models.(c) 2022 THE AUTHORS. Published by Elsevier BV on behalf of Faculty of Computers and Artificial Intel-ligence, Cairo University. This is an open access article under the CC BY-NC-ND license (http://creative-commons.org/licenses/by-nc-nd/4.0/).","2022-12","2025-02-26 20:43:30","2025-02-26 20:43:30","","121-131","","4","23","","","","","","","","","","English","","","","WOS:000903536100011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;15</p>","","","Audio-visual speech; Cepstral Coefficients; Log Filterbank Energies and Spectral; Speech Analysis using STFT; Speech separation; Subband Centroid; Surpassing Speech Noise","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FVAIPKE8","journalArticle","2021","Campi, M; Peters, GW; Azzaoui, N; Matsui, T","Machine Learning Mitigants for Speech Based Cyber Risk","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2021.3117080","","Statistical analysis of speech is an emerging area of machine learning. In this paper, we tackle the biometric challenge of Automatic Speaker Verification (ASV) of differentiating between samples generated by two distinct populations of utterances, those of an authentic human voice and those generated by a synthetic one. Solving such an issue through a statistical perspective foresees the definition of a decision rule function and a learning procedure to identify the optimal classifier. Classical state-of-the-art countermeasures rely on strong assumptions such as stationarity or local-stationarity of speech that may be atypical to encounter in practice. We explore in this regard a robust non-linear and non-stationary signal decomposition method known as the Empirical Mode Decomposition combined with the Mel-Frequency Cepstral Coefficients in a novel fashion with a refined classifier technique known as multi-kernel Support Vector machine. We undertake significant real data case studies covering multiple ASV systems using different datasets, including the ASVSpoof 2019 challenge database. The obtained results overwhelmingly demonstrate the significance of our feature extraction and classifier approach versus existing conventional methods in reducing the threat of cyber-attack perpetrated by synthetic voice replication seeking unauthorised access.","2021","2025-02-26 20:43:30","2025-02-26 20:43:30","","136831-136860","","","9","","","","","","","","","","English","","","","WOS:000706831000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","Biometrics (access control); COUNTERMEASURES; Cyberattack; empirical mode decomposition; EMPIRICAL MODE DECOMPOSITION; Feature extraction; FEATURES; RECOGNITION; SPEAKER VERIFICATION; speech analysis; Standards; support vector machine; Support vector machines; SYNTHESIS SYSTEM; Task analysis; Time-frequency analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CU99VNY2","journalArticle","2021","Park, H; Park, JS; Jeong, WS; Choi, JW","Dynamic Hemitongue Defect Reconstruction With Functional Gracilis Muscle Free Transfer","ANNALS OF PLASTIC SURGERY","","0148-7043","10.1097/SAP.0000000000002555","","Background Because the tongue consists of 26 intrinsic and extrinsic muscles, even hemiglossectomy, which preserves some of the tongue and its muscles, leads to functional morbidity in speech and swallowing. Subsequent reconstruction using a conventional fasciocutaneous flap results in limited functional recovery. This study compared the functional recovery of patients who underwent hemiglossectomy based on the fasciocutaneous free flap with or without dynamic gracilis muscle flap reconstruction. Methods Twenty-three patients were included in the study. Reconstruction was achieved using radial forearm and gracilis conjoined flaps (n = 7), gracilis flaps (n = 7), and radial forearm flaps (RFFFs) (n = 9) between 2014 and 2019. Functional outcome data were collected via videofluoroscopic swallowing, speech analysis, and a tongue movement scale. Results In the conjoined flap group, the lingual range of motion in terms of elevation and defect-side lateralization was superior to that of the RFFF group. Furthermore, the conjoined flap was associated with superior protrusion, elevation, and lateralization (on both sides) than the gracilis-only flap. Patients who underwent conjoined-flap reconstruction had better articulation, intelligence, and dysphagia outcomes than patients who underwent reconstruction with RFFFs or gracilis-only flaps. Conclusions Although this was a preliminary study, the findings suggest that using a conjoined free flap with an RFFF and a functional gracilis muscle flap for dynamic hemitongue reconstructions could improve postoperative tongue function.","2021-03","2025-02-26 20:43:30","2025-02-26 20:43:30","","308-316","","3","86","","","","","","","","","","English","","","","WOS:000617900500014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;15</p>","","","gracilis flap; radial forearm flap; tongue cancer; tongue reconstruction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CGLW8IED","journalArticle","2021","Ramallo-González, AP; González-Vidal, A; Skarmeta, AF","CIoTVID: Towards an Open IoT-Platform for Infective Pandemic Diseases such as COVID-19","SENSORS","","1424-8220","10.3390/s21020484","","The factors affecting the penetration of certain diseases such as COVID-19 in society are still unknown. Internet of Things (IoT) technologies can play a crucial role during the time of crisis and they can provide a more holistic view of the reasons that govern the outbreak of a contagious disease. The understanding of COVID-19 will be enriched by the analysis of data related to the phenomena, and this data can be collected using IoT sensors. In this paper, we show an integrated solution based on IoT technologies that can serve as opportunistic health data acquisition agents for combating the pandemic of COVID-19, named CIoTVID. The platform is composed of four layers-data acquisition, data aggregation, machine intelligence and services, within the solution. To demonstrate its validity, the solution has been tested with a use case based on creating a classifier of medical conditions using real data of voice, performing successfully. The layer of data aggregation is particularly relevant in this kind of solution as the data coming from medical devices has a very different nature to that coming from electronic sensors. Due to the adaptability of the platform to heterogeneous data and volumes of data; individuals, policymakers, and clinics could benefit from it to fight the propagation of the pandemic.","2021-01","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","2","21","","","","","","","","","","English","","","","WOS:000611699800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;18<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","covid19; IoT platform; spectrogram; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QN27SH2P","journalArticle","2021","Kocon, J; Figas, A; Gruza, M; Puchalska, D; Kajdanowicz, T; Kazienko, P","Offensive, aggressive, and hate speech analysis: From data-centric to human-centered approach","INFORMATION PROCESSING & MANAGEMENT","","0306-4573","10.1016/j.ipm.2021.102643","","Analysis of subjective texts like offensive content or hate speech is a great challenge, especially regarding annotation process. Most of current annotation procedures are aimed at achieving a high level of agreement in order to generate a high quality reference source. However, the annotation guidelines for subjective content may restrict the annotators' freedom of decision making. Motivated by a moderate annotation agreement in offensive content datasets, we hypothesize that personalized approaches to offensive content identification should be in place. Thus, we propose two novel perspectives of perception: group-based and individual. Using demographics of annotators as well as embeddings of their previous decisions (annotated texts), we are able to train multimodal models (including transformer-based) adjusted to personal or community profiles. Based on the agreement of individuals and groups, we experimentally showed that annotator group agreeability strongly correlates with offensive content recognition quality. The proposed personalized approaches enabled us to create models adaptable to personal user beliefs rather than to agreed offensiveness understanding. Overall, our individualized approaches to offensive content classification outperform classic data-centric methods that generalize offensiveness perception and it refers to all six tested models. Additionally, we developed requirements for annotation procedures, personalization and content processing to make the solutions human-centered.","2021-09","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","5","58","","","","","","","","","","English","","","","WOS:000679812700014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;53<br/>Total Times Cited:&nbsp;&nbsp;54<br/>Cited Reference Count:&nbsp;&nbsp;144</p>","","","Annotator agreement; Hate speech; Human-centered NLP; Multimodal deep learning; Offensive content; Personalization; Subjective content perception; TEMPORAL EXPRESSIONS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QF5446VX","journalArticle","2022","Huang, GX; Ni, A; Lu, WD; Peng, H; Wang, JW","Sub-Nyquist Sampling of Multiple Exponentially Damped Sinusoids With Feedback Structure","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2021.3128712","","Multiple exponentially damped sinusoids (MEDS) signals have been widely applied to the fields of speech analysis and nuclear magnetic resonance imaging systems. Although sub-Nyquist sampling schemes were proposed in previous works, either the image frequency aliasing was not resolved or the parameters measuring process required a large number of samples. In this article, a feedback-based sub-Nyquist sampling and parameters measurement scheme for MEDS signals is proposed to address these problems. Since sub-Nyquist sampling would lead to frequencies ambiguity, an additional sampling is designed to determine the true frequencies. Moreover, image frequency aliasing would occur when the difference between two true frequencies is an integer multiple of the sampling rate. To prevent image frequency aliasing, a feedback sampling strategy and a dealiasing algorithm are proposed. The proposed scheme enables the sub-Nyquist sampling and parameters measurement of MEDS signals with K frequency components by using only 4K samples. We also propose a hardware prototype to implement the proposed system. Simulation and hardware experiment results have shown that the frequency estimation accuracy of the proposed method has been improved on average by about 11.65 dB than previous works under noise environment, and the statistical variance experiments have shown that it has better stability.","2022","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","","71","","","","","","","","","","English","","","","WOS:000761247800048","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Damping; ERROR; Estimation; Frequency ambiguity; Frequency estimation; Hardware; image frequency aliasing; Image resolution; Mathematical models; multiple exponentially damped sinusoids (MEDS); parameter measurement; PARAMETER-ESTIMATION; Signal resolution; sub-Nyquist sampling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H3AT6D3M","journalArticle","2021","Binos, P; Theodorou, E; Elriz, T; Konstantopoulos, K","Effectiveness of Aural-Oral Approach Based on Volubility of a Deaf Child with Late-Mapping Bilateral Cochlear Implants","AUDIOLOGY RESEARCH","","2039-4330","10.3390/audiolres11030035","","Background: The purpose of this study was to investigate the effectiveness of aural-oral habilitation (AO) over the traditional speech-language therapy, based on the number of vocalization-volubility of a deaf child with late-mapping bilateral cochlear implants using sequential measurements. Methods: The spontaneous productions during child interactions were analyzed. The child (CY, 7;0 years old) with a mean unaided pure-tone average (PTA) hearing loss >80 dB HL was assessed by using an assessment battery. Study design consisted of two phases: (a) baseline (end of speech therapy) and (b) end of AO treatment. Protophones were analyzed via acoustical analysis using PRAAT software. Results: One-way repeated-measure ANOVAs were conducted within and between phases. The analyses revealed significant differences between the 'phase' and the vocalization outcome (F = 9.4, df = 1, p = 0.035). Post hoc analyses revealed the significant difference between the mean number of disyllable vocalizations of AO approach (p = 0.05). The mean number of vocalizations was calculated for each protophone type, but no other significant difference was measured. Conclusions: AO approach proved effective as measured through volubility. The outcome of this study is indicative and is a starting point for broader research.","2021-09","2025-02-26 20:43:30","2025-02-26 20:43:30","","373-383","","3","11","","","","","","","","","","English","","","","WOS:000702380200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","aural approach; cochlear implant; INFANTS; INTELLIGIBILITY; PRELINGUALLY DEAF; protophones; SKILLS; speech analysis; SPEECH-PERCEPTION; VOCAL DEVELOPMENT; volubility","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YCHVINS8","journalArticle","2021","Stegmann, GM; Hahn, S; Duncan, CJ; Rutkove, SB; Liss, J; Shefner, JM; Berisha, V","Estimation of forced vital capacity using speech acoustics in patients with ALS","AMYOTROPHIC LATERAL SCLEROSIS AND FRONTOTEMPORAL DEGENERATION","","2167-8421","10.1080/21678421.2020.1866013","","In this study, we present and provide validation data for a tool that predicts forced vital capacity (FVC) from speech acoustics collected remotely via a mobile app without the need for any additional equipment (e.g. a spirometer). We trained a machine learning model on a sample of healthy participants and participants with amyotrophic lateral sclerosis (ALS) to learn a mapping from speech acoustics to FVC and used this model to predict FVC values in a new sample from a different study of participants with ALS. We further evaluated the cross-sectional accuracy of the model and its sensitivity to within-subject change in FVC. We found that the predicted and observed FVC values in the test sample had a correlation coefficient of .80 and mean absolute error between .54 L and .58 L (18.5% to 19.5%). In addition, we found that the model was able to detect longitudinal decline in FVC in the test sample, although to a lesser extent than the observed FVC values measured using a spirometer, and was highly repeatable (ICC = 0.92-0.94), although to a lesser extent than the actual FVC (ICC = .97). These results suggest that sustained phonation may be a useful surrogate for VC in both research and clinical environments.","2021-07-30","2025-02-26 20:43:30","2025-02-26 20:43:30","","14-21","","","22","","","","","","","","","","English","","","","WOS:000681584200005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","biomarker; Clinical trial; MODELS; respiratory function; speech analysis; ventilation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WH46N38R","journalArticle","2022","Uddin, MA; Pathan, RK; Hossain, MS; Biswas, M","Gender and region detection from human voice using the three-layer feature extraction method with 1D CNN","JOURNAL OF INFORMATION AND TELECOMMUNICATION","","2475-1839","10.1080/24751839.2021.1983318","","Analysing the human voice has always been a challenge to the engineering society for various purposes such as product review, emotional state detection, developing AI, and much more. Two basic grounds of voice or speech analysis are to detect human gender and the geographical region based on accent. This study presents a three-layer feature extraction method from the raw human voice to detect the gender as male or female, as well as the region from where that voice belongs. Fundamental frequency, spectral entropy, spectral flatness, and mode frequency have been calculated in the first layer of feature extraction. On the other hand, Mel Frequency Cepstral Coefficient has been used to extract the features in the second layer and linear predictive coding in the third layer. Regular voice contains some noises which have been removed with multiple audio data filtering processes to get noise-free smooth data. Multi-Output-based 1D Convolutional Neural Network has been used to recognize gender and region from a combined dataset which consists of TIMIT, RAVDESS, and BGC datasets. The model has successfully predicted the gender with 93.01% and region with 97.07% accuracy. This method works better than usual state-of-the-art methods in separate datasets along with the combined dataset on both gender and region classification.","2022-01-02","2025-02-26 20:43:30","2025-02-26 20:43:30","","27-42","","1","6","","","","","","","","","","English","","","","WOS:000706227100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","1D CNN; Gender recognition; MFCC; RECOGNITION; region of accent detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SHBJY3S2","journalArticle","2024","Arbogast, T; Van Doorslaer, H; Vermeiren, M","Another strange non-death: the NAIRU and the ideational foundations of the Federal Reserve's new monetary policy framework","REVIEW OF INTERNATIONAL POLITICAL ECONOMY","","0969-2290","10.1080/09692290.2023.2250348","","Monetary policy has long relied on the 'natural rate hypothesis', suggesting that after an economic shock the unemployment rate will automatically return to its supply-side 'natural' rate or NAIRU. Macroeconomic developments since the 2008 financial crisis have challenged this hypothesis, forcing the US Federal Reserve to conduct a strategic review of its monetary policy framework, published in 2020. We conducted an in-depth case study of the Fed through a content analysis of 120 speeches given by the Fed's top-level body (FOMC) from 2012 to 2022. We show that policy learning has occurred in that FOMC members have problematised the NAIRU either on (1) epistemological grounds, acknowledging the risk of relying on NAIRU estimates, or on (2) ontological grounds, highlighting the endogeneity of the NAIRU to monetary policy. While both interpretations lead to a more expansionary monetary policy stance, the differing motivations matter for future policymaking. In the case of (1) the rationale is mainly to a avoid downward de-anchoring of inflation expectations, whereas with (2) it is to deliberately chase hot labour markets and a high-pressure-economy. Our speech analysis shows that (1) has been far more dominant in the FOMC, indicating incremental rather than fundamental ideational change.","2024-05-03","2025-02-26 20:43:30","2025-02-26 20:43:30","","805-830","","3","31","","","","","","","","","","English","","","","WOS:001056260100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","Central banks; hysteresis; IDEAS; ideational change; INFLATION; labour market; LESSONS; monetary policy; NAIRU; NATURAL RATE; natural rate of unemployment; policy learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VZFF3JGF","journalArticle","2023","Freixes, M; Joglar-Ongay, L; Socoró, JC; Alías-Pujol, F","Evaluation of Glottal Inverse Filtering Techniques on OPENGLOT Synthetic Male and Female Vowels","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13158775","","Current articulatory-based three-dimensional source-filter models, which allow the production of vowels and diphtongs, still present very limited expressiveness. Glottal inverse filtering (GIF) techniques can become instrumental to identify specific characteristics of both the glottal source signal and the vocal tract transfer function to resemble expressive speech. Several GIF methods have been proposed in the literature; however, their comparison becomes difficult due to the lack of common and exhaustive experimental settings. In this work, first, a two-phase analysis methodology for the comparison of GIF techniques based on a reference dataset is introduced. Next, state-of-the-art GIF techniques based on iterative adaptive inverse filtering (IAIF) and quasi closed phase (QCP) approaches are thoroughly evaluated on OPENGLOT, an open database specifically designed to evaluate GIF, computing well-established GIF error measures after extending male vowels with their female counterparts. The results show that GIF methods obtain better results on male vowels. The QCP-based techniques significantly outperform IAIF-based methods for almost all error metrics and scenarios and are, at the same time, more stable across sex, phonation type, F0, and vowels. The IAIF variants improve the original technique for most error metrics on male vowels, while QCP with spectral tilt compensation achieves a lower spectral tilt error for male vowels than the original QCP.","2023-08","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","15","13","","","","","","","","","","English","","","","WOS:001046140100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","FLOW; glottal inverse filtering; glottal source; OPENGLOT; PERCEPTION; performance evaluation; phonation types; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UVTWD3EK","journalArticle","2024","Malakar, M; Keskar, RB; Zadgaonkar, A","Hypertension Detection Through Speech Analysis Using Machine Learning-Based Approaches with the Identification of BP Sensitive Phonemes and Features","INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS","","0218-2130","10.1142/S0218213024500210","","There are certain difficulties and unpleasant issues related to conventional diagnostic tools. These factors tilted the researchers toward finding an alternative non-invasive way of diagnosis. This alternate approach usually involves physiological and lifestyle-related data. The non-invasive tools are more convenient for common people as they are user-friendly and have no side effects. At the same time, they are cost-effective as well. The non-invasive diagnosis is also preferred by the people who live in places where medical facilities are not abundant. This study concentrates on detecting a person as hypertensive by analyzing certain parameters in speech using machine learning approaches. We identify some phonemes and features of speech that are more sensitive to capture the distortions in speech due to hypertension. Four different machine learning methods involving both classical and state-of-the-art methods in our study show the effectiveness of both types of machine learning methods in different dimensions. The study shows inspiring results in terms of prediction accuracy ( similar to 95%) as well as identifying a minimal set of hypertension-sensitive features. It is also found that when we combine the predictions of both classical and state-of-the-art methods, the result gives more reliable predictions.","2024-09","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","06","33","","","","","","","","","","English","","","","WOS:001340314200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","cepstral features; Hypertension, machine learning; optimal feature set; phoneme analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HWFJGNF4","journalArticle","2024","Rybinski, K","Automated question answering for unveiling leadership dynamics in US Presidential speeches","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.125222","","This study introduces an innovative methodology utilising deep learning and automated question-answering techniques to explore leadership dynamics. The research analyses 989 speeches from U.S. Presidents, ranging from George Washington to Joe Biden, applying a machine learning model to decipher the essence of effective leadership within the context of presidential rhetoric. This approach facilitates an interrogation of ""What constitutes a great leader?"" by extracting pertinent attributes from these presidential discourses. The study conducts a comprehensive statistical examination of the responses generated, unveiling the evolution of presidential perspectives on leadership across historical epochs. Furthermore, the research employs a regression analysis that extends over 120 years, integrating the attributes of outstanding leadership with the Economic Policy Uncertainty (EPU) index specific to the United States. The findings indicate that periods marked by heightened uncertainty necessitate leaders with a charismatic approach, whereas servant leadership is more effective during times of reduced uncertainty. An extensive validation and robustness assessment of the study affirm that the outcomes are steadfast, notwithstanding variations in key parameters of the deployed machine learning models. Moreover, these findings align coherently with the qualitative assessments of U.S. Presidential views on leadership undertaken in prior research, thus contributing novel insights into the intricate relationship between leadership qualities and historical and economic contexts.","2024-12-15","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","","258","","","","","","","","","","English","","","","WOS:001309616300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Automated question answering; FUTURE; Leadership; Natural language processing; Speech analysis; US presidents","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5PZCV8MB","journalArticle","2022","Mota, NB; Pimenta, J; Tavares, M; Palmeira, L; Loch, AA; Hedin-Pereira, C; Dias, EC","A Brazilian bottom-up strategy to address mental health in a diverse population over a large territorial area - an inspiration for the use of digital mental health","PSYCHIATRY RESEARCH","","0165-1781","10.1016/j.psychres.2022.114477","","Brazil is a continental country with a history of massive immigration waves from around the world. Consequently, the Brazilian population is rich in ethnic, cultural, and religious diversity, but suffers from tremendous socioeconomic inequality. Brazil has a documented history of categorizing individuals with culturally specific behaviors as mentally ill, which has led to psychiatric institutionalization for reasons that were more social than clinical. To address this, a ""network for psychosocial care"" was created in Brazil, that included mental health clinics and community services distributed throughout the country. This generates local support for mental health rehabilitation, integrating psychiatric care, family support and education/work opportunities. These clinics and community services are tailored to provide care for each specific area, and are more attuned to regional culture, values and neighborhood infrastructure. Here we review existing reports about the Brazilian experience, including advances in public policy on mental health, and challenges posed by the large diversity to the psychosocial rehabilitation. In addition, we show how new digital technologies in general, and computational speech analysis in particular, can contribute to unbiased assessments, resulting in decreased stigma and more effective diagnosis of the mental diseases, with methods that are free of gender, ethnic, or socioeconomic biases.","2022-05","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","","311","","","","","","","","","","English","","","","WOS:000835603600004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","CARE; COMMUNITY; Computational psychiatry; Diversity; Psychiatric rehabilitation; Public policy; SOCIAL DETERMINANTS; Social stigma; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A5RD8724","journalArticle","2024","Lv, H; Liu, JD; Chen, Q; Ji, JZ; Zhai, JH; Zhang, ZZ; Wang, ZD; Gong, SS; Wang, ZC","Brain Network Evaluation by Functional-Guided Effective Connectivity Reinforcement Learning Method Indicates Therapeutic Effect for Tinnitus","IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING","","1534-4320","10.1109/TNSRE.2024.3373335","","Using functional connectivity (FC) or effective connectivity (EC) alone cannot effectively delineate brain networks based on functional magnetic resonance imaging (fMRI) data, limiting the understanding of the mechanism of tinnitus and its treatment. Investigating brain FC is a foundational step in exploring EC. This study proposed a functionally guided EC (FGEC) method based on reinforcement learning (FGECRL) to enhance the precision of identifying EC between distinct brain regions. An actor-critic framework with an encoder-decoder model was adopted as the actor network. The encoder utilizes a transformer model; the decoder employs a bidirectional long short-term memory network with attention. An FGEC network was constructed for the enrolled participants per fMRI scan, including 65 patients with tinnitus and 28 control participants healthy at the enrollment time. After 6 months of sound therapy for tinnitus and prospective follow-up, fMRI data were acquired again and retrospectively categorized into an effective group (EG) and an ineffective group (IG) according to the treatment effect. Compared with FC and EC, the FGECRL method demonstrated better accuracy in discriminating between different groups, highlighting the advantage of FGECRL in identifying brain network features. For the FGEC network of the EG and IG per state (before and after treatment) and healthy controls, effective therapy is characterized by a similar pattern of FGEC network between patients with tinnitus after treatment and healthy controls. Deactivated information output in the motor network, somatosensory network, and medioventral occipital cortex may biologically indicate effective treatment. The maintenance of decreased EC in the primary auditory cortex may represent a failure of sound therapy, further supporting the Bayesian inference theory for tinnitus perception. The FGEC network can provide direct evidence for the mechanism of sound therapy in patients with tinnitus with distinct outcomes.","2024","2025-02-26 20:43:30","2025-02-26 20:43:30","","1132-1141","","","32","","","","","","","","","","English","","","","WOS:001184889600003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Brain modeling; brain network; Data models; Decoding; fMRI; Functional magnetic resonance imaging; Mathematical models; Medical treatment; reinforcement learning; Reinforcement learning; sound therapy; Tinnitus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9NR423D8","journalArticle","2023","Luo, J; Wang, YJ; Xia, SX; Lu, N; Ren, XY; Shi, ZH; Hei, XH","A shallow mirror transformer for subject-independent motor imagery BCI","COMPUTERS IN BIOLOGY AND MEDICINE","","0010-4825","10.1016/j.compbiomed.2023.107254","","Objective: Motor imagery BCI plays an increasingly important role in motor disorders rehabilitation. However, the position and duration of the discriminative segment in an EEG trial vary from subject to subject and even trial to trial, and this leads to poor performance of subject-independent motor imagery classification. Thus, determining how to detect and utilize the discriminative signal segments is crucial for improving the performance of subject-independent motor imagery BCI. Approach: In this paper, a shallow mirror transformer is proposed for subject-independent motor imagery EEG classification. Specifically, a multihead self-attention layer with a global receptive field is employed to detect and utilize the discriminative segment from the entire input EEG trial. Furthermore, the mirror EEG signal and the mirror network structure are constructed to improve the classification precision based on ensemble learning. Finally, the subject-independent setup was used to evaluate the shallow mirror transformer on motor imagery EEG signals from subjects existing in the training set and new subjects. Main results: The experiments results on BCI Competition IV datasets 2a and 2b and the OpenBMI dataset demonstrated the promising effectiveness of the proposed shallow mirror transformer. The shallow mirror transformer obtained average accuracies of 74.48% and 76.1% for new subjects and existing subjects, respectively, which were highest among the compared state-of-the-art methods. In addition, visualization of the attention score showed the ability of discriminative EEG segment detection. This paper demonstrated that multihead self-attention is effective in capturing global EEG signal information in motor imagery classification. Significance: This study provides an effective model based on a multihead self-attention layer for subject-independent motor imagery-based BCIs. To the best of our knowledge, this is the shallowest transformer model available, in which a small number of parameters promotes the performance in motor imagery EEG classification for such a small sample problem.","2023-09","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","","164","","","","","","","","","","English","","","","WOS:001047289300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;21<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","ATTENTION; Brain-computer interfaces (BCI); EEG; INTERFACES; Motor imagery (MI); Multihead self-attention; NETWORK; Subject-independent BCI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2W2SX8V4","journalArticle","2023","Katar, O; Yildirim, O","An Explainable Vision Transformer Model Based White Blood Cells Classification and Localization","DIAGNOSTICS","","2075-4418","10.3390/diagnostics13142459","","White blood cells (WBCs) are crucial components of the immune system that play a vital role in defending the body against infections and diseases. The identification of WBCs subtypes is useful in the detection of various diseases, such as infections, leukemia, and other hematological malignancies. The manual screening of blood films is time-consuming and subjective, leading to inconsistencies and errors. Convolutional neural networks (CNN)-based models can automate such classification processes, but are incapable of capturing long-range dependencies and global context. This paper proposes an explainable Vision Transformer (ViT) model for automatic WBCs detection from blood films. The proposed model uses a self-attention mechanism to extract features from input images. Our proposed model was trained and validated on a public dataset of 16,633 samples containing five different types of WBCs. As a result of experiments on the classification of five different types of WBCs, our model achieved an accuracy of 99.40%. Moreover, the model's examination of misclassified test samples revealed a correlation between incorrect predictions and the presence or absence of granules in the cell samples. To validate this observation, we divided the dataset into two classes, Granulocytes and Agranulocytes, and conducted a secondary training process. The resulting ViT model, trained for binary classification, achieved impressive performance metrics during the test phase, including an accuracy of 99.70%, recall of 99.54%, precision of 99.32%, and F-1 score of 99.43%. To ensure the reliability of the ViT model's, we employed the Score-CAM algorithm to visualize the pixel areas on which the model focuses during its predictions. Our proposed method is suitable for clinical use due to its explainable structure as well as its superior performance compared to similar studies in the literature. The classification and localization of WBCs with this model can facilitate the detection and reporting process for the pathologist.","2023-07","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","14","13","","","","","","","","","","English","","","","WOS:001035148900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","deep learning; explainable AI models; Score-CAM; vision transformers; white blood cells","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VVSKBXBT","journalArticle","2024","Aberna, P; Agilandeeswari, L","Optimal Semi-Fragile Watermarking Based on Maximum Entropy Random Walk and Swin Transformer for Tamper Localization","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3370411","","In the multimedia arena, image tampering is an uncontrollable process that necessitates content authentication and tamper detection in a variety of applications. One method that is recommended for meeting all of those needs in the multimedia arena is watermarking. Mobile cameras may now be used to effortlessly take high dynamic range (HDR) photographs, which increase the image's visual quality and realism. Watermark visibility and recognition algorithms built for standard images may be affected by this introduction of perceptual variations in the image relative to the source. In order to overcome those shortcomings, we introduced a novel, an optimal semi-blind watermarking technique that works for both colour and HDR compressed JPEG images. A unique quaternion dual-tree complex wavelet transform technique is used to extract the highly informative features from the original image. The optimal embedding region in the low frequency sub-band is determined using the maximal entropy random walk (MERW) algorithm. In order to detect tampering and to localize the tampered region a watermark is generated using the swin transformer model and watermark embedding is carried out in the selected optimal blocks. A dual scrambled image is encoded in the effective principal component coefficient values of the singular value decomposition (SVD) Transform in order to authenticate the watermarked image prior to watermark extraction. The semi-blind extraction process is intended to confirm the content's authenticity by comparing the recovered scrambled watermark with the regenerated original watermark. The process of extraction is merely the opposite of the process of embedding. When compared to previous research, the experimental results demonstrated good imperceptibility with an average PSNR of 65 dB and SSIM of 0.999 and strong robustness against attacks.","2024","2025-02-26 20:43:30","2025-02-26 20:43:30","","37757-37781","","","12","","","","","","","","","","English","","","","WOS:001189822500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","ALGORITHM; Authentication; Discrete wavelet transforms; Feature extraction; High dynamic image; Image color analysis; IMAGE WATERMARKING; maximum entropy random walk algorithm; Multimedia communication; PSNR; quaternion dual-tree complex wavelet transform; Quaternions; SCHEME; Swin transformer; Transformers; Transforms; Watermarking; Wavelet transforms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"325GR4GW","journalArticle","2022","Klein, AZ; Magge, A; Gonzalez-Hernandez, G","ReportAGE: Automatically extracting the exact age of Twitter users based on self-reports in tweets","PLOS ONE","","1932-6203","10.1371/journal.pone.0262087","","Advancing the utility of social media data for research applications requires methods for automatically detecting demographic information about social media study populations, including users' age. The objective of this study was to develop and evaluate a method that automatically identifies the exact age of users based on self-reports in their tweets. Our end-to-end automatic natural language processing (NLP) pipeline, ReportAGE, includes query patterns to retrieve tweets that potentially mention an age, a classifier to distinguish retrieved tweets that self-report the user's exact age (""age"" tweets) and those that do not (""no age"" tweets), and rule-based extraction to identify the age. To develop and evaluate ReportAGE, we manually annotated 11,000 tweets that matched the query patterns. Based on 1000 tweets that were annotated by all five annotators, inter-annotator agreement (Fleiss' kappa) was 0.80 for distinguishing ""age"" and ""no age"" tweets, and 0.95 for identifying the exact age among the ""age"" tweets on which the annotators agreed. A deep neural network classifier, based on a RoBERTa-Large pretrained transformer model, achieved the highest F-1-score of 0.914 (precision = 0.905, recall = 0.942) for the ""age"" class. When the age extraction was evaluated using the classifier's predictions, it achieved an F-1-score of 0.855 (precision = 0.805, recall = 0.914) for the ""age"" class. When it was evaluated directly on the held-out test set, it achieved an F-1-score of 0.931 (precision = 0.873, recall = 0.998) for the ""age"" class. We deployed ReportAGE on a collection of more than 1.2 billion tweets, posted by 245,927 users, and predicted ages for 132,637 (54%) of them. Scaling the detection of exact age to this large number of users can advance the utility of social media data for research applications that do not align with the predefined age groupings of extant binary or multi-class classification approaches.","2022-01-25","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","1","17","","","","","","","","","","English","","","","WOS:000792720400021","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DVKRG9TY","journalArticle","2021","Borson, S; Chen, AY; Wang, SE; Nguyen, HQ","Patterns of incident dementia codes during the COVID-19 pandemic at an integrated healthcare system","JOURNAL OF THE AMERICAN GERIATRICS SOCIETY","","0002-8614","10.1111/jgs.17527","","Background The COVID-19 pandemic delayed diagnosis and care for some acute conditions and reduced monitoring for some chronic conditions. It is unclear whether new diagnoses of chronic conditions such as dementia were also affected. We compared the pattern of incident Alzheimer's disease and related dementia (ADRD) diagnosis codes from 2017 to 2019 through 2020, the first pandemic year. Methods Retrospective cohort design, leveraging 2015-2020 data on all members 65 years and older with no prior ADRD diagnosis, enrolled in a large integrated healthcare system for at least 2 years. Incident ADRD was defined as the first ICD-10 code at any encounter, including outpatient (face-to-face, video, or phone), hospital (emergency department, observation, or inpatient), or continuing care (home, skilled nursing facility, and long-term care). We also examined incident ADRD codes and use of telehealth by age, sex, race/ethnicity, and spoken language. Results Compared to overall annual incidence rates for ADRD codes in 2017-2019, 2020 incidence was slightly lower (1.30% vs. 1.40%), partially compensating later in the year for reduced rates during the early months of the pandemic. No racial or ethnic group differences were identified. Telehealth ADRD codes increased fourfold, making up for a 39% drop from face-to-face outpatient encounters. Older age (85+) was associated with higher odds of receiving telecare versus face-to-face care in 2020 (OR:1.50, 95%CI: 1.25-1.80) and a slightly lower incidence of new codes; no racial/ethnic, sex, or language differences were identified in the mode of care. Conclusions Rates of incident ADRD codes dropped early in the first pandemic year but rose again to near pre-pandemic rates for the year as a whole, as clinicians rapidly pivoted to telehealth. With refinement of protocols for remote dementia detection and diagnosis, health systems could improve access to equitable detection and diagnosis of ADRD going forward.","2021-12","2025-02-26 20:43:30","2025-02-26 20:43:30","","3389-3396","","12","69","","","","","","","","","","English","","","","WOS:000710509300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","ALZHEIMER-DISEASE; dementia diagnosis; incident ADRD codes; MINI-MENTAL-STATE; SELECTION; telehealth","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XEWLZQ78","journalArticle","2024","Celik, E; Omurca, SI","Skip-Gram and Transformer Model for Session-Based Recommendation","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14146353","","Session-based recommendation uses past clicks and interaction sequences from anonymous users to predict the next item most likely to be clicked. Predicting the user's subsequent behavior in online transactions becomes a problem mainly due to the lack of user information and limited behavioral information. Existing methods, such as recurrent neural network (RNN)-based models that model user's past behavior sequences and graph neural network (GNN)-based models that capture potential relationships between items, miss different time intervals in the past behavior sequence and can only capture certain types of user interest patterns due to the characteristics of neural networks. Graphic models created to improve the current session reduce the model's success due to the addition of irrelevant items. Moreover, attention mechanisms in recent approaches have been insufficient due to weak representations of users and products. In this study, we propose a model based on the combination of skip-gram and transformer (SkipGT) to solve the above-mentioned drawbacks in session-based recommendation systems. In the proposed method, skip-gram both captures chained user interest in the session thread through item-specific subreddits and learns complex interaction information between items. The proposed method captures short-term and long-term preference representations to predict the next click with the help of a transformer. The transformer in our proposed model overcomes many limitations in turn-based models and models longer contextual connections between items more effectively. In our proposed model, by giving the transformer trained item embeddings from the skip-gram model as input, the transformer has better performance because it does not learn item representations from scratch. By conducting extensive experiments with three real-world datasets, we confirm that SkipGT significantly outperforms state-of-the-art solutions with an average MRR score of 5.58%.","2024-07","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","14","14","","","","","","","","","","English","","","","WOS:001276531000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","recommender system; session-based recommendation; skip-gram; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PBHYWRJR","journalArticle","2023","Liu, LB; Perez-Concha, O; Nguyen, A; Bennett, V; Jorm, L","Automated ICD coding using extreme multi-label long text transformer-based models","ARTIFICIAL INTELLIGENCE IN MEDICINE","","0933-3657","10.1016/j.artmed.2023.102662","","Encouraged by the success of pretrained Transformer models in many natural language processing tasks, their use for International Classification of Diseases (ICD) coding tasks is now actively being explored. In this study, we investigated two existing Transformer-based models (PLM-ICD and XR-Transformer) and proposed a novel Transformer-based model (XR-LAT), aiming to address the extreme label set and long text classification challenges that are posed by automated ICD coding tasks. The Transformer-based model PLM-ICD, which currently holds the state-of-the-art (SOTA) performance on the ICD coding benchmark datasets MIMIC-III and MIMIC-II, was selected as our baseline model for further optimisation on both datasets. In addition, we extended the capabilities of the leading model in the general extreme multi-label text classification domain, XR-Transformer, to support longer sequences and trained it on both datasets. Moreover, we proposed a novel model, XR-LAT, which was also trained on both datasets. XR-LAT is a recursively trained model chain on a predefined hierarchical code tree with label-wise attention, knowledge transferring and dynamic negative sampling mechanisms. Our optimised PLM-ICD models, which were trained with longer total and chunk sequence lengths, significantly outperformed the current SOTA PLM-ICD models, and achieved the highest micro-F1 scores of 60.8 % and 50.9 % on MIMIC-III and MIMIC-II, respectively. The XR-Transformer model, although SOTA in the general domain, did not perform well across all metrics. The best XR-LAT based models obtained results that were competitive with the current SOTA PLM-ICD models, including improving the macro-AUC by 2.1 % and 5.1 % on MIMIC-III and MIMIC-II, respectively. Our optimised PLM-ICD models are the new SOTA models for automated ICD coding on both datasets, while our novel XR-LAT models perform competitively with the previous SOTA PLM-ICD models.","2023-10","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","","144","","","","","","","","","","English","","","","WOS:001080316500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Discharge summaries; Extreme multi-label long text classification; ICD coding; MIMIC-II; MIMIC-III; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4EVE7XAK","journalArticle","2023","Huertas-García, A; Marín, A; Huertas-Tato, J; Camacho, D","Countering malicious content moderation evasion in online social networks: Simulation and detection of word camouflage","APPLIED SOFT COMPUTING","","1568-4946","10.1016/j.asoc.2023.110552","","Content moderation is the process of screening and monitoring user-generated content online. It plays a crucial role in stopping content resulting from unacceptable behaviors such as hate speech, harassment, violence against specific groups, terrorism, racism, xenophobia, homophobia, or misogyny, to mention some few, in Online Social Platforms. These platforms make use of a plethora of tools to detect and manage malicious information; however, malicious actors also improve their skills, developing strategies to surpass these barriers and continuing to spread misleading information. Twisting and camouflaging keywords are among the most widely used techniques to evade platform content moderation systems. In response to this recent ongoing issue This paper presents an innovative approach to address this linguistic trend in social networks through the simulation of different content evasion techniques and a multilingual transformer model for content evasion detection. In this way a multilingual public tool Named ""pyleetspeak""is shared with the scientific community, enabling the generation and simulation of content evasion through automatic word camouflage in a customizable way. Additionally a multilingual named-entity recognition (NER) transformer-based model is provided Designed for the recognition and detection of such evasion technique. The developed tool is multilingual Supporting over 20 languages (ar, az, da, de, el, en, es, fi, fr, hu, id, it, kk, nb, ne, nl, pt, ro, ru, sl, sv, tg, tr) and the NER model has been tested in English, Spanish, French, Italian, and German. This multilingual NER model is evaluated in different textual scenarios Detecting different types and mixtures of camouflage techniques Achieving an overall weighted F1 score of 0.8795. This article contributes significantly to countering malicious information by developing multilingual tools to simulate and detect new methods of evasion of content on social networks Making the fight against information disorders more effective","2023-09","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","","145","","","","","","","","","","English","","","","WOS:001055664000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","Content evasion; Information disorders; Leetspeak; Multilingualism; Word camouflage","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XZEK7Q68","journalArticle","2023","Hernandez, C; Lara, J; Arjona, MA; Melgoza-Vazquez, E","Multi-Objective Electromagnetic Design Optimization of a Power Transformer Using 3D Finite Element Analysis, Response Surface Methodology, and the Third Generation Non-Sorting Genetic Algorithm","ENERGIES","","1996-1073","10.3390/en16052248","","This paper presents a multi-objective design optimization of a power transformer to find the optimal geometry of its core and the low- and high-voltage windings, representing the minimum power losses and the minimum core and copper weights. The optimal design is important because it allows manufacturers to build more efficient and economical transformers. The approach employs a manufacturer's design methodology, which is based on the usage of the laws of physics and leads to an analytical transformer model with the advantage of requiring a low amount of computing time. Afterward, the multi-objective design optimization is defined along with its constraints, and they are solved using the Non-Sorting Genetic Algorithm III (NSGA-III), which finds a set of optimal solutions. Once an optimal solution is selected from the Pareto front, it is necessary to fine-tune it with the 3D Finite Element Analysis (FEA). To avoid the large computing times needed to carry out the 3D Finite Element (FE) model simulations used in multi-objective design optimization, Response Surface Methodology (RSM) polynomial models are developed using 3D FE model transformer simulations. Finally, a second multi-objective design optimization is carried out using the developed RSM empirical models that represent the cost functions and is solved using the NSGA-III. The numerical results of the optimal core and windings geometries demonstrate the validity of the proposed design methodology based on the NSGA-III. The used global optimizer has the feature of solving optimization problems with many cost functions, but it has not been applied to the design of transformers. The results obtained in this paper demonstrate better performance and accuracy with respect to the commonly used NSGA-II.","2023-03","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","5","16","","","","","","","","","","English","","","","WOS:000948249200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","finite element analysis; genetic algorithms; optimization; power transformer; surface response methodology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E2NR2ZUX","journalArticle","2022","Xia, GZ; Liu, MR; Zhang, FB; Zhou, C","CAiTST: Conv-Attentional Image Time Sequence Transformer for Ionospheric TEC Maps Forecast","REMOTE SENSING","","2072-4292","10.3390/rs14174223","","In recent years, transformer has been widely used in natural language processing (NLP) and computer vision (CV). Comparatively, forecasting image time sequences using transformer has received less attention. In this paper, we propose the conv-attentional image time sequence transformer (CAiTST), a transformer-based image time sequences prediction model equipped with convolutional networks and an attentional mechanism. Specifically, we employ CAiTST to forecast the International GNSS Service (IGS) global total electron content (TEC) maps. The IGS TEC maps from 2005 to 2017 (except 2014) are divided into the training dataset (90% of total) and validation dataset (10% of total), and TEC maps in 2014 (high solar activity year) and 2018 (low solar activity year) are used to test the performance of CAiTST. The input of CAiTST is presented as one day's 12 TEC maps (time resolution is 2 h), and the output is the next day's 12 TEC maps. We compare the results of CAiTST with those of the 1-day Center for Orbit Determination in Europe (CODE) prediction model. The root mean square errors (RMSEs) from CAiTST with respect to the IGS TEC maps are 4.29 and 1.41 TECU in 2014 and 2018, respectively, while the RMSEs of the 1-day CODE prediction model are 4.71 and 1.57 TECU. The results illustrate CAiTST performs better than the 1-day CODE prediction model both in high and low solar activity years. The CAiTST model has less accuracy in the equatorial ionization anomaly (EIA) region but can roughly predict the features and locations of EIA. Additionally, due to the input only including past TEC maps, CAiTST performs poorly during magnetic storms. Our study shows that the transformer model and its unique attention mechanism are very suitable for images of a time sequence forecast, such as the prediction of ionospheric TEC map sequences.","2022-09","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","17","14","","","","","","","","","","English","","","","WOS:000851895100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;16<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","global prediction; ionospheric TEC maps; MODEL; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A8TJV32L","journalArticle","2024","Li, YH; Wynne, J; Wang, J; Qiu, RLJ; Roper, J; Pan, SY; Jani, AB; Liu, T; Patel, PR; Mao, H; Yang, XF","Cross-shaped windows transformer with self-supervised pretraining for clinically significant prostate cancer detection in bi-parametric MRI","MEDICAL PHYSICS","","0094-2405","10.1002/mp.17546","","BackgroundBi-parametric magnetic resonance imaging (bpMRI) has demonstrated promising results in prostate cancer (PCa) detection. Vision transformers have achieved competitive performance compared to convolutional neural network (CNN) in deep learning, but they need abundant annotated data for training. Self-supervised learning can effectively leverage unlabeled data to extract useful semantic representations without annotation and its associated costs.PurposeThis study proposes a novel self-supervised learning framework and a transformer model to enhance PCa detection using prostate bpMRI.Methods and materialsWe introduce a novel end-to-end Cross-Shaped windows (CSwin) transformer UNet model, CSwin UNet, to detect clinically significant prostate cancer (csPCa) in prostate bpMRI. We also propose a multitask self-supervised learning framework to leverage unlabeled data and improve network generalizability. Using a large prostate bpMRI dataset (PI-CAI) with 1476 patients, we first pretrain CSwin transformer using multitask self-supervised learning to improve data-efficiency and network generalizability. We then finetune using lesion annotations to perform csPCa detection. We also test the network generalization using a separate bpMRI dataset with 158 patients (Prostate158).ResultsFive-fold cross validation shows that self-supervised CSwin UNet achieves 0.888 +/- 0.010 aread under receiver operating characterstics curve (AUC) and 0.545 +/- 0.060 Average Precision (AP) on PI-CAI dataset, significantly outperforming four comparable models (nnFormer, Swin UNETR, DynUNet, Attention UNet, UNet). On model generalizability, self-supervised CSwin UNet achieves 0.79 AUC and 0.45 AP, still outperforming all other comparable methods and demonstrating good generalization to external data.ConclusionsThis study proposes CSwin UNet, a new transformer-based model for end-to-end detection of csPCa, enhanced by self-supervised pretraining to enhance network generalizability. We employ an automatic weighted loss (AWL) to unify pretext tasks, improving representation learning. Evaluated on two multi-institutional public datasets, our method surpasses existing methods in detection metrics and demonstrates good generalization to external data.","2024-11-26","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","","","","","","","","","","","","English","","","","WOS:001362924800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","magnetic resonance imaging; prostate cancer; self-supervised learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2WVVE5SI","journalArticle","2024","Qiu, KY; Zhang, YJ; Ren, ZK; Li, M; Wang, Q; Feng, YQ; Chen, F","SpemNet: A Cotton Disease and Pest Identification Method Based on Efficient Multi-Scale Attention and Stacking Patch Embedding","INSECTS","","2075-4450","10.3390/insects15090667","","Simple Summary Cotton is a crucial economic crop, but it is often threatened by various pests and diseases during its growth, significantly impacting its yield and quality. Earlier image classification methods often suffer from low accuracy and struggle to perform effectively in complex real-world environments. This paper proposes a novel image classification network named SpemNet, specifically designed for cotton pest and disease recognition. By introducing the Efficient Multi-Scale Attention (EMA) module and the Stacking Patch Embedding (SPE) module, the network enhances the ability to learn local features and integrate multi-scale information, thereby significantly improving the accuracy and efficiency of cotton pest and disease recognition. Extensive experiments conducted on the publicly available CottonInsect and IP102 datasets, as well as a self-collected cotton leaf disease dataset, demonstrate that SpemNet exhibits significant advantages in key metrics such as precision, recall, and F1 score, confirming its effectiveness and superiority in the task of cotton pest and disease recognition.Abstract We propose a cotton pest and disease recognition method, SpemNet, based on efficient multi-scale attention and stacking patch embedding. By introducing the SPE module and the EMA module, we successfully solve the problems of local feature learning difficulty and insufficient multi-scale feature integration in the traditional Vision Transformer model, which significantly improve the performance and efficiency of the model. In our experiments, we comprehensively validate the SpemNet model on the CottonInsect dataset, and the results show that SpemNet performs well in the cotton pest recognition task, with significant effectiveness and superiority. The SpemNet model excels in key metrics such as precision and F1 score, demonstrating significant potential and superiority in the cotton pest and disease recognition task. This study provides an efficient and reliable solution in the field of cotton pest and disease identification, which is of great theoretical and applied significance.","2024-09","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","9","15","","","","","","","","","","English","","","","WOS:001323465800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","attention mechanism; cotton pest recognition; deep learning; efficient multi-scale attention; feature fusion; image classification; NETWORK; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IVE2QEXE","journalArticle","2024","Qin, YB; Wang, Y; Deng, DZ; Yang, XL; Zhao, ZR; Zhou, Y; Fan, YQ; Wei, JC; Chen, TB; Liu, LB; Wei, SJ; Hu, Y; Yin, SY","Ayaka: A Versatile Transformer Accelerator With Low-Rank Estimation and Heterogeneous Dataflow","IEEE JOURNAL OF SOLID-STATE CIRCUITS","","0018-9200","10.1109/JSSC.2024.3397189","","Transformer model has demonstrated outstanding performance in the field of artificial intelligence. However, its remarkable performance comes at the cost of substantial computational complexity, posing limitations on deploying transformers from cloud to edge due to power and throughput constraints. There are two main challenges in designing a transformer accelerator for practical tasks. First, a transformer has inconsistent bottlenecks due to input length changes: for short inputs, such as using vision transformer (ViT) for ImageNet or bidirectional encoder representations from transformers (BERT) for general language understanding evaluation (GLUE), the linear layer of the model becomes the computational bottleneck. In contrast, for long inputs, such as high-resolution images or long-text tasks, attention computation becomes the bottleneck. Second, even for a given input length, different layers in the model exhibit various computational characteristics and workloads, such as matrix sizes and data reuse strategies. This article introduces Ayaka, a versatile transformer accelerator designed to address these issues. Ayaka uses a cross-layer sparse prediction approach based on random projection (RP), enabling simultaneous sparsification of attention computation and linear layers, thereby enhancing throughput for various bottlenecks for different input lengths. Furthermore, Ayaka optimizes the sparse attention computation by leveraging the input translation invariance of softmax. In addition, Ayaka features a heterogeneous dataflow processing element (HDPE) design, dynamically adjusting stationary matrix operands based on the current computation to maximize on-chip data reuse and reduce memory footprint. With these features, Ayaka is so far the first accelerator that accelerates the whole attention layer. Evaluation of 12 typical models and tasks shows that it achieves a peak energy efficiency of 49.7 TOPS/W, which is 1.20-258.9 x higher than the state-of-the-art works.","2024-10","2025-02-26 20:43:30","2025-02-26 20:43:30","","3342-3356","","10","59","","","","","","","","","","English","","","","WOS:001226162600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Artificial intelligence; Computational efficiency; Computational modeling; deep learning accelerator; efficient computing; Head; sparsity processing; Task analysis; Technological innovation; Throughput; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XY2TJBEZ","journalArticle","2024","Shao, CH; Shao, FJ; Huang, S; Sun, RC; Zhang, T","An Evolved Transformer Model for ADME/Tox Prediction","ELECTRONICS","","2079-9292","10.3390/electronics13030624","","Drug discovery aims to keep fueling new medicines to cure and palliate many ailments and some untreatable diseases that still afflict humanity. The ADME/Tox (absorption, distribution, metabolism, excretion/toxicity) properties of candidate drug molecules are key factors that determine the safety, uptake, elimination, metabolic behavior and effectiveness of drug research and development. The predictive technique of ADME/Tox drastically reduces the fraction of pharmaceutics-related failure in the early stages of drug development. Driven by the expectation of accelerated timelines, reduced costs and the potential to reveal hidden insights from vast datasets, artificial intelligence techniques such as Graphormer are showing increasing promise and usefulness to perform custom models for molecule modeling tasks. However, Graphormer and other transformer-based models do not consider the molecular fingerprint, as well as the physicochemicals that have been proved effective in traditional computational drug research. Here, we propose an enhanced model based on Graphormer which uses a tree model that fully integrates some known information and achieves better prediction and interpretability. More importantly, the model achieves new state-of-the-art results on ADME/Tox properties prediction benchmarks, surpassing several challenging models. Experimental results demonstrate an average SMAPE (Symmetric Mean Absolute Percentage Error) of 18.9 and a PCC (Pearson Correlation Coefficient) of 0.86 on ADME/Tox prediction test sets. These findings highlight the efficacy of our approach and its potential to enhance drug discovery processes. By leveraging the strengths of Graphormer and incorporating additional molecular descriptors, our model offers improved predictive capabilities, thus contributing to the advancement of ADME/Tox prediction in drug development. The integration of various information sources further enables better interpretability, aiding researchers in understanding the underlying factors influencing the predictions. Overall, our work demonstrates the potential of our enhanced model to expedite drug discovery, reduce costs, and enhance the success rate of our pharmaceutical development efforts.","2024-02","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","3","13","","","","","","","","","","English","","","","WOS:001159947700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","ADME/Tox; ALGORITHM; DISCOVERY; drug discovery; DRUG SOLUBILITY; Graphormer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G7JTABYH","journalArticle","2023","Peng, C; Yang, X; Yu, ZH; Bian, J; Hogan, WR; Wu, YH","Clinical concept and relation extraction using prompt-based machine reading comprehension","JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION","","1067-5027","10.1093/jamia/ocad107","","Objective: To develop a natural language processing system that solves both clinical concept extraction and relation extraction in a unified prompt-based machine reading comprehension (MRC) architecture with good generalizability for cross-institution applications.Methods: We formulate both clinical concept extraction and relation extraction using a unified prompt-based MRC architecture and explore state-of-the-art transformer models. We compare our MRC models with existing deep learning models for concept extraction and end-to-end relation extraction using 2 benchmark datasets developed by the 2018 National NLP Clinical Challenges (n2c2) challenge (medications and adverse drug events) and the 2022 n2c2 challenge (relations of social determinants of health [SDoH]). We also evaluate the transfer learning abil-ity of the proposed MRC models in a cross-institution setting. We perform error analyses and examine how different prompting strategies affect the performance of MRC models.Results and Conclusion: The proposed MRC models achieve state-of-the-art performance for clinical concept and relation extraction on the 2 benchmark datasets, outperforming previous non-MRC transformer models. GatorTron-MRC achieves the best strict and lenient F1-scores for concept extraction, outperforming previous deep learning models on the 2 datasets by 1%-3% and 0.7%-1.3%, respectively. For end-to-end relation extraction, GatorTron-MRC and BERT-MIMIC-MRC achieve the best F1-scores, outperforming previous deep learning models by 0.9%- 2.4% and 10%-11%, respectively. For cross-institution evaluation, GatorTron-MRC outperforms traditional GatorTron by 6.4% and 16% for the 2 datasets, respectively. The proposed method is better at handling nested/overlapped concepts, extracting relations, and has good portability for cross-institute applications. Our clinical MRC package is publicly available at https://github.com/uf-hobi-informatics-lab/ ClinicalTransformerMRC.","2023-08-18","2025-02-26 20:43:30","2025-02-26 20:43:30","","1486-1493","","9","30","","","","","","","","","","English","","","","WOS:001010477100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","clinical concept extraction; INFORMATION EXTRACTION; machine reading comprehension; natural language processing; NEURAL-NETWORK; relation extraction; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AI3Z4Z4T","journalArticle","2022","Tang, Y; Zhang, L; Wu, H; He, J; Song, AG","Dual-Branch Interactive Networks on Multichannel Time Series for Human Activity Recognition","IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS","","2168-2194","10.1109/JBHI.2022.3193148","","The popularity of convolutional architecture has made sensor-based human activity recognition (HAR) become one primary beneficiary. By simply superimposing multiple convolution layers, the local features can be effectively captured from multi-channel time series sensor data, which could output high-performance activity prediction results. On the other hand, recent years have witnessed great success of Transformer model, which uses powerful self-attention mechanism to handle long-range sequence modeling tasks, hence avoiding the shortcoming of local feature representations caused by convolutional neural networks (CNNs). In this paper, we seek to combine the merits of CNN and Transformer to model multi-channel time series sensor data, which might provide compelling recognition performance with fewer parameters and FLOPs based on lightweight wearable devices. To this end, we propose a new Dual-branch Interactive Network (DIN) that inherits the advantages from both CNN and Transformer to handle multi-channel time series for HAR. Specifically, the proposed framework utilizes two-stream architecture to disentangle local and global features by performing conv-embedding and patch-embedding, where a co-attention mechanism is used to adaptively fuse global-to-local and local-to-global feature representations. We perform extensive experiments on three mainstream HAR benchmark datasets including PAMAP2, WISDM, and OPPORTUNITY, which verify that our method consistently outperforms several state-of-the-art baselines, reaching an F1-score of 92.05%, 98.17%, and 91.55% respectively with fewer parameters and FLOPs. In addition, the practical execution time is validated on an embedded Raspberry Pi P3 system, which demonstrates that our approach is adequately efficient for real-time HAR implementations and deserves as a better alternative in ubiquitous HAR computing scenario. Our model code will be released soon.","2022-10","2025-02-26 20:43:30","2025-02-26 20:43:30","","5223-5234","","10","26","","","","","","","","","","English","","","","WOS:000864195200045","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;27<br/>Total Times Cited:&nbsp;&nbsp;27<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","Activity recognition; CNNs; Computer architecture; Convolution; Feature extraction; Human activity recognition; multi-channel time series; Task analysis; Time series analysis; transformer; Transformers; wearable sensors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ECPBUX87","journalArticle","2025","Yang, JS; Chen, WJ; Xiao, X; Zhang, ZH","Explainable deep learning method for power system stability evaluation with incomplete voltage data based on transfer learning","MEASUREMENT","","0263-2241","10.1016/j.measurement.2025.116781","","Real-time voltage assessment is critical for power system fault diagnosis. However, traditional deep learning methods often suffer from deficiencies in prediction accuracy and interpretability when handling missing voltage data, which limits their practical applicability. To address these challenges, this paper proposes the Interpretable Wavelet-Visual Transformer Model (X-WaveVT). By integrating wavelet transform, vision transformer (ViT), and transfer learning, X-WaveVT provides an effective solution for incomplete voltage data processing and power system stability assessment. The proposed method extracts multi-scale features from voltage data using wavelet transform and leverages the visual transformer to efficiently capture scale-space correlations, accurately distinguishing interference and noise caused by missing data. This enhances the model's ability to learn and utilize multi-scale features. When faced with severe data loss and limited samples, transfer learning fine-tunes a pre- trained model, effectively addressing data scarcity and significantly improving prediction accuracy. Furthermore, by incorporating a novel voltage time series driven Class Activation Mapping (CAM) technique, the model's decision process is visualized, enhancing interpretability and credibility. This visualization supports the extraction of key features and provides insights into the model's decision-making process. The experimental results show that the proposed method delivers outstanding performance in voltage stability assessment under full data conditions. Furthermore, as challenges such as data loss, sample insufficiency, and class imbalance become more severe, X-WaveVT exhibits a growing performance advantage over existing models, underscoring its stability and robustness in complex power systems. Additionally, the model's visualization capability not only enhances trust in its predictions but also offers valuable insights for real-time voltage assessment and power system optimization, underscoring its significant application potential and practical value.","2025-04-15","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","","247","","","","","","","","","","English","","","","WOS:001410029000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","Class activation score; CLASSIFICATION; Explainable wavelet vision transformer; FAULT-DETECTION; Missing voltage data; MODEL; Real-time voltage assessment; Transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RMQI44CJ","journalArticle","2023","Al-Bashabsheh, E; Alaiad, A; Al-Ayyoub, M; Beni-Yonis, O; Zitar, RA; Abualigah, L","Improving clinical documentation: automatic inference of ICD-10 codes from patient notes using BERT model","JOURNAL OF SUPERCOMPUTING","","0920-8542","10.1007/s11227-023-05160-z","","Electronic health records provide a vast amount of text health data written by physicians as patient clinical notes. The world health organization released the international classification of diseases version 10 (ICD-10) system to monitor and analyze clinical notes. ICD-10 is system physicians and other healthcare providers use to classify and code all diagnoses and symptom records in conjunction with hospital care. Therefore, the data can be easily stored, retrieved, and analyzed for decision-making. In order to address the problem, this paper introduces a system to classify the clinical notes to ICD-10 codes. This paper examines 7541 clinical notes collected from a health institute in Jordan and annotated by ICD-10's coders. In addition, the research uses another outsource dataset to augment the actual dataset. The research presented many approaches, such as the baseline and pipeline models. The Baseline model employed several methods like Word2vec embedding for representing the text. The model structure also involves long-short-term memory a convolutional neural network, and two fully-connected layers. The second Pipeline approach adopts the transformer model, such as Bidirectional Encoder Representations from Transformers (BERT), which is pre-trained on a similar health domain. The Pipeline model builds on two BERT models. The first model classifies the category codes representing the first three characters of ICD-10. The second BERT model uses the outputs from the general BERT model (first model) as input for the special BERT (second model) to classify the clinical notes into total codes of ICD-10. Moreover, Baseline and Pipeline models applied the Focal loss function to eliminate the imbalanced classes. However, The Pipeline model demonstrates a significant performance by evaluating it over the F1 score, recall, precision, and accuracy metric, which are 92.5%, 84.9%, 91.8%, and 84.97%, respectively.","2023-07","2025-02-26 20:43:30","2025-02-26 20:43:30","","12766-12790","","11","79","","","","","","","","","","English","","","","WOS:000953175000003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","BERT; Convolutional neural network; Deep learning; ICD-10; Long short-term memory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TKJMR3UK","journalArticle","2025","Su, C; Huang, JC; Dong, SS; He, YQ; Li, J; Hu, LY; Liu, X; Liao, Y","Transformer-Gate Recurrent Unit-Based Hourly Purified Natural Gas Prediction Algorithm","PROCESSES","","2227-9717","10.3390/pr13010116","","With the rapid development of industrial automation and intelligence, the consumption of resources and the environmental impact of production processes cannot today be ignored. Today, natural gas, as a commonly used energy source, produces significantly lower emissions of carbon dioxide, sulphur dioxide, and nitrogen oxides from combustion than coal and oil, and can be further purified to remove the small amount of impurities it contains, such as sulphur compounds. Therefore, purified natural gas (hereinafter referred to as purified gas), as a clean energy source, plays an important role in realising sustainable development. At the same time, It becomes more and more important to dispatch purified gas resources reasonably and accurately, and the paramount factor is that the load of purified gas needs to be predicted accurately. Therefore, this paper proposes a Transformer-GRU-based hourly prediction model for purified gas. The model uses the Transformer model for data fusion and feature extraction, and then combines the time series processing capability of the Gate Recurrent Unit (GRU) model to capture long-term dependencies and short-term dynamic changes in time series data. In this paper, the purified gas load data of Chongqing Municipality in 2020 was first preprocessed, and then divided into daily and hourly load datasets according to the measurement step. Meanwhile, considering the influence of temperature factor, the experimental dataset is subdivided according to whether it includes temperature data or not, and then the Transformer-GRU model was built for prediction, respectively. The results show that, compared with the Dual-Stage Attention-Based Recurrent Neural Network (DA-RNN) and the Transformer and GRU models alone, the Transformer-GRU model exhibits good performance in terms of the coefficient of determination, the average absolute percentage error, and mean square error, which can well meet the requirement of hourly prediction accuracy and has greater application value.","2025-01","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","1","13","","","","","","","","","","English","","","","WOS:001403891400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;17</p>","","","GRU; load forecasting; predictive modelling; purified natural gas; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BRJ3NTYZ","journalArticle","2024","Yang, ZC; Jin, AT; Li, Y; Yu, XY; Xu, X; Wang, JX; Li, QL; Guo, XY; Liu, Y","A coordinated adaptive multiscale enhanced spatio-temporal fusion network for multi-lead electrocardiogram arrhythmia detection","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-71700-z","","The multi-lead electrocardiogram (ECG) is widely utilized in clinical diagnosis and monitoring of cardiac conditions. The advancement of deep learning has led to the emergence of automated multi-lead ECG diagnostic networks, which have become essential in the fields of biomedical engineering and clinical cardiac disease diagnosis. Intelligent ECG diagnosis techniques encompass Recurrent Neural Networks (RNN), Transformers, and Convolutional Neural Networks (CNN). While CNN is capable of extracting local spatial information from images, it lacks the ability to learn global spatial features and temporal memory features. Conversely, RNN relies on time and can retain significant sequential features. However, they are not proficient in extracting lengthy dependencies of sequence data in practical scenarios. The self-attention mechanism in the Transformer model has the capability of global feature extraction, but it does not adequately prioritize local features and cannot extract spatial and channel features. This paper proposes STFAC-ECGNet, a model that incorporates CAMV-RNN block, CBMV-CNN block, and TSEF block to enhance the performance of the model by integrating the strengths of CNN, RNN, and Transformer. The CAMV-RNN block incorporates a coordinated adaptive simplified self-attention module that adaptively carries out global sequence feature retention and enhances spatial-temporal information. The CBMV-CNN block integrates spatial and channel attentional mechanism modules in a skip connection, enabling the fusion of spatial and channel information. The TSEF block implements enhanced multi-scale fusion of image spatial and sequence temporal features. In this study, comprehensive experiments were conducted using the PTB-XL large publicly available ECG dataset and the China Physiological Signal Challenge 2018 (CPSC2018) database. The results indicate that STFAC-ECGNet surpasses other cutting-edge techniques in multiple tasks, showcasing robustness and generalization.","2024-09-06","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","1","14","","","","","","","","","","English","","","","WOS:001308223300037","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","Arrhythmia detection; CLASSIFICATION; Convolutional neural network; MODELS; Muti-lead ECG; MYOCARDIAL-INFARCTION; Recurrent neural networks; Spatio -temporal fusion network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8LW2ELKV","journalArticle","2022","Halder, S; Lim, KH; Chan, J; Zhang, XZ","POI recommendation with queuing time and user interest awareness","DATA MINING AND KNOWLEDGE DISCOVERY","","1384-5810","10.1007/s10618-022-00865-w","","Point-of-interest (POI) recommendation is a challenging problem due to different contextual information and a wide variety of human mobility patterns. Prior studies focus on recommendation that considers user travel spatiotemporal and sequential patterns behaviours. These studies do not pay attention to user personal interests, which is a significant factor for POI recommendation. Besides user interests, queuing time also plays a significant role in affecting user mobility behaviour, e.g., having to queue a long time to enter a POI might reduce visitor's enjoyment. Recently, attention-based recurrent neural networks-based approaches show promising performance in the next POI recommendation task. However, they are limited to single head attention, which can have difficulty in finding the appropriate user mobility behaviours considering complex relationships among POI spatial distances, POI check-in time, user interests and POI queuing times. In this research work, we are the first to consider queuing time and user interest awareness factors for next POI recommendation. We demonstrate how it is non-trivial to recommend a next POI and simultaneously predict its queuing time. To solve this problem, we propose a multi-task, multi-head attention transformer model called TLR-M_UI. The model recommends the next POIs to the target users and predicts queuing time to access the POIs simultaneously by considering user mobility behaviours. The proposed model utilises POIs description-based user personal interest that can also solve the new categorical POI cold start problem. Extensive experiments on six real-world datasets show that the proposed models outperform the state-of-the-art baseline approaches in terms of precision, recall, and F1-score evaluation metrics. The model also predicts and minimizes the queuing time. For the reproducibility of the proposed model, we have publicly shared our implementation code at GitHub (https://github.com/sajalhalder/TLR-M_UI).","2022-11","2025-02-26 20:43:30","2025-02-26 20:43:30","","2379-2409","","6","36","","","","","","","","","","English","","","","WOS:000863549200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Multi-head attention; Multi-tasking; POI recommendation; Points of Interest (POI); Queuing time; Transformer; User interest","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q8FVQ2UP","journalArticle","2021","He, X; Chen, YS; Lin, ZH","Spatial-Spectral Transformer for Hyperspectral Image Classification","REMOTE SENSING","","2072-4292","10.3390/rs13030498","","Recently, a great many deep convolutional neural network (CNN)-based methods have been proposed for hyperspectral image (HSI) classification. Although the proposed CNN-based methods have the advantages of spatial feature extraction, they are difficult to handle the sequential data with and CNNs are not good at modeling the long-range dependencies. However, the spectra of HSI are a kind of sequential data, and HSI usually contains hundreds of bands. Therefore, it is difficult for CNNs to handle HSI processing well. On the other hand, the Transformer model, which is based on an attention mechanism, has proved its advantages in processing sequential data. To address the issue of capturing relationships of sequential spectra in HSI in a long distance, in this study, Transformer is investigated for HSI classification. Specifically, in this study, a new classification framework titled spatial-spectral Transformer (SST) is proposed for HSI classification. In the proposed SST, a well-designed CNN is used to extract the spatial features, and a modified Transformer (a Transformer with dense connection, i.e., DenseTransformer) is proposed to capture sequential spectra relationships, and multilayer perceptron is used to finish the final classification task. Furthermore, dynamic feature augmentation, which aims to alleviate the overfitting problem and therefore generalize the model well, is proposed and added to the SST (SST-FA). In addition, to address the issue of limited training samples in HSI classification, transfer learning is combined with SST, and another classification framework titled transferring-SST (T-SST) is proposed. At last, to mitigate the overfitting problem and improve the classification accuracy, label smoothing is introduced for the T-SST-based classification framework (T-SST-L). The proposed SST, SST-FA, T-SST, and T-SST-L are tested on three widely used hyperspectral datasets. The obtained results reveal that the proposed models provide competitive results compared to the state-of-the-art methods, which shows that the concept of Transformer opens a new window for HSI classification.","2021-02","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","3","13","","","","","","","","","","English","","","","WOS:000615470800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;265<br/>Total Times Cited:&nbsp;&nbsp;274<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","classification; convolutional neural network (CNN); hyperspectral image (HSI); Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B8TA7TPF","journalArticle","2025","Asefa, SH; Assabie, Y","Transformer-Based Amharic-to-English Machine Translation With Character Embedding and Combined Regularization Techniques","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3521985","","Amharic is the working language of Ethiopia and, owing to its Semitic characteristics, the language is known for its complex morphology. It is also an under-resourced language, presenting significant challenges for natural language processing tasks like machine translation. The primary challenges include the scarcity of parallel data, which increases the risk of overfitting and limits the model's ability to generalize effectively, and the complex morphology of Amharic, which further complicates learning patterns in translation tasks. This study proposes a Transformer-based Amharic-to-English neural machine translation model that leverages character-level embeddings and integrates advanced regularization techniques, including dropout, L1, L2, and Elastic Net. By focusing on character-level embeddings, the model captures the intricate morphological patterns of Amharic and effectively handles out-of-vocabulary words. Our model significantly improves upon the previous state-of-the-art results on the Amharic-to-English neural machine translation benchmark, achieving a BLEU score of 40.59, which is 7% higher than the previous state-of-the-art result. Among the regularization techniques tested, the integration of L2 regularization with dropout applied to the pointwise feed-forward network yielded the best translation performance. Additionally, the proposed model significantly reduces the parameter count from 75 million to just 5.4 million, demonstrating substantial computational efficiency while maintaining high accuracy. Extensive experiments demonstrated improvements in test accuracy, loss reduction, and translation fidelity compared to word-level embedding models. This research provides valuable insights into addressing the challenges of low-resource and morphologically complex languages, while also offering promising directions for future work, including the exploration of multilingual models, attention mechanism optimization, and the broader application of hybrid regularization techniques in the Transformer model architecture.","2025","2025-02-26 20:43:30","2025-02-26 20:43:30","","1090-1105","","","13","","","","","","","","","","English","","","","WOS:001392836900004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Amharic-to-English translation; Attention mechanisms; Complexity theory; low resource languages; morphologically complex languages; Multilingual; Neural machine translation; Neurons; Overfitting; regularization techniques; Standards; Training; transformer; Transformers; Translation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YRIPTPT3","journalArticle","2024","Zhang, W; Alzahrani, AI; Lee, MY","Fake News Detection in Large-Scale Social Network with Generalized Bayesian Classification","MOBILE NETWORKS & APPLICATIONS","","1383-469X","10.1007/s11036-024-02436-3","","Fake news in large-scale social networks is relatively rare, resulting in poor detection performance of deep learning method without sufficient samples. Meantime, false information comes from various sources and forms in large-scale social networks, which increases the difficulty of detection by simple Bayesian decision. Therefore, a method for detecting fake news in large-scale social networks based on a generalized Bayesian classifier is proposed. By using web crawlers to collect news in social network from multiple platforms such as entertainment, education, and medical diseases, and employing the HITS (Hyperlink-Induced Topic Search) algorithm to analyze webpage links, the accuracy of webpage target data retrieval is improved. A network data cleaning function is utilized to remove redundant and cluttered data from social network. A multi-modal Transformer model is employed to extract fusion features of text and image from large-scale social network data. By optimizing the Bayesian classifier using a greedy selection algorithm, a generalized Bayesian classifier is obtained. The extracted features of fake news from social networks are used as inputs to the generalized Bayesian classifier to obtain the prior probability of fake news in social networks. Based on this prior probability, evidence factors that meet the conditions of fake news in large-scale social networks are obtained. By evaluating the numerical values of these evidence factors, the classification and detection of fake news in large-scale social networks are achieved. Experimental results show that the maximum KL divergence value of the proposed method is 0.01, and the maximum Gini coefficient value is 0.1, indicating excellent performance in information cleaning and feature extraction. The maximum number of false positive results is only one sample, demonstrating its ability to accurately detect Fake News in social networks.","2024-11-18","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","","","","","","","","","","","","English","","","","WOS:001357804000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","Fake News; Generalized Bayesian classifier; Greedy algorithm; Large-scale Network; Social Network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LX3VT3EF","journalArticle","2024","Karaca, A; Aydin, Ö","Generating headlines for Turkish news texts with transformer architecture based deep learning method","JOURNAL OF THE FACULTY OF ENGINEERING AND ARCHITECTURE OF GAZI UNIVERSITY","","1300-1884","10.17341/gazimmfd.963240","","Nowadays, the Internet is a structure that people can access easily and at the same time produce content easily and without control. In parallel with this situation, the ability of extract information from the raw data that makes up big data has become more complex. The fact that the headlines of the contents contain uncontrolled and misleading elements makes it difficult to reach the right information. The headlines of the contents are important for people to reach the information they want in their limited time. In this study, it is aimed to produce headlines suitable for the content instead of headlines that may be misleading for news. For this purpose, an application that produces headlines for Turkish news with deep learning method has been developed. SuDer news corpus is used as dataset. For the training of the model, it is aimed to obtain more humanoid results in the production of news headlines by using the Transformer architecture, which is frequently preferred in natural language studies today and the abstract summarization method. In this study, in order to compare the performance of the Transformer model, models are prepared and trained with Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) architectures. At the end of 25 epochs of training with LSTM, GRU and Transformer architectures on the corpus, the values of loss are 1.03, 0.55 and 2.49 respectively. In the experiments performed on the validation data, measurements are made with ROUGE-1, ROUGE-2 and ROUGE-L metrics. As a result of the measurements, it is observed that the Transformer architecture is partially good, based on the metric values produced. In addition, when the headlines produced with these architectures are examined, it is observed that the headline obtained with the Transformer architecture produce headlines that are partially more suitable for the news content compared to other architectures.","2024","2025-02-26 20:43:30","2025-02-26 20:43:30","","485-495","","1","39","","","","","","","","","","English","","","","WOS:001058089000037","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Abstract text summarization; Automatic headline generation; Deep learning; Transformers; Turkish natural language processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZYUI4BYD","journalArticle","2024","Rieger, J; Yanchenko, K; Ruckdeschel, M; von Nordheim, G; Königslöw, KKV; Wiedemann, G","Few-shot learning for automated content analysis: Efficient coding of arguments and claims in the debate on arms deliveries to Ukraine","SCM STUDIES IN COMMUNICATION AND MEDIA","","2192-4007","10.5771/2192-4007-2024-1-72","","Pre-trained language models (PLM) based on transformer neural networks developed in the field of natural language processing (NLP) offer great opportunities to improve automatic content analysis in communication science, especially for the coding of complex semantic categories in large datasets via supervised machine learning. However, three characteristics so far impeded the widespread adoption of the methods in the applying disciplines: the dominance of English language models in NLP research, the necessary computing resources, and the effort required to produce training data to fine -tune PLMs. In this study, we address these challenges by using a multilingual transformer model in combination with the adapter extension to transformers, and few-shot learning methods. We test our approach on a realistic use case from communication science to automatically detect claims and arguments together with their stance in the German news debate on arms deliveries to Ukraine. In three experiments, we evaluate (1) data preprocessing strategies and model variants for this task, (2) the performance of different few-shot learning methods, and (3) how well the best setup performs on varying training set sizes in terms of validity, reliability, replicability and reproducibility of the results. We find that our proposed combination of transformer adapters with pattern exploiting training provides a parameterefficient and easily shareable alternative to fully fine-tuning PLMs. It performs on par in terms of validity, while overall, provides better properties for application in communication studies. The results also show that pre-fine-tuning for a task on a near-domain dataset leads to substantial improvement, in particular in the few-shot setting. Further, the results indicate that it is useful to bias the dataset away from the viewpoints of specific prominent individuals.","2024","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","1","13","","","","","","","","","","English","","","","WOS:001262738700005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","argument and stance detection; automatic media content analysis; claim; DIVERSITY; Pre-trained language models; quality metrics; transformer adapters","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YIVDU9YI","journalArticle","2024","Xiao, XY; Qi, B; Liang, JA; Tong, JJ; Deng, Q; Chen, P","Enhancing LOCA Breach Size Diagnosis with Fundamental Deep Learning Models and Optimized Dataset Construction","ENERGIES","","1996-1073","10.3390/en17010159","","In nuclear power plants, the loss-of-coolant accident (LOCA) stands out as the most prevalent and consequential incident. Accurate breach size diagnosis is crucial for the mitigation of LOCAs, and identifying the cause of an accident can prevent catastrophic consequences. Traditional methods mostly focus on combining model algorithms and utilize intricate composite model neural network architectures. However, it is crucial to investigate whether greater complexity necessarily leads to better performance. In addition, the consideration of the impact of dataset construction and data preprocessing on model performance is also needed for model building. This paper proposes a framework named DeepLOCA-Lattice to experiment with different preprocessing approaches to fundamental deep learning models for a comprehensive analysis of the diagnosis of LOCA breach size. The DeepLOCA-Lattice involves data preprocessing via the lattice algorithm and equal-interval partitioning and deep-learning-based models, including the multi-layer perceptron (MLP), recurrent neural networks (RNNs), convolutional neural networks (CNNs), and the transformer model in LOCA breach size diagnosis. After conducting rigorous ablation experiments, we have discovered that even rudimentary foundational models can achieve accuracy rates that exceed 90%. This is a significant improvement when compared to the previous models, which yield an accuracy rate of lower than 50%. The results interestingly demonstrate the superior performance and efficacy of the fundamental deep learning model, with an effective dataset construction approach. It elucidates the presence of a complex interplay among diagnostic scales, sliding window size, and sliding stride. Furthermore, our investigation reveals that the model attains its highest accuracy within the discussed range when utilizing a smaller sliding stride size and a longer sliding window length. This study could furnish valuable insights for constructing models for LOCA breach size estimation.","2024-01","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","1","17","","","","","","","","","","English","","","","WOS:001139161600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","breach size estimation; deep learning; fault diagnosis; INTERFACE; lattice algorithm; loss-of-coolant accident (LOCA)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FQDWGMJI","journalArticle","2025","Rathod, D; Yadav, AK; Kumar, M; Yadav, D","Character-Level Encoding based Neural Machine Translation for Hindi language","NEURAL PROCESSING LETTERS","","1370-4621","10.1007/s11063-025-11718-0","","Neural Machine Translation (NMT) is one step ahead of traditional statistical phrase-based translation systems because of its better translation ability. But it requires a large amount of parallel training data, which can be challenging for languages with limited resources like many Indian languages. In the past, researchers have tried to address the issue using data augmentation. In this paper, we present a data augmentation technique for the Hindi language based on five phrases: noun phrases, verb phrases, prepositional phrases, adjective phrases, and adverb phrases. We augment the training corpus using parser-generated phrasal segments and evaluate the efficiency of the proposed work on the Hindi language. Further, the paper presents training in the NMT model at the character level instead of the word level. This approach can help overcome challenges associated with word-level translations, such as handling rare and out-of-vocabulary words and phrases, dealing with morphological complexity, and addressing languages with ambiguous word boundaries. The proposed work was evaluated on a low-resource language pair, Hindi-English, using the Google Transformer model as the baseline state-of-the-art. The experiments used two distinct datasets: WMT14 Hin-Eng and Samanantar Hin-Eng parallel corpus with character-level encoding for the translation task. The proposed model is able to surpass the cutting-edge baseline and saw an increase in BLEU scores for the WMT14 translation challenge with +2.52 on base paper using three phrase sentences with character-level encoding and +2.68 BLEU Score on base paper using five phrase sentences with character-level encoding. Further, character-level encoding is evaluated on non-augmented Samanantar dataset; it performs better in the baseline approach for translation purposes. It clearly shows that the proposed model outperforms in Hindi language translation.","2025-02-18","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","2","57","","","","","","","","","","English","","","","WOS:001424572500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Character-embeddings; Data augmentation; Hindi neural machine translation; Neural machine translation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8Y3SMPUZ","journalArticle","2024","He, X; Bai, XH; Chen, H; Feng, WW","Machine learning models in evaluating the malignancy risk of ovarian tumors: a comparative study","JOURNAL OF OVARIAN RESEARCH","","1757-2215","10.1186/s13048-024-01544-8","","ObjectivesThe study aimed to compare the diagnostic efficacy of the machine learning models with expert subjective assessment (SA) in assessing the malignancy risk of ovarian tumors using transvaginal ultrasound (TVUS).MethodsThe retrospective single-center diagnostic study included 1555 consecutive patients from January 2019 to May 2021. Using this dataset, Residual Network(ResNet), Densely Connected Convolutional Network(DenseNet), Vision Transformer(ViT), and Swin Transformer models were established and evaluated separately or combined with Cancer antigen 125 (CA 125). The diagnostic performance was then compared with SA.ResultsOf the 1555 patients, 76.9% were benign, while 23.1% were malignant (including borderline). When differentiating the malignant from ovarian tumors, the SA had an AUC of 0.97 (95% CI, 0.93-0.99), sensitivity of 87.2%, and specificity of 98.4%. Except for Vision Transformer, other machine learning models had diagnostic performance comparable to that of the expert. The DenseNet model had an AUC of 0.91 (95% CI, 0.86-0.95), sensitivity of 84.6%, and specificity of 95.1%. The ResNet50 model had an AUC of 0.91 (0.85-0.95). The Swin Transformer model had an AUC of 0.92 (0.87-0.96), sensitivity of 87.2%, and specificity of 94.3%. There was a statistically significant difference between the Vision Transformer and SA, and between the Vision Transformer and Swin Transformer models (AUC: 0.87 vs. 0.97, P = 0.01; AUC: 0.87 vs. 0.92, P = 0.04). Adding CA125 did not improve the diagnostic performance of the models in distinguishing benign and malignant ovarian tumors.ConclusionThe deep learning model of TVUS can be used in ovarian cancer evaluation, and its diagnostic performance is comparable to that of expert assessment.","2024-11-06","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","1","17","","","","","","","","","","English","","","","WOS:001349591300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","CANCER; DIAGNOSIS; Diagnostic models; EXTERNAL VALIDATION; LOGISTIC-REGRESSION MODELS; Machine learning; Ovarian cancer; PREDICTION; Ultrasound","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L8QUT67I","journalArticle","2024","Yang, S; Yang, X; Lyu, T; Huang, JL; Chen, AK; He, X; Braithwaite, D; Mehta, HJ; Wu, YH; Guo, Y; Bian, J","Extracting Pulmonary Nodules and Nodule Characteristics from Radiology Reports of Lung Cancer Screening Patients Using Transformer Models","JOURNAL OF HEALTHCARE INFORMATICS RESEARCH","","2509-4971","10.1007/s41666-024-00166-5","","Pulmonary nodules and nodule characteristics are important indicators of lung nodule malignancy. However, nodule information is often documented as free text in clinical narratives such as radiology reports in electronic health record systems. Natural language processing (NLP) is the key technology to extract and standardize patient information from radiology reports into structured data elements. This study aimed to develop an NLP system using state-of-the-art transformer models to extract pulmonary nodules and associated nodule characteristics from radiology reports. We identified a cohort of 3080 patients who underwent LDCT at the University of Florida health system and collected their radiology reports. We manually annotated 394 reports as the gold standard. We explored eight pretrained transformer models from three transformer architectures including bidirectional encoder representations from transformers (BERT), robustly optimized BERT approach (RoBERTa), and A Lite BERT (ALBERT), for clinical concept extraction, relation identification, and negation detection. We examined general transformer models pretrained using general English corpora, transformer models fine-tuned using a clinical corpus, and a large clinical transformer model, GatorTron, which was trained from scratch using 90 billion words of clinical text. We compared transformer models with two baseline models including a recurrent neural network implemented using bidirectional long short-term memory with a conditional random fields layer and support vector machines. RoBERTa-mimic achieved the best F1-score of 0.9279 for nodule concept and nodule characteristics extraction. ALBERT-base and GatorTron achieved the best F1-score of 0.9737 in linking nodule characteristics to pulmonary nodules. Seven out of eight transformers achieved the best F1-score of 1.0000 for negation detection. Our end-to-end system achieved an overall F1-score of 0.8869. This study demonstrated the advantage of state-of-the-art transformer models for pulmonary nodule information extraction from radiology reports.","2024-09","2025-02-26 20:43:30","2025-02-26 20:43:30","","463-477","","3","8","","","","","","","","","","English","","","","WOS:001226606600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","CLASSIFICATION; Deep learning; ENTITY RECOGNITION; Natural language processing; Nodule characteristics; Pulmonary nodule","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KJB5SXNZ","journalArticle","2024","Saez-Perez, J; Benlloch-Caballero, P; Tena-Gago, D; Garcia-Rodriguez, J; Calero, JMA; Wang, Q","Optimizing AI Transformer Models for CO2 Emission Prediction in Self-Driving Vehicles With Mobile/Multi-Access Edge Computing Support","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3491306","","With the increasing prominence of self-driving vehicles, there has been a pressing need to accurately estimate their carbon dioxide (CO2) emissions and evaluate their environmental sustainability. This paper has introduced a novel approach that leverages Artificial Intelligence (AI) transformer architectures to predict CO2 emissions in Society of Automotive Engineers (SAE) Level 2 self-driving cars, surpassing the performance of previous algorithms. After examining and comparing the use of previously proposed LSTM-based and the proposed transformer architecture (CO(2)ViT), and identifying their strengths and limitations, we have explored the vehicular networking paradigm with the Mobile/Multi-Access Edge Computing (MEC) capabilities of 5G infrastructure to provide the prediction service of the proposed transformer model under different networking topologies. Through extensive experimentation and evaluation on a dataset specifically designed for CO2 emissions prediction in self-driving vehicles, we have demonstrated the superior predictive capabilities of our proposed CO(2)ViT model based on the Visual Transformer architecture, achieving a model that predicts the CO2 emissions 71.14% faster than the previous state-of-the-art model (LSTM) applied to the same problem and that achieves an R-2 higher score of 0.9898 against the one achieved by the LSTM (0.9712). Furthermore, we have deployed a 5G emulation testbed with MEC capabilities to demonstrate the proposed Deep Learning (DL) resilience of the model to changes and concurrent connections. While delays for 2 to 16 connected vehicles have grown linearly with a maximum delay value of 41.01 ms, resource limitations have arisen with 32 or more cars due to varied delays, necessitating additional physical resources for the emulated 5G network to achieve better performance under high stress. The deployed models' inference time over the 5G infrastructure for 64 concurrent connected vehicles in scenarios A and B has been 4.31 ms and 8.42 ms, respectively.","2024","2025-02-26 20:43:30","2025-02-26 20:43:30","","179689-179706","","","12","","","","","","","","","","English","","","","WOS:001373800700024","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","deep learning; Environmental sustainability; IoT; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IV3MD5UP","journalArticle","2024","Guo, ZL; Lu, JY; Chen, Q; Liu, ZG; Song, CC; Tan, HJ; Zhang, HR; Yan, JY","TransPV: Refining photovoltaic panel detection accuracy through a vision transformer-based deep learning model","APPLIED ENERGY","","0306-2619","10.1016/j.apenergy.2023.122282","","The increasing need to develop renewable energy sources to combat climate change has led to a significant rise in demand for photovoltaic (PV) installations. Consequently, accurately detecting and estimating the capacity and potential for electricity generation of these installed PV systems has become crucial for effective energy management. However, due to the limitation of localized mechanism in convolution operations, traditional FCNbased methods face challenges in capturing global dependencies among remote sensing image patches. As a result, they struggle to model long-range interactions between different PV panels with diverse structures, including varying size, shape, and texture, particularly in distributed residential areas. To tackle the challenge of modeling PV panels with diverse structures, we propose a coupled U-Net and Vision Transformer model named TransPV for refining PV semantic segmentation. Specifically, Mix Transformer block is incorporated in the encoder to enhance the modeling of global context, while the U-Shaped structure enables the combination of multi-level features, resulting in enriched feature representation, which helps the model better understand objects in the images, regardless of their shape, size, and texture. In addition, we implement the PointRend module in the decoder to obtain finer segmentation boundary details, and utilize a novel refiner loss function during the training process to alleviate the problem of extremely unbalanced samples. The experimental results from the Heilbronn datasets demonstrate the remarkable performance of our proposed TransPV model in addressing intraclass diversity of PV structures, surpassing previous state-of-the-art methods with an impressive IoU and accuracy of 0.802 and 0.876, respectively. Furthermore, our model exhibits high generalization capability on the BDPV dataset with IoU of 0.745. The obtained results highlight the superiority of TransPV in improving accuracy and addressing diverse structure issues in PV segmentation, which provides valuable insights for optimizing the efficiency and sustainability of renewable energy.","2024-02-01","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","","355","","","","","","","","","","English","","","","WOS:001115630100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Deep learning; FRAMEWORK; Photovoltaic panels; Renewable energy; Semantic segmentation; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7IWQ56NK","journalArticle","2022","Pang, T; Zhao, XH; He, XD; Kan, CN; Venketasubramanian, N; Cheng, CY; Yuan, CZ; Chen, CSP; Xu, X","The discriminant validity of single-question assessments of subjective cognitive complaints in an Asian older adult population","FRONTIERS IN AGING NEUROSCIENCE","","1663-4365","10.3389/fnagi.2022.901592","","ObjectiveTo compare the discriminant validity of three different single-question assessments of subjective cognitive complaints (SCC) for dementia in a community-based older adult population in Singapore. MethodsEligible older adults aged >= 60 were recruited into phase I for identifying those who require further assessment using the Abbreviated Mental Test (AMT) and progressive forgetfulness question (PFQ). Participants who failed either tests entered phase II and were administered various single-question assessments of SCC, such as the 8th question on the patient Ascertain Dementia 8 (AD8-8(pt)), informant AD8 (AD8-8(info)), and the 10th item on the Geriatric Depression Scale (GDS-10), followed by the Montreal Cognitive Assessment (MoCA) and a formal neuropsychological battery to identify the participant's cognitive status by a research diagnosis and DSM-IV criteria. Differences in characteristics among diagnostic groups were compared. All discriminatory indices (sensitivity, specificity, positive, and negative predictive values, overall accuracy) for these single-question assessments and their combinations with the MoCA were calculated and reported to confirm their discriminant validity in identifying the existence of subjective complaints and objective impairment. ResultsA total of 3,780 participants were assessed at phase I, of which 957 entered and completed phase II. Of whom, 911 were dementia-free and 46 had dementia. The MoCA (13/14) displayed good sensitivity (95.6%), specificity (81.5%), and overall accuracy (82.1%) for dementia detection. The GDS-10 and AD8-8(pt) showed poor discriminant validity, while the AD8-8(info) had the highest specificity (83.2%) and the greatest overall accuracy (82.5%) for dementia. Compensatory combination of the AD8-8(info) with MoCA, the sensitivity and positive predictive values were optimized (100%), while the conjunctive combination of two tools achieved excellent specificity (96.3%) and overall accuracy (94.8%) in discriminating dementia patients. Conclusion and implicationsCombining a reliable single-question SCC assessment with an objective tool can efficiently discriminate dementia patients from healthy older adults in the community.","2022-08-08","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","","14","","","","","","","","","","English","","","","WOS:000843327100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","CHINESE; cognitive screening; COHORT; DECLINE; dementia; DEMENTIA; discriminant validity; EDUCATION; EPIDEMIOLOGY; IMPAIRMENT; MEMORY COMPLAINTS; PEOPLE; SINGAPORE; single-question assessment; subjective cognitive complaints","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F2DGVEDL","journalArticle","2024","Jones, MO; Figueiredo, G; Howson, S; Toro, A; Rundquist, S; Garner, G; Della Nave, F; Delgado, G; Yi, ZF; Ahn, P; Barrett, SJ; Bader, M; Rollend, D; Bendixen, T; Albrecht, J; Sogomo, K; Musse, ZZ; Shriver, J","Monitoring and Mapping a Decade of Regenerative Agricultural Practices Across the Contiguous United States","LAND","","2073-445X","10.3390/land13122246","","Satellite remote sensing enables monitoring of regenerative agriculture practices, such as crop rotation, cover cropping, and conservation tillage to allow tracking and quantification at unprecedented scales. The Monitor system presented here capitalizes on the scope and scale of these data by integrating crop identification, cover cropping, and tillage intensity estimations annually at field scales across the contiguous United States (CONUS) from 2014 to 2023. The results provide the first ever mapping of these practices at this temporal fidelity and spatial scale, unlocking valuable insights for sustainable agricultural management. Monitor incorporates three datasets: CropID, a deep learning transformer model using Sentinel-2 and USDA Cropland Data Layer (CDL) data from 2018 to 2023 to predict annual crop types; the living root data, which use Normalized Difference Vegetation Index (NDVI) data to determine cover crop presence through regional parameterization; and residue cover (RC) data, which uses the Normalized Difference Tillage Index (NDTI) and crop residue cover (CRC) index to assess tillage intensity. The system calculates field-scale statistics and integrates these components to compile a comprehensive field management history. Results are validated with 35,184 ground-truth data points from 19 U.S. states, showing an overall accuracy of 80% for crop identification, 78% for cover crop detection, and 63% for tillage intensity. Also, comparisons with USDA NASS Ag Census data indicate that cover crop adoption rates were within 20% of estimates for 90% of states in 2017 and 81% in 2022, while for conventional tillage, 52% and 25% of states were within 20% of estimates, increasing to 75% and 67% for conservation tillage. Monitor provides a comprehensive view of regenerative practices by crop season for all of CONUS across a decade, supporting decision-making for sustainable agricultural management including associated outcomes such as reductions in emissions, long term yield resiliency, and supply chain stability.","2024-12","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","12","13","","","","","","","","","","English","","","","WOS:001387685100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","agricultural monitoring; CONSERVATION; cover crops; crop identification; CROP RESIDUE; DECOMPOSITION; LANDSAT; MODIS; MRV; QUALITY; REFLECTANCE; resilient agriculture; satellite remote sensing; SPECTRAL INDEXES; sustainability; tillage; TILLAGE PRACTICES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JXGLLIQS","journalArticle","2024","Jin, HX; Liang, YY; Lu, HP; Zhang, SL; Gao, YX; Zhao, Y; Zhu, ZZ","An intelligent framework for spatiotemporal simulation of flooding considering urban underlying surface characteristics","INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION","","1569-8432","10.1016/j.jag.2024.103908","","In current urban flood modeling, challenges arise from the inadequate consideration of heterogeneous underlying urban surface characteristics and the complexity of parameter optimization processes. This study integrates multiple machine learning methods to propose an intelligent framework for urban flood modeling that accounts for underlying surface characteristics. It began by coupling a surface runoff model with a pipe network model to form an interpretable flooding model (FM). Subsequently, utilizing the BIC-GMM machine learning method on the sample set of the urban flooding model ' s parameters, this study explored the grouping trends of these parameters. The Transformer model was employed to classify different categories of urban land use, which, along with other environmental indices, aided in the construction of an Artificial Neural Network (ANN) model. This model expedites the acquisition of the sensitivity parameters. The study also proposes urban functional zoning rules incorporating "" socio-driven-nature-assisted "" characteristics of the underlying surface. Finally, the clustering feature thresholds of the sensitive parameters were distributed across various catchment units based on the urban functional area distribution rules. This distribution was used to select multiple observed rainfall-runoff events to determine the optimal parameters of the inundation model, culminating in the construction of the BIC-GMM-Transformer-ANN-flooding model (BGTA-FM). The experimental results indicated that the method based on this intelligent modeling framework reached a mean Nash-Sutcliffe efficiency coefficient (NSE) of 0.8. This performance represents a 0.3 and 0.15 increase in NSE compared to the Transformer-ANN-flooding model and BIC-GMM-flooding model, respectively, and significantly enhances modeling efficiency. This effectively reflects the complex underlying surface environments of the research area. Our work demonstrates the substantial potential of integrating physical knowledge with machine learning in urban flood intelligent modeling and reaffirms the critical role of applying geospatial artificial intelligence (GeoAI) in geo-environmental research and disaster management.","2024-06","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","","130","","","","","","","","","","English","","","","WOS:001245325900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Geo-environmental; GeoAI; Machine learning; MODEL; PATTERNS; Transformer; Urban flooding disaster; Urban geospatial data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"763C8HJG","journalArticle","2025","Zhang, KC; Li, J; Li, Z; Jin, Z; Li, G","Transformer-based code model with compressed hierarchy representation","EMPIRICAL SOFTWARE ENGINEERING","","1382-3256","10.1007/s10664-025-10612-6","","Source code representation with deep learning techniques is an important research field. There have been many studies to learn sequential or structural information for code representation. However, existing sequence-based models and non-sequence models both have their limitations. Although researchers attempt to incorporate structural information into sequence-based models, they only mine part of token-level hierarchical structure information. In this paper, we analyze how the complete hierarchical structure influences the tokens in code sequences and abstract this influence as a property of code tokens called hierarchical embedding. This hierarchical structure includes frequent combinations, which represent strong semantics and can help identify unique code structures. We further analyze these hierarchy combinations and propose a novel compression algorithm Hierarchy BPE. Our algorithm can extract frequent hierarchy combinations and reduce the total length of hierarchical embedding. Based on the above compression algorithm, we propose the Byte-Pair Encoded Hierarchy Transformer (BPE-HiT), a simple but effective sequence model that incorporates the compressed hierarchical embeddings of source code into a Transformer model. Given that BPE-HiT significantly reduces computational overhead, we scale up the model training phase and implement a hierarchy-aware pre-training framework. We conduct extensive experiments on 10 datasets for evaluation, including code classification, clone detection, method name prediction and code completion tasks. Results show that our non-pre-trained BPE-HiT outperforms the state-of-the-art baselines by at least 0.94% on average accuracy on code classification tasks with three different program languages. On the method name prediction task, BPE-HiT outperforms baselines by at least 2.04, 1.34 in F1-score on two real-world datasets. Besides, our pre-trained BPE-HiT outperforms other pre-trained baseline models with the same number of parameters over all experiments, demonstrating the robust capability of our approach. Furthermore, we conduct a detailed ablation study, proving the effectiveness of our compression algorithm and the training efficiency of our proposed model.","2025-03","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","2","30","","","","","","","","","","English","","","","WOS:001403134300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Clone detection; Code classification; Code representation; Code summarization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5MJS4JWX","journalArticle","2024","Ray, P; Ganguli, B; Chakrabarti, A","Multivariate Bayesian Time-Series Model with Multi-temporal Convolution Network for Forecasting Stock Market During COVID-19 Pandemic","INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS","","1875-6891","10.1007/s44196-024-00525-5","","The paper proposes a hybrid algorithm for forecasting multiple correlated time-series data, which consists of two main steps. First, it employs a multivariate Bayesian structural time series (MBSTS) approach as a base step. This method allows for the incorporation of potentially high-dimensional regression components, and it utilizes spike and slab priors to identify a parsimonious model. Second, the algorithm includes a post-model fitting diagnostic step where the residuals from the MBSTS step are processed through a multi-input/output temporal convolutional network (M-TCN) with multiple time scale feature learning. This step serves as an alternative to traditional subjective residual-based diagnostic procedures in time-series analysis, with the aim of improving forecasting accuracy. The key advantage of the M-TCN is its ability to capture sequential information efficiently. The M-TCN expands the field of convolution kernel without increasing the number of parameters, thus enhancing the capacity of model to capture complex sequential patterns. The paper presents two applications showcasing the effectiveness of the proposed hybrid algorithm. First, it utilizes pre-lockdown data from eleven Nifty stock sectoral indices to predict stock price movements, including the initial post-lockdown upturn. In the second application, it focuses on stock market data from pharmaceutical companies involved in manufacturing COVID-19 vaccines. In both cases, sentiment data sourced from newspapers and social media serve as the regression component. Through rigorous analysis, the paper demonstrates that the hybrid model outperforms various benchmark models, including LSTM, Bidirectional Encoder Representations from Transformers (BERT)-based LSTM, Deep Transformer Model, and GRU, among others, in terms of forecasting accuracy. This underscores the utility of the hybrid algorithm, particularly in predicting stock market trends during the COVID-19 pandemic period and its associated market dynamics.","2024-06-27","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","1","17","","","","","","","","","","English","","","","WOS:001257152300003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Multivariate time-series; Residual diagnostics; Sentiment analysis; SHORT-TERM-MEMORY; State space model; Stock forecasting; Temporal convolutional network; VARIABLE SELECTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FWBJ2I2C","journalArticle","2024","Rydholm, E; Bastys, T; Svensson, E; Kannas, C; Engkvist, O; Kogej, T","Expanding the chemical space using a chemical reaction knowledge graph","DIGITAL DISCOVERY","","2635-098X","10.1039/d3dd00230f","","In this work, we present a new molecular de novo design approach which utilizes a knowledge graph encoding chemical reactions, extracted from the publicly available USPTO (United States Patent and Trademark Office) dataset. Our proposed method can be used to expand the chemical space by performing forward synthesis prediction by finding new combinations of reactants in the knowledge graph and can in this way generate libraries of de novo compounds along with a valid synthetic route. The forward synthesis prediction of novel compounds involves two steps. In the first step, a graph neural network-based link prediction model is used to suggest pairs of existing reactant nodes in the graph that are likely to react. In the second step, product prediction is performed using a molecular transformer model to obtain the potential products for the suggested reactant pairs. We achieve a ROC-AUC score of 0.861 for link prediction in the knowledge graph and for the product prediction, a top-1 accuracy of 0.924. The method's utility is demonstrated by generating a set of de novo compounds by predicting high probability reactions in the USPTO. The generated compounds are diverse in nature and many exhibit drug-like properties. A brief comparison with a template-based library design is provided. Furthermore, evaluation of the potential activity using a quantitative structure-activity relationship (QSAR) model suggested the presence of potential dopamine receptor D2 (DRD2) modulators among the proposed compounds. In summary, our results suggest that the proposed method can expand the easily accessible chemical space, by combining known compounds, and identify novel drug-like compounds for a specific target. Expanding the chemical space by inferring new chemical reactions through link prediction (SEAL) in a Chemical Reaction Knowledge Graph (CRKG). From high probability links, de novo products can be generated using a molecular transformer (Chemformer).","2024-07-10","2025-02-26 20:43:30","2025-02-26 20:43:30","","1378-1388","","7","3","","","","","","","","","","English","","","","WOS:001242933000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","NETWORKS; TOOL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X8APICYZ","journalArticle","2024","Chauhan, VK; Thakur, A; O'Donoghue, O; Rohanian, O; Molaei, S; Clifton, DA","Continuous patient state attention model for addressing irregularity in electronic health records","BMC MEDICAL INFORMATICS AND DECISION MAKING","","1472-6947","10.1186/s12911-024-02514-2","","Background Irregular time series (ITS) are common in healthcare as patient data is recorded in an electronic health record (EHR) system as per clinical guidelines/requirements but not for research and depends on a patient's health status. Due to irregularity, it is challenging to develop machine learning techniques to uncover vast intelligence hidden in EHR big data, without losing performance on downstream patient outcome prediction tasks.Methods In this paper, we propose Perceiver, a cross-attention-based transformer variant that is computationally efficient and can handle long sequences of time series in healthcare. We further develop continuous patient state attention models, using Perceiver and transformer to deal with ITS in EHR. The continuous patient state models utilise neural ordinary differential equations to learn patient health dynamics, i.e., patient health trajectory from observed irregular time steps, which enables them to sample patient state at any time.Results The proposed models' performance on in-hospital mortality prediction task on PhysioNet-2012 challenge and MIMIC-III datasets is examined. Perceiver model either outperforms or performs at par with baselines, and reduces computations by about nine times when compared to the transformer model, with no significant loss of performance. Experiments to examine irregularity in healthcare reveal that continuous patient state models outperform baselines. Moreover, the predictive uncertainty of the model is used to refer extremely uncertain cases to clinicians, which enhances the model's performance. Code is publicly available and verified at https://codeocean.com/capsule/4587224.Conclusions Perceiver presents a computationally efficient potential alternative for processing long sequences of time series in healthcare, and the continuous patient state attention models outperform the traditional and advanced techniques to handle irregularity in the time series. Moreover, the predictive uncertainty of the model helps in the development of transparent and trustworthy systems, which can be utilised as per the availability of clinicians.","2024-05-03","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","1","24","","","","","","","","","","English","","","","WOS:001225958400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Deep learning; Electronic health records; In-hospital-mortality; Irregular time series; MIMIC-III; Neural ordinary differential equations; Perceiver","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"93FPUSRS","journalArticle","2024","Hossain, MR; Hoque, MM; Siddique, N; Dewan, AA","AraCovTexFinder: Leveraging the transformer-based language model for Arabic COVID-19 text identification","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2024.107987","","In light of the pandemic, the identification and processing of COVID-19-related text have emerged as critical research areas within the field of Natural Language Processing (NLP). With a growing reliance on online portals and social media for information exchange and interaction, a surge in online textual content, comprising disinformation, misinformation, fake news , and rumors has led to the phenomenon of an infodemic on the World Wide Web. Arabic, spoken by over 420 million people worldwide, stands as a significant low -resource language, lacking efficient tools or applications for the detection of COVID-19-related text. Additionally, the identification of COVID-19 text is an essential prerequisite task for detecting fake and toxic content associated with COVID19. This gap hampers crucial COVID information retrieval and processing necessary for policymakers and health authorities. Addressing this issue, this paper introduces an intelligent Arabic COVID-19 text identification system named 'AraCovTexFinder,' leveraging a fine-tuned fusion -based transformer model. Recognizing the challenges posed by a scarcity of related text corpora, substantial morphological variations in the language, and a deficiency of well -tuned hyperparameters, the proposed system aims to mitigate these hurdles. To support the proposed method, two corpora are developed: an Arabic embedding corpus (AraEC) and an Arabic COVID-19 text identification corpus (AraCoV). The study evaluates the performance of six transformer -based language models (mBERT, XML-RoBERTa, mDeBERTa-V3, mDistilBERT, BERT -Arabic, and AraBERT), 12 deep learning models (combining Word2Vec, GloVe, and FastText embedding with CNN, LSTM, VDCNN, and BiLSTM), and the newly introduced model AraCovTexFinder. Through extensive evaluation, AraCovTexFinder achieves a high accuracy of 98.89 +/- 0.001%, outperforming other baseline models, including transformer -based language and deep learning models. This research highlights the importance of specialized tools in low -resource languages to combat the infodemic relating to COVID-19, which can assist policymakers and health authorities in making informed decisions.","2024-07","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","","133","","","","","","","","","","English","","","","WOS:001176673700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Ablation study; Arabic covid text; Language model; Late-fusion; Low-resource text identification; Natural language processing; Text processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ECYNF8YY","journalArticle","2024","Hao, XL; Xu, WJ; Huang, X; Sheng, ZZ; Yan, HY","MFUIE: A Fake News Detection Model Based on Multimodal Features and User Information Enhancement","EAI ENDORSED TRANSACTIONS ON SCALABLE INFORMATION SYSTEMS","","2032-9407","10.4108/eetsis.7517","","INTRODUCTION: Deep learning algorithms have advantages in extracting key features for detecting fake news. However, the existing multi-modal fake news detection models only fuse the visual and textual features after the encoder, failing to effectively utilize the multi-modal contextual relationships and resulting in insufficient feature fusion. Moreover, most fake news detection algorithms focus on mining news content and overlook the users' preferences whether to spread fake news. OBJECTIVES: The model uses the multi-modal context relationship when extracting model features, and combines with user features to assist in mining multi-modal information to improve the performance of fake news detection. METHODS: A fake news detection model called MFUIE (Multimodal Feature and User Information Enhancement) is proposed, which utilizes multi-modal features and user information enhancement. Firstly, for news content, we utilize the pre-trained language model BERT to encode sentences. At the same time, we use the Swin Transformer model as the main framework and introduce textual features during the early visual feature encoding to enhance semantic interactions. Additionally, we employ InceptionNetV3 as the image pattern analyser. Secondly, for user's historical posts, we use the same model as the news text to encode them, and introduce GAT (Graph Attention Network) to enhance information interaction between post nodes, capturing user-specific features. Finally, we fuse the obtained user features with the multi- modal features and validate the performance of the model. RESULTS: The proposed model's performance is compared with those of existing methods. MFUIE model achieves an accuracy of 0.926 and 0.935 on the Weibo dataset and Weibo-21 dataset, respectively. F1 on Weibo is 0.926, 0.017 greater than SOAT model BRM; while F1 on Weibo-21 is 0.935, 0.009 greater than that of BRM. CONCLUSION: Experimental results demonstrate that MFUIE can improve the fake news recognition in some degree.","2024","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","1","12","","","","","","","","","","English","","","","WOS:001382058100021","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","deep learning; fake news detection; Multimodal; user information","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H4SIUZCH","journalArticle","2024","Li, GN; Chen, JJ; Tao, YT; Li, AX; Zhang, XW","Residual Life Prediction of Pneumatic Control Valves Based on Trans-TCN-GRU Modeling","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3513484","","Control valves, as key actuating components in process industrial systems, are widely used in major industrial fields such as coal chemical, petrochemical, and nuclear power. In recent years, with the gradual increase in industry scale and industrial technology, the operating conditions of control valves have become increasingly harsh. To ensure their safe and stable operation, accurately predicting their remaining useful life (RUL) is an important task. In current research on RUL prediction for control valves, challenges such as difficulty in obtaining fault data, limited real-world data, and information loss due to the use of only time-series data can lead to reduced prediction accuracy. To address these issues, this study collected a variety of simulated fault data based on a DAMADICS model built in Simulink, as well as real fault data generated from a pneumatic control valve test bench. The approach involved using an improved Transformer model for feature extraction from the data, applying a Temporal Convolutional Network (TCN) to mine temporal relationships among the data, and finally using a GRU module to extract features from non-time-series operating condition data. This resulted in a hybrid neural network model that uses full-scale data for predicting the remaining useful life of control valves. To validate the effectiveness of this model, the collected data was applied to it and compared with single models such as TCN and Transformer. The results showed that the Root Mean Square Error (RMSE) was reduced by 49.8% and 63.7%, the Mean Absolute Error (MAE) was reduced by 61.1% and 75%, and the Mean Absolute Percentage Error (MAPE) was reduced by 50.6% and 69.6%, respectively, demonstrating that the proposed method offers higher accuracy.","2024","2025-02-26 20:43:30","2025-02-26 20:43:30","","191670-191681","","","12","","","","","","","","","","English","","","","WOS:001381662100044","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;16</p>","","","Computational modeling; Data models; deep learning; Degradation; Feature extraction; Logic gates; Maintenance; neural network; Neural networks; Pneumatic control valve; Predictive models; residual life prediction; Transformers; Valves","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HWUPJ6IE","journalArticle","2024","Jeong, S; Shin, Y","LTE: Lightweight Transformer Encoder for Orbit Prediction","ELECTRONICS","","2079-9292","10.3390/electronics13224371","","As the focus of space exploration has recently shifted from national efforts to private enterprises, interest in the space industry has increased. With the rising number of satellite launches, the risk of collisions between satellites and between satellites and space debris has grown, which can lead not only to property damage but also casualties caused by the debris. To address this issue, various machine learning and deep learning-based methods have been researched to improve the accuracy of satellite orbit prediction and mitigate these risks. However, most studies have applied basic machine learning models to orbit prediction without considering the model size and execution time, even though satellite operations require lightweight models that offer both a strong prediction performance and rapid execution. In this study, we propose a time series forecasting framework, the Lightweight Transformer Encoder (LTE), for satellite orbit prediction. The LTE is a prediction model that modifies the encoder structure of the Transformer model to enhance the accuracy of satellite orbit prediction and reduce the computational resources used. To evaluate its performance, we conducted experiments using about 4.8 million data points collected every minute from January 2016 to December 2018 by the KOMPSAT-3, KOMPSAT-3A, and KOMPSAT-5 satellites, which are part of the Korea Multi-Purpose Satellite (KOMPSAT) series operated by the Korea Aerospace Research Institute (KARI). We compare the performance of our model against various baseline models in terms of prediction error, execution time, and the number of parameters used. Our LTE model demonstrates significant improvements: it reduces the orbit prediction error by 50.61% in the KOMPSAT-3 dataset, 42.40% in the KOMPSAT-3A dataset, and 30.00% in the KOMPSAT-5 dataset compared to the next-best-performing model. Additionally, in the KOMPSAT-3 dataset, it decreases the execution time by 36.86% (from 1731 to 1093 s) and lowers the number of parameters by 2.33% compared to the next-best-performing model.","2024-11","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","22","13","","","","","","","","","","English","","","","WOS:001364338300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","MACHINE; machine learning; orbit prediction; time series forecasting; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6LPVVYLP","journalArticle","2024","Zhao, Y; Gao, ZM; Fan, RM; Yu, FJ; Zhang, XL; Tang, JW; Chen, G","Reconstruction of Typhoon-Induced Ocean Thermal Structures Using Deep Learning and Multi-Source Satellite Data with News Impact Analysis","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app142110050","","Reconstructing the three-dimensional thermal structure of the ocean under typhoon conditions presents significant challenges due to the scarcity of observational data, particularly in subsurface regions, and the limitations of existing observation methods in terms of spatial and temporal resolution. Accurate reconstruction of these structures is crucial for understanding the energy exchange between the ocean and typhoons, as this exchange directly influences typhoon intensity and trajectory. To address these challenges, this study introduces a fully connected transformer network (FCT), which integrates fully connected layers with a transformer model. The FCT model leverages the attention mechanisms inherent in the transformer architecture to effectively extract and integrate multi-scale ocean dynamical features. Using data from Typhoon Lekima in 2019, this study reconstructs ocean thermal structures at various depths and achieves an RMSE of 1.03 degrees C and an MAE of 0.83 degrees C when validated against Argo data. Furthermore, the model's robustness was demonstrated through five-fold cross-validation, with the validation loss exhibiting minor fluctuations across folds but remaining stable overall, with an average validation loss of 0.986 degrees C, indicating the model's generalizability. Sensitivity analysis also revealed the model's resilience to variations in key input variables, showing minimal impact on output even with perturbations of up to 10% in input data. In addition, the study incorporates content analysis of typhoon-related news reports from 2011 to 2020, revealing a predominance of political topics, which underscores the central role of government in disaster response, with economic and ecological topics following. This integrated approach not only enhances our understanding of the interactions between ocean thermal structures and typhoon dynamics but also provides valuable insights into the societal impacts of typhoons, as reflected in media coverage, contributing to improved disaster management strategies.","2024-11","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","21","14","","","","","","","","","","English","","","","WOS:001351081200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","Argo data; content analysis; cross-validation; fully connected transformer network; INTENSITY; ocean dynamics; sensitivity analysis; three-dimensional thermal structure reconstruction; typhoon","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X4N7VB6G","journalArticle","2024","Tian, Y; Deng, YL; Zhang, MZ; Pang, X; Ma, RP; Zhang, JX","Short-term displacement prediction for newly established monitoring slopes based on transfer learning","CHINA GEOLOGY","","2096-5192","10.31035/cg2024053","","This study makes a significant progress in addressing the challenges of short-term slope displacement prediction in the Universal Landslide Monitoring Program, an unprecedented disaster mitigation program in China, where lots of newly established monitoring slopes lack sufficient historical deformation data, making it difficult to extract deformation patterns and provide effective predictions which plays a crucial role in the early warning and forecasting of landslide hazards. A slope displacement prediction method based on transfer learning is therefore proposed. Initially, the method transfers the deformation patterns learned from slopes with relatively rich deformation data by a pre-trained model based on a multi-slope integrated dataset to newly established monitoring slopes with limited or even no useful data, thus enabling rapid and efficient predictions for these slopes. Subsequently, as time goes on and monitoring data accumulates, fine-tuning of the pre-trained model for individual slopes can further improve prediction accuracy, enabling continuous optimization of prediction results. A case study indicates that, after being trained on a multi-slope integrated dataset, the TCN-Transformer model can efficiently serve as a pre-trained model for displacement prediction at newly established monitoring slopes. The three-day average RMSE is significantly reduced by 34.6% compared to models trained only on individual slope data, and it also successfully predicts the majority of deformation peaks. The fine-tuned model based on accumulated data on the target newly established monitoring slope further reduced the three-day RMSE by 37.2%, demonstrating a considerable predictive accuracy. In conclusion, taking advantage of transfer learning, the proposed slope displacement prediction method effectively utilizes the available data, which enables the rapid deployment and continual refinement of displacement predictions on newly established monitoring slopes. (c) 2024 China Geology Editorial Office.","2024-04-25","2025-02-26 20:43:30","2025-02-26 20:43:30","","351-364","","2","7","","","","","","","","","","English","","","","WOS:001370963200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Geological hazards survey engineering; Integrated dataset; Landslide; LANDSLIDE DISPLACEMENT; Pre-trained model; SIMILARITY MEASURE; Slope displacement prediction; Transfer learning; Transformer; Universal Landslide Monitoring Program (ULMP)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q4BSYK24","journalArticle","2023","Breden, S; Hinterwimmer, F; Consalvo, S; Neumann, J; Knebel, C; von Eisenhart-Rothe, R; Burgkart, RH; Lenze, U","Deep Learning-Based Detection of Bone Tumors around the Knee in X-rays of Children","JOURNAL OF CLINICAL MEDICINE","","2077-0383","10.3390/jcm12185960","","Even though tumors in children are rare, they cause the second most deaths under the age of 18 years. More often than in other age groups, underage patients suffer from malignancies of the bones, and these mostly occur in the area around the knee. One problem in the treatment is the early detection of bone tumors, especially on X-rays. The rarity and non-specific clinical symptoms further prolong the time to diagnosis. Nevertheless, an early diagnosis is crucial and can facilitate the treatment and therefore improve the prognosis of affected children. A new approach to evaluating X-ray images using artificial intelligence may facilitate the detection of suspicious lesions and, hence, accelerate the referral to a specialized center. We implemented a Vision Transformer model for image classification of healthy and pathological X-rays. To tackle the limited amount of data, we used a pretrained model and implemented extensive data augmentation. Discrete parameters were described by incidence and percentage ratio and continuous parameters by median, standard deviation and variance. For the evaluation of the model accuracy, sensitivity and specificity were computed. The two-entity classification of the healthy control group and the pathological group resulted in a cross-validated accuracy of 89.1%, a sensitivity of 82.2% and a specificity of 93.2% for test groups. Grad-CAMs were created to ensure the plausibility of the predictions. The proposed approach, using state-of-the-art deep learning methodology to detect bone tumors on knee X-rays of children has achieved very good results. With further improvement of the algorithm, enlargement of the dataset and removal of potential biases, this could become a useful additional tool, especially to support general practitioners for early, accurate and specific diagnosis of bone lesions in young patients.","2023-09","2025-02-26 20:43:30","2025-02-26 20:43:30","","","","18","12","","","","","","","","","","English","","","","WOS:001072196700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","artificial intelligence; bone tumor; cancer; deep learning; DELAY; DIAGNOSIS; EWING SARCOMA; OSTEOSARCOMA; pediatrics; PROGNOSTIC-FACTORS; SURVIVAL; SYMPTOMS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UQ2IGHU2","journalArticle","2022","Raza, S; Schwartz, B; Rosella, LC","CoQUAD: a COVID-19 question answering dataset system, facilitating research, benchmarking, and practice","BMC BIOINFORMATICS","","1471-2105","10.1186/s12859-022-04751-6","","Background Due to the growing amount of COVID-19 research literature, medical experts, clinical scientists, and researchers frequently struggle to stay up to date on the most recent findings. There is a pressing need to assist researchers and practitioners in mining and responding to COVID-19-related questions on time. Methods This paper introduces CoQUAD, a question-answering system that can extract answers related to COVID-19 questions in an efficient manner. There are two datasets provided in this work: a reference-standard dataset built using the CORD-19 and LitCOVID initiatives, and a gold-standard dataset prepared by the experts from a public health domain. The CoQUAD has a Retriever component trained on the BM25 algorithm that searches the reference-standard dataset for relevant documents based on a question related to COVID-19. CoQUAD also has a Reader component that consists of a Transformer-based model, namely MPNet, which is used to read the paragraphs and find the answers related to a question from the retrieved documents. In comparison to previous works, the proposed CoQUAD system can answer questions related to early, mid, and post-COVID-19 topics. Results Extensive experiments on CoQUAD Retriever and Reader modules show that CoQUAD can provide effective and relevant answers to any COVID-19-related questions posed in natural language, with a higher level of accuracy. When compared to state-of-the-art baselines, CoQUAD outperforms the previous models, achieving an exact match ratio score of 77.50% and an F1 score of 77.10%. Conclusion CoQUAD is a question-answering system that mines COVID-19 literature using natural language processing techniques to help the research community find the most recent findings and answer any related questions.","2022-06-02","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","1","23","","","","","","","","","","English","","","","WOS:000805177600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","CORD-19; COVID-19; LitCOVID; Long-COVID; Pipeline; Post-COVID-19; Question answering system; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I7F3ZY33","journalArticle","2024","Vinotha, R; Hepsiba, D; Anand, LDV; Andrew, J; Eunice, RJ","Enhancing dysarthric speech recognition through SepFormer and hierarchical attention network models with multistage transfer learning","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-80764-w","","Dysarthria, a motor speech disorder that impacts articulation and speech clarity, presents significant challenges for Automatic Speech Recognition (ASR) systems. This study proposes a groundbreaking approach to enhance the accuracy of Dysarthric Speech Recognition (DSR). A primary innovation lies in the integration of the SepFormer-Speech Enhancement Generative Adversarial Network (S-SEGAN), an advanced generative adversarial network tailored for Dysarthric Speech Enhancement (DSE), as a front-end processing stage for DSR systems. The S-SEGAN integrates SEGAN's adversarial learning with SepFormer speech separation capabilities, demonstrating significant improvements in performance. Furthermore, a multistage transfer learning approach is employed to assess the DSR models for both word-level and sentence-level DSR. These DSR models are first trained on a large speech dataset (LibriSpeech) and then fine-tuned on dysarthric speech data (both isolated and augmented). Evaluations demonstrate significant DSR accuracy improvements in DSE integration. The Dysarthric Speech (DS)-baseline models (without DSE), Transformer and Conformer achieved Word Recognition Accuracy (WRA) percentages of 68.60% and 69.87%, respectively. The introduction of Hierarchical Attention Network (HAN) with the Transformer and Conformer architectures resulted in improved performance, with T-HAN achieving a WRA of 71.07% and C-HAN reaching 73%. The Transformer model with DSE + DSR for isolated words achieves a WRA of 73.40%, while that of the Conformer model reaches 74.33%. Notably, the T-HAN and C-HAN models with DSE + DSR demonstrate even more substantial enhancements, with WRAs of 75.73% and 76.87%, respectively. Augmenting words further boosts model performance, with the Transformer and Conformer models achieving WRAs of 76.47% and 79.20%, respectively. Remarkably, the T-HAN and C-HAN models with DSE + DSR and augmented words exhibit WRAs of 82.13% and 84.07%, respectively, with C-HAN displaying the highest performance among all proposed models.","2024-11-27","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","1","14","","","","","","","","","","English","","","","WOS:001366866100018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;77</p>","","","Conformer; DSR; Dysarthric speech enhancement; ENHANCEMENT; HAN; SepFormer-SEGAN; Transformer; WRA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HEPLJ63E","journalArticle","2024","Nakasone, K; Nishimori, M; Shinohara, M; Takami, M; Imamura, K; Nishida, T; Shimane, A; Oginosawa, Y; Nakamura, Y; Yamauchi, Y; Fujiwara, R; Asada, H; Yoshida, A; Takami, K; Akita, T; Nagai, T; Sommer, P; El Hamriti, M; Imada, H; Pannone, L; Sarkozy, A; Chierchia, GB; de Asmundis, C; Kiuchi, K; Hirata, K; Fukuzawa, K","Enhancing origin prediction: deep learning model for diagnosing premature ventricular contractions with dual-rhythm analysis focused on cardiac rotation","EUROPACE","","1099-5129","10.1093/europace/euae240","","Aims Several algorithms can differentiate inferior axis premature ventricular contractions (PVCs) originating from the right side and left side on 12-lead electrocardiograms (ECGs). However, it is unclear whether distinguishing the origin should rely solely on PVC or incorporate sinus rhythm (SR). We compared the dual-rhythm model (incorporating both SR and PVC) to the PVC model (using PVC alone) and quantified the contribution of each ECG lead in predicting the PVC origin for each cardiac rotation. Methods and results This multicentre study enrolled 593 patients from 11 centres-493 from Japan and Germany, and 100 from Belgium, which were used as the external validation data set. Using a hybrid approach combining a Resnet50-based convolutional neural network and a transformer model, we developed two variants-the PVC and dual-rhythm models-to predict PVC origin. In the external validation data set, the dual-rhythm model outperformed the PVC model in accuracy (0.84 vs. 0.74, respectively; P < 0.01), precision (0.73 vs. 0.55, respectively; P < 0.01), specificity (0.87 vs. 0.68, respectively; P < 0.01), area under the receiver operating characteristic curve (0.91 vs. 0.86, respectively; P = 0.03), and F1-score (0.77 vs. 0.68, respectively; P = 0.03). The contributions to PVC origin prediction were 77.3% for PVC and 22.7% for the SR. However, in patients with counterclockwise rotation, SR had a greater contribution in predicting the origin of right-sided PVC. Conclusion Our deep learning-based model, incorporating both PVC and SR morphologies, resulted in a higher prediction accuracy for PVC origin, considering SR is particularly important for predicting right-sided origin in patients with counterclockwise rotation. Graphical Abstract","2024-10-03","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","10","26","","","","","","","","","","English","","","","WOS:001327409500004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Algorithm; Artificial intelligence; ARTIFICIAL-INTELLIGENCE; Cardiac rotation; Deep learning; ECG ALGORITHM; ELECTROCARDIOGRAPHIC CRITERION; OPTIMAL ABLATION SITE; OUTFLOW TRACT; Outflow tracts; Premature ventricular contraction; TRACT TACHYCARDIA ORIGIN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M6CXRSSB","journalArticle","2022","Huang, L; Wang, FX; Zhang, YL; Xu, QX","Fine-Grained Ship Classification by Combining CNN and Swin Transformer","REMOTE SENSING","","2072-4292","10.3390/rs14133087","","The mainstream algorithms used for ship classification and detection can be improved based on convolutional neural networks (CNNs). By analyzing the characteristics of ship images, we found that the difficulty in ship image classification lies in distinguishing ships with similar hull structures but different equipment and superstructures. To extract features such as ship superstructures, this paper introduces transformer architecture with self-attention into ship classification and detection, and a CNN and Swin transformer model (CNN-Swin model) is proposed for ship image classification and detection. The main contributions of this study are as follows: (1) The proposed approach pays attention to different scale features in ship image classification and detection, introduces a transformer architecture with self-attention into ship classification and detection for the first time, and uses a parallel network of a CNN and a transformer to extract features of images. (2) To exploit the CNN's performance and avoid overfitting as much as possible, a multi-branch CNN-Block is designed and used to construct a CNN backbone with simplicity and accessibility to extract features. (3) The performance of the CNN-Swin model is validated on the open FGSC-23 dataset and a dataset containing typical military ship categories based on open-source images. The results show that the model achieved accuracies of 90.9% and 91.9% for the FGSC-23 dataset and the military ship dataset, respectively, outperforming the existing nine state-of-the-art approaches. (4) The good extraction effect on the ship features of the CNN-Swin model is validated as the backbone of the three state-of-the-art detection methods on the open datasets HRSC2016 and FAIR1M. The results show the great potential of the CNN-Swin backbone with self-attention in ship detection.","2022-07","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","13","14","","","","","","","","","","English","","","","WOS:000824166500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;20<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","CNN; image classification; remote sensing images; self-attention; ship detection; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WDHP8B66","journalArticle","2024","Uomoto, KE","Increasing Identification and Follow-Up of Cognitive Impairment in Primary Care: A Quality Improvement Pilot Study","JOURNAL OF PRIMARY CARE AND COMMUNITY HEALTH","","2150-1319","10.1177/21501319241277397","","Introduction: Beyond our population growing older and living longer, there is an increased risk of developing a cognitive disorder. Standardized screening during a routine visit in primary care may be ideal for early detection of mild cognitive impairment (MCI) and follow-up for cognitive changes.Aim: This quality improvement (QI) project aimed to determine the impact of implementing the Mini-Cog (c) quick screening for early dementia detection to identify and follow up on the cognitive impairment of older adults in a primary care clinic setting.Methods: Implementation started in February 2024 in a primary care clinic in Southern California. Data was collected for this project over a total of 16 weeks. This QI project implemented a routine cognitive screening using the Mini-Cog (c). Cognitive impairment was identified, and if indicated by the Mini-Cog (c) scores, follow-up for a cognitive assessment and care plan services were initiated. Data were obtained from the project site's electronic medical record on a total sample size of 471 participants (n = 382 in the pre-implementation group and n = 89 in the post-implementation group).Results: Pearson's chi-square test indicated a statistically significant improvement in the identification rate of cognitive impairment, increasing from 11.8% (n = 45 out of 382) at pre-implementation to 34.8% (n = 31 out of 89) at post-implementation, and specifically, mild cognitive impairment increased from zero identified in pre-implementation to 12.4% (n = 11 out of 89) post-implementation. Lastly, follow-up rates improved from 91.1% (n = 41 out of 45) to 100% (n = 31 out of 31) in post-implementation, and clinical significance was evident based on the phi-coefficient (phi = 0.196), indicating a small effect size and a 100% follow-up rate.Conclusions: The findings of this project suggest older adults should receive cognitive screenings to help identify early cognitive impairment and increase follow-up for further evaluation, treatment, and advanced care planning.","2024","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","15","","","","","","","","","","English","","","","WOS:001306315100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;17</p>","","","ADAPTATION; dementia; geriatrics; health outcomes; MINI-COG; primary care; quality improvement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H8HFF7JC","journalArticle","2023","Nokkaew, M; Nongpong, K; Yeophantong, T; Ploykitikoon, P; Arjharn, W; Siritaratiwat, A; Narkglom, S; Wongsinlatam, W; Remsungnen, T; Namvong, A; Surawanitkun, C","Analyzing online public opinion on Thailand-China high-speed train and Laos-China railway mega-projects using advanced machine learning for sentiment analysis","SOCIAL NETWORK ANALYSIS AND MINING","","1869-5450","10.1007/s13278-023-01168-8","","Sentiment analysis is becoming a very popular research technique. It can effectively identify hidden emotional trends in social networks to understand people's opinions and feelings. This research therefore focuses on analyzing the sentiments of the public on the social media platform, YouTube, about the Thailand-China high-speed train project and the Laos-China Railway, a mega-project that is important to the country and a huge investment to develop transportation infrastructure. It affects both the economic and social dimensions of Thai people and is also an important route to connect the rail systems of ASEAN countries as part of the Belt and Road Initiative. We gathered public Thai reviews from YouTube using the Data Application Program Interface. This dataset was used to train six sentiment classifiers using machine learning and deep learning algorithms. The performance of all six models by means of precision, recall, F1-score and accuracy are compared to find the most suitable model architecture for sentiment classification. The results show that the transformer model with the WangchanBERTa language model yields best accuracy, 94.57%. We found that the use of a Thai language-specific model that was trained from a large variety of data sources plays a major role in the model performance and significantly increases the accuracy of sentiment prediction. The promising performance of this sentiment classification model also suggests that it can be used as a tool for government agencies to plan, make strategic decisions, and improve communication with the public for better understanding of their projects. Furthermore, the model can be integrated with any online platform to monitor people's sentiments on other public matters. Regular monitoring of public opinions could help the policy makers in designing public policies to address the citizens' problems and concerns as well as planning development strategies for the country.","2023-12-18","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","1","14","","","","","","","","","","English","","","","WOS:001126279100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Deep learning; Government; Machine learning; Public opinion; Sentiment analysis; Social media","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J4HX23UF","journalArticle","2023","Altan, D; Marijan, D; Kholodna, T","SafeWay: Improving the safety of autonomous waypoint detection in maritime using transformer and interpolation","MARITIME TRANSPORT RESEARCH","","2666-822X","10.1016/j.martra.2023.100086","","Detecting waypoints where vessels change their behavior (i.e., maneuvers, speed changes, etc.) is essential for optimizing vessel trajectories to increase the efficiency and safety of sailing. However, accurately detecting waypoints is challenging due to potential AIS data quality issues (i.e., missing or inaccurate messages). In this paper, we propose a five-step learning approach (SafeWay) to estimate waypoints on a given AIS trajectory. First, we interpolate trajectories to tackle AIS data quality issues. Then, we annotate historical trajectories by using an existing waypoint library that contains historical waypoints. As the historical waypoints are passage plans manually created by port operators considering sailing conditions at that time, they are not specific to other historical trajectories between the same ports. We, therefore, use a similarity metric to determine overlapping segments of historical trajectories with the historical waypoints from the waypoint library. Then, we build a transformer model to capture vessel movement patterns based on speed-and location-related features. We do not process location features directly to avoid learning location-specific context, but take into account tailored delta features. We test our approach on a real-world AIS dataset collected from the Norwegian Sea between & ANGS;lesund and Maloy and show its effectiveness in terms of a harmonic mean of purity and coverage, mean absolute error and detection rate on the task of detecting trajectory waypoints compared to a state-of-the-art approach. We also show the effectiveness of the trained model on the trajectories obtained from two other regions, the North Sea (London and Rotterdam) and the North Atlantic Ocean (Setubal and Gibraltar), on which the model has not been trained. The experiments indicate that our interpolation-enabled transformer design provides improvements in the safety of the estimated waypoints.","2023-06","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","4","","","","","","","","","","English","","","","WOS:001023629700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","AIS; Automatic identification system; Interpolation; Maneuver; Maritime; Safety; Trajectory prediction; Transformers; Vessel; Waypoint detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K5Z6PKXI","journalArticle","2024","Wei, J; Wang, ZH; Li, ZQ; Li, ZQ; Pang, SL; Xi, XY; Cribb, M; Sun, L","Global aerosol retrieval over land from Landsat imagery integrating Transformer and Google Earth Engine","REMOTE SENSING OF ENVIRONMENT","","0034-4257","10.1016/j.rse.2024.114404","","Landsat imagery offers remarkable potential for various applications, including land monitoring and environmental assessment, thanks to its high spatial resolution and over 50 years of data records. However, the presence of atmospheric aerosols greatly hinders the precision of land classification and the quantitative retrieval of surface parameters. There is a pressing need for reliable and accurate global aerosol optical depth (AOD) data derived from Landsat imagery, particularly for atmospheric correction purposes and various other applications. To address this issue, we introduce an innovative framework for retrieving AOD from Landsat imagery over land, which leverages the deep-learning Transformer model (named AeroTrans-Landsat) and operates on the Google Earth Engine (GEE) cloud platform. We gather Landsat 8 and 9 images starting from their launch dates (February 2013 and September 2021, respectively) until the end of 2022, which are used to construct a robust aerosol retrieval model. The global AOD retrievals are then rigorously validated across similar to 560 monitoring stations on land using diverse spatiotemporally independent methods. Leveraging information from multiple spectral channels, which contributes to 80 % according to the SHapley Additive exPlanation (SHAP) method, our retrieved AODs from 2013 to 2022 generally agree well with surface observations, with a sample-based cross-validation correlation coefficient of 0.905 and a root-mean-square error of 0.083. Around 86 % and 55 % of our AOD retrievals meet the criteria of Moderate Resolution Imaging Spectroradiometer (MODIS) Deep Blue expected errors [+/-(0.05 + 20 %)] and the Global Climate Observation System {[max(0.03, 10 %)]}, respectively. Additionally, our model is not as sensitive to fluctuations in both surface and atmospheric conditions, enabling the generation of spatially continuous AOD distributions with exceptionally fine-scale information over dark to bright surfaces. This capability extends to areas characterized by high pollution levels originating from both anthropogenic and natural sources.","2024-12-15","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","315","","","","","","","","","","English","","","","WOS:001322713300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","AERONET; ALGORITHM; AOD retrieval; ATMOSPHERIC CORRECTION; CLIMATE; eXplainable Artificial Intelligence; Google Earth Engine; IMPACT; Landsat; MODIS; OPTICAL DEPTH; PARTICULATE MATTER; PRODUCTS; Transformer; VALIDATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LVZVEGCS","journalArticle","2024","He, KK; Li, LM; Zhou, J; Gou, FF; Wu, J","Asymptotic multilayer pooled transformer based strategy for medical assistance in developing countries","COMPUTERS & ELECTRICAL ENGINEERING","","0045-7906","10.1016/j.compeleceng.2024.109493","","With the continuous progress of medical imaging technology, pathology images have become an important basis for doctors to judge the condition. However, pathology images have problems such as large numbers, large sizes, and complex backgrounds, which make the task of manual recognition exceptionally difficult. The use of computer-aided diagnosis technology can improve the diagnostic accuracy of medical image recognition. Transformer model-based methods have made great progress in the field of medical image recognition, but the self-attention mechanism in them has high computational complexity. Although single-layer pooling can reduce the computational cost, the strategy is prone to feature loss, and too many self-attention operations can exacerbate the distraction problem. Based on this, this study proposes an asymptotic multilayer pooling transformer-based pathology image assistance strategy in medical decision-making systems. First, we pre-process the pathology images with denoising and enhancement to accurately capture the detailed features of the lesion region. Then the asymptotic multilayer pooling transformer pyramid structure (PMPSNet) is used to identify cell nuclei. In the self-focused module, a multilayer pooling operation is employed to simplify the sequence and efficiently capture contextual features. In addition, the strategy utilizes a pyramid encoder to obtain multi- scale feature maps and a novel multilayer perceptual structure to limit the attention interference problem. The results show that our proposed PMPSNet-L model achieves a DSC value of 0.822, which is about 1.4 % better than the second-ranked model, and the IoU value reaches up to 0.702. In addition, our PMPSNet-S maintains a relatively lightweight parameter size of about 14.49 million, which is considerably lower than the existing segmentation models. Our proposed method not only achieves higher segmentation accuracy but also has fewer model parameters and lower computational complexity.","2024-10","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","119","","","","","","","","","","English","","","","WOS:001289418200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","Attention distraction; Medical image segmentation; Multi-layer pooling; Pathology images; Pyramid multilayer pooling structure net","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G8ECLYGH","journalArticle","2023","Wei, H; Wang, WS; Kao, XX","A novel approach to ultra-short-term wind power prediction based on feature engineering and informer","ENERGY REPORTS","","2352-4847","10.1016/j.egyr.2022.12.062","","Wind power is prone to dramatic fluctuations in the short term, posing a threat to the safety and stability of the grid, so accurate forecasting of ultra-short-term wind power is important to ensure the stability and economy of the power system. The historical data of wind power is an enormous and nonlinear time series. It is expected to mine the independent features related to wind power from the original data through feature engineering, and then use the Informer model to solve the prediction problem of long-time series of wind power, thus reducing the space complexity and improving the prediction accuracy. In this paper, Turkey wind farm data are selected to predict ultra-short-term wind power of 10 min based on feature engineering and the Informer model. First, factor data with a high correlation with wind power is formed after feature engineering. Then, train the Informer model and conduct multiple experiments to obtain the optimal parameters. Finally, the prediction results are compared with the recurrent neural network (RNN) model, the long-short-term memory (LSTM) model, and the Transformer model. The experimental results show that the Informer model has high prediction accuracy and operation efficiency. Four evaluation metrics of mean absolute error, mean square error, symmetric mean absolute percentage error, and runtime decreased by at least 32.849, 8495.193, 5.544%, and 92, which proves the approach based on feature engineering and Informer has prominent advantages in ultra-short-term wind power prediction. Its prediction results can provide a reference for the coordinated dispatching, risk analysis, and scientific decision-making of wind power systems.(c) 2022 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).","2023-12","2025-02-26 20:43:31","2025-02-26 20:43:31","","1236-1250","","","9","","","","","","","","","","English","","","","WOS:000913006300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;32<br/>Total Times Cited:&nbsp;&nbsp;34<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","DECOMPOSITION; Feature engineering; FORECAST; Informer model; LOAD; Long time series; MODEL; NEURAL-NETWORK; Prediction; SPEED; Ultra-short-term wind power","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JJXMVZRR","journalArticle","2024","Ataa, MS; Sanad, EE; El-khoribi, RA","Intrusion detection in software defined network using deep learning approaches","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-79001-1","","Ensuring robust network security is crucial in the context of Software-Defined Networking(SDN). Which, becomes a multi-billion dollar industry, and it's deployed in many data centers nowadays. The new technology provides network programmability, network centralized control, and a global view of the network. But, unfortunately, it comes with new vulnerabilities, and new attack vectors compared to the traditional network. SDN network cybersecurity became a trending research topic due to the hype of Machine Learning (ML) when a group of Machine Learning(ML) techniques called Deep Learning(DL) started to take shape in the setting of SDN networks. This paper focuses on developing advanced Deep Learning(DL) models to address the inherent new attack vectors. In this paper, we have built and compared two models that can be used for building a complete Intrusion Detection System(IDS) solution, one using a hybrid CNN-LSTM architecture and the other using Transformer encoder-only architecture. We specifically target the SDN controller where it represents a crucial point. We utilized the InSDN dataset for training and testing our models, this dataset captures real-world traffic within the SDN environment. For evaluation, we have used accuracy, precision, recall, and F1 Score. Our experiment results show that the Transformer model with 48 features achieves the highest accuracy at 99.02%, while the CNN-LSTM model achieves 99.01%. We have reduced the features to 6 and 4, which gave us varying impacts on the models' performance. We have merged 4 poorly represented attacks in one class, which enhanced the accuracy by a significant score. Additionally, we investigate binary classification by merging all attack types into a single class, as a result, the accuracy increased for both models. The CNN-LSTM model achieves the best results with an accuracy of 99.19% for 6 feature sets, this enhances the state-of-the-art results.","2024-11-25","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","1","14","","","","","","","","","","English","","","","WOS:001364088200028","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FVLMR8DB","journalArticle","2024","Balasundaram, A; Aziz, ABA; Gupta, A; Shaik, A; Kavitha, MS","A fusion approach using GIS, green area detection, weather API and GPT for satellite image based fertile land discovery and crop suitability","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-67070-1","","Proper utilization of agricultural land is a big challenge as they often laid over as waste lands. Farming is a significant occupation in any country and improving it further by promoting more farming opportunities will take the country towards making a huge leap forward. The issue in achieving this would be the lack of knowledge of cultivable land for food crops. The objective of this work is to utilize modern computer vision technology to identify and map cultivable land for agricultural needs. With increasing population and demand for food, improving the farming sector is crucial. However, the challenge lies in the lack of suitable land for food crops cultivation. To tackle this issue, we propose to use sophisticated image processing techniques on satellite images of the land to determine the regions that are capable of growing food crops. The solution architecture includes enhancement of satellite imagery using sophisticated pan sharpening techniques, notably the Brovey transformation, aiming to transform dull satellite images into sharper versions, thereby improving the overall quality and interpretability of the visual data. Making use of the weather data on the location observed and taking into factors like the soil moisture, weather, humidity, wind, sunlight times and so on, this data is fed into a generative pre-trained transformer model which makes use of it and gives a set of crops that are suitable to be grown on this piece of land under the said conditions. The results obtained by the proposed fusion approach is compared with the dataset provided by the government for different states in India and the performance was measured. We achieved an accuracy of 80% considering the crop suggested by our model and the predominant crop of the region. Also, the classification report detailing the performance of the proposed model is presented.","2024-07-15","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","1","14","","","","","","","","","","English","","","","WOS:001270858800004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Crop recommendation; Crop suitability; Fertile land discovery; GIS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"URP8FPWH","journalArticle","2023","Wang, ZZ; Wang, J; Zhang, HR; Yan, C; Wang, XK; Wen, X","Mstnet: method for glaucoma grading based on multimodal feature fusion of spatial relations","PHYSICS IN MEDICINE AND BIOLOGY","","0031-9155","10.1088/1361-6560/ad0520","","Objective. The objective of this study is to develop an efficient multimodal learning framework for the classification of glaucoma. Glaucoma is a group of eye diseases that can result in vision loss and blindness, often due to delayed detection and treatment. Fundus images and optical coherence tomography (OCT) images have proven valuable for the diagnosis and management of glaucoma. However, current models that combine features from both modalities often lack efficient spatial relationship modeling. Approach. In this study, we propose an innovative approach to address the classification of glaucoma. We focus on leveraging the features of OCT volumes and harness the capabilities of transformer models to capture long-range spatial relationships. To achieve this, we introduce a 3D transformer model to extract features from OCT volumes, enhancing the model's effectiveness. Additionally, we employ downsampling techniques to enhance model efficiency. We then utilize the spatial feature relationships between OCT volumes and fundus images to fuse the features extracted from both sources. Main results. Our proposed framework has yielded remarkable results, particularly in terms of glaucoma grading performance. We conducted our experiments using the GAMMA dataset, and our approach outperformed traditional feature fusion methods. By effectively modeling spatial relationships and combining OCT volume and fundus map features, our framework achieved outstanding classification results. Significance. This research is of significant importance in the field of glaucoma diagnosis and management. Efficient and accurate glaucoma classification is essential for timely intervention and prevention of vision loss. Our proposed approach, which integrates 3D transformer models, offers a novel way to extract and fuse features from OCT volumes and fundus images, ultimately enhancing the effectiveness of glaucoma classification. This work has the potential to contribute to improved patient care, particularly in the early detection and treatment of glaucoma, thereby reducing the risk of vision impairment and blindness.","2023-12-21","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","24","68","","","","","","","","","","English","","","","WOS:001117875000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","3D transformer; ANGLE GLAUCOMA; fundus map; glaucoma; multimodal fusion; OCT; OPTICAL COHERENCE TOMOGRAPHY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NZ7R64WR","journalArticle","2025","Duong, QA; Tran, SD; Gahm, JK","Multimodal surface-based transformer model for early diagnosis of Alzheimer's disease","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-025-90115-y","","Current deep learning methods for diagnosing Alzheimer's disease (AD) typically rely on analyzing all or parts of high-resolution 3D volumetric features, which demand expensive computational resources and powerful GPUs, particularly when using multimodal data. In contrast, lightweight cortical surface representations offer a more efficient approach for quantifying AD-related changes across different cortical regions, such as alterations in cortical structures, impaired glucose metabolism, and the deposition of pathological biomarkers like amyloid-\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\beta$$\end{document} and tau. Despite these advantages, few studies have focused on diagnosing AD using multimodal surface-based data. This study pioneers a novel method that leverages multimodal, lightweight cortical surface features extracted from MRI and PET scans, providing an alternative to computationally intensive 3D volumetric features. Our model employs a middle-fusion approach with a cross-attention mechanism to efficiently integrate features from different modalities. Experimental evaluations on the ADNI series dataset, using T1-weighted MRI and \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$[<^>{18}\text {F}]$$\end{document}Fluorodeoxyglucose PET, demonstrate that the proposed model outperforms volume-based methods in both early AD diagnosis accuracy and computational efficiency. The effectiveness of our model is further validated with the combination of T1-weighted MRI, A\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\beta$$\end{document} PET, and Tau PET scans, yielding favorable results. Our findings highlight the potential of surface-based transformer models as a superior alternative to conventional volume-based approaches.","2025-02-17","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","1","15","","","","","","","","","","English","","","","WOS:001424402700014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Alzheimer's disease; Attention model; Cortical surface; MRI; Multimodal; PET; REGISTRATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VI2MXQ9F","journalArticle","2025","Tampu, IE; Bianchessi, T; Blystad, I; Lundberg, P; Nyman, P; Eklund, A; Haj-Hosseini, N","Pediatric brain tumor classification using deep learning on MR images with age fusion","NEURO-ONCOLOGY ADVANCES","","2632-2498","10.1093/noajnl/vdae205","","Purpose To implement and evaluate deep learning-based methods for the classification of pediatric brain tumors (PBT) in magnetic resonance (MR) data.Methods A subset of the ""Children's Brain Tumor Network"" dataset was retrospectively used (n = 178 subjects, female = 72, male = 102, NA = 4, age range [0.01, 36.49] years) with tumor types being low-grade astrocytoma (n = 84), ependymoma (n = 32), and medulloblastoma (n = 62). T1w post-contrast (n = 94 subjects), T2w (n = 160 subjects), and apparent diffusion coefficient (ADC: n = 66 subjects) MR sequences were used separately. Two deep learning models were trained on transversal slices showing tumor. Joint fusion was implemented to combine image and age data, and 2 pre-training paradigms were utilized. Model explainability was investigated using gradient-weighted class-activation mapping (Grad-CAM), and the learned feature space was visualized using principal component analysis (PCA).Results The highest tumor-type classification performance was achieved when using a vision transformer model pre-trained on ImageNet and fine-tuned on ADC images with age fusion (Matthews correlation coefficient [MCC]: 0.77 +/- 0.14, Accuracy: 0.87 +/- 0.08), followed by models trained on T2w (MCC: 0.58 +/- 0.11, Accuracy: 0.73 +/- 0.08) and T1w post-contrast (MCC: 0.41 +/- 0.11, Accuracy: 0.62 +/- 0.08) data. Age fusion marginally improved the model's performance. Both model architectures performed similarly across the experiments, with no differences between the pre-training strategies. Grad-CAMs showed that the models' attention focused on the brain region. PCA of the feature space showed greater separation of the tumor-type clusters when using contrastive pre-training.Conclusion Classification of PBT on MR images could be accomplished using deep learning, with the top-performing model being trained on ADC data, which radiologists use for the clinical classification of these tumors.","2025-01-06","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","1","7","","","","","","","","","","English","","","","WOS:001390014100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","age; CHILDREN; data fusion; deep learning; MRI; pediatric brain tumor","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J5P6N6T6","journalArticle","2024","Wei, MM; Fang, GS; Nikitas, N; Ge, YJ","Machine-learning-based tropical cyclone wind field model incorporating multiple meteorological parameters","JOURNAL OF WIND ENGINEERING AND INDUSTRIAL AERODYNAMICS","","0167-6105","10.1016/j.jweia.2024.105936","","Multiple hazards caused by tropical cyclones (TCs), such as heavy rains and strong winds, result in substantial property losses and casualties worldwide each year. TC wind field models, describing the development of the wind hazard, are key within early warning realizations and associated risk assessments. Different to conventional parametric, analytical or meteorological numerical models, this study aims to develop a machine-learning-based approach for modeling TC wind fields by incorporating multiple meteorological parameters. The wind field model considers linear and nonlinear modeling respectively, where the input data includes various meteorological parameters such as surface pressure gradient (SPG), geopotential (GEO), boundary layer height (BLH), and forecast surface roughness (FSR). The output data is the TC wind field data of the Regional and Mesoscale Meteorology Branch (RAMMB) extracted by image recognition method, and assimilated with the wind field from the fifth generation of the European Center for Medium-Range Weather Forecasts (ECMWF) atmospheric reanalysis dataset ERA5. In the linear model, various combinations of parameters are considered, yet always yielding unsatisfactory results. The best results in the linear model were obtained using all four parameter combinations, where the root mean square error (RMSE) was 2.60 m/s and the coefficient of determination R2 value was 0.44. To increase performance, three nonlinear machine learning methods-Fully Connected Deep Neural Networks (FC-DNN), Convolutional Neural Networks (CNN), and Transformer-are introduced to the training process. Comparing the wind field continuity, RMSE and R2 between the three models, it is found that the Transformer outperforms all other models, with R2 value of 0.877 and an RMSE of 2.23. As a final step, the trained Transformer model was used to predict the evolution of wind speed of the Typhoon Lekima (1909), in what could serve as effective model validation.","2024-12","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","255","","","","","","","","","","English","","","","WOS:001351089300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","BOUNDARY-LAYER; Machine learning; Multiple meteorological parameters; PRESSURE; REGRESSION; SIMULATION; SYSTEM; Tropical cyclone; Wind data assimilation; Wind field model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5G9PUSNC","journalArticle","2024","Huang, WQ; Feng, L; He, YL","LTPLN: Automatic pavement distress detection","PLOS ONE","","1932-6203","10.1371/journal.pone.0309172","","Automatic pavement disease detection aims to address the inefficiency in practical detection. However, traditional methods heavily rely on low-level image analysis, handcrafted features, and classical classifiers, leading to limited effectiveness and poor generalization in complex scenarios. Although significant progress has been made with deep learning methods, challenges persist in handling high-resolution images and diverse disease types. Therefore, this paper proposes a novel approach based on the lightweight Transformer Patch Labeling Network (LTPLN) to enhance the efficiency of automatic pavement disease detection and overcome the limitations of existing methods. Firstly, the input images undergo histogram equalization preprocessing to enhance image quality. Subsequently, the images are evenly partitioned into small patch blocks, serving as inputs to the enhanced Transformer model. This enhancement strategy involves integrating feature map labels at each layer of the model to reduce computational complexity and enhance model lightweightness. Furthermore, a depthwise separable convolution module is introduced into the Transformer architecture to introduce convolutional bias and reduce the model's dependence on large amounts of data. Finally, an iterative training process utilizing the label distillation strategy based on expectation maximization is employed to update the labels of patch blocks and roughly locate the positions of pavement diseases under weak supervision. Experimental results demonstrate that compared to the baseline model, the proposed enhanced model achieves a reduction of 2.5G Flops computational complexity and a 16% speed improvement on a private pavement disease dataset, with only a 1.2 percentage point decrease in AUC accuracy. Moreover, compared to other mainstream image classification models, this model exhibits more balanced performance on a public dataset, with improved accuracy and speed that better align with the practical requirements of pavement inspection. These findings highlight the significant performance advantages of the LTPLN model in automatic pavement disease detection tasks, making it more efficiently applicable in real-world scenarios.","2024-10-10","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","10","19","","","","","","","","","","English","","","","WOS:001336875300007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","COMPUTER VISION; CRACK DETECTION; NETWORKS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NG7YA9U2","journalArticle","2024","Baruah, H; Singh, SR; Sarmah, P","Transliteration Characteristics in Romanized Assamese Language Social Media Text and Machine Transliteration","ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING","","2375-4699","10.1145/3639565","","This article aims to understand different transliteration behaviors of Romanized Assamese text on social media. Assamese, a language that belongs to the Indo-Aryan language family, is also among the 22 scheduled languages in India. With the increasing popularity of social media in India and also the common use of the EnglishQwerty keyboard, Indian users on socialmedia express themselves in their native languages, but using the Roman/Latin script. Unlike some other popular South Asian languages (say Pinyin for Chinese), Indian languages do not have a common standard romanization convention for writing on social media platforms. Assamese and English are two very different orthographical languages. Thus, considering both orthographic and phonemic characteristics of the language, this study tries to explain how Assamese vowels, vowel diacritics, and consonants are represented in Roman transliterated form. From a dataset of romanized Assamese social media texts collected from three popular social media sites: (Facebook, YouTube, and X (formerly known as Twitter)),1 we have manually labeled them with their native Assamese script. A comparison analysis is also carried out between the transliterated Assamese social media texts with six different Assamese romanization schemes that reflect how Assamese users on social media do not adhere to any fixed romanization scheme. We have built three separate character-level transliteration models from our dataset. One using a traditional phrase-based statistical machine transliteration model, (1) PBSMT model and two separate neural transliteration models, (2) BiLSTM neural seq2seq model with attention, and (3) Neural transformer model. A thorough error analysis has been performed on the transliteration result obtained from the three state-of-the-art models mentioned above. This may help to build a more robust machine transliteration system for the Assamese social media domain in the future. Finally, an attention analysis experiment is also carried out with the help of attention weight scores taken from the character-level BiLSTM neural seq2seq transliteration model built from our dataset.","2024-02","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","2","23","","","","","","","","","","English","","","","WOS:001193524700015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","attention; BiLSTM; grapheme; PBSMT; phoneme; transformer; Transliteration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6UNSTT4B","journalArticle","2024","Sun, YZ; Zhang, JH; Zhang, YG","Base on temporal convolution and spatial convolution transformer for fluid prediction through well logging data","PHYSICS OF FLUIDS","","1070-6631","10.1063/5.0188850","","Fluid prediction is important in exploration work, helping to determine the location of exploration targets and the reserve potential of the estimated area. Machine learning methods can better adapt to different data distributions and nonlinear relationships through model training, resulting in better learning of these complex relationships. We started by using the convolution operation to process the log data, which includes temporal convolution and spatial convolution. Temporal convolution is specifically designed to capture time series relationships in time series data. In well log data, time information is often critical for understanding fluid changes and other important details. Temporal convolution learns trends and cyclical changes in the data. The spatial convolution operation makes the model more sensitive to the local features in the logging data through the design of the local receptive field and improves the sensitivity to fluid changes. Spatial convolution helps capture spatial correlations at different depths or locations. This can help the model understand the change of fluid in the vertical direction and identify the spatial relationship between different fluids. Then, we use the transformer module to predict the fluid. The transformer module uses a self-attention mechanism that allows the model to focus on information with different weights at different locations in the sequence. In the well log data, this helps the model to better capture the formation characteristics at different depths or time points and improves the modeling ability of time series information. The fully connected structure in the transformer module enables each position to interact directly with other locations in the sequence. By applying it to the data of Tarim Oilfield, the experimental results show that the convolutional transformer model proposed in this paper has better results than other machine learning models. This study provides a new idea in the field of logging fluid prediction.","2024-02","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","2","36","","","","","","","","","","English","","","","WOS:001157930600017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","LITHOLOGY IDENTIFICATION; MODEL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZNU5A9ZJ","journalArticle","2024","Tang, YX; Liu, ZJ","A Credit Card Fraud Detection Algorithm Based on SDT and Federated Learning","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3491175","","With the rise of digital payment methods and the growth in financial transactions, the issue of credit card fraud has become increasingly severe. Traditional fraud detection methods are currently facing challenges such as poor model performance, difficulty in obtaining accurate results, and limitations in distributed deployment. These challenges stem from constantly evolving fraud strategies, higher volumes of transactions, and the complexity of the financial environment. This study proposes a credit card fraud detection algorithm based on Structured Data Transformer (SDT) and federated learning, which leverages the advanced capabilities of the Transformer model in deep learning. First, we organize credit card data into sequences and introduce a special, learnable token at the beginning of each sequence for classification purposes. Thanks to the attention mechanism of the Transformer, the model can automatically highlight important features in the data, significantly improving the accuracy of fraud detection. Second, addressing the complex financial environment and concerns about financial data privacy, we introduce a federated learning architecture to deploy the SDT model across different banks in a distributed manner. Momentum updates are used for model parameter updates during training, which enhance model performance and ensure data privacy between banks. Lastly, we conducted experimental validation on two financial datasets of different scales. The results on Dataset 1 and Dataset 2 show that our proposed SDT model surpasses traditional detection methods in terms of AUC-PR values (0.882, 0.816) and AUC-ROC values (0.982, 0.994). By integrating federated learning and deploying and testing the two datasets in a distributed environment, the AUC-PR values (0.884, 0.892) and AUC-ROC values (0.963, 0.998) can be further improved.","2024","2025-02-26 20:43:31","2025-02-26 20:43:31","","182547-182560","","","12","","","","","","","","","","English","","","","WOS:001375816400042","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Accuracy; Adaptation models; Attention mechanisms; Credit cards; Data models; deep learning; Distributed databases; Feature extraction; federated learning; Federated learning; Fraud; fraud detection; Predictive models; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"39PWW8VC","journalArticle","2023","Gilany, M; Wilson, P; Perera-Ortega, A; Jamzad, A; To, MNN; Fooladgar, F; Wodlinger, B; Abolmaesumi, P; Mousavi, P","TRUSformer: improving prostate cancer detection from micro-ultrasound using attention and self-supervision","INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY","","1861-6410","10.1007/s11548-023-02949-4","","Purpose A large body of previous machine learning methods for ultrasound-based prostate cancer detection classify small regions of interest (ROIs) of ultrasound signals that lie within a larger needle trace corresponding to a prostate tissue biopsy (called biopsy core). These ROI-scale models suffer from weak labeling as histopathology results available for biopsy cores only approximate the distribution of cancer in the ROIs. ROI-scale models do not take advantage of contextual information that are normally considered by pathologists, i.e., they do not consider information about surrounding tissue and larger-scale trends when identifying cancer. We aim to improve cancer detection by taking a multi-scale, i.e., ROI-scale and biopsy core-scale, approach.Methods Our multi-scale approach combines (i) an ""ROI-scale"" model trained using self-supervised learning to extract features from small ROIs and (ii) a ""core-scale"" transformer model that processes a collection of extracted features from multiple ROIs in the needle trace region to predict the tissue type of the corresponding core. Attention maps, as a by-product, allow us to localize cancer at the ROI scale.Results We analyze this method using a dataset of micro-ultrasound acquired from 578 patients who underwent prostate biopsy, and compare our model to baseline models and other large-scale studies in the literature. Our model shows consistent and substantial performance improvements compared to ROI-scale-only models. It achieves 80.3% AUROC, a statistically significant improvement over ROI-scale classification. We also compare our method to large studies on prostate cancer detection, using other imaging modalities.Conclusions Taking a multi-scale approach that leverages contextual information improves prostate cancer detection compared to ROI-scale-only models. The proposed model achieves a statistically significant improvement in performance and outperforms other large-scale studies in the literature. Our code is publicly available at www.github.com/med-i-lab/ TRUSFormer.","2023-07","2025-02-26 20:43:31","2025-02-26 20:43:31","","1193-1200","","7","18","","","","","","","","","","English","","","","WOS:000993658000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","BIOPSY; ELASTOGRAPHY; Micro-ultrasound; Prostate cancer; Self-attention; Self-supervised learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9YK89N8L","journalArticle","2022","Kuriyama, S; Mukai, T; Taketomi, T; Mukasa, T","Context-based style transfer of tokenized gestures","COMPUTER GRAPHICS FORUM","","0167-7055","10.1111/cgf.14645","","Gestural animations in the amusement or entertainment field often require rich expressions; however, it is still challenging to synthesize characteristic gestures automatically. Although style transfer based on a neural network model is a potential solution, existing methods mainly focus on cyclic motions such as gaits and require re-training in adding new motion styles. Moreover, their per-pose transformation cannot consider the time-dependent features, and therefore motion styles of different periods and timings are difficult to be transferred. This limitation is fatal for the gestural motions requiring complicated time alignment due to the variety of exaggerated or intentionally performed behaviors. This study introduces a context-based style transfer of gestural motions with neural networks to ensure stable conversion even for exaggerated, dynamically complicated gestures. We present a model based on a vision transformer for transferring gestures' content and style features by time-segmenting them to compose tokens in a latent space. We extend this model to yield the probability of swapping gestures' tokens for style-transferring. A transformer model is suited to semantically consistent matching among gesture tokens, owing to the correlation with spoken words. The compact architecture of our network model requires only a small number of parameters and computational costs, which is suitable for real-time applications with an ordinary device. We introduce loss functions provided by the restoration error of identically and cyclically transferred gesture tokens and the similarity losses of content and style evaluated by splicing features inside the transformer. This design of losses allows unsupervised and zero-shot learning, by which the scalability for motion data is obtained. We comparatively evaluated our style transfer method, mainly focusing on expressive gestures using our dataset captured for various scenarios and styles by introducing new error metrics tailored for gestures. Our experiment showed the superiority of our method in numerical accuracy and stability of style transfer against the existing methods.","2022-12","2025-02-26 20:43:31","2025-02-26 20:43:31","","305-315","","8","41","","","","","","","","","","English","","","","WOS:001047605100029","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4U86NIQC","journalArticle","2022","Wang, HX; Xiao, N; Zhang, JN; Yang, WT; Ma, YL; Suo, Y; Zhao, JJ; Qiang, Y; Lian, JH; Yang, QQ","Static-Dynamic coordinated Transformer for Tumor Longitudinal Growth Prediction","COMPUTERS IN BIOLOGY AND MEDICINE","","0010-4825","10.1016/j.compbiomed.2022.105922","","Accurate prediction of the tumor's future imaging features can provide its complete growth evolution and more detailed clinical parameters. The existing longitudinal models tend to lose detailed growth information and make it difficult to model the complete tumor development process. In this paper, we propose the Static- Dynamic coordinated Transformer for Tumor Longitudinal Growth Prediction (SDC-Transformer). To extract the static high-level features of tumors in each period, and to further explore the dynamic growth associations and expansion trend of tumors between different periods. Aiming at the insensitivity to local pixel information of the Transformer, we propose the Local Adaptive Transformer Module to facilitate a strongly coupled status of feature images, which ensures the characterization of tumor complex growth trends. Faced with the dynamic changes brought about by tumor growth, we introduce the Dynamic Growth Estimation Module to predict the future growth trend of the tumor. As a core part of SDC-Transformer, we design the Enhanced Deformable Convolution to enrich the sampling space of tumor growth pixels. And a novel Cascade Self -Attention is performed under multi-growth imaging to obtain dynamic growth relationships between periods and use dual cascade operations to predict the tumor's future expansion trajectories and growth contours. Our SDC-Transformer is rigorously trained and tested on longitudinal tumor data composed of the National Lung Screening Trial (NLST) and collaborative Shanxi Provincial People's Hospital. The RMSE, Dice, Recall, and Specificity of the longitudinal prediction results reach 11.32, 89.31%, 90.57%, and 89.64%, respectively. This result shows that our proposed SDC-Transformer model can achieve accurate longitudinal prediction of tumors, which will help physicians to establish specific treatment plans and accurately diagnose lung cancer. The code will be released soon.","2022-09","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","148","","","","","","","","","","English","","","","WOS:000862696000007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","Dynamic growth; IMAGES; MODEL; NETWORKS; REACTION-DIFFUSION; Static imaging information; Transformer; Tumor longitudinal prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VEE2QHT5","journalArticle","2025","Lv, ZL; Zhao, JY","Resource-efficient artificial intelligence for battery capacity estimation using convolutional FlashAttention fusion networks","ETRANSPORTATION","","2590-1168","10.1016/j.etran.2024.100383","","Accurate battery capacity estimation is crucial for optimizing lifespan and monitoring health conditions. Deep learning has made notable strides in addressing long-standing issues in the artificial intelligence community. However, large AI models often face challenges such as high computational resource consumption, extended training times, and elevated deployment costs. To address these issues, we developed an efficient end-to-end hybrid fusion neural network model. This model combines FlashAttention-2 with local feature extraction through convolutional neural networks (CNNs), significantly reducing memory usage and computational demands while maintaining precise and efficient health estimation. For practical implementation, the model uses only basic parameters, such as voltage and charge, and employs partial charging data (from 80 % SOC to the upper limit voltage) as features, without requiring complex feature engineering. We evaluated the model using three datasets: 77 lithium iron phosphate (LFP) cells, 16 nickel cobalt aluminum (NCA) cells, and 50 nickel cobalt manganese (NCM) oxide cells. For LFP battery health estimation, the model achieved a root mean square error of 0.109 %, a coefficient of determination of 0.99, and a mean absolute percentage error of 0.096 %. Moreover, the proposed convolutional and flash-attention fusion networks deliver an average inference time of 57 milliseconds for health diagnosis across the full battery life cycle (approximately 1898 cycles per cell). The resource-efficient AI (REAI) model operates at an average of 1.36 billion floating point operations per second (FLOPs), with GPU power consumption of 17W and memory usage of 403 MB. This significantly outperforms the Transformer model with vanilla attention. Furthermore, the multi-fusion model proved to be a powerful tool for evaluating capacity in NCA and NCM cells using transfer learning. The results emphasize its ability to reduce computational complexity, energy consumption, and memory usage, while maintaining high accuracy and robust generalization capabilities.","2025-01","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","23","","","","","","","","","","English","","","","WOS:001367057700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","Batteries; Capacity; Convolutional neural networks; Deep learning; Flash-attention; Health; HEALTH; LITHIUM-ION BATTERY; MODEL; NEURAL-NETWORK; PREDICTION; STATE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QLUCJI4A","journalArticle","2024","Kumar, KN; Roy, D; Suman, TA; Vishnu, C; Mohan, CK","TSANet: Forecasting traffic congestion patterns from aerial videos using graphs and transformers","PATTERN RECOGNITION","","0031-3203","10.1016/j.patcog.2024.110721","","Forecasting traffic congestion patterns in lane-less traffic scenarios is a complex task because of the combination of high & irregular vehicle densities, fluctuating speeds, and the presence of environmental obstacles. Existing techniques like vehicle counting and density prediction, which successfully estimate congestion in lane-based traffic, are unsuitable for lane-less traffic scenarios due to the irregular and unpredictable nature of traffic density patterns. To overcome these challenges, we propose traffic states to measure congestion patterns in lane-less traffic scenarios. Each traffic state is characterized by the spatio-temporal distribution of neighbouring road users, including vehicles and motorcyclists. We employ traffic graphs to capture the spatial distribution of neighbouring road users. Also, we propose a novel method for the automated construction of traffic graphs by leveraging the detection and tracking of individual road users in aerial videos. Further, in order to incorporate the temporal distribution, we utilize a transformer model to capture the evolution of spatial traffic graphs over time. This enables us to forecast future spatio-temporal distributions and their associated traffic states. Our proposed model, named Traffic State Anticipation Network (TSANet), can effectively forecast future traffic states by analysing sequences of current traffic graphs, thereby enhancing our understanding of evolving traffic patterns in lane-less scenarios. Also, to address the lack of publicly available lane-less traffic datasets, we introduce EyeonTraffic (EoT), a large-scale lane-less traffic dataset containing three hours of aerial videos captured at three busy intersections in Ahmedabad city, India. Experimental results on the EoT dataset demonstrate the efficacy of our proposed TSANet in effectively anticipating traffic states across diverse spatial regions within an intersection. In addition, we also show that TSANet generalizes well for previously unseen intersections, making it suitable for analysing various traffic scenarios without the need for explicit training, thereby enhancing its practical applicability.","2024-11","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","155","","","","","","","","","","English","","","","WOS:001266020200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Sequence estimation; Sequence modelling; Spatio-temporal graphs; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9RFTJE28","journalArticle","2023","Liu, XW; Hu, YK; Chen, JG","Hybrid CNN-Transformer model for medical image segmentation with pyramid convolution and multi-layer perceptron","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2023.105331","","Vision Transformer (ViT) has emerged as a potential alternative to convolutional neural networks for large datasets. However, applying ViT directly to medical image segmentation is challenging due to its lack of induction bias, which requires a large number of high-quality annotated medical images for effective model training. Recent studies have discovered that, in addition to the increased model capacity and generalization resulting from the lack of induction bias, the excellent performance of Transformer can also be attributed to its large receptive field. In this paper, we propose a U-shaped medical image segmentation model that combines large kernel convolutions with Transformers. Specifically, we construct a basic Transformer unit using pyramidal convolution modules with multi-scale kernels and multi-layer perceptron. In the pyramid convolution module, we employ grouped convolution to reduce parameter and computational complexity while utilizing multi-scale large kernel attention as a foundation for more efficient feature extraction. For different types of grouping, different sizes of convolutions are used to enhance the extraction of features with multiple receptive fields. To optimize the extracted features from the encoder, the U-shaped model integrates a variant of the pyramidal convolutional module into the skip connections. This variant utilizes multi-scale large kernel convolutional attention based on channel splitting. The incorporation of this variant enables efficient refinement of the feature representations within the skip connections. Through extensive comparisons on multi-modal medical image datasets, our model outperforms state-of-the-art methods across various evaluation metrics, with notable superiority observed on small-scale medical datasets. Our research findings suggest that the combination of large kernel convolutions and Transformer models introduces an advantageous inductive bias, resulting in enhanced performance specifically for small-scale medical image datasets. To facilitate accessibility, we have made our code openly accessible on our GitHub repository, which can be found at https://github.com/medical-images-process/CNN-Transformer.","2023-09","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","86","","","","","","","","","","English","","","","WOS:001061617400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","CNNs; Large kernel attention; Medical image segmentation; NETWORK; Transformers; U-NET","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XWH2H6BB","journalArticle","2025","Yan, XY; Zhang, XF; Xia, SX","Multi-View topology assisted dynamic graph learning for fMRI-based Alzheimer's disease identification","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2024.129025","","Resting-state functional magnetic resonance imaging (rs-fMRI) provides a non-invasive technology that helps identify abnormal connections in the brain by tracking changes in blood flow components. Functional connectivity networks (FCNs) derived from fMRI data are commonly used for identifying brain disorders such as Alzheimer's disease (AD). Unfortunately, most existing AD identification models rely solely on static single-view FCN (e.g., Pearson correlation, PC), neglecting the temporal information and complex topological structures present in fMRI data. Additionally, the imbalance of training data significantly hampers the generalization ability of the model. To this end, we propose a multi-view topology assisted dynamic graph learning (MTDGL) framework for fMRI analysis and AD automated identification, with a three-pipeline fMRI feature extraction structure composed of a spatiotemporal branch, a topological branch and a raw information branch. At the outset, we adopt a category balancing strategy for the training data to enhance the representation ability of the model. In the spatiotemporal branch, we employ a spatiotemporal attention graph isomorphism network (STAGIN) to capture latent dynamic representations in fMRI data. In the topological branch, we integrate topological information extracted from multiple views (i.e., PC, mutual information, MI). In the raw information branch, we extract the fine-grained information in the raw signal and adaptively fuse them with the dynamic representations for the final AD classification task. This can overcome the limitations of single- view methods in describing topological structures. In the feature fusion stage, the relevant features are first integrated, and then the original signal features are merged into these integrated relevant features through the Transformer model to achieve deep fusion between the two main information streams. The experimental results on the ADNI dataset demonstrate that the proposed MTDGL achieves an accuracy of 92.43% in AD recognition, outperforming several state-of-the-art approaches.","2025-02-14","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","618","","","","","","","","","","English","","","","WOS:001387858200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Disease identification; FUNCTIONAL CONNECTIVITY; Functional MRI; Graph neural network; Topological features","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y5KTU7Y6","journalArticle","2024","Glazkova, AV; Morozov, DA; Vorobeva, MS; Stupnikov, AA","Keyword Generation for Russian-Language Scientific Texts Using the mT5 Model","AUTOMATIC CONTROL AND COMPUTER SCIENCES","","0146-4116","10.3103/S014641162470041X","","The authors propose an approach to generate keywords for Russian-language scientific texts using the mT5 (multilingual text-to-text transformer) model, fine-tuned on the Keyphrases CS&Math Russian text corpus. Automatic keyword selection is an urgent task in natural language processing, since keywords help readers search for articles and facilitate the systematization of scientific texts. In this paper, the task of selecting keywords is considered as a task of automatic text abstracting. Additional training of mT5 is carried out on the texts of abstracts of Russian-language scientific articles. The input and output data are abstracts and comma-separated lists of keywords, respectively. The results obtained using mT5 are compared with the results of several basic methods: TopicRank, YAKE!, RuTermExtract, and KeyBERT. The following metrics are used to present the results: F-measure, ROUGE-1, and BERTScore. The best results on the test sample are obtained using mT5 and RuTermExtract. The highest F-measure is demonstrated by the mT5 model (11.24%), surpassing RuTermExtract by 0.22%. RuTermExtract shows the best result according to the ROUGE-1 metric (15.12%). The best results for BERTScore are also achieved by these two methods: mT5, 76.89% (BERTScore using the mBERT model); RuTermExtract, 75.8% (BERTScore based on ruSciBERT). The authors also assess the ability of mT5 to generate keywords that are not in the source text. The limitations of the proposed approach include the need to form a training sample for additional model training and probably the limited applicability of the additional trained model for texts in other subject areas. The advantages of keyword generation using mT5 are the absence of the need to set fixed values for the length and number of keywords, the need for normalization, which is especially important for inflected languages, and the ability to generate keywords that are not explicitly present in the text.","2024-12","2025-02-26 20:43:31","2025-02-26 20:43:31","","995-1002","","7","58","","","","","","","","","","English","","","","WOS:001421219900007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","automatic abstracting; EXTRACTION; keyword selection; mT5","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G2FKWGTM","journalArticle","2024","Pemmaraju, R; Kim, G; Mekki, LN; Song, DY; Lee, JH","Cascaded cross-attention transformers and convolutional neural networks for multi-organ segmentation in male pelvic computed tomography","JOURNAL OF MEDICAL IMAGING","","2329-4302","10.1117/1.JMI.11.2.024009","","Purpose Segmentation of the prostate and surrounding organs at risk from computed tomography is required for radiation therapy treatment planning. We propose an automatic two-step deep learning-based segmentation pipeline that consists of an initial multi-organ segmentation network for organ localization followed by organ-specific fine segmentation. Approach Initial segmentation of all target organs is performed using a hybrid convolutional-transformer model, axial cross-attention UNet. The output from this model allows for region of interest computation and is used to crop tightly around individual organs for organ-specific fine segmentation. Information from this network is also propagated to the fine segmentation stage through an image enhancement module, highlighting regions of interest in the original image that might be difficult to segment. Organ-specific fine segmentation is performed on these cropped and enhanced images to produce the final output segmentation. Results We apply the proposed approach to segment the prostate, bladder, rectum, seminal vesicles, and femoral heads from male pelvic computed tomography (CT). When tested on a held-out test set of 30 images, our two-step pipeline outperformed other deep learning-based multi-organ segmentation algorithms, achieving average dice similarity coefficient (DSC) of 0.836 +/- 0.071 (prostate), 0.947 +/- 0.038 (bladder), 0.828 +/- 0.057 (rectum), 0.724 +/- 0.101 (seminal vesicles), and 0.933 +/- 0.020 (femoral heads). Conclusions Our results demonstrate that a two-step segmentation pipeline with initial multi-organ segmentation and additional fine segmentation can delineate male pelvic CT organs well. The utility of this additional layer of fine segmentation is most noticeable in challenging cases, as our two-step pipeline produces noticeably more accurate and less erroneous results compared to other state-of-the-art methods on such images.","2024-03-01","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","2","11","","","","","","","","","","English","","","","WOS:001295175600016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","AUTOMATIC SEGMENTATION; convolutional neural networks; deep learning; image segmentation; INTEROBSERVER VARIABILITY; PROSTATE; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FC4FPPUH","journalArticle","2024","Ding, ZG; Fu, FC; Zheng, JS; Yang, HY; Zou, FM; Linghua, K","Intelligent Wood Inspection Approach Utilizing Enhanced Swin Transformer","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3359048","","Wood diameter needs to be measured in the process of production, sales and import and export. In order to solve the problem that it is difficult to accurately measure the densely stacked and irregularly arranged vehicle wood manually, this paper proposes a timber segmentation methodology that leverages a Swin Transformer model mechanism to enhance the performance of the target detection model. The method automatically learns and calculates distinct regions in the input image, assigning varying weights to different sizes and shapes of wood. This approach achieves finer detection of densely stacked logs, thereby promoting intelligent inspection and enhancing inspection efficiency.This study optimizes the backbone network by refining its modules and incorporating the operation of the log-space bias module. Additionally, improvements are made to the feature fusion network and loss function to further enhance network performance. The instance segmentation model parameters are also modified, encompassing multi-scale training, an increased number of training samples, improved image input size, and effective data widening techniques, all of which enhance log measurement accuracy and resolve the issue of partially occluded logs.This study conducts multiple control experiments to evaluate various scale metrics, such as mean average precision (mAP), log true detection rate, false detection rate, as well as comparing the root count and volume of logs through prediction. The experiments demonstrate that the mAP of this methodology reaches 0.685, and the true detection rate reaches 0.96 when compared with mainstream neural networks of similar scale, highlighting the advantages of this paper's approach in wood segmentation detection. The model exhibits a strong detection effect on dense wood, effectively overcoming occlusion challenges, leading to more accurate measurement data. Moreover, the algorithm demonstrates robustness and migration ability, rendering it highly applicable to the task of detecting and segmenting dense wood of all sizes.","2024","2025-02-26 20:43:31","2025-02-26 20:43:31","","16794-16804","","","12","","","","","","","","","","English","","","","WOS:001161951100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;16</p>","","","deep learning; Dense wood detection; obscured targets; Swin transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6LZCX4T8","journalArticle","2024","Lee, N; Oh, Y; Moon, J","Catching Robot: Predicting the Trajectory of a Rolling Ball Using Transformer","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3455553","","Various tasks in robotics such as pick and place and catching flying/rolling objects have been studied in the literature. Previously, to accomplish such tasks, it was necessary to detect the position of the object using a Sobel detector, a marker, or a stereo method and then predict the trajectory of the object through the model-based Kalman filter. However, these existing studies are not practical, since with this detection method, only one type of object can be detected or additional equipments are required. In addition, to compute the Kalman filter, a measurement of the object's position is essentially required, which may not be precise in various situations due to unmodeled noise. In this paper, we study the new framework of catching a rolling ball task in robotics using only machine learning techniques. Unlike previous approaches that rely on specified markers or stereo camera systems, our method uses a machine learning algorithm that can learn object positions and detect various sizes of balls using only one RGB camera without any markers. In our method, Convolutional Neural Network (CNN)-based models are applied to detect objects and the transformer model with an attention mechanism is applied for end-to-end trajectory prediction. We use the robotics simulator to efficiently train models and evaluate their performance directly in the real world. The experimental results of catching a rolling ball show that our framework is practical, and performs well in various sizes of balls. By using the proposed framework, the performance of the Gripper vicinity is 93.3% and the Catching success rate is 73.3%. In contrast, other baselines, such as CNN and long short-term memory (LSTM), show poor Gripper vicinity and success rates, with all criteria falling below 30%.","2024","2025-02-26 20:43:31","2025-02-26 20:43:31","","128551-128558","","","12","","","","","","","","","","English","","","","WOS:001316117500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","attention mechanisms; Collaborative robots; Computational modeling; Data models; image recognition; Image recognition; Manipulators; prediction algorithms; Prediction algorithms; robot learning; Trajectory; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4XE8DK4C","journalArticle","2024","Pham, TH; Li, XQ; Nguyen, KD","seUNet-Trans: A Simple Yet Effective UNet-Transformer Model for Medical Image Segmentation","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3451304","","Medical image segmentation plays a crucial role in modern clinical practice, enabling accurate diagnosis and personalized treatment plans. Advancements in machine learning, particularly deep learning techniques, have significantly driven this progress. While Convolutional Neural Networks (CNNs) dominate the field, transformer-based models are emerging as powerful alternatives for computer vision tasks. However, most existing CNN-Transformer models underutilize the full potential of Transformers, often relegating them to assistant modules. To address this issue, we propose a novel and efficient UNet-Transformer (seUNet-Trans) model for medical image segmentation. The seUNet-Trans framework leverages a UNet architecture for feature extraction, generating rich representations from input images. These features are then passed through a bridge layer that connects the UNet to a transformer module. To improve efficiency, we employ a novel pixel-wise embedding method that eliminates the need for position embedding vectors. We utilize spatially reduced attention within the transformer to reduce computational complexity. By combining the strengths of UNet's localization capabilities and the transformer's ability to capture long-range dependencies, seUNet-Trans effectively captures both local and global information within medical images. This holistic understanding enables the model to achieve superior segmentation performance. The efficacy of our model is demonstrated through extensive experimentation on seven medical image segmentation datasets. The seUNet-Trans model outperforms several state-of-the-art segmentation models, achieving impressive mean Dice Coefficient (mDC) and mean Intersection over Union (mIoU) scores. On the CVC-ClinicDB dataset, it achieves scores of 0.945 and 0.895, respectively; on the GlaS dataset, it scores 0.899 and 0.823, respectively; on the ISIC 2018 dataset, it achieves 0.922 and 0.854, respectively; and on the Data Science Bowl dataset, it scores 0.928 and 0.867, respectively. The code is available on seUnet-Trans.","2024","2025-02-26 20:43:31","2025-02-26 20:43:31","","122139-122154","","","12","","","","","","","","","","English","","","","WOS:001310756700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","ATTENTION; Biomedical imaging; colonoscopy; Colonoscopy; Computer architecture; Decoding; deep learning; Deep learning; Image segmentation; Medical diagnostic imaging; medical image analysis; Polyps; Transformers; vision transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QZMHIXTH","journalArticle","2023","Geng, MS; Li, JY; Xia, YJ; Chen, XQ","A physics-informed Transformer model for vehicle trajectory prediction on highways","TRANSPORTATION RESEARCH PART C-EMERGING TECHNOLOGIES","","0968-090X","10.1016/j.trc.2023.104272","","Autonomous Vehicles (AVs) have made remarkable developments and are anticipated to replace human drivers. In transitioning from human-driven vehicles to fully AVs, one crucial task is to predict the trajectories of the subject vehicle and its surrounding vehicles in real time. Most existing methods of vehicle trajectory prediction on highways are based on physical models or purely data-driven models. However, they either yield unsatisfactory prediction performance or lack model interpretability and physical implications. This paper proposes a Physics-Informed Deep Learning framework that fully leverages the advantages of data-driven and physics-based models to go beyond the existing models. We use the Transformer neural network architecture with self-attention as Physics-Uninformed Neural Network (PUNN) and Intelligent Driver Model (IDM) as physical model to construct of Physics-Informed Transformer-Intelligent Driver Model (PIT-IDM). Extensive experiments have been conducted on two datasets with different traffic environments, i.e., Next Generation SIMulation (NGSIM) data in the US and the Ubiquitous Traffic Eyes (UTE) data in China, to verify model accuracy and efficiency. Compared with the three kinds of baselines by relative and absolute measures of effectiveness, the best performing PIT-IDM reduces longitudinal trajectory prediction errors for long horizons by 5%-50%, some even reduced up to 70%. Extensive empirical analyses have been carried out to verify its excellent spatio-temporal transferability and explore the physics-informed mechanism underlying this deep learning method. The training and inference time analysis indicates that although it takes longer to train PIT-IDM, it requires fewer calls and accumulates fewer errors with less computation time in real-world applications. The overall results further validate the efficacy of this PhysicsInformed Deep Learning framework in enhancing model accuracy, interpretability, and transferability.","2023-09","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","154","","","","","","","","","","English","","","","WOS:001067593800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Attention mechanism; CAR-FOLLOWING MODEL; FRAMEWORK; Intelligent driver model; NETWORKS; Physics-informed deep learning; Transformer; Vehicle trajectory prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G5IPRY25","journalArticle","2023","Wang, N; Zhao, XL","Time Series Forecasting Based on Convolution Transformer","IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS","","0916-8532","10.1587/transinf.2022EDP7136","","For many fields in real life, time series forecasting is es- sential. Recent studies have shown that Transformer has certain advantages when dealing with such problems, especially when dealing with long se- quence time input and long sequence time forecasting problems. In order to improve the efficiency and local stability of Transformer, these studies combine Transformer and CNN with different structures. However, previ- ous time series forecasting network models based on Transformer cannot make full use of CNN, and they have not been used in a better combination of both. In response to this problem in time series forecasting, we propose the time series forecasting algorithm based on convolution Transformer. (1) ES attention mechanism: Combine external attention with traditional self-attention mechanism through the two-branch network, the computa- tional cost of self-attention mechanism is reduced, and the higher forecast- ing accuracy is obtained. (2) Frequency enhanced block: A Frequency Enhanced Block is added in front of the ESAttention module, which can capture important structures in time series through frequency domain map- ping. (3) Causal dilated convolution: The self-attention mechanism module is connected by replacing the traditional standard convolution layer with a causal dilated convolution layer, so that it obtains the receptive field of exponentially growth without increasing the calculation consumption. (4) Multi-layer feature fusion: The outputs of different self-attention mech- anism modules are extracted, and the convolutional layers are used to adjust the size of the feature map for the fusion. The more fine-grained feature in- formation is obtained at negligible computational cost. Experiments on real world datasets show that the time series network forecasting model struc- ture proposed in this paper can greatly improve the real-time forecasting performance of the current state-of-the-art Transformer model, and the cal- culation and memory costs are significantly lower. Compared with previ- ous algorithms, the proposed algorithm has achieved a greater performance improvement in both effectiveness and forecasting accuracy.","2023-05","2025-02-26 20:43:31","2025-02-26 20:43:31","","976-985","","5","E106D","","","","","","","","","","English","","","","WOS:000985526700044","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","CNN; time series forecasting; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"72HXF3X7","journalArticle","2023","Gan, AA; Gong, AM; Ding, P; Yuan, X; Chen, MZ; Fu, YF; Cheng, YQ","Computer-aided diagnosis of schizophrenia based on node2vec and Transformer","JOURNAL OF NEUROSCIENCE METHODS","","0165-0270","10.1016/j.jneumeth.2023.109824","","Objective: Compared with the healthy control (HC) group, the brain structure and function of schizophrenia (SZ) patients are significantly abnormal, so brain imaging methods can be used to achieve the aided diagnosis of SZ. However, a brain network based on brain imaging data is non-Euclidean, and its intrinsic features cannot be learned effectively by general deep learning models. Furthermore, in the majority of existing studies, brain network features were manually specified as the input of machine learning models.Methods: In this study, brain functional network constructed from the subject's fMRI data is analyzed, and its small-world value is calculated and t-tested; the node2vec algorithm in graph embedding is introduced to transform the constructed brain network into low-dimensional dense vectors, and the brain network's non-Euclidean spatial structure characteristics are retained to the greatest extent, so that its intrinsic features can be extracted by deep learning models; GridMask is used to randomly mask part of the information in the vectors to enhance the data; and then features can be extracted using the Transformer model to identify SZ.Results: It is again shown that the small-world value of the brain network in SZ is significantly lower than that in HC by t-test (p=0.014<0.05). 97.78% classification accuracy is achieved by the proposed methods (node2vec + GridMask + Transformer) in 30 SZ patients and 30 healthy people.Conclusion: The experiment shows that the node2vec used in this paper can effectively solve the problem of brain network features being difficult to learn by general deep learning models. The high-precision computer-aided diagnosis of SZ can be obtained by combining node2vec with Transformer and GridMask.Significance: The proposed methods in the paper are expected to be used for aided diagnosis of SZ.","2023-04-01","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","389","","","","","","","","","","English","","","","WOS:000953814500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","BRAIN NETWORKS; fMRI based brain network; FUNCTIONAL CONNECTIVITY; GridMask; node2vec; Schizophrenia; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XYQW84MJ","journalArticle","2024","Abdul, A; Chen, BH; Phani, S; Chen, JH","Improving preliminary clinical diagnosis accuracy through knowledge filtering techniques in consultation dialogues","COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE","","0169-2607","10.1016/j.cmpb.2024.108051","","\Background and Objective: Symptom descriptions by ordinary people are often inaccurate or vague when seeking medical advice, which often leads to inaccurate preliminary clinical diagnoses. To address this issue, we propose a deep learning model named the knowledgeable diagnostic transformer (KDT) for the natural language processing (NLP)-based preliminary clinical diagnoses. Methods: The KDT extracts symptom-disease relation triples (h, r, t) from patient symptom descriptions by using a proposed bipartite medical knowledge graph (bMKG). To avoid too many relation triples causing the knowledge noise issue, we propose a knowledge inclusion-exclusion approach (KIA) to eliminate undesirable triples (a knowledge filtering layer). Next, we combine token embedding techniques with the transformer model to predict the diseases that patients may encounter. Results: To train the KDT, a medical diagnosis question-answering dataset (named MDQA dataset) containing large-scale, high-quality questions (patient syndrome description) and answering (diagnosis) corpora with 2.6M entries (1.07GB in size) in Mandarin was built. We also train the KDT with the National Institutes of Health (NIH) English dataset (MedQuAD). The KDT marks a transformative approach by achieving a remarkable accuracy of 99% for different evaluation metrics when compared with the baseline transformers used for the NLP-based preliminary clinical diagnoses approaches. Conclusions: In essence, our study not only demonstrates the effectiveness of the KDT in enhancing diagnostic precision but also underscores its potential to revolutionize the field of preliminary clinical diagnoses. By harnessing the power of knowledge-based approaches and advanced NLP techniques, we have paved the way for more accurate and reliable diagnoses, ultimately benefiting both healthcare providers and patients. The KDT has the potential to significantly reduce misdiagnoses and improve patient outcomes, marking a pivotal advancement in the realm of medical diagnostics.","2024-04","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","246","","","","","","","","","","English","","","","WOS:001175586000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Disease; Knowledge graph; Natural language processing; NATURAL-LANGUAGE GENERATION; Patient syndrome; Preliminary clinical diagnosis; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EVNTLDU9","journalArticle","2024","Çetiner, G; Yayan, U; Yazici, A","Mutation-Based White Box Testing of Deep Neural Networks","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3482114","","Deep Neural Networks (DNNs) are used in many critical areas, such as autonomous vehicles, generative AI systems, etc. Therefore, testing DNNs is vital, especially for models used in critical areas. Mutation-based testing is a very successful technique for testing DNNs by mutating their complex structures. Deep Mutation Module was developed to address mutation-based testing and the robustness challenges of DNNs. It analyses the structures of DNNs in detail. It tests models by applying mutation to parameters and structures using its fault library. Testing DNN structures and detecting faults is a highly complex and open-ended challenge. The method proposed in this study applies mutations to DNN parameters to expose faults and weaknesses in the models, thereby testing their robustness. The paper focuses on mutation-based tests of an Reinforce Learning (RL) model developed for electric vehicle routing, a Long Short-Term Memory (LSTM) model developed for prognostic predictions, and a Transformer-based neural network model for electric vehicle routing tasks. The best mutation scores for the LSTM model were measured as 96%, 91.02%, 71.19%, and 68.77%. The test results for the RL model resulted in mutation scores of 93.20%, 72.13%, 77.47%, 79.28%, and 55.74%. The mutation scores of the Transformer model were 75.87%, 76.36%, and 74.93%. These results show that the module can successfully test the targeted models and generate mutants classified as ""survived mutants"" that outperform the original models. In this way, it provides critical information to researchers to improve the overall performance of the models. Conducting these tests before using them in real-world applications minimizes faults and maximizes model success.","2024","2025-02-26 20:43:31","2025-02-26 20:43:31","","160156-160174","","","12","","","","","","","","","","English","","","","WOS:001349756500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Accuracy; Artificial neural networks; Convolutional neural network; Convolutional neural networks; deep neural networks; Libraries; Long short term memory; long short-term memory; machine learning; mutation-based testing; Predictive models; reinforcement learning; Reinforcement learning; Robustness; Software testing; Testing; transformers; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BZ2ZVTHQ","journalArticle","2023","Song, PF; Yang, Z; Li, JJ; Fan, H","DPCTN: Dual path context-aware transformer network for medical image segmentation","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2023.106634","","Accurate segmentation of lesions in medical images is a key step to assist clinicians in diagnosis and analysis. Most studies combine the Transformer model with CNN at a single scale or use the highest-level feature tensor extracted by CNN as input to Transformer without fully exploiting Transformer's potential. In addition, for the problems of structural boundary blurring, heterogeneous textures, etc., in medical images, most existing methods pay attention to using contour information to solve this problem but simply fuse the contour information and ignore the potential relationship between the regions and the contours. We propose the DPCTN network based on the traditional encoding-decoding structure, consisting of the CNN, Transformer dual backbone networks and parallel attention mechanisms, to achieve accurate segmentation in medical image lesions. Local and global multiscale feature information is extracted by CNN and Transformer. The Transformer block of channel cross fusion can implement multiscale information fusion of the high-level local features and reduce the impact of the redundant information. The dual backbone feature fusion module effectively couples the local and global high-level feature information. The decoder refines and enriches the boundary and regional features, layer by layer, to achieve effective supervision of the boundary and region. Considering the possible dimension collapse in the attention mechanism, a novel three branch transposed self-attention module is designed to reduce the information loss caused by feature pooling. To verify the effectiveness of our proposed method, subjective and objective comparative experiments and ablation experiments were performed on four medical segmentation tasks, polyps, skin lesions, glands and breast tumors. A large number of experimental results show that our method is superior to the current state-of-the-art method, reduces the standard deviation and is more robust. Source code is released at https://github.com/sd-spf/DPCTN.","2023-09","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","124","","","","","","","","","","English","","","","WOS:001025808200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","ATTENTION; Convolutional neural networks; Graph convolution network; Medical image segmentation; Multi-scale fusion; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8VM5DPFR","journalArticle","2023","Lee, DI; Lee, JH; Jang, SH; Oh, SJ; Doo, IC","Crop Disease Diagnosis with Deep Learning-Based Image Captioning and Object Detection","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13053148","","The number of people participating in urban farming and its market size have been increasing recently. However, the technologies that assist the novice farmers are still limited. There are several previously researched deep learning-based crop disease diagnosis solutions. However, these techniques only focus on CNN-based disease detection and do not explain the characteristics of disease symptoms based on severity. In order to prevent the spread of diseases in crops, it is important to identify the characteristics of these disease symptoms in advance and cope with them as soon as possible. Therefore, we propose an improved crop disease diagnosis solution which can give practical help to novice farmers. The proposed solution consists of two representative deep learning-based methods: Image Captioning and Object Detection. The Image Captioning model describes prominent symptoms of the disease, according to severity in detail, by generating diagnostic sentences which are grammatically correct and semantically comprehensible, along with presenting the accurate name of it. Meanwhile, the Object Detection model detects the infected area to help farmers recognize which part is damaged and assure them of the accuracy of the diagnosis sentence generated by the Image Captioning model. The Image Captioning model in the proposed solution employs the InceptionV3 model as an encoder and the Transformer model as a decoder, while the Object Detection model of the proposed solution employs the YOLOv5 model. The average BLEU score of the Image Captioning model is 64.96%, which can be considered to have high performance of sentence generation and, meanwhile, the mAP50 for the Object Detection model is 0.382, which requires further improvement. Those results indicate that the proposed solution allows the precise and elaborate information of the crop diseases, thereby increasing the overall reliability of the diagnosis.","2023-03","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","5","13","","","","","","","","","","English","","","","WOS:000948056700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","crop diseases diagnosis; deep learning; farm-tech; image captioning; Inceptionv3; object detection; transformer; YOLOv5","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RWX8I8YU","journalArticle","2022","Li, QY; Zhong, RF; Du, X; Du, Y","TransUNetCD: A Hybrid Transformer Network for Change Detection in Optical Remote-Sensing Images","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2022.3169479","","In the change detection (CD) task, the UNet architecture has achieved superior results. However, due to the inherent limitation of convolution operations, UNet is inadequate in learning global context and long-range spatial relations. Transformers can capture long-range feature dependencies, but the lack of low-level details may result in limited localization capabilities. Therefore, this article proposes an end-to-end encoding-decoding hybrid transformer model for CD, TransUNetCD, which has the advantages of both transformers and UNet. The model encodes the tokenized image patches from the convolutional neural network (CNN) feature map to extract rich global context information. The decoder upsamples the encoded features, connects them with higher-resolution multiscale features through skip connections to learn local-global semantic features, and restores the full spatial resolution of the feature map to achieve precise localization. The model proposed in this article not only solves the problem that redundant information is generated when extracting low-level features under the UNet framework, but also solves the problem that the relationship between each feature layer cannot be fully modeled and the optimal feature difference representation cannot be obtained. On this basis, we introduce a difference enhancement module to generate a difference feature map containing rich change information. By weighting each pixel and selectively aggregating features, the effectiveness of the network and the accuracy of extracting changing features are improved. The results on multiple datasets demonstrate that, compared to state-of-the-art methods, the TransUNetCD can further reduce false alarms and missed alarms, and the edge of the changing area is more accurate. The model has the highest score in each metric than other baseline models and has a robust generalization ability.","2022","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","60","","","","","","","","","","English","","","","WOS:000793964300005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;176<br/>Total Times Cited:&nbsp;&nbsp;178<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Change detection (CD); Data mining; DATASET; Feature extraction; FUSION NETWORK; Image segmentation; optical remote-sensing image; Remote sensing; Semantics; Sensors; transformer; Transformers; UNet","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9UV3E8D6","journalArticle","2024","Eidex, Z; Safari, M; Wynne, J; Qiu, RLJ; Wang, TH; Hernandez, DV; Shu, HK; Mao, H; Yang, XF","Deep learning based apparent diffusion coefficient map generation from multi-parametric MR images for patients with diffuse gliomas","MEDICAL PHYSICS","","0094-2405","10.1002/mp.17509","","PurposeApparent diffusion coefficient (ADC) maps derived from diffusion weighted magnetic resonance imaging (DWI MRI) provides functional measurements about the water molecules in tissues. However, DWI is time consuming and very susceptible to image artifacts, leading to inaccurate ADC measurements. This study aims to develop a deep learning framework to synthesize ADC maps from multi-parametric MR images.MethodsWe proposed the multiparametric residual vision transformer model (MPR-ViT) that leverages the long-range context of vision transformer (ViT) layers along with the precision of convolutional operators. Residual blocks throughout the network significantly increasing the representational power of the model. The MPR-ViT model was applied to T1w and T2-fluid attenuated inversion recovery images of 501 glioma cases from a publicly available dataset including preprocessed ADC maps. Selected patients were divided into training (N = 400), validation (N = 50), and test (N = 51) sets, respectively. Using the preprocessed ADC maps as ground truth, model performance was evaluated and compared against the Vision Convolutional Transformer (VCT) and residual vision transformer (ResViT) models with the peak signal-to-noise ratio (PSNR), structural similarity index measure (SSIM), and mean squared error (MSE).ResultsThe results are as follows using T1w + T2-FLAIR MRI as inputs: MPR-ViT-PSNR: 31.0 +/- 2.1, MSE: 0.009 +/- 0.0005, SSIM: 0.950 +/- 0.015. In addition, ablation studies showed the relative impact on performance of each input sequence. Both qualitative and quantitative results indicate that the proposed MR-ViT model performs favorably against the ground truth data.ConclusionWe show that high-quality ADC maps can be synthesized from structural MRI using a MPR-ViT model. Our predicted images show better conformality to the ground truth volume than ResViT and VCT predictions. These high-quality synthetic ADC maps would be particularly useful for disease diagnosis and intervention, especially when ADC maps have artifacts or are unavailable.","2024-11-08","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","","","","","","","","","","","English","","","","WOS:001357606100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","deep learning; DWI; glioma; intramodal MRI synthesis; MRI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NXGV9438","journalArticle","2023","Li, J; Cao, S; Liu, XJ; Yu, RY; Wang, XW","Trans-UTPA: PSO and MADDPG based multi-UAVs trajectory planning algorithm for emergency communication","FRONTIERS IN NEUROROBOTICS","","1662-5218","10.3389/fnbot.2022.1076338","","Communication infrastructure is damaged by disasters and it is difficult to support communication services in affected areas. UAVs play an important role in the emergency communication system. Due to the limited airborne energy of a UAV, it is a critical technical issue to effectively design flight routes to complete rescue missions. We fully consider the distribution of the rescue area, the type of mission, and the flight characteristics of the UAV. Firstly, according to the distribution of the crowd, the PSO algorithm is used to cluster the target-POI of the task area, and the neural collaborative filtering algorithm is used to prioritize the target-POI. Then we also design a Trans-UTPA algorithm. Based on MAPPO 's policy network and value function, we introduce transformer model to make Trans-UTPA's policy learning have no action space limitation and can be multi-task parallel, which improves the efficiency and generalization of sample processing. In a three-dimensional space, the UAV selects the emergency task to be performed (data acquisition and networking communication) based on strategic learning of state information (location information, energy consumption information, etc.) and action information (horizontal flight, ascent, and descent), and then designs the UAV flight path based on the maximization of the global value function. The experimental results show that the performance of the Trans-UTPA algorithm is further improved compared with the USCTP algorithm in terms of the success rate of each UAV reaching the target position, the number of collisions, and the average reward of the algorithm. Among them, the average reward of the algorithm exceeds the USCTP algorithm by 13%, and the number of collisions is reduced by 60%. Compared with the heuristic algorithm, it can cover more target-POIs, and has less energy consumption than the heuristic algorithm.","2023-01-24","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","16","","","","","","","","","","English","","","","WOS:000924811000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","energy consumption; multi-agent reinforcement learning; multi-UAVs collaboration; PSO; trajectory planning; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3PGNQ6MV","journalArticle","2024","Lin, GR; Bao, ZQ; Huang, ZH; Li, ZY; Zheng, WS; Chen, YW","A Multi-Level Relation-Aware Transformer model for occluded person re-identification","NEURAL NETWORKS","","0893-6080","10.1016/j.neunet.2024.106382","","Occluded person re-identification (Re-ID) is a challenging task, as pedestrians are often obstructed by various occlusions, such as non-pedestrian objects or non-target pedestrians. Previous methods have heavily relied on auxiliary models to obtain information in unoccluded regions, such as human pose estimation. However, these auxiliary models fall short in accounting for pedestrian occlusions, thereby leading to potential misrepresentations. In addition, some previous works learned feature representations from single images, ignoring the potential relations among samples. To address these issues, this paper introduces a Multi-Level Relation-Aware Transformer (MLRAT) model for occluded person Re-ID. This model mainly encompasses two novel modules: Patch-Level Relation-Aware (PLRA) and Sample-Level Relation-Aware (SLRA). PLRA learns finegrained local features by modeling the structural relations between key patches, bypassing the dependency on auxiliary models. It adopts a model-free method to select key patches that have high semantic correlation with the final pedestrian representation. In particular, to alleviate the interference of occlusion, PLRA captures the structural relations among key patches via a two-layer Graph Convolution Network (GCN), effectively guiding the local feature fusion and learning. SLRA is designed to facilitate the model to learn discriminative features by modeling the relations among samples. Specifically, to mitigate noisy relations of irrelevant samples, we present a Relation-Aware Transformer (RAT) block to capture the relations among neighbors. Furthermore, to bridge the gap between training and testing phases, a self-distillation method is employed to transfer the sample-level relations captured by SLRA to the backbone. Extensive experiments are conducted on four occluded datasets, two partial datasets and two holistic datasets. The results show that the proposed MLRAT model significantly outperforms existing baselines on four occluded datasets, while maintains top performance on two partial datasets and two holistic datasets.","2024-09","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","177","","","","","","","","","","English","","","","WOS:001362191700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;86</p>","","","Occluded pedestrian; Person Re-ID; Self-distillation; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XWSHIJF4","journalArticle","2024","Guirguis, J; Abdulmaksoud, A; Ismail, M; Kollmeyer, PJ; Ahmed, R","Transformer-Based Deep Learning Strategies for Lithium-Ion Batteries SOX Estimation Using Regular and Inverted Embedding","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3495560","","The accurate estimation of Li-ion battery (LIB) states such as State of Charge (SOC), State of Health (SOH), and State of Power (SOP) plays a pivotal role in the efficient operation of Electric Vehicles (EVs). These parameters can impact the battery's health, driving range, and overall vehicle performance. Transformer-based artificial neural networks have shown impressive results in natural language processing (NLP) and estimation problems of many other domains. This paper presents an intensive study on the capabilities of various Transformer-based models in estimating the SOC and SOH of LIBs, the SOP is obtained based on the estimated SOC. This paper provides the following key original contributions: 1) the application of the Informer and Reformer variants of the Transformer model for the first time for SOH estimation of LIBs in EVs, 2) studying the effect of inverted embedding of iTransformers, a modified architecture of the transformers, on SOC and SOH estimation, inversion is performed on the Informer and Reformer as well; 3) applying a simple feature extraction method using partial discharge cycles for SOH estimation with Transformer-based models; 4) a new robust method is proposed for SOC estimation based on a 2-Encoder-Transformer with a one-dimensional convolutional neural network (1D-CNN) architecture; 5) the various architectures are trained, validated and tested on two real-world datasets comprising various driving scenarios and battery conditions. Comparative analysis with various deep learning architectures show impressive accuracy for estimating the SOC and SOH, leading to better SOP calculation.","2024","2025-02-26 20:43:31","2025-02-26 20:43:31","","167108-167119","","","12","","","","","","","","","","English","","","","WOS:001358536300023","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Artificial intelligence; CAPACITY; CHARGE ESTIMATION; Computational modeling; Computer architecture; Convolutional neural networks; Decoding; deep learning; electric vehicles; Estimation; Face recognition; FRAMEWORK; iTransformers; li-ion batteries; Long short term memory; MANAGEMENT-SYSTEMS; PACKS; Predictive models; STATE; state estimation; state of charge; State of charge; state of health; state of power; transformers; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LBEFIZHK","journalArticle","2024","Touahri, I; Mazroui, A","Annotation and evaluation of a dialectal Arabic sentiment corpus against benchmark datasets using transformers","LANGUAGE RESOURCES AND EVALUATION","","1574-020X","10.1007/s10579-024-09750-y","","Sentiment analysis is a task in natural language processing aiming to identify the overall polarity of reviews for subsequent analysis. This study used the Arabic speech-act and sentiment analysis, Arabic sentiment tweets dataset, and SemEval benchmark datasets, along with the Moroccan sentiment analysis corpus, which focuses on the Moroccan dialect. Furthermore, the modern standard and dialectal Arabic corpus dataset has been created and annotated based on the three language types: modern standard Arabic, Moroccan Arabic Dialect, and Mixed Language. Additionally, the annotation has been performed at the sentiment level, categorizing sentiments as positive, negative, or mixed. The sizes of the datasets range from 2000 to 21,000 reviews. The essential dialectal characteristics to enhance a sentiment classification system have been outlined. The proposed approach has involved deploying several models employing the supervised approach, including occurrence vectors, Recurrent Neural Network-Long Short Term Memory, and the pre-trained transformer model Arabic bidirectional encoder representations from transformers (AraBERT), complemented by the integration of Generative Adversarial Networks (GANs). The uniqueness of the proposed approach lies in constructing and annotating manually a dialectal sentiment corpus and studying carefully its main characteristics, which are used then to feed the classical supervised model. Moreover, GANs that widen the gap between the studied classes have been used to enhance the obtained results with AraBERT. The classification test results have been promising, enabling a comparison with other systems. The proposed system has been evaluated against Mazajak and CAMelTools state-of-the-art systems, designed for most Arabic dialects, using the mentioned datasets. A significant improvement of 30 points in FNN has been observed. These results have affirmed the versatility of the proposed system, demonstrating its effectiveness across multi-dialectal, multi-domain datasets, as well as balanced and unbalanced ones.","2024-08-18","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","","","","","","","","","","","English","","","","WOS:001292750800004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","AraBERT; Dialectal Arabic language; GANs; Sentiment analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CFZWTHAE","journalArticle","2024","Ma, XH; Jin, RZ; Wang, JM; Chung, TS","Attentional bias for hands: Cascade dual-decoder transformer for sign language production","IET COMPUTER VISION","","1751-9632","10.1049/cvi2.12273","","Sign Language Production (SLP) refers to the task of translating textural forms of spoken language into corresponding sign language expressions. Sign languages convey meaning by means of multiple asynchronous articulators, including manual and non-manual information channels. Recent deep learning-based SLP models directly generate the full-articulatory sign sequence from the text input in an end-to-end manner. However, these models largely down weight the importance of subtle differences in the manual articulation due to the effect of regression to the mean. To explore these neglected aspects, an efficient cascade dual-decoder Transformer (CasDual-Transformer) for SLP is proposed to learn, successively, two mappings SLPhand: Text -> Hand pose and SLPsign: Text -> Sign pose, utilising an attention-based alignment module that fuses the hand and sign features from previous time steps to predict more expressive sign pose at the current time step. In addition, to provide more efficacious guidance, a novel spatio-temporal loss to penalise shape dissimilarity and temporal distortions of produced sequences is introduced. Experimental studies are performed on two benchmark sign language datasets from distinct cultures to verify the performance of the proposed model. Both quantitative and qualitative results show that the authors' model demonstrates competitive performance compared to state-of-the-art models, and in some cases, achieves considerable improvements over them. An efficient cascade dual decoder Transformer model is presented, which heuristically optimises mappings among text, hand pose, and full-articulatory pose for sign language production (SLP). In addition, a novel spatio-temporal loss is introduced to provide more efficacious guidance for SLP models. Both quantitative and qualitative results show that the proposed SLP model with spatio-temporal loss function achieves state-of-the-art results on both German and Korean SLP tasks. image","2024-08","2025-02-26 20:43:31","2025-02-26 20:43:31","","696-708","","5","18","","","","","","","","","","English","","","","WOS:001180960800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","computer vision; natural language processing; pose estimation; sign language production","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q44BNC4W","journalArticle","2023","Chen, WH; Zhou, SB; Liu, XJ; Chen, YJ","Semi-TMS: an efficient regularization-oriented triple-teacher semi-supervised medical image segmentation model","PHYSICS IN MEDICINE AND BIOLOGY","","0031-9155","10.1088/1361-6560/acf90f","","Objective. Although convolutional neural networks (CNN) and Transformers have performed well in many medical image segmentation tasks, they rely on large amounts of labeled data for training. The annotation of medical image data is expensive and time-consuming, so it is common to use semi-supervised learning methods that use a small amount of labeled data and a large amount of unlabeled data to improve the performance of medical imaging segmentation. Approach. This work aims to enhance the segmentation performance of medical images using a triple-teacher cross-learning semi-supervised medical image segmentation with shape perception and multi-scale consistency regularization. To effectively leverage the information from unlabeled data, we design a multi-scale semi-supervised method for three-teacher cross-learning based on shape perception, called Semi-TMS. The three teacher models engage in cross-learning with each other, where Teacher A and Teacher C utilize a CNN architecture, while Teacher B employs a transformer model. The cross-learning module consisting of Teacher A and Teacher C captures local and global information, generates pseudo-labels, and performs cross-learning using prediction results. Multi-scale consistency regularization is applied separately to the CNN and Transformer to improve accuracy. Furthermore, the low uncertainty output probabilities from Teacher A or Teacher C are utilized as input to Teacher B, enhancing the utilization of prior knowledge and overall segmentation robustness. Main results. Experimental evaluations on two public datasets demonstrate that the proposed method outperforms some existing semi-segmentation models, implicitly capturing shape information and effectively improving the utilization and accuracy of unlabeled data through multi-scale consistency. Significance. With the widespread utilization of medical imaging in clinical diagnosis, our method is expected to be a potential auxiliary tool, assisting clinicians and medical researchers in their diagnoses.","2023-10-21","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","20","68","","","","","","","","","","English","","","","WOS:001075280000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","image segmentation; multi-scale consistency; PROSTATE; semi-supervised learning; shape perception; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IXVHK6VU","journalArticle","2023","Jungiewicz, M; Jastrzebski, P; Wawryka, P; Przystalski, K; Sabatowski, K; Bartus, S","Vision Transformer in stenosis detection of coronary arteries","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2023.120234","","About 380 thousand people in the United States die each year because of coronary artery disease. About 2 in 10 deaths from CAD happen in adults less than 65 years old. Early detection of blocked arteries can prevent serious surgeries and decrease the number of deaths. Coronary angiography, as one of the methods for diagnosing the state of the arteries, is a complex and invasive procedure. Neural networks can be used to support physicians in the diagnostic process and improve stenoses detection effectiveness. In this paper, we compare different variants of the Inception Network and the Vision Transformer in a stenosis detection task that, in our case, is a binary classification problem. The data set used in the experiments consists of small fragments extracted from coronary angiography videos. Furthermore, we analyze the impact of different percentages of arteries in fragments without stenosis on model performance and show that the data set configuration plays an important role. As the fragment images are small, we analyzed the Sharpness-Aware Minimization together with the Visual Transformers. We employ explainable AI methods to understand the differences in classification performance between selected models. Our results show that convolutional neural networks generally perform better than transformer-based architectures, but perform slightly worse if the Visual Transformer model is supported by the Sharpness-Aware Minimization method. While increasing the percentage of arteries in nonstenosis class, the F1 median decreases by 2.3, 5.4, and 2.2 for the Inception, ViT, and SAM-ViT models. The F1 mean decreases by 3.4, 4.8, and 2.3. The SAM-ViT is more stable compared to other models and based on the F1 mean outperforms other models. This indicates the usefulness of ViT in medical applications, especially in the analysis of coronary angiography.","2023-10-15","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","228","","","","","","","","","","English","","","","WOS:001001979700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Convolution neural networks; Coronary angiography; Inception network; NEURAL-NETWORKS; Sharpness-Aware Minimization; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2RSTR866","journalArticle","2023","Li, CY; Qian, GQ","Stock Price Prediction Using a Frequency Decomposition Based GRU Transformer Neural Network","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13010222","","Stock price prediction is crucial but also challenging in any trading system in stock markets. Currently, family of recurrent neural networks (RNNs) have been widely used for stock prediction with many successes. However, difficulties still remain to make RNNs more successful in a cluttered stock market. Specifically, RNNs lack power to retrieve discerning features from a clutter of signals in stock information flow. Making it worse, by RNN a single long time cell from the market is often fused into a single feature, losing all the information about time which is essential for temporal stock prediction. To tackle these two issues, we develop in this paper a novel hybrid neural network for price prediction, which is named frequency decomposition induced gate recurrent unit (GRU) transformer, abbreviated to FDGRU-transformer or FDG-trans). Inspired by the success of frequency decomposition, in FDG-transformer we apply empirical model decomposition to decompose the complete ensemble of cluttered data into a trend component plus several informative and independent mode components. Equipped with the decomposition, FDG-transformer has the capacity to extract the discriminative insights from the cluttered signals. To retain the temporal information in the observed cluttered data, FDG-transformer utilizes hybrid neural network of GRU, long short term memory (LSTM) and multi-head attention (MHA) transformers. The integrated transformer network is capable of encoding the impact of different weights from each past time step to the current one, resulting in the establishment of a time series model from a deeper fine-grained level. We appy the developed FDG-transformer model to analyze Limit Order Book data and compare the results with that obtained from other state-of-the-art methods. The comparison shows that our model delivers effective price forecasting. Moreover, an ablation study is conducted to validate the importance and necessity of each component in the proposed model.","2023-01","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","1","13","","","","","","","","","","English","","","","WOS:000909301800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;25<br/>Total Times Cited:&nbsp;&nbsp;25<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","complete ensemble empirical mode decomposition; gated recurrent unit; LSTM; stock prediction; transformer; VOLATILITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z2RSPXFN","journalArticle","2022","Liu, SQ; Cao, JN; Yang, RS; Wen, ZY","Key phrase aware transformer for abstractive summarization","INFORMATION PROCESSING & MANAGEMENT","","0306-4573","10.1016/j.ipm.2022.102913","","summarization aims to generate a concise summary covering salient content from single or multiple text documents. Many recent abstractive summarization methods are built on the transformer model to capture long-range dependencies in the input text and achieve parallelization. In the transformer encoder, calculating attention weights is a crucial step for encoding input documents. Input documents usually contain some key phrases convey-ing salient information, and it is important to encode these phrases completely. However, existing transformer-based summarization works did not consider key phrases in input when determining attention weights. Consequently, some of the tokens within key phrases only receive small attention weights, which is not conducive to encoding the semantic information of input documents. In this paper, we introduce some prior knowledge of key phrases into the transformer-based summarization model and guide the model to encode key phrases. For the contextual representation of each token in the key phrase, we assume the tokens within the same key phrase make larger contributions compared with other tokens in the input sequence. Based on this assumption, we propose the Key Phrase Aware Transformer (KPAT), a model with the highlighting mechanism in the encoder to assign greater attention weights for tokens within key phrases. Specifically, we first extract key phrases from the input document and score the phrases' importance. Then we build the block diagonal highlighting matrix to indicate these phrases' importance scores and positions. To combine self-attention weights with key phrases' importance scores, we design two structures of highlighting attention for each head and the multi-head highlighting attention. Experimental results on two datasets (Multi-News and PubMed) from different summarization tasks and domains show that our KPAT model significantly outperforms advanced summarization baselines. We conduct more experiments to analyze the impact of each part of our model on the summarization performance and verify the effectiveness of our proposed highlighting mechanism.","2022-05","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","3","59","","","","","","","","","","English","","","","WOS:000786544200006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;21<br/>Total Times Cited:&nbsp;&nbsp;22<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Abstractive summarization; Deep learning; Key phrase extraction; Text summarization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MIHSSL7V","journalArticle","2025","Pang, YN; Yang, Z; Zhang, LX; Liu, XQ; Dong, XS; Sheng, X; Tan, JG; Mao, XY; Liu, MY","Establishment and evaluation of a deep learning-based tooth wear severity grading system using intraoral photographs","JOURNAL OF DENTAL SCIENCES","","1991-7902","10.1016/j.jds.2024.05.013","","Background/purpose: Artificial intelligence (AI) can assist in medical diagnosis owing to its high accuracy and efficiency. This study aimed to develop a diagnostic system for automatically determining the degree of tooth wear (TW) using intraoral photographs with deep learning. Materials and methods: The study included 388 intraoral photographs. A tooth segmentation model was first established using the Mask R-CNN architecture, which incorporated U-Net and SGE attention mechanisms. Subsequently, 2774 individual tooth images output from the segmentation model were included into the classification task, labeled and randomized into training, validation, and test sets with 6.0:2.0:2.0 ratio. A vision transformer model optimized using a mask mechanism was constructed for TW degree classification. The models were evaluated using the accuracy, precision, recall, and F1-score metrics. The time required for AI analysis was calculated. Results: The accuracy of the tooth segmentation model was 0.95. The average accuracy, precision, recall, and F1-score in the classification task were 0.93, 0.91, 0.88, and 0.89, respectively. The F1-score differed in different grades (0.97 for grade 0, 0.90 for grade 1, 0.88 for grade 2, and 0.82 for grade 3). No significant difference was observed in the accuracy between different surfaces. The AI system reduced the time required to grade an individual tooth surface to 0.07 s, compared to the 2.67 s required by clinicians. Conclusion: The developed system provides superior accuracy and efficiency in determining TW degree using intraoral photographs. It might assist clinicians in the decision-making for <feminine ordinal indicator> 2025 Association for Dental Sciences of the Republic of China. Publishing services by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons. org/licenses/by-nc-nd/4.0/).","2025-01","2025-02-26 20:43:31","2025-02-26 20:43:31","","477-486","","1","20","","","","","","","","","","English","","","","WOS:001402930600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Artificial intelligence; ARTIFICIAL-INTELLIGENCE; Deep learning; Diagnosis; Tooth wear","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PG55SAN3","journalArticle","2024","Xie, DY; Liu, ZY; Wang, FH; Song, ZY","A Transformer and LSTM-Based Approach for Blind Well Lithology Prediction","SYMMETRY-BASEL","","2073-8994","10.3390/sym16050616","","Petrographic prediction is crucial in identifying target areas and understanding reservoir lithology in oil and gas exploration. Traditional logging methods often rely on manual interpretation and experiential judgment, which can introduce subjectivity and constraints due to data quality and geological variability. To enhance the precision and efficacy of lithology prediction, this study employed a Savitzky-Golay filter with a symmetric window for anomaly data processing, coupled with a residual temporal convolutional network (ResTCN) model tasked with completing missing logging data segments. A comparative analysis against the support vector regression and random forest regression model revealed that the ResTCN achieves the smallest MAE, at 0.030, and the highest coefficient of determination, at 0.716, which are indicative of its proximity to the ground truth. These methodologies significantly enhance the quality of the training data. Subsequently, a Transformer-long short-term memory (T-LS) model was applied to identify and classify the lithology of unexplored wells. The input layer of the Transformer model follows an embedding-like principle for data preprocessing, while the encoding block encompasses multi-head attention, Add & Norm, and feedforward components, integrating the multi-head attention mechanism. The output layer interfaces with the LSTM layer through dropout. A performance evaluation of the T-LS model against established rocky prediction techniques such as logistic regression, k-nearest neighbor, and random forest demonstrated its superior identification and classification capabilities. Specifically, the T-LS model achieved a precision of 0.88 and a recall of 0.89 across nine distinct lithology features. A Shapley analysis of the T-LS model underscored the utility of amalgamating multiple logging data sources for lithology classification predictions. This advancement partially addresses the challenges associated with imprecise predictions and limited generalization abilities inherent in traditional machine learning and deep learning models applied to lithology identification, and it also helps to optimize oil and gas exploration and development strategies and improve the efficiency of resource extraction.","2024-05","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","5","16","","","","","","","","","","English","","","","WOS:001231256100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","embedding; IDENTIFICATION; lithology prediction; LSTM; OIL; ResTCN; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8AMPQH4N","journalArticle","2024","Wu, QG; Li, Y; Huang, W; Chen, QQ; Wu, YL","C3TB-YOLOv5: integrated YOLOv5 with transformer for object detection in high-resolution remote sensing images","INTERNATIONAL JOURNAL OF REMOTE SENSING","","0143-1161","10.1080/01431161.2024.2329528","","In the realm of object detection from high-resolution remote sensing images (HRRSIs), the existing YOLOv5 methods encounter several challenges, including dense object arrangements, small object sizes, and complex backgrounds. To tackle these challenges, we propose a novel approach called C3TB-YOLOv5, which combines traditional YOLOv5 with the Transformer model to detect objects in HRRSIs. Unlike conventional YOLOv5 methods that primarily focus on capturing local information from remote sensing scenes, our C3TB-YOLOv5 method incorporates global information through the introduction of a new C3TB module. This module, based on the Transformer multi-head attention mechanism (AM), consists of two branches that extract local and global information from feature maps. By integrating these branches and establishing long-range relationships, our method successfully detects densely arranged small objects in HRRSIs. Furthermore, to improve the accuracy of tiny object detection, a novel detection head has been developed to effectively utilize the unused C3 module, thereby preventing the loss of fine-grained textures and positional features. In addition, we integrate an enhanced SimAM, namely Sim-GMP, into the model to adjust the focus across varying regions, effectively distinguishing the features of interested objects from complex backgrounds. Finally, to address the problem of sample imbalance in remote sensing object detection, the most recent Wise-IoU v3 loss function is employed to improve the accuracy of anchor box predictions for objects. To maintain a high object detection speed, the most critical C3 modules are substituted with the proposed C3TB module for the purpose of striking a good balance between object detection accuracy and model lightweight. Extensive experiments conducted on two remote sensing datasets of NWPU VHR-10 and VisDrone 2019 demonstrates that our method achieves superior object detection performance than state-of-the-art methods.","2024-04-17","2025-02-26 20:43:31","2025-02-26 20:43:31","","2622-2650","","8","45","","","","","","","","","","English","","","","WOS:001196370500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","attention mechanism; High-resolution remote sensing images (HRRSIs); object detection; tiny detection head; transformer; YOLOv5","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HUHHDEQY","journalArticle","2024","Alkhodari, M; Hadjileontiadis, LJ; Khandoker, AH","Identification of Congenital Valvular Murmurs in Young Patients Using Deep Learning-Based Attention Transformers and Phonocardiograms","IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS","","2168-2194","10.1109/JBHI.2024.3357506","","One in every four newborns suffers from congenital heart disease (CHD) that causes defects in the heart structure. The current gold-standard assessment technique, echocardiography, causes delays in the diagnosis owing to the need for experts who vary markedly in their ability to detect and interpret pathological patterns. Moreover, echo is still causing cost difficulties for low- and middle-income countries. Here, we developed a deep learning-based attention transformer model to automate the detection of heart murmurs caused by CHD at an early stage of life using cost-effective and widely available phonocardiography (PCG). PCG recordings were obtained from 942 young patients at four major auscultation locations, including the aortic valve (AV), mitral valve (MV), pulmonary valve (PV), and tricuspid valve (TV), and they were annotated by experts as absent, present, or unknown murmurs. A transformation to wavelet features was performed to reduce the dimensionality before the deep learning stage for inferring the medical condition. The performance was validated through 10-fold cross-validation and yielded an average accuracy and sensitivity of 90.23% and 72.41%, respectively. The accuracy of discriminating between murmurs' absence and presence reached 76.10% when evaluated on unseen data. The model had accuracies of 70%, 88%, and 86% in predicting murmur presence in infants, children, and adolescents, respectively. The interpretation of the model revealed proper discrimination between the learned attributes, and AV channel was found important (score > 0.75) for the murmur absence predictions while MV and TV were more important for murmur presence predictions. The findings potentiate deep learning as a powerful front-line tool for inferring CHD status in PCG recordings leveraging early detection of heart anomalies in young people. It is suggested as a tool that can be used independently from high-cost machinery or expert assessment.","2024-04","2025-02-26 20:43:31","2025-02-26 20:43:31","","1803-1814","","4","28","","","","","","","","","","English","","","","WOS:001197865400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;79</p>","","","ALZHEIMERS-DISEASE; ASSOCIATION; attention transformer; BIG DATA; congenital heart disease; DATA QUALITY; Deep learning; DEFINITION; DEMENTIA; DESIGN; GENETICS; heart murmur; INTEGRATION; phonocard- iography","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R4XGZXPT","journalArticle","2023","Indolia, S; Nigam, S; Singh, R; Singh, VK; Singh, MK","Micro Expression Recognition Using Convolution Patch in Vision Transformer","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3314797","","Humans possess an intrinsic ability to hide their true emotions. Micro-expressions are subtle changes in facial muscles that are involuntary by nature and easy to hide. To address these issues, several machine and deep learning models have been proposed in the past few years. Convolution neural network (CNN) is a deep learning method that has widely been adopted in vision-related tasks due to its remarkable performance. However, CNN suffers from overfitting due to a large number of trainable parameters. Additionally, CNN cannot capture global information with respect to an input image. Furthermore, the identification of important regions for the classification of micro-expressions is a challenging task. Self-attention mechanism addresses these issues by focusing on key areas. Furthermore, specific transformers, known as vision transformers are widely explored in vision-related applications. However, existing vision transformers divide an input image into a fixed number of patches due to which local correlation of image pixels is lost. Further, a vision transformer relies on self-attention mechanism which effectively captures global dependencies but does not exploit the local spatial relationships in an image. In this work, we propose a vision transformer based on convolution patches to overcome this problem. The proposed algorithm generates $c $ number of feature maps from input images using $c $ filters through convolution operation. These feature maps are then applied to a transformer model as fixed-size image patches to perform classification. Thus, the proposed architecture leverages advantages of both convolutional layers and transformer, and captures both spatial information and global dependencies respectively, leading to improved performance. The performance of the proposed model is evaluated on three benchmark datasets: CASME-I, CASME-II, and SAMM and compared with state-of-the-art machine and deep learning models, which generated classification accuracy of 95.97%, 98.59%, and 100%, respectively.","2023","2025-02-26 20:43:31","2025-02-26 20:43:31","","100495-100507","","","11","","","","","","","","","","English","","","","WOS:001071719700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","& nbsp; deep learning; Facial expression recognition; micro-expression recognition; self-attention; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LDTNMHC9","journalArticle","2023","Yu, DW; Ji, SP","Long-Range Correlation Supervision for Land-Cover Classification From Remote Sensing Images","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2023.3324706","","Long-range dependency modeling has been widely considered in modern deep learning-based semantic segmentation methods, especially those designed for large-size remote sensing images, to compensate the intrinsic locality of standard convolutions. However, in previous studies, the long-range dependency, modeled with an attention mechanism or transformer model, has been based on unsupervised learning, instead of explicit supervision from the objective ground truth (GT). In this article, we propose a novel supervised long-range correlation method for land-cover classification, called the supervised long-range correlation network (SLCNet), which is shown to be superior to the currently used unsupervised strategies. In SLCNet, pixels sharing the same category are considered highly correlated and those having different categories are less relevant, which can be easily supervised by the category consistency information available in the GT semantic segmentation map. Under such supervision, the recalibrated features are more consistent for pixels of the same category and more discriminative for pixels of other categories, regardless of their proximity. To complement the detailed information lacking in the global long-range correlation, we introduce an auxiliary adaptive receptive field feature extraction (ARFE) module, parallel to the long-range correlation module in the encoder, to capture finely detailed feature representations for multisize objects in multiscale remote sensing images. In addition, we apply multiscale side-output supervision and a hybrid loss function as local and global constraints to further boost the segmentation accuracy. Experiments were conducted on three public remote sensing datasets (the ISPRS Vaihingen dataset, the ISPRS Potsdam dataset, and the DeepGlobe dataset). Compared with the advanced segmentation methods from the computer vision, medicine, and remote sensing communities, the proposed SLCNet method achieved state-of-the-art performance on all the datasets. The code will be made available at gpcv.whu.edu.cn/data.","2023","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","61","","","","","","","","","","English","","","","WOS:001104073300018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Computational modeling; Convolutional neural network (CNN); Correlation; Feature extraction; land-cover classification; long-range correlation supervision; Remote sensing; remote sensing images; semantic segmentation; Semantic segmentation; SEMANTIC SEGMENTATION; Semantics; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"35KHQKNE","journalArticle","2023","Long, XJ; Gong, XY; Zhang, B; Zhou, HY","Deep learning based data prefetching in CPU-GPU unified virtual memory","JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING","","0743-7315","10.1016/j.jpdc.2022.12.004","","Unified Virtual Memory (UVM) relieves the developers from the onus of maintaining complex data structures and explicit data migration by enabling on-demand data movement between CPU memory and GPU memory. However, on-demand paging soon becomes a performance bottleneck of UVM due to the high latency caused by page table walks and data migration over interconnect. Prefetching is considered a promising solution to this problem given its ability to leverage the locality of program memory access patterns. However, existing locality-based prefetching schemes can not handle all the situations. An ideal prefetcher should not only look at narrow regions of the requested address space but also capture global context to deliver a good prediction of the memory access pattern. This paper proposes a novel framework for page prefetching for UVM through deep learning. We first show that a powerful Transformer learning model can provide high accuracy for UVM page prefetching. We then perform analysis to interpret this Transformer model and derive several insights that allow us to design a simpler model to match the unconstrained model's accuracy with orders of magnitude lower cost. We use a pattern-based method to make the UVM page preditor general to different GPU workloads. We evaluate this framework on a set of 11 memory-intensive benchmarks from popular benchmark suites. Our solution outperforms the state-of-the-art (SOTA) UVM framework, improving the performance by 10.89%, improving the device memory page hit rate by 16.98% (89.02% vs. 76.10% for prior art), and reducing the CPU-GPU interconnect traffic by 11.05%. According to our proposed unified metric, which combines the accuracy, coverage, and page hit rate, our solution is approaching the ideal prefetching scheme more than the SOTA design (0.90 vs. 0.85, with the perfect prefetcher of 1.0).(c) 2022 Elsevier Inc. All rights reserved.","2023-04","2025-02-26 20:43:31","2025-02-26 20:43:31","","19-31","","","174","","","","","","","","","","English","","","","WOS:000964060200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Data prefetching; Deep learning; Graphics processing unit; Transformer; Unified virtual memory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y7SPVQWL","journalArticle","2021","Wu, JF; Hu, R; Xiao, ZH; Chen, JX; Liu, JW","Vision Transformer-based recognition of diabetic retinopathy grade","MEDICAL PHYSICS","","0094-2405","10.1002/mp.15312","","Background In the domain of natural language processing, Transformers are recognized as state-of-the-art models, which opposing to typical convolutional neural networks (CNNs) do not rely on convolution layers. Instead, Transformers employ multi-head attention mechanisms as the main building block to capture long-range contextual relations between image pixels. Recently, CNNs dominated the deep learning solutions for diabetic retinopathy grade recognition. However, spurred by the advantages of Transformers, we propose a Transformer-based method that is appropriate for recognizing the grade of diabetic retinopathy. Purpose The purposes of this work are to demonstrate that (i) the pure attention mechanism is suitable for diabetic retinopathy grade recognition and (ii) Transformers can replace traditional CNNs for diabetic retinopathy grade recognition. Methods This paper proposes a Vision Transformer-based method to recognize the grade of diabetic retinopathy. Fundus images are subdivided into non-overlapping patches, which are then converted into sequences by flattening, and undergo a linear and positional embedding process to preserve positional information. Then, the generated sequence is input into several multi-head attention layers to generate the final representation. The first token sequence is input to a softmax classification layer to produce the recognition output in the classification stage. Results The dataset for training and testing employs fundus images of different resolutions, subdivided into patches. We challenge our method against current CNNs and extreme learning machines and achieve an appealing performance. Specifically, the suggested deep learning architecture attains an accuracy of 91.4%, specificity = 0.977 (95% confidence interval (CI) (0.951-1)), precision = 0.928 (95% CI (0.852-1)), sensitivity = 0.926 (95% CI (0.863-0.989)), quadratic weighted kappa score = 0.935, and area under curve (AUC) = 0.986. Conclusion Our comparative experiments against current methods conclude that our model is competitive and highlight that an attention mechanism based on a Vision Transformer model is promising for the diabetic retinopathy grade recognition task.","2021-12","2025-02-26 20:43:31","2025-02-26 20:43:31","","7850-7863","","12","48","","","","","","","","","","English","","","","WOS:000718879800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;56<br/>Total Times Cited:&nbsp;&nbsp;56<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","ATTENTION; deep learning; diabetic retinopathy; multi-head attention; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UENDGVV2","journalArticle","2025","Yang, XQ; Gao, XQ; Zheng, HY; Yang, MS; Liu, Y","A hybrid prognosis method based on health indicator and wiener process: The case of multi-sensor monitored aero-engine","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2025.110099","","The stochastic nature of the multi-sensor monitored aero-engine degradation process limits the accuracy of its remaining useful life (RUL) prediction. To address this problem, a hybrid prognosis method for multi-sensor monitored aero-engine based on health indicators and the Wiener process is proposed. The method constructs composite health indicators (CHI) for aero-engine. The one-dimensional sensor-monitored signals are converted to two-dimensional features through the Gramian Angle Field (GAF), thereby preserving potential feature relationships in the time series data. A hybrid convolutional neural network (CNN) and Transformer are constructed, and the feature maps obtained from the GAF are used as inputs to fuse multi-sensor data to obtain the CHI. The Wiener process is used to model the CHI degradation. The initial parameters for the degradation model are obtained using the maximum likelihood estimation. The Bayesian and expectation maximization methods adaptively update the parameters online based on real-time data. On this basis, the probability density function of the RUL under the first-hitting-time is derived. To enhance adaptability, CHI is combined with the Wiener process for joint training. The effectiveness of the hybrid model is experimentally verified on the Commercial Modular Aero-Propulsion System Simulation (C-MAPSS) dataset, and the generalization ability is further verified on the New Commercial Modular Aero-Propulsion System Simulation (N-CMAPSS) dataset. The results show that the proposed method improves the root mean square error by 2.07 and the prediction accuracy by 18% on average, which can meet the real-time and storage requirements in engineering applications and provide technical support for actual maintenance decision-making.","2025-03-15","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","144","","","","","","","","","","English","","","","WOS:001414425200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Aero-engine; Composite health indicator; CONSTRUCTION; DATA FUSION; Gramian angular field; INDEX; MODEL; NETWORK; Remaining useful life prediction; Transformer model; USEFUL LIFE PREDICTION; Wiener process","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z8ZEG9SE","journalArticle","2024","Liu, D; Lu, C; Sun, HN; Gao, SP","NA-segformer: A multi-level transformer model based on neighborhood attention for colonoscopic polyp segmentation","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-74123-y","","In various countries worldwide, the incidence of colon cancer-related deaths has been on the rise in recent years. Early detection of symptoms and identification of intestinal polyps are crucial for improving the cure rate of colon cancer patients. Automated computer-aided diagnosis (CAD) has emerged as a solution to the low efficiency of traditional methods relying on manual diagnosis by physicians. Deep learning is the latest direction of CAD development and has shown promise for colonoscopic polyp segmentation. In this paper, we present a multi-level encoder-decoder architecture for polyp segmentation based on the Transformer architecture, termed NA-SegFormer. To improve the performance of existing Transformer-based segmentation algorithms for edge segmentation on colon polyps, we propose a patch merging module with a neighbor attention mechanism based on overlap patch merging. Since colon tract polyps vary greatly in size and different datasets have different sample sizes, we used a unified focal loss to solve the problem of category imbalance in colon tract polyp data. To assess the effectiveness of our proposed method, we utilized video capsule endoscopy and typical colonoscopy polyp datasets, as well as a dataset containing surgical equipment. On the datasets Kvasir-SEG, Kvasir-Instrument and KvasirCapsule-SEG, the Dice score of our proposed model reached 94.30%, 94.59% and 82.73%, with an accuracy of 98.26%, 99.02% and 81.84% respectively. The proposed method achieved inference speed with an Frame-per-second (FPS) of 125.01. The results demonstrated that our suggested model effectively segmented polyps better than several well-known and latest models. In addition, the proposed method has advantages in trade-off between inference speed and accuracy, and it will be of great significance to real-time colonoscopic polyp segmentation. The code is available at https://github.com/promisedong/NAFormer.","2024-09-28","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","1","14","","","","","","","","","","English","","","","WOS:001325241700064","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","Colon Cancer; Colonoscopy; Computer Vision; Deep Learning; Image Processing; PLUS PLUS; Segmentation; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HN4Z838S","journalArticle","2023","Li, QY; Yu, MY","Achieving Sales Forecasting with Higher Accuracy and Efficiency: A New Model Based on Modified Transformer","JOURNAL OF THEORETICAL AND APPLIED ELECTRONIC COMMERCE RESEARCH","","0718-1876","10.3390/jtaer18040100","","With the exponential expansion of e-commerce, an immense volume of historical sales data has been generated and amassed. This influx of data has created an opportunity for more accurate sales forecasting. While various sales forecasting methods and models have been applied in practice, existing ones often struggle to fully harness sales data and manage significant fluctuations. As a result, they frequently fail to make accurate predictions, falling short of meeting enterprise needs. Therefore, it is imperative to explore new models to enhance the accuracy and efficiency of sales forecasting. In this paper, we introduce a model tailored for sales forecasting based on a Transformer with encoder-decoder architecture and multi-head attention mechanisms. We have made specific modifications to the standard Transformer model, such as removing the Softmax layer in the last layer and adapting input embedding, position encoding, and feedforward network components to align with the unique characteristics of sales forecast data and the specific requirements of sales forecasting. The multi-head attention mechanism in our proposed model can directly compute the dot product results in a single step, addressing long-term time-dependent computation challenges while maintaining lower time complexity and greater interpretability. This enhancement significantly contributes to improving the model's accuracy and efficiency. Furthermore, we provide a comprehensive formula representation of the model for the first time, facilitating better understanding and implementation. We conducted experiments using sales datasets that incorporate various factors influencing sales forecasts, such as seasons, holidays, and promotions. The results demonstrate that our proposed model significantly outperforms seven selected benchmark methods, reducing RMSLE, RMSWLE, NWRMSLE, and RMALE by approximately 48.2%, 48.5%, 45.2, and 63.0%, respectively. Additionally, ablation experiments on the multi-head attention and the number of encoder-decoders validate the rationality of our chosen model parameters.","2023-12","2025-02-26 20:43:31","2025-02-26 20:43:31","","1990-2006","","4","18","","","","","","","","","","English","","","","WOS:001131450000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","deep learning; higher accuracy and efficiency; model; multi-head attention mechanisms; NEURAL-NETWORKS; sales forecasting; TIME-SERIES; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PQ6KG2UK","journalArticle","2023","Verma, A; Ranga, V; Vishwakarma, DK","A novel approach for forecasting PM2.5 pollution in Delhi using CATALYST","ENVIRONMENTAL MONITORING AND ASSESSMENT","","0167-6369","10.1007/s10661-023-12020-z","","Air pollution is one of the main environmental issues in densely populated urban areas like Delhi. Predictions of the PM2.5 concentration must be accurate for pollution reduction strategies and policy actions to succeed. This research article presents a novel approach for forecasting PM2.5 pollution in Delhi by combining a pre-trained CNN model with a transformer-based model called CATALYST (Convolutional and Transformer model for Air Quality Forecasting). This proposed strategy uses a mixture of the two models. To derive attributes of the PM2.5 timeline of data, a pre-existing CNN model is utilized to transform the data into visual representations, which are analyzed subsequently. The CATALYST model is trained to predict future PM2.5 pollution levels using a sliding window training approach on extracted features. The model is utilized for analyzing temporal dependencies in PM2.5 time-series data. This model incorporates the advancements in the transformer-based architecture initially designed for natural language processing applications. CATALYST combines positional encoding with the Transformer architecture to capture intricate patterns and variations resulting from diverse meteorological, geographical, and anthropogenic factors. In addition, an innovative approach is suggested for building input-output couples, intending to address the problem of missing or partial data in environmental time-series datasets while ensuring that all training data blocks are comprehensive. On a PM2.5 dataset, we analyze the proposed CATALYST model and compare its performance with other standard time-series forecasting approaches, such as ARIMA and LSTM. The outcomes of the experiments demonstrate that the suggested model works better than conventional methods and is a potential strategy for accurately forecasting PM2.5 pollution. The applicability of CATALYST to real-world scenarios can be tested by running more experiments on real-world datasets. This can help develop efficient pollution mitigation measures, impacting public health and environmental sustainability.","2023-12","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","12","195","","","","","","","","","","English","","","","WOS:001100910000004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","AIR-POLLUTION; ATHENS; Delhi; EMISSIONS; Forecasting; MODEL; OZONE; PM2.5; Time-Series; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D83G7Y3W","journalArticle","2022","Jamali, A; Mahdianpari, M; Mohammadimanesh, F; Homayouni, S","A deep learning framework based on generative adversarial networks and vision transformer for complex wetland classification using limited training samples","INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION","","1569-8432","10.1016/j.jag.2022.103095","","Wetlands have long been recognized among the most critical ecosystems globally, yet their numbers quickly diminish due to human activities and climate change. Thus, large-scale wetland monitoring is essential to provide efficient spatial and temporal insights for resource management and conservation plans. However, the main challenge is the lack of enough reference data for accurate large-scale wetland mapping. As such, the main objective of this study was to investigate the efficient deep-learning models for generating high-resolution and temporally rich training datasets for wetland mapping. The Sentinel-1 and Sentinel-2 satellites from the Euro-pean Copernicus program deliver radar and optical data at a high temporal and spatial resolution. These Earth observations provide a unique source of information for more precise wetland mapping from space. The second objective was to investigate the efficiency of vision transformers for complex landscape mapping. As such, we proposed a 3D Generative Adversarial Network (3D GAN) to best achieve these two objectives of synthesizing training data and a Vision Transformer model for large-scale wetland classification. The proposed approach was tested in three different study areas of Saint John, Sussex, and Fredericton, New Brunswick, Canada. The results showed the ability of the 3D GAN to stimulate and increase the number of training data and, as a result, increase the accuracy of wetland classification. The quantitative results also demonstrated the capability of jointly using data augmentation, 3D GAN, and Vision Transformer models with overall accuracy, average accuracy, and Kappa index of 75.61%, 73.4%, and 71.87%, respectively, using a disjoint data sampling strategy. Therefore, the proposed deep learning method opens a new window for large-scale remote sensing wetland classification.","2022-12","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","115","","","","","","","","","","English","","","","WOS:000892537000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;24<br/>Total Times Cited:&nbsp;&nbsp;24<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Convolutional neural network; Deep learning; Generative adversarial network; New Brunswick; Vision Transformer (ViT); Wetland classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F4HJ3IHL","journalArticle","2022","Sengar, N; Burget, R; Dutta, MK","A vision transformer based approach for analysis of plasmodium vivax life cycle for malaria prediction using thin blood smear microscopic images","COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE","","0169-2607","10.1016/j.cmpb.2022.106996","","Background and objectives: Microscopic images are an important part for haematologists in diagnosing var-ious diseases in the blood cell. Changes in blood cells are caused by malaria disease, and early diagnosis can prevent the disease from entering its severe stage.Methods: In this paper, an automated non-invasive and efficient deep learning-based framework is de-veloped for multi-class plasmodium vivax life cycle classification and malaria diagnosis. A multi-class microscopic blood cell of different plasmodium vivax life cycle stage dataset is analysed, and a diagnostic framework is designed. Several stages of the disease are examined and augmented through various tech-niques to make the framework robust in real-time. Generative adversarial network is specially designed to generate extended training samples of various life cycle stages to increase robustness of the resulting model. A special transformer-based neural network vision transformer is designed to improve generalisa-tion capabilities. Microscopic images are classified into multi classes of plasmodium vivax life cycle stage, where the keystone transformer layers extract relevant disease features from microscopic colour images, and the extracted relevant features are used to make predictive diagnostic decisions.Results: The capabilities of the vision transformer are computed and analysed by statistical parameters, and the performance of the vision transformer model is compared with baseline architectures, where it was evident that the performance of the vision transformer was significantly better, reaching 90.03% accuracy.Conclusions: A comprehensive comparison of the proposed framework to the state-of-the-art methods proves its efficiency in the classification of plasmodium vivax life cycle for malaria disease identification through thin blood smear microscopic images.(c) 2022 Elsevier B.V. All rights reserved.","2022-09","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","224","","","","","","","","","","English","","","","WOS:000839021700010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Deep Learning; Image Classification; Malaria Disease; Medical Imaging; Microscopic Images; Neural Networks; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2FFMVFMX","journalArticle","2022","Zhang, H; Yao, YB; Xu, CQ; Xu, W; Shi, JB","Transformer-Based Global Zenith Tropospheric Delay Forecasting Model","REMOTE SENSING","","2072-4292","10.3390/rs14143335","","Zenith tropospheric delay (ZTD) plays an important role in high-precision global navigation satellite system (GNSS) positioning and meteorology. At present, commonly used ZTD forecasting models comprise empirical, meteorological parameter, and neural network models. The empirical model can only fit approximate periodic variations, and its accuracy is relatively low. The accuracy of the meteorological parameter model depends heavily on the accuracy of the meteorological parameters. The recurrent neural network (RNN) is suitable for short-term series data prediction, but for long-term series, the ZTD prediction accuracy is clearly reduced. Long short-term memory (LSTM) has superior forecasting accuracy for long-term ZTD series; however, the LSTM model is complex, cannot be parallelized, and is time-consuming. In this study, we propose a novel ZTD time-series forecasting utilizing transformer-based machine-learning methods that are popular in natural language processing (NLP) and forecasting global ZTD, the training parameters provided by the global geodetic observing system (GGOS). The proposed transformer model leverages self-attention mechanisms by encoder and decoder modules to learn complex patterns and dynamics from long ZTD time series. The numeric results showed that the root mean square error (RMSE) of the forecasting ZTD results were 1.8 cm and mean bias, STD, MAE, and R 0.0, 1.7, 1.3, and 0.95, respectively, which is superior to that of the LSTM, RNN, convolutional neural network (CNN), and GPT3 series models. We investigated the global distribution of these accuracy indicators, and the results demonstrated that the accuracy in continents was superior to maritime space transformer ZTD forecasting model accuracy at high latitudes superior to that at low latitude. In addition to the overall accuracy improvement, the proposed transformer ZTD forecast model also mitigates the accuracy variations in space and time, thereby guaranteeing high accuracy globally. This study provides a novel method to estimate the ZTD, which could potentially contribute to precise GNSS positioning and meteorology.","2022-07","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","14","14","","","","","","","","","","English","","","","WOS:000834449200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","ALGORITHM; long short-term memory; recurrent neural network; transformer; zenith tropospheric delay; zenith tropospheric delay forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YGCG8XBC","journalArticle","2024","Li, HY; Chung, H; Li, ZT; Li, WP","Compressive Strength Prediction of Fly Ash-Based Concrete Using Single and Hybrid Machine Learning Models","BUILDINGS","","2075-5309","10.3390/buildings14103299","","The compressive strength of concrete is a crucial parameter in structural design, yet its determination in a laboratory setting is both time-consuming and expensive. The prediction of compressive strength in fly ash-based concrete can be accelerated through the use of machine learning algorithms with artificial intelligence, which can effectively address the problems associated with this process. This paper presents the most innovative model algorithms established based on artificial intelligence technology. These include three single models-a fully connected neural network model (FCNN), a convolutional neural network model (CNN), and a transformer model (TF)-and three hybrid models-FCNN + CNN, TF + FCNN, and TF + CNN. A total of 471 datasets were employed in the experiments, comprising 7 input features: cement (C), fly ash (FA), water (W), superplasticizer (SP), coarse aggregate (CA), fine aggregate (S), and age (D). Six models were subsequently applied to predict the compressive strength (CS) of fly ash-based concrete. Furthermore, the loss function curves, assessment indexes, linear correlation coefficient, and the related literature indexes of each model were employed for comparison. This analysis revealed that the FCNN + CNN model exhibited the highest prediction accuracy, with the following metrics: R2 = 0.95, MSE = 14.18, MAE = 2.32, SMAPE = 0.1, and R = 0.973. Additionally, SHAP was utilized to elucidate the significance of the model parameter features. The findings revealed that C and D exerted the most substantial influence on the model prediction outcomes, followed by W and FA. Nevertheless, CA, S, and SP demonstrated comparatively minimal influence. Finally, a GUI interface for predicting compressive strength was developed based on six models and nonlinear functional relationships, and a criterion for minimum strength was derived by comparison and used to optimize a reasonable mixing ratio, thus achieving a fast data-driven interaction that was concise and reliable.","2024-10","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","10","14","","","","","","","","","","English","","","","WOS:001342008600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;103</p>","","","ANN; artificial intelligence; CNN; compressive strength; concrete; FCNN; fly ash; hybrid models; machine learning; TF; TRANSFORMER NETWORKS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EHH8AM9A","journalArticle","2024","Himel, GMS; Islam, MM; Al-Aff, KA; Karim, SI; Sikder, MKU","Skin Cancer Segmentation and Classification Using Vision Transformer for Automatic Analysis in Dermatoscopy-Based Noninvasive Digital System","INTERNATIONAL JOURNAL OF BIOMEDICAL IMAGING","","1687-4188","10.1155/2024/3022192","","Skin cancer is a significant health concern worldwide, and early and accurate diagnosis plays a crucial role in improving patient outcomes. In recent years, deep learning models have shown remarkable success in various computer vision tasks, including image classification. In this research study, we introduce an approach for skin cancer classification using vision transformer, a state-of-the-art deep learning architecture that has demonstrated exceptional performance in diverse image analysis tasks. The study utilizes the HAM10000 dataset; a publicly available dataset comprising 10,015 skin lesion images classified into two categories: benign (6705 images) and malignant (3310 images). This dataset consists of high-resolution images captured using dermatoscopes and carefully annotated by expert dermatologists. Preprocessing techniques, such as normalization and augmentation, are applied to enhance the robustness and generalization of the model. The vision transformer architecture is adapted to the skin cancer classification task. The model leverages the self-attention mechanism to capture intricate spatial dependencies and long-range dependencies within the images, enabling it to effectively learn relevant features for accurate classification. Segment Anything Model (SAM) is employed to segment the cancerous areas from the images; achieving an IOU of 96.01% and Dice coefficient of 98.14% and then various pretrained models are used for classification using vision transformer architecture. Extensive experiments and evaluations are conducted to assess the performance of our approach. The results demonstrate the superiority of the vision transformer model over traditional deep learning architectures in skin cancer classification in general with some exceptions. Upon experimenting on six different models, ViT-Google, ViT-MAE, ViT-ResNet50, ViT-VAN, ViT-BEiT, and ViT-DiT, we found out that the ML approach achieves 96.15% accuracy using Google's ViT patch-32 model with a low false negative ratio on the test dataset, showcasing its potential as an effective tool for aiding dermatologists in the diagnosis of skin cancer.","2024-02-03","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","2024","","","","","","","","","","English","","","","WOS:001159863000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;85</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MURK7KXG","journalArticle","2024","Zhu, CZ; Chai, X; Xiao, YL; Liu, X; Zhang, RM; Yang, ZZ; Wang, ZY","Swin-Net: A Swin-Transformer-Based Network Combing with Multi-Scale Features for Segmentation of Breast Tumor Ultrasound Images","DIAGNOSTICS","","2075-4418","10.3390/diagnostics14030269","","Breast cancer is one of the most common cancers in the world, especially among women. Breast tumor segmentation is a key step in the identification and localization of the breast tumor region, which has important clinical significance. Inspired by the swin-transformer model with powerful global modeling ability, we propose a semantic segmentation framework named Swin-Net for breast ultrasound images, which combines Transformer and Convolutional Neural Networks (CNNs) to effectively improve the accuracy of breast ultrasound segmentation. Firstly, our model utilizes a swin-transformer encoder with stronger learning ability, which can extract features of images more precisely. In addition, two new modules are introduced in our method, including the feature refinement and enhancement module (RLM) and the hierarchical multi-scale feature fusion module (HFM), given that the influence of ultrasonic image acquisition methods and the characteristics of tumor lesions is difficult to capture. Among them, the RLM module is used to further refine and enhance the feature map learned by the transformer encoder. The HFM module is used to process multi-scale high-level semantic features and low-level details, so as to achieve effective cross-layer feature fusion, suppress noise, and improve model segmentation performance. Experimental results show that Swin-Net performs significantly better than the most advanced methods on the two public benchmark datasets. In particular, it achieves an absolute improvement of 1.4-1.8% on Dice. Additionally, we provide a new dataset of breast ultrasound images on which we test the effect of our model, further demonstrating the validity of our method. In summary, the proposed Swin-Net framework makes significant advancements in breast ultrasound image segmentation, providing valuable exploration for research and applications in this domain.","2024-02","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","3","14","","","","","","","","","","English","","","","WOS:001160149100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","breast tumor; LESIONS; medical image segmentation; swin-transformer; ultrasonic image segmentation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W6MVKMVS","journalArticle","2025","Ma, JD; Ma, ZH; Li, MY; Li, YJ; Tan, BY; Ding, SX","TRMD: a transformer-based reverse design model for quad-band metasurface absorbers","PHYSICA SCRIPTA","","0031-8949","10.1088/1402-4896/ad9558","","Metasurfaces have the ability to manipulate electromagnetic waves, which allows for the creation of functions such as perfect absorbers. The goal of a perfect absorber is to achieve high absorption peaks within a specific frequency band. This paper introduces an improved metasurface absorber structure that can achieve efficient absorption in four different frequency bands within the range of 2-9 GHz. In the field of metasurface design, deep learning methods have been recently applied due to their powerful data processing capabilities. However, these methods have primarily used fully connected neural networks and Long Short-Term Memory (LSTM). Despite their capabilities, fully connected networks and LSTM struggle to capture the global information in absorption spectrum data, leading to less accurate predictions. In this study, it was observed that the Transformer model can effectively capture global information using Multi-Head Self-Attention (MHSA) and is not affected by the length of the data. Based on this observation, this paper presents a lightweight model consisting solely of an encoder, achieving a Mean Squared Error (MSE) that is one-twentieth of the State-of-the-Art (SOTA). This model predicts metasurface structure based on target absorption spectra, enabling users to rapidly obtain metasurface absorber structures directly from input absorption spectra. The model consists of two parts: embedding and encoder. The embedding processes input absorption spectra data and adds positional encoding, while the encoder extracts spectral data features. MHSA effectively captures contextual information of absorption spectra, emphasizing key feature information. The final model achieved a MSE convergence of 2 x 10(-4) and a coefficient of determination (R-2)value of 0.998, successfully optimizing the design of multi-band metasurface absorbers. Moreover, the predicted results from the model exhibit an absorption spectrum that is highly consistent with the target spectrum.","2025-01-01","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","1","100","","","","","","","","","","English","","","","WOS:001370993500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","ABSORPTION; attention mechanism; deep learning; INVERSE DESIGN; META-ATOMS; METAMATERIAL ABSORBER; multi-band metasurface absorber; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NRZRTNRP","journalArticle","2024","Zhang, XY; Li, LJ; Shi, H; Dong, ZS","An ensemble Swin-LE model with residuals for rolling bearing fault diagnosis","JOURNAL OF THE BRAZILIAN SOCIETY OF MECHANICAL SCIENCES AND ENGINEERING","","1678-5878","10.1007/s40430-024-04759-4","","Deep learning-based rolling bearing fault diagnosis has been widely used in practical production. In this paper, an ensemble Swin-LE Transformer model with residuals is proposed to address the problems of background noise interference, difficulty in fault feature extraction and insufficient generalisation of the model. A local enhancement module is proposed and applied to the Swin Transformer, named Swin-LE Transformer, to enhance the model fault feature extraction and thus improve the diagnostic accuracy. An ensemble learning architecture with residuals is also proposed based on complete ensemble empirical modal decomposition with adaptive noise (CEEMDAN). The architecture structure uses the original signal as the residual structure for fusion voting to improve the overall generalisation capability of the model. The performance of the Swin-LE Transformer under this architecture is analysed against the original Swin Transformer and networks such as ViT and YOLO through experimental simulations on different bearing datasets, and the results show that the proposed ensemble Swin-LE Transformer achieves an accuracy of 98.62%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document}, which is higher than the original network by 2.4%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document}. Based on this, a multi-noise set was designed to verify the performance of the proposed architecture. The experimental results show that the proposed fusion architecture is still 2.94%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document} higher at SNR-10 dB compared to the single-vote ensemble learning model, demonstrating its improved robustness.","2024-04","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","4","46","","","","","","","","","","English","","","","WOS:001184117200003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","CONVOLUTIONAL NEURAL-NETWORK; Deep learning; Ensemble learning; Fault diagnosis; IDENTIFICATION; Rolling bearings; ROTATING MACHINERY; Swin Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DJHU5QLT","journalArticle","2025","Cutur, ES; Inan, NG","Multi-class Classification of Retinal Eye Diseases from Ophthalmoscopy Images Using Transfer Learning-Based Vision Transformers","JOURNAL OF IMAGING INFORMATICS IN MEDICINE","","2948-2925","10.1007/s10278-025-01416-7","","This study explores a transfer learning approach with vision transformers (ViTs) and convolutional neural networks (CNNs) for classifying retinal diseases, specifically diabetic retinopathy, glaucoma, and cataracts, from ophthalmoscopy images. Using a balanced subset of 4217 images and ophthalmology-specific pretrained ViT backbones, this method demonstrates significant improvements in classification accuracy, offering potential for broader applications in medical imaging. Glaucoma, diabetic retinopathy, and cataracts are common eye diseases that can cause vision loss if not treated. These diseases must be identified in the early stages to prevent eye damage progression. This paper focuses on the accurate identification and analysis of disparate eye diseases, including glaucoma, diabetic retinopathy, and cataracts, using ophthalmoscopy images. Deep learning (DL) has been widely used in image recognition for the early detection and treatment of eye diseases. In this study, ResNet50, DenseNet121, Inception-ResNetV2, and six variations of ViT are employed, and their performance in diagnosing diseases such as glaucoma, cataracts, and diabetic retinopathy is evaluated. In particular, the article uses the vision transformer model as an automated method to diagnose retinal eye diseases, highlighting the accuracy of pre-trained deep transfer learning (DTL) structures. The updated ViT#5 model with the augmented-regularized pre-trained model (AugReg ViT-L/16_224) and learning rate of 0.00002 outperforms the state-of-the-art techniques, obtaining a data-based accuracy score of 98.1% on a publicly accessible retinal ophthalmoscopy image dataset, which includes 4217 images. In most categories, the model outperforms other convolutional-based and ViT models in terms of accuracy, precision, recall, and F1 score. This research contributes significantly to medical image analysis, demonstrating the potential of AI in enhancing the precision of eye disease diagnoses and advocating for the integration of artificial intelligence in medical diagnostics.","2025-01-27","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","","","","","","","","","","","English","","","","WOS:001406576300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Convolutional neural networks; Deep learning; LIVER SEGMENTATION; Multi-class classification; Retinal images; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BIVKVZ87","journalArticle","2024","Zhang, HY; Polson, JS; Wang, ZC; Nael, K; Rao, NM; Speier, WF; Arnold, CW","A Deep Learning Approach to Predict Recanalization First-Pass Effect following Mechanical Thrombectomy in Patients with Acute Ischemic Stroke","AMERICAN JOURNAL OF NEURORADIOLOGY","","0195-6108","10.3174/ajnr.A8272","","BACKGROUND AND PURPOSE: Following endovascular thrombectomy in patients with large-vessel occlusion stroke, successful recanalization from 1 attempt, known as the first-pass effect, has correlated favorably with long-term outcomes. Pretreatment imaging may contain information that can be used to predict the first-pass effect. Recently, applications of machine learning models have shown promising results in predicting recanalization outcomes, albeit requiring manual segmentation. In this study, we sought to construct completely automated methods using deep learning to predict the first-pass effect from pretreatment CT and MR imaging. MATERIALS AND METHODS: Our models were developed and evaluated using a cohort of 326 patients who underwent endovascular thrombectomy at UCLA Ronald Reagan Medical Center from 2014 to 2021. We designed a hybrid transformer model with nonlocal and cross-attention modules to predict the first-pass effect on MR imaging and CT series. RESULTS: The proposed method achieved a mean 0.8506 (SD, 0.0712) for cross-validation receiver operating characteristic area under the curve (ROC-AUC) on MR imaging and 0.8719 (SD, 0.0831) for cross-validation ROC-AUC on CT. When evaluated on the prospective test sets, our proposed model achieved a mean ROC-AUC of 0.7967 (SD, 0.0335) with a mean sensitivity of 0.7286 (SD, 0.1849) and specificity of 0.8462 (SD, 0.1216) for MR imaging and a mean ROC-AUC of 0.8051 (SD, 0.0377) with a mean sensitivity of 0.8615 (SD, 0.1131) and specificity 0.7500 (SD, 0.1054) for CT, respectively, representing the first classification of the first-pass effect from MR imaging alone and the first automated first-pass effect classification method in CT. CONCLUSIONS: Results illustrate that both nonperfusion MR imaging and CT from admission contain signals that can predict a successful first-pass effect following endovascular thrombectomy using our deep learning methods without requiring time-intensive manual segmentation.","2024-08","2025-02-26 20:43:31","2025-02-26 20:43:31","","1044-1052","","8","45","","","","","","","","","","English","","","","WOS:001246565200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","THROMBOLYSIS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P6D96ZKG","journalArticle","2024","Zheng, ZZ; Liu, YX; Dong, JX; Zhao, PF; Qiao, YC; Sun, SP; Huang, YX","A novel jujube tree trunk and branch salient object detection method for catch-and-shake robotic visual perception","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.124022","","Visual perception has become a prerequisite for automated jujube harvesting robot operations under complex orchard conditions. Catch -and -Shake harvesting, as the most efficient and common harvesting method, has widely been applied on various manually operated harvesters to complete large -area jujube fruit harvesting. However, the main factors restricting the development of existing harvesters are labor shortage, high labor cost, and low operating efficiency. To address the issues, we designed a catch -and -shake harvesting robot for jujube tree trunks and branches visual perception that can provide a barrier -free catch -and -shake operation area and guide the manipulator to reach the area to complete the harvesting operation. Meanwhile, a visual perception system including tree trunks and branches detection, skeleton extraction, catch -and -shake area confirmation was presented to guide robot intelligent operations. In the visual perception system, a novel salient object detection model called feature intersection and fusion Transformer (FIT -Transformer) network was proposed to split branches and background to provide reference for determining safe catch -and -shake areas. Moreover, we designed a diverse feature aggregation (DFA) and an attention feature fusion module (AFFM) to strengthen feature learning capabilities and obtain robust perception models. Comparative experimental results showed that our proposed FIT -Transformer model outperformed 12 state-of-the-art (SOTA) algorithms including C 2 FNet, RAS, BASNet, U 2 Net, SCRNet, PiCANet, EDRNet, EGNet, ICONR, VST, TransSOD and ABiU_Net. Specifically, the segmentation accuracy of jujube tree trunks and branches using our method showed the satisfactory result on five evaluation indexes under natural environment (the EM, SM, WF, FM and MAE reached 0.9713, 0.8991, 0.8854, 0.8905, and 0.0302, respectively). Field experiments also proved that our method could meet the requirements of operational accuracy and real-time operations.","2024-10-01","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","251","","","","","","","","","","English","","","","WOS:001232681800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","Catch-and-Shake harvesting; Deep learning; Robot; Salient object detection; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W2PUIWR5","journalArticle","2023","Li, Y; Xie, WX; Yang, Y; Mei, Q; Wang, ZS; Li, ZX; Wang, P","Research on the carbon emissions traceability inventory and multi-horizon prediction of ship carbon emissions: a case study of Tianjin Port","FRONTIERS IN MARINE SCIENCE","","2296-7745","10.3389/fmars.2023.1174411","","IntroductionIn recent years, the adverse effects of escalating maritime trade and international shipping- particularly in regard to increased greenhouse gas emissions and their impact on human health- have come to the fore. These issues have thus instigated a surge in pressure to enhance the regulation of shipborne carbon emissions. MethodsThe study utilized the automatic identification system (AIS) data, Lloyd's register data, and pollutant emission parameters to calculate the carbon emissions from the main engine, auxiliary engine, and boiler of vessels under varying sailing conditions, utilizing the dynamic method of ships. In relation to geographic information and ship trajectory, a comprehensive inventory of ship carbon emissions was developed, revealing pronounced spatiotemporal characteristics. To assure the accuracy of the substantial AIS dataset, procedures including data cleaning, trajectory integration, data fusion, and completion were executed. Such processes are indispensable, given the potential for transmission and storage errors associated with AIS data. To forecast CO2 emissions over diverse time intervals, a temporal fusion transformer model equipped with attention mechanisms was employed. ResultThe paper furnishes a case study on Tianjin Port, wherein a high-resolution carbon emissions inventory was devised based on AIS data acquired from vessels. This inventory was subsequently employed to generate multi-feature predictions of future carbon emissions. Given the optimal parameter configuration, the proposed method attained P-50 and P-90 values of 0.244 and 0.118 respectively, thereby demonstrating its efficacy. DiscussionRecognizing the sources of ship carbon emissions in this region and forecasting such emissions in the future substantiates that this method accurately portrays the laws of ship carbon emissions. Our study provides a scientific basis for decision-making in port and pollution management, enabling the creation of targeted emission reduction policies for ships.","2023-06-21","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","10","","","","","","","","","","English","","","","WOS:001019440700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;82</p>","","","AIS; AIS-BASED APPROACH; carbon emissions inventory; CHINA; forecast CO2 emissions; HEALTH; IMPACTS; NEURAL-NETWORKS; ship pollutant; STATE; Tianjin Port; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U44PDXB5","journalArticle","2023","Ghosh, B; Sathi, KA; Hosain, MK; Hossain, MA; Dewan, MAA; Kouzani, AZ","ViTab Transformer Framework for Predicting Induced Electric Field and Focality in Transcranial Magnetic Stimulation","IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING","","1534-4320","10.1109/TNSRE.2023.3331258","","Transcranial magnetic stimulation is an electromagnetic induction-based non-invasive therapeutic technique for neurological diseases. For finding new clinical applications and enhancing the efficacy of TMS in existing neurological disorders, the current study focuses on a deep learning-based prediction model as an alternative to time-consuming electromagnetic (EM) simulation software. The main bottleneck of the existing prediction models is to consider very few input parameters of a standard coil such as coil type and coil position for predicting an output of electric field value. To overcome this limitation, a transformer-based prediction model titled as ViTab transformer is developed in this work to predict electric field (E-max), focality or area of stmulation (S-half), and volume of stimulation (V-half) by considering several input parameters such as sources of MRI images, types of coils, coil position, rate of change of current, brain tissues conductivity, and coil distance from the scalp. The proposed framework consists of a vision and a tab transformer to handle both image and tabular-type data. The prediction performance of the offered model is evaluated in terms of coefficient determination, R-2 score, for E-max, V-half, and S-half in the testing phase. The obtained result in terms of R-2 score for E-max, V-half, and S-half are found 0.97, 0.87, and 0.90 respectively. The results indicate that the suggested ViTab transformer model can predict electric field as well as focality more accurately than the current state-of-the-art methods. The reduced computational time, as well as efficient prediction accuracy, resembles that ViTab transformer can assist the neuroscientist and neurosurgeon prior to providing superior TMS treatment in near future.","2023","2025-02-26 20:43:31","2025-02-26 20:43:31","","4713-4724","","","31","","","","","","","","","","English","","","","WOS:001115758600003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","BRAIN; CONDUCTIVITY; DISORDER; electric field; EXPOSURE; focality; MRI images; regression; SAFETY; Transcranial magnetic stimulation; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9YGPGE6D","journalArticle","2024","Theodoridis, G; Tsadiras, A","Retail Demand Forecasting: A Multivariate Approach and Comparison of Boosting and Deep Learning Methods","INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS","","0218-2130","10.1142/S0218213024500015","","Retail demand forecasting is a highly intricate and multilevel problem as it may include numerous products, under multiple categories, and potentially sold in many different stores. Forecasts may also process products in isolation or collectively so as to detect mutual correlations. In technical terms, retail demand forecasting may be broken down to a multivariate time series forecasting problem where the time axis is prevalent and introduces added complexity which necessitates proper usage of advanced methodologies with machine/deep learning backgrounds. Popular boosting regressors, such as XGBoost and LightGBM, are excellent machine learning candidates with extensive bibliographic backgrounds covering multiple scientific fields and applications including generic multivariate time series forecasts. The Temporal Convolutional Network and the Temporal Fusion Transformer are recently proposed deep neural network architectures that found success in specific multivariate scenarios but are yet to be tested in a variety of related fields such as retail demand forecasting. Therefore, within this paper, these novel in-the-field models are compared to the aforementioned boosting approaches alongside popular statistical univariate methods, namely Exponential Smoothing and SARIMA. To properly compare the selected models and attempt to generalize their usability, two separate datasets are analyzed and forecasted; an item sales dataset with 500 time series and a category sales dataset with 540 time series. The findings suggest that the deep learning solutions are the better predictors, with the Transformer model surpassing the Boosting solutions by up to 16.8% sMAPE decrease and the statistical approaches by up to 28.6% decrease, further substantiating the notion that deep learning techniques are exceptionally promising in handling large-scale, non-linear and outlier data whilst suggesting that retail demand forecasting does benefit from multivariate approaches and the application of advanced machine learning methods.","2024-06","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","04","33","","","","","","","","","","English","","","","WOS:001231158100003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","boosting models; Deep neural networks; multivariate forecasting; PREDICTION; REGRESSION; retail demand forecasting; SALES; SELECTION; SUPPORT VECTOR MACHINES; time series forecasting; TIME-SERIES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H7J43LXU","journalArticle","2024","Wu, XL; Zhang, DG; Li, GY; Gao, X; Metcalfe, B; Chen, L","Data augmentation for invasive brain-computer interfaces based on stereo-electroencephalography (SEEG)","JOURNAL OF NEURAL ENGINEERING","","1741-2560","10.1088/1741-2552/ad200e","","Objective. Deep learning is increasingly used for brain-computer interfaces (BCIs). However, the quantity of available data is sparse, especially for invasive BCIs. Data augmentation (DA) methods, such as generative models, can help to address this sparseness. However, all the existing studies on brain signals were based on convolutional neural networks and ignored the temporal dependence. This paper attempted to enhance generative models by capturing the temporal relationship from a time-series perspective. Approach. A conditional generative network (conditional transformer-based generative adversarial network (cTGAN)) based on the transformer model was proposed. The proposed method was tested using a stereo-electroencephalography (SEEG) dataset which was recorded from eight epileptic patients performing five different movements. Three other commonly used DA methods were also implemented: noise injection (NI), variational autoencoder (VAE), and conditional Wasserstein generative adversarial network with gradient penalty (cWGANGP). Using the proposed method, the artificial SEEG data was generated, and several metrics were used to compare the data quality, including visual inspection, cosine similarity (CS), Jensen-Shannon distance (JSD), and the effect on the performance of a deep learning-based classifier. Main results. Both the proposed cTGAN and the cWGANGP methods were able to generate realistic data, while NI and VAE outputted inferior samples when visualized as raw sequences and in a lower dimensional space. The cTGAN generated the best samples in terms of CS and JSD and outperformed cWGANGP significantly in enhancing the performance of a deep learning-based classifier (each of them yielding a significant improvement of 6% and 3.4%, respectively). Significance. This is the first time that DA methods have been applied to invasive BCIs based on SEEG. In addition, this study demonstrated the advantages of the model that preserves the temporal dependence from a time-series perspective.","2024-02-01","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","1","21","","","","","","","","","","English","","","","WOS:001169721100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;86</p>","","","brain-computer interface (BCI); data augmentation; deep learning; ELECTROCORTICOGRAPHIC SIGNALS; stereo-electroencephalography (SEEG); transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SS7J55UW","journalArticle","2024","Shi, XF","Driver Distraction Behavior Detection Framework Based on the DWPose Model, Kalman Filtering, and Multi-Transformer","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3406605","","Driver distraction behavior recognition is crucial for improving driving safety. Traditional end-to-end driver distraction detection models are susceptible to factors such as the driving environment, the in-vehicle background, and the driver characteristics, which leads to the low performance of the models in cross-dataset testing. To address this problem, this paper proposes a driver distraction detection framework based on the Distillation for Whole-body Pose estimators (DWPose), Kalman filtering, and Multi-Transformer (DKT). DKT consists of a feature extraction calibration module and a distraction behavior recognition module. In the feature extraction calibration module, a pre-trained DWPose model is used to extract the facial, hand, and body keypoints of the driver, and improved Kalman filtering algorithm is applied for tracking and correction keypoint sequences. In the distraction behavior recognition module, a Multi-Transformer model is used to model the relationships between keypoint sequences and the distraction behaviors of various parts of the human body. The model can extract features from the action-behavior process of different body parts and perform weighted fusion to obtain the final distraction behavior category. The results of experiments show that DKT can accurately recognize the distraction behaviors of drivers, and maintains high cross-test accuracy under the State Farm Driver 2 (SFD2) and 100-Driver datasets, thereby demonstrating its high generalization performance. Specifically, when trained using the 100-Driver dataset, the mAcc of DKT on the 100-Driver and SFD2 test sets are respectively 98.03% and 73.88%, thus exhibiting respective improvements of 1.38% and 19.56%, as compared to the MobileNetV2-CA model. The results verify that the proposed DKT is an advanced model in the field of driver distraction recognition and can provide technical support for driver distraction warning.","2024","2025-02-26 20:43:31","2025-02-26 20:43:31","","80579-80589","","","12","","","","","","","","","","English","","","","WOS:001246129600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","deep learning; Driver distraction; driving safety; Kalman filtering; RECOGNITION; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MUDKDJ3C","journalArticle","2023","Karyukin, V; Rakhimova, D; Karibayeva, A; Turganbayeva, A; Turarbek, A","The neural machine translation models for the low-resource Kazakh-English language pair","PEERJ COMPUTER SCIENCE","","2376-5992","10.7717/peerj-cs.1224","","The development of the machine translation field was driven by people's need to communicate with each other globally by automatically translating words, sentences, and texts from one language into another. The neural machine translation approach has become one of the most significant in recent years. This approach requires large parallel corpora not available for low-resource languages, such as the Kazakh language, which makes it difficult to achieve the high performance of the neural machine translation models. This article explores the existing methods for dealing with low-resource languages by artificially increasing the size of the corpora and improving the performance of the Kazakh-English machine translation models. These methods are called forward translation, backward translation, and transfer learning. Then the Sequence-to-Sequence (recurrent neural network and bidirectional recurrent neural network) and Transformer neural machine translation architectures with their features and specifications are concerned for conducting experiments in training models on parallel corpora. The experimental part focuses on building translation models for the high-quality translation of formal social, political, and scientific texts with the synthetic parallel sentences from existing monolingual data in the Kazakh language using the forward translation approach and combining them with the parallel corpora parsed from the official government websites. The total corpora of 380,000 parallel Kazakh-English sentences are trained on the recurrent neural network, bidirectional recurrent neural network, and Transformer models of the OpenNMT framework. The quality of the trained model is evaluated with the BLEU, WER, and TER metrics. Moreover, the sample translations were also analyzed. The RNN and BRNN models showed a more precise translation than the Transformer model. The Byte-Pair Encoding tokenization technique showed better metrics scores and translation than the word tokenization technique. The Bidirectional recurrent neural network with the Byte-Pair Encoding technique showed the best performance with 0.49 BLEU, 0.51 WER, and 0.45 TER.","2023-02-08","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","9","","","","","","","","","","English","","","","WOS:000933018100005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Backward translation; BRNN; English; Forward translation; Kazakh; Neural machine translation; OpenNMT; RNN; Seq2Seq; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WMHQGQ9T","journalArticle","2022","Tan, KL; Lee, CP; Anbananthen, KSM; Lim, KM","RoBERTa-LSTM: A Hybrid Model for Sentiment Analysis With Transformer and Recurrent Neural Network","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3152828","","Due to the rapid development of technology, social media has become more and more common in human daily life. Social media is a platform for people to express their feelings, feedback, and opinions. To understand the sentiment context of the text, sentiment analysis plays the role to determine whether the sentiment of the text is positive, negative, neutral or any other personal feeling. Sentiment analysis is prominent from the perspective of business or politics where it highly impacts the strategic decision making. The challenges of sentiment analysis are attributable to the lexical diversity, imbalanced dataset and long-distance dependencies of the texts. In view of this, a data augmentation technique with GloVe word embedding is leveraged to synthesize more lexically diverse samples by similar word vector replacements. The data augmentation also focuses on the oversampling of the minority classes to mitigate the imbalanced dataset problems. Apart from that, the existing sentiment analysis mostly leverages sequence models to encode the long-distance dependencies. Nevertheless, the sequence models require a longer execution time as the processing is done sequentially. On the other hand, the Transformer models require less computation time with parallelized processing. To that end, this paper proposes a hybrid deep learning method that combines the strengths of sequence model and Transformer model while suppressing the limitations of sequence model. Specifically, the proposed model integrates Robustly optimized BERT approach and Long Short-Term Memory for sentiment analysis. The Robustly optimized BERT approach maps the words into a compact meaningful word embedding space while the Long Short-Term Memory model captures the long-distance contextual semantics effectively. The experimental results demonstrate that the proposed hybrid model outshines the state-of-the-art methods by achieving F1-scores of 93%, 91%, and 90% on IMDb dataset, Twitter US Airline Sentiment dataset, and Sentiment140 dataset, respectively.","2022","2025-02-26 20:43:31","2025-02-26 20:43:31","","21517-21525","","","10","","","","","","","","","","English","","","","WOS:000764063400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;74<br/>Total Times Cited:&nbsp;&nbsp;74<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Analytical models; Blogs; Computational modeling; long short-term memory; LSTM; recurrent neural network; RNN; RoBERTa; Sentiment; Sentiment analysis; Social networking (online); Testing; Training; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G87S98KP","journalArticle","2022","Nguyen, HQ; Borson, S; Khang, P; Langer-Gould, A; Wang, SE; Carrol, J; Lee, JS","Dementia diagnosis and utilization patterns in a racially diverse population within an integrated health care delivery system","ALZHEIMERS & DEMENTIA-TRANSLATIONAL RESEARCH & CLINICAL INTERVENTIONS","","2352-8737","10.1002/trc2.12279","","IntroductionIn an effort to identify improvement opportunities for earlier dementia detection and care within a large, integrated health care system serving diverse Medicare Advantage (MA) beneficiaries, we examined where, when, and by whom Alzheimer's disease and related dementias (ADRD) diagnoses are recorded as well as downstream health care utilization and life care planning. MethodsPatients 65 years and older, continuously enrolled in the Kaiser Foundation health plan for at least 2 years, and with a first ADRD diagnosis between January 1, 2015, and December 31, 2018, comprised the incident cohort. Electronic health record data were used to identify site and source of the initial diagnosis (clinic vs hospital-based, provider type), health care utilization in the year before and after diagnosis, and end-of-life care. ResultsADRD prevalence was 5.5%. A total of 25,278 individuals had an incident ADRD code (rate: 1.2%) over the study period-nearly half during a hospital-based encounter. Hospital-diagnosed patients had higher comorbidities, acute care use before and after diagnosis, and 1-year mortality than clinic-diagnosed individuals (36% vs 11%). Many decedents (58%-72%) received palliative care or hospice. Of the 55% diagnosed as outpatients, nearly two-thirds were diagnosed by dementia specialists; when used, standardized cognitive assessments indicated moderate stage ADRD. Despite increases in advance care planning and visits to dementia specialists in the year after diagnosis, acute care use also increased for both clinic- and hospital-diagnosed cohorts. DiscussionSimilar to other MA plans, ADRD is under-diagnosed in this health system, compared to traditional Medicare, and diagnosed well beyond the early stages, when opportunities to improve overall outcomes are presumed to be better. Dementia specialists function primarily as consultants whose care does not appear to mitigate acute care use. Strategic targets for ADRD care improvement could focus on generating pragmatic evidence on the value of proactive detection and tracking, care planning, and the role of specialists in chronic care management.","2022","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","1","8","","","","","","","","","","English","","","","WOS:000907667800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","ASSOCIATIONS; dementia; diagnosis; DISEASE; END; integrated delivery system; MANAGED CARE; Medicare Advantage; MINI-MENTAL-STATE; OLDER-ADULTS; OUTCOMES; PREVALENCE; QUALITY; utilization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"44A9LTF6","journalArticle","2025","He, YF; Zhou, Y; Qian, Y; Liu, JJ; Zhang, JY; Liu, DB; Wu, Q","Cardioattentionnet: advancing ECG beat characterization with a high-accuracy and portable deep learning model","FRONTIERS IN CARDIOVASCULAR MEDICINE","","2297-055X","10.3389/fcvm.2024.1473482","","Introduction The risk of mortality associated with cardiac arrhythmias is considerable, and their diagnosis presents significant challenges, often resulting in misdiagnosis. This situation highlights the necessity for an automated, efficient, and real-time detection method aimed at enhancing diagnostic accuracy and improving patient outcomes.Methods The present study is centered on the development of a portable deep learning model for the detection of arrhythmias via electrocardiogram (ECG) signals, referred to as CardioAttentionNet (CANet). CANet integrates Bi-directional Long Short-Term Memory (BiLSTM) networks, Multi-head Attention mechanisms, and Depthwise Separable Convolution, thereby facilitating its application in portable devices for early diagnosis. The architecture of CANet allows for effective processing of extended ECG patterns and detailed feature extraction without a substantial increase in model size.Results Empirical results indicate that CANet outperformed traditional models in terms of predictive performance and stability, as confirmed by comprehensive cross-validation. The model demonstrated exceptional capabilities in detecting cardiac arrhythmias, surpassing existing models in both cross-validation and external testing scenarios. Specifically, CANet achieved high accuracy in classifying various arrhythmic events, with the following accuracies reported for different categories: Normal (97.37 +/- 0.30%), Supraventricular (98.09 +/- 0.25%), Ventricular (92.92 +/- 0.09%), Atrial Fibrillation (99.07 +/- 0.13%), and Unclassified arrhythmias (99.68 +/- 0.06%). In external evaluations, CANet attained an average accuracy of 94.41%, with the area under the curve (AUC) for each category exceeding 99%, thereby demonstrating its substantial clinical applicability and significant advancements over traditional models.Discussion The deep learning model proposed in this study has the potential to enhance the accuracy of early diagnosis for various types of arrhythmias. Looking ahead, this technology is anticipated to provide improved medical services for patients with heart disease through continuous, non-invasive monitoring and timely intervention.","2025-01-06","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","11","","","","","","","","","","English","","","","WOS:001399393200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","cardiac arrhythmias; CLASSIFICATION; electrocardiogram; Long Short-Term Memory; MobileNet; MYOCARDIAL-INFARCTION; NETWORK; portable deep learning model; RHYTHM; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CGADHJ9N","journalArticle","2025","Bhuyan, HK; Unhelkar, B; Shankar, SS; Chakrabarti, P","Mutual Information-Based Generalisation Gap Analysis Using Deep Learning Model","JOURNAL OF INFORMATION & KNOWLEDGE MANAGEMENT","","0219-6492","10.1142/S0219649225500017","","Most deep learning models face difficulties in analysing image information due to the concept of information bottlenecks and their corresponding methodologies. But, the information bottleneck is used for discarding redundant data and trying to maximise in favour of data directly relevant to the task-oriented information. However, managing information bottlenecks is challenging in the learning model process. Although convolutional neural networks are designed for small-scale processing, their inductive bias makes it difficult to learn contextual features. Thus, we have considered the theoretical learning model to justify the advantages of information bottleneck in deep learning model. We tried to use a fundamental information bottleneck in the vision transformer model. The channel density module cleans up task-related data, while the collected image representations are encouraged to be diverse through local connections in cumulative local transformer blocks. We considered the encoder and decoder methods that analyse the information bottleneck techniques in the deep learning model. This paper presents a rigorous learning theory that mathematically links information bottlenecks for generalisation errors, demonstrating the usefulness of information bottlenecks in deep learning. Our approach suggests that limiting information bottlenecks is crucial for managing errors in deep learning techniques. We conducted experiments across various mathematical models and learning environments to test the validity of our new mathematical insights. In many cases, generalisation errors correspond to unwanted information at hidden levels. We have considered boundary approaches using various scaling parameters and dimensions for the degree of information bottleneck. As per the estimation loss and error by different correlation approaches using generalisation gap methods, we found Spearman correlation having loss (0.86) and error (0.758), whereas Pearson correlation having loss (0.85) and error (0.76), respectively. We also considered outputs for model compression metrics and analysed them through comparative performance.","2025-02","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","01","24","","","","","","","","","","English","","","","WOS:001385821000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","adversarial generative model; CLASSIFICATION; convolutional neural network (CNN); Healthcare image; information bottleneck; local features; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4PW8T98B","journalArticle","2024","Benet, D; Costa, F; Widiwijayanti, C","Volcanic Ash Classification Through Machine Learning","GEOCHEMISTRY GEOPHYSICS GEOSYSTEMS","","1525-2027","10.1029/2023GC011224","","Volcanic ash provides information that can help understanding the evolution of volcanic activity during the early stages of a crisis and possible transitions toward different eruptive styles. Ash consists of particles from a range of origins within the volcanic system and its analysis can be indicative of the processes driving the eruptive activity. However, classifying ash particles into different types is not straightforward. Diagnostic observations for particle classification are not standardized and vary across samples. Here we explore the use of machine learning (ML) to improve the classification accuracy and reproducibility. We use a curated database of ash particles (VolcAshDB) to optimize and train two ML-based models: Extreme Gradient Boosting (XGBoost) that uses the measured physical attributes of the particles, from which predictions are interpreted by the SHapley Additive exPlanations (SHAP) method, and a Vision Transformer (ViT) that classifies binocular, multi-focused, particle images. We find that the XGBoost has an overall classification accuracy of 0.77 (macro F1-score), and specific features of color (hue_mean) and texture (correlation) are the most discriminant between particle types. Classification using the particle images and the ViT is more accurate (macro F1-score of 0.93), with performances varying from 0.85 for samples of dome explosions, to 0.95 for phreatic and subplinian events. Notwithstanding the success of the classification algorithms, the training dataset is limited in number of particles, ranges of eruptive styles, and volcanoes. Thus, the algorithms should be tested further with additional samples, and it is likely that classification for a given volcano is more accurate than between volcanoes. Volcanic ash particles are classified through machine learning algorithms into juvenile, lithic, free-crystal and altered material types Discriminant features per each particle type are revealed by the Shapley values of XGBoost's predictions Classification by a Vision Transformer model is very accurate and could be used by volcano observatories","2024-03","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","3","25","","","","","","","","","","English","","","","WOS:001184588300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;81</p>","","","ERUPTION; EVOLUTION; INSIGHTS; interpretable AI; machine learning; SAKURAJIMA VOLCANO; SHAP; TEXTURE; vision transformer; volcanic ash classification; XGBoost","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZIHM4YWF","journalArticle","2024","Jamshidi, B; Hakak, S; Lu, RX","A Self-Attention Mechanism-Based Model for Early Detection of Fake News","IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS","","2329-924X","10.1109/TCSS.2023.3322160","","Extensive studies have indicated that fake news has become one of the major threats to our social system (e.g., influencing public opinion, financial markets, journalism, and health system), and its impact cannot be understated, particularly in our current socially and digitally connected society. In the past years, this problem has been investigated from different perspectives and various disciplines, such as computer science, political science, information science, and linguistics. Even though such efforts have proposed many helpful solutions, it remains challenging to detect fake news in its early phases of dissemination. Based on previously reported studies, detecting fake news early after its propagation is a very tough task due to the unavailability of context-based features within the first hours of spreading and the ineffectiveness of merely content-based features methods. To address this challenge, we propose a new framework for detecting fake news in the early stages of its propagation. The first three components of the proposed framework convert each news article's propagation network into a sequence of nodes after preprocessing and feature extraction. The last module of our framework leverages a self-attention mechanism-based encoder. Self-attention technique is the core of the well-known transformer model, which has achieved promising results in different areas, especially in complex tasks such as language translation. In the module, a new representation of the input sequence is generated, which is mapped to a label for the news article by a binary classifier. We evaluated our method on two datasets and achieved promising results. The achieved F1 scores by the proposed model on the GossipCop and PolitiFact datasets are higher than the best baseline model by 9% and 6%, respectively.","2024-08","2025-02-26 20:43:31","2025-02-26 20:43:31","","5241-5252","","4","11","","","","","","","","","","English","","","","WOS:001088287500002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Context modeling; Deep learning; Early detection; fake news; Fake news; Feature extraction; misinformation; propagation-network-based detection; social media; Social networking (online); Visualization; Writing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UFUFXCZS","journalArticle","2022","Jeong, S; Cheon, W; Cho, S; Han, Y","Clinical applicability of deep learning-based respiratory signal prediction models for four-dimensional radiation therapy","PLOS ONE","","1932-6203","10.1371/journal.pone.0275719","","For accurate respiration gated radiation therapy, compensation for the beam latency of the beam control system is necessary. Therefore, we evaluate deep learning models for predicting patient respiration signals and investigate their clinical feasibility. Herein, long short-term memory (LSTM), bidirectional LSTM (Bi-LSTM), and the Transformer are evaluated. Among the 540 respiration signals, 60 signals are used as test data. Each of the remaining 480 signals was spilt into training and validation data in a 7:3 ratio. A total of 1000 ms of the signal sequence (T-s) is entered to the models, and the signal at 500 ms afterward (P-t) is predicted (standard training condition). The accuracy measures are: (1) root mean square error (RMSE) and Pearson correlation coefficient (CC), (2) accuracy dependency on T-s and P-t, (3) respiratory pattern dependency, and (4) error for 30% and 70% of the respiration gating for a 5 mm tumor motion for latencies of 300, 500, and 700 ms. Under standard conditions, the Transformer model exhibits the highest accuracy with an RMSE and CC of 0.1554 and 0.9768, respectively. An increase in T-s improves accuracy, whereas an increase in P-t decreases accuracy. An evaluation of the regularity of the respiratory signals reveals that the lowest predictive accuracy is achieved with irregular amplitude patterns. For 30% and 70% of the phases, the average error of the three models is <1.4 mm for a latency of 500 ms and >2.0 mm for a latency of 700 ms. The prediction accuracy of the Transformer is superior to LSTM and Bi-LSTM. Thus, the three models have clinically applicable accuracies for a latency <500 ms for 10 mm of regular tumor motion. The clinical acceptability of the deep learning models depends on the inherent latency and the strategy for reducing the irregularity of respiration.","2022-10-18","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","10","17","","","","","","","","","","English","","","","WOS:000903426100016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","ABDOMINAL COMPRESSION; IMPACT; LSTM; LUNG; MANAGEMENT; MOTION; MOVEMENT; STEREOTACTIC BODY RADIOTHERAPY; TUMORS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VBGC8TVK","journalArticle","2023","Porco, AV; Dongshik, K","Estimation of Hazardous Environments Through Speech and Ambient Noise Analysis","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","In recent years, significant attention has been directed towards the development of artificial empathy within the engineering academic community. Replicating artificial empathy necessitates the capability of agents to discern human emotions and comprehend environmental risks. Analyzing acoustic data in real environments offers a higher level of non-invasive privacy compared to video and camera data, limiting the agent's understanding to specific patterns. However, current studies are negatively affected by subjective inferences from real data, which can result in inaccurate predictions, leading to both false positives and negatives, especially when contextual data and human speech are involved. This paper work proposes the estimation of a dangerous environment in accordance with the emotional speech and additional ambient noises. In this approach we implement a variational autoencoder model in conjunction with a classifier for training the classification task. Additional regularization techniques are applied to bridge the gap between the original training data and the expected data. The classifier utilizes feature data generated by the variational autoencoder to extract class patterns and determine whether the environment is hazardous. Emotional speech is classified as angry, sad, or scared emotions, contributing to the classification of danger, while happy, calm, and neutral emotions are considered safe. Various ambient noise types, including gunfire and broken glass, are categorized as dangerous, while real-life indoor noises like cooking, eating, and movements are considered safe.","2023-11","2025-02-26 20:43:31","2025-02-26 20:43:31","","1311-1317","","11","14","","","","","","","","","","English","","","","WOS:001126444100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","acoustic audio analysis; ambient noises; Dangerous environment detection; EMOTION RECOGNITION; empathetic systems; EVENTS; MODEL; speech analysis; variational autoencoder model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JZFKHYB2","journalArticle","2022","Badr, AA; Abdul-Hassan, AK","SPEAKER GENDER IDENTIFICATION IN MATCHED AND MISMATCHED CONDITIONS BASED ON STACKING ENSEMBLE METHOD","JOURNAL OF ENGINEERING SCIENCE AND TECHNOLOGY","","1823-4690","","","Identifying the gender of the human voice has been considered one of the challenging tasks because it acts as a pre-processing ingredient for enhancing speech analysis applications. In this work, an automatic system is proposed to identify the speaker's gender without depending on the text in matched and mismatched conditions. Firstly, three groups of features are extracted from each utterance using Fundamental Frequency (F0), Fractal Dimensions, and Mel Frequency Cepstral Coefficient (MFCC) methods. Then, the extracted feature dimensions are reduced using Linear Discriminant Analysis (LDA) method. Finally, the speaker's gender is identified based on proposed stacking ensemble classifier when Logistic Regression (LR), K-Nearest Neighbours (KNN) and Gaussian Naive Bayes (GNB) are used as base classifiers, while Support Vector Machine (SVM) is used as meta classifier. Four experiments are conducted on two datasets: TIMIT, and Common-Voice. In matched conditions (i.e., same language), the proposed system accuracy is 99.74%, 87.28% for the TIMIT, and the Common-Voice dataset, respectively. In mismatched conditions (i.e., cross language), the proposed system shows a high ability to generalize, taking advantage of using the LDA method, where the system accuracy is 81.19%, 97.78% for the (TIMIT\Common-Voice), and (Common-Voice\TIMIT) datasets, respectively. The results also showed a clear superiority for the proposed system in comparison to related works that utilized the TIMIT dataset.","2022-04","2025-02-26 20:43:31","2025-02-26 20:43:31","","1119-1134","","2","17","","","","","","","","","","English","","","","WOS:000782915100022","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","AGE; CLASSIFICATION; Cross-language; Features fusion; Fractal dimensions; LDA; LOGISTIC-REGRESSION; NAIVE BAYES; RECOGNITION; Speaker gender detection; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VR4NWZ3L","journalArticle","2022","Arias-Vergara, T; Batliner, A; Rader, T; Polterauer, D; Högerle, C; Müller, J; Orozco-Arroyave, JR; Nöth, E; Schuster, M","Adult Cochlear Implant Users Versus Typical Hearing Persons: An Automatic Analysis of Acoustic-Prosodic Parameters","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2022_JSLHR-21-00116","","Purpose: The aim of this study was to investigate the speech prosody of post-lingually deaf cochlear implant (CI) users compared with control speakers without hearing or speech impairment. Method: Speech recordings of 74 CI users (37 males and 37 females) and 72 age-balanced control speakers (36 males and 36 females) are considered. All participants are German native speakers and read Der Nordwind und die Sonne (The North Wind and the Sun), a standard text in pathological speech analysis and phonetic transcriptions. Automatic acoustic analysis is performed considering pitch, loudness, and duration features, including speech rate and rhythm. Results: In general, duration and rhythm features differ between CI users and control speakers. CI users read slower and have a lower voiced segment ratio compared with control speakers. A lower voiced ratio goes along with a prolongation of the voiced segments' duration in male and with a prolongation of pauses in female CI users. Rhythm features in CI users have higher variability in the duration of vowels and consonants than in control speakers. The use of bilateral CIs showed no advantages concerning speech prosody features in comparison to unilateral use of CI. Conclusions: Even after cochlear implantation and rehabilitation, the speech of postlingually deaf adults deviates from the speech of control speakers, which might be due to changed auditory feedback. We suggest considering changes in temporal aspects of speech in future rehabilitation strategies.","2022-12","2025-02-26 20:43:31","2025-02-26 20:43:31","","4623-4636","","12","65","","","","","","","","","","English","","","","WOS:000931940600007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;78</p>","","","DEAF; DISCRIMINATION; FUNDAMENTAL-FREQUENCY; LEVEL; PITCH; PROCESSING CODING STRATEGY; RHYTHM; SPEECH-PERCEPTION; VOICE; VOWEL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3GMNWMJ8","journalArticle","2021","Krecichwost, M; Mocko, N; Badura, P","Automated detection of sigmatism using deep learning applied to multichannel speech signal","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2021.102612","","This paper presents a system for the analysis of acoustic data for the computer-aided diagnosis and therapy of sigmatism in children. The analysis is focused on the detection and recognition of selected articulation disorders in sibilant sounds. The system relies on the dedicated data acquisition device recording the speech signal using 15 microphones spatially arranged around the speaker's mouth. The collected speech corpus contains 923 samples of the /s/ and /?/ consonants from 98 five- and six-year-old children with either normative or pathological pronunciation features. Each recording is supplemented with a detailed speech therapy annotation. A dedicated multibranch convolutional neural network architecture was designed for the speech sample classification. The filter bank energy feature maps are extracted from each channel along with their two derivatives in the time domain. The feature maps are aggregated along different dimensions to constitute a four-dimensional data structure called acoustic volume, being the input data for the deep network. We proposed three ways to aggregate the multichannel data into the acoustic volume and two techniques for the data augmentation to enlarge the available dataset and avoid overfitting. Classification experiments involving different data subsets have proven the system's ability to detect the analyzed pronunciation disorders with reasonable accuracy. The framework with speech data organized spatially in five channels provides the most efficient classification.","2021-07","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","68","","","","","","","","","","English","","","","WOS:000670370300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Computer-aided speech diagnosis; Convolutional neural network; Deep learning; Multichannel acoustic signal; NEURAL-NETWORK; Sigmatism; Speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PTKTR28W","journalArticle","2024","Révész, A; Jeong, H; Suzuki, S; Cui, HN; Matsuura, S; Saito, K; Sugiura, M","Task-generated processes in second language speech production: Exploring the neural correlates of task complexity during silent pauses","STUDIES IN SECOND LANGUAGE ACQUISITION","","0272-2631","10.1017/S0272263124000421","","The last three decades have seen significant development in understanding and describing the effects of task complexity on learner internal processes. However, researchers have primarily employed behavioral methods to investigate task-generated cognitive load. Being the first to adopt neuroimaging to study second language (L2) task effects, we aimed to provide novel insights into the neural correlates of task-related variation in L2 oral production. To advance research methodology, we also tested the utility of a neuroimaging technique, functional magnetic resonance imaging (fMRI), in examining the impact of task-related variables on L2 speech production when combined with cognitive-behavioral tools (speech analysis, expert and learner judgments). Our research focus was the effects of task complexity on silent pausing. Twenty-four Japanese learners of English completed eight simple and complex versions of decision-making tasks, half in their first language and half in their L2. The dataset for the present study included the L2 speech and fMRI data, expert judgments, and participants' difficulty ratings of the L1 and L2 tasks they completed. Based on our findings, we concluded that brain imaging and L1 task difficulty ratings were more sensitive to detecting task complexity effects than L2 self-ratings and pausing measures. These results point to the benefits of triangulating cognitive and neural data to study task-based neurocognitive processes.","2024-09","2025-02-26 20:43:31","2025-02-26 20:43:31","","1179-1205","","4","46","","","","","","","","","","English","","","","WOS:001315479800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","ACCURACY; fluency; FLUENCY; INFERENCES; L1; L2 production; NETWORK; neuroimaging; pausing; task complexity; UTTERANCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YEFGNEI2","journalArticle","2021","Gennari, G; Marti, S; Palu, M; Fló, A; Dehaene-Lambertz, G","Orthogonal neural codes for speech in the infant brain","PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA","","0027-8424","10.1073/pnas.2020410118","","Creating invariant representations from an everchanging speech signal is a major challenge for the human brain. Such an ability is particularly crucial for preverbal infants who must discover the phonological, lexical, and syntactic regularities of an extremely inconsistent signal in order to acquire language. Within the visual domain, an efficient neural solution to overcome variability consists in factorizing the input into a reduced set of orthogonal components. Here, we asked whether a similar decomposition strategy is used in early speech perception. Using a 256-channel electroencephalographic system, we recorded the neural responses of 3-mo-old infants to 120 natural consonant-vowel syllables with varying acoustic and phonetic profiles. Using multivariate pattern analyses, we show that syllables are factorized into distinct and orthogonal neural codes for consonants and vowels. Concerning consonants, we further demonstrate the existence of two stages of processing. A first phase is characterized by orthogonal and context-invariant neural codes for the dimensions of manner and place of articulation. Within the second stage, manner and place codes are integrated to recover the identity of the phoneme. We conclude that, despite the paucity of articulatory motor plans and speech production skills, pre-babbling infants are already equipped with a structured combinatorial code for speech analysis, which might account for the rapid pace of language acquisition during the first year.","2021-08-03","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","31","118","","","","","","","","","","English","","","","WOS:000685041400026","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;20<br/>Total Times Cited:&nbsp;&nbsp;20<br/>Cited Reference Count:&nbsp;&nbsp;83</p>","","","CUES; DISCRIMINATION; ELECTROPHYSIOLOGICAL EVIDENCE; ERP; FEATURES; infant; INFORMATION; language; LANGUAGE; MEG; PERCEPTION; phoneme; REPRESENTATIONS; RESPONSES; speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KY7XL4RP","journalArticle","2023","Gómez-Zaragozá, L; Marín-Morales, J; Vargas, EP; Giglioli, IAC; Raya, MA","An Online Attachment Style Recognition System Based on Voice and Machine Learning","IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS","","2168-2194","10.1109/JBHI.2023.3304369","","Attachment styles are known to have significant associations with mental and physical health. Specifically, insecure attachment leads individuals to higher risk of suffering from mental disorders and chronic diseases. The aim of this study is to develop an attachment recognition model that can distinguish between secure and insecure attachment styles from voice recordings, exploring the importance of acoustic features while also evaluating gender differences. A total of 199 participants recorded their responses to four open questions intended to trigger their attachment system using a web-based interrogation system. The recordings were processed to obtain the standard acoustic feature set eGeMAPS, and recursive feature elimination was applied to select the relevant features. Different supervised machine learning models were trained to recognize attachment styles using both gender-dependent and gender-independent approaches. The gender-independent model achieved a test accuracy of 58.88%, whereas the gender-dependent models obtained 63.88% and 83.63% test accuracy for women and men respectively, indicating a strong influence of gender on attachment style recognition and the need to consider them separately in further studies. These results also demonstrate the potential of acoustic properties for remote assessment of attachment style, enabling fast and objective identification of this health risk factor, and thus supporting the implementation of large-scale mobile screening systems.","2023-11","2025-02-26 20:43:31","2025-02-26 20:43:31","","5576-5587","","11","27","","","","","","","","","","English","","","","WOS:001129955100034","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Acoustic features; ACTIVATION; ADULTHOOD; ALGORITHMS; artificial intelligence; attachment; EMOTION RECOGNITION; gender; GENDER; HEALTH; MIDDLE CHILDHOOD; psychometrics; ROMANTIC ATTACHMENT; SEX-DIFFERENCES; SPEECH; speech analysis; statistical machine learning; voice","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DI93JYJC","journalArticle","2022","Amiriparian, S; Hübner, T; Karas, V; Gerczuk, M; Ottl, S; Schuller, BW","DeepSpectrumLite: A Power-Efficient Transfer Learning Framework for Embedded Speech and Audio Processing From Decentralized Data","FRONTIERS IN ARTIFICIAL INTELLIGENCE","","2624-8212","10.3389/frai.2022.856232","","Deep neural speech and audio processing systems have a large number of trainable parameters, a relatively complex architecture, and require a vast amount of training data and computational power. These constraints make it more challenging to integrate such systems into embedded devices and utilize them for real-time, real-world applications. We tackle these limitations by introducing DeepSpectrumLite, an open-source, lightweight transfer learning framework for on-device speech and audio recognition using pre-trained image Convolutional Neural Networks (CNNs). The framework creates and augments Mel spectrogram plots on the fly from raw audio signals which are then used to finetune specific pre-trained CNNs for the target classification task. Subsequently, the whole pipeline can be run in real-time with a mean inference lag of 242.0 ms when a DenseNet121 model is used on a consumer-grade Motorola moto e7 plus smartphone. DeepSpectrumLite operates decentralized, eliminating the need for data upload for further processing. We demonstrate the suitability of the proposed transfer learning approach for embedded audio signal processing by obtaining state-of-the-art results on a set of paralinguistic and general audio tasks, including speech and music emotion recognition, social signal processing, COVID-19 cough and COVID-19 speech analysis, and snore sound classification. We provide an extensive command-line interface for users and developers which is comprehensively documented and publicly available at .","2022-03-17","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","5","","","","","","","","","","English","","","","WOS:000917511500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","audio processing; computational paralinguistics; deep spectrum; embedded devices; NETWORKS; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IIAGFHDN","journalArticle","2022","Ngo, QC; Motin, MA; Pah, ND; Drotár, P; Kempster, P; Kumar, D","Computerized analysis of speech and voice for Parkinson's disease: A systematic review","COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE","","0169-2607","10.1016/j.cmpb.2022.107133","","Background and objective: Speech impairment is an early symptom of Parkinson's disease (PD). This study has summarized the literature related to speech and voice in detecting PD and assessing its severity. Methods: A systematic review of the literature from 2010 to 2021 to investigate analysis methods and signal features. The keywords ""Automatic analysis "" in conjunction with ""PD speech "" or ""PD voice "" were used, and the PubMed and ScienceDirect databases were searched. A total of 838 papers were found on the first run, of which 189 were selected. One hundred and forty-seven were found to be suitable for the review. The different datasets, recording protocols, signal analysis methods and features that were reported are listed. Values of the features that separate PD patients from healthy controls were tabulated. Finally, the barriers that limit the wide use of computerized speech analysis are discussed. Results: Speech and voice may be valuable markers for PD. However, large differences between the datasets make it difficult to compare different studies. In addition, speech analytic methods that are not informed by physiological understanding may alienate clinicians. Conclusions: The potential usefulness of speech and voice for the detection and assessment of PD is confirmed by evidence from the classification and correlation results. Crown Copyright (C) 2022 Published by Elsevier B.V. All rights reserved.","2022-11","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","226","","","","","","","","","","English","","","","WOS:000875969200005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;36<br/>Total Times Cited:&nbsp;&nbsp;36<br/>Cited Reference Count:&nbsp;&nbsp;197</p>","","","ACCURACY; ACOUSTIC CHARACTERISTICS; Acoustics; ALZHEIMER-DISEASE; Articulation; CLASSIFICATION; CLINICAL-DIAGNOSIS; COGNITIVE IMPAIRMENT; DEEP BRAIN-STIMULATION; FEATURE-SELECTION; Parkinson's disease; Phonation; PROGRESSION; SIGNAL-PROCESSING ALGORITHMS; Speech; Voice","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WCHSYRNZ","journalArticle","2023","Ying, YW; Yang, T; Zhou, H","Multimodal fusion for alzheimer's disease recognition","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-022-04255-z","","Alzheimer's disease (AD) is the most prevalent form of progressive degenerative dementia, which has a great impact on social economics throughout the world. In the vast majority of cases, AD patients are diagnosed by biochemical analysis, lumbar puncture and advanced imaging examination, which cannot play a preventive role in early stage of Alzheimer's disease. Speech signals contain abundant personal information, especially AD patients always accompany with speech disorder, which provides a potential to utilize speech information to distinguish AD patients from healthy persons. The work presented in this paper aims to develop new approach for early detection of AD by noninvasive methods. We propose to make utilization of multimodal features with speech acoustic and linguistic features for the speech recognition of Alzheimer's disease. Three different kinds of features, IS10_paraling features, deep acoustic using fine-tuned Wav2Vec2.0 model and deep linguistic features extracted using fine-tuned BERT, are adopted for AD classification by SVM classifier. By conducting experiments on two publicly available datasets of NCMMSC2021 and ADReSSo, the experimental results show that our model achieves state-of-the-art (SOTA) performance with satisfactory recognition effect. Our best-performing model obtains the accuracy of 89.1% and 84.0% in the long and short-audio of NCMMSC2021, and 83.7% in ADReSSo, which is promising for the early diagnosis and classification of AD patients.","2023-06","2025-02-26 20:43:31","2025-02-26 20:43:31","","16029-16040","","12","53","","","","","","","","","","English","","","","WOS:000914623900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Alzheimer's disease; BERT; CLASSIFICATION; Digital signal processing; Multimodal deep learning; SPEECH; Speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6MQ9P5GG","journalArticle","2022","De Vooght, E; Van Leuven, S; Hudders, L","Figuring out political rhetoric: a quantitative content analysis of the use of rhetorical figures on the 2018 Flemish municipal election day","ACTA POLITICA","","0001-6810","10.1057/s41269-021-00212-9","","Recent decades of research into political discourse and political rhetoric have revealed how language and rhetorical figures in particular are employed by politicians to shape political realities and persuade voters. However, little is known about the overall use of figures beyond metaphors. Therefore, a quantitative content analysis was conducted on the use of figures by Flemish politicians to explore which figures were used and how political (election result and political affiliation), speaker-related (seniority and renown) and delivery context factors (organization level and presence of the press) might influence this use. Our sample revealed both a great variety and frequency of figures beyond metaphors. Our findings also suggest a gap between rhetorical theory and practice as the range of figures studied most in literature does not accord with the figures found in our sample. Moreover, striking similarities were observed in figure use across speeches, as half of the used figures were repetitions. Although the figure use was not dependent of the political context or speaker-related factors, it was dependent of the delivery context, which suggests the existence of rhetorical registers. These findings might suggest that instead of being mainly strategic, the use of figures could also reflect a shared cultural view on political speech making. Theoretical and practical implications for rhetorical speech analysis are discussed and illustrated.","2022-07","2025-02-26 20:43:31","2025-02-26 20:43:31","","623-643","","3","57","","","","","","","","","","English","","","","WOS:000682493000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Content analysis; DISCOURSE; Metaphors; Political discourse; Political speech; POPULISM; Rhetorical analysis; Rhetorical figures; Rhetorical strategy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C25DIKPS","journalArticle","2023","Mounia, M; Nouhaila, B; Benayad, N; Taoufiq, BD","Use of ANN, LSTM and CNN Classifiers for the New MSCC and BSCC Methods in the Detection of Parkinson's Disease by Voice Analysis","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","Parkinson's disease (PD) is a neurodegenerative condition that impacts a significant global population. The timely and precise identification of PD plays a pivotal role in facilitating early intervention and the efficient management of the condition. Recently, speech analysis has emerged as a promising noninvasive technique for the detection of PD due to its accessibility and ability to reveal subtle vocal biomarkers associated with the disease. This research introduces an innovative approach utilizing Short-Time Fourier Transform (STFT) to generate spectrograms, specifically Bark Spectrogram Cepstral Coefficients (BSCC) and Mel Spectrogram Cepstral Coefficients (MSCC). These coefficients are compared with traditional and well-known coefficients, namely Mel-Frequency Cepstral Coefficients (MFCC) and Bark Frequency Cepstral Coefficients (BFCC). To extract the most effective coefficients for Parkinson's disease detection, three robust classification techniques-Long Short-Term Memory neural networks (LSTM), Convolutional Neural Networks (CNN), and Artificial Neural Networks (ANN)-are employed. As a result, the BSCC and MSCC algorithms achieve a maximum accuracy rate of 90%, surpassing the accuracy of the traditional MFCC and BFCC coefficients. Therefore, these newly proposed coefficients prove to be more precise in diagnosing Parkinson's disease compared to the conventional MFCC and BFCC coefficients.","2023-12","2025-02-26 20:43:31","2025-02-26 20:43:31","","560-567","","12","14","","","","","","","","","","English","","","","WOS:001244766300027","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Artificial Neural Networks (ANN); Bark Spectrogram Cepstral Coefficients (BSCC); CLASSIFICATION; Convolutional Neural Networks (CNN); DEEP NEURAL-NETWORK; DIAGNOSIS; Long-Term Memory Neural Networks (LSTM); Mel Spectrogram Cepstral Coefficients (MSCC); Parkinson's Disease (PD); SIGNAL-PROCESSING ALGORITHMS; WAVELET TRANSFORM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ILNLN2C2","journalArticle","2023","Basalamah, A; Hasan, M; Bhowmik, S; Shahriyar, SA","A Highly Accurate Dysphonia Detection System Using Linear Discriminant Analysis","COMPUTER SYSTEMS SCIENCE AND ENGINEERING","","0267-6192","10.32604/csse.2023.027399","","The recognition of pathological voice is considered a difficult task for speech analysis. Moreover, otolaryngologists needed to rely on oral communication with patients to discover traces of voice pathologies like dysphonia that are caused by voice alteration of vocal folds and their accuracy is between 60%-70%. To enhance detection accuracy and reduce processing speed of dysphonia detection, a novel approach is proposed in this paper. We have leveraged Linear Discriminant Analysis (LDA) to train multiple Machine Learning (ML) models for dysphonia detection. Several ML models are utilized like Support Vector Machine (SVM), Logistic Regression, and K-nearest neighbor (K-NN) to predict the voice pathologies based on features like Mel-Frequency Cepstral Coefficients (MFCC), Fundamental Frequency (F0), Shimmer (%), Jitter (%), and Harmonic to Noise Ratio (HNR). The experiments were performed using Saarbrucken Voice Database (SVD) and a privately collected dataset. The K-fold cross-validation approach was incorporated to increase the robustness and stability of the ML models. According to the experimental results, our proposed approach has a 70% increase in processing speed over Principal Component Analysis (PCA) and performs remarkably well with a recognition accuracy of 95.24% on the SVD dataset surpassing the previous best accuracy of 82.37%. In the case of the private dataset, our proposed method achieved an accuracy rate of 93.37%. It can be an effective non-invasive method to detect dysphonia.","2023","2025-02-26 20:43:31","2025-02-26 20:43:31","","1921-1938","","3","44","","","","","","","","","","English","","","","WOS:000843903900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Dimensionality reduction; dysphonia detection; FUSION; linear discriminant analysis; logistic regression; speech feature extraction; support vector machine; VOICE PATHOLOGY DETECTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NKDFNISQ","journalArticle","2023","Dong, L","Loudness and Pitch of Emotional Stage Speech in Kunqu Opera","JOURNAL OF VOICE","","0892-1997","10.1016/j.jvoice.2021.04.021","","Equivalent sound level (Leq), sound pressure level (SPL) and fundamental frequency (F0) were ana-lyzed in the stage speech of six Kunqu Opera roles, Young woman, Old woman, Young man, Old man, Colorful face and Clown. The roles differ in gender, age, personality and phonation types. Differences among emotions (neutral, sad, angry and happy), singers and roles were examined. For most roles, more similarities were observed between neutral and sad stage speech and between angry and happy stage speeches. In most cases, the latter group showed higher Leq, mean SPL and Mean F0 and larger standard deviation (SD) of SPL difference than the former. Some parameters, such as SD of SPL, the mean of SPL difference and the difference between Leq and mean SPL, also showed the intra-group differences.Young woman role, Young man role and Old woman role were similar in some parameters. Colorful face role and Old man role showed a lot of similarities. Clown role showed the least similarities with the other roles. With regard to gender and age, young roles showed smaller SPL difference, larger correlation coefficient between F0 and SPL and larger mean SPL differences between emotions than old roles; female roles had greater parameter consistency and larger correlation coefficient between F0 and SPL than male roles. The personality and phonation types also effected the characteristics of loudness and pitch. This study showed the importance of speakers' characteristics in emotional speech analysis.","2023-09","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","5","37","","","","","","","","","","English","","","","WOS:001080482700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;14</p>","","","Emotional stage speech; Equivalent sound level; Fundamental frequency; Kunqu Opera; Sound pressure level","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MW4AEWFL","journalArticle","2022","Faro, S; Scafiti, S","A weak approach to suffix automata simulation for exact and approximate string matching","THEORETICAL COMPUTER SCIENCE","","0304-3975","10.1016/j.tcs.2022.08.028","","String matching is one of the most extensively studied problems in computer science, mainly due to its direct applications to such diverse areas as text, image and signal processing, speech analysis and recognition, information retrieval, data compression, computational biology and chemistry. In the last few decades a myriad of alternative solutions have been proposed, based on very different techniques. However, automata have always played a very important role in the design of efficient string matching algorithms. In this paper we present the Range Automaton, a weak yet efficient variant of the non-deterministic suffix automaton of a string whose configuration can be encoded in a very simple form and which is particularly suitable to be used for solving a multitude of text-searching problems. We will firstly develop our approach in the case of exact string matching and present an efficient algorithm, named Backward Range Automaton Matcher, which turns out to be very fast in many practical cases. Later, we will show how the Range Automaton can be adapted in an effective way also to non-standard string matching problems such as swap matching and multiple string matching. Experimental results suggest that our approach is flexible and effective for all three search problems addressed, especially in the case of long patterns. (c) 2022 Elsevier B.V. All rights reserved.","2022-10-14","2025-02-26 20:43:31","2025-02-26 20:43:31","","88-103","","","933","","","","","","","","","","English","","","","WOS:000934337300007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","ALGORITHMS; Automata; Design and analysis of algorithms; Exact string matching; Experimental algorithms; Swap matching; Text processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NK7AT6UI","journalArticle","2023","Widodo, J","The Culture of Creating Poetry and Writing Speech Texts among Indonesian Higher Education Students","EURASIAN JOURNAL OF APPLIED LINGUISTICS","","2149-1135","10.32601/ejal.902016","","Poetry and spoken texts serve as dynamic instructional resources that enhance language proficiency in the domains of art and rhetoric while concurrently promoting language development. EFL learners hailing from Indonesia emphasise the significance of employing effective teaching methodologies while also shedding light on the challenges they face during the learning process. The analysis of poetry and speech texts authored by students reveals that the utilisation of template-based poetry plays a vital role in enhancing students' understanding of language and fostering significant literacy encounters. Creative ideas serve as catalysts, stimulating students to engage in experimentation with a wide range of literary genres and techniques. This study underscores the importance of speech analysis and the incorporation of rhetorical techniques in the construction of speech texts, enabling students to produce written works that demonstrate linguistic proficiency and evoke emotional resonance. However, persistent challenges include the use of appropriate language registers and maintaining linguistic coherence. This study emphasises the importance of employing innovative strategies to address these obstacles and promote the development of creative expression among English as a Foreign Language (EFL) learners. The results of this study offer valuable insights for educators, promoting the adoption of customised strategies to enhance students' abilities in composing poetry and speech texts in the Indonesian English as a Foreign Language (EFL) context. (c) 2023 EJAL & the Authors. Published by Eurasian Journal of Applied Linguistics (EJAL).","2023","2025-02-26 20:43:31","2025-02-26 20:43:31","","186-196","","2","9","","","","","","","","","","English","","","","WOS:001115284000011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","EFL; Meaningful Literacy; Poetry; Speech Texts; Teaching Methods","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7RV8E2BW","journalArticle","2023","Wang, WC; Xu, WZ; Chander, A; Nepal, S; Buck, B; Pakhomov, S; Cohen, T; Ben-Zeev, D; Campbell, A","The Power of Speech in the Wild: Discriminative Power of Daily Voice Diaries in Understanding Auditory Verbal Hallucinations Using Deep Learning","PROCEEDINGS OF THE ACM ON INTERACTIVE MOBILE WEARABLE AND UBIQUITOUS TECHNOLOGIES-IMWUT","","2474-9567","10.1145/3610890","","Mobile phone sensing is increasingly being used in clinical research studies to assess a variety of mental health conditions (e.g., depression, psychosis). However, in-the-wild speech analysis - beyond conversation detecting - is a missing component of these mobile sensing platforms and studies. We augment an existing mobile sensing platform with a daily voice diary to assess and predict the severity of auditory verbal hallucinations (i.e., hearing sounds or voices in the absence of any speaker), a condition that affects people with and without psychiatric or neurological diagnoses. We collect 4809 audio diaries from N=384 subjects over a one-month-long study period. We investigate the performance of various deep-learning architectures using different combinations of sensor behavioral streams (e.g., voice, sleep, mobility, phone usage, etc.) and show the discriminative power of solely using audio recordings of speech as well as automatically generated transcripts of the recordings; specifically, our deep learning model achieves a weighted f-1 score of 0.78 solely from daily voice diaries. Our results surprisingly indicate that a simple periodic voice diary combined with deep learning is sufficient enough of a signal to assess complex psychiatric symptoms (e.g., auditory verbal hallucinations) collected from people in the wild as they go about their daily lives.","2023-09","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","3","7","","","","","","","","","","English","","","","WOS:001079730400051","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;127</p>","","","1ST-EPISODE PSYCHOSIS; Auditory Verbal Hallucinations; Daily Voice Diaries; DELUSIONS; DISORDERS; DYSFUNCTION; LANGUAGE; MENTAL-HEALTH; Mobile Sensing; SCHIZOPHRENIA; SELF-REPORT; Speech in the Wild; VISUAL HALLUCINATIONS; WORDS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SICATX39","journalArticle","2024","Davila-Gonzalez, S; Martin, S","Human Digital Twin in Industry 5.0: A Holistic Approach to Worker Safety and Well-Being through Advanced AI and Emotional Analytics","SENSORS","","1424-8220","10.3390/s24020655","","This research introduces a conceptual framework designed to enhance worker safety and well-being in industrial environments, such as oil and gas construction plants, by leveraging Human Digital Twin (HDT) cutting-edge technologies and advanced artificial intelligence (AI) techniques. At its core, this study is in the developmental phase, aiming to create an integrated system that could enable real-time monitoring and analysis of the physical, mental, and emotional states of workers. It provides valuable insights into the impact of Digital Twins (DT) technology and its role in Industry 5.0. With the development of a chatbot trained as an empathic evaluator that analyses emotions expressed in written conversations using natural language processing (NLP); video logs capable of extracting emotions through facial expressions and speech analysis; and personality tests, this research intends to obtain a deeper understanding of workers' psychological characteristics and stress levels. This innovative approach might enable the identification of stress, anxiety, or other emotional factors that may affect worker safety. Whilst this study does not encompass a case study or an application in a real-world setting, it lays the groundwork for the future implementation of these technologies. The insights derived from this research are intended to inform the development of practical applications aimed at creating safer work environments.","2024-01","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","2","24","","","","","","","","","","English","","","","WOS:001151004300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","artificial intelligence; emotional well-being; health and safety environment; Human Digital Twin; Industry 5.0; Internet of Things; mental health; physiological health; STRESS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LWS4QPUJ","journalArticle","2021","Wang, YY; Huang, XL; Li, BQ; Liu, XQ; Ma, YY; Huang, XJ","Spreading mechanism of Weibo public opinion phonetic representation based on the epidemic model","INTERNATIONAL JOURNAL OF SPEECH TECHNOLOGY","","1381-2416","10.1007/s10772-020-09790-z","","Public opinion is the abbreviation of public ideas, which is the sum of the beliefs, attitudes, opinions and emotions expressed by the masses about various phenomena in the society. Network public opinion is not only the mapping of public opinion in the network, but also the direct response of social public opinion. Weibo public opinion has gradually become an important medium for people to obtain public opinion in time. The outbreak of Weibo public opinion is very likely to cause social repercussions, which will even affect people's trust in the government and even social stability. The scale of the Internet is expanding, the number of users is increasing, and the applications provided by the Internet are becoming more and more popular. In this context, Weibo public opinion analysis has become an important research topic. Facing the rapid growth of micro blog information, how to obtain the hot topics of micro blog public opinion timely, comprehensively and accurately is the primary problem to be solved in the process of micro blog public opinion analysis. Based on the infectious disease model, this paper proposes an analysis model of Weibo public opinion communication. The speech analysis model is proposed to extract the information for the processing, and the representation of the data is applied to improve the algorithm efficiency. The experimental results compared with the state-of-the-art have proven the satisfactory performance.","2021-01-13","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","","","","","","","","","","","English","","","","WOS:000607483300003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","ATTENTION; Communicability; Infectious disease model; Public opinion analysis; Social media; SPEECH; Weibo","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UPD7QENJ","journalArticle","2024","Rubio, VJ; Aguado, D; Toledano, DT; Fernandez-Gallego, MP","Feasibility of Big Data Analytics to Assess Personality Based on Voice Analysis","SENSORS","","1424-8220","10.3390/s24227151","","(1) Background: As far back as the 1930s, it was already thought that gestures, clothing, speech, posture, and gait could express an individual's personality. Different research programs, some focused on linguistic cues, were launched, though results were inconsistent. The development of new speech analysis technology and the generalization of big data analysis have created an opportunity to test the predictive power of voice features on personality dimensions. This study aims to explore the feasibility of an automatic personality assessment system in the context of personnel selection. (2) Methods: One hundred participants were recorded during an individual interview for voice analysis. They also completed the NEO-FFI and were required to ask and collect the assessment of their personality by a close significant other. Furthermore, an expert estimated participants' personality dimensions based on the viewing of the recorded interviews. (3) Results: Results showed there are specific voice features related to the externalization of individuals' personalities (predictions ranging from 0.3 to 0.4). Voice features also predicted significant others' estimations and expert ratings of the target individual's personality, though the features were not exactly the same. (4) Conclusions: It is noteworthy that predictions were made based on voice recordings obtained using ordinary devices in controlled but not restricted speech situations, which may make such an approach a promising tool for personality assessment in contexts such as personnel selection.","2024-11","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","22","24","","","","","","","","","","English","","","","WOS:001366092200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","ACCURACY; externalization of personality; JUDGING PERSONALITY; JUDGMENTS; personality assessment; RECOGNITION; SPEECH; voice analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LL44AD5U","journalArticle","2021","Stasak, B; Huang, ZC; Razavi, S; Joachim, D; Epps, J","Automatic Detection of COVID-19 Based on Short-Duration Acoustic Smartphone Speech Analysis","JOURNAL OF HEALTHCARE INFORMATICS RESEARCH","","2509-4971","10.1007/s41666-020-00090-4","","Currently, there is an increasing global need for COVID-19 screening to help reduce the rate of infection and at-risk patient workload at hospitals. Smartphone-based screening for COVID-19 along with other respiratory illnesses offers excellent potential due to its rapid-rollout remote platform, user convenience, symptom tracking, comparatively low cost, and prompt result processing timeframe. In particular, speech-based analysis embedded in smartphone app technology can measure physiological effects relevant to COVID-19 screening that are not yet digitally available at scale in the healthcare field. Using a selection of the Sonde Health COVID-19 2020 dataset, this study examines the speech of COVID-19-negative participants exhibiting mild and moderate COVID-19-like symptoms as well as that of COVID-19-positive participants with mild to moderate symptoms. Our study investigates the classification potential of acoustic features (e.g., glottal, prosodic, spectral) from short-duration speech segments (e.g., held vowel, pataka phrase, nasal phrase) for automatic COVID-19 classification using machine learning. Experimental results indicate that certain feature-task combinations can produce COVID-19 classification accuracy of up to 80% as compared with using the all-acoustic feature baseline (68%). Further, with brute-forced n-best feature selection and speech task fusion, automatic COVID-19 classification accuracy of upwards of 82-86% was achieved, depending on whether the COVID-19-negative participant had mild or moderate COVID-19-like symptom severity.","2021-06","2025-02-26 20:43:31","2025-02-26 20:43:31","","201-217","","2","5","","","","","","","","","","English","","","","WOS:000658568800005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;26<br/>Total Times Cited:&nbsp;&nbsp;27<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Digital medicine; Machine learning; Remote sensing; Respiratory illness","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IRT9BGTN","journalArticle","2024","Qi, PX","Movie Visual and Speech Analysis Through Multi-Modal LLM for Recommendation Systems","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3471568","","Understanding speech as a component of broader video comprehension within audio-visual large language models remains a critical yet underexplored area. Previous research has predominantly tackled this challenge by adapting models developed for conventional video classification tasks, such as action recognition or event detection. However, these models often overlook the linguistic elements present in videos, such as narrations or dialogues, which can implicitly convey high-level semantic information related to movie understanding, including narrative structure or contextual background. Moreover, existing methods are generally configured to encode the entire video content, which can lead to inefficiencies in genre classification tasks. In this paper, we propose a multi-modal Large Language Model (LLM) framework, termed Visual-Speech Multimodal LLM (VSM-LLM), for analyzing movie visual and speech data to predict movie genre. The model incorporates an advanced MGC Q-Former architecture, enabling fine-grained, temporal alignment of audio-visual features across various time scales. On the MovieNet dataset, VSM-LLM attains 40.3% and 55.3% in macro and micro recall@0.5, respectively, outperforming existing baselines. On the Condensed Movies dataset, VSM-LLM achieves 43.5% in macro recall@0.5 and 53.5% in micro recall@0.5, further confirming its superior genre classification performance.","2024","2025-02-26 20:43:31","2025-02-26 20:43:31","","145686-145702","","","12","","","","","","","","","","English","","","","WOS:001336065000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Accuracy; Adaptation models; Analytical models; Classification algorithms; Context modeling; Deep learning; Feature extraction; large language model; Large language models; Linguistics; Motion pictures; movie analysis; multimodality; Semantics; transformer; video classification; Videos; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XNTAQKVN","journalArticle","2023","Python, G; Demierre, C; Bourqui, M; Bourbon, A; Chardenon, E; Trouville, R; Laganaro, M; Fougeron, C","Comparison of In-Person and Online Recordings in the Clinical Teleassessment of Speech Production: A Pilot Study","BRAIN SCIENCES","","2076-3425","10.3390/brainsci13020342","","In certain circumstances, speech and language therapy is proposed in telepractice as a practical alternative to in-person services. However, little is known about the minimum quality requirements of recordings in the teleassessment of motor speech disorders (MSD) utilizing validated tools. The aim here is to examine the comparability of offline analyses based on speech samples acquired from three sources: (1) in-person recordings with high quality material, serving as the baseline/gold standard; (2) in-person recordings with standard equipment; (3) online recordings from videoconferencing. Speech samples were recorded simultaneously from these three sources in fifteen neurotypical speakers performing a screening battery of MSD and analyzed by three speech and language therapists. Intersource and interrater agreements were estimated with intraclass correlation coefficients on seventeen perceptual and acoustic parameters. While the interrater agreement was excellent for most speech parameters, especially on high quality in-person recordings, it decreased in online recordings. The intersource agreement was excellent for speech rate and mean fundamental frequency measures when comparing high quality in-person recordings to the other conditions. The intersource agreement was poor for voice parameters, but also for perceptual measures of intelligibility and articulation. Clinicians who plan to teleassess MSD should adapt their recording setting to the parameters they want to reliably interpret.","2023-02","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","2","13","","","","","","","","","","English","","","","WOS:000938468400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","ACOUSTICS; apraxia of speech; COMPRESSION; DISORDERS; dysarthria; dysphonia; INTELLIGIBILITY; LANGUAGE; motor speech disorders; recording devices; RELIABILITY; speech analysis; speech and language therapy; speech and voice disorders; TECHNOLOGY; teleassessment; TELEHEALTH; telerehabilitation; TELEREHABILITATION SYSTEM; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QD7FYWXV","journalArticle","2023","Campi, M; Peters, GW; Toczydlowska, D","Ataxic speech disorders and Parkinson's disease diagnostics via stochastic embedding of empirical mode decomposition","PLOS ONE","","1932-6203","10.1371/journal.pone.0284667","","Medical diagnostic methods that utilise modalities of patient symptoms such as speech are increasingly being used for initial diagnostic purposes and monitoring disease state progression. Speech disorders are particularly prevalent in neurological degenerative diseases such as Parkinson's disease, the focus of the study undertaken in this work. We will demonstrate state-of-the-art statistical time-series methods that combine elements of statistical time series modelling and signal processing with modern machine learning methods based on Gaussian process models to develop methods to accurately detect a core symptom of speech disorder in individuals who have Parkinson's disease. We will show that the proposed methods out-perform standard best practices of speech diagnostics in detecting ataxic speech disorders, and we will focus the study, particularly on a detailed analysis of a well regarded Parkinson's data speech study publicly available making all our results reproducible. The methodology developed is based on a specialised technique not widely adopted in medical statistics that found great success in other domains such as signal processing, seismology, speech analysis and ecology. In this work, we will present this method from a statistical perspective and generalise it to a stochastic model, which will be used to design a test for speech disorders when applied to speech time series signals. As such, this work is making contributions both of a practical and statistical methodological nature.","2023-04-26","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","4","18","","","","","","","","","","English","","","","WOS:000984779900025","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;88</p>","","","FREQUENCY; RECOGNITION; REPRESENTATIONS; SIGNAL; SPECTRUM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TQG9AKB6","journalArticle","2024","Cascella, M; Cutugno, F; Mariani, F; Vitale, VN; Iuorio, M; Cuomo, A; Bimonte, S; Conti, V; Sabbatino, F; Ponsiglione, AM; Montomoli, J; Bellini, V; Semeraro, F; Vittori, A; Bignami, EG; Piazza, O","AI-based cancer pain assessment through speech emotion recognition and video facial expressions classification","SIGNA VITAE","","1334-5605","10.22514/sv.2024.153","","The effective assessment of cancer pain requires a meticulous analysis of all the components that shape the painful experience collectively. Implementing Automatic Pain Assessment (APA) methods and computational analytical approaches, with a specific focus on emotional content, can facilitate a thorough characterization of pain. The proposed approach moves towards the use of automatic emotion recognition from speech recordings alongside a model we previously developed to examine facial expressions of pain. For training and validation, we adopted the EMOVO dataset, which simulates six emotional states (the Big Six). A Neural Network, consisting of a Multi- Layered Perceptron, was trained on 181 prosodic features to classify emotions. For testing, we used a dataset of interviews collected from cancer patients and selected two case studies. Speech annotation and continuous facial expression analysis (resulting in pain/no pain classifications) were carried out using Eudico Linguistic Annotator (ELAN) version 6.7. The model for emotion analysis achieved 84% accuracy, with encouraging precision, recall, and F1-score metrics across all classes. The preliminary results suggest the potential use of artificial intelligence (AI) strategies for continuous estimation of emotional states from video recordings, unveiling predominant emotional states, and providing the ability to corroborate the corresponding pain assessment. Despite limitations, the proposed AI framework exhibits potential for holistic and realtime pain assessment, paving the way for personalized pain management strategies in oncological settings.","2024-12","2025-02-26 20:43:31","2025-02-26 20:43:31","","28-38","","12","20","","","","","","","","","","English","","","","WOS:001376976400003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Artificial intelligence; Automatic pain assessment; Cancer pain; Computational language analysis; Pain; Speech analysis; Speech emotion recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7ESWZMI2","journalArticle","2024","Chauhan, R; Sharma, U","Exploiting speech tremors: machine learning for early diagnosis of amyotrophic lateral sclerosis","ENGINEERING RESEARCH EXPRESS","","2631-8695","10.1088/2631-8695/ad7d62","","Neurodegenerative diseases pose significant challenges in healthcare, with Amyotrophic Lateral Sclerosis ( ALS ) being one such rare yet debilitating condition affecting motor neurons. Machine learning ( ML ) and artificial intelligence ( AI ) have emerged as powerful tools in healthcare, offering insights and solutions for various medical conditions. This study investigates the application of ML to enhance early ALS diagnosis through the analysis of tremors in sustained speech. By focusing on tremor detection as a diagnostic marker, the research employs ML algorithms to develop predictive models capable of distinguishing ALS patients from healthy controls. The dataset comprises 54 patients from the Republican Research and Clinical Centre of Neurology and Neurosurgery in Belarus, Minsk. The study adopts a two-faceted approach: ( 1 ) Exploratory voice analysis to identify tremors associated with ALS in speech samples. ( 2 ) Development of ML algorithms to construct predictive models for early ALS diagnosis based on the identified tremors. The ML models exhibit promising results in distinguishing ALS patients from healthy controls based on speech analysis. Tremor detection in sustained speech proves to be an effective marker for early ALS diagnosis. While initial fi ndings are encouraging, larger-scale studies are required to validate the clinical applicability of this approach. The successful application of ML and AI in early ALS diagnosis by leveraging innovative approaches, such as tremor detection in sustained speech, we can enhance early diagnosis and improve patient outcomes in neurodegenerative diseases like ALS on a broader scale.","2024-12-01","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","4","6","","","","","","","","","","English","","","","WOS:001350923500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","ALS; machine learning; PATHOLOGY; speech tremor analysis; VOICE ANALYSIS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T8HNE52Y","journalArticle","2021","Samuel, AG; Dumay, N","Auditory Selective Adaptation Moment by Moment, at Multiple Timescales","JOURNAL OF EXPERIMENTAL PSYCHOLOGY-HUMAN PERCEPTION AND PERFORMANCE","","0096-1523","10.1037/xhp0000841","","Over the course of a lifetime, adults develop perceptual categories for the vowels and consonants in their native language, based on the distribution of those sounds in their environment. However, in any given listening situation, the short-term distribution of sounds can cause changes in this long-term categorization. For example, if the same sound (the ""adaptor"") is heard many times in a short period of time, listeners adapt and become less prone to hearing that sound. Although hundreds of speech selective adaptation experiments have been published, there is almost no information about how long this adaptation lasts. Using stimuli chosen to produce very large initial adaptation, we test adaptation effects with essentially no delay. and with delays of 25 min. 90 min, and 5.5 hr: these tests probe the duration of adaptation both in the (single) ear to which the adaptor was presented, and in the opposite ear. Reliable adaptation remains 5.5 hr after exposure in the same-ear condition, whereas it is undetectable at 90 min in the opposite ear. Surprisingly, the amount of residual adaptation is largely unaffected by whether the listener is exposed to speech between adaptation and test, unless the speech shares critical acoustic properties with the adapting sounds. Analyses of the shifts on three time scales (seconds. minutes, and hours) provide information about the multiple levels of analysis that the speech signal undergoes.","2021-04","2025-02-26 20:43:31","2025-02-26 20:43:31","","596-615","","4","47","","","","","","","","","","English","","","","WOS:000651094900009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","auditory selective adaptation; BRAIN; FEATURE-DETECTORS; IDENTIFICATION; INFORMATION; levels of speech analysis; POSITION; recovery time; speech perception; SPEECH-PERCEPTION; time course; VISUAL RECALIBRATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YVVE229Q","journalArticle","2022","Wang, XC; Wang, T","Voice Recognition and Evaluation of Vocal Music Based on Neural Network","COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE","","1687-5265","10.1155/2022/3466987","","Artistic voice is the artistic life of professional voice users. In the process of selecting and cultivating artistic performing talents, the evaluation of voice even occupies a very important position. Therefore, an appropriate evaluation of the artistic voice is crucial. With the development of art education, how to scientifically evaluate artistic voice training methods and fairly select artistic voice talents is an urgent need for objective evaluation of artistic voice. The current evaluation methods for artistic voices are time-consuming, laborious, and highly subjective. In the objective evaluation of artistic voice, the selection of evaluation acoustic parameters is very important. Attempt to extract the average energy, average frequency error, and average range error of singing voice by using speech analysis technology as the objective evaluation acoustic parameters, use neural network method to objectively evaluate the singing quality of artistic voice, and compare with the subjective evaluation of senior professional teachers. In this paper, voice analysis technology is used to extract the first formant, third formant, fundamental frequency, sound range, fundamental frequency perturbation, first formant perturbation, third formant perturbation, and average energy of singing acoustic parameters. By using BP neural network methods, the quality of singing was evaluated objectively and compared with the subjective evaluation of senior vocal professional teachers. The results show that the BP neural network method can accurately and objectively evaluate the quality of singing voice by using the evaluation parameters, which is helpful in scientifically guiding the selection and training of artistic voice talents.","2022-05-20","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","2022","","","","","","","","","","English","","","","WOS:000806028400006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CTQTTKDD","journalArticle","2022","Pérez-Espinosa, H; Gutiérrez-Serafín, B; Martínez-Miranda, J; Espinosa-Curiel, IE","Automatic children's personality assessment from emotional speech","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2021.115885","","Identifying personality traits in children is a topic of interest due to its importance in adapting strategies for the teaching-learning process and detecting psychopathological features. The most straightforward procedure to identify children's personality type is by applying a validated and suitable questionnaire according to their age. However, an interesting approach is automatically identifying the children's personalities using their speech generated during their interaction with computer systems, software, or robots. This approach would allow obtaining the personality identification transparently to the children without answering a written test. This article presents a method for the automatic personality assessment of children between 8 and 12 years old. The assessment is based on their voices' acoustic analysis while participating in playful activity with another child and a robot. We created a database with 98 children involved in several activities while their voices were recorded. The database was labeled with five paralinguistic aspects. Using these labels, we trained a set of classification models that helped us recognize primary and secondary personality traits according to the Children's Personality Questionnaire. We obtained good results for two secondary personality traits, extroversion (0.89 F-Score) and excitability (0.79 F-Score). The best F-score obtained for anxiety was 0.70. These results indicate that it is feasible to estimate personality from analyzing children's voices during interaction with computer systems.","2022-01","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","187","","","","","","","","","","English","","","","WOS:000704060500005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","Affective computing; Computational paralinguistics; PERCEPTION; Personality assessment; Personality aware systems; PREDICTION; Speech analysis; TRAITS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MS6QM3GJ","journalArticle","2023","Ribas, D; Pastor, MA; Miguel, A; Martinez, D; Ortega, A; Lleida, E","Automatic Voice Disorder Detection Using Self-Supervised Representations","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3243986","","Many speech features and models, including Deep Neural Networks (DNN), are used for classification tasks between healthy and pathological speech with the Saarbruecken Voice Database (SVD). However, accuracy values of 80.71% for phrases or 82.8% for vowels /aiu/ are the highest reported for audio samples in SVD when the evaluation includes the wide amount of pathologies in the database, instead of a selection of some pathologies. This paper targets this top performance in the state-of-the-art Automatic Voice Disorder Detection (AVDD) systems. In the framework of a DNN-based AVDD system we study the capability of Self-Supervised (SS) representation learning for describing discriminative cues between healthy and pathological speech. The system processes the SS temporal sequence of features with a single feed-forward layer and Class-Token (CT) Transformer for obtaining the classification between healthy and pathological speech. Furthermore, there is evaluated a suitable data extension of the training set with out-ofdomain data is also evaluated to deal with the low availability of data for using DNN-based models in voice pathology detection. Experimental results using audio samples corresponding to phrases in the SVD dataset, including all pathologies available, show classification accuracy values until 93.36%. This means that the proposed AVDD system achieved accuracy improvements of 4.1% without the training data extension, and 15.62% after the training data extension compared to the baseline system. Beyond the novelty of using SS representations for AVDD, the fact of obtaining accuracies over 90% in these conditions and using the whole set of pathologies in the SVD is a milestone for voice disorder-related research. Furthermore, the study on the amount of in-domain data in the training set related to the system performance show guidance for the data preparation stage. Lessons learned in this work suggest guidelines for taking advantage of DNN, to boost the performance in developing automatic systems for diagnosis, treatment, and monitoring of voice pathologies.","2023","2025-02-26 20:43:31","2025-02-26 20:43:31","","14915-14927","","","11","","","","","","","","","","English","","","","WOS:000936230300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","advanced voice function assessment database; class token; deep neural networks; pathological speech; PATHOLOGY DETECTION; PREVALENCE; Saarbruecken voice database; self-supervised; transformer; Voice disorder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EI6BU3E2","journalArticle","2024","García-Valdez, AA; Román-Godínez, I; Salido-Ruiz, RA; Torres-Ramos, S","Identifying PTSD sex-based patterns through explainable artificial intelligence in biometric data","NETWORK MODELING AND ANALYSIS IN HEALTH INFORMATICS AND BIOINFORMATICS","","2192-6662","10.1007/s13721-024-00485-y","","Post-Traumatic Stress Disorder (PTSD) is a mental health condition that arises from exposure to traumatic events, affecting various aspects of human well-being. The complexity and variability of symptoms pose challenges for accurate diagnosis and monitoring, exacerbated by accessibility barriers. In response, alternative methodologies leveraging biometric data have emerged, such as facial movements, speech, or voice-to-text transcriptions, and analyzing them using Explainable Artificial Intelligence (XAI) techniques. Numerous studies have explored the presence or absence of PTSD, yet few have concentrated on either explicable indicators or distinctions among these indicators, such as the patient's sex. This research used an XAI algorithm to identify patterns related to PTSD in three biometric data sets: facial movements, speech, and voice-to-text transcriptions. Such biometric data are grouped by sex. Utilizing the DAIC-WOZ database, this study involves feature selection and characterization. Experiment configurations addressed participant segmentation, feature reduction, and standardization. Training phases employed machine-learning classification algorithms with their corresponding performance evaluation. The interpretability stage explored the relationship between input features and class output. The findings reveal that among the three biometric data sets evaluated in this work (facial movements, speech, and voice-to-text transcriptions), speech characterization is the most effective in identifying PTSD indicators, suggesting a uniform speech pattern associated with breathy and tense voice and weak phonation in PTSD patients. Sex-specific analysis enhances prediction performance, revealing distinctions in the associated speech features. The Women's model prioritizes tense voice and vocal volume variations, reduced glottal closure, and interrupted phonation. Conversely, the Speech-Men model reflects reduced resonance, making the voice thinner and weaker, indicating altered vocal quality. As for facial movements, sex-specific characteristics are not evident, but some features focused on lips are associated with PTSD. Similarly, PTSD is related to alertness, determination, and anxiety in both women and men. In conclusion, using an XAI algorithm to differentiate sex-based patterns in biometric data contributes to a better understanding of PTSD indicators, offering potential advancements in personalized diagnostic strategies.","2024-09-04","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","1","13","","","","","","","","","","English","","","","WOS:001308533400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Biometric data; Explainable artificial intelligence; POSTTRAUMATIC-STRESS-DISORDER; PTSD; Sex-based analysis; SHAP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I2U53PFL","journalArticle","2024","Yang, LR; Mu, Y; Zhai, YX; Chen, RJ","Impaired speech input and output processing abilities in children with cleft palate speech disorder","INTERNATIONAL JOURNAL OF LANGUAGE & COMMUNICATION DISORDERS","","1368-2822","10.1111/1460-6984.13037","","BackgroundCleft lip and palate is one of the most common oral and maxillofacial deformities associated with a variety of functional disorders. Cleft palate speech disorder (CPSD) occurs the most frequently and manifests a series of characteristic speech features, which are called cleft speech characteristics. Some scholars believe that children with CPSD and poor speech outcomes may also have weaknesses in speech input processing ability, but evidence is still lacking so far.Aims(1) To explore whether children with CPSD and speech output disorders also have defects in speech input processing abilities; (2) to explore the correlation between speech input and output processing abilities. Methods & Procedures: Children in the experimental group were enrolled from Beijing Stomatological Hospital, Capital Medical University, and healthy volunteers were recruited as controls. Then three tasks containing real and pseudo words were performed sequentially. Reaction time, accuracy and other indicators in three tasks were collected and then analysed.Aims(1) To explore whether children with CPSD and speech output disorders also have defects in speech input processing abilities; (2) to explore the correlation between speech input and output processing abilities. Methods & Procedures: Children in the experimental group were enrolled from Beijing Stomatological Hospital, Capital Medical University, and healthy volunteers were recruited as controls. Then three tasks containing real and pseudo words were performed sequentially. Reaction time, accuracy and other indicators in three tasks were collected and then analysed.Outcomes & ResultsThe indicators in the experimental group were significantly lower than those in the control group. There was a strong correlation between speech input and output processing tasks. The performance of both groups when processing pseudo words in the three tasks was worse than that when dealing with real words.Conclusions & ImplicationsCompared with normal controls, children with CPSD have deficits in both speech input and output processing, and there is a strong correlation between speech input and output speech processing abilities. In addition, the pseudo words task was more challenging than the real word task for both groups.","2024-09","2025-02-26 20:43:31","2025-02-26 20:43:31","","1906-1922","","5","59","","","","","","","","","","English","","","","WOS:001217088100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","5-YEAR-OLDS; ARTICULATION; AUDIT PROTOCOL; cleft palate; LIP; OUTCOMES; PHONOLOGICAL AWARENESS; SKILLS; speech disorder; speech processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A6K3EK2Q","journalArticle","2021","García, SKB; Lucero, ES; Huerta, EB; Hernández, JCH; Cruz, JFR; Méndez, BEP","Implementation of Neural Machine Translation for Nahuatl as a Web Platform: A Focus on Text Translation","PROGRAMMING AND COMPUTER SOFTWARE","","0361-7688","10.1134/S0361768821080168","","Thereare few on-line platforms related to Natural Language Processing and zero services of machine translation for Nahuatl as a low-resource language. However, Nahuatl has had academical implementations on machine translation, from Statistical Machine Translation (SMT) to Neural Machine Translation (NMT), in specific Recurrent Neural Networks (RNNs). This research aims to create a platform that can address this issue with text, voice and Text-To-Speech features. In particular, the current paper presents several advancements on text translation as a comparative analysis between two attention architectures, transformers and RNNs using several models that combine such architectures, two parallel corpuses, and two tokenization techniques. Additionally, the development of a platform and iOS application client is described. A new and bigger corpus, over 35,000 pairs, is made to improve the state of the art, where a conscious cleaning of it shows a reduction on the religious bias presented on the source text. The model performance is evaluated with % BLEU in order to conduct a direct comparative on previous Nahuatl machine translation works. The results outperformed those works with a score of 66.45 at best using transformers compared to 34.78 and 14.28 for RNNs and SMT respectively, confirming that transformers and a sub-word tokenization are the best combination so far for Nahuatl Machine translation. Moreover, emerging behaviors were observed in the Transformers, where a subtle pleonasm seen only in rural locations where Mexican Spanish is spoken arouse from the model, linking its origin to Nahuatl, as well as the ability of the model of transforming numbers from base 10 to base 20. Finally, some out of corpus translations were presented to a Nahuatl speaker where the model demonstrated a good performance and retention of information for its size. This research seeks to be used as a framework of how a polysynthetic language can be manipulated to be used for different languages like Spanish, English or Russian. This research work was carried out at the ""Tecnologico Nacional de Mexico"" (TecNM), campus ""Instituto Tecnologico de Apizaco"" (ITA).","2021-12","2025-02-26 20:43:31","2025-02-26 20:43:31","","778-792","","8","47","","","","","","","","","","English","","","","WOS:000736161100017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q5D4DJBF","journalArticle","2021","Mesik, J; Ray, L; Wojtczak, M","Effects of Age on Cortical Tracking of Word-Level Features of Continuous Competing Speech","FRONTIERS IN NEUROSCIENCE","","1662-453X","10.3389/fnins.2021.635126","","Speech-in-noise comprehension difficulties are common among the elderly population, yet traditional objective measures of speech perception are largely insensitive to this deficit, particularly in the absence of clinical hearing loss. In recent years, a growing body of research in young normal-hearing adults has demonstrated that high-level features related to speech semantics and lexical predictability elicit strong centro-parietal negativity in the EEG signal around 400 ms following the word onset. Here we investigate effects of age on cortical tracking of these word-level features within a two-talker speech mixture, and their relationship with self-reported difficulties with speech-in-noise understanding. While undergoing EEG recordings, younger and older adult participants listened to a continuous narrative story in the presence of a distractor story. We then utilized forward encoding models to estimate cortical tracking of four speech features: (1) word onsets, (2) ""semantic"" dissimilarity of each word relative to the preceding context, (3) lexical surprisal for each word, and (4) overall word audibility. Our results revealed robust tracking of all features for attended speech, with surprisal and word audibility showing significantly stronger contributions to neural activity than dissimilarity. Additionally, older adults exhibited significantly stronger tracking of word-level features than younger adults, especially over frontal electrode sites, potentially reflecting increased listening effort. Finally, neuro-behavioral analyses revealed trends of a negative relationship between subjective speech-in-noise perception difficulties and the model goodness-of-fit for attended speech, as well as a positive relationship between task performance and the goodness-of-fit, indicating behavioral relevance of these measures. Together, our results demonstrate the utility of modeling cortical responses to multi-talker speech using complex, word-level features and the potential for their use to study changes in speech processing due to aging and hearing loss.","2021-04-01","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","15","","","","","","","","","","English","","","","WOS:000640067700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;16<br/>Cited Reference Count:&nbsp;&nbsp;84</p>","","","aging; BLIND SEPARATION; BRAIN POTENTIALS; COGNITIVE-FACTORS; electroencephalography; HEARING-LOSS; lexical surprisal; LINGUISTIC CONTEXT; NATURAL SPEECH; NOISE; PERCEPTION; QUALITY-OF-LIFE; RECOGNITION; semantic processing; speech perception; speech-in-noise (SIN) perception; temporal response function (TRF)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"55UX5V8V","journalArticle","2023","Ahmed, MR; Islam, S; Islam, AKMM; Shatabda, S","An ensemble 1D-CNN-LSTM-GRU model with data augmentation for speech emotion recognition","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2023.119633","","Precise recognition of emotion from speech signals aids in enhancing human-computer interaction (HCI). The performance of a speech emotion recognition (SER) system depends on the derived features from speech signals. However, selecting the optimal set of feature representations remains the most challenging task in SER because the effectiveness of features varies with emotions. Most studies extract hidden local speech features ignoring the global long-term contextual representations of speech signals. The existing SER system suffers from low recog-nition performance mainly due to the scarcity of available data and sub-optimal feature representations. Moti-vated by the efficient feature extraction of convolutional neural network (CNN), long short-term memory (LSTM), and gated recurrent unit (GRU), this article proposes an ensemble utilizing the combined predictive performance of three different architectures. The first architecture uses 1D CNN followed by Fully Connected Networks (FCN). In the other two architectures, LSTM-FCN and GRU-FCN layers follow the CNN layer respec-tively. All three individual models focus on extracting both local and long-term global contextual representations of speech signals. The ensemble uses a weighted average of the individual models. We evaluated the model's performance on five benchmark datasets: TESS, EMO-DB, RAVDESS, SAVEE, and CREMA-D. We have augmented the data by injecting additive white gaussian noise, pitch shifting, and stretching the signal level to obtain better model generalization. Five categories of features were extracted from the speech samples: mel-frequency cepstral coefficients, log mel-scaled spectrogram, zero-crossing rate, chromagram, and root mean square value from each audio file in those datasets. All four models perform exceptionally well in the SER task; notably, the ensemble model accomplishes the state-of-the-art (SOTA) weighted average accuracy of 99.46% for TESS, 95.42% for EMO-DB, 95.62% for RAVDESS, 93.22% for SAVEE, and 90.47% for CREMA-D datasets and thus significantly outperformed the SOTA models using the same datasets.","2023-05-15","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","218","","","","","","","","","","English","","","","WOS:000963710400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;58<br/>Total Times Cited:&nbsp;&nbsp;58<br/>Cited Reference Count:&nbsp;&nbsp;105</p>","","","1D CNN GRU LSTM network; 2D CNN; CLASSIFICATION; Data augmentation; Ensemble learning; FEATURE-SELECTION; FEATURES; Human-computer interaction; NETWORK; Speech emotion recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UPM68G9A","journalArticle","2024","Parisae, V; Bhavanam, SN","Stacked U-Net with Time-Frequency Attention and Deep Connection Net for Single Channel Speech Enhancement","INTERNATIONAL JOURNAL OF IMAGE AND GRAPHICS","","0219-4678","10.1142/S0219467825500676","","Deep neural networks have significantly promoted the progress of speech enhancement technology. However, a great number of speech enhancement approaches are unable to fully utilize context information from various scales, hindering performance enhancement. To tackle this issue, we introduce a method called TFADCSU-Net (Stacked U-Net with Time-Frequency Attention (TFA) and Deep Connection Layer (DCL)) for enhancing noisy speech in the time-frequency domain. TFADCSU-Net adopts an encoder-decoder structure with skip links. Within TFADCSU-Net, a multiscale feature extraction layer (MSFEL) is proposed to effectively capture contextual data from various scales. This allows us to leverage both global and local speech features to enhance the reconstruction of speech signals. Moreover, we incorporate deep connection layer and TFA mechanisms into the network to further improve feature extraction and aggregate utterance level context. The deep connection layer effectively captures rich and precise features by establishing direct connections starting from the initial layer to all subsequent layers, rather than relying on connections from earlier layers to subsequent layers. This approach not only enhances the information flow within the network but also avoids a significant rise in computational complexity as the number of network layers increases. The TFA module consists of two attention branches operating concurrently: one directed towards the temporal dimension and the other towards the frequency dimension. These branches generate distinct forms of attention - one for identifying relevant time frames and another for selecting frequency wise channels. These attention mechanisms assist the models in discerning ""where"" and ""what"" to prioritize. Subsequently, the TA and FA branches are combined to produce a comprehensive attention map in two dimensions. This map assigns specific attention weights to individual spectral components in the time-frequency representation, enabling the networks to proficiently capture the speech characteristics in the T-F representation. The results confirm that the proposed method outperforms other models in terms of objective speech quality as well as intelligibility.","2024-04-09","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","","","","","","","","","","","","English","","","","WOS:001198655800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","DCL deep connection layer; DNN deep neural network; MSFEL - multiscale feature extraction layer; MULTISCALE; NOISE; RECURRENT NEURAL-NETWORK; T-F time-frequency; TFA - time-frequency attention","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PLLRBVM5","journalArticle","2024","Mohammad, F; Al Mansoor, KM","MDD: A Unified Multimodal Deep Learning Approach for Depression Diagnosis Based on Text and Audio Speech","CMC-COMPUTERS MATERIALS & CONTINUA","","1546-2218","10.32604/cmc.2024.056666","","Depression is a prevalent mental health issue affecting individuals of all age groups globally. Similar to other mental health disorders, diagnosing depression presents significant challenges for medical practitioners and clinical experts, primarily due to societal stigma and a lack of awareness and acceptance. Although medical interventions such as therapies, medications, and brain stimulation therapy provide hope for treatment, there is still a gap in the efficient detection of depression. Traditional methods, like in-person therapies, are both time-consuming and labor-intensive, emphasizing the necessity for technological assistance, especially through Artificial Intelligence. Alternative to this, in most cases it has been diagnosed through questionnaire-based mental status assessments. However, this method often produces inconsistent and inaccurate results. Additionally, there is currently a lack of a comprehensive diagnostic framework that could be effective achieving accurate and robust diagnostic outcomes. For a considerable time, researchers have sought methods to identify symptoms of depression through individuals' speech and responses, leveraging automation systems and computer technology. This research proposed MDD which composed of multimodal data collection, preprocessing, and feature extraction (utilizing the T5 model for text features and the WaveNet model for speech features). Canonical Correlation Analysis (CCA) is then used to create correlated projections of text and audio features, followed by feature fusion through concatenation. Finally, depression detection is performed using a neural network with a sigmoid output layer. The proposed model achieved remarkable performance, on the Distress Analysis Interview Corpus-Wizard (DAIC-WOZ) dataset, it attained an accuracy of 92.75%, precision of 92.05%, and recall of 92.22%. For the E-DAIC dataset, it achieved an accuracy of 91.74%, precision of 90.35%, and recall of 90.95%. Whereas, on CD-III dataset (Custom Dataset for Depression), the model demonstrated an accuracy of 93.05%, precision of 92.12%, and recall of 92.85%. These results underscore the model's robust capability in accurately diagnosing depressive disorder, demonstrating the efficacy of advanced feature extraction methods and improved classification algorithm.","2024","2025-02-26 20:43:31","2025-02-26 20:43:31","","4125-4147","","3","81","","","","","","","","","","English","","","","WOS:001385235800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","CCA; deep learning; Depression; neural network; SOCIAL MEDIA; T5; WaveNet","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GKLS8SL9","journalArticle","2021","Geravanchizadeh, M; Forouhandeh, E; Bashirpour, M","Feature compensation based on the normalization of vocal tract length for the improvement of emotion-affected speech recognition","EURASIP JOURNAL ON AUDIO SPEECH AND MUSIC PROCESSING","","1687-4722","10.1186/s13636-021-00216-5","","The performance of speech recognition systems trained with neutral utterances degrades significantly when these systems are tested with emotional speech. Since everybody can speak emotionally in the real-world environment, it is necessary to take account of the emotional states of speech in the performance of the automatic speech recognition system. Limited works have been performed in the field of emotion-affected speech recognition and so far, most of the researches have focused on the classification of speech emotions. In this paper, the vocal tract length normalization method is employed to enhance the robustness of the emotion-affected speech recognition system. For this purpose, two structures of the speech recognition system based on hybrids of hidden Markov model with Gaussian mixture model and deep neural network are used. To achieve this goal, frequency warping is applied to the filterbank and/or discrete-cosine transform domain(s) in the feature extraction process of the automatic speech recognition system. The warping process is conducted in a way to normalize the emotional feature components and make them close to their corresponding neutral feature components. The performance of the proposed system is evaluated in neutrally trained/emotionally tested conditions for different speech features and emotional states (i.e., Anger, Disgust, Fear, Happy, and Sad). In this system, frequency warping is employed for different acoustical features. The constructed emotion-affected speech recognition system is based on the Kaldi automatic speech recognition with the Persian emotional speech database and the crowd-sourced emotional multi-modal actors dataset as the input corpora. The experimental simulations reveal that, in general, the warped emotional features result in better performance of the emotion-affected speech recognition system as compared with their unwarped counterparts. Also, it can be seen that the performance of the speech recognition using the deep neural network-hidden Markov model outperforms the system employing the hybrid with the Gaussian mixture model.","2021-08-04","2025-02-26 20:43:31","2025-02-26 20:43:31","","","","1","2021","","","","","","","","","","English","","","","WOS:000681310200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Acoustic feature normalization; Emotion-affected speech recognition; Frequency warping; NETWORKS; Vocal tract length normalization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5R6VSIAZ","journalArticle","2023","Kiyani, HS; Naz, S; Mubeen, R; Zubair, R","Effectiveness of a Verbal Expressive Skills Management Program for Pakistani Patients with Broca Aphasia: A Randomized Clinical Trial","ALTERNATIVE THERAPIES IN HEALTH AND MEDICINE","","1078-6791","","","Background center dot It is estimated that 25% of the patients in Pakistan experience stroke resulting in problems with language. Among many of the conditions, problem with verbal expressive production (Broca's Aphasia) is one of the main problem faced by people having stoke. Many traditional therapies are incorporated to treat symptoms of Aphasia including fluent and non-fluent Aphasia. Objectives center dot The primary objective of the current study was to determine the effectiveness of Verbal Expressive Skill Management Program in Urdu (VESMP-U) with convention speech therapy, Melodic Intonation therapy (MIT) in enhancing the verbal expressive skills in patients with severe Broca's Aphasia. Another objective of this study was to compare the efficacy of Verbal Expressive Skill Management Program in Urdu (VESMP-U) with traditional therapy, as well as the quality of life of patients with severe Broca's Aphasia. Methods center dot A randomized control trial (NCT03699605, clinicaltrials.gov) was conducted from November 2018 June 2019 in Pakistan railway Hospital (PRH). Patients having a three-month history of severe Broca's Aphasia, aged between 40-60 years, bilingual (Urdu and English language) and having the ability to use a smart phone were included in the study. Patients with cognitive impairments were excluded. Total of 77 patients were evaluated for eligibility criteria according to the G Power software for sample size. Out of 77, 54 individuals fulfilled the inclusion criteria. The participants were divided into 2 groups (27 each) through sealed envelope method. Patients of both groups were assessed pre and post intervention using the Boston Diagnostic Aphasia Examination (BADE) battery (Primary outcome measure). Experimental group n = 25 received VESMP-U therapy and control group n = 25 (2 drop out in each group) received MIT for 16 weeks i.e. 4 days per week having 64 sessions altogether. Each intervention session lasted up to 30-45 minutes for both groups. Results center dot Within and between group analysis after intervention showed that the VESMP-U group had significantly improved BDAE scores (P = .001; 95% CI) than the MIT group for all variables (articulatory intelligibility, phrase length, grammatical form, prosody/intonation, spontaneous speech, word finding, repetition, and auditory comprehension). The BDAE scores of participants in experimental group having VESMP-U therapy pre- and post-intervention were statistically significant (P = .001; 95% CI), which indicates that participant's communication skills were enhanced by use of VESMP-U. Conclusion center dot Android based application VESMP-U has been found to be effective in improving expression and quality of life of patients with severe Broca's aphasia.","2023-09","2025-02-26 20:43:31","2025-02-26 20:43:31","","204-208","","6","29","","","","","","","","","","English","","","","WOS:001050004000030","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","STROKE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W27SDQ3A","journalArticle","2024","Ji, XJ; Liao, ZZ; Dong, LF; Tang, YC; Li, GM; Mao, M","3D facial animation driven by speech-video dual-modal signals","COMPLEX & INTELLIGENT SYSTEMS","","2199-4536","10.1007/s40747-024-01481-5","","In recent years, the applications of digital humans have become increasingly widespread. One of the most challenging core technologies is the generation of highly realistic and automated 3D facial animation that combines facial movements and speech. The single-modal 3D facial animation driven by speech typically ignores the weak correlation between speech and upper facial movements as well as head posture. In contrast, the video-driven approach can perfectly solve the posture problem while obtaining natural expressions. However, mapping 2D facial information to 3D facial information may lead to information loss, which make lip synchronization generated by video-driven methods is not as good as the speech-driven methods trained on 4D facial data. Therefore, this paper proposes a dual-modal generation method that uses speech and video information to generate more natural and vivid 3D facial animation. Specifically, the lip movements related to speech are generated by speech-video information, while speech-uncorrelated postures and expressions are generated solely by video information. The speech-driven module is used to extract speech features, and its output lip animation is then used as the foundation for facial animation. The expression and pose module is used to extract temporal visual features for regressing expression and head posture parameters. We fuse speech and video features to obtain chin posture parameters related to lip movements, and use these parameters to fine-tune the lip animation generated form the speech-driven module. This paper introduces multiple consistency losses to enhance the network's capability to generate expressions and postures. Experiments conducted on the LRS3, TCD-TIMIT and MEAD datasets show that the proposed method achieves better performance on evaluation metrics such as CER, WER, VER and VWER than the current state-of-the-art methods. In addition, a perceptual user study show that over 77% and 70% of cases believe that this paper's method is better than the comparative algorithms EMOCA and SPECTRE in terms of realism. In terms of lip synchronization, it received over 79% and 66% of cases support, respectively. Both evaluation methods demonstrate the effectiveness of the proposed method.","2024-10","2025-02-26 20:43:31","2025-02-26 20:43:31","","5951-5964","","5","10","","","","","","","","","","English","","","","WOS:001230082000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","3D facial animation; AUDIO; Deep learning; Dual-modal; Speech-video driven","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GF7FFVHS","journalArticle","2021","Chen, X; Huang, RB; Li, X; Xiao, L; Zhou, M; Zhang, LH","A Novel User Emotional Interaction Design Model Using Long and Short-Term Memory Networks and Deep Learning","FRONTIERS IN PSYCHOLOGY","","1664-1078","10.3389/fpsyg.2021.674853","","Emotional design is an important development trend of interaction design. Emotional design in products plays a key role in enhancing user experience and inducing user emotional resonance. In recent years, based on the user's emotional experience, the design concept of strengthening product emotional design has become a new direction for most designers to improve their design thinking. In the emotional interaction design, the machine needs to capture the user's key information in real time, recognize the user's emotional state, and use a variety of clues to finally determine the appropriate user model. Based on this background, this research uses a deep learning mechanism for more accurate and effective emotion recognition, thereby optimizing the design of the interactive system and improving the user experience. First of all, this research discusses how to use user characteristics such as speech, facial expression, video, heartbeat, etc., to make machines more accurately recognize human emotions. Through the analysis of various characteristics, the speech is selected as the experimental material. Second, a speech-based emotion recognition method is proposed. The mel-Frequency cepstral coefficient (MFCC) of the speech signal is used as the input of the improved long and short-term memory network (ILSTM). To ensure the integrity of the information and the accuracy of the output at the next moment, ILSTM makes peephole connections in the forget gate and input gate of LSTM, and adds the unit state as input data to the threshold layer. The emotional features obtained by ILSTM are input into the attention layer, and the self-attention mechanism is used to calculate the weight of each frame of speech signal. The speech features with higher weights are used to distinguish different emotions and complete the emotion recognition of the speech signal. Experiments on the EMO-DB and CASIA datasets verify the effectiveness of the model for emotion recognition. Finally, the feasibility of emotional interaction system design is discussed.","2021-04-20","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","12","","","","","","","","","","English","","","","WOS:000646589000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","emotion recognition; FEATURES; interaction design; LSTM; RECOGNITION; self-attention mechanism; speech; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L4IRVT84","journalArticle","2022","Wu, TT; Wen, ML","An English Teaching Ability Assessment Method Based on Fuzzy Mean-Shift Clustering","SCIENTIFIC PROGRAMMING","","1058-9244","10.1155/2022/4219249","","This paper presents an in-depth study and analysis of the assessment of English teaching ability using the algorithm of fuzzy mean-shift clustering. The paper proposes an automatic scoring model for Chinese-English sentence-level interpretation based on semantic scoring. The automatic scoring model calculates candidates' Chinese-English sentence interpretation scores by fusing the feature parameters at both the phonological and content levels. Adaptive weights are introduced to fuse the current pixel and the neighborhood mean with adaptive weighting, and the weighted entropy constraint term is embedded in the clustering objective function to solve the selection problem of the weighting parameters. Finally, the graphical fuzzy division information of the neighboring pixels is used to construct the local spatial information constraint term of the current pixel, and the graphical fuzzy division term of the current pixel is adjusted to correct the clustering center obtained from the iteration. Fluency is selected as the feature scoring parameter at the speech level, and the automatic scoring model directly scores the fluency features of the candidates' recordings; two feature scoring parameters, keywords, and sentence semantics are selected at the content level, and the content features are scored after converting the candidates' recordings to text by manual conversion. The zero-energy product method is used to extract speech features to calculate fluency feature scores; the semantic scoring model introduced in this paper is used to calculate keyword and sentence semantic feature scores; finally, the random forest algorithm is used to fuse the above three feature scoring parameters to obtain the total quality score of Chinese-English interpretation. Considering the correlation of neighborhood pixel affiliation, the KL scatter and affiliation space information is used to supervise the current pixel affiliation, to further improve the segmentation accuracy of the algorithm; finally, segmentation tests are conducted on synthetic images, medical images, and remote sensing images. The results show that the proposed algorithm has a stronger noise suppression ability and can obtain more satisfactory segmentation results than other robust fuzzy clustering algorithms.","2022-05-04","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","2022","","","","","","","","","","English","","","","WOS:000797442800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","GESTURE RECOGNITION; IMPLEMENTATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FX43CVTG","journalArticle","2021","Adeel, A; Gogate, M; Hussain, A; Whitmer, WM","Lip-Reading Driven Deep Learning Approach for Speech Enhancement","IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE","","2471-285X","10.1109/TETCI.2019.2917039","","This paper proposes a novel lip-reading driven deep learning framework for speech enhancement. The approach leverages the complementary strengths of both deep learning and analytical acoustic modeling (filtering-based approach) as compared to benchmark approaches that rely only on deep learning. The proposed audio-visual (AV) speech enhancement framework operates at two levels. In the first level, a novel deep learning based lip-reading regression model is employed. In the second level, lip-reading approximated clean-audio features are exploited, using an enhanced, visually-derived Wiener filter (EVWF), for estimating the clean audio power spectrum. Specifically, a stacked long-short-term memory (LSTM) based lip-reading regression model is designed for estimating the clean audio features using only temporal visual features (i.e., lip reading), by considering a range of prior visual frames. For clean speech spectrum estimation, a new filterbank-domain EVWF is formulated, which exploits the estimated speech features. The EVWF is compared with conventional spectral subtraction and log-minimum mean-square error methods using both ideal AV mapping and LSTM driven AV mapping approaches. The potential of the proposed AV speech enhancement framework is evaluated under four different dynamic real-world scenarios [cafe, street junction, public transport, and pedestrian area] at different SNR levels (ranging from low to high SNRs) using benchmark grid and ChiME3 corpora. For objective testing, perceptual evaluation of speech quality is used to evaluate the quality of restored speech. For subjective testing, the standard mean-opinion-score method is used with inferential statistics. Comparative simulation results demonstrate significant lip-reading and speech enhancement improvements in terms of both speech quality and speech intelligibility. Ongoing work is aimed at enhancing the accuracy and generalization capability of the deep learning driven lip-reading model, using contextual integration of AV cues, leading to context-aware, autonomous AV speech enhancement.","2021-06","2025-02-26 20:43:32","2025-02-26 20:43:32","","481-490","","3","5","","","","","","","","","","English","","","","WOS:000658320500013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;34<br/>Total Times Cited:&nbsp;&nbsp;34<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","audio-visual ChiME3 corpus; context-aware audio-visual speech enhancement; Deep learning; enhanced visually-derived Wiener filtering; Feature extraction; Hidden Markov models; INFORMATION; Lip-reading; Lips; Speech enhancement; stacked long-short-term memory; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PYB7RF72","journalArticle","2022","Kakuba, S; Poulose, A; Han, DS","Attention-Based Multi-Learning Approach for Speech Emotion Recognition With Dilated Convolution","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3223705","","The success of deep learning in speech emotion recognition has led to its application in resource-constrained devices. It has been applied in human-to-machine interaction applications like social living assistance, authentication, health monitoring and alertness systems. In order to ensure a good user experience, robust, accurate and computationally efficient deep learning models are necessary. Recurrent neural networks (RNN) like long short-term memory (LSTM), gated recurrent units (GRU) and their variants that operate sequentially are often used to learn time series sequences of the signal, analyze long-term dependencies and the contexts of the utterances in the speech signal. However, due to their sequential operation, they encounter problems in convergence and sluggish training that uses a lot of memory resources and encounters the vanishing gradient problem. In addition, they do not consider spatial cues that may exist in the speech signal. Therefore, we propose an attention-based multi-learning model (ABMD) that uses residual dilated causal convolution (RDCC) blocks and dilated convolution (DC) layers with multi-head attention. The proposed ABMD model achieves comparable performance while taking global contextualized long-term dependencies between features in a parallel manner using a large receptive field with less increase in the number of parameters compared to the number of layers and considers spatial cues among the speech features. Spectral and voice quality features extracted from the raw speech signals are used as inputs. The proposed ABMD model obtained a recognition accuracy and F1 score of 93.75% and 92.50% on the SAVEE datasets, 85.89% and 85.34% on the RAVDESS datasets and 95.93% and 95.83% on the EMODB datasets. The model's robustness in terms of the confusion ratio of the individual discrete emotions especially happiness which is often confused with emotions that belong to the same dimensional plane with it also improved when validated on the same datasets.","2022","2025-02-26 20:43:32","2025-02-26 20:43:32","","122302-122313","","","10","","","","","","","","","","English","","","","WOS:000916756000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Computational modeling; Convolution; Deep learning; Emotion recognition; Feature extraction; LSTM; multi-head attention; residual dilated causal convolution; Speech recognition; Task analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MWRNLMRM","journalArticle","2023","Desai, M; Field, AM; Hamilton, LS","Dataset size considerations for robust acoustic and phonetic speech encoding models in EEG","FRONTIERS IN HUMAN NEUROSCIENCE","","1662-5161","10.3389/fnhum.2022.1001171","","In many experiments that investigate auditory and speech processing in the brain using electroencephalography (EEG), the experimental paradigm is often lengthy and tedious. Typically, the experimenter errs on the side of including more data, more trials, and therefore conducting a longer task to ensure that the data are robust and effects are measurable. Recent studies used naturalistic stimuli to investigate the brain's response to individual or a combination of multiple speech features using system identification techniques, such as multivariate temporal receptive field (mTRF) analyses. The neural data collected from such experiments must be divided into a training set and a test set to fit and validate the mTRF weights. While a good strategy is clearly to collect as much data as is feasible, it is unclear how much data are needed to achieve stable results. Furthermore, it is unclear whether the specific stimulus used for mTRF fitting and the choice of feature representation affects how much data would be required for robust and generalizable results. Here, we used previously collected EEG data from our lab using sentence stimuli and movie stimuli as well as EEG data from an open-source dataset using audiobook stimuli to better understand how much data needs to be collected for naturalistic speech experiments measuring acoustic and phonetic tuning. We found that the EEG receptive field structure tested here stabilizes after collecting a training dataset of approximately 200 s of TIMIT sentences, around 600 s of movie trailers training set data, and approximately 460 s of audiobook training set data. Thus, we provide suggestions on the minimum amount of data that would be necessary for fitting mTRFs from naturalistic listening data. Our findings are motivated by highly practical concerns when working with children, patient populations, or others who may not tolerate long study sessions. These findings will aid future researchers who wish to study naturalistic speech processing in healthy and clinical populations while minimizing participant fatigue and retaining signal quality.","2023-01-20","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","16","","","","","","","","","","English","","","","WOS:000926928500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","electroencephalography; experimental design; linear model; natural stimuli; NEURONS; RECEPTIVE-FIELDS; RESPONSES; spectrotemporal receptive field","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VA6MDYIP","journalArticle","2023","Hovsepyan, S; Olasagasti, I; Giraud, AL","Rhythmic modulation of prediction errors: A top-down gating role for the beta-range in speech processing","PLOS COMPUTATIONAL BIOLOGY","","1553-734X","10.1371/journal.pcbi.1011595","","Natural speech perception requires processing the ongoing acoustic input while keeping in mind the preceding one and predicting the next. This complex computational problem could be handled by a dynamic multi-timescale hierarchical inferential process that coordinates the information flow up and down the language network hierarchy. Using a predictive coding computational model (Precoss-beta) that identifies online individual syllables from continuous speech, we address the advantage of a rhythmic modulation of up and down information flows, and whether beta oscillations could be optimal for this. In the model, and consistent with experimental data, theta and low-gamma neural frequency scales ensure syllable-tracking and phoneme-level speech encoding, respectively, while the beta rhythm is associated with inferential processes. We show that a rhythmic alternation of bottom-up and top-down processing regimes improves syllable recognition, and that optimal efficacy is reached when the alternation of bottom-up and top-down regimes, via oscillating prediction error precisions, is in the beta range (around 20-30 Hz). These results not only demonstrate the advantage of a rhythmic alternation of up- and down-going information, but also that the low-beta range is optimal given sensory analysis at theta and low-gamma scales. While specific to speech processing, the notion of alternating bottom-up and top-down processes with frequency multiplexing might generalize to other cognitive architectures. During speech perception, our brain achieves continuous acoustic analysis of the ongoing speech signal, its transformation into linguistic representations, and the prediction of the most likely next words or syllables. In this computational study, we address the biological mechanisms underpinning the coordination of these operations during natural speech processing. Using a model that recognizes on-line syllables in natural sentences, we show that neural activity at specific rhythms is dedicated to specific operations, and that while the theta and low-gamma rhythms are engaged in speech features signaling and encoding, the more endogenous low-beta rhythm drives the rhythmic and coordinated modulation of prediction errors across levels of hierarchy.","2023-11","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","11","19","","","","","","","","","","English","","","","WOS:001101898700003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;97</p>","","","BAND; BRAIN OSCILLATIONS; FEEDBACK; FEEDFORWARD; GAMMA RHYTHMS; MODEL; NEURAL ACTIVITY; SHORTLIST; THETA; VISUAL-CORTEX","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S7UU78AE","journalArticle","2023","Özbay, FA; Özbay, E","A new approach for gender detection from voice data: Feature selection with optimization methods","JOURNAL OF THE FACULTY OF ENGINEERING AND ARCHITECTURE OF GAZI UNIVERSITY","","1300-1884","10.17341/gazimmfd.938294","","In recent years, gender detection has been an important problem in speech analysis, with many different applications. Different features of sound data such as pitch, median, and frequency are used for gender detection. In this study, a feature selection method based on metaheuristic optimization algorithms is proposed for gender detection from voice data. In the proposed method, the feature set representing the voice data in the most appropriate way is selected with optimization algorithms, and gender detection has been implemented with artificial intelligence algorithms using the obtained features. Nature-inspired metaheuristic optimization algorithms, which are capable of solving complex problems, are used to select features from voice data. Particle Swarm Optimization (PSO), Ant Colony Optimization (ACO), Salp Swarm Algorithm (SSA), and Whale Optimization Algorithm (WOA) have been modeled for the first time for feature selection from voice data. A publicly accessible data set has been used to measure the efficiency of metaheuristic optimization algorithms. The performances of PSO, ACO, SSA, and WOA for feature selection have been compared in terms of three different criteria: fitness function value, accuracy value, and the number of selected features. After feature selection with metaheuristic optimization algorithms, Naive Bayes and Decision Tree algorithms have been applied to the new data sets obtained and the original data set. As a result of the analysis, it was observed that this method which uses metaheuristic optimization algorithms for feature selection increased the success rate in the results obtained with Naive Bayes and Decision Tree algorithms.","2023","2025-02-26 20:43:32","2025-02-26 20:43:32","","1179-1192","","2","38","","","","","","","","","","English","","","","WOS:000873967500043","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","ALGORITHM; CANCER; classification; CLASSIFICATION; DESIGN; feature selection; Gender detection; IDENTIFICATION; optimization; REDUCTION; ROUGH; SEARCH; SET; WHALE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SSSKKCFK","journalArticle","2025","Garbey, M; Lesport, Q; Oztosun, G; Ghodasara, V; Kaminski, HJ; Bayat, E","Improving care for amyotrophic lateral sclerosis with artificial intelligence and affective computing","JOURNAL OF THE NEUROLOGICAL SCIENCES","","0022-510X","10.1016/j.jns.2024.123328","","Background: Patients with ALS often face difficulties expressing emotions due to impairments in facial expression, speech, body language, and cognitive function. This study aimed to develop non-invasive AI tools to detect and quantify emotional responsiveness in ALS patients, providing objective insights. Improved understanding of emotional responses could enhance patient-provider communication, telemedicine effectiveness, and clinical trial outcome measures. Methods: In this preliminary exploratory study, fourteen patients with ALS had audio recordings performed during routine clinic visits while wearing a wireless pulse oximeter. Emotion-triggering questions related to symptom progression, breathing, mobility, feeding tube, and financial burden were randomly asked. The same questions were posed in separate psychiatric evaluations. Natural language processing (NLP) was used to analyze transcriptions, topic classifications, sentiment, and emotional states, combining pulse and speech data. AI- generated reports summarized the findings. Results: Pulse alterations consistent with emotional arousal were identified, with longer consultations and positive communication reducing pulse fluctuations. Financial concerns triggered the strongest emotional response, while discussions about breathing, mobility, and feeding tube increased anxiety. AI-generated reports prioritized patient concerns and streamlined documentation for providers. Conclusions: This study introduces a novel approach to linking pulse and speech analysis to evaluate emotional responses in ALS patients. AI and affective computing provide valuable insights into emotional responses and disease progression, with potential applications for other neurological disorders. This approach could augment clinical trial outcomes by offering a more comprehensive view of patient well-being.","2025-01-15","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","468","","","","","","","","","","English","","","","WOS:001371581700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Affective computing; ALS; Amyotrophic lateral sclerosis; Clinical trial; Generative language; Natural language processing; Signal analysis; Telemedicine","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E4TJ6E2M","journalArticle","2024","Malekroodi, HS; Madusanka, N; Lee, BI; Yi, M","Leveraging Deep Learning for Fine-Grained Categorization of Parkinson's Disease Progression Levels through Analysis of Vocal Acoustic Patterns","BIOENGINEERING-BASEL","","2306-5354","10.3390/bioengineering11030295","","Speech impairments often emerge as one of the primary indicators of Parkinson's disease (PD), albeit not readily apparent in its early stages. While previous studies focused predominantly on binary PD detection, this research explored the use of deep learning models to automatically classify sustained vowel recordings into healthy controls, mild PD, or severe PD based on motor symptom severity scores. Popular convolutional neural network (CNN) architectures, VGG and ResNet, as well as vision transformers, Swin, were fine-tuned on log mel spectrogram image representations of the segmented voice data. Furthermore, the research investigated the effects of audio segment lengths and specific vowel sounds on the performance of these models. The findings indicated that implementing longer segments yielded better performance. The models showed strong capability in distinguishing PD from healthy subjects, achieving over 95% precision. However, reliably discriminating between mild and severe PD cases remained challenging. The VGG16 achieved the best overall classification performance with 91.8% accuracy and the largest area under the ROC curve. Furthermore, focusing analysis on the vowel /u/ could further improve accuracy to 96%. Applying visualization techniques like Grad-CAM also highlighted how CNN models focused on localized spectrogram regions while transformers attended to more widespread patterns. Overall, this work showed the potential of deep learning for non-invasive screening and monitoring of PD progression from voice recordings, but larger multi-class labeled datasets are needed to further improve severity classification.","2024-03","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","3","11","","","","","","","","","","English","","","","WOS:001191613000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","deep learning; mel spectrogram; Parkinson's disease (PD); speech analysis; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"57D7XHNI","journalArticle","2024","Zhou, Y; Yao, XY; Han, W; Li, YX; Xue, JJ; Li, Z","Measurement of neuropsychiatric symptoms in the older adults with mild cognitive impairment based on speech and facial expressions: a cross-sectional observational study","AGING & MENTAL HEALTH","","1360-7863","10.1080/13607863.2023.2280913","","ObjectivesTo examine the association between speech and facial features with depression, anxiety, and apathy in older adults with mild cognitive impairment (MCI).MethodsSpeech and facial expressions of 319 MCI patients were digitally recorded via audio and video recording software. Three of the most common neuropsychiatric symptoms (NPS) were evaluated by the Public Health Questionnaire, General Anxiety Disorder, and Apathy Evaluation Scale, respectively. Speech and facial features were extracted using the open-source data analysis toolkits. Machine learning techniques were used to validate the diagnostic power of extracted features.ResultsDifferent speech and facial features were associated with specific NPS. Depression was associated with spectral and temporal features, anxiety and apathy with frequency, energy, spectral, and temporal features. Additionally, depression was associated with facial features (action unit, AU) 10, 12, 15, 17, 25, anxiety with AU 10, 15, 17, 25, 26, 45, and apathy with AU 5, 26, 45. Significant differences in speech and facial features were observed between males and females. Based on machine learning models, the highest accuracy for detecting depression, anxiety, and apathy reached 95.8%, 96.1%, and 83.3% for males, and 87.8%, 88.2%, and 88.6% for females, respectively.ConclusionDepression, anxiety, and apathy were characterized by distinct speech and facial features. The machine learning model developed in this study demonstrated good classification in detecting depression, anxiety, and apathy. A combination of audio and video may provide objective methods for the precise classification of these symptoms.","2024-05-03","2025-02-26 20:43:32","2025-02-26 20:43:32","","828-837","","5","28","","","","","","","","","","English","","","","WOS:001102663200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","APATHY; DEPRESSION; facial analysis; machine learning; mild cognitive impairment; Neuropsychiatric symptoms; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MYEWXQ4Z","journalArticle","2022","Jain, S; Gupta, S; Ramalingam, WVBS","To Compare and Evaluate Laryngeal Changes in Patients with Dysphonia in Laryngopharyngeal Reflux (LPR) before and after Treatment with Proton Pump Inhibitors (PPI) and Prokinetic Drugs","INDIAN JOURNAL OF OTOLARYNGOLOGY AND HEAD & NECK SURGERY","","2231-3796","10.1007/s12070-020-02323-9","","To evaluate and compare pre and post treatment results using the following parameters by (a) Dual probe pH monitoring. (b) Laryngeal mucosal changes as assessed by direct video laryngoscopy/stroboscopy using Belafsky scores. (c) Voice changes by using GRBAS and Dr Speech software for speech analysis. In our study we have evaluated and compared voice and laryngeal changes in patients with dysphonia and RSI > 10 (which is suggestive of LPR) before treatment and after 6 months of treatment with Tab. Pantoprazole and Tab. Mosapride. This prospective study was carried out on 50 patients attending the ENT OPD of a tertiary care referral centre over a period of 18 months i.e. from Nov 2008 to Apr 2010. The study showed that prolonged therapy (> 6 months) is required to treat LPR effectively and 24 h ambulatory dual probe pH metry and videolaryngoscopy to assess RFS are the most preferred diagnostic tools in LPR. Dr Speech software for voice analysis can give an objective assessment of voice changes in LPR before and after treatment. The treatment consisting of PPI and prokinetic drugs proved to be effective in laryngopharyngeal reflux disease as improvement was seen in all the parameters including reflux findings score, subjective and objective voice assessment. According to results of our study, 24 h ambulatory dual probe pH metry, Reflux Finding Score (RFS), subjective and objective acoustic parameters can be used as indicators of efficacy of treatment.","2022-12","2025-02-26 20:43:32","2025-02-26 20:43:32","","4933-4947","","SUPPL 3","74","","","","","","","","","","English","","","","WOS:000623737100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","Dysphonia; Laryngopharyngeal reflux (LPR); Prokinetic drugs","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8HVL5JSY","journalArticle","2023","Aloufi, R; Haddadi, H; Boyle, D","Paralinguistic Privacy Protection at the Edge","ACM TRANSACTIONS ON PRIVACY AND SECURITY","","2471-2566","10.1145/3570161","","Voice user interfaces and digital assistants are rapidly entering our lives and becoming singular touch points spanning our devices. These always-on services capture and transmit our audio data to powerful cloud services for further processing and subsequent actions. Our voices and raw audio signals collected through these devices contain a host of sensitive paralinguistic information that is transmitted to service providers regardless of deliberate or false triggers. As our emotional patterns and sensitive attributes like our identity, gender, andwell-being are easily inferred using deep acoustic models, we encounter a newgeneration of privacy risks by using these services. One approach to mitigate the risk of paralinguistic-based privacy breaches is to exploit a combination of cloud-based processing with privacy-preserving, on-device paralinguistic information learning and filtering before transmitting voice data. In this article we introduce EDGY, a configurable, lightweight, disentangled representation learning framework that transforms and filters high-dimensional voice data to identify and contain sensitive attributes at the edge prior to offloading to the cloud. We evaluate EDGY's on-device performance and explore optimization techniques, including model quantization and knowledge distillation, to enable private, accurate, and efficient representation learning on resource-constrained devices. Our results show that EDGY runs in tens of milliseconds with 0.2% relative improvement in ""zero-shot"" ABX score or minimal performance penalties of approximately 5.95% word error rate (WER) in learning linguistic representations from raw voice signals, using a CPU and a single-core ARM processor without specialized hardware.","2023-05","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","2","26","","","","","","","","","","English","","","","WOS:000970870300009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;92</p>","","","Deep Learning; disentangled representation learning; Internet of Things (IoT); model optimization; privacy; speech analysis; voice synthesis; Voice user interface","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JIRCIG8N","journalArticle","2021","Kim, JH; Kang, J; Oh, JS; Ahn, T; Kim, BK; Baek, RM","Characteristics and surgical outcomes of cleft palate in kabuki syndrome: a case series of 11 patients","BMC PEDIATRICS","","1471-2431","10.1186/s12887-021-02852-4","","Objective A significant number of patients with KS have cleft palate (CP) or submucous cleft palate (SMCP) and show delayed speech development. However, few reports have discussed the characteristics of CP in KS and the outcomes of postoperative speech development. The purpose of this study was to investigate the characteristics and surgical outcomes of CP in patients with KS, and to discuss the importance of the diagnosis of CP or SMCP. Methods We conducted a retrospective study on patients with clinically diagnosed KS who underwent palatoplasty. Clinical and surgical data were collected from patients' medical records, and velopharyngeal function was evaluated using nasopharyngoscopy and speech analysis. Results In 11 cases, 5 patients had CP (45.5%) and 6 had SMCP (54.5%). Four patients who were genetically tested had a pathogenic variant of KMT2D. Seven of nine patients (77.8%) who underwent conventional palatoplasty showed velopharyngeal insufficiency and hypernasality. All patients who underwent pharyngeal flap surgery achieved velopharyngeal competency. Statistical analysis revealed a statistically significant difference in postoperative results between non-syndromic and KS patients. Conclusion Patients with SMCP may be more common than previously reported. The results showed that it is difficult to produce optimal results with conventional palatoplasty; therefore, pharyngeal flap surgery should be considered as a treatment to obtain favorable results. Pharyngeal flap surgery in patients with KS should be carefully designed based on speech evaluation and nasopharyngoscopic findings.","2021-09-03","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","1","21","","","","","","","","","","English","","","","WOS:000694239900005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Cleft palate; INDIVIDUALS; Kabuki syndrome; MAKE-UP SYNDROME; MLL2; MUTATION; PHARYNGEAL FLAP; Pharyngeal flap surgery; REPAIR; SPEECH; SURGERY; VELOPHARYNGEAL INSUFFICIENCY; Z-PLASTY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NADY5ZQP","journalArticle","2023","Alku, P; Kadiri, SR; Gowda, D","Refining a deep learning-based formant tracker using linear prediction methods","COMPUTER SPEECH AND LANGUAGE","","0885-2308","10.1016/j.csl.2023.101515","","In this study, formant tracking is investigated by refining the formants tracked by an existing data-driven tracker, DeepFormants, using the formants estimated in a model-driven manner by linear prediction (LP)-based methods. As LP-based formant estimation methods, conventional covariance analysis (LP-COV) and the recently proposed quasi-closed phase forward-backward (QCP-FB) analysis are used. In the proposed refinement approach, the contours of the three lowest formants are first predicted by the data-driven DeepFormants tracker, and the predicted formants are replaced frame-wise with local spectral peaks shown by the model-driven LP-based methods. The refinement procedure can be plugged into the DeepFormants tracker with no need for any new data learning. Two refined DeepFormants trackers were compared with the original DeepFormants and with five known traditional trackers using the popular vocal tract resonance (VTR) corpus. The results indicated that the data-driven DeepFormants trackers outperformed the conventional trackers and that the best performance was obtained by refining the formants predicted by DeepFormants using QCP-FB analysis. In addition, by tracking formants using VTR speech that was corrupted by additive noise, the study showed that the refined DeepFormants trackers were more resilient to noise than the reference trackers. In general, these results suggest that LP-based model-driven approaches, which have traditionally been used in formant estimation, can be combined with a modern data-driven tracker easily with no further training to improve the tracker's performance.","2023-06","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","81","","","","","","","","","","English","","","","WOS:001053708700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","DeepFormants; EXTRACTION; Formant tracking; FREQUENCY; Linear prediction; SPEECH; Speech analysis; Vocal tract resonances","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U72LBLJX","journalArticle","2024","Okada, K; Mizuguchi, D; Omiya, Y; Endo, K; Kobayashi, Y; Iwahashi, N; Kosuge, M; Ebina, T; Tamura, K; Sugano, T; Ishigami, T; Kimura, K; Hibi, K","Clinical Utility of Machine Learning-Derived Vocal Biomarkers in the Management of Heart Failure","CIRCULATION REPORTS","","2434-0790","10.1253/circrep.CR-24-0064","","Background: This study aimed to systematically evaluate voice symptoms during heart failure (HF) treatments and to exploratorily extract HF-related vocal biomarkers. Methods and results: This single-center, prospective study longitudinally acquired 839 audio files from 59 patients with acute decompensated HF. Patients' voices were analyzed along with conventional HF indicators (New York Heart Association [NYHA] class, presence of pulmonary congestion and pleural effusion on chest X-ray, and B-type natriuretic peptide [BNP]) and GOKAN scores based on the assessment of a cardiologist. Machine-learning (ML) models to estimate HF conditions were created using a Light Gradient Boosting Machine. Voice analysis identified 27 acoustic features that correlated with conventional HF indicators and GOKAN scores. When creating ML models based on the acoustic features, there was a significant correlation between actual and ML-derived BNP levels (r=0.49; P<0.001). ML models also identified good diagnostic accuracies in determining HF conditions characterized by NYHA class >= 2, BNP >= 300 pg/mL, presence of pulmonary congestion or pleural effusion on chest X-ray, and decompensated HF (defined as NYHA class >= 2 and BNP levels >= 300 pg/mL; accuracy: 75.1%, 69.1%, 68.7%, 66.4%, and 80.4%, respectively). Conclusions: The present study successfully extracted HF-related acoustic features that correlated with conventional HF indicators. Although the data are preliminary, ML models based on acoustic features (vocal biomarkers) have the potential to infer various HF conditions, which warrant future studies.","2024-08","2025-02-26 20:43:32","2025-02-26 20:43:32","","303-312","","8","6","","","","","","","","","","English","","","","WOS:001296623200003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","Acoustic features; Artificial intelligence; CARE; HOSPITALIZED-PATIENTS; SPEECH ANALYSIS; Telemedicine; Vocal biomarker","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3BXHR9AG","journalArticle","2024","Ng, SI; Ng, CWY; Wang, JR; Lee, T","Automatic Detection of Speech Sound Disorder in Cantonese-Speaking Pre-School Children","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2024.3463503","","Speech sound disorder (SSD) is a type of developmental disorder in which children encounter persistent difficulties in correctly producing certain speech sounds. Conventionally, assessment of SSD relies largely on speech and language pathologists (SLPs) with appropriate language background. With the unsatisfied demand for qualified SLPs, automatic detection of SSD is highly desirable for assisting clinical work and improving the efficiency and quality of services. In this paper, methods and systems for fully automatic detection of SSD in young children are investigated. A microscopic approach and a macroscopic approach are developed. The microscopic system is based on detection of phonological errors in impaired child speech. A deep neural network (DNN) model is trained to learn the similarity and contrast between consonant segments. Phonological error is identified by contrasting a test speech segment to reference segments. The phone-level similarity scores are aggregated for speaker-level SSD detection. The macroscopic approach leverages holistic changes of speech characteristics related to disorders. Various types of speaker-level embeddings are investigated and compared. Experimental results show that the proposed microscopic system achieves unweighted average recall (UAR) from 84.0% to 91.9% on phone-level error detection. The proposed macroscopic approach can achieve a UAR of 89.0% on speaker-level SSD detection. The speaker embeddings adopted for macroscopic SSD detection can effectively discard the information related to speaker's personal identity.","2024","2025-02-26 20:43:32","2025-02-26 20:43:32","","4355-4368","","","32","","","","","","","","","","English","","","","WOS:001335932500003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Acoustics; ACQUISITION; Artificial neural networks; Children; deep neural network (DNN); Microscopy; pathological speech detection; Pathology; Phonetics; PREDICTORS; PREVALENCE; Production; SERVICE DELIVERY; Speech analysis; speech sound disorder (SSD)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4FUS3ZGZ","journalArticle","2022","Tsang, A","Self-access learning of English intonation with speech software: examining learners' perceptions with a focus on their concerns and negative comments","LANGUAGE LEARNING IN HIGHER EDUCATION","","2191-611X","10.1515/cercles-2022-2045","","Language laboratories exist in many language centres across the globe. Situated in the popularity of self-access and computer-assisted language learning in the present era, the study investigated tertiary-level English as a foreign language (EFL) learners' general and, particularly, negative views of speech analysis software. Two hundred and eighty intermediate-level (CEFR B1 and B2 levels) EFL participants completed trial sessions with some free speech software in which they listened to and recorded utterances to practise English intonation at a language laboratory in Hong Kong. Each participant was observed during the session, completed a questionnaire, and attended a brief post-questionnaire interview after the session. Both quantitative and qualitative data were collected. The results showed that learning with this kind of software was perceived generally positively in relation to language enhancement and self-access learning. However, from the qualitative data collected about their negative views and concerns, three themes emerged: absence of a teacher, an interaction-less environment, and the little value of graphic outputs. This article concludes with a discussion of these findings and implications for language educators and researchers in self-access and computer-assisted language learning, which are in vogue globally nowadays. Suggestions for addressing learners' negative views and comments, which have not received much attention among stakeholders, are also provided.","2022-05-25","2025-02-26 20:43:32","2025-02-26 20:43:32","","209-229","","1","12","","","","","","","","","","English","","","","WOS:000807697000009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","2ND-LANGUAGE; CALL; computer-assisted language learning (CALL); English as a foreign language (EFL); intonation; learners' perceptions; PRONUNCIATION; self-access language learning (SALL); speech software; STUDENTS; WORLD ENGLISHES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"83DZQ4XF","journalArticle","2023","Kadiri, SR; Alku, P; Yegnanarayana, B","Analysis of Instantaneous Frequency Components of Speech Signals for Epoch Extraction","COMPUTER SPEECH AND LANGUAGE","","0885-2308","10.1016/j.csl.2022.101443","","The major impulse-like excitation in the speech signal is due to abrupt closure of the vocal folds, which takes place at the glottal closure instant (GCI) or epoch in each cycle. GCIs are used in many areas of speech science and technology, such as in prosody modification, voice source analysis, formant extraction and speech synthesis. It is difficult to observe these discontinuities (corresponding to GCIs) in the speech signal because of the superimposed time-varying response of the vocal tract system. This paper examines the phase part of different frequency components of the speech signal to extract epochs. Three analysis methods to decompose the speech signal into different frequency components are considered. These methods are the short-time Fourier transform (STFT), narrow bandpass filtering (NBPF), and single frequency filtering (SFF). The locations of the discontinuities in the speech signal are obtained from the instantaneous frequency (IF) (i.e., the time derivative of the phase) of each of the frequency components. A method for automatic detection of epochs using the amplitude weighted IF is proposed. Performance of the proposed epoch detection method is compared with four state-of-the-art methods in clean and telephone quality speech. The performance of the proposed method is comparable with the performance of the existing epoch detection methods for clean speech but better for telephone quality speech.","2023-03","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","78","","","","","","","","","","English","","","","WOS:000864656900008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;85</p>","","","ALGORITHMS; Epochs; EXCITATION; Excitation source; FEATURES; FORMANT EXTRACTION; FUNDAMENTAL-FREQUENCY; Glottal closure instants; GLOTTAL CLOSURE INSTANTS; Group delay; GROUP DELAY FUNCTIONS; Instantaneous frequency; LINEAR-PREDICTION; Phase processing; PHASE SPECTRUM; RECONSTRUCTION; Speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MCUDEXW5","journalArticle","2024","Bhat, M; Paul, S; Sahu, UK; Yadav, UK","Revolutionizing crowd surveillance through voice-driven face recognition empowering rapid identification: towards development of sustainable smart cities","ENGINEERING RESEARCH EXPRESS","","2631-8695","10.1088/2631-8695/ad4ae9","","Recent global efforts to create sustainable smart cities have significantly transformed society and improved the lives of people. Nowadays, crowd surveillance (CS) has become essential in sustainable smart cities and society to protect public safety and security. In this regard, the face-based human detection system has received considerable attention because it is recognized as an emerging method in crowd surveillance applications. Thus, in this work, a new method for real-time identification of people for a crowd surveillance system (CSS) that uses facial and speech recognition technology has been introduced. In traditional CS systems, human operators are frequently used by crowd surveillance systems to watch and evaluate video feeds. Human error and operator weariness may result in lost opportunities or slow replies, which reduce the system's efficacy. Certain procedures, including the initial identification and monitoring of people in video feeds, can be automated using a voice-activated system. To address the issues with the present CSS, a new framework Voice-Activated Face Recognition (VAFR) is proposed in this work. The proposed framework combines the speech and face recognition models for crowd surveillance. Experimental and simulation studies have been performed to analyze the performance of the proposed VAFR framework. The proposed framework uses the Viola-Jones algorithm for face identification and the Conformer architecture for speech analysis, reaching a noteworthy 99.8% accuracy rate in live video feeds. In addition, the ethical and safety aspect of the proposed VAFR system is presented.","2024-06-01","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","2","6","","","","","","","","","","English","","","","WOS:001234260500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","conformer architecture; crowd surveillance; facial recognition; speech recognition; sustainable smart cities; Viola-Jones algorithm; voice-activated system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8FC3DSGR","journalArticle","2021","Farrús, M; Codina-Filbà, J; Reixach, E; Andrés, E; Sans, M; Garcia, N; Vilaseca, J","Speech-Based Support System to Supervise Chronic Obstructive Pulmonary Disease Patient Status","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app11177999","","Featured Application This work represents a proof of concept for COPD patient supervision, which can lead to a potential application related to home monitoring for clinicians working on the respiratory field. Patients with chronic obstructive pulmonary disease (COPD) suffer from voice changes with respect to the healthy population. However, two issues remain to be studied: how long-term speech elements such as prosody are affected; and whether physical effort and medication also affect the speech of patients with COPD, and if so, how an automatic speech-based detection system of COPD measurements can be influenced by these changes. The aim of the current study is to address both issues. To this end, long read speech from COPD and control groups was recorded, and the following experiments were performed: (a) a statistical analysis over the study and control groups to analyse the effects of physical effort and medication on speech; and (b) an automatic classification experiment to analyse how different recording conditions can affect the performance of a COPD detection system. The results obtained show that speech-especially prosodic features-is affected by physical effort and inhaled medication in both groups, though in opposite ways; and that the recording condition has a relevant role when designing an automatic COPD detection system. The current work takes a step forward in the understanding of speech in patients with COPD, and in turn, in the research on its automatic detection to help professionals supervising patient status.","2021-09","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","17","11","","","","","","","","","","English","","","","WOS:000694194100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","ACOUSTIC ANALYSIS; ASTHMA PATIENTS; chronic obstructive pulmonary disease; CLINICAL METHODS; COPD; DYSPNEA; machine learning; PREDICTION; prosody; SOUNDS; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5NYK3DVL","journalArticle","2024","Pereira, PH; Beccaro, W; Ramírez, MA","Advantages and Pitfalls of Dataset Condensation: An Approach to Keyword Spotting with Time-Frequency Representations","ELECTRONICS","","2079-9292","10.3390/electronics13112097","","With the exponential growth of data, the need for efficient techniques to extract relevant information from datasets becomes increasingly imperative. Reducing the training data can be useful for applications wherein storage space or computational resources are limited. In this work, we explore the concept of data condensation (DC) in the context of keyword spotting systems (KWS). Using deep learning architectures and time-frequency speech representations, we have obtained condensed speech signal representations using gradient matching with Efficient Synthetic-Data Parameterization. From a series of classification experiments, we analyze the models and condensed data performances in terms of accuracy and number of data per class. We also present results using cross-model techniques, wherein models are trained with condensed data obtained from a different architecture. Our findings demonstrate the potential of data condensation in the context of the speech domain for reducing the size of datasets while retaining their most important information and maintaining high accuracy for the model trained with the condensed dataset. We have obtained an accuracy of 80.75% with 30 condensed speech representations per class with ConvNet, representing an addition of 24.9% in absolute terms when compared to 30 random samples from the original training dataset. However, we demonstrate the limitations of this approach in the cross-model tests. We also highlight the challenges and opportunities for further improving the accuracy of condensed data obtained and trained with different neural network architectures.","2024-06","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","11","13","","","","","","","","","","English","","","","WOS:001246660000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","automatic speech recognition; data condensation; deep learning; keyword spotting; spectral analysis; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YWW5X37F","journalArticle","2025","Balouchzahi, F; Butt, S; Amjad, M; Sidorov, G; Gelbukh, A","UrduHope: Analysis of hope and hopelessness in Urdu texts","KNOWLEDGE-BASED SYSTEMS","","0950-7051","10.1016/j.knosys.2024.112746","","Hope is a crucial aspect of human psychology that has received considerable attention due to its role in facing challenges in human life. However, current research predominantly focuses on hope as positive anticipation, overlooking its counterpart, hopelessness. This paper addresses this gap by presenting an expanded framework for analyzing hope speech in social media, incorporating hope and hopelessness. Drawing on insights from psychology and Natural Language Processing (NLP), we argue that a comprehensive understanding of human emotions necessitates considering both constructs. We introduce the concept of hopelessness as a distinct category in hope speech analysis and develop a novel dataset for Urdu, an underrepresented language in NLP research. We proposed a semi-supervised annotation procedure by utilizing Large Language Models (LLMs) along with human annotators to annotate the dataset and explored various learning approaches for hope speech detection, including traditional machine learning models, neural networks, and state-of-the-art transformers. The findings demonstrate the effectiveness of different learning approaches in capturing the nuances of hope speech in Urdu social media discourse. The hope speech detection task was modeled in two subtasks: a binary classification of Urdu tweets to Hope and Not Hope classes and then a multiclass classification of Urdu tweets into Generalized, Realistic, and Unrealistic Hopes, along with Hopelessness, and Not Hope (Neutral) categories. The best results for binary classification were obtained with Logistic Regression (LR) with an averaged macro F1 score of 0.7593, and for the multiclass classification experiments, transformers outperformed other experiments with an averaged macro F1 score of 0.4801.","2025-01-10","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","308","","","","","","","","","","English","","","","WOS:001395224000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","Hope speech detection; LANGUAGE; LLMs; Text classification; Transformers; Urdu","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"87Z3FZU7","journalArticle","2021","Ben Letaifa, L; Torres, MI","Perceptual Borderline for Balancing Multi-Class Spontaneous Emotional Data","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2021.3071485","","Speech is a behavioural biometric signal that can provide important information to understand the human intends as well as their emotional status. The paper is centered on the speech-based identification of the seniors's emotional status during their interaction with a virtual agent playing the role of a health professional coach. Under real conditions, we can just identify a small set of task-dependent spontaneous emotions. The number of identified samples is largely different for each emotion, which results in an imbalanced dataset problem. This research proposes the dimensional model of emotions as a perceptual representation space alternative to the generally used acoustic one. The main contribution of the paper is the definition of a perceptual borderline for the oversampling of minority emotion classes in this space. This limit, based on arousal and valence criteria, leads to two methods of balancing the data: the Perceptual Borderline oversampling and the Perceptual Borderline SMOTE (Synthetic Minority Oversampling TEchnique). Both methods are implemented and compared to state-of-the-art approaches of Random oversampling and SMOTE. The experimental evaluation was carried out on three imbalanced datasets of spontaneous emotions acquired in human-machine scenarios in three different cultures: Spain, France and Norway. The emotion recognition results obtained by neural networks classifiers show that the proposed perceptual oversampling methods led to significant improvements when compared with the state-of-the art, for all scenarios and languages.","2021","2025-02-26 20:43:32","2025-02-26 20:43:32","","55939-55954","","","9","","","","","","","","","","English","","","","WOS:000641004800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","Acoustics; Dimensional model of emotions; emotion recognition; Emotion recognition; Man-machine systems; Mood; multi-class classification; Noise measurement; perceptual borderline; speech analysis; speech processing; Support vector machines; Task analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WXGSA6FA","journalArticle","2021","Harhare, T; Shah, M","Linear Mixed Effect Modelling for Analyzing Prosodic Parameters for Marathi Language Emotions","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","Along with linguistic messages, prosody is an essential paralinguistic component of emotional speech. Prosodic parameters such as intensity, fundamental frequency (F0), and duration were studied worldwide to understand the relationship between emotions and corresponding prosody features for various languages. For evaluating prosodic aspects of emotional Marathi speech, the Marathi language has received less attention. This study aims to see how different emotions affect suprasegmental properties such as pitch, duration, and intensity in Marathi's emotional speech. This study investigates the changes in prosodic features based on emotions, gender, speakers, utterances, and other aspects using a database with 440 utterances in happiness, fear, anger, and neutral emotions recorded by eleven Marathi professional artists in a recording studio. The acoustic analysis of the prosodic features was employed using PRAAT, a speech analysis framework. A statistical study using a two-way Analysis of Variance (two-way ANOVA) explores emotion, gender, and their interaction for mean pitch, mean intensity, and sentence utterance time. In addition, three distinct linear mixed-effect models (LMM), one for each prosody characteristic designed comprising emotion and gender factors as fixed effect variables, whereas speakers and sentences as random effect variables. The relevance of the fixed effect and random effect on each prosodic variable was verified using likelihood ratio tests that assess the goodness of fit. Based on Marathi's emotional speech, the R programming language examined linear mixed modeling for mean pitch, mean intensity, and sentence duration.","2021-12","2025-02-26 20:43:32","2025-02-26 20:43:32","","104-111","","12","12","","","","","","","","","","English","","","","WOS:000738710600014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","a marathi language prosody model; a two-way analysis of variance; linear mixed-effect models; Prosodic parameters; r programming language; RECOGNITION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"54TQKKMR","journalArticle","2023","Guatelli, R; Aubin, V; Mora, M; Naranjo-Torres, J; Mora-Olivari, A","Detection of Parkinson's disease based on spectrograms of voice recordings and Extreme Learning Machine random weight neural networks","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2023.106700","","Parkinson's disease consists in the degeneration of the mesencephalic black substance, affecting the dopaminer-gic vias. Its causes are varied, including exposure to pesticides, genetic factors and, one of the most influential ones, age. Given the decrease in dopamine levels, the most common symptoms are the appearance of tremors and muscle rigidity. Due to the rigidity of the muscles, the patient has voice alterations which have great potential for non-invasive and early diagnosis of the disease. In addition, considering the low cost of the sound recorder respect to the clinical studies, this approach allows the diagnosis of Parkinson's disease in a large number of people. Recent works, which present the analysis of voice recordings through Convolutional Neural Networks, show high level of accuracy in the diagnosis of Parkinson's disease. Convolutional Neural Networks use a Multilayer Neural Network to classify convolutional feature vectors. In order to improve the training time of the classifier, in this paper the use Extreme Learning Machines are proposed. Experiments considering 4 types of spectrograms with AlexNet, VGG-16, SqueezeNet, Inception V3 and ResNet-50 Convolutional Neural Networks models. In the experiments, hit rate, training and testing time, sensitivity and the specificity indicators of all the neural architectures involved in the work are objectively compared. It is shown that the Extreme Learning Machine have a high level of accuracy in the diagnosis of Parkinson's disease but with reduced training time.","2023-10","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","125","","","","","","","","","","English","","","","WOS:001032324400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;95</p>","","","ALGORITHMS; CNN-ELM; DIAGNOSIS; Extreme Learning Machine; MODELS; Parkinson detection; PROGRESSION; Spectrogram images; Speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BLRH9VW8","journalArticle","2021","Loizou, CP","An automated integrated speech and face imageanalysis system for the identification of human emotions","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2021.04.001","","Objective: Human interactions are related to speech and facial characteristics. It was suggested that speech signals and/or images of facial expressions may reveal human emotions and that both interact for the verification of a person's identity. The present study proposes and evaluates an automated integrated speech signal and facial image analysis system for the identification of seven different human emotions (Normal (N), Happy (H), Sad (S), Disgust (D), Fear (F), Anger (A), and Surprise (Su)). Methods: Speech recordings and face images from 7,441 subjects aged 20 Results: For each of the above mentioned human emotions, statistical significantly different speech and face image features were identified that may be used to distinguish between the aforementioned groups (N vs H, N vs S, N vs D, N vs F, N vs A, N vs Su). Using solely the statistically significant speech and image features identified, an overall percentage of correct classification (%CC) score of 93% was achieved. Conclusions: A significant number of speech and face image features have been derived from continuous speech and face images. Features were identified that were able to identify between seven different emotional human states. This study poses the basis for the development of an integrated system for the identification of emotional states from automatic analysis of free speech and image face analysis. Future work will investigate the devel- opment and integration of the proposed method into a mobile device.","2021-06","2025-02-26 20:43:32","2025-02-26 20:43:32","","15-26","","","130","","","","","","","","","","English","","","","WOS:000647676900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","CLASSIFICATION; Classification analysis; COGNITIVE IMPAIRMENT; DISEASE; EXCITATION; Face analysis; Human emotions detection; NORMALIZATION; Speech analysis; Statistical analysis; TEXTURAL FEATURES; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3BZU9NAD","journalArticle","2024","Morgan, DG; Kosteniuk, J; Bayly, M","Perceptions and outcomes of an embedded Alzheimer Society First Link Coordinator in rural primary health care memory clinics","BMC HEALTH SERVICES RESEARCH","","1472-6963","10.1186/s12913-024-11066-0","","Background Primary health care has a central role in dementia detection, diagnosis, and management, especially in low-resource rural areas. Care navigation is a strategy to improve integration and access to care, but little is known about how navigators can collaborate with rural primary care teams to support dementia care. In Saskatchewan, Canada, the RaDAR (Rural Dementia Action Research) team partnered with rural primary health care teams to implement interprofessional memory clinics that included an Alzheimer Society First Link Coordinator (FLC) in a navigator role. Study objectives were to examine FLC and clinic team member perspectives of the impact of FLC involvement, and analysis of Alzheimer Society data comparing outcomes associated with three types of navigator-client contacts.Methods This study used a mixed-method design. Individual semi-structured interviews were conducted with FLC (n = 3) and clinic team members (n = 6) involved in five clinics. Data were analyzed using thematic inductive analysis. A longitudinal retrospective analysis was conducted with previously collected Alzheimer Society First Link database records. Memory clinic clients were compared to self- and direct-referred clients in the geographic area of the clinics on time to first contact, duration, and number of contacts.Results Three key themes were identified in both FLC and team interviews: perceived benefits to patients and families of FLC involvement, benefits to memory clinic team members, and impact of rural location. Whereas other team members assessed the patient, only FLC focused on caregivers, providing emotional and psychological support, connection to services, and symptom management. Face-to-face contact helped FLC establish a relationship with caregivers that facilitated future contacts. Team members were relieved knowing caregiver needs were addressed and learned about dementia subtypes and available services they could recommend to non-clinic clients with dementia. Although challenges of rural location included fewer available services and travel challenges in winter, the FLC role was even more important because it may be the only support available.Conclusions FLC and team members identified perceived benefits of an embedded FLC for patients, caregivers, and themselves, many of which were linked to the FLC being in person.","2024-05-09","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","1","24","","","","","","","","","","English","","","","WOS:001219637700003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","AVAILABILITY; BARRIERS; Care navigator; Caregiver support; Dementia; DEMENTIA; DIAGNOSIS; EXPERIENCES; MANAGEMENT; Memory clinic; Primary care; Rural; SERVICES; SUPPORT; Team-based care","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RYXL32CN","journalArticle","2023","Liu, CT; Fan, HM; Jiang, YY; Ma, RM; Song, S","Gully erosion susceptibility assessment based on machine learning-A case study of watersheds in Tuquan County in the black soil region of Northeast China","CATENA","","0341-8162","10.1016/j.catena.2022.106798","","Owing to its unique topographic and climatic conditions, agricultural production, and anthropogenic grazing, severe gully erosion has developed in the watersheds of Tuquan County located in the black soil region of Northeast China. Using three machine learning models to assess gully erosion susceptibility in this region, the main purpose of this study was to determine the important factors affecting the occurrence of gully erosion from 25 geo-environmental factors and select the model with the best prediction performance. Field data collection was conducted for 823 gullies. 12,496 pixels corresponding to 823 gullies and 12,496 pixels without gully erosion were randomly selected to form the model calculation database. According to the principle of multiple screening, this study selected 25 geo-environmental factors affecting the occurrence of gully erosion. Two fac-tors, coarse sand content and fine sand content, were excluded by multi-collinearity analysis and using random forest (RF), convolution neural network (CNN), and transformer models, combining the 10-fold cross-validation and related validation metrics to assess the susceptibility of gully erosion in Tuquan County's small watersheds. The results show that the convergence index (CI), topographical wetness index (TWI), terrain ruggedness index (TRI), and distance from the river based on the RF model are important factors affecting the occurrence of gully erosion. The transformer model (mean AUC of training = 95.338 %, mean AUC of validation = 95.342 %) was superior to the RF (mean AUC of training = 99.997 %, mean AUC of validation = 92.518 %) and CNN (mean AUC of training = 86.995 %, mean AUC of validation = 84.647 %) models in predicting performance. To ensure that the management and decision-making departments take reasonable and effective measures to prevent gully erosion in the study area, the gully erosion susceptibility maps produced using the three machine learning models were beneficial.","2023-03","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","222","","","","","","","","","","English","","","","WOS:000907629100004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;111</p>","","","10-fold cross validation; CATCHMENT; CLASSIFIERS; Convolution neural network; ENSEMBLE; Geo-environmental factors; Gully erosion susceptibility; IMPACTS; LOGISTIC-REGRESSION; MODELS; Random forest; RILL EROSION; RIVER-BASIN; SEMIARID REGION; TOPOGRAPHIC THRESHOLDS; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U4F747XW","journalArticle","2021","Nieuwazny, J; Nowakowski, K; Ptaszynski, M; Masui, F","Can you fool AI by doing a 180? - A case study on authorship analysis of texts by Arata Osada","INFORMATION PROCESSING & MANAGEMENT","","0306-4573","10.1016/j.ipm.2021.102644","","This paper is our attempt at answering a twofold question covering the areas of ethics and authorship analysis solutions. Firstly, since the methods used for performing authorship analysis imply that an author can be recognized by the content he or she creates, we were interested in finding out whether it would be possible for an author identification system to correctly attribute works to authors if in the course of years they have undergone a major psychological transition. Secondly - and from the point of view of the evolution of an author's ethical values - we checked what it would mean if the authorship attribution system encounters difficulties in detecting single authorship. We set out to answer those questions through performing a binary authorship analysis task using a text classifier based on a pre-trained transformer model and a baseline method relying on conventional similarity metrics. For the test set, we chose several works of Arata Osada, a Japanese educator and specialist in the history of education, with half of them being books written before the Second World War and another half in the 1950s, in between which the author underwent a transformation in terms of political opinions. As a result, we were able to confirm that in the case of texts authored by Arata Osada in a time span of more than 10 years, while the classification accuracy drops by a large margin and is substantially lower than for texts by other non-fiction writers, confidence scores of the predictions remain at a similar level as in the case of a shorter time span, indicating that the classifier was in many instances tricked into deciding that texts written by Arata Osada over a time span of multiple years were actually written by two different people, which in turn leads us to believe that such a change can affect authorship analysis, and that historical events have great impact on a person's ethical outlook as expressed in their writings.","2021-09","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","5","58","","","","","","","","","","English","","","","WOS:000679812700015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Authorship analysis; Authorship verification; Binary text classification; DOCUMENTS; IDENTIFICATION; Personal ethics; Similarity detection; Single authorship identification; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NWME72Q9","journalArticle","2025","Fang, XH; Song, QH; Li, ZY; Wang, XJ; Ma, HF; Liu, ZQ","Intelligent monitoring system for production lines in smart factories: A hybrid method integrating Transformer and Kalman filter","JOURNAL OF MANUFACTURING SYSTEMS","","0278-6125","10.1016/j.jmsy.2024.12.014","","Intelligent monitoring systems for production lines in smart factories are used to ensure production efficiency, quality control and fault warning, promoting the optimization of production processes and resource allocation. Tool wear monitoring (TWM) bridges the gap between the perception of machining state information and accurate health management of tools. However, signal features undergo significant and abnormal changes during the late-stage of tool wear, posing substantial challenges to the development of an accurate tool wear intelligent monitoring model. In this paper, a hybrid TWM model integrating the Transformer and Kalman filter is proposed, with a state-space model of tool wear constructed and dynamically updated to address the gap in late-stage prediction accuracy of existing TWM methods. Specifically, the Transformer model is designed to describe the observation model of early tool wear states based on monitoring data. A system model is developed based on the actual tool wear mechanism to describe the relationship between the tool wear rate and tool-workpiece contact load over time. The Kalman filter is used to estimate the parameters of the mechanism model and track the evolution of wear. Within the Bayesian inference framework, measurement noise in the monitoring data is accounted for to optimize and update state estimation deviations and mechanism model parameters, enabling late-stage wear prediction through posterior estimation. The effectiveness and generalization of the proposed method are validated through milling experiments on both thin-walled and rectangular block parts. The experimental results indicate that the average RMSE error of tool wear prediction for thin-walled parts is 6.02, while for rectangular block parts, it is 4.70. The average RMSE errors of the proposed method are reduced by 16.34 % and 11.31 %, respectively, with respect to the single model. More importantly, the proposed method for TWM demonstrates strong predictive performance in the late-stage of tool wear while quantifying the uncertainty of wear prediction.","2025-04","2025-02-26 20:43:32","2025-02-26 20:43:32","","27-47","","","79","","","","","","","","","","English","","","","WOS:001397518100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","FEATURE FUSION; Hybrid model; Kalman filter; MODEL; Smart factories; STABILITY; Tool wear monitoring; TOOL WEAR PREDICTION; Transformer; Wear mechanism","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DKAN9PIM","journalArticle","2025","Roozbehi, A; Abbasi, H; Davidson, JO; Dhillon, SK; Zhou, KQ; Wassink, G; Gunn, AJ; Bennet, L","Enhanced EEG seizure recognition after hypoxia-ischemia in fetal sheep using transformer-based wavelet-scalogram deep learning","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.125081","","This study introduces transformer-based deep learning models as superior alternatives to convolutional neural network (CNN) architectures for seizure detection after hypoxia-ischemia (HI) in electroencephalography (EEG) recordings in the developing brain. We further demonstrate that these models excel in classifying of varied and subtle morphologies of electrographic seizures observed in the EEG of fetal sheep after HI. The study explores model training combinations from four cohorts of Romney/Suffolk fetal sheep (HI-normothermia-term (n = 7), HI-hypothermia-term (n = 14), sham-normothermia-term (n = 5), and HI-normothermia-preterm (n = 14)), totalling 31,015 EEG segments from 17,300 h of recordings. We evaluated multiple Transformer architectures using both 2D wavelet-scalograms (WS) and 1D raw EEG signals through leave-one-out and k-fold crossvalidation, comparing models' performance with or without sham-normothermia-term data and contrasting them with CNN-based results from our previous work. The Data-Efficient image Transformer (DeiT) emerged as the top-performing model, achieving 99.60 % accuracy (AUC = 0.992) when fed with WS, surpassing the 2D WS CNN result (98.94 % accuracy, AUC = 0.967) from our prior study. Notably, the Wav2Vec2 transformer model, fed with raw 1D EEG segments, demonstrated comparable performance with 99.60 % accuracy (AUC = 0.992), outperforming the 1D CNN result (98.43 % accuracy, AUC = 0.961) from the previous study. More importantly, the transformers can adeptly distinguish between seizures in both the preterm and term brain, and under the influence of treatment with 99.92 % accuracy (AUC = 0.997). Our findings highlight the superior ability of transformer models to capture long-range dependencies within EEG data, enhancing seizure detection without the added complexity of generating 2D WS images. Transformer models show promise for generalized automated seizure detection, irrespective of the perinatal brain maturation stage and the influence of hypothermia, offering potential improvements for seizure detection after HI in newborns.","2025-02-01","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","261","","","","","","","","","","English","","","","WOS:001339029500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Deep learning; EEG; ELECTROGRAPHIC SEIZURES; ENCEPHALOPATHY; Full-term and preterm fetal sheep; Hypothermia; HYPOTHERMIA; Neonatal hypoxic-ischemic encephalopathy; Pattern recognition; PRETERM; Seizure detection; SYSTEM; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"37ZBTSCS","journalArticle","2024","Dai, WY","Stochastic Differential Games and a Unified Forward-Backward Coupled Stochastic Partial Differential Equation with Lévy Jumps","MATHEMATICS","","2227-7390","10.3390/math12182891","","We establish a relationship between stochastic differential games (SDGs) and a unified forward-backward coupled stochastic partial differential equation (SPDE) with discontinuous L & eacute;vy Jumps. The SDGs have q players and are driven by a general-dimensional vector L & eacute;vy process. By establishing a vector-form Ito-Ventzell formula and a 4-tuple vector-field solution to the unified SPDE, we obtain a Pareto optimal Nash equilibrium policy process or a saddle point policy process to the SDG in a non-zero-sum or zero-sum sense. The unified SPDE is in both a general-dimensional vector form and forward-backward coupling manner. The partial differential operators in its drift, diffusion, and jump coefficients are in time-variable and position parameters over a domain. Since the unified SPDE is of general nonlinearity and a general high order, we extend our recent study from the existing Brownian motion (BM)-driven backward case to a general L & eacute;vy-driven forward-backward coupled case. In doing so, we construct a new topological space to support the proof of the existence and uniqueness of an adapted solution of the unified SPDE, which is in a 4-tuple strong sense. The construction of the topological space is through constructing a set of topological spaces associated with a set of exponents {gamma 1,gamma 2,& mldr;} under a set of general localized conditions, which is significantly different from the construction of the single exponent case. Furthermore, due to the coupling from the forward SPDE and the involvement of the discontinuous L & eacute;vy jumps, our study is also significantly different from the BM-driven backward case. The coupling between forward and backward SPDEs essentially corresponds to the interaction between noise encoding and noise decoding in the current hot diffusion transformer model for generative AI.","2024-09","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","18","12","","","","","","","","","","English","","","","WOS:001323972000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","APPROXIMATIONS; diffusion transformer; discontinuous L & eacute; forward and backward coupling; GO; NETWORKS; non-Gaussian noise; non-zero-sum game; NONLINEAR SCHRODINGER-EQUATION; stochastic differential game; stochastic partial differential equation; SYSTEMS; vy jump; zero-sum game","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BEFL6IJM","journalArticle","2023","Jaotombo, F; Adorni, L; Ghattas, B; Boyer, L","Finding the best trade-off between performance and interpretability in predicting hospital length of stay using structured and unstructured data","PLOS ONE","","1932-6203","10.1371/journal.pone.0289795","","Objective This study aims to develop high-performing Machine Learning and Deep Learning models in predicting hospital length of stay (LOS) while enhancing interpretability. We compare performance and interpretability of models trained only on structured tabular data with models trained only on unstructured clinical text data, and on mixed data. Methods The structured data was used to train fourteen classical Machine Learning models including advanced ensemble trees, neural networks and k-nearest neighbors. The unstructured data was used to fine-tune a pre-trained Bio Clinical BERT Transformer Deep Learning model. The structured and unstructured data were then merged into a tabular dataset after vectorization of the clinical text and a dimensional reduction through Latent Dirichlet Allocation. The study used the free and publicly available Medical Information Mart for Intensive Care (MIMIC) III database, on the open AutoML Library AutoGluon. Performance is evaluated with respect to two types of random classifiers, used as baselines. Results The best model from structured data demonstrates high performance (ROC AUC = 0.944, PRC AUC = 0.655) with limited interpretability, where the most important predictors of prolonged LOS are the level of blood urea nitrogen and of platelets. The Transformer model displays a good but lower performance (ROC AUC = 0.842, PRC AUC = 0.375) with a richer array of interpretability by providing more specific in-hospital factors including procedures, conditions, and medical history. The best model trained on mixed data satisfies both a high level of performance (ROC AUC = 0.963, PRC AUC = 0.746) and a much larger scope in interpretability including pathologies of the intestine, the colon, and the blood; infectious diseases, respiratory problems, procedures involving sedation and intubation, and vascular surgery. Conclusions Our results outperform most of the state-of-the-art models in LOS prediction both in terms of performance and of interpretability. Data fusion between structured and unstructured text data may significantly improve performance and interpretability.","2023-11-30","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","11","18","","","","","","","","","","English","","","","WOS:001139775100042","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","BLOOD UREA NITROGEN; MODEL; MORTALITY; RATIO; RISK-FACTORS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QS3WA28H","journalArticle","2023","Smitha, ES; Sendhilkumar, S; Mahalakshmi, GS","Intelligence system for sentiment classification with deep topic embedding using N-gram based topic modeling","JOURNAL OF INTELLIGENT & FUZZY SYSTEMS","","1064-1246","10.3233/JIFS-230246","","Multi-modal information outbreak is consistently increasing in social media. Classification of tweet sentiments using various information modalities will help the recommender systems to achieve success in digital marketing. Moreover, aspect-level sentiment analysis categorizes a target's sentiment polarity in a specific environment. Using topic modelling in aspect-level sentiment analysis enables the identification of more accurate aspect-based tweet sentiments. The existing sentiment classification techniques used for the development of recommendation systems do not focus on the aspect-based approach modelled using deep learning classifier with temporal analysis on the social media data. Hence, this paper proposes an efficient sentiment classification model that highlights the impact of topic modelling-based word feature embedding for improvising the classification of Twitter sentiments and product reviews based on temporal reasoning and analysis for performing predictive analysis. For tweets context analysis, Latent Dirichlet Allocation based topic modelling is used in this work which generates the topics. For each topic, the sentiment is calculated separately and the topic guided feature expansion is done using Senti-wordnet. Moreover, an extended deep learning classification algorithm called Long Short-Term Memory (LSTM) with word embedding and temporal reasoning(LSTMWTR) is proposed in this paper for improving the classification accuracy. Finally, the labelled data are classified using the existing machine learning algorithms namely Naive Bayes, SupportVector Machines and also using the deep learning models such as Convolution Neural Network(CNN),LSTM, Recurrent Neural Networks (RNN) and the transformer model namelyBi-directional Encoder Representation from Transformers (BERT),Convolution Bi-directional Recurrent Neural Network (CBRNN) and the proposed deep learning algorithm namelyLSTMWTR. These sentiment classification algorithms have been evaluated with word embedding for tweet sentiment classification and product review classification. The results obtained from this work show that the proposed LSTMWTR algorithm emerges as the highly accurate model for tweet sentiment and product review classification.","2023","2025-02-26 20:43:32","2025-02-26 20:43:32","","1539-1565","","1","45","","","","","","","","","","English","","","","WOS:001028560600105","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","and CBRNN; ATTENTION; BERT; classification; CNN; LSTM; LSTMWTR; multinomial NB; NB; NEURAL-NETWORK; RNN; Sentiment; SHORT-TERM-MEMORY; SVM; temporal reasoning; word embedding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2NPNUV9B","journalArticle","2023","Yang, G; Luo, SH; Greer, P","A Novel Vision Transformer Model for Skin Cancer Classification","NEURAL PROCESSING LETTERS","","1370-4621","10.1007/s11063-023-11204-5","","Skin cancer can be fatal if it is found to be malignant. Modern diagnosis of skin cancer heavily relies on visual inspection through clinical screening, dermoscopy, or histopathological examinations. However, due to similarity among cancer types, it is usually challenging to identify the type of skin cancer, especially at its early stages. Deep learning techniques have been developed over the last few years and have achieved success in helping to improve the accuracy of diagnosis and classification. However, the latest deep learning algorithms still do not provide ideal classification accuracy. To further improve the performance of classification accuracy, this paper presents a novel method of classifying skin cancer in clinical skin images. The method consists of four blocks. First, class rebalancing is applied to the images of seven skin cancer types for better classification performance. Second, an image is preprocessed by being split into patches of the same size and then flattened into a series of tokens. Third, a transformer encoder is used to process the flattened patches. The transformer encoder consists of N identical layers with each layer containing two sublayers. Sublayer one is a multihead self-attention unit, and sublayer two is a fully connected feed-forward network unit. For each of the two sublayers, a normalization operation is applied to its input, and a residual connection of its input and its output is calculated. Finally, a classification block is implemented after the transformer encoder. The block consists of a flattened layer and a dense layer with batch normalization. Transfer learning is implemented to build the whole network, where the ImageNet dataset is used to pretrain the network and the HAM10000 dataset is used to fine-tune the network. Experiments have shown that the method has achieved a classification accuracy of 94.1%, outperforming the current state-of-the-art model IRv2 with soft attention on the same training and testing datasets. On the Edinburgh DERMOFIT dataset also, the method has better performance compared with baseline models.","2023-12","2025-02-26 20:43:32","2025-02-26 20:43:32","","9335-9351","","7","55","","","","","","","","","","English","","","","WOS:000952693800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","AUTOMATED DETECTION; Deep learning; DERMOSCOPY; DIAGNOSIS; Image processing; LESIONS; MELANOMA; Neural networks; SEGMENTATION; Skin cancer classification; STATISTICS; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2Q97YRL2","journalArticle","2023","Abbas, Q; Daadaa, Y; Rashid, U; Ibrahim, MEA","Assist-Dermo: A Lightweight Separable Vision Transformer Model for Multiclass Skin Lesion Classification","DIAGNOSTICS","","2075-4418","10.3390/diagnostics13152531","","A dermatologist-like automatic classification system is developed in this paper to recognize nine different classes of pigmented skin lesions (PSLs), using a separable vision transformer (SVT) technique to assist clinical experts in early skin cancer detection. In the past, researchers have developed a few systems to recognize nine classes of PSLs. However, they often require enormous computations to achieve high performance, which is burdensome to deploy on resource-constrained devices. In this paper, a new approach to designing SVT architecture is developed based on SqueezeNet and depthwise separable CNN models. The primary goal is to find a deep learning architecture with few parameters that has comparable accuracy to state-of-the-art (SOTA) architectures. This paper modifies the SqueezeNet design for improved runtime performance by utilizing depthwise separable convolutions rather than simple conventional units. To develop this Assist-Dermo system, a data augmentation technique is applied to control the PSL imbalance problem. Next, a pre-processing step is integrated to select the most dominant region and then enhance the lesion patterns in a perceptual-oriented color space. Afterwards, the Assist-Dermo system is designed to improve efficacy and performance with several layers and multiple filter sizes but fewer filters and parameters. For the training and evaluation of Assist-Dermo models, a set of PSL images is collected from different online data sources such as Ph2, ISBI-2017, HAM10000, and ISIC to recognize nine classes of PSLs. On the chosen dataset, it achieves an accuracy (ACC) of 95.6%, a sensitivity (SE) of 96.7%, a specificity (SP) of 95%, and an area under the curve (AUC) of 0.95. The experimental results show that the suggested Assist-Dermo technique outperformed SOTA algorithms when recognizing nine classes of PSLs. The Assist-Dermo system performed better than other competitive systems and can support dermatologists in the diagnosis of a wide variety of PSLs through dermoscopy. The Assist-Dermo model code is freely available on GitHub for the scientific community.","2023-08","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","15","13","","","","","","","","","","English","","","","WOS:001045438700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","CANCER; classification; deep learning; depthwise separable CNN; dermoscopy; FEATURES; NETWORK; pigmented skin lesions; skin cancer; SqueezeNet; vision transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TPEGIGR6","journalArticle","2025","Wang, YR; Li, YF; Chen, SY; Wen, ZJ; Hu, YH; Zhang, HW; Zhou, P; Pang, HW","Development of a CT radiomics prognostic model for post renal tumor resection overall survival based on transformer enhanced K-means clustering","MEDICAL PHYSICS","","0094-2405","10.1002/mp.17639","","BackgroundKidney tumors, common in the urinary system, have widely varying survival rates post-surgery. Current prognostic methods rely on invasive biopsies, highlighting the need for non-invasive, accurate prediction models to assist in clinical decision-making.PurposeThis study aimed to construct a K-means clustering algorithm enhanced by Transformer-based feature transformation to predict the overall survival rate of patients after kidney tumor resection and provide an interpretability analysis of the model to assist in clinical decision-making.MethodsThis study was based on a publicly available C4KC-KiTS-2019 dataset from the TCIA database, including preoperative computed tomography (CT) images and survival time data of 210 patients. Initially, the radiomics features of the kidney tumor area were extracted using the 3D slicer software. Feature selection was then conducted using ICC, mRMR algorithms, and LASSO regression to calculate radiomics scores. Subsequently, the selected features were input into a pre-trained Transformer model for feature transformation to obtain a higher-dimensional feature set. Then, K-means clustering was performed using this feature set, and the model was evaluated using receiver operating characteristic (ROC) and Kaplan-Meier curves. Finally, the SHAP interpretability algorithm was used for the feature importance analysis of the K-means clustering results.ResultsEleven important features were selected from 851 radiomics features. The K-means clustering model after Transformer feature transformation showed AUCs of 0.889, 0.841, and 0.926 for predicting 1-, 3-, and 5-year overall survival rates, respectively, thereby outperforming both the K-means model with original feature inputs and the radiomics score method. A clustering analysis revealed survival prognosis differences among different patient groups, and a SHAP analysis provided insights into the features that had the most significant impacts on the model predictions.ConclusionsThe K-means clustering algorithm enhanced by the Transformer feature transformation proposed in this study demonstrates promising accuracy and interpretability in predicting the overall survival rate after kidney tumor resection. This method provides a valuable tool for clinical decision-making and contributes to improved management and treatment strategies for patients with kidney tumors.","2025-01-27","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","","","","","","","","","","","English","","","","WOS:001406531600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","deep learning; large language model; machine learning; radiomics; unsupervised learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"THG4URCV","journalArticle","2023","Zheng, HT; Duan, JC; Dong, Y; Liu, Y","Real-time fire detection algorithms running on small embedded devices based on MobileNetV3 and YOLOv4","FIRE ECOLOGY","","1933-9747","10.1186/s42408-023-00189-0","","AimFires are a serious threat to people's lives and property. Detecting fires quickly and effectively and extinguishing them in the nascent stage is an effective way to reduce fire hazards. Currently, deep learning-based fire detection algorithms are usually deployed on the PC side.MethodsAfter migrating to small embedded devices, the accuracy and speed of recognition are degraded due to the lack of computing power. In this paper, we propose a real-time fire detection algorithm based on MobileNetV3-large and yolov4, replacing CSP Darknet53 in yolov4 with MobileNetV3-large to achieve the initial extraction of flame and smoke features while greatly reducing the computational effort of the network structure. A path connecting PANet was explored on Gbneck(104, 104, 24), while SPP was embedded in the path from MobileNetV3 to PANet to improve the feature extraction capability for small targets; the PANet in yolo4 was improved by combining the BiFPN path fusion method, and the improved PANet further improved the feature extraction capability; the Vision Transformer model is added to the backbone feature extraction network and PANet of the YOLOv4 model to give full play to the model's multi-headed attention mechanism for pre-processing image features; adding ECA Net to the head network of yolo4 improves the overall recognition performance of the network.ResultThese algorithms run well on PC and reach 95.14% recognition accuracy on the public dataset BoWFire. Finally, these algorithms were migrated to the Jeston Xavier NX platform, and the entire network was quantized and accelerated with the TensorRT algorithm. With the image propagation function of the fire robot, the overall recognition frame rate can reach about 26.13 with high real-time performance while maintaining a high recognition accuracy.ConclusionSeveral comparative experiments have also validated the effectiveness of this paper's improvements to the YOLOv4 algorithm and the superiority of these structures. With the effective integration of these components, the algorithm shows high accuracy and real-time performance.","2023-05-15","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","1","19","","","","","","","","","","English","","","","WOS:000988013500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;18<br/>Total Times Cited:&nbsp;&nbsp;18<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","BiFPN; CONVOLUTIONAL NEURAL-NETWORKS; DYNAMIC TEXTURE ANALYSIS; ECA Net; Fire detection; FLAME DETECTION; FRAMEWORK; IMAGE; MobileNetV3-large; PANet; SMOKE DETECTION; SPP; SURVEILLANCE; TensorRT; YOLOv4","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"94KPIB2S","journalArticle","2023","Yang, GQ; Li, KW; Yao, JH; Chang, SM; He, C; Lu, F; Wang, XG; Wang, Z","Automatic measurement of anterior chamber angle parameters in AS-OCT images using deep learning","BIOMEDICAL OPTICS EXPRESS","","2156-7085","10.1364/BOE.481419","","The early assessment of angle closure is of great significance for the timely diagnosis and treatment of primary angle-closure glaucoma (PACG). Anterior segment optical coherence tomography (AS-OCT) provides a fast and non-contact way to evaluate the angle close using the iris root (IR) and scleral spur (SS) information. The objective of this study was to develop a deep learning method to automatically detect IR and SS in AS-OCT for measuring anterior chamber (AC) angle parameters including angle opening distance (AOD), trabecular iris space area (TISA), trabecular iris angle (TIA), and anterior chamber angle (ACA). 3305 AS-OCT images from 362 eyes and 203 patients were collected and analyzed. Based on the recently proposed transformer-based architecture that learns to capture long-range dependencies by leveraging the self-attention mechanism, a hybrid convolutional neural network (CNN) and transformer model to encode both local and global features was developed to automatically detect IR and SS in AS-OCT images. Experiments demonstrated that our algorithm achieved a significantly better performance than state-of-the-art methods for AS-OCT and medical image analysis with a precision of 0.941, a sensitivity of 0.914, an F1 score of 0.927, and a mean absolute error (MAE) of 37.1 +/- 25.3 mu m for IR, and a precision of 0.805, a sensitivity of 0.847, an F1 score of 0.826, and an MAE of 41.4 +/- 29.4 mu m for SS, and a high agreement with expert human analysts for AC angle parameter measurement. We further demonstrated the application of the proposed method to evaluate the effect of cataract surgery with IOL implantation in a PACG patient and to assess the outcome of ICL implantation in a patient with high myopia with a potential risk of developing PACG. The proposed method can accurately detect IR and SS in AS-OCT images and effectively facilitate the AC angle parameter measurement for pre- and post-operative management of PACG. (c) 2023 Optica Publishing Group under the terms of the Optica Open Access Publishing Agreement","2023-04-01","2025-02-26 20:43:32","2025-02-26 20:43:32","","1378-1392","","4","14","","","","","","","","","","English","","","","WOS:001031293800004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","CLOSURE GLAUCOMA; EXTRACTION; IMPLANTATION; PREVALENCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B93P4TP4","journalArticle","2022","El-allaly, ED; Sarrouti, M; En-Nahnahi, N; El Alaoui, SO","An attentive joint model with transformer-based weighted graph convolutional network for extracting adverse drug event relation","JOURNAL OF BIOMEDICAL INFORMATICS","","1532-0464","10.1016/j.jbi.2021.103968","","Adverse drug event (ADE) relation extraction is a crucial task for drug safety surveillance which aims to discover potential relations between ADE mentions from unstructured medical texts. To date, the graph convolutional networks (GCN) have been the state-of-the-art solutions for improving the ability of relation extraction task. However, there are many challenging issues that should be addressed. Among these, the syntactic information is not fully exploited by GCN-based methods, especially the diversified dependency edges. Still, these methods fail to effectively extract complex relations that include nested, discontinuous and overlapping mentions. Besides, the task is primarily regarded as a classification problem where each candidate relation is treated independently which neglects the interaction between other relations. To deal with these issues, in this paper, we propose an attentive joint model with transformer-based weighted GCN for extracting ADE Relations, called ADERel. Firstly, the ADERel system formulates the ADE relation extraction task as an N-level sequence labelling so as to model the complex relations in different levels and capture greater interaction between relations. Then, it exploits our neural joint model to process the N-level sequences jointly. The joint model leverages the contextual and structural information by adopting a shared representation that combines a bidirectional encoder representation from transformers (BERT) and our proposed weighted GCN (WGCN). The latter assigns a score to each dependency edge within a sentence so as to capture rich syntactic features and determine the most influential edges for extracting ADE relations. Finally, the system employs a multi-head attention to exchange boundary knowledge across levels. We evaluate ADERel on two benchmark datasets from TAC 2017 and n2c2 2018 shared tasks. The experimental results show that ADERel is superior in performance compared with several state-of-the-art methods. The results also demonstrate that incorporating a transformer model with WGCN makes the proposed system more effective for extracting various types of ADE relations. The evaluations further highlight that ADERel takes advantage of joint learning, showing its effectiveness in recognizing complex relations.","2022-01","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","125","","","","","","","","","","English","","","","WOS:000735573800004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;18<br/>Total Times Cited:&nbsp;&nbsp;18<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","Adverse drug events; INFORMATION; Joint learning; Natural language processing; Relation extraction; Transfer learning; Weighted graph convolutional network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CI83DSW7","journalArticle","2024","Huang, JX; Chang, YH; Li, WY; Tong, JG; Du, SZ","A Spatio-Temporal Capsule Neural Network with Self-Correlation Routing for EEG Decoding of Semantic Concepts of Imagination and Perception Tasks","SENSORS","","1424-8220","10.3390/s24185988","","Decoding semantic concepts for imagination and perception tasks (SCIP) is important for rehabilitation medicine as well as cognitive neuroscience. Electroencephalogram (EEG) is commonly used in the relevant fields, because it is a low-cost noninvasive technique with high temporal resolution. However, as EEG signals contain a high noise level resulting in a low signal-to-noise ratio, it makes decoding EEG-based semantic concepts for imagination and perception tasks (SCIP-EEG) challenging. Currently, neural network algorithms such as CNN, RNN, and LSTM have almost reached their limits in EEG signal decoding due to their own short-comings. The emergence of transformer methods has improved the classification performance of neural networks for EEG signals. However, the transformer model has a large parameter set and high complexity, which is not conducive to the application of BCI. EEG signals have high spatial correlation. The relationship between signals from different electrodes is more complex. Capsule neural networks can effectively model the spatial relationship between electrodes through vector representation and a dynamic routing mechanism. Therefore, it achieves more accurate feature extraction and classification. This paper proposes a spatio-temporal capsule network with a self-correlation routing mechaninsm for the classification of semantic conceptual EEG signals. By improving the feature extraction and routing mechanism, the model is able to more effectively capture the highly variable spatio-temporal features from EEG signals and establish connections between capsules, thereby enhancing classification accuracy and model efficiency. The performance of the proposed model was validated using the publicly accessible semantic concept dataset for imagined and perceived tasks from Bath University. Our model achieved average accuracies of 94.9%, 93.3%, and 78.4% in the three sensory modalities (pictorial, orthographic, and audio), respectively. The overall average accuracy across the three sensory modalities is 88.9%. Compared to existing advanced algorithms, the proposed model achieved state-of-the-art performance, significantly improving classification accuracy. Additionally, the proposed model is more stable and efficient, making it a better decoding solution for SCIP-EEG decoding.","2024-09","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","18","24","","","","","","","","","","English","","","","WOS:001323548500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","brain-computer interface (BCI); capsule neural network; CLASSIFICATION; DOMAIN; EEG decoding; MECHANISMS; self-correlation routing; semantic concepts","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XX6BC9YS","journalArticle","2024","Fahad, AR; Al Nahian, N; Islam, MA; Rahman, RM","Answer Agnostic Question Generation in Bangla Language","INTERNATIONAL JOURNAL OF NETWORKED AND DISTRIBUTED COMPUTING","","2211-7938","10.1007/s44227-023-00018-5","","Question generation (QG) from a given context paragraph is a demanding task in natural language processing for its practical applications and prospects in various fields. Several studies have been conducted on QG in high-resource languages like English, however, very few have been done on resource-poor languages like Arabic and Bangla. In this work, we propose a finetuning method for QG that uses pre-trained transformer-based language models to generate questions from a given context paragraph in Bangla. Our approach is based on the idea that a transformer-based language model can be used to learn the relationships between words and phrases in a context paragraph which allows the models to generate questions that are both relevant and grammatically correct. We finetuned three different transformer models: (1) BanglaT5, (2) mT5-base, (3) BanglaGPT2, and demonstrated their capabilities using two different data formatting techniques: (1) AQL-All Question Per Line, (2) OQL-One Question Per Line, making it a total of six different variations of QG models. For each of these variants, six different decoding algorithms: (1) Greedy search, (2) Beam search, (3) Random Sampling, (4) Top K sampling, (5) Top- p Sampling, 6) a combination of Top K and Top-p Sampling were used to generate questions from the test dataset. For evaluation of the quality of questions generated using different models and decoding techniques, we also fine-tuned another transformer model BanglaBert on two custom datasets of our own and created two question classifier (QC) models that check the relevancy and Grammatical correctness of the questions generated by our QG models. The QC models showed test accuracy of 88.54% and 95.76% in the case of correctness and relevancy checks, respectively. Our results show that among all the variants of the QG, the mT5 OQL approach and beam decoding algorithm outperformed all the other ones in terms of relevancy (77%) and correctness (96%) with 36.60 Bleu_4, 48.98 METEOR, and 63.38 ROUGE-L scores.","2024-06","2025-02-26 20:43:32","2025-02-26 20:43:32","","82-107","","1","12","","","","","","","","","","English","","","","WOS:001132710400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Bangla language; Natural language generation; Natural language processing; Neural networks; Question answering; Question generation; Transformer models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8RMTKY7R","journalArticle","2022","Botelle, R; Bhavsar, V; Kadra-Scalzo, G; Mascio, A; Williams, M; Roberts, A; Velupillai, S; Stewart, R","Can natural language processing models extract and classify instances of interpersonal violence in mental healthcare electronic records: an applied evaluative study","BMJ OPEN","","2044-6055","10.1136/bmjopen-2021-052911","","Objective This paper evaluates the application of a natural language processing (NLP) model for extracting clinical text referring to interpersonal violence using electronic health records (EHRs) from a large mental healthcare provider. Design A multidisciplinary team iteratively developed guidelines for annotating clinical text referring to violence. Keywords were used to generate a dataset which was annotated (ie, classified as affirmed, negated or irrelevant) for: presence of violence, patient status (ie, as perpetrator, witness and/or victim of violence) and violence type (domestic, physical and/or sexual). An NLP approach using a pretrained transformer model, BioBERT (Bidirectional Encoder Representations from Transformers for Biomedical Text Mining) was fine-tuned on the annotated dataset and evaluated using 10-fold cross-validation. Setting We used the Clinical Records Interactive Search (CRIS) database, comprising over 500 000 de-identified EHRs of patients within the South London and Maudsley NHS Foundation Trust, a specialist mental healthcare provider serving an urban catchment area. Participants Searches of CRIS were carried out based on 17 predefined keywords. Randomly selected text fragments were taken from the results for each keyword, amounting to 3771 text fragments from the records of 2832 patients. Outcome measures We estimated precision, recall and F1 score for each NLP model. We examined sociodemographic and clinical variables in patients giving rise to the text data, and frequencies for each annotated violence characteristic. Results Binary classification models were developed for six labels (violence presence, perpetrator, victim, domestic, physical and sexual). Among annotations affirmed for the presence of any violence, 78% (1724) referred to physical violence, 61% (1350) referred to patients as perpetrator and 33% (731) to domestic violence. NLP models' precision ranged from 89% (perpetrator) to 98% (sexual); recall ranged from 89% (victim, perpetrator) to 97% (sexual). Conclusions State of the art NLP models can extract and classify clinical text on violence from EHRs at acceptable levels of scale, efficiency and accuracy.","2022-02","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","2","12","","","","","","","","","","English","","","","WOS:000757529000005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","CLINICAL INFORMATION; health informatics; mental health; psychiatry; public health; TEXT; VICTIMIZATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y2S34Z9M","journalArticle","2023","Shah, SMAH; Shah, SFH; Ullah, A; Rizwan, A; Atteia, G; Alabdulhafith, M","Arabic Sentiment Analysis and Sarcasm Detection Using Probabilistic Projections-Based Variational Switch Transformer","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3289715","","Text classification is a common task in natural language processing (NLP), where the objective is to assign predefined categories or labels to a given text. Detecting sarcasm and classifying sentiment and dialect in NLP has practical applications, including spam detection, topic classification, and sentiment analysis. However, sarcasm and sentimental expressions, such as irony, humor, or criticism, can be difficult to identify through traditional NLP methods dueto their implicit nature. To address this, we propose a Modified Switch Transformer (MST) for detecting sarcasm and classifying sentiment and dialect in Arabic text data. Our approach includes two key contributions: Variational Enmesh Expert's Routing (VEeR) and Probabilistic Projections (P-f). The switch transformer model incorporates probabilistic projections using a Variational Spatial Gated Unit-MLP to enhance the embedding generation mechanism. This updated mechanism introduces a variational aspect, providing dynamic control over the flow of information in the network, in contrast to the simpler embedding generation phase used in the original switch transformer. Moreover, we incorporate Variational Enmesh Expert's Routing, which utilizes a hierarchical set of Variational experts, where each expert is a small and variational-directed acyclic graph network. The VEeR routing technique allows the network to dynamically choose which path to take at each layer based on the input, using a set of weights learned during training to determine the best route for a given input. Instead of optimizing route paths deterministically, we utilize Variational Inference and model each route as a random variable from a distribution. Our study evaluates the effectiveness of the Modified Switch Transformer (MST) model on the ArSarcasm Dataset, which includes Arabic language data related to sarcasm, dialect, and sentiments. We compare the performance of our proposed model with existing state-of-the-art models in the literature. The results show that the switch transformer outperforms other models in detecting sarcasm and also performs well in classifying sentiment and dialect.","2023","2025-02-26 20:43:32","2025-02-26 20:43:32","","67865-67881","","","11","","","","","","","","","","English","","","","WOS:001028885000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","Arabic sarcasm detection; Arabic sentiment analysis; Bayesian inference; deep learning; NLP; probabilistic projections; switch transformer; Text classification; variational expert routing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6NL9J4SV","journalArticle","2022","Li, KY; Zhang, M; Xu, MP; Tang, R; Wang, L; Wang, H","Ship Detection in SAR Images Based on Feature Enhancement Swin Transformer and Adjacent Feature Fusion","REMOTE SENSING","","2072-4292","10.3390/rs14133186","","Convolutional neural networks (CNNs) have achieved milestones in object detection of synthetic aperture radar (SAR) images. Recently, vision transformers and their variants have shown great promise in detection tasks. However, ship detection in SAR images remains a substantial challenge because of the characteristics of strong scattering, multi-scale, and complex backgrounds of ship objects in SAR images. This paper proposes an enhancement Swin transformer detection network, named ESTDNet, to complete the ship detection in SAR images to solve the above problems. We adopt the Swin transformer of Cascade-R-CNN (Cascade R-CNN Swin) as a benchmark model in ESTDNet. Based on this, we built two modules in ESTDNet: the feature enhancement Swin transformer (FESwin) module for improving feature extraction capability and the adjacent feature fusion (AFF) module for optimizing feature pyramids. Firstly, the FESwin module is employed as the backbone network, aggregating contextual information about perceptions before and after the Swin transformer model using CNN. It uses single-point channel information interaction as the primary and local spatial information interaction as the secondary for scale fusion based on capturing visual dependence through self-attention, which improves spatial-to-channel feature expression and increases the utilization of ship information from SAR images. Secondly, the AFF module is a weighted selection fusion of each high-level feature in the feature pyramid with its adjacent shallow-level features using learnable adaptive weights, allowing the ship information of SAR images to be focused on the feature maps at more scales and improving the recognition and localization capability for ships in SAR images. Finally, the ablation study conducted on the SSDD dataset validates the effectiveness of the two components proposed in the ESTDNet detector. Moreover, the experiments executed on two public datasets consisting of SSDD and SARShip demonstrate that the ESTDNet detector outperforms the state-of-the-art methods, which provides a new idea for ship detection in SAR images.","2022-07","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","13","14","","","","","","","","","","English","","","","WOS:000822193700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;26<br/>Total Times Cited:&nbsp;&nbsp;26<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","adjacent feature fusion; Cascade R-CNN; feature enhancement Swin transformer; NETWORK; ship detection; synthetic aperture radar (SAR)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6LUUL963","journalArticle","2025","Lee, Y; Min, S; Yoon, J; Ha, J; Jeong, S; Ryu, S; Ahn, MH","Application of deep learning in cloud cover prediction using geostationary satellite images","GISCIENCE & REMOTE SENSING","","1548-1603","10.1080/15481603.2024.2440506","","Predicting cloud cover is essential in fields, such as agriculture, climatology, and meteorology, where accurate weather forecasting can significantly impact decision-making. Traditional methods for cloud cover prediction encounter significant limitations in capturing complete spatial and temporal cloud dynamics. To address the problem, this study employs high-resolution data from the new-generation geostationary satellite Geostationary Korea Multi-Purpose Satellite 2A (GEO-KOMPSAT-2A; GK2A) and enables more accurate and timely predictions when combined with advanced deep learning techniques. We explore the effectiveness of advanced deep learning techniques - specifically 3D Convolutional Neural Networks, Long Short-Term Memory networks, and Convolutional Long Short-Term Memory (ConvLSTM) - using GK2A cloud detection data, which provides updates every 10 minutes at 2 km spatial resolution. Our model utilizes training sequences of four past hourly images to predict cloud cover up to 4 hours ahead. For improved computational efficiency, each image is divided into four patches during training. Notably, this research incorporates a dynamic learning model, continuously updating with the most recent data, in contrast with static models which do not update their parameters with new data once trained. Results show that ConvLSTM tends to exhibit stable and relatively higher performance across prediction times compared to the other models in August 2021. While transformer models, such as Video Swin Transformer and TimeSformer, showed strong training performance, they struggled with overfitting, particularly on smaller datasets. In contrast, ConvLSTM demonstrated better generalization to test data, highlighting its suitability for tasks with limited training data and simpler structures. Year-long validation demonstrates the robustness of the ConvLSTM model, which consistently outperforms the other models in all major metrics, including a precision of 0.79, recall of 0.80, F1-score of 0.80 (which balances precision and recall), and accuracy of 0.78 throughout 2021. However, results show that the model's performance in terms of F1-score, recall, and precision is positively correlated with cloud fraction, with a slight tendency for higher accuracy during the summer compared to winter, indicating sensitivity to seasonal cloud cover variations.","2025-12-31","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","1","62","","","","","","","","","","English","","","","WOS:001377415300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Cloud cover prediction; CNN; Convolutional Long Short-Term Memory (ConvLSTM); deep learning; dynamic learning; GEO-KOMPSAT-2A (GK2A); transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2UMYWDHI","journalArticle","2024","Peng, C; Yang, X; Smith, KE; Yu, ZH; Chen, AK; Bian, J; Wu, YH","Model tuning or prompt Tuning? a study of large language models for clinical concept and relation extraction","JOURNAL OF BIOMEDICAL INFORMATICS","","1532-0464","10.1016/j.jbi.2024.104630","","Objective: To develop soft prompt-based learning architecture for large language models (LLMs), examine prompt-tuning using frozen/unfrozen LLMs, and assess their abilities in transfer learning and few-shot learning. Methods: We developed a soft prompt-based learning architecture and compared 4 strategies including (1) finetuning without prompts; (2) hard-prompting with unfrozen LLMs; (3) soft-prompting with unfrozen LLMs; and (4) soft-prompting with frozen LLMs. We evaluated GatorTron, a clinical LLM with up to 8.9 billion parameters, and compared GatorTron with 4 existing transformer models for clinical concept and relation extraction on 2 benchmark datasets for adverse drug events and social determinants of health (SDoH). We evaluated the few-shot learning ability and generalizability for cross-institution applications. Results and Conclusion: When LLMs are unfrozen, GatorTron-3.9B with soft prompting achieves the best strict F1scores of 0.9118 and 0.8604 for concept extraction, outperforming the traditional fine-tuning and hard promptbased models by 0.6 - 3.1 % and 1.2 - 2.9 %, respectively; GatorTron-345 M with soft prompting achieves the best F1-scores of 0.8332 and 0.7488 for end-to-end relation extraction, outperforming other two models by 0.2 - 2 % and 0.6 - 11.7 %, respectively. When LLMs are frozen, small LLMs have a big gap to be competitive with unfrozen models; scaling LLMs up to billions of parameters makes frozen LLMs competitive with unfrozen models. Soft prompting with a frozen GatorTron-8.9B model achieved the best performance for cross-institution evaluation. We demonstrate that (1) machines can learn soft prompts better than hard prompts composed by human, (2) frozen LLMs have good few-shot learning ability and generalizability for cross-institution applications, (3) frozen LLMs reduce computing cost to 2.5 - 6 % of previous methods using unfrozen LLMs, and (4) frozen LLMs require large models (e.g., over several billions of parameters) for good performance.","2024-05","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","153","","","","","","","","","","English","","","","WOS:001224748300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Clinical concept extraction; Large language model; Prompt tuning; Relation extraction; SYSTEM; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8B2D3QJ8","journalArticle","2022","Buehler, MJ","FieldPerceiver: Domain agnostic transformer model to predict multiscale physical fields and nonlinear material properties through neural ologs","MATERIALS TODAY","","1369-7021","10.1016/j.mattod.2022.05.020","","Attention-based transformer neural networks have had significant impact in recent years. However, their applicability to model the behavior of physical systems has not yet been broadly explored. This is partly due to the high computational burden owing to the nonlinear scaling of very deep models, preventing application to a range of physical systems, in particular complex field data. Here we report the development of a general-purpose attention-based deep neural network model using a multi-headed self-attention approach, FieldPerceiver, that is capable of effectively predicting physical field data - such as stress, energy and displacement fields, as well as predicting overall material properties that characterize the statistics of stress distributions due to applied loading and crack defects, solely based on descriptive input that characterizes the material microstructure based on a set of interacting building blocks, all while capturing extreme short- and long-range relationships. Not using images as input, but rather realizing a neural olog description of materials where the categorization is learned by multi-headed attention, the model has no domain knowledge in its formulation, uses no convolutional layers, scales well to extremely large sizes and has no knowledge about specific properties of the material building blocks. Specifically, as applied to a fracture mechanics problem considered here, the model is capable of capturing size, orientation and geometry effects of crack problems for near- and far-field predictions, offering an alternative way to model materials failure based on language modeling without any convolutional layers commonly used in similar problems. We show that the FieldPerceiver can be used in a general framework, where the model can use insights learned during an initial, general training stage in order to fine-tune predictions for new scenarios, even when using only small additional datasets, revealing its broad generalization capacity. Once trained, the model can make predictions of thousands of scenarios within just a few minutes of compute time. It would take tens of hours, days or months to compute similar output using molecular dynamics simulation, for instance.","2022-07","2025-02-26 20:43:32","2025-02-26 20:43:32","","9-25","","","57","","","","","","","","","","English","","","","WOS:000863541200006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;34<br/>Total Times Cited:&nbsp;&nbsp;34<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","Attention models; Category theory; Computer vision; Deep learning; DESIGN; Fracture; Mechanics; Natural language processing; Ologs; Physics; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EP3UQKFL","journalArticle","2024","Abinaya, K; Sivakumar, B","A Deep Learning-Based Approach for Cervical Cancer Classification Using 3D CNN and Vision Transformer","JOURNAL OF IMAGING INFORMATICS IN MEDICINE","","2948-2925","10.1007/s10278-023-00911-z","","Cervical cancer is a significant health problem worldwide, and early detection and treatment are critical to improving patient outcomes. To address this challenge, a deep learning (DL)-based cervical classification system is proposed using 3D convolutional neural network and Vision Transformer (ViT) module. The proposed model leverages the capability of 3D CNN to extract spatiotemporal features from cervical images and employs the ViT model to capture and learn complex feature representations. The model consists of an input layer that receives cervical images, followed by a 3D convolution block, which extracts features from the images. The feature maps generated are down-sampled using max-pooling block to eliminate redundant information and preserve important features. Four Vision Transformer models are employed to extract efficient feature maps of different levels of abstraction. The output of each Vision Transformer model is an efficient set of feature maps that captures spatiotemporal information at a specific level of abstraction. The feature maps generated by the Vision Transformer models are then supplied into the 3D feature pyramid network (FPN) module for feature concatenation. The 3D squeeze-and-excitation (SE) block is employed to obtain efficient feature maps that recalibrate the feature responses of the network based on the interdependencies between different feature maps, thereby improving the discriminative power of the model. At last, dimension minimization of feature maps is executed using 3D average pooling layer. Its output is then fed into a kernel extreme learning machine (KELM) for classification into one of the five classes. The KELM uses radial basis kernel function (RBF) for mapping features in high-dimensional feature space and classifying the input samples. The superiority of the proposed model is known using simulation results, achieving an accuracy of 98.6%, demonstrating its potential as an effective tool for cervical cancer classification. Also, it can be used as a diagnostic supportive tool to assist medical experts in accurately identifying cervical cancer in patients.","2024-02","2025-02-26 20:43:32","2025-02-26 20:43:32","","280-296","","1","37","","","","","","","","","","English","","","","WOS:001305398600021","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","3D convolution block; 3D feature pyramid network; Cervical cancer; Kernel extreme learning machine; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LYBYVWSU","journalArticle","2024","Song, ZH; Zhou, Y; Cheng, W; Liang, FT; Zhang, CH","Missing Value Imputation for Radar-Derived Time-Series Tracks of Aerial Targets Based on Improved Self-Attention-Based Network","CMC-COMPUTERS MATERIALS & CONTINUA","","1546-2218","10.32604/cmc.2024.047034","","The frequent missing values in radar-derived time-series tracks of aerial targets (RTT-AT) lead to significant challenges in subsequent data-driven tasks. However, the majority of imputation research focuses on random missing (RM) that differs significantly from common missing patterns of RTT-AT. The method for solving the RM may experience performance degradation or failure when applied to RTT-AT imputation. Conventional autoregressive deep learning methods are prone to error accumulation and long-term dependency loss. In this paper, a non-autoregressive imputation model that addresses the issue of missing value imputation for two common missing patterns in RTT-AT is proposed. Our model consists of two probabilistic sparse diagonal masking selfattention (PSDMSA) units and a weight fusion unit. It learns missing values by combining the representations outputted by the two units, aiming to minimize the difference between the missing values and their actual values. The PSDMSA units effectively capture temporal dependencies and attribute correlations between time steps, improving imputation quality. The weight fusion unit automatically updates the weights of the output representations from the two units to obtain a more accurate final representation. The experimental results indicate that, despite varying missing rates in the two missing patterns, our model consistently outperforms other methods in imputation performance and exhibits a low frequency of deviations in estimates for specific missing entries. Compared to the state-of-the-art autoregressive deep learning imputation model Bidirectional Recurrent Imputation for Time Series (BRITS), our proposed model reduces mean absolute error (MAE) by 31%similar to 50%. Additionally, the model attains a training speed that is 4 to 8 times faster when compared to both BRITS and a standard Transformer model when trained on the same dataset. Finally, the findings from the ablation experiments demonstrate that the PSDMSA, the weight fusion unit, cascade network design, and imputation loss enhance imputation performance and confirm the efficacy of our design.","2024","2025-02-26 20:43:32","2025-02-26 20:43:32","","3349-3376","","3","78","","","","","","","","","","English","","","","WOS:001205586300004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","diagonal masking; Missing value imputation; OUTLIER DETECTION; probabilistic sparsity; self -attention; time -series tracks; weight fusion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q5T52AUM","journalArticle","2024","Tao, JT; Zhang, NN; Chang, JY; Chen, L; Zhang, H; Liao, SB; Li, SY","Deep learning-based mineral exploration named entity recognition: A case study of granitic pegmatite-type lithium deposits","ORE GEOLOGY REVIEWS","","0169-1368","10.1016/j.oregeorev.2024.106367","","Geological text data play a crucial role as sources of geological information and knowledge for mineral exploration. Mineral exploration involves predicting and detecting mineral resources using geological, geochemical, geophysical, and remote sensing data. However, existing named entity recognition studies on mineral deposits have mainly focused on geological environments and mineral deposit models, which are insufficient for capturing the extensive knowledge essential for mineral exploration and supporting subsequent exploration efforts. This paper presents an efficient workflow for automatically extracting mineral exploration information from unstructured geological text data using a deep learning method. Initially, 21 entity types were identified based on a conceptual prospecting model of granitic pegmatite-type lithium deposits. A mineral exploration corpus was constructed from Chinese geological literature and reports, comprising 3,386 sentences and 13,167 entities. Subsequently, a Mineral Exploration Named Entity Recognition (MENER) model is proposed to extract mineral exploration information. This model integrates entity-type enhanced characters, words, and contextual features to enhance the performance. Bidirectional encoder representations from the transformer model were employed to obtain character embeddings of the input text. Mineral exploration entity types provide external knowledge, aiding the understanding of entity semantics within sentences through multi-head attention. Convolutional neural networks and bidirectional long short-term memory models have been employed to extract word and contextual features and capture additional structural information. Geological entity nomenclature and expressions follow certain default conventions and paradigms. A boundary prediction classifier was introduced to identify the head and tail characteristics of geological entities. A conditional random field was then utilized to classify the entities. The MENER model achieved an average F1-score of 79.69% on the constructed dataset. Finally, a geological document was selected as a case study to demonstrate the effectiveness of the proposed model. The workflow outlined in this study enables the rapid and robust extraction of specific information and knowledge mining from geological text data, with potential applications across various domains.","2024-12","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","175","","","","","","","","","","English","","","","WOS:001370514500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","Deep learning; EXTRACTION; Geological text; GEOSCIENCE; Lithium deposit; Mineral exploration information extraction; Named entity recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3MGEUKBD","journalArticle","2024","Wang, M; Li, S; Peng, R; Räisänen, SE; Serviento, AM; Sun, X; Wang, K; Yu, F; Niu, M","Learning end-to-end respiratory rate prediction of dairy cows from red, green, and blue videos","JOURNAL OF DAIRY SCIENCE","","0022-0302","10.3168/jds.2023-24601","","Respiratory rate (RR) is an important indicator of the health and welfare status of dairy cows. In recent years, progress has been made in monitoring the RR of dairy cows using video data and learning methods. However, existing approaches often involve multiple processing modules, such as region of interest (ROI) detection and tracking, which can introduce errors that propagate through successive steps. The objective of this study was to develop an end-to-end computer vision method to predict RR of dairy cows continuously and automatically. The method leverages the capabilities of a stateof-the-art Transformer model, VideoMAE, which divides video frames into patches as input tokens, enabling the automated selection and featurization of relevant regions, such as a cow's abdomen, for predicting RR. The original encoder of VideoMAE was retained, and a classification head was added on top of it. Further, the weights of the first 11 layers of the pre-trained model were kept, whereas the weights of the final layer and classifier were fine-tuned using video data collected in a tiestall barn from 6 dairy cows. Respiratory rates measured using a respiratory belt for individual cows were serving as the ground truth (GT). The evaluation of the developed model was conducted using multiple metrics, including mean absolute error (MAE) of 2.58 breaths per minute (bpm), root mean squared error (RMSE) of 3.52 bpm, root mean squared prediction error (RMSPE; as a proportion of observed mean) of 15.03%, and Pearson r of 0.86. Compared with a conventional method involving multiple processing modules, the end-to-end approach performed better in terms of MAE, RMSE, and RMSPE. These results suggest the potential to implement the developed computer vision method for an end-to-end solution, for monitoring RR of dairy cows automatically in a tiestall setting. Future research on integrating this method with other behavioral detection and animal identification algorithms for animal monitoring in a freestall dairy barn can be beneficial for a broader application.","2024-11","2025-02-26 20:43:32","2025-02-26 20:43:32","","9862-9874","","11","107","","","","","","","","","","English","","","","WOS:001353994900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","animal welfare; computer vision; physiological parameters; precision livestock farming; transformer; WELFARE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A54VHIET","journalArticle","2022","Wang, AL; Xing, S; Zhao, Y; Wu, HB; Iwahori, Y","A Hyperspectral Image Classification Method Based on Adaptive Spectral Spatial Kernel Combined with Improved Vision Transformer","REMOTE SENSING","","2072-4292","10.3390/rs14153705","","In recent years, methods based on deep convolutional neural networks (CNNs) have dominated the classification task of hyperspectral images. Although CNN-based HSI classification methods have the advantages of spatial feature extraction, HSI images are characterized by approximately continuous spectral information, usually containing hundreds of spectral bands. CNN cannot mine and represent the sequence properties of spectral features well, and the transformer model of attention mechanism proves its advantages in processing sequence data. This study proposes a new spectral spatial kernel combined with the improved Vision Transformer (ViT) to jointly extract spatial spectral features to complete classification task. First, the hyperspectral data are dimensionally reduced by PCA; then, the shallow features are extracted with an spectral spatial kernel, and the extracted features are input into the improved ViT model. The improved ViT introduces a re-attention mechanism and a local mechanism based on the original ViT. The re-attention mechanism can increase the diversity of attention maps at different levels. The local mechanism is introduced into ViT to make full use of the local and global information of the data to improve the classification accuracy. Finally, a multi-layer perceptron is used to obtain the classification result. Among them, the Focal Loss function is used to increase the loss weight of small-class samples and difficult-to-classify samples in HSI data samples and reduce the loss weight of easy-to-classify samples, so that the network can learn more useful hyperspectral image information. In addition, using the Apollo optimizer to train the HSI classification model to better update and compute network parameters that affect model training and model output, thereby minimizing the loss function. We evaluated the classification performance of the proposed method on four different datasets, and achieved good classification results on urban land object classification, crop classification and mineral classification, respectively. Compared with the state-of-the-art backbone network, the method achieves a significant improvement and achieves very good classification accuracy.","2022-08","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","15","14","","","","","","","","","","English","","","","WOS:000839891000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","feature extraction; hyperspectral image (HSI); image classification; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HS4IW74Z","journalArticle","2024","Perbet, P; Guindon, L; Côté, JF; Béland, M","Evaluating deep learning methods applied to Landsat time series subsequences to detect and classify boreal forest disturbances events: The challenge of partial and progressive disturbances","REMOTE SENSING OF ENVIRONMENT","","0034-4257","10.1016/j.rse.2024.114107","","The monitoring of forest ecosystems is significantly affected by the lack of consistent historical data of lowseverity (forest partially disturbed) or gradual disturbance (e.g. eastern spruce budworm epidemic). The goal of this paper is to explore the use of a subset of Landsat time series and deep learning models to identify both the type and the year of disturbances, including low-severity and gradual disturbances, in the boreal forest of eastern Canada at the pixel level. Remote sensing data such as the spectral information from Landsat time series are the best available option for large scale observations of disturbances that go back decades. Traditional modeling approaches, like LandTrendr, require substantial handcrafted pre-processing to remove noise and to extract temporal features from the image sequences before using them as input to a classical machine-learning model. Deep-learning models can autonomously discern which features are relevant within the coarse temporal and spectral information from the Landsat annual dense time series. We evaluated the performance of TempCNN and Transformer model in detecting and classifying the type and the year of the forest disturbance using Landsat time series subsequences. Our findings resulted in the generation of four disturbance maps outlining the forest history from 1986 to 2021 within the eastern Canadian boreal forest. Our experimental outcomes demonstrate several significant benefits of employing deep learning models. Firstly, using noisy Landsat time series they achieve comparable accuracy for classifying fire and total harvesting than existing publicly available disturbance maps. Secondly, the use of shorter time series subsequence with deep learning models enables to map adequately different overlapping disturbances occurring in the complete time series. Finally, they increase the number of distinguishable disturbance classes by adding partial harvesting, gradual disturbances, and forest recovery from older events, making them useful approaches for obtaining the first remote sensing-based map for areas affected by the eastern spruce budworm.","2024-05-15","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","306","","","","","","","","","","English","","","","WOS:001218279000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;102</p>","","","ALGORITHM; Boreal forest; CANADA; CLASSIFICATION; CONVOLUTIONAL NEURAL-NETWORKS; Deep learning; Forest disturbances; Landsat time series; LANDTRENDR; OLD-GROWTH; Remote sensing; SPRUCE BUDWORM DEFOLIATION; Time series subsequence; Transformer; TREE MORTALITY; TRENDS; VALIDATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8BIX7TB9","journalArticle","2024","Lin, SF; Zhang, YY; Fei, XJ; Liu, XL; Mei, Q","ConvFormer-KDE: A Long-Term Point-Interval Prediction Framework for PM2.5 Based on Multi-Source Spatial and Temporal Data","TOXICS","","2305-6304","10.3390/toxics12080554","","Accurate long-term PM2.5 prediction is crucial for environmental management and public health. However, previous studies have mainly focused on short-term air quality point predictions, neglecting the importance of accurately predicting the long-term trends of PM2.5 and studying the uncertainty of PM2.5 concentration changes. The traditional approaches have limitations in capturing nonlinear relationships and complex dynamic patterns in time series, and they often overlook the credibility of prediction results in practical applications. Therefore, there is still much room for improvement in long-term prediction of PM2.5. This study proposes a novel long-term point and interval prediction framework for urban air quality based on multi-source spatial and temporal data, which further quantifies the uncertainty and volatility of the prediction based on the accurate PM2.5 point prediction. In this model, firstly, multi-source datasets from multiple monitoring stations are preprocessed. Subsequently, spatial clustering of stations based on POI data is performed to filter out strongly correlated stations, and feature selection is performed to eliminate redundant features. In this paper, the ConvFormer-KDE model is presented, whereby local patterns and short-term dependencies among multivariate variables are mined through a convolutional neural network (CNN), long-term dependencies among time-series data are extracted using the Transformer model, and a direct multi-output strategy is employed to realize the long-term point prediction of PM2.5 concentration. KDE is utilized to derive prediction intervals for PM2.5 concentration at confidence levels of 85%, 90%, and 95%, respectively, reflecting the uncertainty inherent in long-term trends of PM2.5. The performance of ConvFormer-KDE was compared with a list of advanced models. Experimental results showed that ConvFormer-KDE outperformed baseline models in long-term point- and interval-prediction tasks for PM2.5. The ConvFormer-KDE can provide a valuable early warning basis for future PM2.5 changes from the aspects of point and interval prediction.","2024-08","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","8","12","","","","","","","","","","English","","","","WOS:001308574100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","convolutional neural network; fine particulate matter; interval prediction; kernel density estimation; long-term point prediction; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IH5VNC2V","journalArticle","2023","Li, A; Han, JY; Zhao, YJ; Li, KY; Liu, L","Realistic Ultrasound Synthesis Based on Diagnostic CT to Facilitate Ultrasound-Guided Robotic Spine Surgery","IEEE TRANSACTIONS ON MEDICAL ROBOTICS AND BIONICS","","2576-3202","10.1109/TMRB.2023.3310201","","This paper aims to tackle the issues of unavailable or insufficient clinical ultrasound (US) data and meaningful annotations to enable bone segmentation and registration for US-guided spinal surgery. Although US-based spine surgery is being more widely utilized, the development of robot-assisted surgical navigation algorithms for this approach is still impeded by the limitation of insufficient training data. Moreover, due to the characteristics of US imaging, it is difficult to clearly annotate bone surfaces, which leads to a sub-optimal inference capacity of the trained model. Hence, we propose an in silico bone US simulation framework that synthesizes realistic US images from diagnostic computed tomography (CT) volumes. Afterward, using these simulated bone US images, we train a lightweight vision transformer model that can achieve accurate and on-the-fly bone segmentation for spinal sonography. In the validation experiments, a realistic US simulation is conducted by deriving from the diagnostic spinal CT volume to facilitate a radiation-free US-guided pedicle screw placement procedure. When the proposed approach is employed for training the bone segmentation task, the Chamfer distance reaches 0.599 mm; when it is applied to CT-US registration, the associated bone segmentation accuracy yields 0.93 Dice score, and the registration accuracy achieved based on the segmented point cloud reaches 0.13 similar to 3.37 mm in a complication-free manner. While bone US images exhibit strong echoes at the medium interface, the model may be unable to distinguish between thin interfaces and bone surfaces by simply relying on small neighborhood information. To overcome these shortcomings, we propose to utilize a long-range contrast learning module (LCLM) to fully explore the long-range differences between the candidates and their surrounding pixels. Comprehensive experiment results demonstrate that the proposed CT -> US simulation dramatically increases the US segmentation performance without any labeled US bone samples, and the proposed LCLM is effective at precisely determining the position of the US region of interest (RoI) on bones.","2023-11","2025-02-26 20:43:32","2025-02-26 20:43:32","","879-889","","4","5","","","","","","","","","","English","","","","WOS:001105153800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","ABSORPTION; bone surface segmentation; CT-US registration; Realistic US simulation; SIMULATION; TISSUES; US-guided spinal navigation; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y36RB7RR","journalArticle","2023","Liao, JX; Hu, J; Yan, FW; Chen, P; Zhu, L; Zhou, Q; Xu, HM; Li, J","A comparative investigation of advanced machine learning methods for predicting transient emission characteristic of diesel engine","FUEL","","0016-2361","10.1016/j.fuel.2023.128767","","Machine learning method provides a promising way to predict the transient emission characteristic of diesel engine due to its many advantages such as short computation time, low consuming, high prediction accuracy and good robustness. In this paper, seven machine learning methods were discussed in detail and compared with each other, including ANN, SVM, NARX, LSTM, GRU, Transformer and TCN, to find the most suitable machine learning method applied to the transient emission characteristic prediction of diesel engine. Each machine learning model was trained, validated, and tested based on WHTC and WHSC cycles and the R2, MAE and RMSE were used as evaluation metrics. In addition, the correlation between input parameters and emission charac-teristic parameters was analyzed based on Pearson and Spearman correlation analysis methods, and the top six important parameters were considered as model inputs. The hyperparameters of each model were optimized by GA and PSO algorithms to identify optimal model structure. The results showed that there was no machine learning method that can show excellent overall performance in all emission characteristic prediction. In the NOx prediction, GRU and TCN models performed the best overall performance. The optimal method for CO and CO2 was TCN and LSTM, respectively. Transformer model had relatively better overall performance in the THC prediction although its prediction curve showed oscillation. If the system configured for the machine learning model has sufficient computing power, more complex NARX or GRU models are recommended for exhaust temperature prediction. Otherwise, TCN model is chosen if the computing power is relatively limited while some prediction performance is sacrificed. In particular, SVM model with simplest structure showed best overall performance in the exhaust pressure prediction. Finally, inspired by Ensemble Learning methods, a hybrid prediction model, combining the best algorithms corresponding to each emission characteristic parameter, was proposed to have best performance in all emission characteristic prediction.","2023-10-15","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","350","","","","","","","","","","English","","","","WOS:001014502500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;20<br/>Total Times Cited:&nbsp;&nbsp;20<br/>Cited Reference Count:&nbsp;&nbsp;77</p>","","","COMBUSTION; DESIGN; Diesel engine; Emission characteristic prediction; EXHAUST EMISSIONS; FILTER; Hyperparameter optimization; Machine learning; MODEL; NEURAL-NETWORK; NOX EMISSIONS; OPTIMIZATION; PERFORMANCE; SUPPORT VECTOR MACHINE; Variable importance analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FL87BS6U","journalArticle","2024","Fang, K; Wang, JL; Chen, QF; Feng, X; Qu, YM; Shi, JC; Xu, ZM","Swin-cryoEM: Multi-class cryo-electron micrographs single particle mixed detection method","PLOS ONE","","1932-6203","10.1371/journal.pone.0298287","","Cryo-electron micrograph images have various characteristics such as varying sizes, shapes, and distribution densities of individual particles, severe background noise, high levels of impurities, irregular shapes, blurred edges, and similar color to the background. How to demonstrate good adaptability in the field of image vision by picking up single particles from multiple types of cryo-electron micrographs is currently a challenge in the field of cryo-electron micrographs. This paper combines the characteristics of the MixUp hybrid enhancement algorithm, enhances the image feature information in the pre-processing stage, builds a feature perception network based on the channel self-attention mechanism in the forward network of the Swin Transformer model network, achieving adaptive adjustment of self-attention mechanism between different single particles, increasing the network's tolerance to noise, Incorporating PReLU activation function to enhance information exchange between pixel blocks of different single particles, and combining the Cross-Entropy function with the softmax function to construct a classification network based on Swin Transformer suitable for cryo-electron micrograph single particle detection model (Swin-cryoEM), achieving mixed detection of multiple types of single particles. Swin-cryoEM algorithm can better solve the problem of good adaptability in picking single particles of many types of cryo-electron micrographs, improve the accuracy and generalization ability of the single particle picking method, and provide high-quality data support for the three-dimensional reconstruction of a single particle. In this paper, ablation experiments and comparison experiments were designed to evaluate and compare Swin-cryoEM algorithms in detail and comprehensively on multiple datasets. The Average Precision is an important evaluation index of the evaluation model, and the optimal Average Precision reached 95.5% in the training stage Swin-cryoEM, and the single particle picking performance was also superior in the prediction stage. This model inherits the advantages of the Swin Transformer detection model and is superior to mainstream models such as Faster R-CNN and YOLOv5 in terms of the single particle detection capability of cryo-electron micrographs.","2024-04-09","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","4","19","","","","","","","","","","English","","","","WOS:001234927600053","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"82INJ26E","journalArticle","2024","Ma, PF; Wu, ZR; Zhang, ZJ; Au, FTK","SAR-Transformer-based decomposition and geophysical interpretation of InSAR time-series deformations for the Hong Kong-Zhuhai-Macao Bridge","REMOTE SENSING OF ENVIRONMENT","","0034-4257","10.1016/j.rse.2023.113962","","Time-series interferometric synthetic aperture radar (InSAR) provides a unique tool for measuring large-scale and long-term land surface deformation. Under the assumption of a single linear deformation model in conventional InSAR, it is difficult to quantify and interpret the impacts of multiple environmental factors that presumably induce nonlinear deformations. In this paper, we propose a SAR-Transformer method to decompose InSAR time-series signals into various physics-related components and apply the method to evaluate the deformation of the world's longest cross-sea bridge, the Hong Kong-Zhuhai-Macao Bridge (HZMB). We first developed an improved bridge geometry-based InSAR network to monitor the deformation of the HZMB using Sentinel-1 and COSMO-SkyMed images from 2019 to 2022, which were validated using the leveling and GPS data. The SAR-Transformer model was trained using synthetic InSAR time-series samples and applied to decompose the monitored InSAR measurements. Compared with that of conventional curve-fitting and seasonal-trend decomposition using LOESS, SAR-Transformer reduced the mean absolute error at least by 58.32% and mean absolute percentage error at least by 8.84% for time-series signal reconstruction. We evaluated the decomposed patterns according to the geotechnical, meteorological, and marine processes, and found that: 1) Seasonal thermal expansion owing to temperature changes was significant in all parts of the bridge, and deflection due to concrete shrinkage and creep was observed on cable-stayed bridges. 2) The artificial islands experienced evident ground subsidence with a decelerating trend. In particular, the newly adopted non-dredged reclamation method resulted in a lower decelerated settlement than that of fully-dredged reclamation areas. 3) The seawall showed linear horizontal movement from the outward stretching of the reclaimed soil consolidation and periodic displacement related to sea tidal loading. Furthermore, typhoons and coastal earthquakes had limited effects on the permanent movement of the bridge. These results improve the understanding of the interactions between artificial super-infrastructures and environmental factors, and provide valuable guidelines for the maintenance and management of the HZMB.","2024-03-01","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","302","","","","","","","","","","English","","","","WOS:001165647600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;22<br/>Total Times Cited:&nbsp;&nbsp;22<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Cross-sea bridge; InSAR time-series signals; INTERFEROMETRY; PERSISTENT; Reclamation; SAR-transformer; Tidal loading","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4FA66MTN","journalArticle","2022","Chen, JQ; Luo, T; Wu, JH; Wang, ZK; Zhang, HD","A Vision Transformer network SeedViT for classification of maize seeds","JOURNAL OF FOOD PROCESS ENGINEERING","","0145-8876","10.1111/jfpe.13998","","Maize is a crop that is widely cultivated all over the world. Thus, the classification of maize seeds quality is important, while the traditional methods based on the texture, shape, and color which require repeated work is not efficient. Recently, deep learning reached the goal in the field of image processing, and a deep convolutional neural network (DCNN) is often used to do the image classification task. Here, we explored another neural network called Vision Transformer (ViT), which originally was applied to the natural language processing. Based on the self-attention mechanism, ViT discards the convolutional structure. But when trained from scratch on medium-sized datasets, ViT performed poorly compared to CNN. Due to the lack of local structure within the input image, tokenization cannot be used to generate a valid training set in the original ViT model. As a result, we proposed an improved ViT model SeedViT. Compared with the original ViT which could only train large datasets, SeedViT can train small and medium datasets to achieve SOTA (State of the Art) in vision classification with only 2,500 images in our study. The feasibility of SeedViT to classify maize seeds' quality was studied in this article, and we compared it with DCNN and traditional machine learning algorithms. The accuracy, sensitivity, specificity, and precision were 97.6%, 94.1%, 98.9%, and 97%, respectively. In addition, we employed ViT and VGG (Visual Geometry Group, a convolutional neural network) to extract image features, and SVM (support vector machine) was used as the classifier to classify them, with the result that ViT-SVM was stable around 96.6% on the test set and VGG-SVM was stable around 94.6%. At last, a visual attention map was generated by visualization technology. It showed that SeedViT can be a new and novel way for maize seed manufacturing. Practical applications An algorithm for classifying and sorting out high-quality maize seeds. Use the Transformer algorithm from the field of natural language processing instead of the convolutional neural network algorithm. Use GeLU function for activation and soft split with images to improve Vision Transformer model so that it can achieve great performance with small and medium datasets.","2022-05","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","5","45","","","","","","","","","","English","","","","WOS:000766838900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","AGRICULTURE; DEEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FSP6KI73","journalArticle","2024","Kumi, S; Snow, C; Lomotey, RK; Deters, R","Uncovering Concerns of Citizens Through Machine Learning and Social Network Sentiment Analysis","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3426329","","Artificial Intelligence and Machine Learning (AI/ML) as analytical tools can be applied across multiple social domains. Thus, these tools are being deployed in several ways to address societal issues and concerns for ""social good"". For instance, AI/ML has applicable use cases for crisis response, economic empowerment, educational demands, environmental challenges, equality and inclusion, health and hunger, and security and justice. In this work, we seek to explore the power and capability of AI/ML in understanding citizens' engagement, which can improve governance and smart city deployment. Specifically, we studied the views expressed by online users about the city of Saskatoon in Canada. The analyzed views have become a value chain that community leaders can use to improve the governance structure of the city. In the study, we extracted 114,390 comments from Reddit (i.e., Saskatoon subreddit posts) between January 1, 2019, and September 20, 2023, to discover topics to highlight citizens' concerns. We compare the performance of three major topic models, namely, Latent Dirichlet Allocation (LDA), Non-negative Matrix Factorization (NMF), and BERTopic with a K-means clustering algorithm in the discovery of topics from the collected Reddit comments. The BERTopic with the K-means clustering algorithm achieved the highest coherence score of approximately 0.64 in the extraction of 25 topics from the dataset. Our findings showed that BERTopic can discover coherent and diverse topics compared to LDA and NMF. We found 12 underlying themes by merging related topics. Also, we leveraged SiEBERT (a pre-trained transformer model), 4 supervised ML models, and VADER (a lexical sentiment analysis classifier) to identify the sentiments expressed in each theme. The SiEBERT model outperformed the other sentiment classifiers with an accuracy of 89% in the prediction of sentiments. The research discovered factors for smart city engagement such as Housing and Facilities, Education, Downtown Development, Tourism and Entertainment, Policing, Healthcare, Online Community, and Cost.","2024","2025-02-26 20:43:32","2025-02-26 20:43:32","","94885-94913","","","12","","","","","","","","","","English","","","","WOS:001272176800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Analytical models; citizens engagement; COVID-19; Data mining; Machine learning; MEDIA; Resource management; Smart cities; smart city; social media; Social networking (online); Support vector machines; Text mining; textual mining; Urban areas; VACCINE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"77TZ5BQL","journalArticle","2023","Zhu, JS; Lacroix, R; Wade, KM","Automated extraction of domain knowledge in the dairy industry","COMPUTERS AND ELECTRONICS IN AGRICULTURE","","0168-1699","10.1016/j.compag.2023.108330","","Three weeks prior to calving to three weeks after calving, the transition period poses challenges for dairy cattle and farmers. Vast changes in housing, feeding, and reproduction might result in milk drop, metabolic and reproductive diseases. Moreover, most of the metabolic processes are intricately linked as many conditions can coexist. This challenge means that dairy producers and their advisors have difficulty drawing concise conclusions because of all aspects and relationships in transition cow management. Herein, machine-learning techniques and knowledge-graph theory were explored with a view to creating a decision-support system that could provide producers and their advisors with knowledge from domain literature. Specifically, knowledge is modelled as entities and relationships in knowledge graph theory, and natural language models were developed to extract information as knowledge graphs. A dataset comprising 1152 sentences from 20 papers was created and split into 922 sentences for training and 230 sentences for testing. Sequentially, two deep learning models were trained to extract entities and relationships respectively. For training results, a Bi-directional Long-Short-Term Memory model was applied for the entity extraction task and obtained an F1 score of 80 %. As for relationship extraction, a Transformer-based model was deployed but yielded a low F1 of 23 %, thus another pre-trained Transformer model with 89 % accuracy was deployed into the system. After feeding the domain literature into the deep -learning models, a knowledge graph of 1,576 nodes and 3,456 edges was constructed and stored in the graph database Neo4j. Afterward, a semantic parsing method was used to allow users to conduct question answering through the knowledge graph in natural language. In addition, to determine the quality of answers that the knowledge built from the papers, answers were sampled and evaluated based on human judgment. On average, answers scored 7.5 out of 10 and proved informative with respect to the original literature. Although the final interactive results demonstrated a high degree of visualization and scalability, this study primarily sought to demonstrate its feasibility. For tailored commercial applications, further improvements could be implemented in knowledge graph expansion and reasoning.","2023-11","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","214","","","","","","","","","","English","","","","WOS:001102423500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","Deep learning; Knowledge base; Knowledge graph; MILK; Question answering; Transition cows","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GJ887JV5","journalArticle","2023","He, YC; Wu, JJ; Wang, WY; Jiang, B; Zhang, YX","AstroYOLO: A hybrid CNN-Transformer deep-learning object-detection model for blue horizontal-branch stars","PUBLICATIONS OF THE ASTRONOMICAL SOCIETY OF JAPAN","","0004-6264","10.1093/pasj/psad071","","Blue horizontal-branch stars (BHBs) are ideal tracers for studying the Milky Way (MW) due to their bright and nearly constant magnitude. However, an incomplete screen of BHBs from a survey would result in bias of estimation of the structure or mass of the MW. With surveys of large sky telescopes like the Sloan Digital Sky Survey (SDSS), it is possible to obtain a complete sample. Thus, detecting BHBs from massive photometric images quickly and effectually is necessary. The current acquisition methods of BHBs are mainly based on manual or semi-automatic modes. Therefore, novel approaches are required to replace manual or traditional machine-learning detection. The mainstream deep-learning-based object-detection methods are often vanilla convolutional neural networks whose ability to extract global features is limited by the receptive field of the convolution operator. Recently, a new Transformer-based method has benefited from the global receptive field advantage brought by the self-attention mechanism, exceeded the vanilla convolution model in many tasks, and achieved excellent results. Therefore, this paper proposes a hybrid convolution and Transformer model called AstroYOLO to take advantage of the convolution in local feature representation and Transformer's easier discovery of long-distance feature dependences. We conduct a comparative experiment on the 4799 SDSS DR16 photometric image dataset. The experimental results show that our model achieves 99.25% AP@50, 93.79% AP@75, and 64.45% AP@95 on the test dataset, outperforming the YOLOv3 and YOLOv4 object-detection models. In addition, we test on larger cutout images based on the same resolution. Our model can reach 99.02% AP@50, 92.00% AP@75, and 61.96% AP@95 respectively, still better than YOLOv3 and YOLOv4. These results also suggest that an appropriate size for cutout images is necessary for the performance and computation of object detection. Compared with the previous models, our model has achieved satisfactory object-detection results and can effectively improve the accuracy of BHB detection.","2023-12-09","2025-02-26 20:43:32","2025-02-26 20:43:32","","1311-1323","","6","75","","","","","","","","","","English","","","","WOS:001091299000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","AGE; CATALOG; CLASSIFICATION; DIGITAL SKY SURVEY; FIELD STARS; GRADIENT; KPC; MASS; methods: data analysis; MILKY-WAY; SDSS; stars: horizontal-branch; surveys","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5DRSIN6Q","journalArticle","2022","Olenskyj, AG; Sams, BS; Fei, ZH; Singh, V; Raja, P; Bornhorst, GM; Earles, JM","End-to-end deep learning for directly estimating grape yield from ground-based imagery","COMPUTERS AND ELECTRONICS IN AGRICULTURE","","0168-1699","10.1016/j.compag.2022.107081","","Yield estimation prior to harvest is a powerful tool in vineyard management, as it allows growers to fine-tune management practices to optimize yield and quality. However, yield estimation is currently performed using manual sampling, which is time-consuming and imprecise. This study demonstrates the applicability of nondestructive proximal imaging combined with deep learning for yield estimation in vineyards. Continuous image data collection using a vehicle-mounted sensing kit combined with collection of ground truth yield data at harvest using a commercial yield monitor allowed for the generation of a large dataset of 23,581 yield points and 107,933 images. Moreover, this study was conducted in a commercial vineyard which was mechanically managed, representing a challenging environment for image analysis but a common set of conditions in the California Central Valley. Three model architectures were tested: object detection, CNN regression, and transformer models. The object detection model was trained on hand-labeled images to localize grape bunches, and detections were either counted or their pixel count was summed to obtain a metric which was correlated to grape yield. Conversely, regression models were trained end-to-end to directly predict grape yield from image data without the need for hand labeling. Results demonstrated that both a transformer model as well as the object detection model with pixel area processing performed comparably, with a mean absolute percent error of 18% and 18.5%, respectively on a representative holdout dataset. Saliency mapping was used to demonstrate the attention of the CNN regression model was localized near the predicted location of grape bunches, as well as on the top of the grapevine canopy. Overall, the study demonstrated the applicability of proximal imaging and deep learning for prediction of grapevine yield on a large scale. Additionally, the end-to-end modeling approach was able to perform comparably to the object detection approach while eliminating the need for hand-labeling.","2022-07","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","198","","","","","","","","","","English","","","","WOS:000818610900003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;18<br/>Total Times Cited:&nbsp;&nbsp;20<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Deep learning; Deep regression; FRUIT; NEURAL-NETWORKS; PREDICTION; Proximal sensing; STAGE; SYSTEMS; Vineyard variability; Yield estimation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TILXH73M","journalArticle","2024","Lv, JM; Zhu, DY; Geng, Z; Han, SL; Wang, Y; Ye, Z; Zhou, T; Chen, HR; Huang, JW","Recognition for SAR deformation military target from a new MiniSAR dataset using multi-view joint transformer approach","ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING","","0924-2716","10.1016/j.isprsjprs.2024.03.009","","Accurately detecting ground armored weapons is crucial for achieving initiative advantages in military operations. Generally, satellite or airborne synthetic aperture radar (SAR) systems face limitations due to their revisit cycles and fixed flight trajectories, resulting in single -view imaging of targets, thereby hampering the recognition of small SAR ground targets. In contrast, MiniSAR possesses the capability to capture the multi -view of a target by acquiring images from different azimuth angles. In this research, our team utilizes a selfdeveloped MiniSAR system to generate multi -view SAR images of real ground armored targets and recognize targets. However, the recognition of small targets in SAR images encounters two significant difficulties. First, small targets in SAR images are prone to interference from background noise. Second, SAR target deformation arises from variations in depression angles and imaging processes. To tackle these difficulties, this paper proposes a novel SAR ground deformation target recognition approach based on a joint multi -view transformer model. The method first preprocesses SAR images based on a low -frequency priori SAR image denoising method. Next, it obtains multi -view joint information through a self -attentive mechanism, inputs joint features to the transformer structure. The outputs are jointly updated by a multi -way averaging adaptive loss function to improve the recognition accuracy of deformed targets. The experimental results demonstrate the superiority of the proposed method in SAR ground deformation target recognition, outperforming other representative approaches such as information fusion of target and shadow (IFTS) and Vision Transformer (ViT). It is concluded that the proposed method has high recognition accuracies of 98.37% and 93.86 % on the moving and stationary target acquisition and recognition (Mstar) and our SAR images dataset, respectively, in the field of SAR ground deformation target recognition. We have included links to the code and data in the abstract of this paper for ease of access. The source code and sample dataset are available at https://github.com/Lvjiming/MJT.","2024-04","2025-02-26 20:43:32","2025-02-26 20:43:32","","180-197","","","210","","","","","","","","","","English","","","","WOS:001222440100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","APERTURE RADAR IMAGERY; CLASSIFICATION; Cross attention mechanism; DEEP; Denoising with low-frequency prior; information (LFPD); MiniSAR; MODEL; Recognition of deformation targets; Transformer network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VKK23MH3","journalArticle","2024","Li, T; Feng, LX","Coordinated development of rural ecological construction and carbon neutrality: a deep learning approach for enhanced sustainability","FRONTIERS IN ECOLOGY AND EVOLUTION","","2296-701X","10.3389/fevo.2023.1267259","","Introduction In recent years, the world has faced increasingly severe climate change and ecological environmental problems. As an important part of the ecological system, rural areas also face many challenges. Rural ecological construction and carbon neutrality, as a solution, have attracted widespread attention. However, achieving the coordinated development of rural ecological construction and carbon neutrality requires more in-depth research and effective methods.Methods This study aims to explore how to promote the coordinated development of rural ecological construction and carbon neutrality through the combination of a Transformer-RNN model and cross-attention mechanism. We propose a deep learning framework that combines the parallelism and global dependency capturing capabilities of the Transformer model with the temporal information handling capabilities of the RNN model. By integrating these two models, we leverage their respective strengths to improve the performance of the model. Furthermore, we introduce a cross-attention mechanism that enables the model to simultaneously focus on the relationship between rural ecological construction and carbon neutrality. Through cross-attention, the model accurately captures the impact of rural ecological construction measures on carbon neutrality and the feedback effect of carbon neutrality on the rural ecological environment. In our experiments, we collected relevant data on rural ecological construction and carbon neutrality, including environmental indicators, socio-economic factors, land use patterns, energy consumption, and carbon emissions.Results and discussion We preprocess the data and train the combined Transformer-RNN model with the cross-attention mechanism. The trained model demonstrates promising results in capturing the complex dependencies and relationships between rural ecological construction and carbon neutrality. The significance of this study lies in deepening the understanding of the coordinated development relationship between rural ecological construction and carbon neutrality and providing a novel deep learning-based method to solve related problems. By introducing the Transformer-RNN model with a cross-attention mechanism, we provide decision-makers with more scientific and accurate decision support, promoting the improvement of the rural ecological environment and the achievement of carbon neutrality goals.","2024-01-29","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","11","","","","","","","","","","English","","","","WOS:001160143300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","carbon neutrality; CHINA; cross attention mechanism; FOOTPRINT; RNN; rural ecological construction; Swin Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8XLERVPH","journalArticle","2024","Xu, ZH; Zhao, YQ; Yin, ZX; Yu, QP","Optimized BottleNet Transformer model with Graph Sampling and Counterfactual Attention for cow individual identification","COMPUTERS AND ELECTRONICS IN AGRICULTURE","","0168-1699","10.1016/j.compag.2024.108703","","In modern dairy farms, accurate and reliable identification of each individual cow is of great significance for precision livestock farming. Individual cow identification is the basis for applications such as disease detection, automatic behaviour analysis, intelligent milking, and individual counting and is crucial for improving the welfare and breeding efficiency of dairy cows. Computer vision-based method is a low-cost, non-contact, automatic, and efficient way. To improve the accuracy and efficiency of cow recognition in different largescale dairy farms, we proposed a BottleNet Transformer (BoTNet) model based on Graph Sampling and Counterfactual Attention Learning for cow surveillance videos. First, we replace the 3 x 3 spatial convolution with Multi-Head Attention in the final three bottleneck blocks of the ResNet. The BoT block module combines attention mechanisms and residual connection to enhance the global representation of cow images, which in turn better captures the features of the cow's back pattern region and ignores the influence of irrelevant information, such as the background of the dairy barn. Subsequently, counterfactual learning measures the quality of attention by comparing the difference between the generated output and the true label. The difference can be used to enhance the causal relationship between prediction results and cow feature attention, allowing the model to obtain more comprehensive cow appearance features. Finally, we added a Graph Sampling module before the feature extraction phase to produce small batches of samples for training. The GS sampler improves the learning efficiency while reducing the memory and computation consumption compared with the usual adopted PK sampling. We conducted comparison experiments on the public dataset Dataset1, and the experimental results reveal that the Rank-1, Rank-5, and mAP values of this study's method are 4%, 3.2%, and 5.3% higher than the optimal results, respectively, when compared with the existing state-of-the-art methods for animal individual recognition. In particular, we construct a challenging dataset by intercepting individual cow images from videos in the public dataset of farms. Experimental results indicate that the proposed method has better generalization performance.","2024-03","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","218","","","","","","","","","","English","","","","WOS:001181785700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Counterfactual attention learning; Deep learning; EAR TAGS; Graph sampling; Individual cow identification; Precision livestock","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RKHQLR85","journalArticle","2025","Joshi, D; Pradhan, S; Sajeed, R; Srinivasan, R; Rana, S","An augmented transformer model trained on protein family specific variant data leads to improved prediction of variants of uncertain significance","HUMAN GENETICS","","0340-6717","10.1007/s00439-025-02727-z","","Variants of uncertain significance (VUS) represent variants that lack sufficient evidence to be confidently associated with a disease, thus posing a challenge in the interpretation of genetic testing results. Here we report an improved method for predicting the VUS of Arylsulfatase A (ARSA) gene as part of the Critical Assessment of Genome Interpretation challenge (CAGI6). Our method uses a transfer learning approach that leverages a pre-trained protein language model to predict the impact of mutations on the activity of the ARSA enzyme, whose deficiency is known to cause a rare genetic disorder, metachromatic leukodystrophy. Our innovative framework combines zero-shot log odds scores and embeddings from the ESM, an evolutionary scale model as features for training a supervised model on gene variants functionally related to the ARSA gene. The zero-shot log odds score feature captures the generic properties of the proteins learned due to its pre-training on millions of sequences in the UniProt data, while the ESM embeddings for the proteins in the ARSA family capture features specific to the family. We also tested our approach on another enzyme, N-acetyl-glucosaminidase (NAGLU), that belongs to the same superfamily as ARSA. Our results demonstrate that the performance of our family models (augmented ESM models) is either comparable or better than the ESM models. The ARSA model compares favorably with the majority of state-of-the-art predictors on area under precision and recall curve (AUPRC) performance metric. However, the NAGLU model outperforms all pathogenicity predictors evaluated in this study on AUPRC metric. The improved AUPRC has relevance in a diagnostic setting where variant prioritization generally entails identifying a small number of pathogenic variants from a larger number of benign variants. Our results also indicate that genes that have sparse or no experimental variant impact data, the family variant data can serve as a proxy training data for making accurate predictions. Attention analysis of active sites and binding sites in ARSA and NAGLU proteins shed light on probable mechanisms of pathogenicity for positions that are highly attended.","2025-01-27","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","","","","","","","","","","","English","","","","WOS:001406574300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","SANFILIPPO-SYNDROME; SEQUENCE; STABILITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I9SLHZBY","journalArticle","2024","Han, HM; Aboubakar, BO; Bhatti, M; Talpur, BA; Ali, YA; Al-Razgan, M; Ghadi, YY","Optimizing image captioning: The effectiveness of vision transformers and VGG networks for remote sensing","BIG DATA RESEARCH","","2214-5796","10.1016/j.bdr.2024.100477","","This study presents a comprehensive evaluation of two prominent deep learning models, Vision Transformer (ViT) and VGG16, within the domain of image captioning for remote sensing data. By leveraging the BLEU score, a widely accepted metric for assessing the quality of text generated by machine learning models against a set of reference captions, this research aims to dissect and understand the capabilities and performance nuances of these models across various sample sizes: 25, 50, 75, and 100 samples. Our findings reveal that the Vision Transformer model generally outperforms the VGG16 model across all evaluated sample sizes, achieving its peak performance at 50 samples with a BLEU score of 0.5507. This performance shows that ViT benefits from its ability to capture global dependencies within the data, providing a more nuanced understanding of the images. However, the performance slightly decreases as the sample size increases beyond 50, indicating potential challenges in scalability or overfitting to the training data. Conversely, the VGG16 model shows a different performance trajectory, starting with a lower BLEU score for smaller sample sizes but demonstrating a consistent improvement as the sample size increases, culminating in its highest BLEU score of 0.4783 for 100 samples. This pattern suggests that VGG16 may require a larger dataset to adequately learn and generalize from the data, although it achieves a more modest performance ceiling compared to ViT. Through a detailed analysis of these findings, the study underscores the strengths and limitations of each model in the context of image captioning. The Vision Transformer's superior performance highlights its potential for applications requiring high accuracy in text generation from images. In contrast, the gradual improvement exhibited by VGG16 suggests its utility in scenarios where large datasets are available, and scalability is a priority. This study contributes to the ongoing discourse in the AI community regarding the selection and optimization of deep learning models for complex tasks such as image captioning, offering insights that could guide future research and application development in this field.","2024-08-28","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","37","","","","","","","","","","English","","","","WOS:001260415700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","Caption generation; CHALLENGES; Remote sensing image captioning; VGG16; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y87RK525","journalArticle","2024","Song, YC; Wang, JC; Ge, YF; Li, LF; Guo, J; Dong, QX; Liao, ZF","Medical image classification: Knowledge transfer via residual U-Net and vision transformer-based teacher-student model with knowledge distillation","JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION","","1047-3203","10.1016/j.jvcir.2024.104212","","With the widespread integration of deep learning techniques in the domain of medical image analysis, there is a prevailing consensus regarding their efficacy in handling high -dimensional and intricate medical image data. However, it is imperative to acknowledge that while complex deep models exhibit a remarkable capacity for processing high -dimensional and intricate data, they often necessitate a substantial allocation of computational resources and time. Furthermore, lightweight models, despite their computational efficiency, tend to underperform when compared to their more intricate counterparts in terms of performance. Hence, the prevailing aspiration is to transfer the cognitive prowess of complex models to their lightweight counterparts. Addressing the aforementioned concern, this study proposes a knowledge distillation approach that encompasses joint feature and soft label transfer. It entails the transference of knowledge from the teacher model's intermediate features and predictive outcomes to the student model. The student model leverages this knowledge to emulate the behavior of the teacher model, thereby enhancing the precision of its own predictions. Building upon this foundation, we introduce a Res -Transformer teacher model based on the U -Net architecture and a student model known as ResU-Net, which is grounded in residual modules. The Res -Transformer teacher model employs multilayer residual attention during the downsampling process to capture deep -level features of the image. Subsequently, we have incorporated a Multi -layer Perceptual Attention module (MPA) for each skip connection layer, facilitating the integration of hierarchical upsampled information to restore fine-grained details within the feature maps. The ResU-Net student model enhances network stability through the utilization of residual modules and optimizes skip connections to recover any lost image information during convolutional operations. Lastly, we conducted experimental assessments on multiple disease datasets. The results reveal that the ACC of the Res -Transformer model achieves an impressive 96.9%. Furthermore, through the knowledge distillation method, rich knowledge is effectively transferred to the ResU-Net model, resulting in a remarkable ACC improvement of 7.2%.","2024-06","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","102","","","","","","","","","","English","","","","WOS:001260003100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Attention; Knowledge distillation; Medical imaging; Residual module; SEGMENTATION; U -Net; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4DKLUVEZ","journalArticle","2024","Aghamohammadesmaeilketabforoosh, K; Nikan, S; Antonini, G; Pearce, JM","Optimizing Strawberry Disease and Quality Detection with Vision Transformers and Attention-Based Convolutional Neural Networks","FOODS","","2304-8158","10.3390/foods13121869","","Machine learning and computer vision have proven to be valuable tools for farmers to streamline their resource utilization to lead to more sustainable and efficient agricultural production. These techniques have been applied to strawberry cultivation in the past with limited success. To build on this past work, in this study, two separate sets of strawberry images, along with their associated diseases, were collected and subjected to resizing and augmentation. Subsequently, a combined dataset consisting of nine classes was utilized to fine-tune three distinct pretrained models: vision transformer (ViT), MobileNetV2, and ResNet18. To address the imbalanced class distribution in the dataset, each class was assigned weights to ensure nearly equal impact during the training process. To enhance the outcomes, new images were generated by removing backgrounds, reducing noise, and flipping them. The performances of ViT, MobileNetV2, and ResNet18 were compared after being selected. Customization specific to the task was applied to all three algorithms, and their performances were assessed. Throughout this experiment, none of the layers were frozen, ensuring all layers remained active during training. Attention heads were incorporated into the first five and last five layers of MobileNetV2 and ResNet18, while the architecture of ViT was modified. The results indicated accuracy factors of 98.4%, 98.1%, and 97.9% for ViT, MobileNetV2, and ResNet18, respectively. Despite the data being imbalanced, the precision, which indicates the proportion of correctly identified positive instances among all predicted positive instances, approached nearly 99% with the ViT. MobileNetV2 and ResNet18 demonstrated similar results. Overall, the analysis revealed that the vision transformer model exhibited superior performance in strawberry ripeness and disease classification. The inclusion of attention heads in the early layers of ResNet18 and MobileNet18, along with the inherent attention mechanism in ViT, improved the accuracy of image identification. These findings offer the potential for farmers to enhance strawberry cultivation through passive camera monitoring alone, promoting the health and well-being of the population.","2024-06","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","12","13","","","","","","","","","","English","","","","WOS:001256527700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","computer vision; image classification; machine learning; MobileNetV2; monitoring; ResNet18; strawberries; vision transformers; yield monitoring","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EAALIFWE","journalArticle","2024","Zhao, LT; Bao, J; Wang, XM; Qiao, XM; Shen, JK; Zhang, YY; Jin, PF; Ji, YT; Zhang, J; Su, YT; Ji, LB; Li, ZK; Lu, J; Hu, CH; Shen, HL; Tian, J; Liu, JG","Detecting Adverse Pathology of Prostate Cancer With a Deep Learning Approach Based on a 3D Swin-Transformer Model and Biparametric MRI: A Multicenter Retrospective Study","JOURNAL OF MAGNETIC RESONANCE IMAGING","","1053-1807","10.1002/jmri.28963","","Background: Accurately detecting adverse pathology (AP) presence in prostate cancer patients is important for personalized clinical decision-making. Radiologists' assessment based on clinical characteristics showed poor performance for detecting AP presence. Purpose: To develop deep learning models for detecting AP presence, and to compare the performance of these models with those of a clinical model (CM) and radiologists' interpretation (RI). Study Type: Retrospective. Population: Totally, 616 men from six institutions who underwent radical prostatectomy, were divided into a training cohort (508 patients from five institutions) and an external validation cohort (108 patients from one institution). Field Strength/Sequences: T2-weighted imaging with a turbo spin echo sequence and diffusion-weighted imaging with a single-shot echo plane-imaging sequence at 3.0 T. Assessment: The reference standard for AP was histopathological extracapsular extension, seminal vesicle invasion, or positive surgical margins. A deep learning model based on the Swin-Transformer network (TransNet) was developed for detecting AP. An integrated model was also developed, which combined TransNet signature with clinical characteristics (TransCL). The clinical characteristics included biopsy Gleason grade group, Prostate Imaging Reporting and Data System scores, prostate-specific antigen, ADC value, and the lesion maximum cross-sectional diameter. Statistical Tests: Model and radiologists' performance were assessed using area under the receiver operating characteristic curve (AUC), sensitivity, and specificity. The Delong test was used to evaluate difference in AUC. P < 0.05 was considered significant. Results: The AUC of TransCL for detecting AP presence was 0.813 (95% CI, 0.726-0.882), which was higher than that of TransNet (0.791 [95% CI, 0.702-0.863], P = 0.429), and significantly higher than those of CM (0.749 [95% CI, 0.656-0.827]) and RI (0.664 [95% CI, 0.566-0.752]). Data Conclusion: TransNet and TransCL have potential to aid in detecting the presence of AP and some single adverse pathologic features.","2024-06","2025-02-26 20:43:32","2025-02-26 20:43:32","","2101-2112","","6","59","","","","","","","","","","English","","","","WOS:001052196900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","adverse pathology; ARTIFICIAL-INTELLIGENCE; deep learning; DIAGNOSIS; EXTRACAPSULAR EXTENSION; IMPACT; MULTIPARAMETRIC MRI; PREDICTION; prostate cancer; RADIOMICS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J3DMQI7A","journalArticle","2024","Wang, X; Zhang, JH; Wang, XP; Wu, ZJ; Prodhan, FA","Incorporating Multi-Temporal Remote Sensing and a Pixel-Based Deep Learning Classification Algorithm to Map Multiple-Crop Cultivated Areas","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14093545","","The accurate monitoring of crop areas is essential for food security and agriculture, but accurately extracting multiple-crop distribution over large areas remains challenging. To solve the above issue, in this study, the Pixel-based One-dimensional convolutional neural network (PB-Conv1D) and Pixel-based Bi-directional Long Short-Term Memory (PB-BiLSTM) were proposed to identify multiple-crop cultivated areas using time-series NaE (a combination of NDVI and EVI) as input for generating a baseline classification. Two approaches, Snapshot and Stochastic weighted averaging (SWA), were used in the base-model to minimize the loss function and improve model accuracy. Using an ensemble algorithm consisting of five PB-Conv1D and seven PB-BiLSTM models, the temporal vegetation index information in the base-model was comprehensively exploited for multiple-crop classification and produced the Pixel-Based Conv1D and BiLSTM Ensemble model (PB-CB), and this was compared with the PB-Transformer model to validate the effectiveness of the proposed method. The multiple-crop cultivated area was extracted from 2005, 2010, 2015, and 2020 in North China by using the PB-Conv1D combine Snapshot (PB-CDST) and PB-CB models, which are a performance-optimized single model and an integrated model, respectively. The results showed that the mapping results of the multiple-crop cultivated area derived by PB-CDST (OA: 81.36%) and PB-BiLSTM combined with Snapshot (PB-BMST) (OA: 79.40%) showed exceptional accuracy compared to PB-Transformer combined with Snapshot and SWA (PB-TRSTSA) (OA: 77.91%). Meanwhile, the PB-CB (OA: 83.43%) had the most accuracy compared to the pixel-based single algorithm. The MODIS-derived PB-CB method accurately identified multiple-crop areas for wheat, corn, and rice, showing a strong correlation with statistical data, exceeding 0.7 at the municipal level and 0.6 at the county level.","2024-05","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","9","14","","","","","","","","","","English","","","","WOS:001219793800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","deep learning; DERIVE; ensemble classifier; INDEX; LAND-COVER DATABASE; multi-temporal data; multiple-crop classification; PHENOLOGY; PRODUCT; remote sensing; SAR; snapshot; SWA; TIME-SERIES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S3S2H8NT","journalArticle","2024","Zhang, SY; Yu, MZ","Enhanced urban PM2.5 prediction: Applying quadtree division and time-series transformer with WRF-chem","ATMOSPHERIC ENVIRONMENT","","1352-2310","10.1016/j.atmosenv.2024.120758","","Accurately predicting air quality levels in urban landscapes is a key environmental and public health challenge due to the complex interactions between pollutant emissions, atmospheric chemistry, and meteorological conditions. Chemical transport models such as Community Multiscale Air Quality (CMAQ) and Weather Research and Forecasting Modeling with Chemistry (WRF-Chem) provide fundamental insights into the behavior of atmospheric pollutants but face limitations in spatial resolution and prediction accuracy. Machine learning combined with low-cost sensors can improve prediction accuracy compared to numerical models, but uneven sensor distribution may result in biased prediction results. To address these limitations, this study introduces an innovative framework that leverages a quadtree space division to refine the numerical simulations of air pollutants into higher spatial resolutions by dynamically adjusting grid sizes based on the distribution of increased sensor deployments. Using a variable-resolution grid, the study first aggregates variables into a grid and then calculates spatial dependence based on grid cells. The deep-learning-based Time Series Transformer model is then used to perform detailed temporal predictions of PM 2.5 concentration across the entire grid. The spatial and temporal modeling framework is designed to use the past 48 h' aggregated data, including meteorological variables from WRF-Chem numerical simulation and PM 2.5 concentrations from ground monitoring stations and sensors, to predict future 48-h' PM 2.5 concentrations and tested across entire grids within Los Angeles County from January to June 2020. The results show that the performance of variable resolution grids is better than that of fixed grids regarding four metrics: minimum resolution, overall spatiotemporal RMSE, average bias, and prediction coverage. Among them, the variable resolution grids with up to 4 sensors showed the best performance, with an overall spatiotemporal RMSE of 1.12 mu g/m3 , 3 , which was about 40% lower than 2-sensor and 8sensor variable resolution grids, a significant reduction of 55% compared to a 3 km fixed grid configuration. Future work will involve additional relevant factors such as emission sources and sinks to improve prediction accuracy.","2024-11-15","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","337","","","","","","","","","","English","","","","WOS:001301102400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Air pollution; MODEL; PM2.5; RESOLUTION; Timeseries prediction; Transformer neural network; Variable resolution grids","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2CMZXBTP","journalArticle","2024","Jahan, M; Hasan, MZ; Samia, IJ; Fatema, K; Rony, MAH; Arefin, MS; Moustafa, A","KOA-CCTNet: An Enhanced Knee Osteoarthritis Grade Assessment Framework Using Modified Compact Convolutional Transformer Model","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3435572","","Knee osteoarthritis (KOA) is a prevalent condition characterized by gradual progression, resulting in observable bone alterations in X-ray images. X-rays are the preferred diagnostic tool for their ease of use and cost-effectiveness. Physicians use the Kellgren and Lawrence (KL) grading system to understand the severity of an individual condition of KOA. This system categorizes the disease from normal to a severe stage. Early detection of the condition with this approach enables knee deterioration to be slowed down with therapy. In this study, we aggregated four datasets to generate an extensive dataset comprising 110,232 raw images by applying an augmentation technique called deep convolutional generative adversarial network (DCGAN). We employed advanced image pre-processing methods (adaptive histogram equalization (AHE), fast non-local means), including image resizing, to generate a substantial dataset and enhance image quality. Our proposed approach involved developing a modified compact convolutional transformer (CCT) model known as KOA-CCTNet as the foundational model. We further investigated optimal configurations by adjusting various parameters and hyperparameters in the final model to handle large datasets and address training time concerns efficiently. We investigated optimizing its configurations by adjusting numerous parameters and hyperparameters to efficiently manage extensive data and address concerns related to training time. Simulation results indicated that our proposed model outperforms other transfer learning models (Swin Transformer, Vision Transformer, Involutional Neural Network) in terms of accuracy. The test accuracy for the ResNet50, MobileNetv2, DenseNet201, InceptionV3, and VGG16 was 80.77%, 79.98%, 80.23%, 76.89%, and 79.58%, respectively. All of them were surpassed by our proposed KOA-CCTNet model, which had a test accuracy of 94.58% while classifying KOA X-ray images. Furthermore, we reduced the number of images to assess the model's performance and compared it to existing models. However, by employing a large datahub, our proposed approach provides a unique and effective way to diagnose KOA grades with satisfying results.","2024","2025-02-26 20:43:32","2025-02-26 20:43:32","","107719-107741","","","12","","","","","","","","","","English","","","","WOS:001288415500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","Accuracy; compact convolutional transformer; Computational modeling; Convolutional neural networks; deep convolutional generative adversarial network (DCGAN); Generative adversarial networks; image pre-processing; Knee osteoarthritis; knee osteoarthritis grades; Knee replacement; knee X-ray; Osteoarthritis; Training; X-ray imaging","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SDPNZZYH","journalArticle","2021","Prystupczuk, F; Rigoni, V; Nouri, A; Ali, R; Keane, A; O'Donnell, T","Hybrid Power Electronic Transformer Model for System-Level Benefits Quantification in Energy Distribution Systems","FRONTIERS IN ELECTRONICS","","2673-5857","10.3389/felec.2021.716448","","The Hybrid Power Electronic Transformer (HPET) has been proposed as an efficient and economical solution to some of the problems caused by Distributed Energy Resources and new types of loads in existing AC distribution systems. Despite this, the HPET has some limitations on the control it can exert due to its fractionally-rated Power Electronic Converter. Various HPET topologies with different capabilities have been proposed, being necessary to investigate the system benefits that they might provide in possible future scenarios. Adequate HPET models are needed in order to conduct such system-level studies, which are still not covered in the current literature. Consequently, this article presents a methodology to develop power flow models of HPET that facilitate the quantification of controllability requirements for voltage, active power and reactive power. A particular HPET topology composed of a three-phase three-winding Low-Frequency Transformer coupled with a Back-to-Back converter is modeled as an example. The losses in the Back-to-Back converter are represented through efficiency curves that are assigned individually to the two modules. The model performance is illustrated through various power flow simulations that independently quantify voltage regulation and reactive power compensation capabilities for different power ratings of the Power Electronic Converter. In addition, a set of daily simulations were conducted with the HPET supplying a real distribution network modeled in OpenDSS. The results show the HPET losses to be around 1.3 times higher than the conventional transformer losses over the course of the day. The proposed methodology offers enough flexibility to investigate different HPET features, such as power ratings of the Power Electronic Converter, losses, and various strategies for the controlled variables. The contribution of this work is to provide a useful tool that can not only assess and quantify some of the system-level benefits that the HPET can provide, but also allow a network-tailored design of HPETs. The presented model along with the simulation platform were made publicly available.","2021-09-14","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","2","","","","","","","","","","English","","","","WOS:001115676900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","energy distribution systems; hybrid transformer; IMPACT; inverter losses; power electronic transformer; power factor; power flow simulation; SOLID-STATE TRANSFORMERS; transformer losses","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CVLRUWVQ","journalArticle","2023","Chuchupal, VY; Makovkin, KA","Development of Speech Technologies at Trunin-Donskoy's School: From Sound Recognition to Natural Speech Recognition","PATTERN RECOGNITION AND IMAGE ANALYSIS","","1054-6618","10.1134/S1054661823040120","","The team of the speech recognition sector of the Computing Center of the Russian Academy of Sciences has participated in the development of speech technologies since their appearance in the Soviet Union in the 1960s. During this time, several generations of researchers have carried out research in this field. Accordingly, the approaches to solve problems of speech recognition have repeatedly undergone fundamental changes: the methods based on the recognition of individual sounds and parts of words using sets of rules obtained by expert means have given place to the methods of recognition and semantic interpretation of natural continuous speech based on mathematical models trained on large data sets. The review of the results begins with a description of the approach to building speech recognition systems, which was proposed by the head of the sector V.N. Trunin-Donskoy. The hardware-software approach has long been the ""calling card"" of the team and played a significant role in popularizing speech recognition and realizing the benefits of developing speech technologies in the Soviet Union. Solutions based on a combination of software and specialized hardware are now standard, but were new at that time. The development of the area, the complication of problems associated with the transition to discrete speech recognition with large dictionaries have resulted in the replacement of recognition methods based on the use of systems of expert rules with methods based on classical optimization algorithms, which were proposed and improved by the staff and graduate students of the team. Understanding the importance of the tasks of collecting, classifying, and annotating representative arrays of speech data was a feature of research at the Computing Center of the USSR Academy of Sciences. The work of the team members was significantly ahead of not only domestic but also modern foreign research in this area. A relevant area of applied work in the 1970s-1980s was the use of modern methods of digital speech processing, the creation of problem-oriented tools and language means that made it possible to simulate in real time the operation of components of speech recognition and signal processing systems, and in particular, interactive methods for filtering speech signals. The consistent increase in computing power and data corpus volumes has made it possible to move to the use of probabilistic speech modeling technologies, as well as the formulation and solution of natural speech recognition problems. Methods have been worked out and data corpuses and software systems have been developed for recognizing spontaneous speech, separating voices, determining gender, identifying key words in a speech stream, and classifying the subject of a speech message. Recent studies are related to the development of computationally efficient neural network methods and models for speech recognition and processing, which are intended for use in mobile devices.","2023-12","2025-02-26 20:43:32","2025-02-26 20:43:32","","888-901","","4","33","","","","","","","","","","English","","","","WOS:001187820900005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","automatic speech recognition; expert methods of speech recognition; hardware-software approach to speech recognition; neural networks; Valerian Nikolaevich Trunin-Donskoy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W4QCY8LH","journalArticle","2023","Toledano, L; Friedmann, N","Letter Migrations between Words in Reading Aloud Can Result either from an Impairment in Orthographic Input or in Phonological Output","BRAIN SCIENCES","","2076-3425","10.3390/brainsci13040588","","Letter migrations between words in reading aloud (e.g., reading ""cane love"" as ""lane love"" or ""lane cove"") are known to result from a deficit in the visual-orthographic analysis and characterize attentional dyslexia. In spontaneous speech, individuals with impairment in the phonological output buffer may show migrations of phonemes between words. The purpose of this study was to examine whether migrations between words in reading aloud can also result from a deficit in the phonological output buffer, to explore the characteristics of migrations resulting from orthographic input and from phonological output deficits, and to examine methods to distinguish these two sources. Using tasks of reading aloud of lists of 92-182 word pairs, we identified 18 adults and adolescents with developmental dyslexia who made between-word letter migrations in reading aloud, significantly more than age-matched controls (372 adults, 26 7th-graders and 44 4th-5th-graders). To distinguish between the orthographic input and phonological output sources for these migrations, we administered a test assessing orthographic input without spoken output (written semantic decision on 140 migratable word pairs) and a repetition test of 36 auditorily presented migratable word pairs, assessing spoken output without orthographic input (as well as nonword repetition and 3 span tests). These tests indicated that the migrations in reading aloud of 10 of the participants with dyslexia resulted from an orthographic input deficit-they made migrations not only in reading aloud but also in written word pair comprehension, but not in word pair repetition. For the other 8 participants, the migrations resulted from a phonological output deficit: they made migrations in reading aloud and in word pair repetition, but not in comprehension, and had limited spans and made errors in nonword repetition. We identified several differences between the two types of between-word errors: first, the individuals with attentional dyslexia made omissions of a letter that appeared in the same position in the two words, but the phonological output buffer group did not make such omissions. Second, the groups differed in the origin of migration: orthographic input migrations involve letters that are orthographically adjacent, whereas phonological output migrations involve phonologically adjacent phonemes: phonemes that have just been spoken or that are prepared together in the phonological buffer for production. Migrations from the line below and from 2 lines above the target occurred only in the orthographic input group. This study thus indicates that between-word migrations in reading aloud can result not only from attentional dyslexia, but also from a phonological output buffer deficit, and offers ways to distinguish between the two.","2023-04","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","4","13","","","","","","","","","","English","","","","WOS:000979336400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;96</p>","","","attentional dyslexia; ATTENTIONAL DYSLEXIA; DEFICIT; developmental dyslexia; DEVELOPMENTAL SURFACE DYSLEXIA; ERRORS; Hebrew; INDIVIDUAL-DIFFERENCES; LEXICAL ACCESS; migrations between words; NEGLECT DYSLEXIA; orthographic-visual analyzer; phonological output buffer; reading; SHORT-TERM-MEMORY; SPEECH PRODUCTION; TIME COURSE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6UIBQVR5","journalArticle","2021","Ramos, VM; Paulyn, C; Van den Steen, L; Huici, MEHD; De Bodt, M; Van Nuffelen, G","Effect of boost articulation therapy (BArT) on intelligibility in adults with dysarthria","INTERNATIONAL JOURNAL OF LANGUAGE & COMMUNICATION DISORDERS","","1368-2822","10.1111/1460-6984.12595","","Background The articulatory accuracy of patients with dysarthria is one of the most affected speech dimensions with a high impact on speech intelligibility. Behavioural treatments of articulation can either involve direct or indirect approaches. The latter have been thoroughly investigated and are generally appreciated for their almost immediate effects on articulation and intelligibility. The number of studies on (short-term) direct articulation therapy is limited. Aims To investigate the effects of short-term, boost articulation therapy (BArT) on speech intelligibility in patients with chronic or progressive dysarthria and the effect of severity of dysarthria on the outcome. Methods & Procedures The study consists of a two-group pre-/post-test design to assess speech intelligibility at phoneme and sentence level and during spontaneous speech, automatic speech and reading a phonetically balanced text. A total of 17 subjects with mild to severe dysarthria participated in the study and were randomly assigned to either a patient-tailored, intensive articulatory drill programme or an intensive minimal pair training. Both training programmes were based on the principles of motor learning. Each training programme consisted of five sessions of 45 min completed within one week. Outcomes & Results Following treatment, a statistically significant increase of mean group intelligibility was shown at phoneme and sentence level, and in automatic sequences. This was supported by an acoustic analysis that revealed a reduction in formant centralization ratio. Within specific groups of severity, large and moderate positive effect sizes with Cohen's d were demonstrated. Conclusions & Implications BArT successfully improves speech intelligibility in patients with chronic or progressive dysarthria at different levels of the impairment. What this paper adds What this paper adds to existing knowledgeWhat is already known on the subject What are the potential or actual clinical implications of this work? Behavioural treatment of articulation in patients with dysarthria mainly involves indirect strategies, which have shown positive effects on speech intelligibility. However, there is limited evidence on the short-term effects of direct articulation therapy at the segmental level of speech. This study investigates the effectiveness of BArT on speech intelligibility in patients with chronic or progressive dysarthria at all severity levels. The intensive and direct articulatory therapy programmes developed and applied in this study intend to reduce the impairment instead of compensating it. This approach results in a significant improvement of speech intelligibility at different dysarthria severity levels in a short period of time while contributing to exploit and develop all available residual motor skills in persons with dysarthria. The improvements in intelligibility demonstrate the effectiveness of a BArT at the segmental level of speech. This makes it to be considered a suitable approach in the treatment of patients with chronic or progressive dysarthria.","2021-03","2025-02-26 20:43:32","2025-02-26 20:43:32","","271-282","","2","56","","","","","","","","","","English","","","","WOS:000610428600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","ATAXIC DYSARTHRIA; dysarthria; INDIVIDUALS; intelligibility; INTENSIVE VOICE TREATMENT; NEURAL PLASTICITY; PARKINSON-DISEASE; POSTSTROKE DYSARTHRIA; segmental articulation therapy; SPEAKERS; SPEECH RATE; TREATMENT LSVT; VOWEL ARTICULATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9HAC2DXB","journalArticle","2021","Zhang, XY; Yu, WY; Teng, WJ; Lu, MY; Wu, XL; Yang, YQ; Chen, C; Liu, LX; Liu, SH; Li, JJ","Effectiveness of Melodic Intonation Therapy in Chinese Mandarin on Non-fluent Aphasia in Patients After Stroke: A Randomized Control Trial","FRONTIERS IN NEUROSCIENCE","","1662-453X","10.3389/fnins.2021.648724","","Melodic intonation therapy (MIT) positively impacts the speech function of patients suffering from aphasia and strokes. Fixed-pitch melodies and phrases formulated in MIT provide the key to the target language to open the language pathway. This randomized controlled trial compared the effects of music therapy-based MIT and speech therapy on patients with non-fluent aphasia. The former is more effective in the recovery of language function in patients with aphasia. Forty-two participants were enrolled in the study, and 40 patients were registered. The participants were randomly assigned to two groups: the intervention group (n = 20; 16 males, 4 females; 52.90 +/- 9.08 years), which received MIT, and the control group (n = 20; 15 males, 5 females; 54.05 +/- 10.81 years), which received speech therapy. The intervention group received MIT treatment for 30 min/day, five times a week for 8 weeks, and the control group received identical sessions of speech therapy for 30 min/day, five times a week for 8 weeks. Each participant of the group was assessed by a Boston Diagnostic Aphasia Examination (BDAE) at the baseline (t1, before the start of the experiment), and after 8 weeks (t2, the experiment was finished). The Hamilton Anxiety Scale (HAMA) and Hamilton Depression Scale (HAMD) were also measured on the time points. The best medical care of the two groups is the same. Two-way ANOVA analysis of variance was used only for data detection. In the spontaneous speech (information), the listening comprehension (right or wrong, word recognition, and sequential order) and repetitions of the intervention group were significantly higher than the control group in terms of the cumulative effect of time and the difference between groups after 8 weeks. The intervention group has a significant time effect in fluency, but the results after 8 weeks were not significantly different from those in the control group. In terms of naming, the intervention group was much better than the control group in spontaneous naming. Regarding object naming, reaction naming, and sentence completing, the intervention group showed a strong time accumulation effect. Still, the results after 8 weeks were not significantly different from those in the control group. These results indicate that, compared with speech therapy, MIT based on music therapy is a more effective musical activity and is effective and valuable for the recovery of speech function in patients with non-fluent aphasia. As a more professional non-traumatic treatment method, MIT conducted by qualified music therapists requires deeper cooperation between doctors and music therapists to improve rehabilitating patients with aphasia. The Ethics Committee of the China Rehabilitation Research Center approved this study (Approval No. 2020-013-1 on April 1, 2020) and was registered with the Chinese Clinical Trial Registry (Registration number: Clinical Trials ChiCTR2000037871) on September 3, 2020.","2021-07-23","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","15","","","","","","","","","","English","","","","WOS:000681764900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Chinese Mandarin; melodic intonation therapy; music therapy; non-fluent aphasia; stroke","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"696HGIE7","journalArticle","2022","Pawelec, LP; Graja, K; Lipowicz, A","Vocal Indicators of Size, Shape and Body Composition in Polish Men","JOURNAL OF VOICE","","0892-1997","10.1016/j.jvoice.2020.09.011","","The Summary: Objectives. From a human evolution perspective, identifying a link between physique and vocal quality could demonstrate dual signaling in terms of the health and biological condition of an individual. In this regard, this study investigates the relationship between men's body size, shape, and composition, and their vocal characteristics. Materials and Methods. Eleven anthropometric measurements, using seven indices, were carried out with 80 adult Polish male participants, while the speech analysis adopted a voice recording procedure that involved phonetically recording vowels /alphaMODIFIER LETTER TRIANGULAR COLON/, /eMODIFIER LETTER TRIANGULAR COLON/, /iMODIFIER LETTER TRIANGULAR COLON/, /LATIN SMALL LETTER OPEN OMODIFIER LETTER TRIANGULAR COLON /, /uMODIFIER LETTER TRIANGULAR COLON/ to define the voice acoustic components used in Praat software. Results. The relationship between voice parameters and body size/shape/composition was found. The analysis indicated that the formants and their derivatives were useful parameters for prediction of height, weight, neck, shoulder, waist, and hip circumferences. Fundamental frequency (F0) was negatively correlated with neck circum-ference at Adam's apple level and body height. Moreover neck circumference and F0 association was observed for the first time in this paper. The association between waist circumference and formant component showed a net effect. In addition, the formant parameters showed significant correlations with body shape, indicating a lower vocal timbre in men with a larger relative waist circumference. Discussion. Men with lower vocal pitch had wider necks, probably a result of larynx size. Furthermore, a greater waist circumference, presumably resulting from abdominal fat distribution in men, correlated with a lower vocal timbre. While these results are inconclusive, they highlight new directions for further research.","2022-11","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","6","36","","","","","","","","","","English","","","","WOS:000905460900003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;104</p>","","","ACOUSTIC PARAMETERS; Formant dispersion; FORMANT FREQUENCIES; Fundamental frequency; FUNDAMENTAL-FREQUENCY; HORMONE-RECEPTORS; Jitter; MASS INDEX; MUSCLE STRENGTH; Shimmer; STEROID-RECEPTORS; TESTOSTERONE LEVELS; Vocal tract; VOICE PARAMETERS; WEIGHT-LOSS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IF22Z5H7","journalArticle","2024","Sun, YS; Chu, WQ; Zhou, H; Wang, KSY; Koike, H","AVI-Talking: Learning Audio-Visual Instructions for Expressive 3D Talking Face Generation","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3390182","","While considerable progress has been made in achieving accurate lip synchronization for 3D speech-driven talking face generation, the task of incorporating expressive facial detail synthesis aligned with the speaker's speaking status remains challenging. Existing efforts either focus on learning a dynamic talking head pose synchronized with speech rhythm or aim for stylized facial movements guided by external reference such as emotional labels or reference video clips. The former works often yield coarse alignment, neglecting the emotional nuances present in the audio content while the latter studies lead to unnatural applications, requiring manual style source selection by users. Our goal is to directly leverage the inherent style information conveyed by human speech for generating an expressive talking face that aligns with the speaking status. In this paper, we propose AVI-Talking, an Audio-Visual Instruction system for expressive Talking face generation. This system harnesses the robust contextual reasoning and hallucination capability offered by Large Language Models (LLMs) to instruct the realistic synthesis of 3D talking faces. Instead of directly learning facial movements from human speech, our two-stage strategy involves the LLMs first comprehending audio information and generating instructions implying expressive facial details seamlessly corresponding to the speech. Subsequently, a diffusion-based generative network executes these instructions. This two-stage process, coupled with the incorporation of LLMs, enhances model interpretability and provides users with flexibility to comprehend instructions and specify desired operations or modifications. Specifically, given a speech clip, we first employ a Q-Former for contrastive alignment the speech features with visual instructions, which is then projected to input text embedding of LLMs. It functions as a prompting strategy, prompting LLMs to generate plausible visual instructions that encompass diverse facial details. In order to use these predicted instructions, a language-guided talking face generation system with disentangled latent space is delicately derived, where the speech content related lip movements and emotion correlated facial expressions are separately represented in speech content space and content irrelevant space. Additionally, we introduce a contrastive instruction-style alignment and diffusion technique within the content-irrelevant space to fully exploit the talking prior network for diverse instruction-following synthesis. Extensive experiments showcase the effectiveness of our approach in producing vivid talking faces with expressive facial movements and consistent emotional status.","2024","2025-02-26 20:43:32","2025-02-26 20:43:32","","57288-57301","","","12","","","","","","","","","","English","","","","WOS:001208900400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;81</p>","","","audio-visual instruction; contrastive learning; diffusion model; expressive talking face generation; Large language models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MFJBGR9N","journalArticle","2024","Rao, PVLN; Meher, S","ORG-RGRU: An automated diagnosed model for multiple diseases by heuristically based optimized deep learning using speech/voice signal","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2023.105493","","Human ailments create an impact in altering the significant metabolism activities of the body irrespective of various parts. Dysarthric speech is commonly known as Parkinson's disease (PD), where most of people suffer from voice impairment. Moreover, the voice analysis could help the clinicians to detect the disease effectively. Since it affects with neurological activities, the existing models are though render better results, but it cannot be able to meet up the desired outcomes. While diagnosing the disease by the clinicians, the abnormality variations in the voice signal become complicated. Due to the occurrence of unwanted interpretations, it affects the quality of the speech/voice signal. In order to meet this prerequisite, a novel diagnosing method is proposed. The proposed model implements the three-stage classification framework termed as Optimized ResNet and GoogleNet and Radial basis function-Gated Recurrent Unit (ORG-RGRU). The signals are garnered and decomposed using Empirical Wavelet Transform (EWT). The decomposed signal is given to classification in three different ways. Firstly, the decomposed signal is fed into Short-Time Fourier transform (STFT) features that are given into ORGRGRU, which yields one classified output. Secondly, the relevant features are retrieved by adopting MelFrequency Cepstral Coefficients (MFCC), Cepstral and Spectral features, principle speech features, and pitch features (zero frequency response filter). Then, the weighted features are obtained with the optimal weight by the Adaptive Controlling Parameters-based African Vultures Optimization Algorithm (ACP-AVOA). Thus, the optimal features are fed into the Optimized Radial basis function-Gated Recurrent Unit (ORGRU) to exhibit the second classified outcome. Thirdly, the extracted STFT features are given into ResNet and GoogleNet, where the deep features are attained that are given to ORGRU. In order to return the optimal value, the hyper parameters in ResNet, GoogleNet, RBF and GRU are tuned optimally by ACP-AVOA. The high ranking is taken for determining the final classified results. The validation takes place among the developed model and existing conventional approaches. The main finding of the developed model shows 95% and 91% regarding accuracy and Matthews Correlation Coefficient (MCC).","2024-02","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","88","","","","","","","","","","English","","","","WOS:001097141900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Adaptive controlling parameters-based African vultures optimization algorithm; basis function-gated recurrent unit; Empirical wavelet transform; Multiple disease diagnosis; Optimized radial basis function-gated recurrent unit; Optimized ResNet and GoogleNet and radial; PARKINSONS-DISEASE; Three Stage Classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZLRV6FYS","journalArticle","2021","Roohani, A; Etemadfar, P","Effect of Micro Flipped Method on EFL Learners' Speaking Fluency","JOURNAL OF ASIA TEFL","","1738-3102","10.18823/asiatefl.2021.18.2.11.559","","This study investigated the effect of the micro flipped method on English as a foreign language (EFL) learners' speaking fluency and compared its effect with the traditional face-to-face teacher-fronted method in the EFL context of Iran. To this end, 40 intermediate-level EFL learners in a language institute were selected through a placement test and were assigned to experimental and control groups. The control group (non-flipped classroom) was exposed to in-class activities and instructional materials in the print format whereas the experimental group (micro flipped classroom) was exposed to both in-class and out-of-class instructional materials, including mini videos uploaded before class via Edmodo, a technology-based pedagogical environment. To assess the participants' speaking fluency, they were interviewed at the beginning and end of their course, and the recorded speech data were analyzed through PRAAT (computer software package for speech analysis) in terms of six aspects of speaking fluency, including articulation rate (syllables per second), rate of all pauses, rate of long pauses, rate of unfilled and filled pauses and mean length of run. The analysis of the data through Mann-Whitney tests revealed statistically significant differences regarding the measures of fluency with the higher articulate rate and mean length of run and lower rates of pauses for the experimental group in the posttest interview. The findings accentuate the role of the flipped classroom and blended learning where second/foreign language (L2) leaners can develop their L2 speaking skills and fluency in online and actual settings.","2021","2025-02-26 20:43:32","2025-02-26 20:43:32","","559-575","","2","18","","","","","","","","","","English","","","","WOS:000672809700011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","CLASSROOM; Edmodo; ENGLISH; FILLED PAUSES; L2 FLUENCY; L2 learners; micro flipped teaching; PERCEPTIONS; PERFORMANCE; speaking fluency; STUDENTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DVDWJZDE","journalArticle","2023","Zeghari, R; Gindt, M; König, A; Nachon, O; Lindsay, H; Robert, P; Fernandez, A; Askenazy, F","Study protocol: how does parental stress measured by clinical scales and voice acoustic stress markers predict children's response to PTSD trauma-focused therapies?","BMJ OPEN","","2044-6055","10.1136/bmjopen-2022-068026","","IntroductionPost-traumatic stress disorder (PTSD) symptoms in youth are influenced by parental anxiety and stress. When parents have high levels of stress or have developed PTSD themselves, children tend to show more anxiety symptoms. Parental stress can affect the severity of children's PTSD and lower the success of recovery. However, the influence of parental stress on the effectiveness of trauma-focused therapies (eye movement desensitisation and reprocessing and cognitive behavioural therapy) has not yet been investigated to our knowledge. Hence, we will measure parental stress (using both validated scales and vocal acoustic markers) and investigate how it influences children's PTSD recovery.Method and analysisSixty children between the ages of 7 and 15 years who experienced type 1 trauma will be recruited at the Nice Pediatric Psychotrauma Center in France. We plan to measure stress using two different approaches. We will ask parents to answer validated scales of stress and mood in general. Stress will also be measured using vocal acoustic markers. Parents will be recorded while narrating their child's trauma and during the narrative of a positive and neutral recall of events. Child participants will have to complete anxiety, PTSD and depression scales before the beginning of the trauma-focused therapy and after 3 months of treatment.Linear mixed effects models and differential statistics, such as significance testing corrected for multiple testing, will be used to determine the validity of speech features for the proposed hypotheses. Repeated measures analysis of variance will be performed on the clinical scales scores according to parental stress. Correlations will be performed between clinical scales of parents and children according to time of assessment.Ethics and disseminationThis study was approved by the Committee for the Protection of Individuals of the University of Nice Sophia Antipolis (CERNI) on 21 February 2022, under the number CER2022-015.All participants will be informed that this is an observational study and their consent taken prior to the experiment. Participants will be informed that they can withdraw from the study at any time and that it would not affect the care provided.","2023-05","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","5","13","","","","","","","","","","English","","","","WOS:001001381400031","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","ADOLESCENTS; ANXIETY; Anxiety disorders; Child & adolescent psychiatry; COGNITIVE-BEHAVIORAL THERAPY; DEPRESSION; DISORDER; Information technology; RISK-FACTORS; SAMPLE; SPEECH; SYMPTOMS; UPDATE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7KR6HMQG","journalArticle","2023","Kavaz, E; Puig, A; Rodríguez, I; Chacón, R; De-la-Paz, D; Torralba, A; Nofre, M; Taule, M","Visualisation of hierarchical multivariate data: Categorisation and case study on hate speech","INFORMATION VISUALIZATION","","1473-8716","10.1177/14738716221120509","","Multivariate hierarchical data has an important role in many applications. To find the best visualisation that best fits a concrete data is crucial to explore and understand the relationships between the data. This paper proposes a categorisation - Elongated and Compact - of hierarchical data based on the inner shapes of the hierarchies, that is the connectivity degree of the internal nodes, the number of nodes, etc, that can be applied to any hierarchical data. Based on this taxonomy, we explore implicit and explicit layouts - Tree, Circle Packing, Force and Radial - to provide users with a complete view of the data. We hypothesise that Tree and Circle Packing fit with Elongated structures, and Force and Radial fit with Compact ones. In addition, we cluster multivariate features to embed them in the hierarchical layouts. Especially, we propose two different glyphs -one-by-one and all-in-one, and we bet for the one-by-one glyphs as the most suitable for showing the distribution of several features along with the hierarchical structures. To validate our hypotheses, we conducted a user study with 35 participants using a hate speech annotated corpus. This corpus comes from 4359 comments posted in online Spanish newspapers. The results indicated that users preferred the Tree layout over the other three layouts (Circle, Force, Radial) with both types of structures (EC and CC). However, when we focused the analysis only on Radial and Force layouts, both of them scored significantly higher with Compact than with Elongated data. Moreover, participants scored the one-by-one glyph higher than the all-in-one glyph, but the difference was not significant.","2023-01","2025-02-26 20:43:32","2025-02-26 20:43:32","","31-51","","1","22","","","","","","","","","","English","","","","WOS:000849421000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","DISPLAYS; EXPLORATION; hate speech analysis; Hierarchical visualisations; multivariate data; OF-THE-ART; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6HC8GSJG","journalArticle","2021","Campbell, EL; Mesía, RY; Docío-Fernández, L; García-Mateo, C","Paralinguistic and linguistic fluency features for Alzheimer's disease detection","COMPUTER SPEECH AND LANGUAGE","","0885-2308","10.1016/j.csl.2021.101198","","Alzheimer's disease (AD) is one of the most common forms of dementia in the world. The Mini-Mental State Examination, a tool developed to detect AD, is composed of various tests that evaluate functional performance in several fields, one of which is language. Several symptoms are manifested in voices as a result of language and speech problems caused by AD, including frequent involuntary pauses during conversations and diction and vocabulary difficulties. Speech fluency is considered a key feature for AD detection in this research, for which two algorithms are proposed. The first algorithm is a paralinguistic system that is independent of the language and task and whose low-dimension feature vectors facilitate the training stage. This algorithm is tested on two databases (AcceXible and ADReSS), on two languages (Spanish and English) and on several tests. The second algorithm is based on analysing temporal patterns of silence between words and errors in spoken words. This approach, based on verbal fluency tests, is tested on the AcceXible database. To benchmark these algorithms, two baseline algorithms are used: the i-vector framework, a speaker modelling algorithm that has been effectively used for speech-related tasks such as speaker recognition, language identification, speaker diarization and speech-related health tasks; and a classic counting-terms algorithm, which processes transcriptions of speech. The paralinguistic system yields promising results for different tests and languages, while the silence-based system achieves high accuracy in verbal fluency tests. (C) 2021 Elsevier Ltd. All rights reserved.","2021-07","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","68","","","","","","","","","","English","","","","WOS:000629287300004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Cognitive impairment; DEMENTIA; DEPRESSION; IDENTIFICATION; MENTAL-STATE-EXAMINATION; Mini mental state exam; Paralinguistic and linguistic features; PROGRESSION; Silence analysis; SPEECH; Speech analysis; Verbal fluency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KUPBY329","journalArticle","2024","Thoret, E; Andrillon, T; Gauriau, C; Léger, D; Pressnitzer, D","Sleep deprivation detected by voice analysis","PLOS COMPUTATIONAL BIOLOGY","","1553-734X","10.1371/journal.pcbi.1011849","","Sleep deprivation has an ever-increasing impact on individuals and societies. Yet, to date, there is no quick and objective test for sleep deprivation. Here, we used automated acoustic analyses of the voice to detect sleep deprivation. Building on current machine-learning approaches, we focused on interpretability by introducing two novel ideas: the use of a fully generic auditory representation as input feature space, combined with an interpretation technique based on reverse correlation. The auditory representation consisted of a spectro-temporal modulation analysis derived from neurophysiology. The interpretation method aimed to reveal the regions of the auditory representation that supported the classifiers' decisions. Results showed that generic auditory features could be used to detect sleep deprivation successfully, with an accuracy comparable to state-of-the-art speech features. Furthermore, the interpretation revealed two distinct effects of sleep deprivation on the voice: changes in slow temporal modulations related to prosody and changes in spectral features related to voice quality. Importantly, the relative balance of the two effects varied widely across individuals, even though the amount of sleep deprivation was controlled, thus confirming the need to characterize sleep deprivation at the individual level. Moreover, while the prosody factor correlated with subjective sleepiness reports, the voice quality factor did not, consistent with the presence of both explicit and implicit consequences of sleep deprivation. Overall, the findings show that individual effects of sleep deprivation may be observed in vocal biomarkers. Future investigations correlating such markers with objective physiological measures of sleep deprivation could enable ""sleep stethoscopes"" for the cost-effective diagnosis of the individual effects of sleep deprivation. Sleep deprivation has an ever-increasing impact on individuals and societies, from accidents to chronic conditions costing billions to health systems. Yet, to date, there is no quick and objective test for sleep deprivation. We show that sleep deprivation can be detected at the individual level with voice recordings. Importantly, we focused on interpretability, which allowed us to identify two independent effects of sleep deprivation on the voice: changes in prosody and changes in voice quality or timbre. The results also revealed a striking variability in individual reactions to the same deprivation, further confirming the need to consider the effects of sleep deprivation at the individual level. Vocal markers could be correlated to specific underlying physiological factors in future studies, outlining possible cost-effective and non-invasive ""sleep stethoscopes"".","2024-02","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","2","20","","","","","","","","","","English","","","","WOS:001157660200004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","CONSEQUENCES; FRAMEWORK; WAKEFULNESS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M6Z9BQ9S","journalArticle","2024","Kim, M; Choi, J; Kim, D; Ro, YM","Textless Unit-to-Unit Training for Many-to-Many Multilingual Speech-to-Speech Translation","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2024.3444470","","This paper proposes a textless training method for many-to-many multilingual speech-to-speech translation that can also benefit the transfer of pre-trained knowledge to text-based systems, text-to-speech synthesis and text-to-speech translation. To this end, we represent multilingual speech with speech units that are the discretized representations of speech features derived from a self-supervised speech model. By treating the speech units as pseudo-text, we can focus on the linguistic content of the speech, which can be easily associated with both speech and text modalities at the phonetic level information. By setting both the inputs and outputs of our learning problem as speech units, we propose to train an encoder-decoder model in a many-to-many spoken language translation setting, namely Unit-to-Unit Translation (UTUT). Specifically, the encoder is conditioned on the source language token to correctly understand the input spoken language, while the decoder is conditioned on the target language token to generate the translated speech in the target language. Therefore, during the training, the model can build the knowledge of how languages are comprehended and how to relate them to different languages. Since speech units can be easily associated from both audio and text by quantization and phonemization respectively, the trained model can easily transferred to text-related tasks, even if it is trained in a textless manner. We demonstrate that the proposed UTUT model can be effectively utilized not only for Speech-to-Speech Translation (S2ST) but also for multilingual Text-to-Speech Synthesis (T2S) and Text-to-Speech Translation (T2ST), requiring only minimal fine-tuning steps on text inputs. By conducting comprehensive experiments encompassing various languages, we validate the efficacy of the proposed method across diverse multilingual tasks. Moreover, thanks to the many-to-many language training, we show that the UTUT can also perform language translations for novel language pairs that are not present during training as pairs, which has not well been explored in the previous literature.","2024","2025-02-26 20:43:32","2025-02-26 20:43:32","","3934-3946","","","32","","","","","","","","","","English","","","","WOS:001311205200002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;104</p>","","","Data models; MULTISPEAKER; Predictive models; Speech coding; Speech processing; Speech-to-speech translation (S2ST); Task analysis; Text to speech; text-to-speech synthesis (T2S); text-to-speech translation (S2ST); Training; TTS; unit-to-unit translation (UTUT)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2CDX39II","journalArticle","2024","Abdulghani, MM; Walters, WL; Abed, HK","Enhancing the Classification Accuracy of EEG-Informed Inner Speech Decoder Using Multi-Wavelet Feature and Support Vector Machine","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3474854","","Speech involves the synchronization of the brain and the oral articulators. Inner speech, also known as imagined speech or covert speech, refers to thinking in the form of sound without intentional movement of the lips, tongue, or hands. Decoding human thoughts is a powerful technique that can help individuals who have lost the ability to speak. This paper introduces a high-performance brain wave decoder based on inner speech, using a novel feature extraction method. The approach combined Support Vector Machine (SVM) and multi-wavelet feature extraction techniques to decode two EEG-based inner speech datasets (Data 1 and Data 2) into internally spoken words. The proposed approach achieved an overall classification accuracy of 68.20%, precision of 68.22%, recall of 68.20%, and F1-score of 68.21% for Data 1, and accuracy of 97.5%, precision of 97.73%, recall of 97.50%, and F1-score of 97.61% for Data 2. Additionally, the Area Under the Curve of the Receiver Operating Characteristic (AUC-ROC) demonstrated the validity of the proposed approach for classifying inner speech commands by achieving a macro-average of 78.76% and 99.32% for Data 1 and Data 2, respectively. The EEG-based inner speech classification method proposed in this research has the potential to improve communication for patients with speech disorders, mutism, cognitive development issues, executive function problems, and mental disorder.","2024","2025-02-26 20:43:32","2025-02-26 20:43:32","","147929-147941","","","12","","","","","","","","","","English","","","","WOS:001339059500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","Accuracy; AR; ARTIFACTS; autoregressive model; Autoregressive processes; Brain modeling; brain-computer interface; Brain-computer interfaces; Decoding; ECG; EEG; Electrodes; Electroencephalography; Entropy; Feature extraction; Headphones; imagined speech; Inner speech; POSITION; Recording; Shannon entropy; Speech analysis; support vector machine; Support vector machines; SVM; Visualization; wavelet variance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"STP3BRDU","journalArticle","2023","Rennie, SM; Prieur, L; Platt, M","Communication style drives emergent leadership attribution in virtual teams","FRONTIERS IN PSYCHOLOGY","","1664-1078","10.3389/fpsyg.2023.1095131","","Leader selection plays a key role in how human social groups are formed and maintained. Leadership is either assigned through formal processes within an organization, or emerges informally through interactions with other group members-particularly in novel contexts. COVID-19 has accelerated the adoption of virtual meetings and more flexible team structures. However our understanding of how assigned leadership influences subsequent leadership emergence in virtual settings is limited. Here we examine the relationship between assigned leadership within an existing organization and subsequent emergent leadership attributions as members engage in virtual interactions. To do so, we created and implemented a novel virtual group decision-making task designed to support quantification of a more comprehensive set of communication style elements, such as speech dynamics and facial expressions, as well as task behaviors. Sixteen members of a real world organization engaged four repeated rounds of a group decision making task with new team members each time. We found participants made novel attributions of emergent leadership rather than relying solely on existing assigned leadership. While assigned leadership did influence leadership attributions, communication style, including amount of speech but also variability in facial expressions, played a larger role. The behavior of these novel emergent leaders was also more consistent with expectations of leadership behavior: they spoke earlier, more often, and focused more on the correct decision than did assigned leaders. These findings suggest that, even within existing social networks, virtual contexts promote flexible group structures that depend more on communication style and task performance than assigned leadership.","2023-03-24","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","14","","","","","","","","","","English","","","","WOS:000963528500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;78</p>","","","EMOTION; EXPRESSIONS; FACE-TO-FACE; facial affect; FACIAL MIMICRY; group decision making; GROUP DECISION-MAKING; HIDDEN PROFILES; leadership selection; NEUROBIOLOGY; PERFORMANCE; speech analysis; synchrony; SYNCHRONY; UNSHARED INFORMATION; virtual teams","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NZVJGMKK","journalArticle","2025","Di Rauso, G; Cavallieri, F; Gessani, A; Fontanesi, D; Coniglio, S; Fioravanti, V; Contardi, S; Menozzi, E; Antonelli, F; Rispoli, V; Valzania, F; Budriesi, C","Speech profile in different clinical PSP phenotypes: an acoustic-perceptual study","NEUROLOGICAL SCIENCES","","1590-1874","10.1007/s10072-024-07833-w","","Progressive supranuclear palsy (PSP) is a neurodegenerative disease with pathological hallmarks and different clinical presentations. Recently, the Movement Disorder Society (MDS) promoted a new classification; specific combinations of the core clinical features identify different phenotypes, including PSP with Richardson's syndrome (PSP-RS) and PSP with predominant parkinsonism (PSP-P). Since speech disorders are very common in PSP, they were included in the MDS-PSP criteria as a supportive clinical feature in the form of hypokinetic, spastic dysarthria. However, little is known about how dysarthria presents across the different PSP variants. The aim of the present study is to evaluate the presence of differences in speech profile in a cohort of PSP-RS and PSP-P patients diagnosed according to the MDS-PSP criteria. Each patient underwent a neurological evaluation and perceptual and acoustic analysis of speech. Disease severity was rated using the Natural History and Neuroprotection in Parkinson plus syndromes-Parkinson plus scale (NNIPPS-PPS), including global score and sub-scores. Twenty-five patients (mean disease duration [standard deviation] = 3.32 [1.79]) were classified as PSP-RS, while sixteen as PSP-P (mean disease duration [standard deviation] = 3.47 [2.00]). These subgroups had homogeneous demographical and clinical characteristics, including disease severity quantified by the NNIPPS-PPS total score. Only the NNIPPS-PPS oculomotor function sub-score significantly differed, being more impaired in PSP-RS patients. No significant differences were found in all speech variables between the two groups. Speech evaluation is not a distinguishing feature of PSP subtypes in mid-stage disease.","2025-02","2025-02-26 20:43:32","2025-02-26 20:43:32","","769-774","","2","46","","","","","","","","","","English","","","","WOS:001341131600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","Acoustic speech analysis; Atypical parkinsonism; COMMUNICATION; DISORDERS; PARKINSONS-DISEASE; Phenotype; Progressive supranuclear palsy; PROGRESSIVE SUPRANUCLEAR PALSY; PSP; PSP classification; VOICE ANALYSIS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8U4EU49I","journalArticle","2021","Izyumenko, E","A Freedom of Expression Right to Register ""Immoral"" Trademarks and Trademarks Contrary to Public Order","IIC-INTERNATIONAL REVIEW OF INTELLECTUAL PROPERTY AND COMPETITION LAW","","0018-9855","10.1007/s40319-021-01085-3","","Recently, in a judgment on the ""Fack Ju Gohte"" case, the Court of Justice of the European Union (CJEU) acknowledged that freedom of expression must be taken into account when applying the absolute ground for refusal of trademark registration related to public policy or to accepted principles of morality. Even prior to this pronouncement by the CJEU, the European Court of Human Rights (ECtHR) had already confirmed that the refusal of trademark registration, as such, implicates the speech rights of trademark applicants. The European Union Intellectual Property Office (EUIPO), likewise, had admitted on a number of occasions that the trademark applicant seeking registration of an ""immoral"" trademark or a trademark contrary to public order has a right ""to freely employ words and images in the signs it wishes to register as trademarks"". This article explains what the freedom of expression grounding of the rights of trademark applicants to the so-called ""immoral"" trademarks and/or trademarks contrary to public order might mean for the future of these absolute grounds for refusal of trademark registration in Europe. It does so by reviewing, first, whether the wording and practical application of these grounds for refusal comply with the standards that can be derived from Art. 10 (freedom of expression) of the European Convention on Human Rights (ECHR). It then examines particularities of the free speech analysis with regards to religious, sexually obscene or otherwise ""immoral"" signs, as well as with regards to the signs amounting to hate speech or other speech presumably dangerous to public order.","2021-08","2025-02-26 20:43:32","2025-02-26 20:43:32","","893-914","","7","52","","","","","","","","","","English","","","","WOS:000668496800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;16</p>","","","Article 10 ECHR; European Court of Human Rights; Impact of fundamental rights; Morality and public order ground for refusal; Trademark applications; Trademarks and freedom of expression","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"73ZCU3PK","journalArticle","2024","Chen, YY; Adolphs, S; Knight, D","Towards a speech-gesture profile of discourse markers: The case of 'I mean'","LINGUA","","0024-3841","10.1016/j.lingua.2024.103836","","Our study aims to develop a new corpus pragmatic approach for exploring the gesture patterns (i.e. functions and forms) co-occurring with the discourse marker 'I mean', including a comparison with previous research on another discourse marker (i.e. 'you know'). We selected and analysed 246 instances of 'I mean' and 88 gestures that co-occur with these instances from the supervisory sub-corpus of the Nottingham Multimodal Corpus (654 mins, 118,508 words). functional framework for the analysis of speech functions was developed based on the emerging speech patterns surrounding 'I mean'. This included three functions: 'editing ', 'introducing modifications' and 'ending modifications'. The cooccurring gestures were categorised into four functional types: pragmatic, referential, beat and deictic gestures. The main results of the speech analysis of 'I mean' suggest that 'I mean' tends to be used predominantly as a marker 'editing ' (163 instances, 66.26%) and 'introducing modifications' (80 instances, 32.52%), both of which emphasise the speaker's intention to present additional information. These findings largely resemble those of 'you know'; however, the functions of 'you know' are more varied. The analysis of the gesture patterns co-occurring with 'I mean' shows that both the 'editing ' and 'introducing modifications' functions tend to co-occur with pragmatic gestures that serve a similar function of presenting and offering information (e.g., open hand palm up and open hand palm oblique gestures), mirroring the results of 'you know'. These results suggest a functional coordination between discourse markers and gestures. (c) 2024 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http:// creativecommons.org/licenses/by/4.0/).","2024-12","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","312","","","","","","","","","","English","","","","WOS:001361988300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;83</p>","","","'I mean'; Corpus pragmatics; Discourse markers; ENGLISH; Gesture functions; MARKING; Multimodality; NEGATION; RECALL; SEQUENCES; SPEAKING; Speech functions; WELL; YOU-KNOW","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CX6JSEPR","journalArticle","2021","Wang, BQ; Meng, B; Wang, J; Chen, SY; Liu, J","Perceiving Residents' Festival Activities Based on Social Media Data: A Case Study in Beijing, China","ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION","","2220-9964","10.3390/ijgi10070474","","Social media data contains real-time expressed information, including text and geographical location. As a new data source for crowd behavior research in the era of big data, it can reflect some aspects of the behavior of residents. In this study, a text classification model based on the BERT and Transformers framework was constructed, which was used to classify and extract more than 210,000 residents' festival activities based on the 1.13 million Sina Weibo (Chinese ""Twitter"") data collected from Beijing in 2019 data. On this basis, word frequency statistics, part-of-speech analysis, topic model, sentiment analysis and other methods were used to perceive different types of festival activities and quantitatively analyze the spatial differences of different types of festivals. The results show that traditional culture significantly influences residents' festivals, reflecting residents' motivation to participate in festivals and how residents participate in festivals and express their emotions. There are apparent spatial differences among residents in participating in festival activities. The main festival activities are distributed in the central area within the Fifth Ring Road in Beijing. In contrast, expressing feelings during the festival is mainly distributed outside the Fifth Ring Road in Beijing. The research integrates natural language processing technology, topic model analysis, spatial statistical analysis, and other technologies. It can also broaden the application field of social media data, especially text data, which provides a new research paradigm for studying residents' festival activities and adds residents' perception of the festival. The research results provide a basis for the design and management of the Chinese festival system.","2021-07","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","7","10","","","","","","","","","","English","","","","WOS:000676376000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","citizen perceptions; festival activities; PATTERNS; PERCEPTIONS; social media data; SPACE; topic analysis; word frequency analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YCKIFPNU","journalArticle","2021","Gallée, J; Cordella, C; Fedorenko, E; Hochberg, D; Touroutoglou, A; Quimby, M; Dickerson, BC","Breakdowns in Informativeness of Naturalistic Speech Production in Primary Progressive Aphasia","BRAIN SCIENCES","","2076-3425","10.3390/brainsci11020130","","""Functional communication"" refers to an individual's ability to communicate effectively in his or her everyday environment, and thus is a paramount skill to monitor and target therapeutically in people with aphasia. However, traditional controlled-paradigm assessments commonly used in both research and clinical settings often fail to adequately capture this ability. In the current study, facets of functional communication were measured from picture-elicited speech samples from 70 individuals with mild primary progressive aphasia (PPA), including the three variants, and 31 age-matched controls. Building upon methods recently used by Berube et al. (2019), we measured the informativeness of speech by quantifying the content of each patient's description that was relevant to a picture relative to the total amount of speech they produced. Importantly, form-based errors, such as mispronunciations of words, unusual word choices, or grammatical mistakes are not penalized in this approach. We found that the relative informativeness, or efficiency, of speech was preserved in non-fluent variant PPA patients as compared with controls, whereas the logopenic and semantic variant PPA patients produced significantly less informative output. Furthermore, reduced informativeness in the semantic variant is attributable to a lower production of content units and a propensity for self-referential tangents, whereas for the logopenic variant, a lower production of content units and relatively ""empty"" speech and false starts contribute to this reduction. These findings demonstrate that functional communication impairment does not uniformly affect all the PPA variants and highlight the utility of naturalistic speech analysis for measuring the breakdown of functional communication in PPA.","2021-02","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","2","11","","","","","","","","","","English","","","","WOS:000622278200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","3 VARIANTS; ANATOMY; CONNECTED SPEECH; DISCOURSE; IMPAIRMENTS; informativeness; LANGUAGE; primary progressive aphasia; speech production","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZC4HTHYY","journalArticle","2025","Vekkot, S; Chavali, ST; Kandavalli, CT; Podila, RSA; Gupta, D; Zakariah, M; Alotaibi, YA","Continuous Speech-Based Fatigue Detection and Transition State Prediction for Air Traffic Controllers","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3524452","","Air traffic controllers (ATC) play a critical role in ensuring aviation safety, but their demanding workload can lead to fatigue, potentially compromising their performance. This paper presents a study that investigates speech features responsible for detecting ATC fatigue and proposes an approach to predict the timestamp at which an ATC transitions into a fatigue state from a continuous speech sample. The main contributions of this work are the creation of a continuous speech ATC dataset and the identification of a lightweight optimum feature set for fatigue classification from ATC speech. For the initial task, the classification of raw speech signals into fatigue and non-fatigue categories was performed using the top-10 best features selected from the openSMILE feature set. The evaluation was carried out using various learning algorithms such as XGBoost, Adaboost, Random Forest, HistogramGB, and 1D-CNN. The ensemble algorithms demonstrated the best performance, achieving a maximum accuracy of 100% on the XGBoost test set. Further, interpretability was analyzed using the SHAP tool, which identified the prominent features for the task. The second task involved creating a continuous speech dataset comprising approximately 18,900 samples from the ATC corpus, with an average duration of 63-65 seconds per sample. The continuous speech samples were prepared by the randomized concatenation of fatigue and non-fatigue chunks, each with a duration of approximately 15 seconds. Automated sequence labeling was performed on uniformly segmented continuous speech samples. MFCC and statistical features were extracted from the labelled continuous speech and input into various Recurrent Neural Networks, such as bi-LSTM and Bi-GRU, for fatigue state prediction tasks. A combination of these features using bi-LSTM modeling achieved a maximum precision, recall, F-score, and average accuracy of 99% each. Finally, sample-wise timestamp prediction was performed using the labels: fatigue, non-fatigue, and ambiguous (transition). To the best of the authors' knowledge, this research is the first of its kind to address continuous speech-based fatigue state prediction for ATCs. All tasks were conducted using the Civil Aviation Administration of China ATC corpus.","2025","2025-02-26 20:43:32","2025-02-26 20:43:32","","3298-3319","","","13","","","","","","","","","","English","","","","WOS:001394723100046","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Accuracy; Acoustics; Air traffic controller; bi-LSTM; Brain modeling; CLASSIFICATION; continuous speech; Fatigue; Feature extraction; Mel frequency cepstral coefficient; MFCC; Physiology; recurrent neural networks; Safety; Speech recognition; Support vector machines; VOCAL FATIGUE; VOICE; XGBoost","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RJKRAWET","journalArticle","2024","Hurley, CR; Mcleod, S; Anthonappa, RP","Extraction of primary maxillary incisors and children's speech production: A case series","CLINICAL LINGUISTICS & PHONETICS","","0269-9206","10.1080/02699206.2024.2355481","","Dental caries (tooth decay) is a disease with a significant global burden. Management may necessitate the extraction of teeth to restore oral health. The association between dental extractions and children's speech is unclear, with clinical implications for speech-language pathologists and dentists. This case series describes a prospective study reporting the impact of primary maxillary incisor teeth extraction on speech sound accuracy for three children (C1 aged 5;6 (years; months), C2 aged 4;6, C3 aged 3;10). Their speech was assessed using the Diagnostic Evaluation of Articulation and Phonology (DEAP) and the Intelligibility in Context Scale (ICS) before (T1) and 1 month after dental treatment (T2). Speech analysis included the percentage of consonants correct (PCC) and error-type analyses. Caregiver and child perception of the child's oral health-related quality of life (OHRQoL) were assessed pre- and post-operatively using a modified Scale of Oral Health Outcomes for 5-year-old children (SOHO-5). At T1, all three children scored >1 standard deviation below the mean on normative data in the DEAP. There was no clinically significant change in PCC for any child (C1 T1: 89.6%, T2: 90.6%, C2 T1: 78.0%, T2: 75.9%, C3 T1: 56.1%, T2: 63.1%). OHRQoL measures were improved for C1 by the carergiver report and remained stable for C2 and C3 and all child reports. Speech sound difficulties were present before dental treatment in all participants and extraction of primary maxillary incisors did not significantly impact speech production. Dental extractions appear to be independent from speech production in this case series of preschool children.","2024-05-27","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","","","","","","","","","","","English","","","","WOS:001232045900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","children; dental caries; dentistry; PREMATURE LOSS; RELIABILITY; Speech; tooth extractions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VSYBCQ8F","journalArticle","2023","Li, N; Ross, R","Invoking and identifying task-oriented interlocutor confusion in human-robot interaction","FRONTIERS IN ROBOTICS AND AI","","2296-9144","10.3389/frobt.2023.1244381","","Successful conversational interaction with a social robot requires not only an assessment of a user's contribution to an interaction, but also awareness of their emotional and attitudinal states as the interaction unfolds. To this end, our research aims to systematically trigger, but then interpret human behaviors to track different states of potential user confusion in interaction so that systems can be primed to adjust their policies in light of users entering confusion states. In this paper, we present a detailed human-robot interaction study to prompt, investigate, and eventually detect confusion states in users. The study itself employs a Wizard-of-Oz (WoZ) style design with a Pepper robot to prompt confusion states for task-oriented dialogues in a well-defined manner. The data collected from 81 participants includes audio and visual data, from both the robot's perspective and the environment, as well as participant survey data. From these data, we evaluated the correlations of induced confusion conditions with multimodal data, including eye gaze estimation, head pose estimation, facial emotion detection, silence duration time, and user speech analysis-including emotion and pitch analysis. Analysis shows significant differences of participants' behaviors in states of confusion based on these signals, as well as a strong correlation between confusion conditions and participants own self-reported confusion scores. The paper establishes strong correlations between confusion levels and these observable features, and lays the ground or a more complete social and affect oriented strategy for task-oriented human-robot interaction. The contributions of this paper include the methodology applied, dataset, and our systematic analysis.","2023-11-20","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","10","","","","","","","","","","English","","","","WOS:001112634600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;91</p>","","","confusion detection; DYNAMICS; ENGAGEMENT; LEARNERS CONFUSION; METACOGNITION; multimodal modeling; SELECTION; situated dialogue; social robot; UNCERTAINTY; user engagement; wizard-of-oz","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QJN5PNL6","journalArticle","2024","Marchese, MR; Longobardi, Y; Libero, R; Yesilli-Puzella, G; D'Alatri, L; Galli, J","""Lombard Effect"" and Voice Changes in Adductor Laryngeal Dystonia: A Pilot Study","LARYNGOSCOPE","","0023-852X","10.1002/lary.31491","","ObjectivesThe aim was to describe the acoustic, auditory-perceptive, and subjective voice changes under the Lombard effect (LE) in adductor laryngeal dystonia (AdLD) patients.MethodsSubjective perception of vocal effort (OMNI Vocal Effort Scale OMNI-VES), Maximum Phonation Time (MPT), and the perceptual severity of dysphonia (GRBAS scale) were assessed in condition of stillness and under LE in 10 AdLD patients and in 10 patients with typical voice. Speakers were asked to produce the sustained vowel /a/ and to read a phonetically balanced text aloud. Using the PRAAT software, the following acoustic parameters were analyzed: Mean Pitch (Hz), Minimum and Maximum Intensity (dB), the Fraction of Locally Unvoiced Frames, the Number of Voice Breaks, the Degree of Voice Breaks (%), the Cepstral Peak Prominence-Smoothed (CPPS) (dB).ResultsUnder LE, the AdLD group showed a decrease of both G and S parameters of GRBAS and subjective effort, mean MPT increased significantly; in the controls there were no significant changes. In both groups under LE, pitch and intensity of the sustained vowel /a/ significantly increased consistently with LE. In the AdLD group the mean gain of OMNI-VES score and the mean gain of each parameter of the speech analysis were significantly greater than the controls' ones.ConclusionAuditory feedback deprivation obtained under LE improves subjective, perceptual-auditory, and acoustics parameters of AdLD patients. These findings encourage further research to provide new knowledge into the role of the auditory system in the pathogenesis of AdLD and to develop new therapeutic strategies.Level of Evidence4 Laryngoscope, 2024","2024-08","2025-02-26 20:43:32","2025-02-26 20:43:32","","3754-3760","","8","134","","","","","","","","","","English","","","","WOS:001219085400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","acoustic analysis; adductor laryngeal dystonia; audio-vocal feedback control; BOTULINUM TOXIN INJECTIONS; CORTEX; HEARING; Lombard effect; MASKING; NETWORK; NOISE; SPASMODIC DYSPHONIA; SPEECH PRODUCTION; STUTTERING FREQUENCY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U6BLDYRB","journalArticle","2021","van Brenk, F; Kain, A; Tjaden, K","Investigating Acoustic Correlates of Intelligibility Gains and Losses During Slowed Speech: A Hybridization Approach","AMERICAN JOURNAL OF SPEECH-LANGUAGE PATHOLOGY","","1058-0360","10.1044/2021_AJSLP-20-00172","","Purpose: This exploratory study sought to identify acoustic variables explaining rate-related variation in intelligibility for speakers with dysarthria secondary to multiple sclerosis. Method: Seven speakers with dysarthria due to multiple sclerosis produced the same set of Harvard sentences at habitual and slow rates. Speakers were selected from a larger corpus on the basis of rate-related intelligibility characteristics. Four speakers demonstrated improved intelligibility and three speakers demonstrated reduced intelligibility when rate was slowed. A speech analysis resynthesis paradigm termed hybridization was used to create stimuli in which segmental (i.e., short-term spectral) and suprasegmental variables (i.e., sentence-level fundamental frequency, energy characteristics, and duration) of sentences produced at the slow rate were donated individually or in combination to habitually produced sentences. Online crowdsourced orthographic transcription was used to quantify intelligibility for six hybridized sentence types and the original habitual and slow productions. Results: Sentence duration alone was not a contributing factor to improved intelligibility associated with slowed rate. Speakers whose intelligibility improved with slowed rate showed higher intelligibility scores for duration spectrum hybrids and energy hybrids compared to the original habitual rate sentences, suggesting these acoustic cues contributed to improved intelligibility for sentences produced with a slowed rate. Energy contour characteristics were also found to play a role in intelligibility losses for speakers with decreased intelligibility at slowed rate. The relative contribution of speech acoustic variables to intelligibility gains and losses varied considerably between speakers. Conclusions: Hybridization can be used to identify acoustic correlates of intelligibility variation associated with slowed rate. This approach has further elucidated speaker-specific and individualized speech production adjustments when slowing rate.","2021-06","2025-02-26 20:43:32","2025-02-26 20:43:32","","1343-1360","","3","30","","","","","","","","","","English","","","","WOS:000663328000004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;85</p>","","","ATAXIC DYSARTHRIA; CLEAR SPEECH; FUNDAMENTAL-FREQUENCY CONTOURS; LEXICAL SEGMENTATION; MULTIPLE-SCLEROSIS; PARKINSONS-DISEASE; SPEAKERS; SPEAKING RATE; TO-NOISE RATIOS; VOWEL ACOUSTICS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L7JDSZIY","journalArticle","2024","Savchenko, VV; Savchenko, LV","A method for the asynchronous analysis of a voice source based on a two-Level autoregressive model of speech signal","MEASUREMENT TECHNIQUES","","0543-1972","10.1007/s11018-024-02330-0","","We consider the problem of analysis of the voice source of speech within the range of short-term observations. The problem of insufficient speed of the available methods for the analysis of voice source is described, regardless of the method of data preparation: either synchronous with the main tone of speech sounds or asynchronous. We propose a method for the analysis of voice sources based on the two-level autoregressive model of the speech signal. We describe a software realization of the developed method based on the Berg-Levinson high-speed procedure of numerical calculations. It is shown that this procedure is characterized by a relatively low level of computation costs and its application does not require synchronization of the sequence of observations with the main tone of speech signal. With the help of software implementation of the proposed method, we designed and performed full-scale experiment aimed at analyzing the vowel sounds in the speech of a reference speaker. The results of this experiment confirmed the elevated speed of the proposed method and enabled us to formulate the requirements to the duration of speech signal for the real-time voice analysis. Thus, the optimal duration of the speech signal should vary within the range 32-128 msec. The obtained results can be used for the development and investigation of digital speech communication systems, systems of voice control, biometrics, biomedicine and other speech systems in which specific voice features of speaker's speech are of primary importance.","2024-05","2025-02-26 20:43:32","2025-02-26 20:43:32","","151-161","","2","67","","","","","","","","","","English","","","","WOS:001271149800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Fundamental tone; Fundamental tone frequency; GLOTTAL SOURCE; Speech acoustics; Speech analysis; Speech signal; Vocal tract; Voice analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S9R7B3G9","journalArticle","2022","Zhang, W; Xie, YL; Lin, BH; Wang, LY; Zhang, JS","Estimation of the Underlying F0 Range of a Speaker from the Spectral Features of a Brief Speech Input","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app12136494","","Featured Application This work could be used in phonetic analysis from a speaker's limited speech. For example, in helping with the speech analysis of new users for a language learning application. From a very brief speech, human listeners can estimate the pitch range of the speaker and normalize pitch perception. Spectral features which inherently involve both articulatory and phonatory characteristics were speculated to play roles in this process, but few were reported to directly correlate with speaker's F0 range. To mimic this human auditory capability and validate the speculation, in a preliminary study we proposed an LSTM-based method to estimate speaker's F0 range from a 300 ms-long speech input, which turned out to outperform the conventional method. By two more experiments, this study further improved the method and verified its validity in estimating the speaker-specific underlying F0 range. After incorporating a novel measurement of F0 range and a multi-task training approach, Experiment 1 showed that the refined model gave more accurate estimates than the initial model. Based on a Japanese-Chinese bilingual parallel speech corpus, Experiment 2 found that the F0 ranges estimated with the model from the Chinese speech and the model from the Japanese speech produced by the same set of speakers had no significant difference, whereas the conventional method showed significant difference. The results indicate that the proposed spectrum-based method captures the speaker-specific underlying F0 range which is independent of the linguistic content.","2022-07","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","13","12","","","","","","","","","","English","","","","WOS:000824471200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","ENGLISH; F0 range estimation; FUNDAMENTAL-FREQUENCY; IDENTIFICATION; INFORMATION; JITTER; NORMALIZATION; PARAMETERS; PERCEPTION; PITCH LOCATION; pitch perception; spectral features; underlying F0 range; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M5ICSVJE","journalArticle","2024","Castillo-Triana, N; Camargo-Mendoza, M; Bernal-Pacheco, O","Effects of subthalamic nucleus deep brain stimulation on the speech of Spanish-during the first year of treatment","CODAS","","2317-1782","10.1590/2317-1782/20242023194en","","Purpose: To describe the effects of subthalamic nucleus deep brain stimulation (STN-DBS) on the speech of Spanish-speaking Parkinson's disease (PD) patients during the first year of treatment. Methods: The speech measures (SMs): maximum phonation time, acoustic voice measures, speech rate, speech intelligibility measures, and oral diadochokinesis rates of nine Colombian idiopathic PD patients (four females and five males; age = 63 f 7 years; years of PD = 10 f 7 years; UPDRS-III = 57 f 6; H&Y = 2 f 0.3) were studied in OFF and ON medication states before and every three months during the first year after STN-DBS surgery. Praat software and healthy native listeners' ratings were used for speech analysis. Statistical analysis tried to find significant differences in the SMs during follow-up (Friedman test) and between medication states (Wilcoxon paired test). Also, a pre-surgery variation interval (PSVI) of reference for every participant and SM was calculated to make an individual analysis of post-surgery variation. Results: Non-significative post-surgery or medication staterelated differences in the SMs were found. Nevertheless, individually, based on PSVIs, the SMs exhibited: no variation, inconsistent or consistent variation during post-surgery follow-up in different combinations, depending on the medication state. Conclusion: As a group, participants did not have a shared post-surgery pattern of change in any SM. Instead, based on PSVIs, the SMs varied differently in every participant, which suggests that in Spanish-speaking PD patients, the effects of STN-DBS on speech during the first year of treatment could be highly variable.","2024","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","5","36","","","","","","","","","","English","","","","WOS:001340329400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;86</p>","","","DBS; Deep Brain Stimulation; Dysarthria; FEATURES; INDIVIDUALS; INTELLIGIBILITY; MODULATION; Parkinson's Disease; PARKINSONS-DISEASE PATIENTS; PERCEPTION; PERTURBATION; SPEAKERS; Speech; Voice; VOICE DISORDERS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RPWP7L5Z","journalArticle","2023","Osipenko, TA","Inference pragmatics of the interjection hm in stress interaction (based on the medical consultations of an oncologist and a cancer patient)","VESTNIK SANKT-PETERBURGSKOGO UNIVERSITETA-YAZYK I LITERATURA","","2541-9358","10.21638/spbu09.2023.207","","The article is dedicated to the study of verbal communication of a physician and a patient as part of institutional medical discourse. The analysis was conducted based on the material of 12 transcripts of the dialogues in German language between oncologists and female patients diagnosed with breast cancer. Utterances of patients with a vocal gesture expressed by the interjection hm are the subject of this study. The purpose of the article is to determine the communicative functions in the intentional structure of the analyzed dialogues, taking the situational, social and cultural context into account, as well as the correlation with the physician's remarks, and syntactic position hm in the utterance. The article presents quantitative analysis, analyses their lexical composition, determines intentional and semantic relationship of the generation of the sound signal hm and the physician's remarks. Two main types of utterances were distinguished: hm as a separate utterance step, as well as hm as part of the phrase including other interjections and content words (in the initial and/or the final and interposition part of the utterance). Context-specific functions were identified for this type of utterances: 1) emotive; 2) establishing and maintaining contact; 3) pause filling; 4) signal; 5) listener activation; 6) imperative; 7) (de)intensification. Recognition of implicit, context specific intention of hm-containing utterances facilitates the establishment of emotional and intellectual contact with the patient, and helps the physician to prepare the dialogue partner for the conscious participation in the decision-making process regarding medical treatment.","2023","2025-02-26 20:43:32","2025-02-26 20:43:32","","312-333","","2","20","","","","","","","","","","English","","","","WOS:001084231300007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;3</p>","","","conversational analysis; inference pragmatics; interjection pragmatics; medical oncological discourse; oral speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FLS8VK2E","journalArticle","2023","Voleti, R; Woolridge, SM; Liss, JM; Milanovic, M; Stegmann, G; Hahn, S; Harvey, PD; Patterson, TL; Bowie, CR; Berisha, V","Language Analytics for Assessment of Mental Health Status and Functional Competency","SCHIZOPHRENIA BULLETIN","","0586-7614","10.1093/schbul/sbac176","","Background and Hypothesis Automated language analysis is becoming an increasingly popular tool in clinical research involving individuals with mental health disorders. Previous work has largely focused on using high-dimensional language features to develop diagnostic and prognostic models, but less work has been done to use linguistic output to assess downstream functional outcomes, which is critically important for clinical care. In this work, we study the relationship between automated language composites and clinical variables that characterize mental health status and functional competency using predictive modeling. Study Design Conversational transcripts were collected from a social skills assessment of individuals with schizophrenia (n = 141), bipolar disorder (n = 140), and healthy controls (n = 22). A set of composite language features based on a theoretical framework of speech production were extracted from each transcript and predictive models were trained. The prediction targets included clinical variables for assessment of mental health status and social and functional competency. All models were validated on a held-out test sample not accessible to the model designer. Study Results Our models predicted the neurocognitive composite with Pearson correlation PCC = 0.674; PANSS-positive with PCC = 0.509; PANSS-negative with PCC = 0.767; social skills composite with PCC = 0.785; functional competency composite with PCC = 0.616. Language features related to volition, affect, semantic coherence, appropriateness of response, and lexical diversity were useful for prediction of clinical variables. Conclusions Language samples provide useful information for the prediction of a variety of clinical variables that characterize mental health status and functional competency.","2023-03-22","2025-02-26 20:43:32","2025-02-26 20:43:32","","S183-S195","","SUPP2","49","","","","","","","","","","English","","","","WOS:000989362600011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","ALZHEIMERS-DISEASE; bipolar disorder; COMPLEXITY; DEFICITS; DISORDERS; machine learning; MULTIPLE INDICATORS; natural language processing; PREDICTION; PSYCHOSIS; schizophrenia; SCHIZOPHRENIA; social skills prediction; SPEECH; speech analysis; TRACKING","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IVCYNIVI","journalArticle","2021","Roldan-Vasco, S; Orozco-Duque, A; Suarez-Escudero, JC; Orozco-Arroyave, JR","Machine learning based analysis of speech dimensions in functional oropharyngeal dysphagia","COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE","","0169-2607","10.1016/j.cmpb.2021.106248","","Background and objective: The normal swallowing process requires a complex coordination of anatomical structures driven by sensory and cranial nerves. Alterations in such coordination cause swallowing malfunctions, namely dysphagia. The dysphagia screening methods are quite subjective and experience dependent. Bearing in mind that the swallowing process and speech production share some anatomical structures and mechanisms of neurological control, this work aims to evaluate the suitability of automatic speech processing and machine learning techniques for screening of functional dysphagia. Methods: Speech recordings were collected from 46 patients with functional oropharyngeal dysphagia produced by neurological causes, and 46 healthy controls. The dimensions of speech including phonation, articulation, and prosody were considered through different speech tasks. Specific features per dimension were extracted and analyzed using statistical tests. Machine learning models were applied per dimension via nested cross-validation. Hyperparameters were selected using the AUC -ROC as optimization criterion. Results: The Random Forest in the articulation related speech tasks retrieved the highest performance measures ( AUC = 0 . 86 +/- 0 . 10 , sensitivity = 0 . 91 +/- 0 . 12 ) for individual analysis of dimensions. In addition, the combination of speech dimensions with a voting ensemble improved the results, which suggests a contribution of information from different feature sets extracted from speech signals in dysphagia conditions. Conclusions: The proposed approach based on speech related models is suitable for the automatic discrimination between dysphagic and healthy individuals. These findings seem to have potential use in the screening of functional oropharyngeal dysphagia in a non-invasive and inexpensive way. (c) 2021 Elsevier B.V. All rights reserved.","2021-09","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","208","","","","","","","","","","English","","","","WOS:000685504400008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;25<br/>Total Times Cited:&nbsp;&nbsp;28<br/>Cited Reference Count:&nbsp;&nbsp;79</p>","","","AUTOMATIC DETECTION; CERVICAL AUSCULTATION; DIAGNOSIS; Dysphagia; Feature extraction; FIBEROPTIC ENDOSCOPIC EVALUATION; Machine learning; PARKINSONS-DISEASE; RELIABILITY; Speech analysis; Speech processing; STROKE; VIDEOFLUOROSCOPY; VISCOSITY SWALLOW TEST; Voice changes; VOICE DISORDERS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KSHZAPXI","journalArticle","2021","Goyal, K; Singh, A; Kadyan, V","A comparison of Laryngeal effect in the dialects of Punjabi language","JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING","","1868-5137","10.1007/s12652-021-03235-4","","Human beings have their own speaking style which helped them in depicting their native language. The major reason behind variability in some language is due to varying dialect of the speakers. In the field of Automatic Speech Recognition (ASR), key challenge is to recognize and to generate an acoustic model which represents differences of redundant acoustic features. In this paper, an issue of dialect classification is perform on the basis of tonal aspects of laryngeal phoneme [h]. This is an empirical study of [h] sound words in four major dialects of Indian Punjabi language with two key parameters, namely F0 variation, and acoustic space, which are calculated using two formant frequencies: F1, and F2. The results are based on four different dialects which provide us some interesting hypotheses and are explored with self-created dataset. The speech analysis tool PRAAT features have been extracted and correlations are studied using Statistical Package for the Social Sciences (SPSS). Each variable has been compared with same variable of all other dialects. The results analysis showed that the fundamental frequency of these vowels are influenced distinctly in different dialectal conditions. Apart F1 and F2 have shown a significant correlation with each spoken dialect. Further work is extended through processing of acoustic information at feature level or by comparing the performance analysis using basic or hybrid Linear Predictive Cepstral Coefficients feature extraction methods. The result shows that the hybrid LPCC + F0 system achieved a Relative Improvement (R.I.) of 6.94% on Subspace Gaussian Mixture Model model in comparison to that of basic LPCC approach respectively.","2021-04-27","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","","","","","","","","","","","English","","","","WOS:000644753700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","ACOUSTIC DESCRIPTION; CLASSIFICATION; LPCC features; NORTHERN; Prosody features; Punjabi tonal language; RECOGNITION; SPEECH; Tone analysis; VOWELS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ND2ILFSB","journalArticle","2021","Arora, S; Lo, C; Hu, M; Tsanas, A","Smartphone Speech Testing for Symptom Assessment in Rapid Eye Movement Sleep Behavior Disorder and Parkinson's Disease","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2021.3057715","","Speech impairment in Parkinson's Disease (PD) has been extensively studied. Our understanding of speech in people who are at an increased risk of developing PD is, however, rather limited. It is known that isolated Rapid Eye Movement (REM) sleep Behavior Disorder (RBD) is associated with a high risk of developing PD. The aim of this study is to investigate smartphone speech testing to: (1) distinguish participants with RBD from controls and PD, and (2) predict a range of self- or researcher-administered clinical scores that quantify participants' motor symptoms, cognition, daytime sleepiness, depression, and the overall state of health. The rationale of our analyses is to test an initial hypothesis that speech can be used to detect and quantify the symptoms associated with RBD and PD. We analyzed 4242 smartphone voice recordings collected in clinic and at home from 92 Controls, 112 RBD and 335 PD participants. We used acoustic signal analysis and machine learning, employing 337 features that quantify different properties of speech impairment. Using a leave-one-subject-out cross-validation scheme, we were able to distinguish RBD from controls (sensitivity 60.7%, specificity 69.6%) and RBD from PD participants (sensitivity 74.9%, specificity 73.2%), and predict clinical assessments with clinically useful accuracy. These promising findings warrant further investigation in using speech as a digital biomarker for PD and RBD to facilitate intervention in the early and prodromal stages of PD.","2021","2025-02-26 20:43:32","2025-02-26 20:43:32","","44813-44824","","","9","","","","","","","","","","English","","","","WOS:000633368200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","ACCURACY; ALGORITHMS; Depression; DIAGNOSIS; Digital biomarkers; Diseases; MOCA; Monitoring; Parkinson’; PROM; Rapid eye movement sleep; REM sleep behavior disorder; s disease; SCREENING TOOL; Sensitivity; smartphones; speech analysis; statistical learning; telemedicine; Testing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CB376JUV","journalArticle","2024","Fuller, C; Gardner, JR; Speed, O; Thomason, A; Zaniletti, I; Buckmiller, L; Johnson, A; Hartzell, L","Outcomes After Pharyngeal Flap Surgery in Children: A Comparison of Lined Versus Unlined Flaps","CLEFT PALATE CRANIOFACIAL JOURNAL","","1055-6656","10.1177/10556656231172642","","Objective The addition of a uvular flap (PFU) was hypothesized to improve outcomes over standard pharyngeal flap (PF) for correction of velopharyngeal dysfunction. We report differences in outcomes of PF vs PFU at our institution. Design Retrospective cohort study. Setting Tertiary children's hospital. Patients Children who underwent PF or PFU with the three highest-volume surgeons at our institution in 2004-2017. Outcome measures We examined differences in complications between groups, frequency and type of revision surgery, and speech-related measures including nasometry, pressure-flow testing (PFT) and perceptual speech analysis (PSA). Results 160 patients were included, 41 PF and 119 PFU (including 18 with Hogan technique). Patients undergoing PFU were older (7.6 yr vs 6.0 yr; p = 0.037) and more likely to have cleft palate (63/119 vs 14/41; p = 0.047). There was no significant difference in complications. With PFU, a decrease in airspace contracting revision surgeries was noted, (4/119 vs 8/41; p = 0.002) which drove a reduction in revision surgery of all types (7/119 vs 13/41; p = 0.033). However, patients that did undergo revision surgery after PFU underwent more revision procedures (p = 0.032). PSA scores were found to be lower (less hypernasal) after PFU (p = 0.009) compared to PF. Objective speech measures had varying results, with nasometry demonstrating a significant difference between groups (p = 0.001), while PFT (p = 0.525) did not demonstrate a statistical difference. Conclusion The use of a uvular lining flap in pharyngeal flap surgery may be associated with improved long term surgical outcomes, including both improvements in subjective and objective testing and a lower rate of revision surgery, without increased complications.","2024-09","2025-02-26 20:43:32","2025-02-26 20:43:32","","1461-1469","","9","61","","","","","","","","","","English","","","","WOS:000981766400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","pharyngeal flap; RISK-FACTORS; soft palate; speech disorders; velopharyngeal function; VELOPHARYNGEAL INSUFFICIENCY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JVKIVLN7","journalArticle","2023","Yilmaz, D; Yildiz, M; Toprak, YU; Yetkin, S","Obstructive sleep apnea detection with nonlinear analysis of speech","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2023.104956","","Studies on the detection of Obstructive Sleep Apnea (OSA) from speech recording have brought an important innovation to this field. This study is based on the hypothesis that the deterioration of the muscles and tissues in the vocal tract in OSA patients changes the nonlinear properties of voice. In this study, the features that reveal the nonlinear structure of the speech for OSA detection were investigated. The nonlinear characteristics were evaluated for vowels and consonants, and it was tried to find out in which voice group the nonlinear features were more distinctive in OSA. The nonlinear analysis was applied to a wide variety of voice samples having vocal tract components affected by OSA, and OSA/healthy classifications were realized. The results revealed that nonlinear analysis gives considerable findings in OSA detection, and consonants are more successful than vowels. For classifications, K-Nearest Neighbors (KNN) and Support Vector Machine (SVM) classifiers, 5-fold cross validation procedure and Minimum Redundancy Maximum Relevance (MRMR) feature selection method were used. Using the whole dataset, OSA detection performance for vowels was found as 83.5% with KNN, and 96% with SVM for consonants. Additionally, the test process was carried out by using a distinct group, and 82.5% test accuracy was achieved with only 6 features for consonants. The results indicated that the proposed study supports the hypothesis that the nonlinear behavior of vocal tract changes in subjects with OSA, especially for consonants, and has considerable potential for OSA detection as the pre-diagnosis or screening test in clinical use.","2023-07","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","84","","","","","","","","","","English","","","","WOS:000990356400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","AUTOMATIC DETECTION; DIAGNOSIS; Nonlinear features; Obstructive sleep apnea detection; PERIPHERAL ARTERIAL TONOMETRY; SIGNALS; Speech analysis; Vocal tract; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7R7PUW66","journalArticle","2021","Mathad, VC; Scherer, N; Chapman, K; Liss, JM; Berisha, V","A Deep Learning Algorithm for Objective Assessment of Hypernasality in Children With Cleft Palate","IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING","","0018-9294","10.1109/TBME.2021.3058424","","Objectives: Evaluation of hypernasality requires extensive perceptual training by clinicians and extending this training on a large scale internationally is untenable; this compounds the health disparities that already exist among children with cleft. In this work, we present the objective hypernasality measure (OHM), a speech-based algorithm that automatically measures hypernasality in speech, and validate it relative to a group of trained clinicians. Methods: We trained a deep neural network (DNN) on approximately 100 hours of a publicly-available healthy speech corpus to detect the presence of nasal acoustic cues generated through the production of nasal consonants and nasalized phonemes in speech. Importantly, this model does not require any clinical data for training. The posterior probabilities of the deep learning model were aggregated at the sentence and speaker-levels to compute the OHM. Results: The results showed that the OHM was significantly correlated with perceptual hypernasality ratings from the Americleft database (r = 0.797, p < 0.001) and the New Mexico Cleft Palate Center (NMCPC) database (r = 0.713, p < 0.001). In addition, we evaluated the relationship between the OHM and articulation errors; the sensitivity of the OHM in detecting the presence of very mild hypernasality; and established the internal reliability of the metric. Further, the performance of the OHM was compared with a DNN regression algorithm directly trained on the hypernasal speech samples. Significance: The results indicate that the OHM is able to measure the severity of hypernasality on par with Americleft-trained clinicians on thisdataset.","2021-10","2025-02-26 20:43:32","2025-02-26 20:43:32","","2986-2996","","10","68","","","","","","","","","","English","","","","WOS:000697820800014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","ACOUSTIC ANALYSIS; Acoustics; Cleft palate; clinical speech analysis; Databases; deep neural networks; Feature extraction; hypernasality; LIP; Protocols; Reliability; RESONANCE; speech assessment; Surgery; Training; vocal biomarkers; VOICE LOW TONE; VOWELS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QNVH4UHF","journalArticle","2025","Heyne, M; Tardif, MC; Ocampo, A; Petitjean, AP; Hacker, EJ; Fox, CN; Liu, MA; Fontana, M; Pennetti, V; Bohland, JW","Dataset of speech produced with delayed auditory feedback","DATA IN BRIEF","","2352-3409","10.1016/j.dib.2025.111300","","Speakers use auditory feedback to monitor their speech output and detect any deviations from their expectations. It has long been known that when auditory feedback is artificially delayed by a fraction of a second, speech may be severely disrupted [ 1-3 ]. Despite the long history of using delayed auditory feedback (DAF) in experimental research on speech motor control, its effects remain relatively poorly understood. To our knowledge, there are currently no publicly available research datasets containing recordings of speech produced with DAF. Here we describe a large dataset of speech produced with DAF using modern experimental methods with systematic controls and varied speaking materials, including phonotactically legal, nonword syllable sequences and American English sentences. Auditory feedback latencies were tightly controlled and included a zero / minimal delay ( similar to 12 ms), 150 ms, 200 ms, and 250 ms. The dataset includes simultaneous audio recordings from the microphone (production) and headphone (feedback) channels. It also includes recordings and annotations of reading passages and multi- ple other demographic and acoustic measures that serve as covariates of interest from each participant. The complete dataset, which is made available in two segments (one fully open access and one password restricted) includes speech audio recordings from 55 participants, 42 of whom com- pleted a second session with similar testing materials. This dataset is valuable for researchers interested in theoretical aspects of speech sensory-motor control and for researchers interested in developing speech analysis tools. (c) 2025 The Author(s). Published by Elsevier Inc. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/)","2025-04","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","59","","","","","","","","","","English","","","","WOS:001413165800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","Acoustic; Phonetics; Speech errors; Speech motor control; Speech production","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X88MVPAF","journalArticle","2021","Belouali, A; Gupta, S; Sourirajan, V; Yu, JW; Allen, N; Alaoui, A; Dutton, MA; Reinhard, MJ","Acoustic and language analysis of speech for suicidal ideation among US veterans","BIODATA MINING","","1756-0381","10.1186/s13040-021-00245-y","","Background Screening for suicidal ideation in high-risk groups such as U.S. veterans is crucial for early detection and suicide prevention. Currently, screening is based on clinical interviews or self-report measures. Both approaches rely on subjects to disclose their suicidal thoughts. Innovative approaches are necessary to develop objective and clinically applicable assessments. Speech has been investigated as an objective marker to understand various mental states including suicidal ideation. In this work, we developed a machine learning and natural language processing classifier based on speech markers to screen for suicidal ideation in US veterans. Methodology Veterans submitted 588 narrative audio recordings via a mobile app in a real-life setting. In addition, participants completed self-report psychiatric scales and questionnaires. Recordings were analyzed to extract voice characteristics including prosodic, phonation, and glottal. The audios were also transcribed to extract textual features for linguistic analysis. We evaluated the acoustic and linguistic features using both statistical significance and ensemble feature selection. We also examined the performance of different machine learning algorithms on multiple combinations of features to classify suicidal and non-suicidal audios. Results A combined set of 15 acoustic and linguistic features of speech were identified by the ensemble feature selection. Random Forest classifier, using the selected set of features, correctly identified suicidal ideation in veterans with 86% sensitivity, 70% specificity, and an area under the receiver operating characteristic curve (AUC) of 80%. Conclusions Speech analysis of audios collected from veterans in everyday life settings using smartphones offers a promising approach for suicidal ideation detection. A machine learning classifier may eventually help clinicians identify and monitor high-risk veterans.","2021-02-02","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","1","14","","","","","","","","","","English","","","","WOS:000614050200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;22<br/>Total Times Cited:&nbsp;&nbsp;26<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","BIAS; DEPRESSION; MARKERS; PHQ-9; RISK-FACTORS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CJJ3RRJQ","journalArticle","2023","Warmbier, WA; Popiel, M; Guzik, A; Druzbicki, M; Bartosik-Psujek, H","Objective assessment of dysarthric disorders in patients with multiple sclerosis depending on sex, age, and type of text read","FRONTIERS IN NEUROLOGY","","1664-2295","10.3389/fneur.2023.1225754","","PurposeTo assess dysarthric disorders in multiple sclerosis (MS) patients in comparison with healthy individuals and MS patients without dysarthria depending on the patient's sex, age, and the type of text read using an objective tool. MethodsThe study was carried out in a group of 72 persons, including 24 with MS presenting dysarthria (study group) and 24 healthy individuals (healthy control group), and 24 with MS without dysarthria (MS control group). Performance (reading) time was evaluated by means of an objective tool created for the purpose of the analysis. ResultsThe study showed significant statistical differences in the analyzed performance time of: poetry reading, prose reading, and completing a diction exercise, among persons with MS from the study group presenting dysarthria and both control groups (p < 0.05). It took more time to read the poem, and prose and to perform a diction exercise in the study group with dysarthria than in both control groups (with no significant differences between the two) Similarly, the comparison between the groups in terms of sex and age showed disturbances in the above-mentioned parameter in the study group. What was not demonstrated were significant differences in the evaluated speech parameters depending on both sex and age separately in the group of MS patients with dysarthria, and both control groups (p < 0.05). ConclusionThe objective tool created for the purpose of speech analysis is useful in detecting discrepancies in performance (reading) time among MS patients with dysarthria, and healthy individuals, as well as patients with MS without dysarthria and can be used in clinical practice for diagnostic purposes, however, further research is essential to complete its validation.","2023-08-09","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","14","","","","","","","","","","English","","","","WOS:001052614100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","age; dysarthria; multiple sclerosis; objective tool; sex; speech; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CJS2UN66","journalArticle","2022","Costantini, G; Cesarini, V; Robotti, C; Benazzo, M; Pietrantonio, F; Di Girolamo, S; Pisani, A; Canzi, P; Mauramati, S; Bertino, G; Cassaniti, I; Baldanti, F; Saggio, G","Deep learning and machine learning-based voice analysis for the detection of COVID-19: A proposal and comparison of architectures","KNOWLEDGE-BASED SYSTEMS","","0950-7051","10.1016/j.knosys.2022.109539","","Alongside the currently used nasal swab testing, the COVID-19 pandemic situation would gain notice-able advantages from low-cost tests that are available at any-time, anywhere, at a large-scale, and with real time answers. A novel approach for COVID-19 assessment is adopted here, discriminating negative subjects versus positive or recovered subjects. The scope is to identify potential discriminating features, highlight mid and short-term effects of COVID on the voice and compare two custom algorithms. A pool of 310 subjects took part in the study; recordings were collected in a low-noise, controlled setting employing three different vocal tasks. Binary classifications followed, using two different custom algorithms. The first was based on the coupling of boosting and bagging, with an AdaBoost classifier using Random Forest learners. A feature selection process was employed for the training, identifying a subset of features acting as clinically relevant biomarkers. The other approach was centered on two custom CNN architectures applied to mel-Spectrograms, with a custom knowledge-based data augmentation. Performances, evaluated on an independent test set, were comparable: Adaboost and CNN differentiated COVID-19 positive from negative with accuracies of 100% and 95% respectively, and recovered from negative individuals with accuracies of 86.1% and 75% respectively. This study highlights the possibility to identify COVID-19 positive subjects, foreseeing a tool for on-site screening, while also considering recovered subjects and the effects of COVID-19 on the voice. The two proposed novel architectures allow for the identification of biomarkers and demonstrate the ongoing relevance of traditional ML versus deep learning in speech analysis. (C) 2022 Elsevier B.V. All rights reserved.","2022-10-11","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","253","","","","","","","","","","English","","","","WOS:000861208200003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;79</p>","","","Adaboost; ADABOOST ALGORITHM; AMYOTROPHIC-LATERAL-SCLEROSIS; Classification; COVID-19; Deep learning; DIAGNOSIS; PARAMETERS; RANDOM FORESTS; Speech processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WJJUC9T4","journalArticle","2024","Aziz, D; David, S","Multitask and Transfer Learning Approach for Joint Classification and Severity Estimation of Dysphonia","IEEE JOURNAL OF TRANSLATIONAL ENGINEERING IN HEALTH AND MEDICINE","","2168-2372","10.1109/JTEHM.2023.3340345","","Objective: Despite speech being the primary communication medium, it carries valuable information about a speaker's health, emotions, and identity. Various conditions can affect the vocal organs, leading to speech difficulties. Extensive research has been conducted by voice clinicians and academia in speech analysis. Previous approaches primarily focused on one particular task, such as differentiating between normal and dysphonic speech, classifying different voice disorders, or estimating the severity of voice disorders.Methods and procedures: This study proposes an approach that combines transfer learning and multitask learning (MTL) to simultaneously perform dysphonia classification and severity estimation. Both tasks use a shared representation; network is learned from these shared features. We employed five computer vision models and changed their architecture to support multitask learning. Additionally, we conducted binary 'healthy vs. dysphonia' and multiclass 'healthy vs. organic and functional dysphonia' classification using multitask learning, with the speaker's sex as an auxiliary task.Results: The proposed method achieved improved performance across all classification metrics compared to single-task learning (STL), which only performs classification or severity estimation. Specifically, the model achieved F1 scores of 93% and 90% in MTL and STL, respectively. Moreover, we observed considerable improvements in both classification tasks by evaluating beta values associated with the weight assigned to the sex-predicting auxiliary task. MTL achieved an accuracy of 77% compared to the STL score of 73.2%. However, the performance of severity estimation in MTL was comparable to STL.Conclusion: Our goal is to improve how voice pathologists and clinicians understand patients' conditions, make it easier to track their progress, and enhance the monitoring of vocal quality and treatment procedures.","2024","2025-02-26 20:43:32","2025-02-26 20:43:32","","233-244","","","12","","","","","","","","","","English","","","","WOS:001129742800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","Convolutional neural networks; deep learning; dysphonia; Estimation; Feature extraction; Multitask learning; Recording; speech; SPEECH; Surgery; Task analysis; Training; VOICE; voice pathology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IIFANGWV","journalArticle","2023","Moreno-Torres, I; Lozano, A; Bermúdez, R; Pino, J; Méndez, MDG; Nava, E","Unmasking Nasality to Assess Hypernasality","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app132312606","","Featured Application The results of this study provide key information, both linguistic and technical, to use signals recorded close to the nose to evaluate hypernasality automatically. The results may also guide the improvement of the accuracy of hypernasality assessment tools by analyzing nose signals.Abstract Automatic evaluation of hypernasality has been traditionally computed using monophonic signals (i.e., combining nose and mouth signals). Here, this study aimed to examine if nose signals serve to increase the accuracy of hypernasality evaluation. Using a conventional microphone and a Nasometer, we recorded monophonic, mouth, and nose signals. Three main analyses were performed: (1) comparing the spectral distance between oral/nasalized vowels in monophonic, nose, and mouth signals; (2) assessing the accuracy of Deep Neural Network (DNN) models in classifying oral/nasal sounds and vowel/consonant sounds trained with nose, mouth, and monophonic signals; (3) analyzing the correlation between DNN-derived nasality scores and expert-rated hypernasality scores. The distance between oral and nasalized vowels was the highest in the nose signals. Moreover, DNN models trained on nose signals outperformed in nasal/oral classification (accuracy: 0.90), but were slightly less precise in vowel/consonant differentiation (accuracy: 0.86) compared to models trained on other signals. A strong Pearson's correlation (0.83) was observed between nasality scores from DNNs trained with nose signals and human expert ratings, whereas those trained on mouth signals showed a weaker correlation (0.36). We conclude that mouth signals partially mask the nasality information carried by nose signals. Significance: the accuracy of hypernasality assessment tools may improve by analyzing nose signals.","2023-12","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","23","13","","","","","","","","","","English","","","","WOS:001116585500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","CHILDREN; CLEFT AUDIT PROTOCOL; clinical speech analysis; deep neural networks; hypernasality; INDIVIDUALS; LIP; NASALANCE SCORES; PALATE; PERCEPTUAL RATINGS; RESONANCE; SPEECH; speech assessment; vocal biomarkers; VOWEL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PFDVNI2V","journalArticle","2022","Moura, GC; Antonetti, AED; Dos Santos, AP; Vitor, JD; Brasolotto, AG; Siqueira, LTD; Silverio, KCA","The influence of the low-frequency transcutaneous electrical nerve stimulation application moment in vocal quality of dysphonic women","LOGOPEDICS PHONIATRICS VOCOLOGY","","1401-5439","10.1080/14015439.2022.2143557","","Objective: to compare the immediate effects of low-frequency TENS employment on vocal quality in women with behavioral dysphonia before and after vocal exercises. Methodology: 30 women (mean = 31.3 years old), diagnosed with behavioral dysphonia received low-frequency TENS before (TENS + VE Group) and after vocal exercises (VE + TENS Group) with a 1-week washout. They had their sustained vowel/a/and running speech recorded before and after each procedure for auditory-perceptual analysis and acoustic measures. The low-frequency TENS parameters applied were symmetrical biphasic quadratic pulse, 200 mu s phase, 10 Hz frequency, intensity on the motor threshold, and the electrodes were positioned on the submandibular and superior fibers of the trapezius muscle region. The vocal exercises: tongue trill, humming, finger kazoo, and water resistance therapy were performed totalizing 20 min. Results: intragroup analysis of sustained vowel/a/showed reduction in both groups of strain parameter and increased the breathiness; only VE + TENS Group increased the instability parameter, decreased fundamental frequency, and increased in SPI values; the running speech analysis showed an increase in the overall degree, roughness, and breathiness parameters. However, in VE + TENS Group, there was a statistically significant decrease in the intensity of the strain and an increase in breathiness. The acoustic measures showed that VE + TENS Group had a higher variation than TENS + VE Group regarding NHR. Conclusion: vocal exercises followed by low-frequency TENS have more immediate positive effects on voice quality than the low-frequency TENS followed by vocal exercises. This is a preliminary immediate effects study, and these effects could be verified through long-term assessments.","2022-11-09","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","","","","","","","","","","","English","","","","WOS:000881901100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","dysphonia; LARYNGEAL MANUAL THERAPY; PAIN; transcutaneous electrical nerve stimulation; vocal exercises; Voice disorders; voice therapy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NFMNFYFJ","journalArticle","2025","Eni, M; Zigel, Y; Ilan, M; Michaelovski, A; Golan, HM; Meiri, G; Menashe, I; Dinstein, I","Reliably quantifying the severity of social symptoms in children with autism using ASDSpeech","TRANSLATIONAL PSYCHIATRY","","2158-3188","10.1038/s41398-025-03233-6","","Several studies have demonstrated that the severity of social communication problems, a core symptom of Autism Spectrum Disorder (ASD), is correlated with specific speech characteristics of ASD individuals. This suggests that it may be possible to develop speech analysis algorithms that can quantify ASD symptom severity from speech recordings in a direct and objective manner. Here we demonstrate the utility of a new open-source AI algorithm, ASDSpeech, which can analyze speech recordings of ASD children and reliably quantify their social communication difficulties across multiple developmental timepoints. The algorithm was trained and tested on the largest ASD speech dataset available to date, which contained 99,193 vocalizations from 197 ASD children recorded in 258 Autism Diagnostic Observation Schedule, Second edition (ADOS-2) assessments. ASDSpeech was trained with acoustic and conversational features extracted from the speech recordings of 136 children, who participated in a single ADOS-2 assessment, and tested with independent recordings of 61 additional children who completed two ADOS-2 assessments, separated by 1-2 years. Estimated total ADOS-2 scores in the test set were significantly correlated with actual scores when examining either the first (r(59) = 0.544, P < 0.0001) or second (r(59) = 0.605, P < 0.0001) assessment. Separate estimation of social communication and restricted and repetitive behavior symptoms revealed that ASDSpeech was particularly accurate at estimating social communication symptoms (i.e., ADOS-2 social affect scores). These results demonstrate the potential utility of ASDSpeech for enhancing basic and clinical ASD research as well as clinical management. We openly share both algorithm and speech feature dataset for use and further development by the community.","2025-01-18","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","1","15","","","","","","","","","","English","","","","WOS:001400351200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","AUTOMATED VOCAL ANALYSIS; DISORDER; PHENOTYPES; SPECTRUM; SPEECH; YOUNG-CHILDREN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VRBB5G7Q","journalArticle","2024","Simmatis, LER; Robin, J; Spilka, MJ; Yunusova, Y","Detecting bulbar amyotrophic lateral sclerosis (ALS) using automatic acoustic analysis","BIOMEDICAL ENGINEERING ONLINE","","1475-925X","10.1186/s12938-023-01174-z","","Automatic speech assessments have the potential to dramatically improve ALS clinical practice and facilitate patient stratification for ALS clinical trials. Acoustic speech analysis has demonstrated the ability to capture a variety of relevant speech motor impairments, but implementation has been hindered by both the nature of lab-based assessments (requiring travel and time for patients) and also by the opacity of some acoustic feature analysis methods. These challenges and others have obscured the ability to distinguish different ALS disease stages/severities. Validation of automated acoustic analysis tools could enable detection of early signs of ALS, and these tools could be deployed to screen and monitor patients without requiring clinic visits. Here, we sought to determine whether acoustic features gathered using an automated assessment app could detect ALS as well as different levels of speech impairment severity resulting from ALS. Speech samples (readings of a standardized, 99-word passage) from 119 ALS patients with varying degrees of disease severity as well as 22 neurologically healthy participants were analyzed, and 53 acoustic features were extracted. Patients were stratified into early and late stages of disease (ALS-early/ALS-E and ALS-late/ALS-L) based on the ALS Functional Ratings Scale-Revised bulbar score (FRS-bulb) (median [interquartile range] of FRS-bulbar scores: 11[3]). The data were analyzed using a sparse Bayesian logistic regression classifier. It was determined that the current relatively small set of acoustic features could distinguish between ALS and controls well (area under receiver-operating characteristic curve/AUROC = 0.85), that the ALS-E patients could be separated well from control participants (AUROC = 0.78), and that ALS-E and ALS-L patients could be reasonably separated (AUROC = 0.70). These results highlight the potential for automated acoustic analyses to detect and stratify ALS.","2024-02-04","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","1","23","","","","","","","","","","English","","","","WOS:001156282400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","DYSARTHRIA; NOISE; VOICE ANALYSIS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6XDMKWVH","journalArticle","2022","Lebedeva, S; Shved, D; Savinkina, A","Assessment of the Psychophysiological State of Female Operators Under Simulated Microgravity","FRONTIERS IN PHYSIOLOGY","","1664-042X","10.3389/fphys.2021.751016","","The article describes methods of non-verbal speech characteristics analysis used to determine psychophysiological state of female subjects under simulated microgravity conditions (""dry"" immersion, DI), as well as the results of the study. A number of indicators of the acute period of adaptation to microgravity conditions was described. The acute adaptation period in female subjects began earlier (evening of the 1st day of DI) and ended faster than in male ones in previous studies (2nd day of DI). This was indicated by a decrease in the level of state anxiety (STAI, p < 0,05) and depression-dejection [Profile of Mood States (POMS), p < 0,05], as well as a decrease in pitch (p < 0,05) and voice intensity (p < 0,05). In addition, women, apparently, used the ""freeze"" coping strategy - the proportion of neutral facial expressions on the most intense days of the experiment was at maximum. The subjects in this experiment assessed their feelings and emotions better, giving more accurate answers in self-assessment questionnaires, but at the same time tried to look and sound as calm and confident as possible, controlling their expressions. Same trends in the subjects' cognitive performance were identified as in similar experimental conditions earlier: the subjects' psychophysiological excitement corresponded to better performance in sensorimotor tasks. The difference was in the speed of mathematical computation: women in the present study performed the computation faster on the same days when they made fewer pauses in speech, while in men in previous experiments this relationship was inverse.","2022-02-11","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","12","","","","","","","","","","English","","","","WOS:000761120200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","dry immersion; ENVIRONMENTS; ground-based model of microgravity; human operator performance; JITTER; NAIAD-2020; PERFORMANCE; psychophysiological state; SHIMMER; SPEECH; speech analysis; STRESS; VALIDATION; women","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LF3JDHQQ","journalArticle","2024","Agar, M; Aydin, S; Cakmak, M; Koc, M; Togacar, M","Detection of Thymoma Disease Using mRMR Feature Selection and Transformer Models","DIAGNOSTICS","","2075-4418","10.3390/diagnostics14192169","","Background: Thymoma is a tumor that originates in the thymus gland, a part of the human body located behind the breastbone. It is a malignant disease that is rare in children but more common in adults and usually does not spread outside the thymus. The exact cause of thymic disease is not known, but it is thought to be more common in people infected with the EBV virus at an early age. Various surgical methods are used in clinical settings to treat thymoma. Expert opinion is very important in the diagnosis of the disease. Recently, next-generation technologies have become increasingly important in disease detection. Today's early detection systems already use transformer models that are open to technological advances. Methods: What makes this study different is the use of transformer models instead of traditional deep learning models. The data used in this study were obtained from patients undergoing treatment at F & imath;rat University, Department of Thoracic Surgery. The dataset consisted of two types of classes: thymoma disease images and non-thymoma disease images. The proposed approach consists of preprocessing, model training, feature extraction, feature set fusion between models, efficient feature selection, and classification. In the preprocessing step, unnecessary regions of the images were cropped, and the region of interest (ROI) technique was applied. Four types of transformer models (Deit3, Maxvit, Swin, and ViT) were used for model training. As a result of the training of the models, the feature sets obtained from the best three models were merged between the models (Deit3 and Swin, Deit3 and ViT, Deit3 and ViT, Swin and ViT, and Deit3 and Swin and ViT). The combined feature set of the model (Deit3 and ViT) that gave the best performance with fewer features was analyzed using the mRMR feature selection method. The SVM method was used in the classification process. Results: With the mRMR feature selection method, 100% overall accuracy was achieved with feature sets containing fewer features. The cross-validation technique was used to verify the overall accuracy of the proposed approach and 99.22% overall accuracy was achieved in the analysis with this technique. Conclusions: These findings emphasize the added value of the proposed approach in the detection of thymoma.","2024-10","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","19","14","","","","","","","","","","English","","","","WOS:001331741900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","feature fusion; feature selection; thymoma detection; thymoma disease; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KIBPSS9X","journalArticle","2024","Muduli, K; Ghosh, I","Predicting pedestrian-vehicle interaction severity at unsignalized intersections","TRAFFIC INJURY PREVENTION","","1538-9588","10.1080/15389588.2024.2404713","","ObjectivesThis study aims to develop and validate a novel deep-learning model that predicts the severity of pedestrian-vehicle interactions at unsignalized intersections, distinctively integrating Transformer-based models with Multilayer Perceptrons (MLP). This approach leverages advanced feature analysis capabilities, offering a more direct and interpretable method than traditional models.MethodsHigh-resolution optical cameras recorded detailed pedestrian and vehicle movements at study sites, with data processed to extract trajectories and convert them into real-world coordinates via precise georeferencing. Trained observers categorized interactions into safe passage, critical event, and conflict based on movement patterns, speeds, and accelerations. Fleiss Kappa statistic measured inter-rater agreement to ensure evaluator consistency. This study introduces a novel deep-learning model combining Transformer-based time series data capabilities with the classification strengths of a Multilayer Perceptron (MLP). Unlike traditional models, this approach focuses on feature analysis for greater interpretability. The model, trained on dynamic input variables from trajectory data, employs attention mechanisms to evaluate the significance of each input variable, offering deeper insights into factors influencing interaction severity.ResultsThe model demonstrated high performance across different severity categories: safe interactions achieved a precision of 0.78, recall of 0.91, and F1-score of 0.84. In more severe categories like critical events and conflicts, precision and recall were even higher. Overall accuracy stood at 0.87, with both macro and weighted averages for precision, recall, and F1-score also at 0.87. The variable importance analysis, using attention scores from the proposed transformer model, identified 'Vehicle Speed' as the most significant input variable positively influencing severity. Conversely, 'Approaching Angle' and 'Vehicle Distance from Conflict Point' negatively impacted severity. Other significant factors included 'Type of Vehicle', 'Pedestrian Speed', and 'Pedestrian Yaw Rate', highlighting the complex interplay of behavioral and environmental factors in pedestrian-vehicle interactions.ConclusionsThis study introduces a deep-learning model that effectively predicts the severity of pedestrian-vehicle interactions at crosswalks, utilizing a Transformer-MLP hybrid architecture with high precision and recall across severity categories. Key factors influencing severity were identified, paving the way for further enhancements in real-time analysis and broader safety assessments in urban settings.","2024-09-23","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","","","","","","","","","","","English","","","","WOS:001331875900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","CRASHES; deep learning; MODEL; Pedestrian safety; RISK; SAFETY; SPEED; traffic modeling; unsignalized intersections; variable importance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3IBIN2W6","journalArticle","2024","Ma, HY; Ma, XB; Yang, CX; Niu, Q; Gao, T; Liu, CX; Chen, Y","Development and evaluation of a program based on a generative pre-trained transformer model from a public natural language processing platform for efficiency enhancement in post-procedural quality control of esophageal endoscopic submucosal dissection","SURGICAL ENDOSCOPY AND OTHER INTERVENTIONAL TECHNIQUES","","0930-2794","10.1007/s00464-023-10620-x","","Background Post-procedural quality control of endoscopic submucosal dissection (ESD) is emphasized in guidelines. However, this process can be tedious and time-consuming. Recently, a pre-training model called generative pre-trained transformer (GPT) on a public natural language processing platform has emerged and garnered significant attention, whose capabilities align well with the post-procedural quality control process and have the potential to streamline it. Therefore, we developed a simple program utilizing this platform and evaluated its performance. Methods Esophageal ESDs were retrospectively included. The manual quality control process was performed and act as reference standard. GPT's prompt was optimized through multiple iterations. A Python program was developed to automatically submit prompt with pathological report of each ESD procedure and collect quality control information provided by GPT. Its performance on quality control was evaluated with accuracy, precision, recall, and F-1 score. Results 165 cases were involved into the dataset, of which 5 were utilized as the prompt optimization dataset and 160 as the validation dataset. Definitive prompt was achieved through seven iterations. Time spent on the validation dataset by GPT was 13.47 +/- 2.43 min. Accuracies of pathological diagnosis, invasion depth, horizontal margin, vertical margin, vascular invasion, and lymphatic invasion of the quality control program were (0.940, 0.952) (95% CI), (0.925, 0.945) (95% CI), 0.931, 1.0, and 1.0, respectively. Precisions were (0.965, 0.969) (95% CI), (0.934, 0.954) (95% CI), and 0.957 for pathological diagnosis, invasion depth, and horizontal margin, respectively. Recalls were (0.940, 0.952) (95% CI), (0.925, 0.945) (95% CI), and 0.931 for factors as mentioned, respectively. F1-score were (0.945, 0.957) (95% CI), (0.928, 0.948) (95% CI), and 0.941 for factors as mentioned, respectively. Conclusions This quality control program was qualified of post-procedural quality control of esophageal ESDs. GPT can be easily applied to this quality control process and reduce workload of the endoscopists.","2024-03","2025-02-26 20:43:32","2025-02-26 20:43:32","","1264-1272","","3","38","","","","","","","","","","English","","","","WOS:001123686400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Artificial Intelligence; ARTIFICIAL-INTELLIGENCE; Endoscopic submucosal dissection; Esophagus; GASTRIC-CANCER; Natural language processing; Quality control","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3FVSAULJ","journalArticle","2024","Shao, R; Zhang, ZY; Tao, C; Zhang, YS; Peng, CL; Li, HF","Homogeneous tokenizer matters: Homogeneous visual tokenizer for remote sensing image understanding","ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING","","0924-2716","10.1016/j.isprsjprs.2024.09.009","","On the basis of the transformer architecture and the pretext task of ""next-token prediction"", multimodal large language models (MLLMs) are revolutionizing the paradigm in the field of remote sensing image understanding. However, the tokenizer, as one of the fundamental components of MLLMs, has long been overlooked or even misunderstood in visual tasks. A key factor contributing to the great comprehension power of large language models is that natural language tokenizers utilize meaningful words or subwords as the basic elements of language. In contrast, mainstream visual tokenizers, represented by patch-based methods such as Patch Embed, rely on meaningless rectangular patches as basic elements of vision. Analogous to words or subwords in language, we define semantically independent regions (SIRs) for vision and then propose two properties that an ideal visual tokenizer should possess: (1) homogeneity, where SIRs serve as the basic elements of vision, and (2) adaptivity, which allows for a flexible number of tokens to accommodate images of any size and tasks of any granularity. On this basis, we design a simple HOmogeneous visual tOKenizer: HOOK. HOOK consists of two modules: an object perception module (OPM) and an object vectorization module (OVM). To achieve homogeneity, the OPM splits the image into 4 x 4 pixel seeds and then uses a self-attention mechanism to identify SIRs. The OVM employs cross-attention to merge seeds within the same SIR. To achieve adaptability, the OVM predefines a variable number of learnable vectors as cross-attention queries, allowing for the adjustment of the token quantity. We conducted experiments on the NWPU-RESISC45, WHU-RS19, and NaSC-TG2 classification datasets for sparse tasks and the GID5 and DGLCC segmentation datasets for dense tasks. The results show that the visual tokens obtained by HOOK correspond to individual objects, thereby verifying their homogeneity. Compared with randomly initialized or pretrained Patch Embed, which required more than one hundred tokens per image, HOOK required only 6 and 8 tokens for sparse and dense tasks, respectively, resulting in performance improvements of 2% to 10% and efficiency improvements of 1.5 to 2.8 times. The homogeneity and adaptability of the proposed approach provide new perspectives for the study of visual tokenizers. Guided by these principles, the developed HOOK has the potential to replace traditional Patch Embed.","2024-12","2025-02-26 20:43:32","2025-02-26 20:43:32","","294-310","","","218","","","","","","","","","","English","","","","WOS:001321941900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","CLASSIFICATION; Homogeneous; Remote sensing image understanding; Semantically independent region; Visual tokenizer; Visual transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P3NEFRHD","journalArticle","2024","Fan, ZG; Yang, YD; Xu, MY; Chen, HM","EC-Conf: A ultra-fast diffusion model for molecular conformation generation with equivariant consistency","JOURNAL OF CHEMINFORMATICS","","1758-2946","10.1186/s13321-024-00893-2","","Despite recent advancement in 3D molecule conformation generation driven by diffusion models, its high computational cost in iterative diffusion/denoising process limits its application. Here, an equivariant consistency model (EC-Conf) was proposed as a fast diffusion method for low-energy conformation generation. In EC-Conf, a modified SE (3)-equivariant transformer model was directly used to encode the Cartesian molecular conformations and a highly efficient consistency diffusion process was carried out to generate molecular conformations. It was demonstrated that, with only one sampling step, it can already achieve comparable quality to other diffusion-based models running with thousands denoising steps. Its performance can be further improved with a few more sampling iterations. The performance of EC-Conf is evaluated on both GEOM-QM9 and GEOM-Drugs sets. Our results demonstrate that the efficiency of EC-Conf for learning the distribution of low energy molecular conformation is at least two magnitudes higher than current SOTA diffusion models and could potentially become a useful tool for conformation generation and sampling.Scientific ContributionsIn this work, we proposed an equivariant consistency model that significantly improves the efficiency of conformation generation in diffusion-based models while maintaining high structural quality. This method serves as a general framework and can be further extended to more complex structure generation and prediction tasks, including those involving proteins, in future steps. Scientific Contributions In this work, we proposed an equivariant consistency model that significantly improves the efficiency of conformation generation in diffusion-based models while maintaining high structural quality. This method serves as a general framework and can be further extended to more complex structure generation and prediction tasks, including those involving proteins, in future steps. Key points A novel ultra-fast equivariant diffusion model, EC-Conf, was proposed for low-energy conformation generation by construction of a consistency process. Compared with other SOTA diffusion models running with thousands denoising steps, EC-Conf can achieve comparable quality with only one sampling step and keep improving with a few more sampling iterations. The efficiency of EC-Conf is at least two magnitudes higher than current SOTA diffusion models. The EC-Conf is universal and can be easily extended to various conformation generation tasks such as protein-ligand docking pose.","2024-09-03","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","1","16","","","","","","","","","","English","","","","WOS:001304038500002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","CAMBRIDGE; Conformation generation; LIGAND; Ultra-fast diffusion models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TQ843FJQ","journalArticle","2025","Jeny, AA; Hamzehei, S; Jin, A; Baker, SA; Van Rathe, T; Bai, J; Yang, C; Nabavi, S","Hybrid transformer-based model for mammogram classification by integrating prior and current images","MEDICAL PHYSICS","","0094-2405","10.1002/mp.17650","","BackgroundBreast cancer screening via mammography plays a crucial role in early detection, significantly impacting women's health outcomes worldwide. However, the manual analysis of mammographic images is time-consuming and requires specialized expertise, presenting substantial challenges in medical practice.PurposeTo address these challenges, we introduce a CNN-Transformer based model tailored for breast cancer classification through mammographic analysis. This model leverages both prior and current images to monitor temporal changes, aiming to enhance the efficiency and accuracy (ACC) of computer-aided diagnosis systems by mimicking the detailed examination process of radiologists.MethodsIn this study, our proposed model incorporates a novel integration of a position-wise feedforward network and multi-head self-attention, enabling it to detect abnormal or cancerous changes in mammograms over time. Additionally, the model employs positional encoding and channel attention methods to accurately highlight critical spatial features, thus precisely differentiating between normal and cancerous tissues. Our methodology utilizes focal loss (FL) to precisely address challenging instances that are difficult to classify, reducing false negatives and false positives to improve diagnostic ACC.ResultsWe compared our model with eight baseline models; specifically, we utilized only current images for the single model ResNet50 while employing both prior and current images for the remaining models in terms of accuracy (ACC), sensitivity (SEN), precision (PRE), specificity (SPE), F1 score, and area under the curve (AUC). The results demonstrate that the proposed model outperforms the baseline models, achieving an ACC of 90.80%, SEN of 90.80%, PRE of 90.80%, SPE of 90.88%, an F1 score of 90.95%, and an AUC of 92.58%. The codes and related information are available at .ConclusionsOur proposed CNN-Transformer model integrates both prior and current images, removes long-range dependencies, and enhances its capability for nuanced classification. The application of FL reduces false positive rate (FPR) and false negative rates (FNR), improving both SEN and SPE. Furthermore, the model achieves the lowest false discovery rate and FNR across various abnormalities, including masses, calcification, and architectural distortions (ADs). These low error rates highlight the model's reliability and underscore its potential to improve early breast cancer detection in clinical practice.","2025-01-30","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","","","","","","","","","","","English","","","","WOS:001409553600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","AGE; ALGORITHM; BREAST-CANCER; CNN; COMPUTER-AIDED DIAGNOSIS; FEATURES; MASSES; MORTALITY; prior and current mammograms; SELECTION; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TEVTRYNB","journalArticle","2024","Torres, LHM; Arrais, JP; Ribeiro, B","Combining graph neural networks and transformers for few-shot nuclear receptor binding activity prediction","JOURNAL OF CHEMINFORMATICS","","1758-2946","10.1186/s13321-024-00902-4","","Nuclear receptors (NRs) play a crucial role as biological targets in drug discovery. However, determining which compounds can act as endocrine disruptors and modulate the function of NRs with a reduced amount of candidate drugs is a challenging task. Moreover, the computational methods for NR-binding activity prediction mostly focus on a single receptor at a time, which may limit their effectiveness. Hence, the transfer of learned knowledge among multiple NRs can improve the performance of molecular predictors and lead to the development of more effective drugs. In this research, we integrate graph neural networks (GNNs) and Transformers to introduce a few-shot GNN-Transformer, Meta-GTNRP to predict the binding activity of compounds using the combined information of different NRs and identify potential NR-modulators with limited data. The Meta-GTNRP model captures the local information in graph-structured data and preserves the global-semantic structure of molecular graph embeddings for NR-binding activity prediction. Furthermore, a few-shot meta-learning approach is proposed to optimize model parameters for different NR-binding tasks and leverage the complementarity among multiple NR-specific tasks to predict binding activity of compounds for each NR with just a few labeled molecules. Experiments with a compound database containing annotations on the binding activity for 11 NRs shows that Meta-GTNRP outperforms other graph-based approaches. The data and code are available at: https://github.com/ltorres97/Meta-GTNRP.Scientific contributionThe proposed few-shot GNN-Transformer model, Meta-GTNRP captures the local structure of molecular graphs and preserves the global-semantic information of graph embeddings to predict the NR-binding activity of compounds with limited available data; A few-shot meta-learning framework adapts model parameters across NR-specific tasks for different NRs in a joint learning procedure to predict the binding activity of compounds for each NR with just a few labeled molecules in highly imbalanced data scenarios; Meta-GTNRP is a data-efficient approach that combines the strengths of GNNs and Transformers to predict the NR-binding properties of compounds through an optimized meta-learning procedure and deliver robust results valuable to identify potential NR-based drug candidates.","2024-09-27","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","1","16","","","","","","","","","","English","","","","WOS:001321932200002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","Drug Discovery; Few-shot Learning; Graph Neural Network; Meta-Learning; NORMALITY; Nuclear Receptor Binding Activity Prediction; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RKYD2HQW","journalArticle","2021","Fang, K; Ouyang, JQ; Hu, BW","Swin-HSTPS: Research on Target Detection Algorithms for Multi-Source High-Resolution Remote Sensing Images","SENSORS","","1424-8220","10.3390/s21238113","","Traffic port stations are composed of buildings, infrastructure, and transportation vehicles. The target detection of traffic port stations in high-resolution remote sensing images needs to collect feature information of nearby small targets, comprehensively analyze and classify, and finally complete the traffic port station positioning. At present, deep learning methods based on convolutional neural networks have made great progress in single-target detection of high-resolution remote sensing images. How to show good adaptability to the recognition of multi-target complexes of high-resolution remote sensing images is a difficult point in the current remote sensing field. This paper constructs a novel high-resolution remote sensing image traffic port station detection model (Swin-HSTPS) to achieve high-resolution remote sensing image traffic port station detection (such as airports, ports) and improve the multi-target complex in high-resolution remote sensing images The recognition accuracy of high-resolution remote sensing images solves the problem of high-precision positioning by comprehensive analysis of the feature combination information of multiple small targets in high-resolution remote sensing images. The model combines the characteristics of the MixUp hybrid enhancement algorithm, and enhances the image feature information in the preprocessing stage. The PReLU activation function is added to the forward network of the Swin Transformer model network to construct a ResNet-like residual network and perform convolutional feature maps. Non-linear transformation strengthens the information interaction of each pixel block. This experiment evaluates the superiority of the model training by comparing the two indicators of average precision and average recall in the training phase. At the same time, in the prediction stage, the accuracy of the prediction target is measured by confidence. Experimental results show that the optimal average precision of the Swin-HSTPS reaches 85.3%, which is about 8% higher than the average precision of the Swin Transformer detection model. At the same time, the target prediction accuracy is also higher than the Swin Transformer detection model, which can accurately locate traffic port stations such as airports and ports in high-resolution remote sensing images. This model inherits the advantages of the Swin Transformer detection model, and is superior to mainstream models such as R-CNN and YOLOv5 in terms of the target prediction ability of high-resolution remote sensing image traffic port stations.","2021-12","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","23","21","","","","","","","","","","English","","","","WOS:000734641700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","MixUp; multi-source; PReLU; remote sensing; Swin Transformer; target detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NBRVPZRW","journalArticle","2022","Okolo, GI; Katsigiannis, S; Ramzan, N","IEViT: An enhanced vision transformer architecture for chest X-ray image classification","COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE","","0169-2607","10.1016/j.cmpb.2022.107141","","Background and Objective: Chest X-ray imaging is a relatively cheap and accessible diagnostic tool that can assist in the diagnosis of various conditions, including pneumonia, tuberculosis, COVID-19, and oth-ers. However, the requirement for expert radiologists to view and interpret chest X-ray images can be a bottleneck, especially in remote and deprived areas. Recent advances in machine learning have made possible the automated diagnosis of chest X-ray scans. In this work, we examine the use of a novel Transformer-based deep learning model for the task of chest X-ray image classification. Methods: We first examine the performance of the Vision Transformer (ViT) state-of-the-art image clas-sification machine learning model for the task of chest X-ray image classification, and then propose and evaluate the Input Enhanced Vision Transformer (IEViT), a novel enhanced Vision Transformer model that can achieve improved performance on chest X-ray images associated with various pathologies.Results: Experiments on four chest X-ray image data sets containing various pathologies (tuberculosis, pneumonia, COVID-19) demonstrated that the proposed IEViT model outperformed ViT for all the data sets and variants examined, achieving an F1-score between 96.39% and 100%, and an improvement over ViT of up to +5.82% in terms of F1-score across the four examined data sets. IEViT's maximum sensitivity (recall) ranged between 93.50% and 100% across the four data sets, with an improvement over ViT of up to +3%, whereas IEViT's maximum precision ranged between 97.96% and 100% across the four data sets, with an improvement over ViT of up to +6.41%.Conclusions: Results showed that the proposed IEViT model outperformed all ViT's variants for all the ex-amined chest X-ray image data sets, demonstrating its superiority and generalisation ability. Given the relatively low cost and the widespread accessibility of chest X-ray imaging, the use of the proposed IEViT model can potentially offer a powerful, but relatively cheap and accessible method for assisting diagnosis using chest X-ray images.(c) 2022 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ )","2022-11","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","226","","","","","","","","","","English","","","","WOS:000866229800005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;30<br/>Total Times Cited:&nbsp;&nbsp;33<br/>Cited Reference Count:&nbsp;&nbsp;78</p>","","","Chest radiography; DEEP; Deep learning; DISEASES; Image classification; SEGMENTATION; Vision transformer; X-Rays","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GVVNENRN","journalArticle","2024","Davari, M; Qasem, O; Gao, WN; Blaabjerg, F; Kotsampopoulos, PC; Lauss, G; Hatziargyriou, ND","A Reinforcement-Learning, Optimal Approach to In Situ Power Hardware-in-the-Loop Interface Control for Testing Inverter-Based Resources: Theory and Application of the Adaptive Dynamic Programming Based on the Hybrid Iteration to Tackle Uncertain Dynamics","IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS","","0278-0046","10.1109/TIE.2024.3426038","","Testing inverter-based resources (IBRs) is of utmost importance. This paper proposes a novel power hardware-in-the-loop (PHIL) interface control (PHIL-IC) employing a reinforcement-learning approach based on adaptive dynamic programming (ADP, also known as approximate dynamic programming) to enhance the PHIL-simulation-based testing of IBRs by virtue of an ADP-based method. It deploys output feedback control because of ""unavailable"" or ""uncertain"" dynamics of the entire systems (states and disturbances) linked to IBRs, power amplifiers, all the components associated with the PHIL-simulation-based testing, and their delays; it optimally designs PHIL-IC while considering all uncertainties and unavailable information about all the systems involved. To this end, the proposed ADP-based PHIL-IC utilizes a new hybrid iteration (HI) method, which differs from the traditional ADP strategies; compared with the policy iteration method, the HI algorithm does not require prior knowledge of an admissible control policy. Moreover, with a quadratic rate of convergence, the proposed HI method converges much faster than the value iteration method. Therefore, the proposed HI method saves significant learning time and iterations compared to the value iteration method. Comparing the results of the PHIL-simulation-based testing utilizing the proposed method with those of the proportional-resonant controller (as the conventional PHIL-IC) and the robust PHIL-IC based on mu synthesis (as the current state-of-the-art PHIL-IC) reveals the effectiveness and practicality of the proposed method. Those comparative results are generated by the ideal transformer model (also known as voltage-type interface) commonly used in the PHIL-simulation-based testing and practical cases of the Thevenin equivalent impedance (resistive, resistive-inductive, and inductive ones) of the model of interest associated with the power networks.","2024-11-14","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","","","","","","","","","","","English","","","","WOS:001358267400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Adaptive dynamic programming (ADP, also known as approximate dynamic programming); CONVERTER; DC; DESIGN; hybrid iteration (HI) method/algorithm; inverter-based resources (IBRs); output feedback control; policy iteration (PI) method/algorithm; power hardware-in-the-loop (PHIL); power hardware-in-the-loop interface control (PHIL-IC); power-hardware-in-the-loop-simulation-based (PHIL-simulation-based) testing; ROBUST VECTOR CONTROL; SYSTEMS; value iteration (VI) method/algorithm","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"364VQZ2G","journalArticle","2022","Lin, JW; Chang, RG","Chinese story generation of sentence format control based on multi-channel word embedding and novel data format","SOFT COMPUTING","","1432-7643","10.1007/s00500-021-06548-w","","It is very difficult to generate stories in Chinese language. So far, there is no effective method to generate smooth articles. Here proposed a novel approach to improve the generation of Chinese stories in artificial intelligence, in order that it can effectively control the part-of-speech structure in sentence generation to imitate the writer's writing style. The main proposal consists of three parts. First, the pre-processing of the sentence discards the input as the summary and the output as the text. It uses the format containing < SOS > < MOS > < EOS > for processing and the detailed method is defined in session 4. The second part is for vectorization. Traditional vectorization methods include Word2vec, Fasttext, LexVec and Glove; the different vectorization methods can help data semantic or grammatical understanding. Combining different vectorization methods improves the information of the input data. Therefore, this paper proposes the multi-channel word embedding and the details defined in session 5. The last part contains the optimization of the model architecture and how to control the process of sentence generation effectively. It also rewrites the Bert model proposed by Google to be the proposed model architecture. In addition, the Softmax function had been optimizing to reduce the search time during training and increase the training speed in the model. To make the model have better performance, the necessary training of the generative adversarial network was carried out, and the GAN architecture was revised for the data set, and the detail is defined in session 6. After the model is trained, to effectively control the structure of the generated sentence. This paper proposes a complete generation flowchart. In the process, based on the concept of FP-Tree, all sentences in the data set are built into a tree structure, and the part-of-speech structure of the next sentence is restricted through model generation combined with FP-Tree and the detail is defined in session 7. In addition, the experimental results show that our proposed method can effectively control the results of Chinese story generation and generate sentences with better performance and the detail is defined in session 8.","2022-03","2025-02-26 20:43:32","2025-02-26 20:43:32","","2179-2196","","5","26","","","","","","","","","","English","","","","WOS:000748452900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Chinese story generation method; Data format; FP-Tree; GAN; Multi-channel word embedding; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6JIV9V4R","journalArticle","2024","Parikh, P; Penfield, J; Juaire, M","Automatic identification of incidents involving potential serious injuries and fatalities (PSIF)","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-58824-y","","Safety incidents have always been a crucial risk in work spaces, especially industrial sites. In the last few decades, significant efforts have been dedicated to incident control measures to reduce the rate of safety incidents. Despite all these efforts, the rate of decline in serious injuries and fatalities (SIFs) has been considerably lower than the rate of decline for non-critical incidents. This observation has led to a change of risk reduction paradigm for safety incidents. Under the new paradigm, more focus has been allocated to reducing the rate of critical/SIF incidents, as opposed to reducing the count of all incidents. One of the challenges in reducing the number of SIF incidents is the proper identification of the risk prior to materialization. One of the reasons for risk identification being a challenge is that companies usually only focus on incidents where SIF did occur reactively, and incidents that did not cause SIF but had the potential to do so go unnoticed. Identifying these potentially significant incidents, referred to as potential serious injuries and fatalities (PSIF), would enable companies to work on identifying critical risk and taking steps to prevent them preemptively. However, flagging PSIF incidents requires all incident reports to be analyzed individually by experts and hence significant investment, which is often not affordable, especially for small and medium sized companies. This study is aimed at addressing this problem through machine learning powered automation. We propose a novel approach based on binary classification for the identification of such incidents involving PSIF (potential serious injuries and fatalities). This is the first work towards automatic risk identification from incident reports. Our approach combines a pre-trained transformer model with XGBoost. We utilize advanced natural language processing techniques to encode an incident record comprising heterogeneous fields into a vector representation fed to XGBoost for classification. Moreover, given the scarcity of manually labeled incident records available for training, we leverage weak labeling to augment the label coverage of the training data. We utilize the F2 metric for hyperparameter tuning using Tree-structured Parzen Estimator to prioritize the detection of PSIF records over the avoidance of non-PSIF records being mis-classified as PSIF. The proposed methods outperform several baselines from other studies on a significantly large test dataset.","2024-04-06","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","1","14","","","","","","","","","","English","","","","WOS:001216187600029","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Natural language processing; Potential serious injuries and fatalities; Risk assessment; Risk identification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RABWTGNU","journalArticle","2024","Vit, AP; Magid, A","Differences in Fear and Negativity Levels Between Formal and Informal Health-Related Websites: Analysis of Sentiments and Emotions","JOURNAL OF MEDICAL INTERNET RESEARCH","","1438-8871","10.2196/55151","","Background: Searching for web-based health-related information is frequently performed by the public and may affect public behavior regarding health decision-making. Particularly, it may result in anxiety, erroneous, and harmful self-diagnosis. Most searched health-related topics are cancer, cardiovascular diseases, and infectious diseases. A health-related web-based search may result in either formal or informal medical website, both of which may evoke feelings of fear and negativity. Objective: Our study aimed to assess whether there is a difference in fear and negativity levels between information appearing on formal and informal health-related websites. Methods: A web search was performed to retrieve the contents of websites containing symptoms of selected diseases, using selected common symptoms. Retrieved websites were classified into formal and informal websites. Fear and negativity of each content were evaluated using 3 transformer models. A fourth transformer model was fine-tuned using an existing emotion data set obtained from a web-based health community. For formal and informal websites, fear and negativity levels were aggregated. t tests were conducted to evaluate the differences in fear and negativity levels between formal and informal websites. Results: In this study, unique websites (N=1448) were collected, of which 534 were considered formal and 914 were considered informal. There were 1820 result pages from formal websites and 1494 result pages from informal websites. According to our findings, fear levels were statistically higher (t(2753)=3.331; P<.001) on formal websites (mean 0.388, SD 0.177) than on informal websites (mean 0.366, SD 0.168). The results also show that the level of negativity was statistically higher (t(2753)=2.726; P=.006) on formal websites (mean 0.657, SD 0.211) than on informal websites (mean 0.636, SD 0.201). Conclusions: Positive texts may increase the credibility of formal health websites and increase their usage by the general public and the public's compliance to the recommendations. Increasing the usage of natural language processing tools before publishing health-related information to achieve a more positive and less stressful text to be disseminated to the public is recommended.","2024-08-09","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","26","","","","","","","","","","English","","","","WOS:001304921800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","ANXIETY; emotions; fear; health websites; ONLINE; PUBLIC-HEALTH; sentiment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W7HIE8EI","journalArticle","2024","Gan, S; Fu, JY; Zhao, G; Chan, P; He, Y","Short-term prediction of tropical cyclone track and intensity via four mainstream deep learning techniques","JOURNAL OF WIND ENGINEERING AND INDUSTRIAL AERODYNAMICS","","0167-6105","10.1016/j.jweia.2023.105633","","Tropical cyclone (TC) is a highly destructive natural disaster, whose impact is closely correlated to its track and intensity. Thus, it is crucial to obtain the information on TC track and intensity both timely and accurately for early warning and mitigation of related disasters. While there are numerous prediction methods, deep learning (DL) technology has demonstrated exceptional potential in recent years. However, studies on TC prediction via DL techniques are still insufficient, and in particular there is a lack of efforts toward the dependence of prediction results upon some key parameters involved in the prediction strategy. To this end, this paper present a comprehensive study on TC prediction via four mainstream DL techniques, i.e., Long Short-Term Memory (LSTM) network, Convolutional LSTM (CovnLSTM) network, Temporal Convolutional Network (TCN), and the recently developed Transformer model. The performance of different DL techniques is examined, with a highlight on the effects of three setting parameters involved in the prediction process on the model performance, i.e., length of input records N-in, interval between input records Delta T, and lead time of the prediction N-out. Results reveal that TCN performs best from the perspectives of prediction accuracy, running efficiency and stability, followed by ConvLSTM; whilst LSTM and Transformer fail to provide competitive predictions, although Transformer showcases notable training efficiency. In reference to the prediction strategy, increasing Delta T and N-out can consistently enlarge prediction errors across all models, while the model performance can be optimized by setting the value of N-in in a range of 3-6. It is interesting to find that the overall performance of all models can be improved noticeably by using records with a finer Delta T in the scenarios with the same lead time but with varied N-out. Meanwhile, TCN can be further improved by extending N-out from N-out = m to N-out = n (n > m) and using the m-th step prediction in the scenario with N-out = n as the output in the scenario with N-out = m. The presented results provide useful insights for reasonably utilizing DL models to deal with prediction issues, which are applicable not only for TCs but also for other objectives that are widely concerned in wind engineering, e.g., wind speed/pressure and structural responses.","2024-01","2025-02-26 20:43:32","2025-02-26 20:43:32","","","","","244","","","","","","","","","","English","","","","WOS:001165937800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Deep learning; IDENTIFICATION; Prediction strategy; Short-term prediction; Tropical cyclone","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GSMDBZZN","journalArticle","2023","Cao, LP; Wang, Q; Hong, JW; Han, YZ; Zhang, WC; Zhong, X; Che, YQ; Ma, YQ; Du, KY; Wu, DY; Pang, TX; Wu, J; Liang, KW","MVI-TR: A Transformer-Based Deep Learning Model with Contrast-Enhanced CT for Preoperative Prediction of Microvascular Invasion in Hepatocellular Carcinoma","CANCERS","","2072-6694","10.3390/cancers15051538","","Simple Summary For early-stage hepatocellular carcinoma (HCC) (size <= 5 cm), the prediction of microvascular invasion (MVI) before operation is important for the therapeutic strategy. This study aimed to construct deep learning (DL) models based only on the venous phase (VP) of contrast-enhanced computed tomography (CECT), and to evaluate the performance of these models for preoperative prediction of MVI. A novel transformer-based end-to-end DL model is proposed for the first time, named MVI-TR, to capture features automatically from radiomics and to perform MVI preoperative assessments. For patient cohorts, it achieved superior outcomes in six performance measures of MVI predication status: accuracy, precision, receiver operating characteristic (ROC), area under the curve (AUC), recalling rate, and F1-score. In this study, we considered preoperative prediction of microvascular invasion (MVI) status with deep learning (DL) models for patients with early-stage hepatocellular carcinoma (HCC) (tumor size <= 5 cm). Two types of DL models based only on venous phase (VP) of contrast-enhanced computed tomography (CECT) were constructed and validated. From our hospital (First Affiliated Hospital of Zhejiang University, Zhejiang, P.R. China), 559 patients, who had histopathological confirmed MVI status, participated in this study. All preoperative CECT were collected, and the patients were randomly divided into training and validation cohorts at a ratio of 4:1. We proposed a novel transformer-based end-to-end DL model, named MVI-TR, which is a supervised learning method. MVI-TR can capture features automatically from radiomics and perform MVI preoperative assessments. In addition, a popular self-supervised learning method, the contrastive learning model, and the widely used residual networks (ResNets family) were constructed for fair comparisons. With an accuracy of 99.1%, a precision of 99.3%, an area under the curve (AUC) of 0.98, a recalling rate of 98.8%, and an F1-score of 99.1% in the training cohort, MVI-TR achieved superior outcomes. Additionally, the validation cohort's MVI status prediction had the best accuracy (97.2%), precision (97.3%), AUC (0.935), recalling rate (93.1%), and F1-score (95.2%). MVI-TR outperformed other models for predicting MVI status, and showed great preoperative predictive value for early-stage HCC patients.","2023-03","2025-02-26 20:43:33","2025-02-26 20:43:33","","","","5","15","","","","","","","","","","English","","","","WOS:000947033900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","contrast-enhanced computed tomography; deep learning; LIVER RESECTION; microvascular invasion; NOMOGRAM; OUTCOMES; transformer model; VALIDATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VKZPYBBK","journalArticle","2025","Elforaici, ME; Montagnon, E; Romero, FP; Le, WT; Azzi, F; Trudel, D; Nguyen, B; Turcotte, S; Tang, A; Kadoury, S","Semi-supervised ViT knowledge distillation network with style transfer normalization for colorectal liver metastases survival prediction","MEDICAL IMAGE ANALYSIS","","1361-8415","10.1016/j.media.2024.103346","","Colorectal liver metastases (CLM) affect almost half of all colon cancer patients and the response to systemic chemotherapy plays a crucial role in patient survival. While oncologists typically use tumor grading scores, such as tumor regression grade (TRG), to establish an accurate prognosis on patient outcomes, including overall survival (OS) and time-to-recurrence (TTR), these traditional methods have several limitations. They are subjective, time-consuming, and require extensive expertise, which limits their scalability and reliability. Additionally, existing approaches for prognosis prediction using machine learning mostly rely on radiological imaging data, but recently histological images have been shown to be relevant for survival predictions by allowing to fully capture the complex microenvironmental and cellular characteristics of the tumor. To address these limitations, we propose an end-to-end approach for automated prognosis prediction using histology slides stained with Hematoxylin and Eosin (H&E) and Hematoxylin Phloxine Saffron (HPS). We first employ a Generative Adversarial Network (GAN) for slide normalization to reduce staining variations and improve the overall quality of the images that are used as input to our prediction pipeline. We propose a semi-supervised model to perform tissue classification from sparse annotations, producing segmentation and feature maps. Specifically, we use an attention-based approach that weighs the importance of different slide regions in producing the final classification results. Finally, we exploit the extracted features for the metastatic nodules and surrounding tissue to train a prognosis model. In parallel, we train a vision Transformer model in a knowledge distillation framework to replicate and enhance the performance of the prognosis prediction. We evaluate our approach on an in-house clinical dataset of 258 CLM patients, achieving superior performance compared to other comparative models with a c-index of 0.804 (0.014) for OS and 0.735 (0.016) for TTR, as well as on two public datasets. The proposed approach achieves an accuracy of 86.9% to 90.3% in predicting TRG dichotomization. For the 3-class TRG classification task, the proposed approach yields an accuracy of 78.5% to 82.1%, outperforming the comparative methods. Our proposed pipeline can provide automated prognosis for pathologists and oncologists, and can greatly promote precision medicine progress in managing CLM patients.","2025-01","2025-02-26 20:43:33","2025-02-26 20:43:33","","","","","99","","","","","","","","","","English","","","","WOS:001338905100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;77</p>","","","Colorectal liver metastases; Deep learning; Histopathology; Outcome prognosis prediction; Semi-supervised learning; Slide normalization; Tumor regression grade; TUMOR-REGRESSION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QGCXUS3V","journalArticle","2024","Miranda, O; Kiehl, SM; Qi, XG; Brannock, MD; Kosten, T; Ryan, ND; Kirisci, L; Wang, YS; Wang, LR","Enhancing post-traumatic stress disorder patient assessment: leveraging natural language processing for research of domain criteria identification using electronic medical records","BMC MEDICAL INFORMATICS AND DECISION MAKING","","1472-6947","10.1186/s12911-024-02554-8","","Background Extracting research of domain criteria (RDoC) from high-risk populations like those with post-traumatic stress disorder (PTSD) is crucial for positive mental health improvements and policy enhancements. The intricacies of collecting, integrating, and effectively leveraging clinical notes for this purpose introduce complexities.Methods In our study, we created a natural language processing (NLP) workflow to analyze electronic medical record (EMR) data and identify and extract research of domain criteria using a pre-trained transformer-based natural language model, all-mpnet-base-v2. We subsequently built dictionaries from 100,000 clinical notes and analyzed 5.67 million clinical notes from 38,807 PTSD patients from the University of Pittsburgh Medical Center. Subsequently, we showcased the significance of our approach by extracting and visualizing RDoC information in two use cases: (i) across multiple patient populations and (ii) throughout various disease trajectories.Results The sentence transformer model demonstrated high F1 macro scores across all RDoC domains, achieving the highest performance with a cosine similarity threshold value of 0.3. This ensured an F1 score of at least 80% across all RDoC domains. The study revealed consistent reductions in all six RDoC domains among PTSD patients after psychotherapy. We found that 60.6% of PTSD women have at least one abnormal instance of the six RDoC domains as compared to PTSD men (51.3%), with 45.1% of PTSD women with higher levels of sensorimotor disturbances compared to men (41.3%). We also found that 57.3% of PTSD patients have at least one abnormal instance of the six RDoC domains based on our records. Also, veterans had the higher abnormalities of negative and positive valence systems (60% and 51.9% of veterans respectively) compared to non-veterans (59.1% and 49.2% respectively). The domains following first diagnoses of PTSD were associated with heightened cue reactivity to trauma, suicide, alcohol, and substance consumption.Conclusions The findings provide initial insights into RDoC functioning in different populations and disease trajectories. Natural language processing proves valuable for capturing real-time, context dependent RDoC instances from extensive clinical notes.","2024-06-04","2025-02-26 20:43:33","2025-02-26 20:43:33","","","","1","24","","","","","","","","","","English","","","","WOS:001238679900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","ALCOHOL; Clinical notes; Natural language processing; Post-traumatic stress disorder; PTSD; Real-world evidence; Research of domain criteria; SYMPTOM SEVERITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CZKM48G6","journalArticle","2024","Gangwar, A; Dhaka, VS; Rani, G; Khandelwal, S; Zumpano, E; Vocaturo, E","Time and Space Efficient Multi-Model Convolution Vision Transformer for Tomato Disease Detection from Leaf Images with Varied Backgrounds","CMC-COMPUTERS MATERIALS & CONTINUA","","1546-2218","10.32604/cmc.2024.048119","","A consumption of 46.9 million tons of processed tomatoes was reported in 2022 which is merely 20% of the total consumption. An increase of 3.3% in consumption is predicted from 2024 to 2032. Tomatoes are also rich in iron, potassium, antioxidant lycopene, vitamins A, C and K which are important for preventing cancer, and maintaining blood pressure and glucose levels. Thus, tomatoes are globally important due to their widespread usage and nutritional value. To face the high demand for tomatoes, it is mandatory to investigate the causes of crop loss and minimize them. Diseases are one of the major causes that adversely affect crop yield and degrade the quality of the tomato fruit. This leads to financial losses and affects the livelihood of farmers. Therefore, automatic disease detection at any stage of the tomato plant is a critical issue. Deep learning models introduced in the literature show promising results, but the models are difficult to implement on handheld devices such as mobile phones due to high computational costs and a large number of parameters. Also, most of the models proposed so far work efficiently for images with plain backgrounds where a clear demarcation exists between the background and leaf region. Moreover, the existing techniques lack in recognizing multiple diseases on the same leaf. To address these concerns, we introduce a customized deep learning-based convolution vision transformer model. The model achieves an accuracy of 93.51% for classifying tomato leaf images with plain as well as complex backgrounds into 13 categories. It requires a space storage of merely 5.8 MB which is 98.93%, 98.33%, and 92.64% less than stateof-the-art visual geometry group, vision transformers, and convolution vision transformer models, respectively. Its training time of 44 min is 51.12%, 74.12%, and 57.7% lower than the above-mentioned models. Thus, it can be deployed on (Internet of Things) IoT-enabled devices, drones, or mobile devices to assist farmers in the real -time monitoring of tomato crops. The periodic monitoring promotes timely action to prevent the spread of diseases and reduce crop loss.","2024","2025-02-26 20:43:33","2025-02-26 20:43:33","","117-142","","1","79","","","","","","","","","","English","","","","WOS:001225035600006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","CLASSIFICATION; deep learning; disease; IDENTIFICATION; mobile devices; Tomato; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""