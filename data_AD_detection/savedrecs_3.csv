"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"335YQZAE","journalArticle","2024","Azimi, M; Yang, TY","Transformer-based framework for accurate segmentation of high-resolution images in structural health monitoring","COMPUTER-AIDED CIVIL AND INFRASTRUCTURE ENGINEERING","","1093-9687","10.1111/mice.13211","","High-resolution image segmentation is essential in structural health monitoring (SHM), enabling accurate detection and quantification of structural components and damages. However, conventional convolutional neural network-based segmentation methods face limitations in real-world deployment, particularly when handling high-resolution images producing low-resolution outputs. This study introduces a novel framework named Refined-Segment Anything Model (R-SAM) to overcome such challenges. R-SAM leverages the state-of-the-art zero-shot SAM to generate unlabeled segmentation masks, subsequently employing the DEtection Transformer model to label the instances. The key feature and contribution of the R-SAM is its refinement module, which improves the accuracy of masks generated by SAM without the need for extensive data annotations and fine-tuning. The effectiveness of the proposed framework was assessed through qualitative and quantitative analyses across diverse case studies, including multiclass segmentation, simultaneous segmentation and tracking, and 3D reconstruction. The results demonstrate that R-SAM outperforms state-of-the-art convolution neural network-based segmentation models with a mean intersection-over-union of 97% and a mean boundary accuracy of 87%. In addition, achieving high coefficients of determination in target-free tracking case studies highlights its versatility in addressing various challenges in SHM.","2024-12","2025-02-26 20:41:48","2025-02-26 20:41:48","","3670-3684","","24","39","","","","","","","","","","English","","","","WOS:001205446000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5Y5TNY39","journalArticle","2024","Demiray, BZ; Sit, M; Mermer, O; Demir, I","Enhancing hydrological modeling with transformers: a case study for 24-h streamflow prediction","WATER SCIENCE AND TECHNOLOGY","","0273-1223","10.2166/wst.2024.110","","In this paper, we address the critical task of 24-h streamflow forecasting using advanced deep-learning models, with a primary focus on the Transformer architecture which has seen limited application in this specific task. We compare the performance of five different models, including Persistence, long short-term memory (LSTM), Seq2Seq, GRU, and Transformer, across four distinct regions. The evaluation is based on three performance metrics: Nash-Sutcliffe Efficiency (NSE), Pearson's r, and normalized root mean square error (NRMSE). Additionally, we investigate the impact of two data extension methods: zero-padding and persistence, on the model's predictive capabilities. Our findings highlight the Transformer's superiority in capturing complex temporal dependencies and patterns in the streamflow data, outperforming all other models in terms of both accuracy and reliability. Specifically, the Transformer model demonstrated a substantial improvement in NSE scores by up to 20% compared to other models. The study's insights emphasize the significance of leveraging advanced deep learning techniques, such as the Transformer, in hydrological modeling and streamflow forecasting for effective water resource management and flood prediction.","2024-05-01","2025-02-26 20:41:49","2025-02-26 20:41:49","","2326-2341","","9","89","","","","","","","","","","English","","","","WOS:001196683400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","deep learning; flood forecasting; MACHINE; machine learning; rainfall-runoff modeling; streamflow forecasting; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8IWRABF3","journalArticle","2024","Burrichter, B; da Silva, JK; Niemann, A; Quirmbach, M","A Temporal Fusion Transformer Model to Forecast Overflow from Sewer Manholes during Pluvial Flash Flood Events","HYDROLOGY","","2306-5338","10.3390/hydrology11030041","","This study employs a temporal fusion transformer (TFT) for predicting overflow from sewer manholes during heavy rainfall events. The TFT utilised is capable of forecasting overflow hydrographs at the manhole level and was tested on a sewer network with 975 manholes. As part of the investigations, the TFT was compared to other deep learning architectures to evaluate its predictive performance. In addition to precipitation measurements and forecasts, the issue of how the additional consideration of measurements in the sewer network as model inputs impacts forecast accuracy was investigated. A varying number of sensors and different measurement signals were compared. The results indicate high performance for the TFT compared to other model architectures like a long short-term memory (LSTM) network or a dual-stage attention-based recurrent neural network (DA-RNN). Additionally, results suggest that considering a single measuring point at the outlet of the sewer network instead of an entire measuring network yields better forecasts. One possible explanation is the high correlation between measurements, which increases model and training complexity without adding much value.","2024-03","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","3","11","","","","","","","","","","English","","","","WOS:001192607300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","deep learning; manhole overflow; real-time flood forecasting; SHORT-TERM-MEMORY; temporal fusion transformer; URBAN; urban drainage system; urban pluvial flooding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BUTEEH6B","journalArticle","2023","Zharova, MA; Tsurkov, VI","Neural Network Approaches for Recommender Systems","JOURNAL OF COMPUTER AND SYSTEMS SCIENCES INTERNATIONAL","","1064-2307","10.1134/S1064230723060126","","Recommender systems are special algorithms that allow users to receive personalized recommendations on topics that interest them. Systems of this kind are widely used in various fields, for example, in e-commerce, provider services, social networks, etc. Together with classical approaches, neural networks have also become popular in recommender systems in recent years, which are gradually replacing traditional methods of collaborative filtering and content-based algorithms. However, neural networks require large computing resources, which often raises questions on whether an increase in quality will be justified and whether there be one at all. The neural network approach in recommender systems-the self-attentive sequential recommendation (SASRec) transformer model from Microsoft Recommenders-is studied and compared with the classic algorithm, the LightFM hybrid model. For training and validation, the data taken from a housing search application are used. It is proposed to use the hit rate as the main metric for comparison. The results of the experiments will help to understand which algorithms have higher accuracy in terms of predictions and recommendations. As an additional part, the clustering of user and object embeddings is considered.","2023-12","2025-02-26 20:41:49","2025-02-26 20:41:49","","1048-1062","","6","62","","","","","","","","","","English","","","","WOS:001141428800012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;14</p>","","","collaborative filtering; matrix factorization; neural networks; recommender systems; users and objects","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4R56REWI","journalArticle","2023","Zhang, C; Liu, ST; Guo, MZ; Liu, YC","A novel ship trajectory clustering analysis and anomaly detection method based on AIS data","OCEAN ENGINEERING","","0029-8018","10.1016/j.oceaneng.2023.116082","","The increasing volume of ship traffic has resulted in new challenges for the supervision of maritime safety administration. The conventional manual monitoring approach for maritime traffic is inefficient and lacks specifics, particularly for supervising ships with abnormal trajectories. To address this issue, this study proposes utilizing the minimum description length criterion to extract features from ship trajectory data provided by the automatic identification system (AIS). This approach simplifies the compression of ship trajectories. Additionally, the dynamic time warping trajectory similarity measurement algorithm is employed to optimize the density-based spatial clustering of applications with noise algorithm. This optimization enables the clustering of ship trajectories and the acquisition of normalized ship motion trajectories. Furthermore, a ship trajectory prediction method based on a transformer model is proposed, and the normalized motion trajectory is used as the training set for model training. The trained ship trajectory prediction model is subsequently utilized to predict the target ship trajectory. The AIS ship trajectory data in the vicinity of Yantai Port were used for experimental verification. The results demonstrate the effectiveness of the proposed approach in identifying abnormal ship trajectories.","2023-11-15","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","288","","","","","","","","","","English","","","","WOS:001104327300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Dynamic time warping; Minimum description length; MODEL; Ship trajectory; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9V43943H","journalArticle","2023","Jeon, H; Park, S; Kim, JG; Kang, U","PET: Parameter-efficient Knowledge Distillation on Transformer","PLOS ONE","","1932-6203","10.1371/journal.pone.0288060","","Given a large Transformer model, how can we obtain a small and computationally efficient model which maintains the performance of the original model? Transformer has shown significant performance improvements for many NLP tasks in recent years. However, their large size, expensive computational cost, and long inference time make it challenging to deploy them to resource-constrained devices. Existing Transformer compression methods mainly focus on reducing the size of the encoder ignoring the fact that the decoder takes the major portion of the long inference time. In this paper, we propose PET (Parameter-Efficient knowledge distillation on Transformer), an efficient Transformer compression method that reduces the size of both the encoder and decoder. In PET, we identify and exploit pairs of parameter groups for efficient weight sharing, and employ a warm-up process using a simplified task to increase the gain through Knowledge Distillation. Extensive experiments on five real-world datasets show that PET outperforms existing methods in machine translation tasks. Specifically, on the IWSLT'14 EN & RARR;DE task, PET reduces the memory usage by 81.20% and accelerates the inference speed by 45.15% compared to the uncompressed model, with a minor decrease in BLEU score of 0.27.","2023-07-06","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","7","18","","","","","","","","","","English","","","","WOS:001025358100006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9TPLKBEU","journalArticle","2023","Moratelli, N; Barraco, M; Morelli, D; Cornia, M; Baraldi, L; Cucchiara, R","Fashion-Oriented Image Captioning with External Knowledge Retrieval and Fully Attentive Gates","SENSORS","","1424-8220","10.3390/s23031286","","Research related to fashion and e-commerce domains is gaining attention in computer vision and multimedia communities. Following this trend, this article tackles the task of generating fine-grained and accurate natural language descriptions of fashion items, a recently-proposed and under-explored challenge that is still far from being solved. To overcome the limitations of previous approaches, a transformer-based captioning model was designed with the integration of external textual memory that could be accessed through k-nearest neighbor (kNN) searches. From an architectural point of view, the proposed transformer model can read and retrieve items from the external memory through cross-attention operations, and tune the flow of information coming from the external memory thanks to a novel fully attentive gate. Experimental analyses were carried out on the fashion captioning dataset (FACAD) for fashion image captioning, which contains more than 130k fine-grained descriptions, validating the effectiveness of the proposed approach and the proposed architectural strategies in comparison with carefully designed baselines and state-of-the-art approaches. The presented method constantly outperforms all compared approaches, demonstrating its effectiveness for fashion image captioning.","2023-02","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","3","23","","","","","","","","","","English","","","","WOS:000929612500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","fashion captioning; image captioning; knowledge retrieval; TRANSFORMER; vision-and-language","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ISS6I47W","journalArticle","2023","Bhagavathsingh, B; Sathish, AV; Kalaiselvan, A; John, CE","Build Your Own Band (BYOB): Generating instrumental accompaniments for a melody","ROMANIAN JOURNAL OF INFORMATION TECHNOLOGY AND AUTOMATIC CONTROL-REVISTA ROMANA DE INFORMATICA SI AUTOMATICA","","1220-1758","10.33436/v33i4y202308","","Artificial Intelligence (AI) has led to advancements in multiple fields of research, and music has always been a field of high interest. Music is an important part of life and various studies have shown the link between better living and listening to music. From completing melodies to composing music from scratch, there are many applications of AI in this domain. This paper aims to analyse one such application of using AI for music generation, specifically for instrumental accompaniment. Instrumental accompaniment is essentially the instrumental music that is composed to support or complement a melody. Creating instrumental accompaniment for music generally requires extensive musical knowledge or forming a band together with skilled instrumentalists. Build Your Own Band (BYOB) attempts to simplify this process with the help of AI. In this research work, three transformer models are employed for training various accompanying instruments. Here, the proposed transformer model accepts a melody line as input and produces an accompanying track with instruments like bass instruments, the guitar and string instruments. One of the main challenges was to make sure that these instruments produce a cohesive sound.","2023","2025-02-26 20:41:49","2025-02-26 20:41:49","","99-108","","4","33","","","","","","","","","","English","","","","WOS:001126126300004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;13</p>","","","Artificial Intelligence; Music Generation Typesetting and Structure.; Seq2Seq; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B27GZGSX","journalArticle","2024","Miok, K; Tenorio, EH; Osenova, P; Benítez-Castro, MA; Robnik-Sikonja, M","Multi-aspect multilingual and cross-lingual parliamentary speech analysis","INTELLIGENT DATA ANALYSIS","","1088-467X","10.3233/IDA-227347","","Parliamentary and legislative debate transcripts provide an informative insight into elected politicians' opinions, positions, and policy preferences. They are interesting for political and social sciences as well as linguistics and natural language processing (NLP) research. While exiting research studied individual parliaments, we apply advanced NLP methods to a joint and comparative analysis of six national parliaments (Bulgarian, Czech, French, Slovene, Spanish, and United Kingdom) between 2017 and 2020. We analyze emotions and sentiment in the transcripts from the ParlaMint dataset collection, and assess if the age, gender, and political orientation of speakers can be detected from their speeches. The results show some commonalities and many surprising differences among the analyzed countries.","2024","2025-02-26 20:41:49","2025-02-26 20:41:49","","239-260","","1","28","","","","","","","","","","English","","","","WOS:001193411600012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","AGE; cross-lingual analysis; deep learning; emotion detection; GENDER; metadata prediction; natural language processing; ParlaMint corpora; Parliamentary debates; PARTIES; POLITICS; sentiment analysis; SENTIMENT ANALYSIS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ED8BJGL4","journalArticle","2024","Arshad, T; Zhang, JP","A Light-Weighted Spectral-Spatial Transformer Model for Hyperspectral Image Classification","IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING","","1939-1404","10.1109/JSTARS.2024.3419070","","Classifying hyperspectral images in remote sensing applications is challenging due to limited training samples and high dimensionality of data. Deep-learning-based methods have recently demonstrated promising results in the classification of HSI. This article presents a proposed methodology for extracting local features and high-level semantic features from HSI input data using a light-weighted spectral-spatial transformer. This approach will allow us to comprehensively examine the spatial and spectral characteristics while reducing the computing expenses. The proposed model integrates lightweight multihead self-attention and residual feedforward modules in order to effectively capture long-range dependencies and address the computational challenges associated with this model. In order to assess the efficiency of the proposed model, we conducted experiments on four publicly available datasets. The obtained experimental results were then compared with those of the existing state-of-the-art models. The proposed model obtains the best classification results in terms of classification accuracy and computational complexity under limited training samples. The overall accuracy of the proposed model achieved 99.91, 98.06, 99.43 and 99.01 on four datasets.","2024","2025-02-26 20:41:49","2025-02-26 20:41:49","","12008-12019","","","17","","","","","","","","","","English","","","","WOS:001270275700020","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Convolutional neural network (CNN); hyperspectral image (HSI) classification; lightweight multihead self-attention; NETWORKS; vision transformers (ViTs)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TAPUBWL8","journalArticle","2023","Jia, YJ; Huang, Z; Luo, K; Wen, WL","Lightweight Joint Source-Channel Coding for Semantic Communications","IEEE COMMUNICATIONS LETTERS","","1089-7798","10.1109/LCOMM.2023.3329533","","Semantic communications, which aim to effectively convey the meaning of messages (such as text and images) rather than transmitting the exact messages themselves, have garnered widespread attention from industry and academia. A suitable joint source-channel coding (JSCC) scheme is crucial for semantic communication systems, as it can significantly improve system performance, such as communication reliability. Current research efforts primarily focus on employing various deep neural network (DNN) models, particularly the Transformer model, to design JSCC schemes. However, existing Transformer-based JSCC schemes usually exhibit a considerable number of model parameters and computational demands, limiting their real-world applicability. To address this challenge, we propose a novel DNN model based on DeLighT, a deep and lightweight variant of the standard Transformer, using a text semantic communication system (TSC) as an example. This proposed model enables a lightweight JSCC scheme for the TSC system. Through simulation results, we demonstrate that the proposed JSCC scheme achieves comparable or better communication reliability than the Transformer-based JSCC scheme while requiring significantly fewer parameters and smaller runtime.","2023-12","2025-02-26 20:41:49","2025-02-26 20:41:49","","3161-3165","","12","27","","","","","","","","","","English","","","","WOS:001126149900010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;15</p>","","","Decoding; deep neural network; joint source-channel coding; lightweight; Neural networks; Receivers; Reliability; Semantic communications; Semantics; transformer; Transformers; Transmitters","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EN8553YX","journalArticle","2023","Manzari, ON; Ahmadabadi, H; Kashiani, H; Shokouhi, SB; Ayatollahi, A","MedViT: A robust vision transformer for generalized medical image classification","COMPUTERS IN BIOLOGY AND MEDICINE","","0010-4825","10.1016/j.compbiomed.2023.106791","","Convolutional Neural Networks (CNNs) have advanced existing medical systems for automatic disease di-agnosis. However, there are still concerns about the reliability of deep medical diagnosis systems against the potential threats of adversarial attacks since inaccurate diagnosis could lead to disastrous consequences in the safety realm. In this study, we propose a highly robust yet efficient CNN-Transformer hybrid model which is equipped with the locality of CNNs as well as the global connectivity of vision Transformers. To mitigate the high quadratic complexity of the self-attention mechanism while jointly attending to information in various representation subspaces, we construct our attention mechanism by means of an efficient convolution operation. Moreover, to alleviate the fragility of our Transformer model against adversarial attacks, we attempt to learn smoother decision boundaries. To this end, we augment the shape information of an image in the high-level feature space by permuting the feature mean and variance within mini-batches. With less computational complexity, our proposed hybrid model demonstrates its high robustness and generalization ability compared to the state-of-the-art studies on a large-scale collection of standardized MedMNIST-2D datasets.","2023-05","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","157","","","","","","","","","","English","","","","WOS:000959642300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;81<br/>Total Times Cited:&nbsp;&nbsp;82<br/>Cited Reference Count:&nbsp;&nbsp;83</p>","","","Adversarial attack; Adversarial robustness; Medical image classification; NETWORK; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RI66BBRI","journalArticle","2023","Dang, LX; Weng, LB; Hou, YN; Zuo, XY; Liu, Y","Double-branch feature fusion transformer for hyperspectral image classification","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-023-27472-z","","Deep learning methods, particularly Convolutional Neural Network (CNN), have been widely used in hyperspectral image (HSI) classification. CNN can achieve outstanding performance in the field of HSI classification due to its advantages of fully extracting local contextual features of HSI. However, CNN is not good at learning the long-distance dependency relation and dealing with the sequence properties of HSI. Thus, it is difficult to continuously improve the performance of CNN-based models because they cannot take full advantage of the rich and continuous spectral information of HSI. This paper proposes a new Double-Branch Feature Fusion Transformer model for HSI classification. We introduce Transformer into the process of HSI on account of HSI with sequence characteristics. The two branches of the model extract the global spectral features and global spatial features of HSI respectively, and fuse both spectral and spatial features through a feature fusion layer. Furthermore, we design two attention modules to adaptively adjust the importance of spectral bands and pixels for classification in HSI. Experiments and comparisons are carried out on four public datasets, and the results demonstrate that our model outperforms any compared CNN-Based models in terms of accuracy.","2023-01-06","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","1","13","","","","","","","","","","English","","","","WOS:000909767900016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","INDEXES; NETWORK; SPECTRAL-SPATIAL CLASSIFICATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TCA7TTG6","journalArticle","2022","Qiao, HR; Wu, YJ; Zhang, Y; Zhang, CY; Wu, XY; Wu, ZP; Zhao, QJ; Wang, XQ; Li, HY; Duan, HL","Transformer-based multitask learning for reaction prediction under low-resource circumstances","RSC ADVANCES","","2046-2069","10.1039/d2ra05349g","","Recently, effective and rapid deep-learning methods for predicting chemical reactions have significantly aided the research and development of organic chemistry and drug discovery. Owing to the insufficiency of related chemical reaction data, computer-assisted predictions based on low-resource chemical datasets generally have low accuracy despite the exceptional ability of deep learning in retrosynthesis and synthesis. To address this issue, we introduce two types of multitask models: retro-forward reaction prediction transformer (RFRPT) and multiforward reaction prediction transformer (MFRPT). These models integrate multitask learning with the transformer model to predict low-resource reactions in forward reaction prediction and retrosynthesis. Our results demonstrate that introducing multitask learning significantly improves the average top-1 accuracy, and the RFRPT (76.9%) and MFRPT (79.8%) outperform the transformer baseline model (69.9%). These results also demonstrate that a multitask framework can capture sufficient chemical knowledge and effectively mitigate the impact of the deficiency of low-resource data in processing reaction prediction tasks. Both RFRPT and MFRPT methods significantly improve the predictive performance of transformer models, which are powerful methods for eliminating the restriction of limited training data.","2022-11-03","2025-02-26 20:41:49","2025-02-26 20:41:49","","32020-32026","","49","12","","","","","","","","","","English","","","","WOS:000881825000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","IDENTIFICATION; MODEL; NEURAL-NETWORK","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZCNWHNSK","journalArticle","2022","Özdemir, Ö; Akin, ES; Velioglu, R; Dalyan, T","A comparative study of neural machine translation models for Turkish language","JOURNAL OF INTELLIGENT & FUZZY SYSTEMS","","1064-1246","10.3233/JIFS-211453","","Machine translation (MT) is an important challenge in the fields of Computational Linguistics. In this study, we conducted neural machine translation (NMT) experiments on two different architectures. First, Sequence to Sequence (Seq2Seq) architecture along with a variation that utilizes attention mechanism is performed on translation task. Second, an architecture that is fully based on the self-attention mechanism, namely Transformer, is employed to perform a comprehensive comparison. Besides, the contribution of employing Byte Pair Encoding (BPE) and Gumbel Softmax distributions are examined for both architectures. The experiments are conducted on two different datasets: TED Talks that is one of the popular benchmark datasets for NMT especially among morphologically rich languages like Turkish and WMT18 News dataset that is provided by The Third Conference on Machine Translation (WMT) for shared tasks on various aspects of machine translation. The evaluation of Turkish-to-English translations' results demonstrate that the Transformer model with combination of BPE and Gumbel Softmax achieved 22.4 BLEU score on TED Talks and 38.7 BLUE score on WMT18 News dataset. The empirical results support that using Gumbel Softmax distribution improves the quality of translations for both architectures.","2022","2025-02-26 20:41:49","2025-02-26 20:41:49","","2103-2113","","3","42","","","","","","","","","","English","","","","WOS:000752849700054","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Gumbel Softmax; Neural machine translation; sequence to sequence; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JMJRDZ2N","journalArticle","2025","Khan, MA; Naqvi, SSA; Faseeh, M; Kim, DH","Transformer-Driven Inverse Learning for AI-Powered Ceramic Material Innovation With Advanced Data Preprocessing","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3519390","","In the advanced landscape of materials science, particularly in the development of ceramic materials, artificial intelligence (AI) emerged as a transformative tool for accelerating innovation. This study proposed a comprehensive analysis of the Transformer-based Inverse Learning model to optimize component and process recommendations. K-Nearest Neighbors (KNN) imputation was first applied, improving data accuracy and completeness to address data gaps. Subsequently, Variational Autoencoders (VAE) were used for data augmentation, enriching the dataset's diversity. The Transformer model, leveraging this enhanced data, demonstrated strong predictive performance, achieving an R2 score of 0.966 for component analysis and an outstanding R2 score of 0.982 for process analysis in Barium Titanate (BaTiO3) material data. These results show the effectiveness of combining imputation, augmentation, and advanced AI modeling in capturing complex material properties. The study highlights the potential of AI-driven methodologies to significantly improve prediction accuracy in material discovery, offering valuable insights for developing future ceramic materials.","2025","2025-02-26 20:41:49","2025-02-26 20:41:49","","7574-7589","","","13","","","","","","","","","","English","","","","WOS:001398321900024","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Accuracy; Artificial intelligence; Artificial intelligence (AI); barium Titanate; ceramic materials; Ceramics; data augmentation; Data augmentation; Data models; FUSION; Imputation; inverse learning; k-nearest neighbors (KNN); materials science; Materials science and technology; Nearest neighbor methods; potassium sodium Niobate; Predictive models; transformer-based model; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E5N33QNT","journalArticle","2024","Pourbehzadi, M; Javidi, G; Howell, CJ; Kamar, E; Sheybani, E","Enhanced (cyber) situational awareness: Using interpretable principal component analysis (iPCA) to automate vulnerability severity scoring","DECISION SUPPORT SYSTEMS","","0167-9236","10.1016/j.dss.2024.114308","","The Common Vulnerability Scoring System (CVSS) is widely used in the cybersecurity industry to assess the severity of vulnerabilities. However, manual assessments and human error can lead to delays and inconsistencies. This study employs situational awareness theory to develop an automated decision support system, integrating perception, comprehension, and projection components to enhance effectiveness. Specifically, an interpretable principal component analysis (iPCA) combined with machine learning is utilized to forecast CVSS scores using text descriptions from the Common Vulnerabilities and Exposures (CVE) database. Different forecasting approaches, including traditional machine learning models, Long-Short Term Memory Neural Networks, and Transformer architectures (ChatGPT) are compared to determine the best performance. The results show that iPCA combined with support vector regression achieves a high performance (R-2 = 98%) in predicting CVSS scores using CVE text descriptions. The results indicate that the variability, length, and details in the vulnerability description contribute to the performance of the transformer model. These findings are consistent across vulnerability descriptions from six companies between 2017 and 2019. The study's outcomes have the potential to enhance organizations' security posture, improving situational awareness and enabling better managerial decision-making in cybersecurity.","2024-11","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","186","","","","","","","","","","English","","","","WOS:001312424500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","CVE; CVSS; Cybersecurity; Machine learning; Situational awareness; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QS4RTUGA","journalArticle","2024","Wang, CY; Liu, GY","From anomaly detection to classification with graph attention and transformer for multivariate time series","ADVANCED ENGINEERING INFORMATICS","","1474-0346","10.1016/j.aei.2024.102357","","Numerous industrial environments and IoT systems in the real world contain a range of sensor devices. These devices, when in operation, produce a large amount of multivariate time series data. These data are interconnected and together reflect the status and changing trends of the devices and environment. To ensure the safety and stability of the working devices, it is of great research value to continuously monitor the generated data and perform accurate and rapid anomaly detection. Moreover, in some emergency situations, after detecting an anomaly, making a preliminary judgment and reporting the type of anomaly can save a lot of precious time and reduce property losses. Therefore, we propose an anomaly detection and classification architecture that can quickly perform sequence modeling. The architecture includes our proposed novel graph learning method and the high -efficiency Transformer model. We use two -stage adversarial training to train the anomaly detection model and apply the model to anomaly classification using a prototype network. Extensive experiments on four public datasets prove that our anomaly detection method outperforms other state-of-the-art methods. We also verify the accuracy of anomaly classification through case studies.","2024-04","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","60","","","","","","","","","","English","","","","WOS:001170752400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","Anomaly detection; Classification; Graph attention; Multivariate time series; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"89MKQLRF","journalArticle","2023","Wei, Y; Bo, LL; Wu, XX; Li, Y; Ye, ZL; Sun, XB; Li, B","VulRep: vulnerability repair based on inducing commits and fixing commits","EURASIP JOURNAL ON WIRELESS COMMUNICATIONS AND NETWORKING","","1687-1472","10.1186/s13638-023-02242-7","","With the rapid development of the information age, software vulnerabilities have threatened the safety of communication and mobile network, and research on vulnerability repair is urgent. Different from the existing machine learning-based approaches, we propose VulRep, a vulnerability repair approach based on vulnerability introduction, which combines empirical research findings on vulnerability inducing and vulnerability fixing commit with machine learning approaches for vulnerability repair. Firstly, we construct the vulnerability introduction and repair dataset, and generate the AST tree for the code of inducing commit and fixing commit to form a sequence after abstraction processing, and input it into the Transformer model to generate a recommendation list through beam search. After filling in the abstracted code, it is combined with the rules defined by empirical research findings, and the final patch is obtained after verification. Experimental results show that VulRep can improve the performance of repairing vulnerabilities, which illustrates the effectiveness of combined empirical research findings. In addition, we found that our approach is more suitable for repairing type CWE-119 (Improper Restriction of Operations within the Bounds of a Memory Buffer) vulnerabilities and can perform vulnerability repair better.","2023-04-21","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","1","2023","","","","","","","","","","English","","","","WOS:000973906400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Patch recommendation; Software vulnerability; Vulnerability fixing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CXSPCZDT","journalArticle","2022","Lv, YH; Wang, CY; Yuan, WT; Qian, XH; Yang, WJ; Zhao, WQ","Transformer-Based Distillation Hash Learning for Image Retrieval","ELECTRONICS","","2079-9292","10.3390/electronics11182810","","In recent years, Transformer has become a very popular architecture in deep learning and has also achieved the same state-of-the-art performance as convolutional neural networks on multiple image recognition baselines. Transformer can obtain global perceptual fields through a self-attention mechanism and can enhance the weights of unique discriminable features for image retrieval tasks to improve the retrieval quality. However, Transformer is computationally intensive and finds it difficult to satisfy real-time requirements when used for retrieval tasks. In this paper, we propose a Transformer-based image hash learning framework and compress the constructed framework to perform efficient image retrieval using knowledge distillation. By combining the self-attention mechanism of the Transformer model, the image hash code is enabled to be global and unique. At the same time, this advantage is instilled into the efficient lightweight model by knowledge distillation, thus reducing the computational complexity and having the advantage of an attention mechanism in the Transformer. The experimental results on the MIRFlickr-25K dataset and NUS-WIDE dataset show that our approach can effectively improve the accuracy and efficiency of image retrieval.","2022-09","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","18","11","","","","","","","","","","English","","","","WOS:000857527300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","hashing learning; image retrieval; knowledge distillation; self-attention; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CCY8KZZU","journalArticle","2024","Di, L; Lv, Z; Chang, H; Cai, JF","Distributed Photovoltaic Communication Anomaly Detection Based on Spatiotemporal Feature Collaborative Modeling","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14219820","","As distributed photovoltaic (PV) technology rapidly develops and is widely applied, the methods of cyberattacks are continuously evolving, posing increasingly severe threats to the communication networks of distributed PV systems. Recent studies have shown that the Transformer model, which effectively integrates global information and handles long-distance dependencies, has garnered significant attention. Based on this, our research proposes a model named STformer, which is applied to the task of attack detection in distributed PV communication. Specifically, we propose a temporal attention mechanism and a variable attention mechanism. The temporal attention mechanism focuses on capturing subtle changes and trends in data sequences over time, ensuring a highly sensitive recognition of patterns inherent in time-series data. In contrast, the variable attention mechanism analyzes the intrinsic relationships and interactions between different variables, uncovering critical correlations that may indicate abnormal behavior or potential attacks. Additionally, we incorporate the Uniform Manifold Approximation and Projection (UMAP) dimensionality reduction technique. This technique not only helps reduce computational complexity but, in certain cases, can enhance anomaly detection performance. Finally, compared to classical and advanced methods, STformer demonstrates satisfactory performance in simulation experiments.","2024-11","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","21","14","","","","","","","","","","English","","","","WOS:001351040100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","attention mechanism; CYBER-ATTACK DETECTION; cyberattack detection; deep learning; FARMS; photovoltaic microgrid; PV; SUPPORT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BIVFSKLG","journalArticle","2024","Ratcliff, J","Transformer model generated bacteriophage genomes are compositionally distinct from natural sequences","NAR GENOMICS AND BIOINFORMATICS","","2631-9268","10.1093/nargab/lqae129","","Novel applications of language models in genomics promise to have a large impact on the field. The megaDNA model is the first publicly available generative model for creating synthetic viral genomes. To evaluate megaDNA's ability to recapitulate the nonrandom genome composition of viruses and assess whether synthetic genomes can be algorithmically detected, compositional metrics for 4969 natural bacteriophage genomes and 1002 de novo synthetic bacteriophage genomes were compared. Transformer-generated sequences had varied but realistic genome lengths, and 58% were classified as viral by geNomad. However, the sequences demonstrated consistent differences in various compositional metrics when compared to natural bacteriophage genomes by rank-sum tests and principal component analyses. A simple neural network trained to detect transformer-generated sequences on global compositional metrics alone displayed a median sensitivity of 93.0% and specificity of 97.9% (n = 12 independent models). Overall, these results demonstrate that megaDNA does not yet generate bacteriophage genomes with realistic compositional biases and that genome composition is a reliable method for detecting sequences generated by this model. While the results are specific to the megaDNA model, the evaluated framework described here could be applied to any generative model for genomic sequences.","2024-09-18","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","3","6","","","","","","","","","","English","","","","WOS:001314667300004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","DINUCLEOTIDE; RNA; VIRUS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F93NZI33","journalArticle","2024","Tuan, TA; Dung, NV; Thang, TN","A Hyper-Transformer model for Controllable Pareto Front Learning with Split Feasibility Constraints","NEURAL NETWORKS","","0893-6080","10.1016/j.neunet.2024.106571","","Controllable Pareto front learning (CPFL) approximates the Pareto optimal solution set and then locates a non- dominated point with respect to a given reference vector. However, decision-maker objectives were limited to a constraint region in practice, so instead of training on the entire decision space, we only trained on the constraint region. Controllable Pareto front learning with Split Feasibility Constraints (SFC) is a way to find the best Pareto solutions to a split multi-objective optimization problem that meets certain constraints. In the previous study, CPFL used a Hypernetwork model comprising multi-layer perceptron (Hyper-MLP) blocks. Transformer can be more effective than previous architectures on numerous modern deep learning tasks in certain situations due to their distinctive advantages. Therefore, we have developed a hyper-transformer (Hyper-Trans) model for CPFL with SFC. We use the theory of universal approximation for the sequence-to- sequence function to show that the Hyper-Trans model makes MED errors smaller in computational experiments than the Hyper-MLP model.","2024-11","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","179","","","","","","","","","","English","","","","WOS:001292617600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","CONNECTEDNESS; Controllable pareto front learning; EFFICIENT SET; Hypernetwork; MONOTONIC OPTIMIZATION; Multi-objective optimization; MULTIOBJECTIVE EVOLUTIONARY ALGORITHMS; PROJECTION; Split feasibility problem; Transformer; VECTOR OPTIMIZATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R4KFX3UT","journalArticle","2024","Gharibi, R; Sadreddini, MH; Fakhrahmad, SM","T5APR: Empowering automated program repair across languages through checkpoint ensemble","JOURNAL OF SYSTEMS AND SOFTWARE","","0164-1212","10.1016/j.jss.2024.112083","","Automated program repair (APR) using deep learning techniques has become an important area of research in recent years, aiming to automatically generate bug -fixing patches that can improve software reliability and maintainability. However, most existing methods either target a single language or require high computational resources to train multilingual models. In this paper, we propose T5APR, a novel neural program repair approach that provides a unified solution for bug fixing across multiple programming languages. T5APR leverages CodeT5, a powerful pre -trained text -to -text transformer model, and adopts a checkpoint ensemble strategy to improve patch recommendation. We conduct comprehensive evaluations on six wellknown benchmarks in four programming languages (Java, Python, C, JavaScript), demonstrating T5APR's competitiveness against state-of-the-art techniques. T5APR correctly fixes 1,985 bugs, including 1,442 bugs that none of the compared techniques has fixed. We further support the effectiveness of our approach by conducting detailed analyses, such as comparing the correct patch ranking among different techniques. The findings of this study demonstrate the potential of T5APR for use in real -world applications and highlight the importance of multilingual approaches in the field of APR.","2024-08","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","214","","","","","","","","","","English","","","","WOS:001239362500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;81</p>","","","Automated program repair; Deep learning; Neural program repair; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KK8X9PIF","journalArticle","2024","Yin, JL; Wu, MC; Yang, Y; Li, P; Li, F; Liang, W; Lv, Z","Research on Multimodal Emotion Recognition Based on Fusion of Electroencephalogram and Electrooculography","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2024.3370813","","Emotion recognition plays a vital role in building a harmonious society and emotional interaction. Recent research has demonstrated that multimodal interchannel correlations and insufficient emotion elicitation plague deep learning-based emotion identification techniques. To cope with these problems, we propose a multimodal and channel attention fusion transformer (MCAF-Transformer). First, we employ an olfactory video approach to evoke emotional expression more fully and acquire electroencephalogram (EEG) and electrooculography (EOG) signal data. Second, the model makes full use of multimodal channel information, time-domain and spatial-domain information of EEG and EOG signals, captures the correlation of different channels using channel attention, and improves the accuracy of emotion recognition by focusing on the global dependence on the temporal order using the transformer. We conducted extensive experiments on the olfactory video sentiment dataset, and the experimental results were correct at 94.63%. The results show that olfactory videos evoke emotion more adequately than pure videos and that the MCAF-Transformer model significantly outperforms other emotion recognition methods.","2024","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","73","","","","","","","","","","English","","","","WOS:001180920500019","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Attention mechanisms; Brain modeling; electroencephalogram (EEG) and electrooculography (EOG); Electroencephalography; Electrooculography; Emotion recognition; Feature extraction; FEATURE-EXTRACTION; multimodal; olfactory video emotion evocation; Time-domain analysis; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ILFGXQK5","journalArticle","2023","Liu, YL; Chen, JL; Wang, TT; Li, AM; Pan, TY","A variational transformer for predicting turbopump bearing condition under diverse degradation processes","RELIABILITY ENGINEERING & SYSTEM SAFETY","","0951-8320","10.1016/j.ress.2022.109074","","Accurate condition prediction is necessary to ensure the reliability of the turbopump components. Meanwhile, with the ever-increasing complexity of the turbopump system, the corresponding degradation processes of the turbopump bearings are also increasingly diverse. Consequently, the investigation into the prediction of the turbopump bearing condition is of great significance. However, current research mostly reported on the remaining useful life prediction and neglected the predictive analysis based on the object's health condition. To address the problem, this paper proposed a combinational framework for the turbopump bearing condition monitoring and prediction. Firstly, a multi-branch residual network is designed to construct the health indicators (HIs), which are intended to indicate the health condition of the objects. Then, a Transformer model-based predictor is proposed to predict the constructed HIs accurately. By implanting the variational mechanism in the network, the predictor can achieve high accuracy under diverse degradation processes. To demonstrate the effectiveness of the proposed approach, a public whole-lifetime bearing dataset and a turbopump bearing dataset are utilized in the contrast experiments. Compared with some existing approaches, the proposed framework can obtain more reliable HIs and achieve higher prediction accuracy under diverse degradation processes.","2023-04","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","232","","","","","","","","","","English","","","","WOS:000992360700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P7Y8IA79","journalArticle","2021","Hu, X; Yang, WJ; Wen, H; Liu, Y; Peng, YX","A Lightweight 1-D Convolution Augmented Transformer with Metric Learning for Hyperspectral Image Classification","SENSORS","","1424-8220","10.3390/s21051751","","Hyperspectral image (HSI) classification is the subject of intense research in remote sensing. The tremendous success of deep learning in computer vision has recently sparked the interest in applying deep learning in hyperspectral image classification. However, most deep learning methods for hyperspectral image classification are based on convolutional neural networks (CNN). Those methods require heavy GPU memory resources and run time. Recently, another deep learning model, the transformer, has been applied for image recognition, and the study result demonstrates the great potential of the transformer network for computer vision tasks. In this paper, we propose a model for hyperspectral image classification based on the transformer, which is widely used in natural language processing. Besides, we believe we are the first to combine the metric learning and the transformer model in hyperspectral image classification. Moreover, to improve the model classification performance when the available training samples are limited, we use the 1-D convolution and Mish activation function. The experimental results on three widely used hyperspectral image data sets demonstrate the proposed model's advantages in accuracy, GPU memory cost, and running time.","2021-03","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","5","21","","","","","","","","","","English","","","","WOS:000628558800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;26<br/>Total Times Cited:&nbsp;&nbsp;27<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","1-D convolution; deep learning; hyperspectral image classification; metric learning; remote sensing; SPARSE; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SZVQQL4Z","journalArticle","2025","Woo, TG; Kim, BJ; Cho, IH; Park, KM","State estimation and visualization of lithium-ion battery using transformer Autoencoder model","JOURNAL OF POWER ELECTRONICS","","1598-2092","10.1007/s43236-025-00995-6","","This study developed and evaluated artificial neural network models for estimating and visualizing the State of Health (SOH) of lithium-ion batteries (LIBs) used in railway vehicles. The models, which include Autoencoder, Long Short-Term Memory (LSTM)-Autoencoder, Attention LSTM-Autoencoder, and Transformer Autoencoder, were trained on large-scale time-series data of LIB voltage, current, and temperature. The Transformer Autoencoder model demonstrated substantial performance improvements, achieving over a 99% enhancement compared to the basic Autoencoder model and up to 82% improvement over the Attention LSTM-Autoencoder model. Unlike classical Transformer models, which typically focus on compressing data into high-dimensional spaces, the Autoencoder approach is applied to the Transformer model, facilitating low-dimensional compression and clustering of the data. This clustering technique was further employed to visualize battery health by converting the clustered data into RGB values, offering an intuitive representation of the SOH. By overcoming the limitations of traditional methods, this novel approach provides an effective means of assessing battery condition. These findings indicate that the proposed method could notably enhance battery management systems, leading to a safe and reliable operation of electric mobility systems.","2025-02-07","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","","","","","","","","","","","English","","","","WOS:001415597400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Autoencoder; Battery state; Deep learning; ELECTROCHEMICAL IMPEDANCE SPECTROSCOPY; MANAGEMENT; State of health (SOH); Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RPS5XC8H","journalArticle","2024","Liu, CY; Zou, WW; Hu, ZL; Li, HY; Sui, X; Ma, XQ; Yang, F; Guo, N","Bearing Health State Detection Based on Informer and CNN plus Swin Transformer","MACHINES","","2075-1702","10.3390/machines12070456","","In response to the challenge of timely fault identification in the spindle bearings of machine tools operating in complex environments, this study proposes a method based on a combination of infrared imaging with an Informer and a CNN + Swin Transformer. The aim is to achieve real-time monitoring of bearing faults, precise fault localization, and classification of fault severity. To accomplish this, an angular contact ball bearing was chosen as the research subject. Initially, an infrared image dataset was constructed, encompassing various fault positions and degrees, by simulating different forms of bearing faults. Subsequently, an Informer-based bearing temperature prediction model was established to select faulty bearing data. Lastly, the faulty data were input into the CNN + Swin Transformer model for bearing fault recognition and classification. The results demonstrate that the Informer model accurately identifies abnormal temperature rises during bearing operation, effectively screening out faulty bearings. Under steady-state conditions, the model achieves a classification accuracy of 97.8%. Furthermore, after employing the Informer screening process, the proposed model exhibits a recognition precision of 98.9%, surpassing other models such as CNN, SVM, and Swin Transformer, which are mentioned in this paper.","2024-07","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","7","12","","","","","","","","","","English","","","","WOS:001277018400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","CLASSIFICATION; CNN; fault recognition; FAULT-DIAGNOSIS; infrared image; swin transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7HX8ZDIG","journalArticle","2024","Dewi, C; Chernovita, HP; Philemon, SA; Ananta, CA; Chen, APS","Adjusted Reasoning Module for Deep Visual Question Answering Using Vision Transformer","CMC-COMPUTERS MATERIALS & CONTINUA","","1546-2218","10.32604/cmc.2024.057453","","Visual Question Answering (VQA) is an interdisciplinary artificial intelligence (AI) activity that integrates computer vision and natural language processing. Its purpose is to empower machines to respond to questions by utilizing visual information. A VQA system typically takes an image and a natural language query as input and produces a textual answer as output. One major obstacle in VQA is identifying a successful method to extract and merge textual and visual data. We examine ""Fusion"" Models that use information from both the text encoder and picture encoder to efficiently perform the visual question-answering challenge. For the transformer model, we utilize BERT and RoBERTa, which analyze textual data. The image encoder designed for processing image data utilizes ViT (Vision Transformer), Deit (Data-efficient Image Transformer), and BeIT (Image Transformers). The reasoning module of VQA was updated and layer normalization was incorporated to enhance the performance outcome of our effort. In comparison to the results of previous research, our proposed method suggests a substantial enhancement in efficacy. Our experiment obtained a 60.4% accuracy with the PathVQA dataset and a 69.2% accuracy with the VizWiz dataset.","2024","2025-02-26 20:41:49","2025-02-26 20:41:49","","4195-4216","","3","81","","","","","","","","","","English","","","","WOS:001385235700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","deep learning; multimodal data; vision transformer; VQA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M3CIRG8I","journalArticle","2024","Tran, V; Septier, F; Murakami, D; Matsui, T","Spatial-Temporal Temperature Forecasting Using Deep-Neural-Network-Based Domain Adaptation","ATMOSPHERE","","2073-4433","10.3390/atmos15010090","","Accurate temperature forecasting is critical for various sectors, yet traditional methods struggle with complex atmospheric dynamics. Deep neural networks (DNNs), especially transformer-based DNNs, offer potential advantages, but face challenges with domain adaptation across different geographical regions. We evaluated the effectiveness of DNN-based domain adaptation for daily maximum temperature forecasting in experimental low-resource settings. We used an attention-based transformer deep learning architecture as the core forecasting framework and used kernel mean matching (KMM) for domain adaptation. Domain adaptation significantly improved forecasting accuracy in most experimental settings, thereby mitigating domain differences between source and target regions. Specifically, we observed that domain adaptation is more effective than exclusively training on a small amount of target-domain training data. This study reinforces the potential of using DNNs for temperature forecasting and underscores the benefits of domain adaptation using KMM. It also highlights the need for caution when using small amounts of target-domain data to avoid overfitting. Future research includes investigating strategies to minimize overfitting and to further probe the effect of various factors on model performance.","2024-01","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","1","15","","","","","","","","","","English","","","","WOS:001149061600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","deep neural network (DNN); domain adaptation; Kernel Mean Matching (KMM); temperature forecasting; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LXRAM629","journalArticle","2023","Wan, YX; Zhang, WL; Li, Z","Double Consistency Regularization for Transformer Networks","ELECTRONICS","","2079-9292","10.3390/electronics12204357","","The large-scale and deep-layer deep neural network based on the Transformer model is very powerful in sequence tasks, but it is prone to overfitting for small-scale training data. Moreover, the prediction result of the model with a small disturbance input is significantly lower than that without disturbance. In this work, we propose a double consistency regularization (DOCR) method for the end-to-end model structure, which separately constrains the output of the encoder and decoder during the training process to alleviate the above problems. Specifically, on the basis of the cross-entropy loss function, we build the mean model by integrating the model parameters of the previous rounds and measure the consistency between the models by calculating the KL divergence between the features of the encoder output and the probability distribution of the decoder output of the mean model and the base model so as to impose regularization constraints on the solution space of the model. We conducted extensive experiments on machine translation tasks, and the results show that the BLEU score increased by 2.60 on average, demonstrating the effectiveness of DOCR in improving model performance and its complementary impacts with other regularization techniques.","2023-10","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","20","12","","","","","","","","","","English","","","","WOS:001089514600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","cross-entropy loss; deep neural network; KL divergence; overfitting; regularization; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A5K3J5KX","journalArticle","2023","Gao, Y; Wang, Y; Zhang, L; Guo, LH; Li, J; Sun, SH","A Sequential Decision Algorithm of Reinforcement Learning for Composite Action Space","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3320137","","It is the key research object of electronic warfare to use UAV (Unmanned Aerial Vehicle) clusters to carry out electronic countermeasure tasks. The UAV carries loads such as reconnaissance and interference at the same time, which makes it necessary to simultaneously decide multiple types of actions-namely, compound actions-which poses a challenge to intelligent decision-making algorithms. Considering the problem of action-space dimensional complexity and weak collaboration between decisions in multi-agent scenarios with composite actions, this study proposed a decision algorithm involving a multi-agent reinforcement-learning sequence, which combined joint composite actions into sequential decision, reducing the difficulty of a single decision and enhancing the collaboration between various agents and their individual decisions. Because long decision sequences required better depth modeling and had high variance, a DeLighT module was added to the naive transformer model to increase the depth and baseline techniques, which were used to reduce the variance in the value estimation. The simulated results verified the effectiveness of the proposed algorithm in the UAV cooperative combat scenario, where each agent had a composite action space and showed better performance than the existing algorithms.","2023","2025-02-26 20:41:49","2025-02-26 20:41:49","","107669-107684","","","11","","","","","","","","","","English","","","","WOS:001082153000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Baseline; composite action space; multi-agent reinforcement learning; transformer; UAVs sensing and jamming strategy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DPR6Q3A7","journalArticle","2024","Jia, LY; Zhang, JX; Zhuo, RB; Li, Y; Zhao, R; Zhang, M; Wang, S","Modernizing Tongue Diagnosis: AI Integration With Traditional Chinese Medicine for Precise Health Evaluation","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3486118","","The integration of traditional Chinese medicine (TCM) diagnostics with modern artificial intelligence (AI) techniques has emerged as a promising approach to enhance the objectivity and accuracy of disease assessment. Tongue diagnosis, a non-invasive and unique TCM practice, plays a critical role in evaluating health status but is often limited by the subjective judgment of practitioners. This study addresses these limitations by developing an intelligent tongue diagnosis system using the Cv-Swin Transformer architecture. The system processes a diverse dataset of 5,365 tongue images, classifying them into ten categories based on TCM diagnostic standards. Key findings indicate that the Cv-Swin Transformer model achieves an average accuracy of 87.37% in tongue image classification, demonstrating superior performance compared to traditional models. The system effectively captures complex tongue features related to various diseases, providing precise health assessments and personalized treatment recommendations. This research represents a significant advancement in integrating AI with TCM, offering a robust tool for objective diagnostics and supporting the modernization of traditional practices.","2024","2025-02-26 20:41:49","2025-02-26 20:41:49","","161670-161678","","","12","","","","","","","","","","English","","","","WOS:001351412500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","Accuracy; ARTIFICIAL-INTELLIGENCE; Coatings; deep learning; Diseases; Feature extraction; IMAGES; Liver; Medical diagnostic imaging; medical diagnostics; Merging; Tongue; tongue diagnosis; Traditional Chinese medicine; Transformers; Vectors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HKE5IBDA","journalArticle","2023","Yang, L; Mohamed, ASA; Ali, MKM","Traffic Conflicts Analysis in Penang Based on Improved Object Detection With Transformer Model","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3299316","","Current road safety detection and analysis tends to focus on hit-and-run accidents that have already occurred, while ignoring near-misses that may pose a potential safety risk. A monitoring method for near-misses based on the improved YOLOv7 of transformers is proposed in this work. First, the backbone network of YOLOv7 is improved using a G3HN structure (g(n) Conv) with recursive gate convolution. Second, the global attention mechanism (GAM) is added to the probe to improve recognition accuracy. Finally, the object detection results are inverted by inverse perspective mapping (IPM) to obtain the centroid of the object, and then the probability of near miss is calculated and analyzed using the DN-based, PICUD-based, and PSD-based methods. This experiment was based on the POL37 Closed-Circuit Television (CCTV) dataset from Penang, Malaysia. The experimental results show that the improved algorithm proposed in this paper can effectively identify small targets in the object detection phase with a detection accuracy of 94.8%, smaller models, and faster training speed, and can fulfill the surveillance task of near-miss events in CCTV surveillance scenes.","2023","2025-02-26 20:41:49","2025-02-26 20:41:49","","84061-84073","","","11","","","","","","","","","","English","","","","WOS:001049941200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","G3HN; near-miss events; object detection; transformer mechanism","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MGUT57JA","journalArticle","2022","Zhang, Z; Xu, ZW; Liu, CA; Tian, Q; Wang, YP","Cloudformer: Supplementary Aggregation Feature and Mask-Classification Network for Cloud Detection","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app12073221","","Cloud detection is an important step in the processing of optical satellite remote-sensing data. In recent years, deep learning methods have achieved excellent results in cloud detection tasks. However, most of the current models have difficulties to accurately classify similar objects (e.g., clouds and snow) and to accurately detect clouds that occupy a few pixels in an image. To solve these problems, a cloud-detection framework (Cloudformer) combining CNN and Transformer is being proposed to achieve high-precision cloud detection in optical remote-sensing images. The framework achieves accurate detection of thin and small clouds using a pyramidal structure encoder. It also achieves accurate classification of similar objects using a dual-path decoder structure of CNN and Transformer, reducing the rate of missed detections and false alarms. In addition, since the Transformer model lacks the perception of location information, an asynchronous position-encoding method is being proposed to enhance the position information of the data entering the Transformer module and to optimize the detection results. Cloudformer is experimented on two datasets, AIR-CD and 38-Cloud, and the results show that it has state-of-the-art performance.","2022-04","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","7","12","","","","","","","","","","English","","","","WOS:000781672400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;16<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","cloud detection; DETECTION ALGORITHM; IMAGERY; mask classification; remote-sensing images; SEGMENTATION; SHADOW; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FZV2A934","journalArticle","2025","Zaim, HC; Yolaçan, EN","FPE-Transformer: A Feature Positional Encoding-Based Transformer Model for Attack Detection","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app15031252","","The increase in cybersecurity threats has made attack detection systems critically important. Traditional deep learning methods often require large amounts of data and struggle to understand relationships between features effectively. With their self-attention mechanism, Transformers excel in modeling complex relationships and long-term dependencies. They are also adaptable to various data types and sources, making them advantageous in large-scale attack detection scenarios. This paper introduces the FPE-Transformer framework, leveraging the strengths of the Transformer architecture. FPE-Transformer incorporates an innovative feature positional encoding mechanism that encodes the positional information of each feature separately, enabling a deeper understanding of feature relationships and more precise attack detection. Additionally, the model includes a ClassificationHead for enhanced accuracy and complex pattern recognition. The framework's performance was validated using the NSL-KDD and CIC-IDS2017 datasets, demonstrating its superiority over traditional methods in detecting diverse attack types and improving overall performance. This study highlights FPE-Transformer's innovative approach and ability to address key limitations of traditional deep learning methods, establishing it as a robust solution for modern attack detection challenges.","2025-02","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","3","15","","","","","","","","","","English","","","","WOS:001418415300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","attack detection; cybersecurity; deep learning; FPE-Transformer; Transformer models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CIYZCVMZ","journalArticle","2024","Mao, BX; Chang, HH; Xing, XH; Zhang, QK; Zou, D; Liu, Y; Yao, JQ; Bi, HX; Wu, L","Designing ultra-broadband terahertz polarization converters based on the transformer model","OPTICS COMMUNICATIONS","","0030-4018","10.1016/j.optcom.2024.130434","","Polarization, a fundamental property of terahertz (THz) waves, can be controlled using metasurfaces for signal transmission and sensitive measurements. However, conventional methods for designing polarization-conversion metasurfaces require numerous numerical simulation iterations and trial and error attempts that are computationally intensive and time-consuming, necessitating a more rapid and efficient approach. This study proposes a transformer-based method for the inverse design of terahertz polarization converters; the approach can accurately design the corresponding metasurface based on the target spectrum. The model also comprises a forward network that can precisely and intuitively predict the meta-atoms spectra with high simulation speed and reduced computational cost. Using this approach, two ultra-broadband polarization conversion devices were designed in approximately 0.006 s within a target frequency range of 0.5-4 THz, with polarization conversion ratios greater than 90% within 1.23-3.19 THz and 1.18-3.24 THz. Additionally, the average cross-polarization ratio was greater than 50%. This study provides insights into designing terahertz polarization converters, which are applicable in terahertz communications, polarization imaging, and biomedical procedures.","2024-05-15","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","559","","","","","","","","","","English","","","","WOS:001218983700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Deep learning; DIELECTRIC METASURFACES; Metasurface; PHASE; Polarization converter; Ultra-broadband","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WXRQYBZH","journalArticle","2023","Jin, Q; Kim, W; Chen, QY; Comeau, DC; Yeganova, L; Wilbur, WJ; Lu, ZY","MedCPT: Contrastive Pre-trained Transformers with large-scale PubMed search logs for zero-shot biomedical information retrieval","BIOINFORMATICS","","1367-4803","10.1093/bioinformatics/btad651","","Motivation: Information retrieval (IR) is essential in biomedical knowledge acquisition and clinical decision support. While recent progress has shown that language model encoders perform better semantic retrieval, training such models requires abundant query-article annotations that are difficult to obtain in biomedicine. As a result, most biomedical IR systems only conduct lexical matching. In response, we introduce MedCPT, a first-of-its-kind Contrastively Pre-trained Transformer model for zero-shot semantic IR in biomedicine. Results: To train MedCPT, we collected an unprecedented scale of 255 million user click logs from PubMed. With such data, we use contrastive learning to train a pair of closely integrated retriever and re-ranker. Experimental results show that MedCPT sets new state-of-the-art performance on six biomedical IR tasks, outperforming various baselines including much larger models, such as GPT-3-sized cpt-text-XL. In addition, MedCPT also generates better biomedical article and sentence representations for semantic evaluations. As such, MedCPT can be readily applied to various real-world biomedical IR tasks. Availability and implementation: The MedCPT code and model are available at https://github.com/ncbi/MedCPT.","2023-11-01","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","11","39","","","","","","","","","","English","","","","WOS:001188936500007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E7KPN3TK","journalArticle","2023","Liu, JH; Deng, AS; Xie, QJ; Yue, GL","A Code Reviewer Recommendation Approach Based on Attentive Neighbor Embedding Propagation","ELECTRONICS","","2079-9292","10.3390/electronics12092113","","Code review as an effective software quality assurance practice has been widely applied in many open-source software communities. However, finding a suitable reviewer for certain codes can be very challenging in open-source communities due to the difficulty of learning the characteristics of reviewers and the code-reviewer interaction sparsity in open-source software communities. To tackle this problem, most previous approaches focus on learning developers' capabilities and experiences and recommending suitable developers based on their historical interactions. However, such approaches usually suffer from data-sparsity and noise problems, which may reduce the recommendation accuracy. In this paper, we propose an attentive neighbor embedding propagation enhanced code reviewer recommendation framework (termed ANEP). In ANEP, we first construct the reviewer-code interaction graph and learn the semantic representations of the reviewer and code based on the transformer model. Then, we explicitly explore the attentive high-order embedding propagation of reviewers and code and refine the representations along their neighbors. Finally, to evaluate the effectiveness of ANEP, we conduct extensive experiments on four real-world datasets. The experimental results show that ANEP outperforms other state-of-the-art approaches significantly.","2023-05-05","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","9","12","","","","","","","","","","English","","","","WOS:000986629400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","attention mechanism; CHALLENGES; code reviewer; high-order embedding propagation; IMPACT; neighbor embedding; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6VKCRTSU","journalArticle","2022","Celen, D; Partal, SZ","A Novel Plug-In Core Design for Three-Phase Transformers Une nouvelle conception de noyau enfichable pour les transformateurs triphases","IEEE CANADIAN JOURNAL OF ELECTRICAL AND COMPUTER ENGINEERING","","2694-1783","10.1109/ICJECE.2021.3108134","","In this study, in order to reduce stacking time and production costs of transformer electrical sheets, a new Plug-In core model has been proposed. This Plug-In transformer was designed as a three-phase transformer made with M330-50A electrical steel with a rated power of 4.7 kVA and then produced as a prototype. Both the proposed transformer model and a reference EI-core transformer with same rated power and electrical ratings were analyzed using an ANSYS Maxwell 2-D simulation program and the results were compared. The distribution of magnetic flux densities, core losses, the local regions where core losses mostly occur, copper losses, and transient inrush currents have been simulated for both the transformers. Apart from simulation, load and no-load tests have been tested and the efficiency analysis of the transformers was determined. It has been determined that considerably less time and labor are required for stacking and assembly progress of the proposed core compared to the reference EI core transformer.","2022","2025-02-26 20:41:49","2025-02-26 20:41:49","","42-49","","1","45","","","","","","","","","","English","","","","WOS:000763588800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;17</p>","","","Core assembly; Core loss; core losses; finite element; FLUX DISTRIBUTION; Lamination; Legged locomotion; Magnetic flux; magnetic flux density; Power transformers; transformer core design; Transformer cores; Windings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6XINRU9U","journalArticle","2022","Huang, NN; Hu, RM; Xiong, MF; Peng, XR; Ding, HW; Jia, XD; Zhang, LK","Multi-scale Interest Dynamic Hierarchical Transformer for sequential recommendation","NEURAL COMPUTING & APPLICATIONS","","0941-0643","10.1007/s00521-022-07281-7","","Existing sequential recommendation methods focus on modeling the temporal relationships of users' historical behaviors and excel in exploiting users' dynamic interests to improve recommendation performance. However, these methods rarely consider the existence of multi-scale user behavior sequences (e.g., temporal, location, and material scales), and sometimes user multi-scale interests play a decisive role in predicting final user preferences. To investigate the influence of multi-scale interests on user preferences, we study to develop a Multi-scale Interest Dynamic Hierarchical Transformer Model (MIDHT) to fine-grain modeling of users' interests. Specifically, the proposal includes: First, the neighbor attention mechanism determines whether two neighboring items merge or not. Second, we generate the block mask matrix based on the above judgment results. Third, we compute the implicit representation of the current layer using the dynamic block mask matrix and the self-attention mechanism. Last, the dynamic block mask matrix of all layers to infer the corresponding hierarchical structure. Thorough experiments are implemented to show the features of MIDHT under different component settings. Furthermore, experimental results on three real-world datasets show that MIDHT significantly outperforms the state-of-the-art baselines on different evaluation metrics.","2022-10","2025-02-26 20:41:49","2025-02-26 20:41:49","","16643-16654","","19","34","","","","","","","","","","English","","","","WOS:000803772700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","MIDHT; Multi-scale interest; Sequential recommendation; Users' behaviors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B2UJPHNX","journalArticle","2022","Zhu, X; Chen, G; Wang, Z; Wu, L; Luo, J; Wang, X","Extinguishment of a transformer fire with a long projection water mist system","FIRE SAFETY JOURNAL","","0379-7112","10.1016/j.firesaf.2022.103603","","When large oil-immersed power transformer fire happens, scenarios such as bushing explosion, oil pool fire, oil spray fire and oil flowing fire are commonly observed. As the nozzles of current water mist or sprinkler system are arranged in the fire region, they are at risk of damage during the explosion or under high temperature. This paper presents a long projection water mist technique based on axial flow inducing to effectively extinguish the fire at far distance. The droplet size, spray density, and effective spray distance were characterized via Laser diffraction technique, water collection method and laser distance measurement. Fire extinguishment tests were conducted through setting up a full-scale 800 kV converter transformer model to verify its capability. The results indicate that the proposed system can extinguish the 800 kV converter transformer fire within dozens of seconds, due to its long spray distance, small droplet size, and large spray density. This study will provide a new method for water mist generation and references for system design for large transformer fire or oil fire extinguishment in open space.","2022-06","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","130","","","","","","","","","","English","","","","WOS:000807121000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Axial flow induced spray; Fire extinguishment; FULL-SCALE EXPERIMENTS; Spray characterization; SUPPRESSION; Transformer fire; Water mist","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BSUSM6C5","journalArticle","2024","Liu, SQ; Li, YZ; Xie, XF; Ma, W; Meng, GZ; Li, Y","Automated Commit Intelligence by Pre-training","ACM TRANSACTIONS ON SOFTWARE ENGINEERING AND METHODOLOGY","","1049-331X","10.1145/3674731","","GitHub commits, which record the code changes with natural language messages for description, play a critical role in software developers' comprehension of software evolution. Due to their importance in software development, several learning-based works are conducted for GitHub commits, such as commit message generation and security patch identification. However, most existing works focus on customizing specialized neural networks for different tasks. Inspired by the superiority of code pre-trained models, which has confirmed their effectiveness across different downstream tasks, to promote the development of open-source software community, we first collect a large-scale commit benchmark including over 7.99 million commits across 7 programming languages. Based on this benchmark, we present CommitBART, a pre-trained encoder- decoder Transformer model for GitHub commits. The model is pre-trained by three categories (i.e., denoizing objectives, cross-modal generation, and contrastive learning) for six pre-training tasks to learn commit fragment representations. Our model is evaluated on one understanding task and three generation tasks for commits. The comprehensive experiments on these tasks demonstrate that CommitBART significantly outperforms previous pre-trained works for code. Further analysis also reveals that each pre-training task enhances the model performance.","2024-11","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","8","33","","","","","","","","","","English","","","","WOS:001391588700002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","code pre-training model; GENERATION; GitHub commit","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M6KKXKG8","journalArticle","2024","Xu, YH; Sha, YY; Wang, C; Cui, HT; Wei, YJ","Reconstructing multiphase flow fields with limited pressure observations based on an improved transformer model","OCEAN ENGINEERING","","0029-8018","10.1016/j.oceaneng.2024.119386","","In practical applications, the implementation of active cavitation control can significantly enhance the hydrodynamic performance of underwater vehicles. However, the sparsity of sensor information poses a substantial challenge to acquiring flow field states. Recent advances in deep learning offer reliable solutions to this problem. Specifically, deep learning methods, through the construction of sparse reconstruction models, establish connections between sparse observational information and flow field states with minimal or no prior knowledge. To reconstruct multiphase flow fields from sparse pressure observations on the hydrofoil surface, this work proposes a Transformer-based sparse reconstruction model. Test results on cavitation datasets demonstrate that the model's predictions of cavity contours, cavity lengths, and cavity volumes are highly consistent with actual results during the sheet cavity growth and cavity shedding stages. However, due to the highly unsteady nature of cavitation flow and the lack of far-field information, the model's prediction performance is limited during the cloud cavity aggregation and collapse stages. This model exhibits potential in the sparse reconstruction of multiphase flow fields, providing support for the observation of flow field states and active cavitation control.","2024-12-01","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","313","","","","","","","","","","English","","","","WOS:001329430700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","CAVITATION; DECOMPOSITION; NEURAL-NETWORK","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"75QJ8CBF","journalArticle","2024","Ma, ZY; Gong, HJ; Wang, XH","Multiagent trajectory decision-making for complex systems based on transformer large model structure","INTERNATIONAL JOURNAL OF ROBUST AND NONLINEAR CONTROL","","1049-8923","10.1002/rnc.7648","","The article explores the application of transformer-based large models for trajectory decision-making in complex decision systems, focusing on multiagent nodes in a topological structure. By leveraging the capabilities of large models, the proposed approach enhances decision-making in model-free control environments characterized by numerous agents, diverse internal tasks, and unknown conditions. The proposed framework integrates advanced transformer models with a sophisticated decision-making framework to enhance the efficiency, safety, and reliability of multiagent operations in dynamic environments. The results demonstrate the superior performance of the transformer model, achieving a trajectory decision-making accuracy of 97.8%, significantly outperforming other models such as long short-term memory (LSTM), gate recurrent unit (GRU), and traditional approaches. The visualizations highlight the close alignment between the true and predicted outcomes of complex decision-making systems, showcasing the model's ability to capture complex dependencies and interactions within the multiagent environment. High task completion rates and low collision rates further underscore the effectiveness of the decision-making framework in optimizing agent coordination and ensuring safe operations.","2024-09-23","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","","","","","","","","","","","English","","","","WOS:001317363500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","complex decision-making systems; decision-making optimization; multiagent nodes; trajectory planning; transformer large model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DEV8KL67","journalArticle","2024","Althubiti, AH; Algethami, H","Dynamic Gesture Recognition using a Transformer and Mediapipe","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","There is a rising interest in dynamic gesture recognition as a research area. This is the result of emerging global pandemics as well as the need to avoid touching different surfaces. Most of the previous research has focused on implementing deep learning algorithms for the RGB modality. However, despite its potential to enhance the algorithm's performance, gesture recognition has not widely utilised the concept of attention. Most research also used three-dimensional convolutional networks with long short-term memory networks for gesture recognition. However, these networks can be computationally expensive. As a result, this paper employs pre-trained models in conjunction with the skeleton modality to address the challenges posed by background noise. The goal is to present a comparative analysis of various gesture recognition models, divided based on video frames or skeletons. The performance of different models was evaluated using a dataset taken from Kaggle with a size of 2 GB. Each video contains 30 frames (or images) to recognise five gestures. The transformer model for skeleton-based gesture recognition achieves 0.99 accuracy and can be used to capture temporal dependencies in sequential data.","2024-06","2025-02-26 20:41:49","2025-02-26 20:41:49","","1424-1439","","6","15","","","","","","","","","","English","","","","WOS:001277906500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Gesture recognition; self-attention; skeleton; transfer learning; transformer encoder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KGCYEQWS","journalArticle","2023","Wang, XY; Li, T; Hua, HQ; Shu, L; Xing, XF","Plantar Space-Gait Cycle Transformer for Early Parkinson Disease Detection","APSIPA TRANSACTIONS ON SIGNAL AND INFORMATION PROCESSING","","2048-7703","10.1561/116.00000227","","Parkinson's disease (PD) is a chronic and long-term disease that seriously affects patients' quality of life. In underdeveloped areas, early detection of PD is primarily based on medical observation and patient self-description. Early diagnosis of PD can effectively reduce the disease's progression. Recent studies have suggested that the motor symptoms of PD can be reflected in plantar pressure. However, traditional machine learning models require manual feature selection, which can be time-consuming. Furthermore, although deep learning has seen rapid development, many clinical characteristics have not been taken into consideration. To address these limitations, a dual self-attention Transformer model is proposed to explore the spatial correlation of plantar space and the temporal correlation of the gait cycle. Considering the presence of symptoms such as foot tremors in PD patients, a masking mechanism is designed to focus locally on the unilateral foot during the support phase. An experimental paradigm is designed to evaluate the model's generalization capability across different subjects. The experimental results demonstrate that the proposed model achieves superior classification performance for the early detection of PD based on plantar pressure data.","2023","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","5","12","","","","","","","","","","English","","","","WOS:001106563400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","DIAGNOSIS; FEATURES; Parkinson; Plantar Pressure; Self-Attention; Transformer; VGRF","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8GXNEX4T","journalArticle","2022","Mahmoud, AH; Masters, M; Lee, SJ; Lill, MA","Accurate Sampling of Macromolecular Conformations Using Adaptive Deep Learning and Coarse-Grained Representation","JOURNAL OF CHEMICAL INFORMATION AND MODELING","","1549-9596","10.1021/acs.jcim.1c01438","","Conformational sampling of protein structures is essential for understanding biochemical functions and for predicting thermodynamic properties such as free energies. Where previous approaches rely on sequential sampling procedures, recent developments in generative deep neural networks rendered possible the parallel, statistically independent sampling of molecular configurations. To be able to accurately generate samples of large molecular systems from a high-dimensional multimodal equilibrium distribution function, we developed a hierarchical approach based on expressive normalizing flows with rational quadratic neural splines and coarse-grained representation. Furthermore, system specific priors and adaptive and property-based controlled learning was designed to diminish the likelihood for the generation of high-energy structures during sampling. Finally, backmapping from a coarse-grained to fully atomistic representation is performed through an equivariant transformer model. We demonstrate the applicability of the method on the one-shot configurational sampling of a protein system with more than a hundred amino acids. The results show enhanced expressivity that diminish the invertibility constraints inherent in the normalizing flow framework. Moreover, the capacity of the hierarchical normalizing flow model was tested on a challenging case study of the folding/unfolding dynamics of the peptide chignolin.","2022-04-11","2025-02-26 20:41:49","2025-02-26 20:41:49","","1602-1617","","7","62","","","","","","","","","","English","","","","WOS:000791024900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZKXUYUT8","journalArticle","2022","Nassif, AB; Darya, AM; Elnagar, A","Empirical Evaluation of Shallow and Deep Learning Classifiers for Arabic Sentiment Analysis","ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING","","2375-4699","10.1145/3466171","","This work presents a detailed comparison of the performance of deep learning models such as convolutional neural networks, long short-term memory, gated recurrent units, their hybrids, and a selection of shallow learning classifiers for sentiment analysis of Arabic reviews. Additionally, the comparison includes state-of-the-art models such as the transformer architecture and the araBERT pre-trained model. The datasets used in this study are multi-dialect Arabic hotel and book review datasets, which are some of the largest publicly available datasets for Arabic reviews. Results showed deep learning outperforming shallow learning for binary and multi-label classification, in contrast with the results of similar work reported in the literature. This discrepancy in outcome was caused by dataset size as we found it to be proportional to the performance of deep learning models. The performance of deep and shallow learning techniques was analyzed in terms of accuracy and F1 score. The best performing shallow learning technique was Random Forest followed by Decision Tree, and AdaBoost. The deep learning models performed similarly using a default embedding layer, while the transformer model performed best when augmented with araBERT.","2022-01","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","1","21","","","","","","","","","","English","","","","WOS:000752286700015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Deep learning; embedding; learning curve; misclassification; shallow learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WHW999XD","journalArticle","2024","Ma, Y; Shi, YH; Zhao, LZ; Lu, XQ; Duh, BL; Wang, ML","PainterAR: A Self-Painting AR Interface for Mobile Devices","COMPUTER ANIMATION AND VIRTUAL WORLDS","","1546-4261","10.1002/cav.2296","","Painting is a complex and creative process that involves the use of various drawing skills to create artworks. The concept of training artificial intelligence models to imitate this process is referred to as neural painting. To enable ordinary people to engage in the process of painting, we propose PainterAR, a novel interface that renders any paintings stroke-by-stroke in an immersive and realistic augmented reality (AR) environment. PainterAR is composed of two components: the neural painting model and the AR interface. Regarding the neural painting model, unlike previous models, we introduce the Kullback-Leibler divergence to replace the original Wasserstein distance existed in the baseline paint transformer model, which solves an important problem of encountering different scales of strokes (big or small) during painting. We then design an interactive AR interface, which allows users to upload an image and display the creation process of the neural painting model on the virtual drawing board. Experiments demonstrate that the paintings generated by our improved neural painting model are more realistic and vivid than previous neural painting models. The user study demonstrates that users prefer to control the painting process interactively in our AR environment.","2024-11","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","6","35","","","","","","","","","","English","","","","WOS:001368842500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","augmented reality; human-computer interaction; neural painting; rendering techniques","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9KGKGB2X","journalArticle","2024","Balasingham, J; Zamaraev, V; Kurlin, V","Accelerating material property prediction using generically complete isometry invariants","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-59938-z","","Periodic material or crystal property prediction using machine learning has grown popular in recent years as it provides a computationally efficient replacement for classical simulation methods. A crucial first step for any of these algorithms is the representation used for a periodic crystal. While similar objects like molecules and proteins have a finite number of atoms and their representation can be built based upon a finite point cloud interpretation, periodic crystals are unbounded in size, making their representation more challenging. In the present work, we adapt the Pointwise Distance Distribution (PDD), a continuous and generically complete isometry invariant for periodic point sets, as a representation for our learning algorithm. The PDD distinguished all (more than 660 thousand) periodic crystals in the Cambridge Structural Database as purely periodic sets of points without atomic types. We develop a transformer model with a modified self-attention mechanism that combines PDD with compositional information via a spatial encoding method. This model is tested on the crystals of the Materials Project and Jarvis-DFT databases and shown to produce accuracy on par with state-of-the-art methods while being several times faster in both training and prediction time.","2024-05-02","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","1","14","","","","","","","","","","English","","","","WOS:001284629600028","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5JELBZPN","journalArticle","2024","Li, ZQ; Zhao, Y; Zhang, YJ; Li, XX; Bu, LG","A novel transformer-enhanced and acoustic-based approach for wind turbine blade fault detection with integrated system implementation","JOURNAL OF ENGINEERING DESIGN","","0954-4828","10.1080/09544828.2024.2332122","","Rising global wind power capacity urgently requires effective real-time turbine monitoring. Complex installations, high maintenance costs, and the occasional need for turbine shutdown hinder conventional monitoring methods. Acoustic-based techniques, while cost-efficient for health assessments, currently face challenges with detection precision and signal processing capabilities in complex acoustic environments. To overcome these challenges, this study proposes a low-cost, AI-driven acoustic-based health monitoring system framework for wind turbine blades, featuring enhanced detection accuracy and signal processing capabilities in complex sound environments. Firstly, a microphone array is employed to capture blade sounds with rich spatial attributes, while beamforming algorithms with a fixed orientation integrate prior spatial information. Furthermore, to further strengthen signal processing and fault detection capabilities, the Transformer model based on self-attention mechanisms is employed for feature extraction and fault diagnosis. An actual wind turbine blade health monitoring system is designed and developed to validate the usability of the proposed framework. Experimental results based on a scaled-down wind turbine model validate the proposed algorithm's effectiveness and practicality, presenting an effective approach in the wind turbine blade health monitoring domain.","2024-03-23","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","","","","","","","","","","","English","","","","WOS:001189905800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","AI-enabled; DAMAGE; decision making; digital twin; intelligentsensing; System design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DBLB3XRB","journalArticle","2023","Wang, C; Zhang, JR; He, J; Luo, W; Yuan, XH; Gu, LC","A two-stream network with complementary feature fusion for pest image classification","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2023.106563","","Pests are diverse and the available datasets often contain an uneven number of examples for different pests (a.k.a., the long-tail distribution). This poses a great challenge to learning-based classification methods, especially deep networks, and often leads to degraded performance, especially for the minority (tail) classes. This paper presents a deep learning integration architecture based on decoupling training and fusion learning, which integrates different models with complementary performance on pest datasets with a long-tailed distribution to improve the overall classification performance of pests. A deep neural network is designed that fuses two complementary deep learning models at the feature level, which consists of a convolution neural network (ConvNeXt) and a Swin Transformer model for decoupling training. Experiments are conducted using three datasets (d0, insect, and IP102), and evaluation on accuracy, recall, and F1-Score is reported. For the large-scale pest dataset with long-tailed distribution IP102, the accuracy achieves 76.1%, which outperforms the state-of-the-art methods. In addition, the accuracy for d0 and insect datasets are 98.5% and 92.3%, respectively.","2023-09","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","124","","","","","","","","","","English","","","","WOS:001025175700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","Classification; Convolutional neural network; Fusion; Long-tailed distribution; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M4XWUCCF","journalArticle","2023","Tan, KL; Lee, CP; Lim, KM","RoBERTa-GRU: A Hybrid Deep Learning Model for Enhanced Sentiment Analysis","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13063915","","This paper proposes a novel hybrid model for sentiment analysis. The model leverages the strengths of both the Transformer model, represented by the Robustly Optimized BERT Pretraining Approach (RoBERTa), and the Recurrent Neural Network, represented by Gated Recurrent Units (GRU). The RoBERTa model provides the capability to project the texts into a discriminative embedding space through its attention mechanism, while the GRU model captures the long-range dependencies of the embedding and addresses the vanishing gradients problem. To overcome the challenge of imbalanced datasets in sentiment analysis, this paper also proposes the use of data augmentation with word embeddings by over-sampling the minority classes. This enhances the representation capacity of the model, making it more robust and accurate in handling the sentiment classification task. The proposed RoBERTa-GRU model was evaluated on three widely used sentiment analysis datasets: IMDb, Sentiment140, and Twitter US Airline Sentiment. The results show that the model achieved an accuracy of 94.63% on IMDb, 89.59% on Sentiment140, and 91.52% on Twitter US Airline Sentiment. These results demonstrate the effectiveness of the proposed RoBERTa-GRU hybrid model in sentiment analysis.","2023-03","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","6","13","","","","","","","","","","English","","","","WOS:000957380500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;18<br/>Total Times Cited:&nbsp;&nbsp;18<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","deep learning; GRU; RoBERTa; sentiment analysis; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5K7TSPMV","journalArticle","2024","Warule, P; Chandratre, S; Mishra, SP; Deb, S","Detection of the common cold from speech signals using transformer model and spectral features","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2024.106158","","The acoustic and prosodic characteristics of speech exhibit alterations when individuals are affected by different health conditions. The field of biomedical engineering holds significant potential in the advancement of non-invasive diagnostic systems that utilize voice as a modality. The common cold is an infectious sickness that affects a large number of people all over the world each year. This paper presents the utilization of various spectral features and a transformer -based model with focal loss function for classifying cold -affected and healthy speech signals. A spectral feature consisting of Mel frequency cepstral coefficients (MFCC), Mel -spectrogram, chromagram, spectral contrast, spectral centroid, spectral bandwidth, spectral flatness, and spectral roll -off features. The efficacy of the proposed methodology is assessed using the URTIC database. The findings indicate that the proposed framework has better results compared to existing state-of-the-art approaches. We have achieved the UAR of 69.55% on the develop set and 70.48% on the test set of the URTIC database. These preliminary findings exhibit significant potential for future investigation in this domain.","2024-07","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","93","","","","","","","","","","English","","","","WOS:001209181700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","Attention mechanism; Cold speech; Focal loss; RECOGNITION; Spectral features; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8Q4X5J7M","journalArticle","2022","Jahanbakht, M; Xiang, W; Azghadi, MR","Sediment Prediction in the Great Barrier Reef using Vision Transformer with finite element analysis","NEURAL NETWORKS","","0893-6080","10.1016/j.neunet.2022.04.022","","Suspended sediment is a significant threat to the Great Barrier Reef (GBR) ecosystem. This catchment pollutant stems primarily from terrestrial soil erosion. Bulk masses of sediments have potential to propagate from river plumes into the mid-shelf and outer-shelf regions. Existing sediment forecasting methods suffer from the problem of low-resolution predictions, making them unsuitable for wide area coverage. In this paper, a novel sediment distribution prediction model is proposed to augment existing water quality management programs for the GBR. This model is based on the state-of-theart Transformer network in conjunction with the well-known finite element analysis. For model training, the emerging physics-informed neural network is employed to incorporate both simulated and measured sediment data. Our proposed Finite Element Transformer (FE-Transformer) model offers accurate predictions of sediment across the entire GBR. It provides unblurred outputs, which cannot be achieved with previous next-frame prediction models. This paves a way for accurate forecasting of sediment, which in turn may lead to improved water quality management for the GBR. (C) 2022 Elsevier Ltd. All rights reserved.","2022-08","2025-02-26 20:41:49","2025-02-26 20:41:49","","311-321","","","152","","","","","","","","","","English","","","","WOS:000807785500004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Deep neural networks; Finite element analysis; Great Barrier Reef; NEURAL-NETWORKS; NUTRIENT; Partial differential equation; Total sediment forecasting; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X5T8RV6W","journalArticle","2024","Wang, S; Sun, YH; Zhang, WJ; Chung, CY; Srinivasan, D","Very short-term wind power forecasting considering static data: An improved transformer model","ENERGY","","0360-5442","10.1016/j.energy.2024.133577","","The randomness and fluctuations in wind power generation present significant challenges for grid and wind farm dispatching. Accurate very short-term wind power forecasting (WPF) is therefore essential for the efficient operation of modern power systems. Data-driven models, such as Transformers, have demonstrated their effectiveness in WPF due to their ability to efficiently capture global features in long sequences. However, limited research has examined the impact of incorporating static data into WPF, which may limit forecasting accuracy. This paper proposes a Temporal Fusion Transformer forecasting model to address this challenge. This approach employs static data as the input features for the model. The model includes feature selection through a variable selection network and employs a specialized temporal fusion decoder to learn effectively from these static features. The case results show that the results of the proposed model are more accurate than the state-of-the-art methods, reducing MAPE by at least 1.32%, RMSE by 0.0091, and improving R 2 by 0.035 in case studies. Additionally, the model maintains a manageable computational burden, underscoring its practical applicability.","2024-12-15","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","312","","","","","","","","","","English","","","","WOS:001350662200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","IMPACT; Improved transformer; SOLAR; Static data; Temporal fusion decoder; Very short-term forecasting; Wind power forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MGWVQC4B","journalArticle","2024","Ji, CQ; Wang, LY; Qin, J; Kang, X; Wang, ZM","Capturing natural position relationships: A neural differential equation approach","PATTERN RECOGNITION LETTERS","","0167-8655","10.1016/j.patrec.2023.12.006","","The Transformer has emerged as the predominant model in Natural Language Processing due to its exceptional performance in various sequence modeling tasks, particularly in handling long-term dependencies. However, the traditional absolute and relative position encoding methods, which do not learn from data, tend to ignore the inherent structure of natural language sequences due to the position embedding layer at the input end of the Transformer model. This paper introduces a novel learnable neural Ordinary Differential Equation Position Encoding (ODEPE) method that can implicitly capture the natural position relationships within a sequence without requiring additional position embeddings. ODEPE can model continuous sequences and leverage differential equations to simulate the evolution of position information along the sequence, enabling position information to flow seamlessly between sequences. Additionally, a highly effective recurrent attention framework is proposed, which hybridizes attention with the ODEPE method to improve model performance. Compared to the Transformer-based sequence modeling network, our framework demonstrates a performance improvement of 24.0 points on the WikiText-103 dataset, while also achieving a performance improvement of 1.06 points on the Enwik8 dataset. This corresponds to an improvement of 4.9% and 0.17%, respectively.","2024-02","2025-02-26 20:41:49","2025-02-26 20:41:49","","14-20","","","178","","","","","","","","","","English","","","","WOS:001166023500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","Neural differential equation; Position encoding; Sequence model; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZZM6HY47","journalArticle","2023","Li, SY; Xia, BW; Li, XC; Wang, YF; Liu, X; Chen, WH","Analysis and Design of Broadband Balance-Compensated Transformer Baluns for Silicon-Based Millimeter-Wave Circuits","IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS","","1549-8328","10.1109/TCSI.2023.3280324","","This paper presents the analysis and design of broadband balance-compensated transformer baluns, suitable for silicon-based millimeter-wave (mm-wave) circuits requir-ing broadband high-quality balanced-unbalanced conversion. By introducing a mode-dependent lumped-element transformer model, a general center-tap-based balance-compensation method is proposed for transformer baluns, with two practical broadband compensation techniques derived. Several critical issues regard-ing the practical design of broadband balance-compensated transformer baluns are also discussed, including the parasitic effects in balance compensation, the consideration of windings' turn number, and the balun design for impedance matching. As a proof-of-concept, three broadband balance-compensated trans-former baluns, operating at different frequencies, are employed in a D-band frequency sextupler in 22 nm FD-SOI CMOS. The fabricated sextupler demonstrates a 5.1-dBm peak output power and 8.49 % peak DC-RF efficiency at 145.5 GHz, and presents a 3-dB peak output power bandwidth ranging from 127 to 162 GHz with more than 37-dBc harmonic rejection ratio (HRR).","2023-08","2025-02-26 20:41:49","2025-02-26 20:41:49","","3103-3116","","8","70","","","","","","","","","","English","","","","WOS:001025555800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","balance compensation; broadband; CMOS; FREQUENCY DOUBLER; imbalance; impedance matching; millimeter-wave (mm-wave); POWER-AMPLIFIER; Transformer; transformer balun","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"79R5LI8S","journalArticle","2021","Xu, ZY; Zhang, WC; Zhang, TX; Yang, ZF; Li, JY","Efficient Transformer for Remote Sensing Image Segmentation","REMOTE SENSING","","2072-4292","10.3390/rs13183585","","Semantic segmentation for remote sensing images (RSIs) is widely applied in geological surveys, urban resources management, and disaster monitoring. Recent solutions on remote sensing segmentation tasks are generally addressed by CNN-based models and transformer-based models. In particular, transformer-based architecture generally struggles with two main problems: a high computation load and inaccurate edge classification. Therefore, to overcome these problems, we propose a novel transformer model to realize lightweight edge classification. First, based on a Swin transformer backbone, a pure Efficient transformer with mlphead is proposed to accelerate the inference speed. Moreover, explicit and implicit edge enhancement methods are proposed to cope with object edge problems. The experimental results evaluated on the Potsdam and Vaihingen datasets present that the proposed approach significantly improved the final accuracy, achieving a trade-off between computational complexity (Flops) and accuracy (Efficient-L obtaining 3.23% mIoU improvement on Vaihingen and 2.46% mIoU improvement on Potsdam compared with HRCNet_W48). As a result, it is believed that the proposed Efficient transformer will have an advantage in dealing with remote sensing image segmentation problems.","2021-09","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","18","13","","","","","","","","","","English","","","","WOS:000699980700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;133<br/>Total Times Cited:&nbsp;&nbsp;137<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","deep learning; edge; FUSION; pure Efficient transformer; remote sensing; semantic segmentation; Swin transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DVJSLZ5P","journalArticle","2025","Shen, CH; Wu, JZ","Research on credit risk of listed companies: a hybrid model based on TCN and DilateFormer","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-025-86371-7","","The ability to assess and manage corporate credit risk enables financial institutions and investors to mitigate risk, enhance the precision of their decision-making, and adapt their strategies in a prompt and effective manner. The growing quantity of data and the increasing complexity of indicators have rendered traditional machine learning methods ineffective in enhancing the accuracy of credit risk assessment. Consequently, academics have begun to explore the potential of models based on deep learning. In this paper, we apply the concept of combining Transformer and CNN to the financial field, building on the traditional CNN-Transformer model's capacity to effectively process local features, perform parallel processing, and handle long-distance dependencies. To enhance the model's ability to capture financial data over extended periods and address the challenge of high-dimensional financial data, we propose a novel hybrid model, TCN-DilateFormer. This integration improves the accuracy of corporate credit risk assessment. The empirical study demonstrates that the model exhibits superior prediction accuracy compared to traditional machine learning assessment models, thereby offering a novel and efficacious tool for corporate credit risk assessment.","2025-01-21","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","1","15","","","","","","","","","","English","","","","WOS:001403090300027","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Credit risk; Deep learning; DEFAULT PREDICTION; Feature capture; Long-range dependencies; Machine learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5XIZZH4D","journalArticle","2024","Varga, D","Understanding How Image Quality Affects Transformer Neural Networks","SIGNALS","","2624-6120","10.3390/signals5030031","","Deep learning models, particularly transformer architectures, have revolutionized various computer vision tasks, including image classification. However, their performance under different types and levels of noise remains a crucial area of investigation. In this study, we explore the noise sensitivity of prominent transformer models trained on the ImageNet dataset. We systematically evaluate 22 transformer variants, ranging from state-of-the-art large-scale models to compact versions tailored for mobile applications, under five common types of image distortions. Our findings reveal diverse sensitivities across different transformer architectures, with notable variations in performance observed under additive Gaussian noise, multiplicative Gaussian noise, Gaussian blur, salt-and-pepper noise, and JPEG compression. Interestingly, we observe a consistent robustness of transformer models to JPEG compression, with top-5 accuracies exhibiting higher resilience to noise compared to top-1 accuracies. Furthermore, our analysis highlights the vulnerability of mobile-oriented transformer variants to various noise types, underscoring the importance of noise robustness considerations in model design and deployment for real-world applications. These insights contribute to a deeper understanding of transformer model behavior under noisy conditions and have implications for improving the robustness and reliability of deep learning systems in practical scenarios.","2024-09","2025-02-26 20:41:49","2025-02-26 20:41:49","","562-579","","3","5","","","","","","","","","","English","","","","WOS:001323907400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","computer vision; image classification; noise sensitivity; RESOLUTION FACE RECOGNITION; transformer models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8QSVLFRE","journalArticle","2024","Li, JQ; Dai, BT; Niu, YY; Xiao, JH; Wu, YX","Multi-Type Attention for Solving Multi-Depot Vehicle Routing Problems","IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS","","1524-9050","10.1109/TITS.2024.3413077","","In recent years, there has been a growing trend towards using deep reinforcement learning (DRL) to solve the NP-hard vehicle routing problems (VRPs). While much success has been achieved, most of the previous studies solely focused on single-depot VRPs, which became less effective in handling more practical scenarios, such as multi-depot VRPs. Although there are many preprocessing measures, such as natural decomposition, those scenarios are still more challenging to optimize. To resolve this issue, we propose the multi-depot multi-type attention (MD-MTA) to solve the multi-depot VRP (MDVRP) and multi-depot open VRP (MDOVRP), respectively. We design a multi-type attention in the network to combine different types of embeddings and the state of the environment at each step, so as to accurately select the next node to visit and construct the route. We introduce a depot rotation augmentation to enhance solution decoding. Results show that it performs favorably against various representative traditional baselines and DRL-based baselines.","2024-11","2025-02-26 20:41:49","2025-02-26 20:41:49","","17831-17840","","11","25","","","","","","","","","","English","","","","WOS:001252962500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","attention mechanism; Computer architecture; Decision making; Decoding; Deep reinforcement learning; Heuristic algorithms; learning to optimize; multi-depot open vehicle routing problem; multi-depot vehicle routing problem; TABU SEARCH; Training; transformer model; Transformers; Vehicle routing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LF3BYYJX","journalArticle","2024","Anarbekova, G; Ruiz, LGB; Akanova, A; Sharipova, S; Ospanova, N","Fine-Tuning Artificial Neural Networks to Predict Pest Numbers in Grain Crops: A Case Study in Kazakhstan","MACHINE LEARNING AND KNOWLEDGE EXTRACTION","","2504-4990","10.3390/make6020054","","This study investigates the application of different ML methods for predicting pest outbreaks in Kazakhstan for grain crops. Comprehensive data spanning from 2005 to 2022, including pest population metrics, meteorological data, and geographical parameters, were employed to train the neural network for forecasting the population dynamics of Phyllotreta vittula pests in Kazakhstan. By evaluating various network configurations and hyperparameters, this research considers the application of MLP, MT-ANN, LSTM, transformer, and SVR. The transformer consistently demonstrates superior predictive accuracy in terms of MSE. Additionally, this work highlights the impact of several training hyperparameters such as epochs and batch size on predictive accuracy. Interestingly, the second season exhibits unique responses, stressing the effect of some features on model performance. By advancing our understanding of fine-tuning ANNs for accurate pest prediction in grain crops, this research contributes to the development of more precise and efficient pest control strategies. In addition, the consistent dominance of the transformer model makes it suitable for its implementation in practical applications. Finally, this work contributes to sustainable agricultural practices by promoting targeted interventions and potentially reducing reliance on chemical pesticides.","2024-06","2025-02-26 20:41:49","2025-02-26 20:41:49","","1154-1169","","2","6","","","","","","","","","","English","","","","WOS:001256696700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","agriculture; artificial neural networks; bread striped flea; forecasting; REGRESSION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6YRPRJMS","journalArticle","2023","Tran, T; Ekenna, C","Molecular Descriptors Property Prediction Using Transformer-Based Approach","INTERNATIONAL JOURNAL OF MOLECULAR SCIENCES","","1661-6596","10.3390/ijms241511948","","In this study, we introduce semi-supervised machine learning models designed to predict molecular properties. Our model employs a two-stage approach, involving pre-training and fine-tuning. Particularly, our model leverages a substantial amount of labeled and unlabeled data consisting of SMILES strings, a text representation system for molecules. During the pre-training stage, our model capitalizes on the Masked Language Model, which is widely used in natural language processing, for learning molecular chemical space representations. During the fine-tuning stage, our model is trained on a smaller labeled dataset to tackle specific downstream tasks, such as classification or regression. Preliminary results indicate that our model demonstrates comparable performance to state-of-the-art models on the chosen downstream tasks from MoleculeNet. Additionally, to reduce the computational overhead, we propose a new approach taking advantage of 3D compound structures for calculating the attention score used in the end-to-end transformer model to predict anti-malaria drug candidates. The results show that using the proposed attention score, our end-to-end model is able to have comparable performance with pre-trained models.","2023-08","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","15","24","","","","","","","","","","English","","","","WOS:001045644600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","DISEASE; large-scale training; machine learning; molecular property; Plasmodium falciparum; QSAR MODELS; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7F7HGXY5","journalArticle","2022","Yu, Y; Börjesson, K","Chemical transformer compression for accelerating both training and inference of molecular modeling","MACHINE LEARNING-SCIENCE AND TECHNOLOGY","","2632-2153","10.1088/2632-2153/ac99ba","","Transformer models have been developed in molecular science with excellent performance in applications including quantitative structure-activity relationship (QSAR) and virtual screening (VS). Compared with other types of models, however, they are large and need voluminous data for training, which results in a high hardware requirement to abridge time for both training and inference processes. In this work, cross-layer parameter sharing (CLPS), and knowledge distillation (KD) are used to reduce the sizes of transformers in molecular science. Both methods not only have competitive QSAR predictive performance as compared to the original BERT model, but also are more parameter efficient. Furthermore, by integrating CLPS and KD into a two-state chemical network, we introduce a new deep lite chemical transformer model, DeLiCaTe. DeLiCaTe accomplishes 4x faster rate for training and inference, due to a 10- and 3-times reduction of the number of parameters and layers, respectively. Meanwhile, the integrated model achieves comparable performance in QSAR and VS, because of capturing general-domain (basic structure) and task-specific knowledge (specific property prediction). Moreover, we anticipate that the model compression strategy provides a pathway to the creation of effective generative transformer models for organic drugs and material design.","2022-12-01","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","4","3","","","","","","","","","","English","","","","WOS:000876703700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","model compression; molecular modeling; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q76GRYN7","journalArticle","2022","Zhang, JZ; Li, XW; Zhao, XF; Zhang, Z","LLGF-Net: Learning Local and Global Feature Fusion for 3D Point Cloud Semantic Segmentation","ELECTRONICS","","2079-9292","10.3390/electronics11142191","","Three-dimensional (3D) point cloud semantic segmentation is fundamental in complex scene perception. Currently, although various efficient 3D semantic segmentation networks have been proposed, the overall effect has a certain gap to 2D image segmentation. Recently, some transformer-based methods have opened a new stage in computer vision, which also has accelerated the effective development of methods in 3D point cloud segmentation. In this paper, we propose a novel semantic segmentation network named LLGF-Net that can aggregate features from both local and global levels of point clouds, effectively improving the ability to extract feature information from point clouds. Specifically, we adopt the multi-head attention mechanism in the original Transformer model to obtain the local features of point clouds and then use the position-distance information of point clouds in 3D space to obtain the global features. Finally, the local features and global features are fused and embedded into the encoder-decoder network to generate our method. Our extensive experimental results on the 3D point cloud dataset demonstrate the effectiveness and superiority of our method.","2022-07","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","14","11","","","","","","","","","","English","","","","WOS:000831401000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","3D point cloud; local and global; multi-head attention; semantic segmentation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XVBKPR3C","journalArticle","2021","Ahmadzadeh-Shooshtari, B; Rezaei-Zare, A","Analysis of transformer differential protection performance under geomagnetically induced current conditions","ELECTRIC POWER SYSTEMS RESEARCH","","0378-7796","10.1016/j.epsr.2021.107094","","Geomagnetically induced current (GIC) results in the part-cycle saturation of the transformer core and con-tributes to a considerable increase of the harmonic components in the transformer currents. Under such con-ditions, transformer differential protection is expected to be blocked from operation, failing to clear internal short-circuit faults. This paper conducts a detailed analysis of the differential protection performance for various fault types under the GIC conditions. An accurate transformer model, validated by the GIC experimental results, is employed in the time-domain simulations within the EMTP-RV program environment. It is revealed that the GIC makes the differential relay incapable of clearing some internal faults. Moreover, it is shown how some factors, such as the fault resistance, the second harmonic inhibition level, and the transformer loading, affect the relay performance in the GIC conditions. The results highlight the need to modify the differential relay logic in order to prevent irreversible damage to the transformers and improve the power system resiliency and reliability during the GIC. Finally, a potential approach for enhancing the differential protection performance under the GIC conditions is proposed.","2021-05","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","194","","","","","","","","","","English","","","","WOS:000632344500007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","Differential protection; Geomagnetic disturbance (GMD); Geomagnetically induced current (GIC); MODEL; OPERATION; Relay; Short-circuit fault; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C6JAMGWP","journalArticle","2025","Chen, YQ; Zhang, RD","Deep Multiscale Convolutional Model With Multihead Self-Attention for Industrial Process Fault Diagnosis","IEEE TRANSACTIONS ON SYSTEMS MAN CYBERNETICS-SYSTEMS","","2168-2216","10.1109/TSMC.2024.3523708","","In industrial fault diagnosis, traditional methods grapple with challenges, such as nonstationarity, nonlinearity, high dimensionality, and strong coupling. To address these issues, we propose an end-to-end fusion model based on multiscale residual convolutional channel attention and transformer model (MRCC-Transformer). This approach initially leverages a multiscale residual convolutional neural network (CNN) to extract data features across various scales, thereby preventing model degradation and autonomously learning and integrating abundant fault information from multiple monitoring variables. Subsequently, a channel attention mechanism (CAM) is introduced to prioritize focus on pertinent convolutional channels to enhance the network's effectiveness and discriminative capacity. Furthermore, the Transformer is employed to establish dependencies among distinct features to enhance fault diagnosis accuracy. Lastly, the input data is classified for fault diagnosis. The efficacy of the proposed method was validated through simulation experiments on the Tennessee-Eastman (TE) process and an industrial coking furnace. Comparative results demonstrate that the proposed method significantly improves the accuracy of fault diagnosis.","2025-01-15","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","","","","","","","","","","","English","","","","WOS:001400115200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Accuracy; Chemical process; CNN; Convolution; convolutional neural network (CNN); Convolutional neural networks; Data mining; Data models; deep learning; Deep learning; fault diagnosis; Fault diagnosis; Feature extraction; Kernel; NEURAL-NETWORK; self-attention mechanism; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XZTZQWWH","journalArticle","2025","Zhang, N; Yang, G; Fu, ZL; Hou, JS","A Grounding Current Prediction Method Based on Frequency-Enhanced Transformer","ENERGIES","","1996-1073","10.3390/en18010032","","Concerning the problem that the coupling relationship in substation scenarios is complex and the Transformer model makes it difficult to capture the correlation between multiple variables of grounding current, resulting in low accuracy of grounding current prediction, a ground current prediction method based on frequency-enhanced Transformer is proposed. Firstly, in the data preprocessing stage, the best frequency domain decomposition algorithm is designed to obtain the high-frequency and low-frequency component data containing different component features so as to enhance the initial features that the model focuses on. Secondly, the data slicing and embedding module is designed to replace the original embedding module of the Transformer to realize the enhanced extraction of local features of the data. Finally, in the feature extraction stage, an enhanced attention mechanism is introduced to replace the standard attention mechanism to capture the intrinsic features of the sequence time dimension and the variable dimension in parallel so as to improve the extraction ability of Transformer multivariate features. Experimental results on the self-built grounding current dataset and the public dataset show that the proposed method outperforms existing advanced methods, verifying the effectiveness of the proposed method.","2025-01","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","1","18","","","","","","","","","","English","","","","WOS:001393584000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","attention mechanisms; grounding current prediction; SYSTEM; time series; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K2DA3ZPX","journalArticle","2025","Zhang, QH; Zhang, WX; Huang, QZ; Wan, CX; Li, ZH","AMSformer: A Transformer for Grain Storage Temperature Prediction Using Adaptive Multi-Scale Feature Fusion","AGRICULTURE-BASEL","","2077-0472","10.3390/agriculture15010058","","Grain storage temperature prediction is crucial for silo safety and can effectively prevent mold and mildew caused by increasing grain temperature and condensation due to decreasing grain temperature. However, current prediction methods lead to information redundancy when capturing temporal and spatial dependencies, which diminishes prediction accuracy. To tackle this issue, this paper introduces an adaptive multi-scale feature fusion transformer model (AMSformer). Firstly, the model utilizes the adaptive channel attention (ACA) mechanism to adjust the weights of different channels according to the input data characteristics and suppress irrelevant or redundant channels. Secondly, AMSformer employs the multi-scale attention mechanism (MSA) to more accurately capture dependencies at different time scales. Finally, the ACA and MSA layers are integrated by a hierarchical encoder (HED) to efficiently utilize adaptive multi-scale information, enhancing prediction accuracy. In this study, actual grain temperature data and six publicly available datasets are used for validation and performance comparison with nine existing models. The results demonstrate that AMSformer outperforms in 36 out of the 58 test cases, highlighting its significant advantages in prediction accuracy and efficiency.","2025-01","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","1","15","","","","","","","","","","English","","","","WOS:001393461200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","adaptive channel attention mechanism; grain storage temperature prediction; hierarchical encoder; information redundancy; multi-scale attention mechanism","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TXP7W7BR","journalArticle","2024","Zheng, W; Pan, B","A spatiotemporal symmetrical transformer structure for EEG emotion recognition","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2023.105487","","In the field of brain-computer interface, automatic recognition of emotions based on electroencephalogram (EEG) signals is of great significance. At present, deep learning can deeply mine the information in the data, especially the convolutional neural network (CNN) and the recurrent neural network (LSTM), which has remarkably improved the accuracy in numerous fields, hence it is applied by researchers to EEG-based emotional identification research. Nonetheless, existing CNN and LSTM-based models still rely on data preprocessing and feature extraction. Furthermore, CNNs have limitations in perceiving global dependencies while LSTMs have problems such as vanishing gradients in the case of long sequences. In this paper, we proposed the Spatiotemporal Symmetric Transformer Model (STS-Transformer), an effective EEG emotion recognition model, to overcome the current problems. STS-Transformer is an end-to-end framework that directly recognizes emotion from raw EEG signals without data preprocessing and feature extraction. This method achieves 89.86% and 86.83% accuracy respectively in the binary classification of valence and arousal in the DEAP dataset; in the DREAMER dataset, the binary classification accuracy of valence and arousal is 85.09% and 82.32%. Therefore, our method exhibits remarkable advantages over other end-to-end models in similar studies.","2024-01","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","87","","","","","","","","","","English","","","","WOS:001085383900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","EEG; Emotion recognition; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GC8RUYBR","journalArticle","2023","Liu, GM; Zhou, X; Pang, JM; Yue, F; Liu, WF; Wang, JC","Codeformer: A GNN-Nested Transformer Model for Binary Code Similarity Detection","ELECTRONICS","","2079-9292","10.3390/electronics12071722","","Binary code similarity detection is used to calculate the code similarity of a pair of binary functions or files, through a certain calculation method and judgment method. It is a fundamental task in the field of computer binary security. Traditional methods of similarity detection usually use graph matching algorithms, but these methods have poor performance and unsatisfactory effects. Recently, graph neural networks have become an effective method for analyzing graph embeddings in natural language processing. Although these methods are effective, the existing methods still do not sufficiently learn the information of the binary code. To solve this problem, we propose Codeformer, an iterative model of a graph neural network (GNN)-nested Transformer. The model uses a Transformer to obtain an embedding vector of the basic block and uses the GNN to update the embedding vector of each basic block of the control flow graph (CFG). Codeformer iteratively executes basic block embedding to learn abundant global information and finally uses the GNN to aggregate all the basic blocks of a function. We conducted experiments on the OpenSSL, Clamav and Curl datasets. The evaluation results show that our method outperforms the state-of-the-art models.","2023-04","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","7","12","","","","","","","","","","English","","","","WOS:000971067000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","binary security; code similarity detection; neural networks; SEARCH; software analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X558KGJV","journalArticle","2023","Saito, R; Haruyama, S","Estimating time-series changes in social sentiment @Twitter in US metropolises during the COVID-19 pandemic","JOURNAL OF COMPUTATIONAL SOCIAL SCIENCE","","2432-2717","10.1007/s42001-022-00186-4","","Since early 2020, the global coronavirus pandemic has strained economic activities and traditional lifestyles. For such emergencies, our paper proposes a social sentiment estimation model that changes in response to infection conditions and state government orders. By designing mediation keywords that do not directly evoke coronavirus, it is possible to observe sentiment waveforms that vary as confirmed cases increase or decrease and as behavioral restrictions are ordered or lifted over a long period. The model demonstrates guaranteed performance with transformer-based neural network models and has been validated in New York City, Los Angeles, and Chicago, given that coronavirus infections explode in overcrowded cities. The time-series of the extracted social sentiment reflected the infection conditions of each city during the 2-year period from pre-pandemic to the new normal and shows a concurrency of waveforms common to the three cities. The methods of this paper could be applied not only to analysis of the COVID-19 pandemic but also to analyses of a wide range of emergencies and they could be a policy support tool that complements traditional surveys in the future.","2023-04","2025-02-26 20:41:49","2025-02-26 20:41:49","","359-388","","1","6","","","","","","","","","","English","","","","WOS:000884519100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Coronavirus; COVID-19; GPT-3; Location information; Neural network model; Sentiment analysis; Transformer model; Twitter","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VZC4RX6W","journalArticle","2025","Hamidi, A; Kiani, K","Motor Imagery EEG signals classification using a Transformer-GCN approach","APPLIED SOFT COMPUTING","","1568-4946","10.1016/j.asoc.2024.112686","","A Brain-Computer Interface (BCI) serves as a vital link between the brain and both internal and external environments, with broad applications in medicine and rehabilitation. Motor Imagery Electroencephalogram (MIEEG) signals, which capture brain activity during motor imagery tasks, are particularly advantageous due to their spontaneous nature and high temporal resolution. While recent studies have advanced the classification of MIEEG signals, developing a unified model that incorporates all relevant aspects remains a critical challenge. This study aims to construct a comprehensive model by leveraging the unique features of MI-EEG signals. We propose a hybrid approach combining Transformer and Graph Convolutional Network (GCN) techniques to enhance MI-EEG signal classification. The Transformer model is employed for pretraining to emphasize temporal dynamics, while the GCN is designed to capture spatial dependencies. Furthermore, we explore various GCN architectures that integrate frequency and temporal information within the node embeddings. Our method achieves a subject-level average classification accuracy of 97.43 % on the Physionet dataset, outperforming recent models. These findings underscore the importance of integrating frequency, phase, spatial, and temporal information, demonstrating a significant improvement in MI-EEG signal classification accuracy.","2025-02","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","170","","","","","","","","","","English","","","","WOS:001397611600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Classification; GCN; Motor Imagery EEG (MI-EEG); Node embedding; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7LECHDXD","journalArticle","2024","Yi, XL; Fu, Y; Liu, RQ; Zhang, H; Hua, R","TSGET: Two-Stage Global Enhanced Transformer for Automatic Radiology Report Generation","IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS","","2168-2194","10.1109/JBHI.2024.3350077","","Recently, automatic radiology report generation, which targets to generate multiple sentences that can accurately describe medical observations for given X-ray images, has gained increasing attention. Existing methods commonly employ the attention mechanism for accurate word generation. However, such attention-based methods fail to leverage useful image-level global features, thereby limiting the model's reasoning ability. To tackle this challenge, we propose two-stage global enhancement layers to facilitate the Transformer to generate more reliable reports from a global perspective. Specifically, the 1st Global Enhancement Layer (1st GEL) is designed to capture the global visual context features by establishing the relationships between image-level global features and previously generated words. The 2nd Global Enhancement Layer (2nd GEL) is devised to capture the region-global level features by building the relationships between image-level global features and region-level information. The experiments demonstrate that by integrating the aforementioned two-stage global enhancement layers into the Transformer model, our proposal achieves state-of-the-art (SOTA) performance on various Natural Language Generation (NLG) evaluation metrics. Further Clinical Efficacy (CE) evaluations also validate that our proposal is able to predict more critical information.","2024-04","2025-02-26 20:41:49","2025-02-26 20:41:49","","2152-2162","","4","28","","","","","","","","","","English","","","","WOS:001258109000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","attention mechanism; global enhancement; INTRA; radiology report generation; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YQ78E5FH","journalArticle","2024","Kim, D; Ko, YW; Kim, DK; Lee, JG","Analysis of Transformer's Attention Behavior in Sleep Stage Classification and Limiting It to Improve Performance","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3424236","","The transformer architecture has been focused on many tasks like natural language processes, vision tasks and etc. The most important and general requirement of using the transformer-based architecture is that the model must be trained on a large-scale dataset before it can be fine-tuned for a specific task like classification, object detection and etc. However, in this paper, we find that the transformer architecture has better generalization capability to capture the features from data samples for sleep stage classification than CNN-based architectures, despite using a small-scale dataset without pretraining on large-scale dataset. This outcome contradicts the widely-held belief that a transformer architecture is more effective when trained on large datasets. In this paper, we investigate the attention behavior of a transformer model and demonstrate how global and local attentions influence an attention map in a transformer architecture. Finally, through experiments, we show that restricting global attention using 'Masked Multi-Head Self-Attention (M-MHSA)' can lead to improved model generalization in sleep stage classification compared with the previous methodologies and original transformer-based architecture on three different datasets.","2024","2025-02-26 20:41:49","2025-02-26 20:41:49","","95914-95925","","","12","","","","","","","","","","English","","","","WOS:001272159800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","deep learning; Sleep stage classification; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D76WQ58P","journalArticle","2024","Cao, BH; Lv, SS; Fan, MB; Li, C","Conductivity measurement of metal films based on eddy current testing","NONDESTRUCTIVE TESTING AND EVALUATION","","1058-9759","10.1080/10589759.2023.2198234","","Currently, most commercial measuring instruments for electrical conductivity are primarily used to measure the conductivity of thick specimens. However, measuring the conductivity of thin films with these instruments can be challenging due to the limitation of skin depth. To address this issue, a conductivity measurement method for metal films has been proposed based on the transformer model of an eddy current sensor. It can be found that the phase of impedance change is related to the thickness and conductivity of the specimen when the thickness of the specimen is less than the skin depth. To validate the method, a finite element model is employed to simulate it, and the relative errors of conductivity measurements are analysed. The experimental results are then compensated using the estimated errors, and the influence of excitation frequency is evaluated. Finally, specimens with different conductivities and thicknesses are prepared to verify the method. The results indicate that the relative errors fall within 7.36% before compensation and within 5.25% after compensation, which demonstrates the feasibility of the proposed method for conductivity measurement of metal films.","2024-02-17","2025-02-26 20:41:49","2025-02-26 20:41:49","","366-383","","2","39","","","","","","","","","","English","","","","WOS:000963465500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","conductivity; Eddy current; ELECTRICAL-CONDUCTIVITY; MAGNETIC-PERMEABILITY; metal films; MODEL; phase of impedance change; SIMULATION; THICKNESS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LGU26EKJ","journalArticle","2024","Divya, S; Sripriya, N; Andrew, J; Mazzara, M","Unified extractive-abstractive summarization: a hybrid approach utilizing BERT and transformer models for enhanced document summarization","PEERJ COMPUTER SCIENCE","","2376-5992","10.7717/peerj-cs.2424","","With the exponential proliferation of digital documents, there arises a pressing need for automated document summarization (ADS). Summarization, a compression technique, condenses a source document into concise sentences that encapsulate its salient information for summary generation. A primary challenge lies in crafting a dependable summary, contingent upon both extracted features and human- established parameters. This article introduces an intelligent methodology that seamlessly integrates extractive and abstractive techniques to ensure heightened relevance between the input document and its summary. Initially, input sentences undergo transformation into representations utilizing BERT, subsequently transposed into a symmetric matrix based on their similarity. Semantically congruent sentences are then extracted from this matrix to construct an extractive summary. The transformer model integrates an objective function highly symmetric and invariant under unitary transformation for language generation. This model refines the extracted informative sentences and generates an abstractive summary akin to manually crafted summaries. Employing this hybrid summarization technique on the CNN/DailyMail dataset and DUC2004, we evaluate its efficacy using ROUGE metrics. Results demonstrate the superiority of our proposed technique over conventional summarization methods.","2024-11-18","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","10","","","","","","","","","","English","","","","WOS:001380519400004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","Abstractive summarization; BERT; CNN; Document summarization; Transformer models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N2CQ2VPD","journalArticle","2024","Luo, LG; Lu, J; Chen, XG; Zhang, KB; Zhou, J","LSGRNet: Local Spatial Latent Geometric Relation Learning Network for 3D point cloud semantic segmentation","COMPUTERS & GRAPHICS-UK","","0097-8493","10.1016/j.cag.2024.104053","","In recent years, remarkable ability has been demonstrated by the Transformer model in capturing remote dependencies and improving point cloud segmentation performance. However, localized regions separated from conventional sampling architectures have resulted in the destruction of structural information of instances and a lack of exploration of potential geometric relationships between localized regions. To address this issue, a Local Spatial Latent Geometric Relation Learning Network (LSGRNet) is proposed in this paper, with the geometric properties of point clouds serving as a reference. Specifically, spatial transformation and gradient computation are performed on the local point cloud to uncover potential geometric relationships within the local neighborhood. Furthermore, a local relationship aggregator based on semantic and geometric relationships is constructed to enable the interaction of spatial geometric structure and information within the local neighborhood. Simultaneously, boundary interaction feature learning module is employed to learn the boundary information of the point cloud, aiming to better describe the local structure. The experimental results indicate that excellent segmentation performance is exhibited by the proposed LSGRNet in benchmark tests on the indoor datasets S3DIS and ScanNetV2, as well as the outdoor datasets SemanticKITTI and Semantic3D.","2024-11","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","124","","","","","","","","","","English","","","","WOS:001301631300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","Point cloud segmentation; Spatial geometric structure; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4WPJUYPV","journalArticle","2024","Min, H; Hong, S; Song, J; Son, B; Noh, B; Moon, J","SolarFlux Predictor: A Novel Deep Learning Approach for Photovoltaic Power Forecasting in South Korea","ELECTRONICS","","2079-9292","10.3390/electronics13112071","","We present SolarFlux Predictor, a novel deep-learning model designed to revolutionize photovoltaic (PV) power forecasting in South Korea. This model uses a self-attention-based temporal convolutional network (TCN) to process and predict PV outputs with high precision. We perform meticulous data preprocessing to ensure accurate data normalization and outlier rectification, which are vital for reliable PV power data analysis. The TCN layers are crucial for capturing temporal patterns in PV energy data; we complement them with the teacher forcing technique during the training phase to significantly enhance the sequence prediction accuracy. By optimizing hyperparameters with Optuna, we further improve the model's performance. Our model incorporates multi-head self-attention mechanisms to focus on the most impactful temporal features, thereby improving forecasting accuracy. In validations against datasets from nine regions in South Korea, SolarFlux outperformed conventional methods. The results indicate that SolarFlux is a robust tool for optimizing PV systems' management and operational efficiency and can contribute to South Korea's pursuit of sustainable energy solutions.","2024-06","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","11","13","","","","","","","","","","English","","","","WOS:001245497200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","energy data analysis; NEURAL-NETWORKS; OPTIMIZATION; Optuna; photovoltaic power forecasting; self-attention mechanism; SYSTEMS; teacher forcing; temporal convolutional network; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ULXBJJM4","journalArticle","2024","Zhang, YR; Su, C; Wu, JJ; Liu, H; Xie, MJ","Trend-augmented and temporal-featured Transformer network with multi-sensor signals for remaining useful life prediction","RELIABILITY ENGINEERING & SYSTEM SAFETY","","0951-8320","10.1016/j.ress.2023.109662","","Deep learning method has obtained abundant achievements in remaining useful life (RUL) prediction, which can steer the preventive maintenance decision-making for improving the reliability of industrial systems. However, the existing deep models often fail to consider mechanical degradation rules, and can not capture the temporal and featured dependencies effectively. To address such issues, this study proposes an improved Transformer network for RUL prediction with multi-sensor signals. Specifically, the trend augmentation module (TAM) and time-feature attention module (TFAM) are embedded into the traditional Transformer model. In TAM, a bidirectional gated recurrent unit (Bi-GRU) network is used to extract the hidden temporal information and a novel distance function is presented to improve the attention distribution. In TFAM, attention calculations are performed sequentially in both the feature and time dimensions to synthetically capture both the feature and time dependencies. Two benchmark experiments are conducted with the CMAPSS and Milling datasets respectively. The results indicate that the proposed approach outperforms state-of-the-art approaches and possesses deep interpretability.","2024-01","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","241","","","","","","","","","","English","","","","WOS:001137992800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;37<br/>Total Times Cited:&nbsp;&nbsp;37<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","BELIEF; multi -sensor signals; PROGNOSTICS; Remaining useful life prediction; time -feature attention; Transformer; trend augmentation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J2GR8J56","journalArticle","2022","Mombello, EE; Venerdini, GG; Flórez, GAD","Optimized high-frequency white-box transformer model for implementation in ATP-EMTP.","ELECTRIC POWER SYSTEMS RESEARCH","","0378-7796","10.1016/j.epsr.2022.108709","","Although several high frequency white-box transformer models have been proposed in the literature, the methodology for their implementation in some programs based on EMTP has not been addressed in detail. This is true in particular for ATP, for which the representation of large transformer models is particularly problematic. This work aims to enable the use of ATP to model detailed transformer equivalent circuits, which would otherwise be seriously questioned. To establish these circuit models, the following must be taken into account: model reduction, magnetic circuit decoupling, avoid numerical instability, limit and optimize the use of resistors, generate ATP versions capable of processing large models. To this end, three generally valid methodologies are presented to reduce the model without compromising the accuracy of the calculation results and, finally, additional specific methodologies are implemented to reduce and adapt the models in the ATP environment. The application of these methodologies results in six possible variants of reduced models, which were successfully validated through a case study used by CIGRE JWG A2/C4.52 to verify the accuracy of transformer models.","2022-12","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","213","","","","","","","","","","English","","","","WOS:000860031400005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","Alternative transient program (ATP); IMPULSE VOLTAGE DISTRIBUTION; Power transformer; Reduced white -box models; Transient overvoltages; TRANSIENTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DBKNPT4I","journalArticle","2025","Liu, Y; Li, XY; Liu, Y; Zhong, W","SimpliFusion: a simplified infrared and visible image fusion network","VISUAL COMPUTER","","0178-2789","10.1007/s00371-024-03423-1","","This paper introduces SimpliFusion, a network designed for the fusion of infrared and visible images, leveraging a simplified transformer architecture. SimpliFusion is engineered to adeptly handle both long-range and short-range information, facilitating a more effective integration of infrared and visible data. The core of SimpliFusion lies in its innovative use of a streamlined transformer model, which simplifies the traditional complexities associated with transformer networks while maintaining high efficiency and accuracy in image fusion tasks. The network architecture of SimpliFusion incorporates specialized attention mechanisms that are adept at capturing and integrating diverse spatial and temporal features from both infrared and visible spectra. This includes an intra-domain fusion unit based on self-attention for processing within each spectral domain, and an inter-domain fusion unit based on cross-attention for bridging and integrating information across the infrared and visible domains. These units are specifically designed to exploit the long-range dependencies characteristic of infrared data and the detailed textural information prevalent in visible images. Extensive experiments conducted on a range of multi-modal image fusion scenarios, including both multi-modal image fusion and object detection, demonstrate the superiority of SimpliFusion.","2025-01","2025-02-26 20:41:49","2025-02-26 20:41:49","","1335-1350","","2","41","","","","","","","","","","English","","","","WOS:001234536800005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;96</p>","","","ARCHITECTURE; ENSEMBLE; FOCUS; FRAMEWORK; Image fusion; Image processing; Low-level vision; MULTISCALE TRANSFORM; NEST; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K6V2TWVP","journalArticle","2024","Zhang, CL; Liu, L; Dai, JJ; Liu, X; He, WF; Chan, YP; Xie, YQ; Chi, F; Liang, XK","XTransCT: ultra-fast volumetric CT reconstruction using two orthogonal x-ray projections for image-guided radiation therapy via a transformer network","PHYSICS IN MEDICINE AND BIOLOGY","","0031-9155","10.1088/1361-6560/ad3320","","Objective. The aim of this study was to reconstruct volumetric computed tomography (CT) images in real-time from ultra-sparse two-dimensional x-ray projections, facilitating easier navigation and positioning during image-guided radiation therapy. Approach. Our approach leverages a voxel-sapce-searching Transformer model to overcome the limitations of conventional CT reconstruction techniques, which require extensive x-ray projections and lead to high radiation doses and equipment constraints. Main results. The proposed XTransCT algorithm demonstrated superior performance in terms of image quality, structural accuracy, and generalizability across different datasets, including a hospital set of 50 patients, the large-scale public LIDC-IDRI dataset, and the LNDb dataset for cross-validation. Notably, the algorithm achieved an approximately 300% improvement in reconstruction speed, with a rate of 44 ms per 3D image reconstruction compared to former 3D convolution-based methods. Significance. The XTransCT architecture has the potential to impact clinical practice by providing high-quality CT images faster and with substantially reduced radiation exposure for patients. The model's generalizability suggests it has the potential applicable in various healthcare settings.","2024-04-21","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","8","69","","","","","","","","","","English","","","","WOS:001196318500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","cone-beam CT; image-guided radiation therapy; ultra-sparse view reconstruction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8R63IAHL","journalArticle","2024","Bian, JC; Zheng, M; Liu, H; Mao, JH; Li, H; Tan, C","SimpleViTFi: A Lightweight Vision Transformer Model for Wi-Fi-Based Person Identification","IEICE TRANSACTIONS ON COMMUNICATIONS","","0916-8516","10.23919/transcom.2023EBP3102","","Wi-Fi-based person identification (PI) tasks are performed by analyzing the fluctuating characteristics of the Channel State Information (CSI) data to determine whether the person's identity is legitimate. This technology can be used for intrusion detection and keyless access to restricted areas. However, the related research rarely considers the restricted computing resources and the complexity of real -world environments, resulting in lacking practicality in some scenarios, such as intrusion detection tasks in remote substations without public network coverage. In this paper, we propose a novel neural network model named SimpleViTFi, a lightweight classification model based on Vision Transformer (ViT), which adds a downsampling mechanism, a distinctive patch embedding method and learnable positional embedding to the cropped ViT architecture. We employ the latest IEEE 802.11ac 80MHz CSI dataset provided by [1]. The CSI matrix is abstracted into a special ""image"" after pre-processing and fed into the trained SimpleViTFi for classification. The experimental results demonstrate that the proposed SimpleViTFi has lower computational resource overhead and better accuracy than traditional classification models, reflecting the robustness on LOS or NLOS CSI data generated by different Tx-Rx devices and acquired by different monitors.","2024-04","2025-02-26 20:41:49","2025-02-26 20:41:49","","377-386","","4","E107B","","","","","","","","","","English","","","","WOS:001235165000003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","CSI; lightweight model; person identification; vision transformer; Wi-Fi sensing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PRB3Z4EU","journalArticle","2024","Yang, ZH; Zhang, QY; Chang, WF; Xiao, P; Li, ML","EGFormer: An Enhanced Transformer Model with Efficient Attention Mechanism for Traffic Flow Forecasting","VEHICLES","","2624-8921","10.3390/vehicles6010005","","Due to the regular influence of human activities, traffic flow data usually exhibit significant periodicity, which provides a foundation for further research on traffic flow data. However, the temporal dependencies in traffic flow data are often obscured by entangled temporal regularities, making it challenging for general models to capture the intrinsic functional relationships within the data accurately. In recent years, a plethora of methods based on statistics, machine learning, and deep learning have been proposed to tackle these problems of traffic flow forecasting. In this paper, the Transformer is improved from two aspects: (1) an Efficient Attention mechanism is proposed, which reduces the time and memory complexity of the Scaled Dot Product Attention; (2) a Generative Decoding mechanism instead of a Dynamic Decoding operation, which accelerates the inference speed of the model. The model is named EGFormer in this paper. Through a lot of experiments and comparative analysis, the authors found that the EGFormer has better ability in the traffic flow forecasting task. The new model has higher prediction accuracy and shorter running time compared with the traditional model.","2024-03","2025-02-26 20:41:49","2025-02-26 20:41:49","","120-139","","1","6","","","","","","","","","","English","","","","WOS:001192580400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Generative Decoding mechanism; Multi-Head Efficient Self-Attention mechanism; PREDICTION; traffic flow forecasting; Transformer; VOLUME","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y2Y335SG","journalArticle","2024","Abiyev, RH; Altabel, MZ; Darwish, M; Helwan, A","A Multimodal Transformer Model for Recognition of Images from Complex Laparoscopic Surgical Videos","DIAGNOSTICS","","2075-4418","10.3390/diagnostics14070681","","The determination of the potential role and advantages of artificial intelligence-based models in the field of surgery remains uncertain. This research marks an initial stride towards creating a multimodal model, inspired by the Video-Audio-Text Transformer, that aims to reduce negative occurrences and enhance patient safety. The model employs text and image embedding state-of-the-art models (ViT and BERT) to assess their efficacy in extracting the hidden and distinct features from the surgery video frames. These features are then used as inputs for convolution-free Transformer architectures to extract comprehensive multidimensional representations. A joint space is then used to combine the text and image features extracted from both Transformer encoders. This joint space ensures that the relationships between the different modalities are preserved during the combination process. The entire model was trained and tested on laparoscopic cholecystectomy (LC) videos encompassing various levels of complexity. Experimentally, a mean accuracy of 91.0%, a precision of 81%, and a recall of 83% were reached by the model when tested on 30 videos out of 80 from the Cholec80 dataset.","2024-04","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","7","14","","","","","","","","","","English","","","","WOS:001200879000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","BERT; laparoscopic videos; text and image embedding; transformer; transformer encoders; ViT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I46UTWPR","journalArticle","2023","Du, NH; Long, NH; Ha, KN; Hoang, NV; Huong, TT; Tran, KP","Trans-Lighter: A light-weight federated learning-based architecture for Remaining Useful Lifetime prediction","COMPUTERS IN INDUSTRY","","0166-3615","10.1016/j.compind.2023.103888","","Predictive maintenance (PdM) plays an important role in industrial manufacturing. One of the most fundamen-tal ideas underlying many PdM solutions is to estimate Remaining Useful Life (RUL) of machines. Recently, advanced deep learning models like convolutional neural network (CNN) and long short-term memory (LSTM) have been widely used for RUL prediction. However, these models also have certain limitations because of the difficulty in dealing with long-term dependencies in time series data. In this study, we propose a novel model based on transformer networks to overcome this difficulty. Rather than using the full structure of a transformer model, we exploit only the encoder combined with a linear layer. The Bayesian Optimization algorithm is applied to find optimal hyperparameters for the encoder. Experiments on widely used turbofan engine datasets show that our proposed method significantly outperforms the state-of-the-art RUL prediction methods by up to 25% in terms of predicting remaining usable life. We also provide a solution for the problem of preserving the privacy and security of data in smart manufacturing by designing a Federated Learning-based architecture for RUL using the proposed transformer-based model.","2023-06","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","148","","","","","","","","","","English","","","","WOS:000956565900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;23<br/>Total Times Cited:&nbsp;&nbsp;24<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Bayesian optimization; Federated learning; Remaining Useful Lifetime; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8V68ZGKA","journalArticle","2025","Zeng, F; Wang, MS; Pan, Y; Lv, SK; Miao, HY; Han, HC; Yuan, XD","Distributed Data Privacy Protection via Collaborative Anomaly Detection","ELECTRONICS","","2079-9292","10.3390/electronics14020295","","Current anomaly detection methods for charging stations primarily rely on centralized network architectures with federated learning frameworks. However, the rapid increase in the number of charging stations and the expanding scale of these networks impose significant communication traffic loads. Consequently, it is essential to explore the relationship between data aggregation among charging stations and the anomaly detection accuracy at individual stations. In this paper, we address efficient anomaly detection in charging stations and propose a distributed anomaly detection algorithm powered by federated learning. To be specific, we introduce a distributed privacy-preserving data aggregation scheme, where a Transformer model is adopted to effectively smooth abnormal data fluctuations, minimizing disruptions to network aggregation nodes. Furthermore, we develop a distributed federated learning framework incorporating an efficient parameter update method without requiring prior knowledge or a central node. Compared with some existing detection solutions, the proposed approach significantly reduces communication bandwidth requirements while maintaining anomaly detection accuracy and mitigating data isolation issues. Extensive experiments demonstrate that the proposed algorithm not only achieves high accuracy in detecting anomalies in electric vehicle charging stations but also ensures robust user data privacy protection.","2025-01","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","2","14","","","","","","","","","","English","","","","WOS:001405270200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","anomalous data; CHARGING STATION; data aggregation; distributed learning; privacy protection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U3QE29J6","journalArticle","2023","Banks, DM; Bekker, JC; Vermeulen, HJ","Investigating Empirical Mode Decomposition in the Parameter Estimation of a Three-Section Winding Model","ENERGIES","","1996-1073","10.3390/en16041668","","Parameter estimation represents an important aspect of modeling electromagnetic systems, and a wide range of parameter estimation strategies has been explored in literature. Most parameter estimation methodologies make use of either time-domain or frequency-domain responses as measured from the terminals of the device under test. Very limited research has, however, been conducted into exploring the use of modal decomposition strategies on the time-domain waveforms for parameter estimation applications. In this paper, the use of Empirical Mode Decomposition for estimating the parameters of a three-section lumped parameter transformer model is explored. A novel approach is proposed to define the optimization cost function in terms of the intrinsic modes of simulated time-domain waveforms. The results are compared with results obtained using classical time-domain and frequency-domain approaches. It is shown through an impulse response test that weighting the modes obtained from the Inferred Empirical Mode Decomposition approach presented in this work offers advantages in terms of accurately representing the target model transfer function dynamics and can assist in interpreting the various dynamic modes associated with the target model.","2023-02","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","4","16","","","","","","","","","","English","","","","WOS:000945157600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","empirical mode decomposition; EQUIVALENT-CIRCUIT; HIGH-FREQUENCY PARAMETERS; IDENTIFICATION; MAXIMUM-LIKELIHOOD-ESTIMATION; parameter estimation; particle swarm; TRANSFORMER; winding model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UYCJP7AK","journalArticle","2023","Qin, PP; Li, X; Bin, SL; Wu, FM; Pang, YZ","Research on transformer and long short-term memory neural network car-following model considering data loss","MATHEMATICAL BIOSCIENCES AND ENGINEERING","","1547-1063","10.3934/mbe.2023869","","There is limited research on the loss and reconstruction of car-following features. To delve into car-following's characteristics, we propose a car-following model based on LSTM-Transformer. By fully leveraging the advantages of long short-term memory (LSTM) and transformer models, this study focuses on reconstructing the input car-following features. Training and testing were conducted using 700 car-following segments extracted from a natural driving dataset and the Next Generation Simulation (NGSIM) dataset, and the proposed model was compared with an LSTM model and an intelligent driver model. The results demonstrate that the model performs exceptionally well in feature reconstruction. Moreover, compared to the other two models, it effectively captures the car-following features and accurately predicts the position and speed of the following car when features are lost. Additionally, the LSTM-Transformer model accurately reproduces traffic phenomena, such as asymmetric driving behavior, traffic oscillations and lag, by reconstructing the lost features. Therefore, the LSTM-Transformer car-following model proposed in this study exhibits advantages in feature reconstruction and reproducing traffic phenomena compared to other models.","2023","2025-02-26 20:41:49","2025-02-26 20:41:49","","19617-19635","","11","20","","","","","","","","","","English","","","","WOS:001103566500005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","car-following; car-following features; IMPUTATION; long short-term memory; reconstruction; TRAFFIC FLOW; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FZVIV63H","journalArticle","2024","Casella, M; Milano, N; Dolce, P; Marocco, D","Transformers deep learning models for missing data imputation: an application of the ReMasker model on a psychometric scale","FRONTIERS IN PSYCHOLOGY","","1664-1078","10.3389/fpsyg.2024.1449272","","Introduction: Missing data in psychometric research presents a substantial challenge, impacting the reliability and validity of study outcomes. Various factors contribute to this issue, including participant non-response, dropout, or technical errors during data collection. Traditional methods like mean imputation or regression, commonly used to handle missing data, rely upon assumptions that may not hold on psychological data and can lead to distorted results. Methods: This study aims to evaluate the effectiveness of transformer-based deep learning for missing data imputation, comparing ReMasker, a masking autoencoding transformer model, with conventional imputation techniques (mean and median imputation, Expectation-Maximization algorithm) and machine learning approaches (K-nearest neighbors, MissForest, and an Artificial Neural Network). A psychometric dataset from the COVID distress repository was used, with imputation performance assessed through the Root Mean Squared Error (RMSE) between the original and imputed data matrices. Results: Results indicate that machine learning techniques, particularly ReMasker, achieve superior performance in terms of reconstruction error compared to conventional imputation techniques across all tested scenarios. Discussion: This finding underscores the potential of transformer-based models to provide robust imputation in psychometric research, enhancing data integrity and generalizability.","2024-12-17","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","15","","","","","","","","","","English","","","","WOS:001390009400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","artificial intelligence; deep learning; machine learning; missing data; psychometrics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UPAZ9GQ7","journalArticle","2024","Xin, ZW; Sirejiding, S; Lu, YX; Ding, Y; Wang, CL; Alsarhan, T; Lu, HT","TFUT: Task fusion upward transformer model for multi-task learning on dense prediction","COMPUTER VISION AND IMAGE UNDERSTANDING","","1077-3142","10.1016/j.cviu.2024.104014","","Transformer-based advancements have shown great promise in solving multi-task learning on dense prediction tasks. Well-designed task interaction modules of these methods further improve the performances by effectively transferring contextual information between tasks. However, many of these methods do not leverage the target task to guide contextual information from the source task. We propose the Task Fusion Upward Transformer (TFUT) model for multi-task learning on dense prediction. To facilitate task interaction, we introduce the Asymmetric Cross Task Interaction module, which utilizes asymmetric transmission in attention. During similarity calculations, the model leverages the target task to guide the expression of contextual information from the source task, ensuring effective transmission of the context information. In order to avoid the loss of detail and the discontinuity of gradient in upsampling, the Upward Transformer Decoder is designed to extract and align multi-scale features using multi-level convolution. The effectiveness of the proposed model has been demonstrated through experiments on the NYUD-v2 dataset and the PASCAL Context dataset. The experimental results show that this model has achieved optimal performance in various single task and multi-task scenarios.","2024-07","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","244","","","","","","","","","","English","","","","WOS:001293330800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Dense prediction; Multi-task learning; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RXDSARVJ","journalArticle","2023","Choi, S; Youn, Y; Kang, J; Kim, S; Jeong, Y; Im, Y; Seo, Y; Kim, W; Choi, M; Lee, Y","Waterbody Detection for the Reservoirs in South Korea Using Swin Transformer and Sentinel-1 Images","KOREAN JOURNAL OF REMOTE SENSING","","1225-6161","10.7780/kjrs.2023.39.5.3.6","","In this study, we propose a method to monitor the surface area of agricultural reservoirs in South Korea using Sentinel-1 synthetic aperture radar images and the deep learning model, Swin Transformer. Utilizing the Google Earth Engine platform, datasets from 2017 to 2021 were constructed for seven agricultural reservoirs, categorized into 700 K-ton, 900 K-ton, and 1.5 M-ton capacities. For four of the reservoirs, a total of 1,283 images were used for model training through shuffling and 5-fold cross-validation techniques. Upon evaluation, the Swin Transformer Large model, configured with a window size of 12, demonstrated superior semantic segmentation performance, showing an average accuracy of 99.54% and a mean intersection over union (mIoU) of 95.15% for all folds. When the best -performing model was applied to the datasets of the remaining three reservoirs for validation, it achieved an accuracy of over 99% and mIoU of over 94% for all reservoirs. These results indicate that the Swin Transformer model can effectively monitor the surface area of agricultural reservoirs in South Korea.","2023-10","2025-02-26 20:41:49","2025-02-26 20:41:49","","949-965","","5-3","39","","","","","","","","","","English","","","","WOS:001110843100006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Agricultural reservoir; SAR; SEGMENTATION; Sentinel -1; Swin Transformer; Waterbody detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M3KNSJRU","journalArticle","2023","Rozowsky, J; Gao, JH; Borsari, B; Yang, YT; Galeev, T; Gürsoy, G; Epstein, CB; Xiong, K; Xu, JR; Li, TX; Liu, J; Yu, KY; Berthel, A; Chen, ZL; Navarro, F; Sun, MS; Wright, J; Chang, JS; Cameron, CJF; Shoresh, N; Gaskell, E; Drenkow, J; Adrian, J; Aganezov, S; Aguet, F; Balderrama-Gutierrez, G; Banskota, S; Corona, GB; Chee, S; Chhetri, SB; Martins, GCC; Danyko, C; Davis, CA; Farid, D; Farrell, NP; Gabdank, I; Gofin, Y; Gorkin, DU; Gu, MT; Hecht, V; Hitz, BC; Issner, R; Jiang, YZ; Kirsche, M; Kong, XM; Lam, BR; Li, ST; Li, B; Li, XQ; Lin, KZ; Luo, RB; Mackiewicz, M; Meng, R; Moore, JE; Mudge, J; Nelson, N; Nusbaum, C; Popov, I; Pratt, HE; Qiu, YJ; Ramakrishnan, S; Raymond, J; Salichos, L; Scavelli, A; Schreiber, JM; Sedlazeck, FJ; See, LH; Sherman, RM; Shi, X; Shi, MY; Sloan, CA; Strattan, JS; Tan, Z; Tanaka, FY; Vlasova, A; Wang, J; Werner, J; Williams, B; Xu, M; Yan, CF; Yu, L; Zaleski, C; Zhang, J; Ardlie, K; Cherry, JM; Mendenhall, EM; Noble, WS; Weng, ZP; Levine, ME; Dobin, A; Wold, B; Mortazavi, A; Ren, B; Gillis, J; Myers, RM; Snyder, MP; Choudhary, J; Milosavljevic, A; Schatz, MC; Bernstein, BE; Guigó, R; Gingeras, TR; Gerstein, M","The EN-TEx resource of multi-tissue personal epigenomes & variant-impact models","CELL","","0092-8674","10.1016/j.cell.2023.02.018","","Understanding how genetic variants impact molecular phenotypes is a key goal of functional genomics, currently hindered by reliance on a single haploid reference genome. Here, we present the EN-TEx resource of 1,635 open-access datasets from four donors (-30 tissues 3 -15 assays). The datasets are mapped to matched, diploid genomes with long-read phasing and structural variants, instantiating a catalog of >1 million allele-specific loci. These loci exhibit coordinated activity along haplotypes and are less conserved than corresponding, non-allele-specific ones. Surprisingly, a deep-learning transformer model can predict the allele specific activity based only on local nucleotide-sequence context, highlighting the importance of transcription-factor-binding motifs particularly sensitive to variants. Furthermore, combining EN-TEx with existing genome annotations reveals strong associations between allele-specific and GWAS loci. It also enables models for transferring known eQTLs to difficult-to-profile tissues (e.g., from skin to heart). Overall, ENTEx provides rich data and generalizable models for more accurate personal functional genomics.","2023-03-30","2025-02-26 20:41:49","2025-02-26 20:41:49","","1493-+","","7","186","","","","","","","","","","English","","","","WOS:001037039300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;22<br/>Total Times Cited:&nbsp;&nbsp;23<br/>Cited Reference Count:&nbsp;&nbsp;173</p>","","","ALLELE-SPECIFIC EXPRESSION; CELIAC-DISEASE; CORONARY-ARTERY-DISEASE; DNA METHYLATION; GENE-EXPRESSION; INTEGRATIVE ANALYSIS; RNA-SEQ; STRUCTURAL VARIATION; TRANSPOSABLE ELEMENTS; UCSC GENOME BROWSER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WWY5JHDV","journalArticle","2022","Yang, YM; Xing, DP; Xu, B","Efficient Spatiotemporal Transformer for Robotic Reinforcement Learning","IEEE ROBOTICS AND AUTOMATION LETTERS","","2377-3766","10.1109/LRA.2022.3186494","","Intense spatiotemporal coupling states frequently appear in robotic tasks, and this coupling enriches the information encapsulated in each state. Taking advantage of historical observations can provide more information about the robot, especially for partially observable Markov decision processes. How to deal with this coupling remains a challenging issue in robotic reinforcement learning (RL), and we allege that the imbalanced processing capability of spatiotemporal details is one of the bottlenecks of the vanilla transformer model in learning robotic policies. To address this problem, we novelly propose an efficient spatiotemporal transformer structure. To our knowledge, this work is the first to improve the transformer with spatiotemporal information in RL. In each attention block, we sequentially execute attention computation twice: the first to process the temporal sequence of the input and the latter to manage the spatial state. This input reconstruction enables sufficient information extraction to promote data efficiency. We also add correlation encoding into the query and key computation of multi-head attention, providing the operability of associating states between and within time steps. We evaluate the proposed approach on several robot tasks, and it outperforms state-of-the-art transformer-based online RL.","2022-07","2025-02-26 20:41:49","2025-02-26 20:41:49","","7982-7989","","3","7","","","","","","","","","","English","","","","WOS:000838441200026","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","reinforcement learning; Spatiotemporal transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TEZFSHAK","journalArticle","2025","Li, JY; Xu, DZ; Pan, TL; Jiang, DN","STATE OF HEALTH PREDICTION OF LITHIUM-ION BATTERIES BASED ON TCN-TRANSFORMER","INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL","","1349-4198","10.24507/ijicic.21.01.17","",". Lithium-ion batteries are widely used in many fields because of their excellent performance, but in the long-term use process, lithium-ion batteries are facing problems such as capacity decline, which affects the performance of the equipment. Therefore, accurate prediction of battery health is an urgent problem to be solved. In this paper, a hybrid neural network model is constructed by combining temporal convolutional network (TCN) and Transformer. A lithium-ion battery state of health (SOH) prediction method combining XGBoost, T-SNE and TCN-Transformer was proposed. This paper collected nine lithium-ion battery health indicators (HI), and screened the importance of health indicators through XGBoost. T-SNE is used to reduce the dimension of the features, and the fused health indicators are input into the TCN-Transformer network to predict the SOH of lithium-ion batteries. The proposed method is validated using the NASA battery dataset, and compared with the LSTM model, GRU model, and RNN model. The experimental results show that the TCN-Transformer model can predict the SOH of lithium-ion batteries more accurately, and has good robustness and generalization.","2025-02","2025-02-26 20:41:49","2025-02-26 20:41:49","","17-35","","1","21","","","","","","","","","","English","","","","WOS:001413920200002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","Lithium-ion battery; MODEL; network; State of health; Temporal convolutional; Transformer; XGBoost","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5CLMEUZS","journalArticle","2024","Kim, JH; Kwon, GR","Unsupervised Visual Anomaly Detection Using Self-Supervised Pre-Trained Transformer","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3454753","","In the various industrial manufacturing processes, the automatic visual inspection system is an essential part as it reduces the chances of delivering defective products and the cost of training and hiring experts for manual inspection. In this work, we propose a new unsupervised anomaly detection method inspired by the masked language model for the automatic visual inspection system. The proposed method consists of an image tokenizer and two subnetworks, a reconstruction subnetwork, and a segmentation subnetwork. We adopt a pre-trained self-supervised vision Transformer model to use it as an image tokenizer. Our first subnetwork is trained to predict the anomaly-free patch tokens and the second subnetwork is trained to produce anomaly segmentation results from both the reconstructed and input patch tokens. During training, only the two subnetworks are optimized, and parameters of an image tokenizer are frozen. Experimental results show that the proposed method exhibits better performance than conventional methods in detecting defective products by achieving 99.05% I-AUROC on MVTecAD dataset and 94.8% I-AUROC on BTAD.","2024","2025-02-26 20:41:49","2025-02-26 20:41:49","","127604-127613","","","12","","","","","","","","","","English","","","","WOS:001316125700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Anomaly detection; Computational modeling; Data augmentation; data-augmentation; Feature extraction; Image reconstruction; Image segmentation; Location awareness; self-supervised learning; Self-supervised learning; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3ZTK5YFA","journalArticle","2023","Zuo, L; Cao, XB; Zhu, LS; Ding, YQ; Sun, MT","Research on the Design Method of UHF Antenna under the Condition of Changing Tag Distribution Density br","JOURNAL OF ELECTRONICS & INFORMATION TECHNOLOGY","","1009-5896","10.11999/JEIT211281","","In view of the problem that the change of the density of the label distribution will lead to the change of the impedance matching relationship between the antenna and the load, and then affect the systemperformance. Based on the theory of electromagnetic wave propagation and the working principle of RadioFrequency IDentification (RFID), the communication link models of RFID system with sparse and dense tagsare derived. Based on the transformer model and the two-port network analysis method, the mutual impedanceexpression of the tag antenna in the dense distribution state is derived. Using power transmission coefficientand backscattering modulation factor, the influence of tag density on RFID system performance is analyzed.Based on the principle of loading bar matching, an optimal design method for label antenna is proposed.Simulation and actual measurement results show that the performance of the improved tag is 16% higher thanthat of the prototype tag when the tags are densely distributed. When the tags are sparsely distributed, the performance of the improved tags reaches 96% of that of the prototype tags","2023-01","2025-02-26 20:41:49","2025-02-26 20:41:49","","158-167","","1","45","","","","","","","","","","English","","","","WOS:000933284900017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","Antenna; Antenna Design; Coupling Effect; Distribution Status; Radio Frequency IDentification (RFID)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HDTCEZBJ","journalArticle","2022","Li, Y; Tu, YC; Chen, XX; Zhao, H; Zhou, GY","Distance-Aware Occlusion Detection With Focused Attention","IEEE TRANSACTIONS ON IMAGE PROCESSING","","1057-7149","10.1109/TIP.2022.3197984","","For humans, understanding the relationships between objects using visual signals is intuitive. For artificial intelligence, however, this task remains challenging. Researchers have made significant progress studying semantic relationship detection, such as human-object interaction detection and visual relationship detection. We take the study of visual relationships a step further from semantic to geometric. In specific, we predict relative occlusion and relative distance relationships. However, detecting these relationships from a single image is challenging. Enforcing focused attention to task-specific regions plays a critical role in successfully detecting these relationships. In this work, (1) we propose a novel three-decoder architecture as the infrastructure for focused attention; 2) we use the generalized intersection box prediction task to effectively guide our model to focus on occlusion-specific regions; 3) our model achieves a new state-of-the-art performance on distance-aware relationship detection. Specifically, our model increases the distance F1-score from 33.8% to 38.6% and boosts the occlusion F1-score from 34.4% to 41.2%. Our code is publicly available.","2022","2025-02-26 20:41:49","2025-02-26 20:41:49","","5661-5676","","","31","","","","","","","","","","English","","","","WOS:000848262600007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Decoding; Feature extraction; Focused attention; Legged locomotion; object pair detection; relative distance detection; relative occlusion detection; Semantics; Task analysis; transformer model; Transformers; Visualization; visualizations of attention weights","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RDFZFZT7","journalArticle","2021","Sui, D; Zhang, K; Liu, WF; Chen, J; Ma, XX; Tian, ZF","CST: A Multitask Learning Framework for Colorectal Cancer Region Mining Based on Transformer","BIOMED RESEARCH INTERNATIONAL","","2314-6133","10.1155/2021/6207964","","Colorectal cancer is a high death rate cancer until now; from the clinical view, the diagnosis of the tumour region is critical for the doctors. But with data accumulation, this task takes lots of time and labor with large variances between different doctors. With the development of computer vision, detection and segmentation of the colorectal cancer region from CT or MRI image series are a great challenge in the past decades, and there still have great demands on automatic diagnosis. In this paper, we proposed a novel transfer learning protocol, called CST, that is, a union framework for colorectal cancer region detection and segmentation task based on the transformer model, which effectively constructs the cancer region detection and its segmentation jointly. To make a higher detection accuracy, we incorporate an autoencoder-based image-level decision approach that leverages the image-level decision of a cancer slice. We also compared our framework with one-stage and two-stage object detection methods; the results show that our proposed method achieves better results on detection and segmentation tasks. And this proposed framework will give another pathway for colorectal cancer screen by way of artificial intelligence.","2021-10-11","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","2021","","","","","","","","","","English","","","","WOS:000769620900006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","CONVOLUTIONAL NEURAL-NETWORKS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G5MIIM47","journalArticle","2025","Huang, DT; Song, JX; Huang, XQ; Hu, ZZ; Zeng, HQ","Multi-Modal Prior-Guided Diffusion Model for Blind Image Super-Resolution","IEEE SIGNAL PROCESSING LETTERS","","1070-9908","10.1109/LSP.2024.3516699","","Recently, diffusion models have achieved remarkable success in blind image super-resolution. However, most existing methods rely solely on uni-modal degraded low-resolution images to guide diffusion models for restoring high-fidelity images, resulting in inferior realism. In this letter, we propose a Multi-modal Prior-Guided diffusion model for blind image Super-Resolution (MPGSR), which fine-tunes Stable Diffusion (SD) by utilizing the superior visual-and-textual guidance for restoring realistic high-resolution images. Specifically, our MPGSR involves two stages, i.e., multi-modal guidance extraction and adaptive guidance injection. For the former, we propose a composited transformer and further incorporate it with GPT-CLIP to extract the representative visual-and-textual guidance. For the latter, we design a feature calibration ControlNet to inject the visual guidance and employ the cross-attention layer provided by the frozen SD to inject the textual guidance, thus effectively activating the powerful text-to-image generation potential. Extensive experiments show that our MPGSR outperforms state-of-the-art methods in restoration quality and convergence time.","2025","2025-02-26 20:41:49","2025-02-26 20:41:49","","316-320","","","32","","","","","","","","","","English","","","","WOS:001383044100011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Adaptive systems; Blind image super-resolution; Degradation; diffusion model; Diffusion models; Feature extraction; Image reconstruction; Image restoration; multi-modal guidance; Navigation; Superresolution; transformer model; Transformers; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"93JFFFE2","journalArticle","2024","Taha, RA; Youssif, AAH; Fouad, MM","Transfer learning model for anomalous event recognition in big video data","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-78414-2","","Video surveillance faces challenges due to the need for improved anomalous event recognition techniques for human activity recognition. Growing security concerns make standard CCTV systems insufficient because of high monitoring costs and operator exhaustion. Therefore, automated security systems with real-time event recognition are essential. This research introduces a semantic key frame extraction algorithm based on action recognition to minimize frame volume big video data. This approach has not been previously applied with ResNet50, VGG19, EfficientNetB7, and ViT_b16 models for recognizing anomalous events in surveillance videos. The findings demonstrate the effectiveness of this method in achieving high accuracy rates. The proposed method addresses the challenges posed by large volumes of frames generated by surveillance videos, requiring effective processing techniques. A large number of videos from the UCF-Crime dataset were used for proposed model evaluation, including both abnormal and normal videos during the training and testing phase. EfficientNetB7 achieved 86.34% accuracy, VGG19 reached 87.90%, ResNet50 attained 90.46%, and ViT_b16 excelled with 95.87% accuracy. Compared to state-of-the-art models from other studies, the transformer model (ViT_b16) outperformed these algorithms, demonstrating significant improvements in recognizing anomalous events.","2024-11-13","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","1","14","","","","","","","","","","English","","","","WOS:001354478800020","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4X5L9WTL","journalArticle","2024","Blaabjerg, LM; Jonsson, N; Boomsma, W; Stein, A; Lindorff-Larsen, K","SSEmb: A joint embedding of protein sequence and structure enables robust variant effect predictions","NATURE COMMUNICATIONS","","2041-1723","10.1038/s41467-024-53982-z","","The ability to predict how amino acid changes affect proteins has a wide range of applications including in disease variant classification and protein engineering. Many existing methods focus on learning from patterns found in either protein sequences or protein structures. Here, we present a method for integrating information from sequence and structure in a single model that we term SSEmb (Sequence Structure Embedding). SSEmb combines a graph representation for the protein structure with a transformer model for processing multiple sequence alignments. We show that by integrating both types of information we obtain a variant effect prediction model that is robust when sequence information is scarce. We also show that SSEmb learns embeddings of the sequence and structure that are useful for other downstream tasks such as to predict protein-protein binding sites. We envisage that SSEmb may be useful both for variant effect predictions and as a representation for learning to predict protein properties that depend on sequence and structure. SSEmb is a multi-modal machine learning model that predicts how changes in a protein's amino acid sequence affect its function by combining information from a multiple sequence alignment and the three-dimensional structure.","2024-11-07","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","1","15","","","","","","","","","","English","","","","WOS:001352440200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;87</p>","","","MODELS; SMALL MOLECULES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"84JEU8QQ","journalArticle","2024","Lee, J; Kang, J; Park, CS; Jeong, J","Distributed Fire Classification and Localization Model Based on Federated Learning with Image Clustering","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14209162","","In this study, we propose a fire classification system using image clustering based on a federated learning (FL) structure. This system enables fire detection in various industries, including manufacturing. The accurate classification of fire, smoke, and normal conditions is an important element of fire prevention and response systems in industrial sites. The server in the proposed system extracts data features using a pretrained vision transformer model and clusters the data using the bisecting K-means algorithm to obtain weights. The clients utilize these weights to cluster local data with the K-means algorithm and measure the difference in data distribution using the Kullback-Leibler divergence. Experimental results show that the proposed model achieves nearly 99% accuracy on the server, and the clustering accuracy on the clients remains high. In addition, the normalized mutual information value remains above 0.6 and the silhouette score reaches 0.9 as the rounds progress, indicating improved clustering quality. This study shows that the accuracy of fire classification is enhanced by using FL and clustering techniques and has a high potential for real-time detection.","2024-10","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","20","14","","","","","","","","","","English","","","","WOS:001341670200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","cluster information; federated learning; fire classification; image clustering; unsupervised learning; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"223WCFVU","journalArticle","2024","Kim, MY; Rabelo, J; Babiker, HKB; Rahman, MA; Goebel, R","Legal Information Retrieval and Entailment Using Transformer-based Approaches","REVIEW OF SOCIONETWORK STRATEGIES","","2523-3173","10.1007/s12626-023-00153-z","","The challenge of information overload in the legal domain increases every day. The COLIEE competition has created four challenge tasks that are intended to encourage the development of systems and methods to alleviate some of that pressure: a case law retrieval (Task 1) and entailment (Task 2), and a statute law retrieval (Task 3) and entailment (Task 4). Here we describe our methods for Task 1 and Task 4. In Task 1, we used a sentence-transformer model to create a numeric representation for each case paragraph. We then created a histogram of the similarities between a query case and a candidate case. The histogram is used to build a binary classifier that decides whether a candidate case should be noticed or not. In Task 4, our approach relies on fine-tuning a pre-trained DeBERTa large language model (LLM) trained on SNLI and MultiNLI datasets. Our method for Task 4 was ranked third among eight participating teams in the COLIEE 2023 competition. For Task 4, We also compared the performance of the DeBERTa model with those of a knowledge distillation model and ensemble methods including Random Forest and Voting.","2024-04","2025-02-26 20:41:49","2025-02-26 20:41:49","","101-121","","1","18","","","","","","","","","","English","","","","WOS:001140304200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","COLIEE 2023; Legal information entailment; Legal information retrieval; Transformer-based legal information extraction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MZWBD6NH","journalArticle","2022","Zhu, XJ; Han, ZQ; Yuan, MK; Guo, QH; Wang, HY; Song, LM","Hformer: Hybrid convolutional neural network transformer network for fringe order prediction in phase unwrapping of fringe projection","OPTICAL ENGINEERING","","0091-3286","10.1117/1.OE.61.9.093107","","Deep learning based on convolutional neural network (CNN) has attracted more and more attention in phase unwrapping of fringe projection three-dimensional (3D) measurement. However, due to the inherent limitations of convolutional operator, it is difficult to accurately determine the fringe order in wrapped phase patterns that rely on continuity and globality. To attack this problem, in this paper we develop a hybrid CNN-transformer model (Hformer) dedicated to phase unwrapping via fringe order prediction. The proposed Hformer model has a hybrid CNN-transformer architecture that is mainly composed of backbone, encoder, and decoder to take advantage of both CNN and transformer. Backbone is used as a wrapped phase pattern feature extractor. Encoder and decoder with cross attention are designed to enhance global dependency for the fringe order prediction. Experimental results show that the proposed Hformer model achieves better performance in fringe order prediction compared with the CNN models such as U-Net and DCNN. Our work opens an alternative way to the CNN-dominated deep learning phase unwrapping of fringe projection 3D measurement. (C) 2022 Society of PhotoOptical Instrumentation Engineers (SPIE)","2022-09-01","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","9","61","","","","","","","","","","English","","","","WOS:000867436200007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","ALGORITHMS; deep learning; fringe order; Hformer; phase unwrapping; PROFILOMETRY; RETRIEVAL; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D6ZUZ2M7","journalArticle","2022","Li, WJ; Zhang, N; Zhu, JH; Liu, Z; Wang, WS; Li, Y; Guo, WJ","Noninvasive real-time traffic and congestion control algorithm based on policy","JOURNAL OF COMPUTATIONAL METHODS IN SCIENCES AND ENGINEERING","","1472-7978","10.3233/JCM-226352","","The Internet of Things has a large number of terminal devices and a wide range of deployment. This feature has higher requirements for reliable transmission and parallel connection, and is more prone to network congestion resulting in the loss of power information flow and excessive delay. The traditional congestion control algorithm is not suitable for the high concurrent mass heterogeneous iot terminal access control and mass information flow storage control. In this paper, the Transformer BBR algorithm is proposed, which is a congestion control algorithm based on BBR deep reinforcement learning combined with Transformer's excellent long-term prediction ability. In the BBR algorithm bandwidth detection stage, transformer model is used as an agent to detect the network state and map it to the congestion window, so as to find the network changing state in time and make the corresponding decision action. Firstly, the congestion control strategy is learned in the simulation network environment, and then the efficiency is verified in the simulation environment. Finally, the experiment shows that the algorithm can reduce the delay while ensuring good bandwidth performance, and is superior to the main application algorithms in network throughput.","2022","2025-02-26 20:41:49","2025-02-26 20:41:49","","2185-2199","","6","22","","","","","","","","","","English","","","","WOS:000893587400027","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","Congestion control; deep reinforcement learning; transformer; web caching","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KAZYMJVS","journalArticle","2021","Xu, ZW; Qin, HB; Hua, YZ","Research on Uyghur-Chinese Neural Machine Translation Based on the Transformer at Multistrategy Segmentation Granularity","MOBILE INFORMATION SYSTEMS","","1574-017X","10.1155/2021/5744248","","In recent years, machine translation based on neural networks has become the mainstream method in the field of machine translation, but there are still challenges of insufficient parallel corpus and sparse data in the field of low resource translation. Existing machine translation models are usually trained on word-granularity segmentation datasets. However, different segmentation granularities contain different grammatical and semantic features and information. Only considering word granularity will restrict the efficient training of neural machine translation systems. Aiming at the problem of data sparseness caused by the lack of Uyghur-Chinese parallel corpus and complex Uyghur morphology, this paper proposes a multistrategy segmentation granular training method for syllables, marked syllable, words, and syllable word fusion and targets traditional recurrent neural networks and convolutional neural networks; the disadvantage of the network is to build a Transformer Uyghur-Chinese Neural Machine Translation model based entirely on the multihead self-attention mechanism. In CCMT2019, dimension results on Uyghur-Chinese bilingual datasets show that the effect of multiple translation granularity training method is significantly better than the rest of granularity segmentation translation systems, while the Transformer model can obtain higher BLEU value than Uyghur-Chinese translation model based on Self-Attention-RNN.","2021-06-28","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","2021","","","","","","","","","","English","","","","WOS:000674595200006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;15</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6QFXE2VT","journalArticle","2022","Shan, W","Optimization of Network Home Management System Based on Big Data","MATHEMATICAL PROBLEMS IN ENGINEERING","","1024-123X","10.1155/2022/5795021","","Network home has become a research hotspot in today's society, and it can improve the comfort, safety, and convenience of people's lives. The traditional network home model only makes certain actions to the home system according to people's instructions, and it is difficult to realize the intelligence of network home. This also limits the security and convenience of an online home. This study makes full use of the advantages of big data technology in processing nonlinear data, and applies the convolutional neural network (CNN) method and long and short-term memory (LSTM) neural network method to the network home system. CNN can be used to extract people's behavior information, and LSTM can be used to extract people's speech features. CNN method can establish the relationship between people's behavior information, speech information, and network home management system. At the same time, this research mainly analyzes the lighting system, home appliance system, security system, and floor heating system in the network home system. The results show that the CNN-LSTM method has high accuracy in predicting the four systems of network home. The largest prediction error is only 2.78%, and this part of the error comes from the prediction of the home appliance system. The smallest prediction error is only 0.98%.","2022-07-13","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","2022","","","","","","","","","","English","","","","WOS:000860750600006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JITNS7P9","journalArticle","2021","Gallardo-Antolín, A; Montero, JM","Detecting Deception from Gaze and Speech Using a Multimodal Attention LSTM-Based Framework","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app11146393","","The automatic detection of deceptive behaviors has recently attracted the attention of the research community due to the variety of areas where it can play a crucial role, such as security or criminology. This work is focused on the development of an automatic deception detection system based on gaze and speech features. The first contribution of our research on this topic is the use of attention Long Short-Term Memory (LSTM) networks for single-modal systems with frame-level features as input. In the second contribution, we propose a multimodal system that combines the gaze and speech modalities into the LSTM architecture using two different combination strategies: Late Fusion and Attention-Pooling Fusion. The proposed models are evaluated over the Bag-of-Lies dataset, a multimodal database recorded in real conditions. On the one hand, results show that attentional LSTM networks are able to adequately model the gaze and speech feature sequences, outperforming a reference Support Vector Machine (SVM)-based system with compact features. On the other hand, both combination strategies produce better results than the single-modal systems and the multimodal reference system, suggesting that gaze and speech modalities carry complementary information for the task of deception detection that can be effectively exploited by using LSTMs.","2021-07","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","14","11","","","","","","","","","","English","","","","WOS:000678141600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","attention; deception detection; fusion; gaze; LSTM; multimodal; speech; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PHFX5528","journalArticle","2024","Yadava, GT; Nagaraja, BG; Jayanna, HS","An end-to-end continuous Kannada ASR system under uncontrolled environment","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-023-15854-4","","Achieving better speech recognition accuracy under real-time conditions is still a challenging task, and many researchers are striving to improve accuracy. In this paper, we developed a system for recognizing continuous Kannada speech sentences under real-time conditions. To develop the automatic speech recognition (ASR) models, we used task-specific continuous Kannada speech data gathered from speakers/farmers in real-time conditions. We designed an interactive voice response system (IVRS) and collected 40 continuous Kannada speech sentences. We transcribed, validated, and extracted speech features using the Mel frequency cepstral coefficient (MFCC) technique. We used 90% and 10% of validated continuous Kannada speech data for Kaldi system training and decoding, respectively, at different phoneme levels. The experimental results revealed that the time delay neural networks (TDNN) based ASR models outperformed ASR models of other acoustic modelling techniques and the earlier developed deep neural networks (DNN)-hidden Markov model (HMM) based continuous Kannada ASR (CKASR) system. The least word error rate (WER) ASR models are used in developing the real-time end-to-end (E2E) CKASR system. We verified the developed E2ECKASR system by testing it with 550 speakers/farmers under real-time conditions.","2024-01","2025-02-26 20:41:49","2025-02-26 20:41:49","","7981-7994","","3","83","","","","","","","","","","English","","","","WOS:001009907400010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Continuous Kannada speech data; CONTINUOUS SPEECH RECOGNITION; Kaldi; Kannada ASR; SQS; WER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D7W34DPZ","journalArticle","2024","Xu, X; Wang, Y; Wei, XR; Wang, F; Zhang, XZ","Attention-based acoustic feature fusion network for depression detection","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2024.128209","","Depression, a common mental disorder, significantly influences individuals and imposes considerable societal impacts. The complexity and heterogeneity of the disorder necessitate prompt and effective detection, which nonetheless, poses a difficult challenge. This situation highlights an urgent requirement for improved detection methods. Exploiting auditory data through advanced machine learning paradigms presents promising research directions. Yet, existing techniques mainly rely on single-dimensional feature models, potentially neglecting the abundance of information hidden in various speech features. To rectify this, we present the novel Attention-Based Acoustic Feature Fusion Network (ABAFnet) for depression detection. ABAFnet combines four different acoustic features into a comprehensive deep neural network, thereby effectively integrating and blending multi-tiered features. We present a novel Type-Adaptive CNN for feature process, a LSTM-Attention Mechanism for features' temporal-spatial computation, and a Dynamic Weight Adjustment module for Linear Late Fusion Network that boosts performance by efficaciously synthesizing these features. The effectiveness of our approach is confirmed via extensive validation on two novel speech databases, CNRAC and CS-NRAC, thereby outperforming previous methods in depression detection and subtype classification. Further in-depth analysis confirms the key role of each feature and highlights the importance of MFCC-related features in speech-based depression detection (SDD).","2024-10-07","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","601","","","","","","","","","","English","","","","WOS:001286105100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","CLINICAL DEPRESSION; Deep Neural Networks; Depression Detection; Feature Fusion; PHQ-9; RECOGNITION; SCALE; SEVERITY; Speech; SPEECH; VALIDATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SPXECD3A","journalArticle","2021","Aydin, ÜA; Kalkan, S; Acartürk, C","Speech Driven Gaze in a Face-to-Face Interaction","FRONTIERS IN NEUROROBOTICS","","1662-5218","10.3389/fnbot.2021.598895","","Gaze and language are major pillars in multimodal communication. Gaze is a non-verbal mechanism that conveys crucial social signals in face-to-face conversation. However, compared to language, gaze has been less studied as a communication modality. The purpose of the present study is 2-fold: (i) to investigate gaze direction (i.e., aversion and face gaze) and its relation to speech in a face-to-face interaction; and (ii) to propose a computational model for multimodal communication, which predicts gaze direction using high-level speech features. Twenty-eight pairs of participants participated in data collection. The experimental setting was a mock job interview. The eye movements were recorded for both participants. The speech data were annotated by ISO 24617-2 Standard for Dialogue Act Annotation, as well as manual tags based on previous social gaze studies. A comparative analysis was conducted by Convolutional Neural Network (CNN) models that employed specific architectures, namely, VGGNet and ResNet. The results showed that the frequency and the duration of gaze differ significantly depending on the role of participant. Moreover, the ResNet models achieve higher than 70% accuracy in predicting gaze direction.","2021-03-04","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","15","","","","","","","","","","English","","","","WOS:000629972800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","deep learning; DUAL EYE-TRACKING; face-to-face interaction; FIXATION; gaze analysis; LANGUAGE; multimodal communication; PATTERNS; ROBOT; speech annotation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7PSYBAHW","journalArticle","2024","Varakuta, M; Kupina, D; Votintseva, M","ARCHETYPICAL SIGNS OF THE KOLOMYIKA IN THE UKRAINIAN MUSIC OF THE 21ST CENTURY","STUDIA UNIVERSITATIS BABES-BOLYAI MUSICA","","1844-4369","10.24193/subbmusica.2024.2.17","",". The article is devoted to studying the implementation/manifestation/ reflection of archetypal features of kolomyika, as a traditional genre of Ukrainian folk art, in the music of Ukrainian composers. The kolomyika has been determined to be a typified intoneme, a semantic-meaning unit, with a set of specific speech features, which sprouts/appears in the music of Ukrainian composers, connecting with concert genres. It has been revealed that the kolomyika intonation complex often serves as the basis of an instrumental piece, which has been confirmed by a large number of Ukrainian composers' opuses, since the second half of the 19th century to the present day. Examples of the kolomyika genre usage have been proven to be sporadic in choral music. That is why Kolomyika for mixed choir, percussion instruments, and piano by the Ukrainian composer Volodymyr Zubytsky is an interesting example of the embodiment of the genre within the framework of choral music. It is proved that the genre of kolomyika is interpreted by Zubytsky as a universal intonation-semantic model, raised to the level of philosophical generalization, which allows the composer to address the exciting sociopolitical issues of the present employing an artificial genre.","2024-12","2025-02-26 20:41:49","2025-02-26 20:41:49","","241-250","","2","69","","","","","","","","","","English","","","","WOS:001416742400015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;7</p>","","","choral concert; composer's mentality; creativity of Volodymyr Zubytsky; genre archetype; intonation model; kolomyika; modern Ukrainian music","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MZM99S9B","journalArticle","2023","Zhang, R; Zhang, PY; Gao, MR; Pan, LH; Bai, XL; Zhao, N","Self-optimizing multi-domain auxiliary fusion deep complex convolution recurrent network for speech enhancement","DIGITAL SIGNAL PROCESSING","","1051-2004","10.1016/j.dsp.2022.103897","","A self-optimizing multi-domain auxiliary fusion deep complex convolution recurrent network for speech enhancement (AMDCCRN) was developed to further improve the feature completeness, correlation expression, and global optimization efficiency of the deep speech enhancement model for speech signals. By constructing a multi-domain auxiliary fusion deep complex convolution recurrent network (MDCCRN), the correlation representation of speech features and features in different spatial domains was enriched. The sparrow search algorithm (PGSSA), which is based on a game theory parallel and global optimization strategy, was introduced to improve parallel search capability and to further augment the efficiency and performance of the model's hyperparameter adaptive search. At the same time, PGSSA was used for adaptive optimization of six key model parameters required for AMDCCRN construction. Finally, a speech enhancement model suitable for multi-domain auxiliary fusion with self-learning ability was constructed. Test results on two common speech corpus data sets, THCHS-30 and WSJ0, showed that the proposed method achieved a better speech enhancement effect than other existing methods and that the validity and generalization of the proposed method had been verified. (c) 2022 Elsevier Inc. All rights reserved.","2023-04-15","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","","134","","","","","","","","","","English","","","","WOS:000969737900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Model efficient search strategy; Model self-optimization; Multi-spatial domain feature representation; Speech enhancement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T2YN9ZVZ","journalArticle","2023","Garg, A","Speech enhancement using long short term memory with trained speech features and adaptive wiener filter","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-022-13302-3","","Speech enhancement is the process of enhancing the clarity and intelligibility of speech signals that have been degraded due to background noise. With the assistance of deep learning, a novel speech signal enhancement model is introduced in this research. The proposed model is divided into two phases: (i) Training (ii) Testing. In the training phase, the noise spectrum and signal spectrum are estimated via a Non-negative Matrix Factorization (NMF) from the noisy input signal. Then, Empirical Mean Decomposition (EMD) features are extracted from the Wiener filter. The de-noised signal is acquired from EMD, the bark frequency is evaluated and the Fractional Delta AMS features are extracted. The key contribution of this study is the use of the Long Short Term Memory (LSTM) model to properly estimate the tuning factor eta of the Wiener filter for all input signals. The LSTM was trained by the extracted features (EMD) via a modified wiener filter for decomposing the spectral signal and the output of EMD is the denoised enhanced speech signal. A comparative evaluation is carried out between the proposed and existing models in terms of error measures.","2023-01","2025-02-26 20:41:49","2025-02-26 20:41:49","","3647-3675","","3","82","","","","","","","","","","English","","","","WOS:000825246000011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Empirical mean curve decomposition; Empirical mean decomposition; MASKING; MODEL; NOISE; NONNEGATIVE MATRIX FACTORIZATION; Speech enhancement; Speech processing; Wiener filter","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NPXB9EHW","journalArticle","2023","Zhao, YH; Shu, XQ","Speech emotion analysis using convolutional neural network (CNN) and gamma classifier-based error correcting output codes (ECOC)","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-023-47118-4","","Speech emotion analysis is one of the most basic requirements for the evolution of Artificial Intelligence (AI) in the field of human-machine interaction. Accurate emotion recognition in speech can be effective in applications such as online support, lie detection systems and customer feedback analysis. However, the existing techniques for this field have not yet met sufficient development. This paper presents a new method to improve the performance of emotion analysis in speech. The proposed method includes the following steps: pre-processing, feature description, feature extraction, and classification. The initial description of speech features in the proposed method is done by using the combination of spectro-temporal modulation (STM) and entropy features. Also, a Convolutional Neural Network (CNN) is utilized to reduce the dimensions of these features and extract the features of each signal. Finally, the combination of gamma classifier (GC) and Error-Correcting Output Codes (ECOC) is applied to classify features and extract emotions in speech. The performance of the proposed method has been evaluated using two datasets, Berlin and ShEMO. The results show that the proposed method can recognize speech emotions in the Berlin and ShEMO datasets with an average accuracy of 93.33 and 85.73%, respectively, which is at least 6.67% better than compared methods.","2023-11-21","2025-02-26 20:41:49","2025-02-26 20:41:49","","","","1","13","","","","","","","","","","English","","","","WOS:001269340000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","FEATURES; RECOGNITION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EKIY5YXC","journalArticle","2022","Lu, C; Zong, Y; Tang, CG; Lian, HL; Chang, HL; Zhu, J; Li, SA; Zhao, Y","Implicitly Aligning Joint Distributions for Cross-Corpus Speech Emotion Recognition","ELECTRONICS","","2079-9292","10.3390/electronics11172745","","In this paper, we investigate the problem of cross-corpus speech emotion recognition (SER), in which the training (source) and testing (target) speech samples belong to different corpora. This case thus leads to a feature distribution mismatch between the source and target speech samples. Hence, the performance of most existing SER methods drops sharply. To solve this problem, we propose a simple yet effective transfer subspace learning method called joint distribution implicitly aligned subspace learning (JIASL). The basic idea of JIASL is very straightforward, i.e., building an emotion discriminative and corpus invariant linear regression model under an implicit distribution alignment strategy. Following this idea, we first make use of the source speech features and emotion labels to endow such a regression model with emotion-discriminative ability. Then, a well-designed reconstruction regularization term, jointly considering the marginal and conditional distribution alignments between the speech samples in both corpora, is adopted to implicitly enable the regression model to predict the emotion labels of target speech samples. To evaluate the performance of our proposed JIASL, extensive cross-corpus SER experiments are carried out, and the results demonstrate the promising performance of the proposed JIASL in coping with the tasks of cross-corpus SER.","2022-09","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","17","11","","","","","","","","","","English","","","","WOS:000852852500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","ADAPTATION; conditional distribution; cross-corpus speech emotion recognition; domain adaptation; KERNEL; marginal distribution; NETWORK; transfer subspace learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CPFHX7PZ","journalArticle","2021","Raharjo, I; Kothare, H; Nagarajan, SS; Houde, JF","Speech compensation responses and sensorimotor adaptation to formant feedback perturbations","JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA","","0001-4966","10.1121/10.0003440","","Control of speech formants is important for the production of distinguishable speech sounds and is achieved with both feedback and learned feedforward control. However, it is unclear whether the learning of feedforward control involves the mechanisms of feedback control. Speakers have been shown to compensate for unpredictable transient mid-utterance perturbations of pitch and loudness feedback, demonstrating online feedback control of these speech features. To determine whether similar feedback control mechanisms exist in the production of formants, responses to unpredictable vowel formant feedback perturbations were examined. Results showed similar within-trial compensatory responses to formant perturbations that were presented at utterance onset and mid-utterance. The relationship between online feedback compensation to unpredictable formant perturbations and sensorimotor adaptation to consistent formant perturbations was further examined. Within-trial online compensation responses were not correlated with across-trial sensorimotor adaptation. A detailed analysis of within-trial time course dynamics across trials during sensorimotor adaptation revealed that across-trial sensorimotor adaptation responses did not result from an incorporation of within-trial compensation response. These findings suggest that online feedback compensation and sensorimotor adaptation are governed by distinct neural mechanisms. These findings have important implications for models of speech motor control in terms of how feedback and feedforward control mechanisms are implemented.","2021-02","2025-02-26 20:41:50","2025-02-26 20:41:50","","1147-1161","","2","149","","","","","","","","","","English","","","","WOS:000630493200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","VOCAL PITCH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IPU9F9KW","journalArticle","2022","Zhang, JF; Xing, LN; Tan, Z; Wang, HS; Wang, KS","Multi-head attention fusion networks for multi-modal speech emotion recognition","COMPUTERS & INDUSTRIAL ENGINEERING","","0360-8352","10.1016/j.cie.2022.108078","","Multi-modal speech emotion recognition is a study to predict emotion categories by combining speech data with other types of data, such as video, speech text transcription, body action, or facial expression when speaking, which will involve the fusion of multiple features. Most of the early studies, however, directly spliced multimodal features in the fusion layer after single-modal modeling, resulting in ignoring the connection between speech and other modal features. As a result, we propose a novel multi-modal speech emotion recognition model based on multi-head attention fusion networks, which employs transcribed text and motion capture (MoCap) data involving facial expression, head rotation, and hand action to supplement speech data and perform emotion recognition. In unimodal, we use a two-layer Transformer's encoder combination model to extract speech and text features separately, and MoCap is modeled using a deep residual shrinkage network. Simultaneously, We innovated by changing the input of the Transformer encoder to learn the similarities between speech and text, speech and MoCap, and then output text and MoCap features that are more similar to speech features, and finally, predict the emotion category using combined features. In the IEMOCAP dataset, our model outperformed earlier research with a recognition accuracy of 75.6%.","2022-06","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","168","","","","","","","","","","English","","","","WOS:000793260700003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;28<br/>Total Times Cited:&nbsp;&nbsp;31<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Feature Fusion; FEATURES; Multi-Head Attention; Multimodal; Speech Emotion Recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K6R4IQTE","journalArticle","2022","Lu, D; Guo, F","Application of Wearable Motion Sensor in Business English Teaching","COMPUTER SCIENCE AND INFORMATION SYSTEMS","","1820-0214","10.2298/CSIS210320020L","","With the advancement of science and technology, portable motion sensors are becoming increasingly popular in life and have become a research point for improving life and learning, and are widely used in medical care and smart terminals. Based on the advantages of portable motion sensors, this paper focuses on its application in learning English business. Collects speech information through special motion sensors, analyzes the accuracy of students' reading through speech recognition, to help students better learn business English. Firstly, the wearable sensor is used to collect and preprocess the speech information of students' business English reading as the input of speech recognition. Secondly, the linear predictive cepstrum coefficient (LPCC) and Meier frequency cepstrum coefficient (MFCC) of students' business English reading speech are extracted, and the mixed parameters of LPCC and MFCC are taken as speech features. Finally, the correctness of reading speech is recognized by combining HMM and WNN. Through the simulation analysis of students' reading speech recognition, it is shown that the speech recognition based on wearable motion sensor is feasible and the recognition method has good performance. In addition, the feasibility of wearable motion sensors in business English teaching is verified by the establishment of an experimental classes, which can promote students' English learning better.","2022-09","2025-02-26 20:41:50","2025-02-26 20:41:50","","1481-1498","","3","19","","","","","","","","","","English","","","","WOS:000877664300024","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","Business English; Business English Teaching; Wearable motion sensor","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FAF7APHG","journalArticle","2023","Pour, LK; Farrokhi, A","Language recognition by convolutional neural networks","SCIENTIA IRANICA","","1026-3098","10.24200/sci.2022.59110.6064","","Speech recognition representing a communication between computers and human as a sub field of computational linguistics or natural language processing has a long history. Automatic Speech Recognition (ASR), Text To Speech (TTS), speech to text, Continuous Speech Recognition (CSR), and interactive voice response systems are different approaches to solving problems in this area. The performance improvement is partially attributed to the ability of the Deep Neural Network (DNN) to model complex correlations in speech features. In this paper, unlike the use of conventional model for sequential data like voice that employs Recurrent Neural Networks (RNNs) with the emergence of different architectures in deep networks and good performance of Conventional Neural Networks (CNNs) in image processing and feature extraction, the application of CNNs was developed in other domains. It was shown that prosodic features for Persian language could be extracted via CNNs for segmentation and labeling speech for short texts. By using 128 and 200 filters for CNN and special architectures, 19.46 error in detection rate and better time consumption than RNNs were obtained. In addition, CNN simplifies the learning procedure. Experimental results show that CNN networks can be a good feature extractor for speech recognition in various languages.","2023","2025-02-26 20:41:50","2025-02-26 20:41:50","","116-123","","1","30","","","","","","","","","","English","","","","WOS:000954835100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Artificial intelligence.; Convolutional neural; networks; Persian language; Speech recognition; Speech segmentation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4A6CBIFS","journalArticle","2021","Lalitha, S; Gupta, D","Investigation of automatic mixed-lingual affective state recognition system for diverse Indian languages","JOURNAL OF INTELLIGENT & FUZZY SYSTEMS","","1064-1246","10.3233/JIFS-189868","","Automatic recognition of human affective state using speech has been the focus of the research world for more than two decades. In the present day, with multi-lingual countries like India and Europe, population are communicating in various languages. However, majority of the existing works have put forth different strategies to recognize affect from various databases, with each comprising single language recordings. There exists a great demand for affective systems to serve the context of mixed-language scenario. Hence, this work focusses on an effective methodology to recognize human affective state using speech samples from a mixed language framework. A unique cepstral and bi-spectral speech features derived from the speech samples classified using random forest (RF) are applied for the task. This work is first of its kind with the proposed approach validated and found to be effective on a self-recorded database with speech samples comprising from eleven various diverse Indian languages. Six different affective states of angry, fear, sad, neutral, surprise and happy are considered. Three affective models have been investigated in the work. The experimental results demonstrate the proposed feature combination in addition to data augmentation show enhanced affect recognition.","2021","2025-02-26 20:41:50","2025-02-26 20:41:50","","5467-5476","","5","41","","","","","","","","","","English","","","","WOS:000722005700024","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Affective state; cepstral; EMOTION RECOGNITION; FEATURES; Indian languages; mixed-lingual; recognition; SPEECH EMOTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7QQWK93D","journalArticle","2025","Kou, YF; Ge, FZ; Chen, DB; Shen, LF; Liu, HY","An Enhanced Cross-Attention Based Multimodal Model for Depression Detection","COMPUTATIONAL INTELLIGENCE","","0824-7935","10.1111/coin.70019","","Depression, a prevalent mental disorder in modern society, significantly impacts people's daily lives. Recently, there have been advancements in developing automated diagnosis models for detecting depression. However, data scarcity, primarily due to privacy concerns, has posed a challenge. Traditional speech features have limitations in representing knowledge for depression diagnosis, and the complexity of deep learning algorithms necessitates substantial data support. Furthermore, existing multimodal methods based on neural networks overlook the heterogeneity gap between different modalities, potentially resulting in redundant information. To address these issues, we propose a multimodal depression detection model based on the Enhanced Cross-Attention (ECA) Mechanism. This model effectively explores text-speech interactions while considering modality heterogeneity. Data scarcity has been mitigated by fine-tuning pre-trained models. Additionally, we design a modal fusion module based on ECA, which emphasizes similarity responses and updates the weight of each modal feature based on the similarity information between modal features. Furthermore, for speech feature extraction, we have reduced the computational complexity of the model by integrating a multi-window self-attention mechanism with the Fourier transform. The proposed model is evaluated on the public dataset, DAIC-WOZ, achieving an accuracy of 80.0% and an average F1 value improvement of 4.3% compared with relevant methods.","2025-02","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","1","41","","","","","","","","","","English","","","","WOS:001396753100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","enhanced cross-attention; multimodal depression detection; pre-trained models; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YZPQTW8Y","journalArticle","2025","Yi, MH; Kwak, KC; Shin, JH","HyFusER: Hybrid Multimodal Transformer for Emotion Recognition Using Dual Cross Modal Attention","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app15031053","","Emotion recognition is becoming increasingly important for accurately understanding and responding to user emotions, driven by the rapid proliferation of non-face-to-face environments and advancements in conversational AI technologies. Existing studies on multimodal emotion recognition, which utilize text and speech, have aimed to improve performance by integrating the information from both modalities. However, these approaches have faced limitations such as restricted information exchange and the omission of critical cues. To address these challenges, this study proposes a Hybrid Multimodal Transformer, which combines Intermediate Layer Fusion and Last Fusion. Text features are extracted using KoELECTRA, while speech features are extracted using HuBERT. These features are processed through a transformer encoder, and Dual Cross Modal Attention is applied to enhance the interaction between text and speech. Finally, the predicted results from each modality are aggregated using an average ensemble method to recognize the final emotion. The experimental results indicate that the proposed model achieves superior emotion recognition performance compared to existing models, demonstrating significant progress in improving both the accuracy and reliability of emotion recognition. In the future, incorporating additional modalities, such as facial expression recognition, is expected to further strengthen multimodal emotion recognition capabilities and open new possibilities for application across diverse fields.","2025-02","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","3","15","","","","","","","","","","English","","","","WOS:001418488300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","Dual Cross Modal Attention; emotion recognition; HuBERT; Hybrid Multimodal Transformer; KoELECTRA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GC7ISBKE","journalArticle","2023","Jiang, WQ; Sun, CL; Chen, FL; Leng, Y; Guo, QS; Sun, JY; Peng, JK","Low Complexity Speech Enhancement Network Based on Frame-Level Swin Transformer","ELECTRONICS","","2079-9292","10.3390/electronics12061330","","In recent years, Transformer has shown great performance in speech enhancement by applying multi-head self-attention to capture long-term dependencies effectively. However, the computation of Transformer is quadratic with the input speech spectrograms, which makes it computationally expensive for practical use. In this paper, we propose a low complexity hierarchical frame-level Swin Transformer network (FLSTN) for speech enhancement. FLSTN takes several consecutive frames as a local window and restricts self-attention within it, reducing the complexity to linear with spectrogram size. A shifted window mechanism enhances information exchange between adjacent windows, so that window-based local attention becomes disguised global attention. The hierarchical structure allows FLSTN to learn speech features at different scales. Moreover, we designed the band merging layer and the band expanding layer for decreasing and increasing the spatial resolution of feature maps, respectively. We tested FLSTN on both 16 kHz wide-band speech and 48 kHz full-band speech. Experimental results demonstrate that FLSTN can handle speech with different bandwidths well. With very few multiply-accumulate operations (MACs), FLSTN not only has a significant advantage in computational complexity but also achieves comparable objective speech quality metrics with current state-of-the-art (SOTA) models.","2023-03","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","6","12","","","","","","","","","","English","","","","WOS:000956642700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","frame-level Swin Transformer; low complexity; NOISE; shifted window mechanism; speech enhancement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LHT7993Y","journalArticle","2023","Li, MJ; Yang, H; Liu, YX","Biomedical named entity recognition based on fusion multi-features embedding","TECHNOLOGY AND HEALTH CARE","","0928-7329","10.3233/THC-236011","","BACKGROUND: With the exponential increase in the volume of biomedical literature, text mining tasks are becoming increasingly important in the medical domain. Named entities are the primary identification tasks in text mining, prerequisites and critical parts for building medical domain knowledge graphs, medical question and answer systems, medical text classification. OBJECTIVE: The study goal is to recognize biomedical entities effectively by fusing multi-feature embedding. Multiple features provide more comprehensive information so that better predictions can be obtained. METHODS: Firstly, three different kinds of features are generated, including deep contextual word-level features, local charlevel features, and part-of-speech features at the word representation layer. The word representation vectors are inputs into BiLSTM as features to obtain the dependency information. Finally, the CRF algorithm is used to learn the features of the state sequences to obtain the global optimal tagging sequences. RESULTS: The experimental results showed that the model outperformed other state-of-the-art methods for all-around performance in six datasets among eight of four biomedical entity types. CONCLUSION: The proposed method has a positive effect on the prediction results. It comprehensively considers the relevant factors of named entity recognition because the semantic information is enhanced by fusing multi-features embedding.","2023","2025-02-26 20:41:50","2025-02-26 20:41:50","","S111-S121","","","31","","","","","","","","","","English","","","","WOS:000987286600012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","BiLSTM-CRF; BioBERT; Biomedical named entity recognition; multi-feature embedding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6U6WDT8C","journalArticle","2022","Kacur, J; Puterka, B; Pavlovicova, J; Oravec, M","Frequency, Time, Representation and Modeling Aspects for Major Speech and Audio Processing Applications","SENSORS","","1424-8220","10.3390/s22166304","","There are many speech and audio processing applications and their number is growing. They may cover a wide range of tasks, each having different requirements on the processed speech or audio signals and, therefore, indirectly, on the audio sensors as well. This article reports on tests and evaluation of the effect of basic physical properties of speech and audio signals on the recognition accuracy of major speech/audio processing applications, i.e., speech recognition, speaker recognition, speech emotion recognition, and audio event recognition. A particular focus is on frequency ranges, time intervals, a precision of representation (quantization), and complexities of models suitable for each class of applications. Using domain-specific datasets, eligible feature extraction methods and complex neural network models, it was possible to test and evaluate the effect of basic speech and audio signal properties on the achieved accuracies for each group of applications. The tests confirmed that the basic parameters do affect the overall performance and, moreover, this effect is domain-dependent. Therefore, accurate knowledge of the extent of these effects can be valuable for system designers when selecting appropriate hardware, sensors, architecture, and software for a particular application, especially in the case of limited resources.","2022-08","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","16","22","","","","","","","","","","English","","","","WOS:000845515800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","audio event recognition; convolutional neural networks; speaker recognition; speech emotions; speech features; speech recognition; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WPRTQE9Z","journalArticle","2024","Cohen, AS; Rodriguez, Z; Opler, M; Kirkpatrick, B; Milanovic, S; Piacentino, D; Szabo, ST; Tomioka, S; Ogirala, A; Koblan, KS; Siegel, JS; Hopkins, S","Evaluating speech latencies during structured psychiatric interviews as an automated objective measure of psychomotor slowing","PSYCHIATRY RESEARCH","","0165-1781","10.1016/j.psychres.2024.116104","","We sought to derive an objective measure of psychomotor slowing from speech analytics during a psychiatric interview to avoid potential burden of dedicated neurophysiological testing. Speech latency, which reflects response time between speakers, shows promise from the literature. Speech data was obtained from 274 subjects with a diagnosis of bipolar I depression enrolled in a randomized, doubleblind, 6-week phase 2 clinical trial. Audio recordings of structured Montgomery-& Aring;sberg Depression Rating Scale (MADRS) interviews at 6 time points were examined (k = 1,352). We evaluated speech latencies, and other aspects of speech, for temporal stability, convergent validity, sensitivity/responsivity to clinical change, and generalization across seven socio-linguistically diverse countries. Speech latency was minimally associated with demographic features, and explained nearly a third of the variance in depression (categorically defined). Speech latency significantly decreased as depression symptoms improved over time, explaining nearly 20 % of variance in depression remission. Classification for differentiating people with versus without concurrent depression was high (AUCs > 0.85) both cross-sectionally and longitudinally. Results replicated across countries. Other speech features offered modest incremental contribution. Neurophysiological speech parameters with face validity can be derived from psychiatric interviews without the added patient burden of additional testing.","2024-10","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","340","","","","","","","","","","English","","","","WOS:001296084500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","ACOUSTIC MEASURES; Biomarker; Depression; DEPRESSION SEVERITY; Digital phenotyping; Interview; Language; Latency; PLACEBO; Psychomotor; SCALE; Speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9KK8Y5CG","journalArticle","2024","Fan, ZP; Zhang, XJ; Huang, M; Bu, ZH","Sampleformer: An efficient conformer-based Neural Network for Automatic Speech Recognition","INTELLIGENT DATA ANALYSIS","","1088-467X","10.3233/IDA-230612","","The Convolution-augmented Transformer (Conformer) model, which was recently introduced, has attained state-ofthe-art(SOTA) results in Automatic Speech Recognition (ASR). In this paper, a series of methodical investigations uncover that the Conformer's design decisions may not represent the most efficient choices when operating within the constraints of a limited computational budget. After a thorough re-evaluation of the Conformer architecture's design choices, we propose Sampleformer which reduces the Conformer architecture complexity and has more robust performance. We introduce downsampling to the Conformer Encoder, and to exploit the information in the speech features, we incorporate an additional downsampling module to enhance the efficiency and accuracy of our model. Additionally, we propose a novel and adaptable attention mechanism called multi-group attention, effectively reducing the attention complexity from O(n2d) to O(n2d <middle dot> f /g). We performed experiments on the AISHELL-1 corpora, our 13.3 million-parameter CTC model demonstrates a 3.0%/2.6% relative reduction in character error rate (CER) on the dev/test sets, all without the utilization of a language model (LM). Additionally, the model exhibits a 30% improvement in inference compared to our CTC Conformer baseline and trains 27% faster.","2024","2025-02-26 20:41:50","2025-02-26 20:41:50","","1647-1659","","6","28","","","","","","","","","","English","","","","WOS:001396436500012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","attention mechanism; complexity reduction; conformer; Speech recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7JQ8RVSE","journalArticle","2023","Xu, HC; Zheng, WH; Zhang, Y; Zhao, DQ; Wang, L; Zhao, YL; Wang, WD; Yuan, YB; Zhang, J; Huo, ZM; Wang, YJ; Zhao, NJ; Qin, YX; Liu, K; Xi, RD; Chen, G; Zhang, HY; Tang, C; Yan, JY; Ge, Q; Cheng, HY; Lu, Y; Gao, LB","A fully integrated, standalone stretchable device platform with in-sensor adaptive machine learning for rehabilitation","NATURE COMMUNICATIONS","","2041-1723","10.1038/s41467-023-43664-7","","Post-surgical treatments of the human throat often require continuous monitoring of diverse vital and muscle activities. However, wireless, continuous monitoring and analysis of these activities directly from the throat skin have not been developed. Here, we report the design and validation of a fully integrated standalone stretchable device platform that provides wireless measurements and machine learning-based analysis of diverse vibrations and muscle electrical activities from the throat. We demonstrate that the modified composite hydrogel with low contact impedance and reduced adhesion provides high-quality long-term monitoring of local muscle electrical signals. We show that the integrated triaxial broad-band accelerometer also measures large body movements and subtle physiological activities/vibrations. We find that the combined data processed by a 2D-like sequential feature extractor with fully connected neurons facilitates the classification of various motion/speech features at a high accuracy of over 90%, which adapts to the data with noise from motion artifacts or the data from new human subjects. The resulting standalone stretchable device with wireless monitoring and machine learning-based processing capabilities paves the way to design and apply wearable skin-interfaced systems for the remote monitoring and treatment evaluation of various diseases.","2023-11-27","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","1","14","","","","","","","","","","English","","","","WOS:001316824700034","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;77<br/>Total Times Cited:&nbsp;&nbsp;79<br/>Cited Reference Count:&nbsp;&nbsp;84</p>","","","DYSPHAGIA; ELECTRONICS; HEAD; PATTERN; PHARYNGEAL; SOFT; SPEECH; SWALLOWING DISORDERS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4WFZ5PIX","journalArticle","2024","Chau, HN; Linh, NTN; Doan, TK; Nguyen, QC","Multi-stage temporal representation learning via global and local perspectives for real-time speech enhancement","APPLIED ACOUSTICS","","0003-682X","10.1016/j.apacoust.2024.110067","","Deep learning-based speech enhancement algorithms have been rapidly developed over the past few years. Although numerous approaches have been proposed, global and local information from speech features have not been thoroughly investigated. In this paper, we introduce a novel and highly effective speech enhancement network called Multi-stage Global-Local Network (MSGLN), which exploits both local and global information via temporal self-attention, temporal graph convolution, and 1D convolution. Local modeling blocks capture the fast changes in speech signals, while global modeling blocks learn long-term trends in noise or speech signals through factors such as pitch, tone, resonance, timbre, and rhythm. In addition, we propose a multi-stage temporal processing module as the bottleneck of a complex convolutional encoder-decoder structure to guide our network to learn different acoustic structures from different scales. Then a dual-path RNN postprocessing module is integrated to reconstruct the speech spectrum mask using a frequency-wise temporal refinement block followed by a frame-wise spectral refinement block. Experimental results demonstrate the superior performance of our proposed methodology compared to other state-of-the-arts on both real-time single- and multi-channel speech enhancement tasks.","2024-07-05","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","223","","","","","","","","","","English","","","","WOS:001290863800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;79</p>","","","ATTENTION; BEAMFORMER; Deep learning-based; DOMAIN; Global and local modeling; Graph convolution; NEURAL-NETWORK; Self-attention; Speech enhancement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"52Q4HKP2","journalArticle","2021","Dong, YZ; Yang, XY","A hierarchical depression detection model based on vocal and emotional cues","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2021.02.019","","Effective and efficient automatic depression diagnosis is a challenging subject in the field of affective computing. Since speech signals provide useful information for diagnosing depression, in this paper, we propose to extract deep speaker recognition (SR) and speech emotion recognition (SER) features using pretrained models, and combine the two deep speech features to take advantage of the complementary information between the vocal and emotional differences of speakers. In addition, due to the small amount of data for depression recognition and the cost sensitivity of the diagnosis results, we propose a hierarchical depression detection model, in which multiple classifiers are set up prior to a regressor to guide the prediction of depression severity. We test our method on the AVEC 2013 and AVEC 2014 benchmark databases. The results demonstrate that the fusion of deep SR and SER features can improve the prediction performance of the model. The proposed method, using only audio features, can avoid the overfitting problem and achieves better performance than the previous audio-based methods on both databases. It also provides results comparable to those of video-based and multimodal-based methods for depression detection. (c) 2021 Elsevier B.V. All rights reserved.","2021-06-21","2025-02-26 20:41:50","2025-02-26 20:41:50","","279-290","","","441","","","","","","","","","","English","","","","WOS:000644068700006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;43<br/>Total Times Cited:&nbsp;&nbsp;45<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","AUDIO; Depression detection; Feature variation coordination; Hierarchical model; NETWORK; Pretrained model; RECOGNITION; SEVERITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"79URGNCZ","journalArticle","2022","Sun, X; Huang, J; Zheng, SX; Rao, XH; Wang, M","Personality Assessment Based on Multimodal Attention Network Learning With Category-Based Mean Square Error","IEEE TRANSACTIONS ON IMAGE PROCESSING","","1057-7149","10.1109/TIP.2022.3152049","","Personality analysis is widely used in occupational aptitude tests and entrance psychological tests. However, answering hundreds of questions at once seems to be a burden. Inspired by personality psychology, we propose a multimodal attention network with Category-based mean square error (CBMSE) for personality assessment. With this method, we can obtain information about one's behaviour from his or her daily videos, including his or her gaze distribution, speech features, and facial expression changes, to accurately determine personality traits. In particular, we propose a new approach to implementing an attention mechanism based on the facial Region of No Interest (RoNI), which can achieve higher accuracy and reduce the number of network parameters. Simultaneously, we use CBMSE, a loss function with a higher penalty for the fuzzy boundary in personality assessment, to help the network distinguish boundary data. After effective data fusion, this method achieves an average prediction accuracy of 92.07%, which is higher than any other state-of-the-art model on the dataset of the ChaLearn Looking at People challenge in association with ECCV 2016.","2022","2025-02-26 20:41:50","2025-02-26 20:41:50","","2162-2174","","","31","","","","","","","","","","English","","","","WOS:000766618300002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","attention mechanism; BEHAVIOR; category-based mean square error; Data models; DEEP; EYES; Face recognition; Faces; FEATURES; Gaze distribution; Hidden Markov models; multidata fusion; Predictive models; Psychology; Videos","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6Q9M8I9P","journalArticle","2021","Ngo, T; Kubo, R; Akagi, M","Increasing speech intelligibility and naturalness in noise based on concepts of modulation spectrum and modulation transfer function","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2021.09.004","","This study focuses on identifying effective features for controlling speech to increase speech intelligibility under adverse conditions. Previous approaches either cancel noise throughout speech presentation or preprocess speech by controlling its intensity and/or spectra. Among them, a method based on modulation transfer function theory, inverting the environmental effects to anticipate attenuation of speech modulation spectrum, shows excellent potential due to its systematic and explicit derivation of intelligibility enhancement against environmental smears. However, strictly following the inverse modulation transfer function is dangerous and inefficient as important speech features can be damaged, and it costs lots of energy to boost all smeared regions. This study takes a different approach: analyzing the relations of smeared modulation spectra by the environments for intelligibility to extract effective modifying features. First, we conduct listening tests for intelligibility in noise with different types of enhanced speech. Next, we extract acoustic and modulation frequency components in the smeared modulation spectra by noise showing high correlation with intelligibility scores. Finally, we examine the intelligibility benefits of modifying these components by performing listening tests. The results show that these components effectively increase intelligibility by at most 18%, which demonstrates that our concept is valid.","2021-12","2025-02-26 20:41:50","2025-02-26 20:41:50","","11-24","","","135","","","","","","","","","","English","","","","WOS:000707033400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","ENHANCEMENT; ENVELOPE; Intelligibility; Modulation spectrum; Modulation transfer function; PERCEPTION; RECOGNITION; ROOM ACOUSTICS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A93R5UQW","journalArticle","2021","Hu, ZF; Si, XT; Luo, Y; Tang, SS; Jian, F","Speaker Recognition Based on 3DCNN-LSTM","ENGINEERING LETTERS","","1816-093X","","","The traditional speaker recognition method reduces the feature signal from high to low dimensions, but this often leads to some speaker information loss, resulting in a low speaker recognition rate. In response to this problem, this paper proposes a model based on the combination of a 3D convolutional neural network (3DCNN) and a long short-term memory neural network (LSTM). First, the model uses a fixed-step speech feature vector as the 3DCNN input, which converts the text-independent speaker recognition mode into a ""semi-text""-related speaker recognition mode, which greatly preserves the speaker's speech features, and thus improving the difference between the characteristics of different speakers. Second, the 3D convolution kernel designed in this paper can extract the personality characteristics of speakers in different dimensions to further distinguish different speakers, connect the output signal to the LSTM network through a time series to enhance the contextual connection of the speaker's voice, and finally mark the classification output result to realize a complete speaker recognition system. The experimental results show that the model structure improves the speaker recognition rate on AISHELL-1 dataset in short-term speech compared with traditional algorithms and popular embedding features, and the system is more robust over time.","2021-05-17","2025-02-26 20:41:50","2025-02-26 20:41:50","","463-470","","2","29","","","","","","","","","","English","","","","WOS:000652486600015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","3DCNN; GMM; LSTM; semi-text processing; speaker recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"URFEAIRX","journalArticle","2023","Geng, YM","Design of English teaching speech recognition system based on LSTM network and feature extraction","SOFT COMPUTING","","1432-7643","10.1007/s00500-023-08550-w","","The development of educational informatization has had a profound impact on college English education. In order to better meet the needs of students, many universities have begun to explore new English education models. This paper designs a speech recognition system for English teaching based on LSTM network and feature extraction. LSTM network is used to process speech signals, extract speech features and then classify them. Feature extraction can transform speech signal into feature vector which can be used by classifier. Using a speech data set containing multiple English pronunciation words, the data set was tested and evaluated. The experimental results show that the speech recognition system based on LSTM network can effectively recognize the differences between different words and can achieve a higher classification accuracy under different noise and interference conditions. The English teaching speech recognition system based on LSTM network and feature extraction has great application prospects. By using the speech recognition system, teachers can evaluate students' English pronunciation level more efficiently and provide personalized teaching programs for students. At the same time, students can also practice English pronunciation independently through the speech recognition system to improve their language expression ability and listening comprehension.","2023-06-05","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","","","","","","","","","","","English","","","","WOS:001000802400027","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;14</p>","","","English teaching; Extract features; LSTM network; Speech recognition system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KB29I5LJ","journalArticle","2021","Lin, ZD; Di, CG; Chen, X","Bionic optimization of MFCC features based on speaker fast recognition","APPLIED ACOUSTICS","","0003-682X","10.1016/j.apacoust.2020.107682","","Surrounded by low SNR, how to make the voice faster and better recognize the owner has become a heated research topic. The human auditory system can accurately acquire the characteristics of acoustic events in complex systems or low SNR noise environment, which is of significance in the research of bionic hearing of human ear. The response curve of human ear output is obtained by bionic technology, which is the best response curve for sound enhancement to modify Mel filter. The method of adaptive threshold selection is used to integrate Mel features to realize the reduction and dynamic extraction of low SNR speech features. This method not only can resist the disadvantages of poor robustness and complexity of parameter model, but also obtain dynamic and comprehensive speech information of different speakers in different scenes. Finally, the improved CNN and I-vector system are contributed to reduce the dimension of the data and to verify the recognition, so as to achieve the optimal frequency selective amplification and simplification of the acoustic signal. In the case of SNR-5db, the model is reduced by 15% and the recognition accuracy is improved by 3%. (C) 2020 Elsevier Ltd. All rights reserved.","2021-02","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","173","","","","","","","","","","English","","","","WOS:000595628100010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","Adaptive endpoint detection; Bionic auditory curve; Improved Mel; Recognition filter; Voice signal","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W7N9KZM5","journalArticle","2025","Huang, YD; Shen, Q; Ma, JF","AFP-Conformer: Asymptotic feature pyramid conformer for spoofing speech detection","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2024.103149","","The existing spoofing speech detection methods mostly use either convolutional neural networks or Transformer architectures as their backbone, which fail to adequately represent speech features during feature extraction, resulting in poor detection and generalization performance of the models. To solve this limitation, we propose a novel spoofing speech detection method based on the Conformer architecture. This method integrates a convolutional module into the Transformer framework to enhance its capacity for local feature modeling, enabling to extract both local and global information from speech signals simultaneously. Besides, to mitigate the issue of semantic information loss or degradation in traditional feature pyramid networks during feature fusion, we propose a feature fusion method based on the asymptotic feature pyramid network (AFPN) to fuse multi-scale features and improve generalization of detecting unknown attacks. Our experiments conducted on the ASVspoof 2019 LA dataset demonstrate that our proposed method achieved the equal error rate (EER) of 1.61 % and the minimum tandem detection cost function (min t-DCF) of 0.045, effectively improving the detection performance of the model while enhancing its generalization capability against unknown spoofing attacks. In particular, it demonstrates substantial performance improvement in detecting the most challenging A17 attack.","2025-01","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","166","","","","","","","","","","English","","","","WOS:001359628000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Asymptotic feature pyramid network; Automatic speaker verification; Conformer; Multi-scale feature aggregation; Spoofing speech detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JEEBXCP9","journalArticle","2023","Sun, YY","Strategies for improving Chinese language proficiency based on artificial intelligence technology","APPLIED MATHEMATICS AND NONLINEAR SCIENCES","","2444-8656","10.2478/amns.2023.1.00074","","In recent years, the development of artificial intelligence technology and theory has been rapid, and the application in language science has been gradually comprehensive and diversified, especially the accuracy rate of artificial intelligence for Chinese language is up to 90%. In the era of artificial intelligence, the effect of different structures and parameters of arithmetic models on Chinese language recognition varies greatly. Language science is an important research area for realizing machine-human communication, and accurate comprehension of the meaning of linguistic expressions is the key to realize communication. In this paper, we construct a speech system that is different from the traditional stable time series for the irreplaceable characteristics of artificial intelligence technology to improve Chinese language ability. A dynamic Bayesian network (DBN) is used for modeling and analysis, and a DBN construction method is investigated to import a hidden Markov model in a speech recognition system to reveal the interactions between nodes within multiple time slices. The accuracy of dynamic Bayesian networks in Chinese dialect inference algorithms is demonstrated using Matlab simulations to characterize the reliability of speech features using a speech spectrogram. It proves that artificial intelligence technology and Chinese language science are complementary and mutually reinforcing, showing a good and rapid development trend.","2023-04-28","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","","","","","","","","","","","English","","","","WOS:000980087000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","artificial intelligence; Chinese language system; dynamic Bayesian network; IDENTIFICATION; speech recognition; speech spectrogram","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KPGG5JRC","journalArticle","2022","Minamisawa, A; Okada, S; Inoue, K; Noguchi, M","Dementia Scale Score Classification Based on Daily Activities Using Multiple Sensors","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3165208","","Early detection of age-related disease symptoms in older people by the use of daily activity data is one of the central challenges of home sensor systems. This paper focuses on dementia scale classification from daily activity data collected using sensors that can be deployed in actual residential environments. Activity data collected by four sensors (a door sensor, human motion sensor, location sensor, and sleep sensor) were obtained by recording 56 older adults living in common residences. We analyzed the effects of different types of sensor data, such as time spent in an individual room according to human motion sensors, location in a facility, and sleep patterns, on dementia detection. We then developed a feature extraction method related to daily activity patterns based on a clustering algorithm and analyzed its effectiveness. In the experimental evaluation, we trained binary classification models to classify dementia scale scores based on the Mini-Mental State Examination (MMSE) from these datasets. The experimental results show that a maximum accuracy of 0.871 was obtained with a linear support vector machine (SVM) model by fusing the door, location, and sleep features and by clustering activity patterns using the X-means algorithm.","2022","2025-02-26 20:41:50","2025-02-26 20:41:50","","38931-38943","","","10","","","","","","","","","","English","","","","WOS:000838364100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","activities of daily living (ADLs); Data mining; Dementia; Feature extraction; machine learning; MILD COGNITIVE IMPAIRMENT; Motion detection; multisensor fusion; PATTERNS; Sensor phenomena and characterization; Sensors; Sleep; SLEEP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"37YX2YXF","journalArticle","2022","Jia, FF; Wang, J; Wei, N; Sun, DW; Cao, FL","Depression, cognitive reserve markers, and dementia risk in the general population","AGING & MENTAL HEALTH","","1360-7863","10.1080/13607863.2021.1972932","","Objectives We investigated depression, cognitive reserve, and their interaction as risk factors for incident dementia among community-dwelling older adults. Methods In total, 2099 participants, aged >= 65 years with no dementia during baseline assessment, who completed the follow-up two years later were included from the Cognitive Function and Ageing Study Wales. Baseline depression and dementia and dementia at follow-up were evaluated using the Geriatric Mental State Examination and the Automated Geriatric Examination for Computer Assisted Taxonomy. Cognitive reserve was measured by combining overall education, mid-life occupational complexity, and later-life social and cognitive activities. Risk of dementia in relation to depression and cognitive reserve was estimated using penalized maximum likelihood logistic regression. Interactions between cognitive reserve and depression were assessed using both multiplicative and additive scales. Results Baseline depression and low cognitive reserve significantly increased the risk of subsequent dementia at follow-up. No multiplicative interaction between cognitive reserve and depression existed. We observed an additive interaction between case-level depression and cognitive reserve. A significant association between depression and dementia was only found among people with low cognitive-reserve levels. Conclusions Greater cognitive reserve attenuated the depression-associated risk of developing dementia. This suggests the need to emphasize prodromal dementia detection among older adults with lower cognitive reserve and depression.","2022-10-03","2025-02-26 20:41:50","2025-02-26 20:41:50","","2006-2013","","10","26","","","","","","","","","","English","","","","WOS:000695175300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","ALZHEIMER-DISEASE; ASSOCIATION; DIAGNOSIS; IMPAIRMENT; LATE-LIFE DEPRESSION; PROGRESSION; SYMPTOMS; TRAJECTORIES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HPAX7S4R","journalArticle","2022","Ramirez, MA; Beccaro, W; Rodriguez, DZ; Rosa, RL","Differentiable Measures for Speech Spectral Modeling","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3150728","","Autoregressive models for the envelope of speech power spectral densities (PSDs) are refined by the self-supervised spectral learning machine (S3LM) provided with differentiable spectral objective functions, including the Itakura-Saito divergence (ISD), the Kullback-Leibler divergence (KLD), the reverse KLD (RKLD) and the log spectral distortion (LSD), which display more significant results. However, in order to assess the models more perceptually, a method is proposed based upon perturbations around perfect reconstruction analysis-synthesis configurations. In the cross-excitation analysis-synthesis assessment (CEASA) method, the residual signals generated by analysis filters of the spectral models are injected as excitation into the synthesis filters derived from the same and other models in order to be evaluated by the perceptual evaluation of speech quality (PESQ) and Itakura divergence (ID), which are averaged over a set of models obtained using the objective functions mentioned above. The results lead to a superior performance when the RKLD is used as the loss function for the estimation of the spectral models with the ISD ranking close behind. The focus of these divergences on the spectral peaks is argued and pointed as the most important factor for this behavior. Specifically, using the PESQ scores obtained with CEASA, the RKLD loss is found to improve the performance by 1.0%, 4.0% and 19.3% with respect to the open-loop analysis, the KLD and the LSD models, respectively, while the corresponding improvements for the ISD loss are 0.1%, 3.0% and 18.2%, and the RKLD models excel the ISD models by 1.0% on average. Even though the spectral measures alone are not able to unequivocally distinguish the better of the two, CEASA is shown to have enough sensitivity to distinguish their performances. In summary, the learning machine S3LM fits models for the short-term spectral envelope of speech and, for the evaluation of its performance under several differentiable loss functions, the CEASA assessment tool has been developed. In addition, CEASA may be used for other assessments connected with speech analysis and synthesis.","2022","2025-02-26 20:41:50","2025-02-26 20:41:50","","17609-17618","","","10","","","","","","","","","","English","","","","WOS:000757826800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Analytical models; Autocorrelation; Autoregressive processes; Electronic mail; FEATURES; Loss measurement; machine learning algorithms; Modeling; NETWORKS; Power harmonic filters; prediction methods; Predictive models; self-supervised learning; spectral analysis; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"77TVIXSG","journalArticle","2023","Uchida, T","A practical method for generating whispers from singing voices: Application of improved phantom silhouette method","ACOUSTICAL SCIENCE AND TECHNOLOGY","","1346-3969","10.1250/ast.44.239","","The previously proposed phantom silhouette method is promising for converting ordinary speech into whispered speech. It is a simple parametric method that uses high-quality vocoder-type speech analysis and synthesis. An ordinary speech sample is first analyzed using the WORLD vocoder. Then, based on the extracted spectral envelope, spectral features are manipulated so that the voice sounds like a whisper. The target speech is synthesized by driving it with white noise instead of the vocal source signal to make the whole speech sound voiceless. In this study, this method was applied to singing voices to generate whisper voices. In addition to actual singing voices, virtual singers' voices were generated using a Vocaloid voice synthesizer, and AI singers' voices synthesized using a NEUTRINO neural singing synthesizer were also tested to generate whisper voices from singing voices.","2023","2025-02-26 20:41:50","2025-02-26 20:41:50","","239-246","","3","44","","","","","","","","","","English","","","","WOS:000974817900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;15</p>","","","Noise-vocoded speech; Spectral envelopment; Speech synthesis; Voice conversion; WORLD vocoder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TLWZA8IK","journalArticle","2023","De Nardis, L; Di Benedetto, MG; Choi, JY; Shattuck-Hufnagel, S","xkl: A legacy software for detailed acoustic analysis of speech made modern","SOFTWAREX","","2352-7110","10.1016/j.softx.2023.101492","","The determination of the fundamental properties of speech relies on a fine and precise estimation of temporal and spectral properties of speech segments. Given the time-varying nature of speech, a digital estimation of its instantaneous spectrum is particularly challenging, and has been the object of investigation throughout the past 50 years. The xkl software, developed in the 80's by the late Dennis Klatt at MIT, has superior capabilities in addressing the above question. Its use in the past 20 years was, however, limited by a lack of support for modern computing platforms. Revamping it will give access to a powerful tool that will eventually lead to new discoveries.& COPY; 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).","2023-07","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","23","","","","","","","","","","English","","","","WOS:001066405400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","CONSONANT GEMINATION; RECOGNITION; Spectral display; Speech analysis; Speech spectral analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"35928M5T","journalArticle","2022","Fernandes, NDCM; De Paiva, FG; Fernandes, OLDC; Da Costa, MF","ONLINE INNOVATION AND COLLABORATION IN THE CREATION OF FREE SOFTWARE","RAE-REVISTA DE ADMINISTRACAO DE EMPRESAS","","0034-7590","10.1590/S0034-759020220304x","","Advances in information technologies have led to user- centered innovation of artifacts from cyber culture. This advent of capitalism causes the emergence of approaches that contemplate collective and immaterial production in force in open source software communities. From a post-structuralist perspective, 6 interviews, 2 videos and an online discussion list were analyzed to appreciate the process of building the hegemonic discourse from the logic of equivalence, difference and fantasy. It was found that the speeches of the developers symbolize a presence yet to come, with the particular demands diluted in an equivalence chain that encompasses the largest number of claims, and that there is an effort to create an incessant process of generating value by overcoming the community frontiers, continuously articulating stakeholders to access resources and generate joint solutions in the innovation process.","2022-05","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","3","62","","","","","","","","","","English","","","","WOS:000886740600010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","BEHAVIOR; COMMUNICATION TECHNOLOGIES; COMMUNITIES; discourse theory; EVOLUTION; INFORMATION; innovation with free software; MODEL; online collaboration; ORGANIZATION; PERSPECTIVES; pug-pe community; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9626WY9X","journalArticle","2022","Dias, LSR; Mendes, LDR","AN ANALYSIS OF THE DISCURSIVE STRUGGLE ABOUT THE MEMORY AND HISTORY OF THE 1964 COUP","REVISTA MEDIACAO","","1676-2827","","","This article aims to debate the discursive dispute over the history and memory of the 1964 coup and the period of the military government in Brazil (1964-1985), and the truth effect produced by the journalistic discourse in this sense, from the analysis of a video made by supporters of the Bolsonaro government to celebrate the 55th anniversary of the beginning of the regime, on March 31, 2019. The film of just under two minutes circulated on the main social networks after being shared not only by supporters of President Jair Bolsonaro, but also by an institutional channel of the Planalto Palace. We understand that the audiovisual product in question materializes the efforts of the extreme right - which took back power in Brazil in 2019, this time through the electoral route - to reposition the 21 years of military dictatorship as a memorable past.","2022-07","2025-02-26 20:41:50","2025-02-26 20:41:50","","69-80","","33-34","23-24","","","","","","","","","","English","","","","WOS:001007225200008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;14</p>","","","1964 Coup; Discursive Dispute; Journalistic Speech; Memory; Speech Analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FA2XZDU3","journalArticle","2023","Schinke, VD; Scheifler, DSD","The rewriting of judicial decisions as a sliding of meanings: from discourse analysis to literature","DIREITO E PRAXIS","","2179-8966","10.1590/2179-8966/2023/79099","","The present article analyze the potential of the Rewriting of Judicial Decisions project with Feminist Perspectives from the analysis of the discourse and language of the literature. It understands the judicial decision as a repetition of meanings authorized by a dominant discursive formation in the Judiciary, while rewritings with feminist perspectives have the potential to slide meanings and point to meanings allocated in the folding of memory because they are interdicted by the hegemonic discursive matrix. The work also reflects on the silence in the process of paraphrasing the discursive matrix and asks if there would be a language capable of passing through the dominant discursive formation. Women's literature presents itself as a language capable of indicating memorable meanings, insofar as it shares narratives of subaltern subjects and destabilizes the traditional conformation about what can or cannot be said.","2023","2025-02-26 20:41:50","2025-02-26 20:41:50","","2664-2687","","4","14","","","","","","","","","","English","","","","WOS:001161798500010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","Feminisms; Judicial decision; Literature; Speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"66ICM7P6","journalArticle","2021","Meer, P; Brato, T; Flores, JAM","Extending automatic vowel formant extraction to New Englishes A comparison of different methods","ENGLISH WORLD-WIDE","","0172-8865","10.1075/eww.00060.mee","","While different automated procedures for vowel formant prediction have recently been proposed, it is unclear how reliably these methods perform in the phonetic study of vowels in New Englishes and how such approaches could be applied to specific varieties. This paper compares different automatic methods for vowel formant prediction in New Englishes, using manual measurements of Trinidadian English as a baseline. The results show that all methods perform significantly better than default formant parameters often used in speech analysis packages, and that a Bayesian formant tracker calibrated with American (US-FAVE) and Trinidadian English (TRINI-FAVE) generally provides better results than an automatic procedure that optimizes formant ceilings on a vowel- and speaker-specific level. TRINI-FAVE measures vowels characteristic of Trinidadian English most accurately. Phonetic studies of vowels in New Englishes can benefit from these methods.","2021","2025-02-26 20:41:50","2025-02-26 20:41:50","","54-84","","1","42","","","","","","","","","","English","","","","WOS:000635051100003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","automated acoustic analysis; automatic formant prediction; FAVE; formant ceiling optimization; New Englishes; Trinidadian English; vowels","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TFR3QAGI","journalArticle","2021","Bertosso, H; Pauli, J","""Who Guards the Guards?"": A Study About the Power of Bank Managers Concerning the Organizational Electronic Control","INTERNATIONAL JOURNAL OF HUMAN CAPITAL AND INFORMATION TECHNOLOGY PROFESSIONALS","","1947-3478","10.4018/IJHCITP.2021010101","","The studies about panopticism have a highlighted spot on organizational researches. Recently, with the inclusion of information technology, it creates the digital panopticon, in which informational systems perform the control, including on the vigilantes themselves (managers). Thus, this study addresses hierarchy, power, and the insertion of information technology in banking organizations to understand the perception of managers about their power over the team on this new kind of materialization of power. For such, this qualitative exploratory research used interview and observation as data collection and triangulation techniques. The treatment of information performed was by speech analysis. The analysis of collected data revealed that the manager is not responsible for the conception of work anymore, because they became a task performer, showing their subjection to the system of the establishment and target control; after all, the power is in the system.","2021-01","2025-02-26 20:41:50","2025-02-26 20:41:50","","1-18","","1","12","","","","","","","","","","English","","","","WOS:000593051100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Banks; Digital Panopticon; Managers; Power","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AZ9R4YYR","journalArticle","2021","Rao, TVM; Korada, S; Srinivas, Y","Machine hearing system for teleconference authentication with effective speech analysis","INTERNATIONAL JOURNAL OF KNOWLEDGE-BASED AND INTELLIGENT ENGINEERING SYSTEMS","","1327-2314","10.3233/KES-210079","","The speaker identification in Teleconferencing scenario, it is important to address whether a particular speaker is a part of a conference or not and to note that whether a particular speaker is spoken at the meeting or not. The feature vectors are extracted using MFCC-SDC-LPC. The Generalized Gamma Distribution is used to model the feature vectors. K-means algorithm is utilized to cluster the speech data. The test speaker is to be verified that he/she is a participant in the conference. A conference database is generated with 50 speakers. In order to test the model, 20 different speakers not belonging to the conference are also considered. The efficiency of the model developed is compared using various measures such as AR, FAR and MDR. And the system is tested by varying number of speakers in the conference. The results show that the model performs more robustly.","2021","2025-02-26 20:41:50","2025-02-26 20:41:50","","357-365","","3","25","","","","","","","","","","English","","","","WOS:000720829200008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","AR; FAR; GGD; K-means; LPC; MDR; MFCC; SDC","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4JPTXW46","journalArticle","2024","Lee, JB; Lee, HG","Quantitative analysis of automatic voice disorder detection studies for hybrid feature and classifier selection☆","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2024.106014","","Owing to the development of machine learning, particularly deep learning, researchers have focused on automatic voice-disorder detection. However, voice-disorder datasets vary significantly in terms of the number of patients per disorder, and different conditions are targeted in different studies. Therefore, conducting direct comparisons of performances across related studies is complicated. Hence, we compare conventional machine learning, deep learning, and multimodal methods by establishing a fixed dataset and an evaluation pipeline using the Saarbrucken voice database, which is the most commonly used database for automatic voice-disorder detection. In addition, we propose an automatic voice-disorder detection method that combines features and classifiers. Experimental results show mean unweighted average recall differences of 8% and 15% on the abovementioned two datasets, respectively, and that the proposed combination improves them by 1.5% and 0.5%, respectively.","2024-05","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","91","","","","","","","","","","English","","","","WOS:001186366400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","HEALTH-CARE; Healthcare; IDENTIFICATION; Machine learning; PATHOLOGY DETECTION; Speech analysis; Voice disorder detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y47AYGNN","journalArticle","2021","Chowdhury, N; Bansal, AR; Goyal, R; Nikhila, G","Cerebral dominance in an unusual case of Landau-Kleffner syndrome","BMJ CASE REPORTS","","1757-790X","10.1136/bcr-2021-246696","","Landau-Kleffner syndrome (LKS) is described by the International Classification of Epileptic Syndromes since 1985 as a constellation of clinical and electrographic signs, including acquired aphasia, regression of language milestones and seizures, along with sleep-activated paroxysms on electroencephalogram which can progress to electrographic status epilepticus of sleep. In this case, a 7-year-old boy presented with an atypical history of new-onset aphasia and regression of language milestones with rare seizures. However, there was an electrographic mismatch in the form of right-sided epileptiform activity and continuous spike and wave of sleep pattern. Detailed speech analysis and perusal of the history revealed a possibly ambidextrous child with right hemispheric language dominance, and he was diagnosed with LKS and treated. This report illustrates the many pitfalls in the diagnosis and treatment of this rare epileptic syndrome.","2021-12","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","12","14","","","","","","","","","","English","","","","WOS:000729569600009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","ACQUIRED APHASIA; CHILDHOOD; clinical neurophysiology; epilepsy and seizures; neurology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JHLIYIHZ","journalArticle","2024","Palominos, C; He, R; Fröhlich, K; Muelfarth, RR; Seuffert, S; Sommer, IE; Homan, P; Kircher, T; Stein, F; Hinzen, W","Approximating the semantic space: word embedding techniques in psychiatric speech analysis","SCHIZOPHRENIA","","2754-6993","10.1038/s41537-024-00524-7","","Large language models provide high-dimensional representations (embeddings) of word meaning, which allow quantifying changes in the geometry of the semantic space in mental disorders. A pattern of a more condensed ('shrinking') semantic space marked by an increase in mean semantic similarity between words has been recently documented in psychosis across several languages. We aimed to explore this pattern further in picture descriptions provided by a transdiagnostic German sample of patients with schizophrenia spectrum disorders (SSD) (n = 42), major depression (MDD, n = 43), and healthy controls (n = 44). Compared to controls, both clinical groups showed more restricted dynamic navigational patterns as captured by the time series of semantic distances crossed, while also showing differential patterns in the total distances and trajectories navigated. These findings demonstrate alterations centred on the dynamics of the flow of meaning across the semantic space in SSD and MDD, preserving previous indications towards a shrinking semantic space in both cases.","2024-12-02","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","1","10","","","","","","","","","","English","","","","WOS:001375832800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","LANGUAGE; SCHIZOPHRENIA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WR83TPLM","journalArticle","2022","Qiu, XL; Li, W; Li, Y; Gu, HM; Song, F; Sabitha, R","Machine Learning in Human Emotion Detection from the Speech","JOURNAL OF INTERCONNECTION NETWORKS","","0219-2659","10.1142/S0219265921460038","","The identification of speech emotions is amongst the most strenuous and fascinating fields of machine learning science. In this article, Chinese emotions are classified as a disruptive atmosphere that classifies several feelings into four major emotional organizations: pleasure, sorrow, resentment, and neutrality. A machine learning in human emotion detection (ML-HED) framework is proposed. The technology suggested removing prosodic and spectrum elements of an audio wave, such as a pulse, power, amplitude, Cepstrum melt frequency correlations, linearly fixed Cepstral, and identification with a template. In all, 87,75% of performers' statements and 93% of women's actors were given reliability. The research findings show that the revolutionary technology achieves greater precision by accurately interpreting the feelings, which contrasts with current speech emotion recognition approaches. Besides, the derived characteristics were contrasting with various classification techniques in this study for the comprehensive idea.","2022-06","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","SUPP04","22","","","","","","","","","","English","","","","WOS:000864173200011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","emotion detection; machine learning; Mel-frequency Cepstrum coefficients; RECOGNITION; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JL6JZ45I","journalArticle","2024","Xie, PG; Wang, H; Xiao, J; Xu, F; Liu, JY; Chen, ZH; Zhao, WJ; Hou, SY; Wu, DD; Ma, Y; Xiao, JJ","Development and Validation of an Explainable Deep Learning Model to Predict In-Hospital Mortality for Patients With Acute Myocardial Infarction: Algorithm Development and Validation Study","JOURNAL OF MEDICAL INTERNET RESEARCH","","1438-8871","10.2024/1/e49848","","Background: Acute myocardial infarction (AMI) is one of the most severe cardiovascular diseases and is associated with a high risk of in-hospital mortality. However, the current deep learning models for in-hospital mortality prediction lack interpretability. Objective: This study aims to establish an explainable deep learning model to provide individualized in-hospital mortality prediction and risk factor assessment for patients with AMI. Methods: In this retrospective multicenter study, we used data for consecutive patients hospitalized with AMI from the Chongqing University Central Hospital between July 2016 and December 2022 and the Electronic Intensive Care Unit Collaborative Research Database. These patients were randomly divided into training (7668/10,955, 70%) and internal test (3287/10,955, 30%) data sets. In addition, data of patients with AMI from the Medical Information Mart for Intensive Care database were used for external validation. Deep learning models were used to predict in-hospital mortality in patients with AMI, and they were compared with linear and tree-based models. The Shapley Additive Explanations method was used to explain the model with the highest area under the receiver operating characteristic curve in both the internal test and external validation data sets to quantify and visualize the features that drive predictions. Results: A total of 10,955 patients with AMI who were admitted to Chongqing University Central Hospital or included in the Electronic Intensive Care Unit Collaborative Research Database were randomly divided into a training data set of 7668 (70%) patients and an internal test data set of 3287 (30%) patients. A total of 9355 patients from the Medical Information Mart for Intensive Care database were included for independent external validation. In-hospital mortality occurred in 8.74% (670/7668), 8.73% (287/3287), and 9.12% (853/9355) of the patients in the training, internal test, and external validation cohorts, respectively. The Self-Attention and Intersample Attention Transformer model performed best in both the internal test data set and the external validation data set among the 9 prediction models, with the highest area under the receiver operating characteristic curve of 0.86 (95% CI 0.84-0.88) and 0.85 (95% CI 0.84-0.87), respectively. Older age, high heart rate, and low body temperature were the 3 most important predictors of increased mortality, according to the explanations of the Self-Attention and Intersample Attention Transformer model. Conclusions: The explainable deep learning model that we developed could provide estimates of mortality and visual contribution of the features to the prediction for a patient with AMI. The explanations suggested that older age, unstable vital signs, and metabolic disorders may increase the risk of mortality in patients with AMI.","2024-05-10","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","26","","","","","","","","","","English","","","","WOS:001226418000003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","acute myocardial infarction; AI; BLACK-BOX; DEATH; deep learning; explainable model; LOGISTIC-REGRESSION; mortality; prediction; REGISTRY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QURSTWZA","journalArticle","2023","Liu, TY; Zhang, M; Zhu, CY; Chang, L","Transformer-based convolutional forgetting knowledge tracking","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-023-45936-0","","Knowledge tracking is to analyze the mastery of students' knowledge through the learning track. This is very important for online education, since it can determine a learner's current knowledge level by analyzing the learning history and then make recommendations for future learning. In the past, the commonly used model for knowledge tracking is the convolutional neural network, but it has long-term sequence dependencies. With the invention of Transformer, it has excellent performance in long-sequence modeling by virtue of the attention mechanism, and is gradually introduced into the field of knowledge tracking. However, through our research, some knowledge tracking data sets have a large number of continuous and repetitive training, which will cause Transformer model to ignore the potential connections between some knowledge points. To overcome this problem, we introduce a convolutional attention mechanism to help the model perceive contextual information better. In addition, we simulate the forgetting phenomenon of students during the learning process by calculating the forgetting factor, and fuse it with the weight matrix generated by the model to improve the accuracy of the model. As a result, a Transformer-based Convolutional Forgetting Knowledge Tracking (TCFKT) model is presented in this paper. According to the experimental results conducted on the real world ASSITments2012, ASSISTments2017, KDD a, STATIC datasets, the TCFKT model outperforms other knowledge tracking models.","2023-11-04","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","1","13","","","","","","","","","","English","","","","WOS:001099663700038","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KTUE4BI2","journalArticle","2023","Ma, MR; Han, LS; Zhou, CJ","BTAD: A binary transformer deep neural network model for anomaly detection in multivariate time series data","ADVANCED ENGINEERING INFORMATICS","","1474-0346","10.1016/j.aei.2023.101949","","In the context of big data, if the task of multivariate time series data anomaly detection cannot be performed efficiently and accurately, it will bring great security risks to industrial systems. However, fast model inference requirements, unlabeled datasets and excessively long time series make it a challenging problem to build an accurate and fast anomaly detection model. In this paper, we propose an unsupervised Bi-Transformer anomaly detection method (BTAD) for multivariate time series data, which uses Bi-Transformer structure to extract dataset association features, and uses an improved adaptive multi-head attention mechanism to infer trends in each meta-dimension of multivariate time series data in parallel. The modified Decoder structure prevents the reconstructed output of BTAD from being disturbed by the input information. Self-conditioning mechanism could enhance the robustness to noisy data, and improve model's generalization ability. Experiments show that BTAD could outperform other models in detection performance and training efficiency. Taking NAB dataset as an example, the AUC and F1 of BTAD are increased by more than 4.78% and 1.40% separately. Finally, we look forward to the future development trend of BTAD, and put forward the corresponding improvement ideas.","2023-04","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","56","","","","","","","","","","English","","","","WOS:000965002200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;36<br/>Total Times Cited:&nbsp;&nbsp;36<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Adaptive multi-head attention mechanism; Bi-Transformer model; Model-agnostic meta learning; Multivariate time series data; Self-conditioning mechanism","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A7PI6LVJ","journalArticle","2023","Fu, PB; Ma, YC; Yang, HR","Speaker diarization with variants of self-attention and joint speaker embedding extractor","JOURNAL OF INTELLIGENT & FUZZY SYSTEMS","","1064-1246","10.3233/JIFS-230249","","The speaker diarization task pertains to the automated differentiation of speakers within an audio recording, while lacking any prior information regarding the speakers. The introduction of the self-attention mechanism in End-to-End Neural Speaker Diarization (EEND) has elegantly resolved the issue of overlapping speakers. The Transformer model equipped with self-attention mechanism has shown great potential in collecting global information, yielding remarkable outcomes in various tasks. However, the individual speaker characteristics are predominantly reflected in the contextual information, which conventional self-attention would not adequately address. In this study, we propose a hierarchical encoders model to augment the encoders' acquisition of speaker information in two distinct ways: (1) Constraining the perceptual field of the self-attentive mechanism with left-right windows or Gaussian weights to highlight contextual information; (2) Utilizing a pre-trained time-delay neural network based speaker embedding extractor to alleviate the shortcomings of speaker feature extraction ability. We evaluate the proposed methods on a simulated dataset of two speakers and a real conversation dataset. The model with the most favorable outcomes among the proposed enhancements achieves a diarization error rate of 7.74% on the simulated dataset and 21.92% on MagicData-RAMC after adaptation. These results compellingly demonstrate the efficacy of the proposed methods.","2023","2025-02-26 20:41:50","2025-02-26 20:41:50","","9169-9180","","5","45","","","","","","","","","","English","","","","WOS:001099536200131","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","constraint self-attention; contextual information; Gaussian weight; Speaker diarization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BMPFI4A5","journalArticle","2024","Mateen, M; Hayat, S; Arshad, F; Gu, YH; Al-antari, MA","Hybrid Deep Learning Framework for Melanoma Diagnosis Using Dermoscopic Medical Images","DIAGNOSTICS","","2075-4418","10.3390/diagnostics14192242","","Background: Melanoma, or skin cancer, is a dangerous form of cancer that is the major cause of the demise of thousands of people around the world. Methods: In recent years, deep learning has become more popular for analyzing and detecting these medical issues. In this paper, a hybrid deep learning approach has been proposed based on U-Net for image segmentation, Inception-ResNet-v2 for feature extraction, and the Vision Transformer model with a self-attention mechanism for refining the features for early and accurate diagnosis and classification of skin cancer. Furthermore, in the proposed approach, hyperparameter tuning helps to obtain more accurate and optimized results for image classification. Results: Dermoscopic shots gathered by the worldwide skin imaging collaboration (ISIC2020) challenge dataset are used in the proposed research work and achieved 98.65% accuracy, 99.20% sensitivity, and 98.03% specificity, which outperforms the other existing approaches for skin cancer classification. Furthermore, the HAM10000 dataset is used for ablation studies to compare and validate the performance of the proposed approach. Conclusions: The achieved outcome suggests that the proposed approach would be able to serve as a valuable tool for assisting dermatologists in the early detection of melanoma.","2024-10","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","19","14","","","","","","","","","","English","","","","WOS:001331728300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","classification; COLOR; deep learning; DERMATOSCOPY; lesion segmentation; melanoma detection; skin lesion; SKIN-LESIONS; SYSTEM; ultraviolet rays","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XIKN757T","journalArticle","2024","Khan, MZ; Usman, M; Ahmad, J; Rahman, MMU; Abbas, H; Imran, M; Abbasi, QH","Tag-free indoor fall detection using transformer network encoder and data fusion","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-67439-2","","This work presents a radio frequency identification (RFID)-based technique to detect falls in the elderly. The proposed RFID-based approach offers a practical and efficient alternative to wearables, which can be uncomfortable to wear and may negatively impact user experience. The system utilises strategically positioned passive ultra-high frequency (UHF) tag array, enabling unobtrusive monitoring of elderly individuals. This contactless solution queries battery-less tag and processes the received signal strength indicator (RSSI) and phase data. Leveraging the powerful data-fitting capabilities of a transformer model to take raw RSSI and phase data as input with minimal preprocessing, combined with data fusion, it significantly improves activity recognition and fall detection accuracy, achieving an average rate exceeding 96.5%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$96.5\%$$\end{document}. This performance surpasses existing methods such as convolutional neural network (CNN), recurrent neural network (RNN), and long short-term memory (LSTM), demonstrating its reliability and potential for practical implementation. Additionally, the system maintains good accuracy beyond a 3-m range using minimal battery-less UHF tags and a single antenna, enhancing its practicality and cost-effectiveness.","2024-07-21","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","1","14","","","","","","","","","","English","","","","WOS:001273447200002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","DETECTION SYSTEM; RFID TAGS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PYA5FPJ2","journalArticle","2024","Ji, TY; Zhao, C; Ji, YX; Du, YC","A two-stage framework for parking search behavior prediction through adversarial inverse reinforcement learning and transformer","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.124548","","Parking scenarios are spatially dense and have a lot of interactions, making predicting vehicles' search behavior crucial and challenging for autonomous driving. Existing data-driven prediction methods struggle to determine vehicles' intents and consider the surrounding environment accurately. This study proposes a novel two-stage framework for parking search behavior prediction, involving parking intent and vehicle trajectory predictions based on imitation learning and deep learning. First, we develop an adversarial inverse reinforcement learning model for parking search intent (PSI-AIRL) learning from measured trajectory data in an actual parking lot. Then, we design an integrated convolutional neural network (CNN) and transformer model to forecast vehicle trajectory using historical observations and the predicted parking search intents. This two-stage framework achieves parking search intent prediction by applying global information about the parking lot while improving vehicle trajectory prediction's accuracy and robustness. Finally, the experiments are conducted on the Dragon Lake Parking (DLP) dataset to compare our framework with state-of-the-art models. The results show that our model outperforms other baseline models in accuracy for parking intent and vehicle trajectory predictions. Moreover, our model shows exceptional accuracy and robustness in predicting across diverse parking scenarios.","2024-12-01","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","255","","","","","","","","","","English","","","","WOS:001288729300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","(AIRL); Adversarial inverse reinforcement learning; Behavior prediction; INTENT PREDICTION; Parking lot; RECOGNITION; Transformer; VEHICLE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CX5PLASA","journalArticle","2024","Hajikhani, M; Hegde, A; Snyder, J; Cheng, JL; Lin, MS","Integrating transformer-based machine learning with SERS technology for the analysis of hazardous pesticides in spinach","JOURNAL OF HAZARDOUS MATERIALS","","0304-3894","10.1016/j.jhazmat.2024.134208","","This study introduces an innovative strategy for the rapid and accurate identification of pesticide residues in agricultural products by combining surface-enhanced Raman spectroscopy (SERS) with a state-of-the-art transformer model, termed SERSFormer. Gold-silver core-shell nanoparticles were synthesized and served as highperformance SERS substrates, which possess well-defined structures, uniform dispersion, and a core-shell composition with an average diameter of 21.44 +/- 4.02 nm, as characterized by TEM-EDS. SERSFormer employs sophisticated, task-specific data processing techniques and CNN embedders, powered by an architecture features weight-shared multi-head self-attention transformer encoder layers. The SERSFormer model demonstrated exceptional proficiency in qualitative analysis, successfully classifying six categories, including five pesticides (coumaphos, oxamyl, carbophenothion, thiabendazole, and phosmet) and a control group of spinach data, with 98.4% accuracy. For quantitative analysis, the model accurately predicted pesticide concentrations with a mean absolute error of 0.966, a mean squared error of 1.826, and an R2 score of 0.849. This novel approach, which combines SERS with machine learning and is supported by robust transformer models, showcases the potential for real-time pesticide detection to improve food safety in the agricultural and food industries.","2024-05-15","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","470","","","","","","","","","","English","","","","WOS:001227659900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Artificial intelligence; ENHANCED RAMAN-SPECTROSCOPY; Machine learning; Pesticide; RESIDUES; SERS; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TMMWNML8","journalArticle","2024","Arthaud, F; Lecoeur, G; Pierre, A","Transformers à Grande Vitesse: Massively parallel real-time predictions of train delay propagation","JOURNAL OF RAIL TRANSPORT PLANNING & MANAGEMENT","","2210-9706","10.1016/j.jrtpm.2023.100418","","Robust travel time predictions are of prime importance in managing any transportation infrastructure, and particularly in rail networks where they have major impacts both on traffic regulation and passenger satisfaction. We aim at predicting the travel time of trains on rail sections at the scale of an entire rail network in real-time, by estimating trains' delays relative to a theoretical circulation plan.Predicting the evolution of a given train's delay is a uniquely hard problem, distinct from mainstream road traffic forecasting problems, since it involves several hard-to-model phenomena: train spacing, station congestion and heterogeneous rolling stock among others. We first offer empirical evidence of the previously unexplored phenomenon of delay propagation at the scale of a railway network, leading to delays being amplified by interactions between trains and the network's physical limitations.We then contribute a novel technique using the transformer architecture and pre-trained embeddings to make real-time massively parallel predictions for train delays at the scale of the whole rail network (over 3000 trains at peak hours, making predictions at an average horizon of 70 min). Our approach yields very positive results on real-world data when compared to currently-used and experimental prediction techniques.","2024-03","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","29","","","","","","","","","","English","","","","WOS:001134474000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Complex systems; Delay propagation; Operations research; Propagation forecasting; Traffic forecasting; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SRP4UVT2","journalArticle","2023","Xiao, JB; Zhou, P; Yao, A; Li, YC; Hong, RC; Yan, SC; Chua, TS","Contrastive Video Question Answering via Video Graph Transformer","IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE","","0162-8828","10.1109/TPAMI.2023.3292266","","We propose to perform video question answering (VideoQA) in a Contrastive manner via a Video Graph Transformer model (CoVGT). CoVGT's uniqueness and superiority are three-fold: 1) It proposes a dynamic graph transformer module which encodes video by explicitly capturing the visual objects, their relations and dynamics, for complex spatio-temporal reasoning. 2) It designs separate video and text transformers for contrastive learning between the video and text to perform QA, instead of multi-modal transformer for answer classification. Fine-grained video-text communication is done by additional cross-modal interaction modules. 3) It is optimized by the joint fully- and self-supervised contrastive objectives between the correct and incorrect answers, as well as the relevant and irrelevant questions respectively. With superior video encoding and QA solution, we show that CoVGT can achieve much better performances than previous arts on video reasoning tasks. Its performances even surpass those models that are pretrained with millions of external data. We further show that CoVGT can also benefit from cross-modal pretraining, yet with orders of magnitude smaller data. The results demonstrate the effectiveness and superiority of CoVGT, and additionally reveal its potential for more data-efficient pretraining.","2023-11-01","2025-02-26 20:41:50","2025-02-26 20:41:50","","13265-13280","","11","45","","","","","","","","","","English","","","","WOS:001258161200009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;85</p>","","","Benchmark testing; Cognition; contrastive learning; cross-modal visual reasoning; Data models; dynamic visual graphs; Question answering (information retrieval); Task analysis; transformer; Transformers; video- language; VideoQA; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2UQMEVWM","journalArticle","2024","Li, PY; Wang, XF; Jiang, CL; Bi, HB; Liu, YZ; Yan, WD; Zhang, C; Dong, TJ; Sun, Y","Advanced transformer model for simultaneous leakage aperture recognition and localization in gas pipelines","RELIABILITY ENGINEERING & SYSTEM SAFETY","","0951-8320","10.1016/j.ress.2023.109685","","This study proposes a joint learning end-to-end dual-stream transformer structure based on enhanced external attention and improved feedforward mechanisms (EEA-JL) to address the problem of simultaneous leakage aperture recognition and localization in gas pipelines under noisy backgrounds. The EEA-JL structure can effectively improve the accuracy of leakage aperture recognition and localization in a single model. Traditional convolutional neural networks (CNNs) and recursive frameworks (RNNs) have limitations in extracting leakage features and analyzing positional information, making it difficult to capture the correlation coupling between different leakage apertures and positions. The EEA-JL structure incorporates a self-attention mechanism with two external linear neural memory units to analyze the correlation between samples and deepen the understanding of different leakage scenarios. Additionally, the multi-scale soft-threshold denoising module (MSSD) adaptively estimates the noise threshold of signals under different leakage conditions to achieve denoising. Through simulation experiments on a 169-meter oil and gas pipeline leakage detection system platform and comparison with other advanced methods, the EEA-JL model achieves a precision rate and R2score of 99.7% and 0.993, respectively, in aperture recognition and localization, with an average positioning error controlled within 1.26 m, demonstrating its guiding significance.","2024-01","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","241","","","","","","","","","","English","","","","WOS:001088785600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Dual-stream network; Joint learning; Leak aperture recognition; Localization; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HQPJYQKU","journalArticle","2023","Chen, YQ","Construction of a carbon neutral enterprise environmental performance assessment model based on transformer-GRU","FRONTIERS IN ECOLOGY AND EVOLUTION","","2296-701X","10.3389/fevo.2023.1247644","","Introduction: Carbon-neutral enterprise environmental performance assessment is an important method for evaluating the impact and benefits of enterprises on the environment during the process of achieving carbon neutrality. This paper proposes a method for evaluating the environmental performance of carbon-neutral enterprises using the Transformer-GRU model.Methods: The proposed method combines the Transformer and GRU models to accurately predict and analyze the environmental performance of carbon-neutral enterprises. The Transformer model is used to extract features, and the GRU model is used for sequence modeling, which improves the model's prediction accuracy and generalization ability. The method is validated using actual enterprise data for experimental verification.Results: The experiments show that the proposed method has significant practical significance in evaluating the environmental performance of carbon-neutral enterprises. The method accurately predicts and analyzes the enterprise's carbon emissions, energy consumption, wastewater and gas discharge, and solid waste treatment.Discussion: The proposed method provides a new approach for evaluating the environmental performance of carbon-neutral enterprises. The combination of the Transformer and GRU models can effectively improve the accuracy and generalization ability of the model. The method can be used to help enterprises evaluate their environmental performance and make decisions to achieve carbon neutrality.","2023-08-10","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","11","","","","","","","","","","English","","","","WOS:001093644800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","BERT; carbon neutral; corporate environmental performance assessment; GRU; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7MQTLE3N","journalArticle","2023","Burgund, D; Nikolovski, S; Galic, D; Maravic, N","Pearson Correlation in Determination of Quality of Current Transformers","SENSORS","","1424-8220","10.3390/s23052704","","The article elaborates on the accuracy of current transformers (CT) in interaction with temperature and frequency using Pearson's correlation. The first part of the analysis compares the accuracy of the mathematical model of the current transformer and the result of the measurement on the real CT using the Pearson correlation calculation. The mathematical model of CT is determined by deriving the formula of the functional error with the display of the accuracy of the measured value. The accuracy of the mathematical model is affected by the accuracy of current transformer model parameters and the calibration characteristic of the ammeter used to measure the CT current. Variables that cause deviation in the accuracy of CT are temperature and frequency. The calculation shows the effects on accuracy in both cases. The second part of the analysis refers to the calculation of the partial correlation of three quantities: (1) CT accuracy, (2) temperature, and (3) frequency on a set of 160 measurements. First, the influence of temperature on the correlation of CT accuracy and frequency is proven, following the proof of the influence of frequency on the correlation of CT accuracy and temperature. In the end, the analysis is combined by comparing the measured results of the first and second part of the analysis.","2023-03","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","5","23","","","","","","","","","","English","","","","WOS:000947295200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;11</p>","","","current transformer; frequency; partial correlation; Pearson correlation; temperature","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NMZTSEAZ","journalArticle","2021","Schwaller, P; Vaucher, AC; Laino, T; Reymond, JL","Prediction of chemical reaction yields using deep learning","MACHINE LEARNING-SCIENCE AND TECHNOLOGY","","2632-2153","10.1088/2632-2153/abc81d","","Artificial intelligence is driving one of the most important revolutions in organic chemistry. Multiple platforms, including tools for reaction prediction and synthesis planning based on machine learning, have successfully become part of the organic chemists' daily laboratory, assisting in domain-specific synthetic problems. Unlike reaction prediction and retrosynthetic models, the prediction of reaction yields has received less attention in spite of the enormous potential of accurately predicting reaction conversion rates. Reaction yields models, describing the percentage of the reactants converted to the desired products, could guide chemists and help them select high-yielding reactions and score synthesis routes, reducing the number of attempts. So far, yield predictions have been predominantly performed for high-throughput experiments using a categorical (one-hot) encoding of reactants, concatenated molecular fingerprints, or computed chemical descriptors. Here, we extend the application of natural language processing architectures to predict reaction properties given a text-based representation of the reaction, using an encoder transformer model combined with a regression layer. We demonstrate outstanding prediction performance on two high-throughput experiment reactions sets. An analysis of the yields reported in the open-source USPTO data set shows that their distribution differs depending on the mass scale, limiting the data set applicability in reaction yields predictions.","2021-03","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","1","2","","","","","","","","","","English","","","","WOS:000660500300021","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;186<br/>Total Times Cited:&nbsp;&nbsp;197<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","chemical reactions; deep learning; OUTCOMES; transformer; TRANSFORMER; yield prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MW9BLCPR","journalArticle","2024","Chen, X; Wang, M; Kan, RX; Qiu, HB","Improved Patch-Mix Transformer and Contrastive Learning Method for Sound Classification in Noisy Environments","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14219711","","In urban environments, noise significantly impacts daily life and presents challenges for Environmental Sound Classification (ESC). The structural influence of urban noise on audio signals complicates feature extraction and audio classification for environmental sound classification methods. To address these challenges, this paper proposes a Contrastive Learning-based Audio Spectrogram Transformer (CL-Transformer) that incorporates a Patch-Mix mechanism and adaptive contrastive learning strategies while simultaneously improving and utilizing adaptive data augmentation techniques for model training. Firstly, a combination of data augmentation techniques is introduced to enrich environmental sounds. Then, the Patch-Mix feature fusion scheme randomly mixes patches of the enhanced and noisy spectrograms during the Transformer's patch embedding. Furthermore, a novel contrastive learning scheme is introduced to quantify loss and improve model performance, synergizing well with the Transformer model. Finally, experiments on the ESC-50 and UrbanSound8K public datasets achieved accuracies of 97.75% and 92.95%, respectively. To simulate the impact of noise in real urban environments, the model is evaluated using the UrbanSound8K dataset with added background noise at different signal-to-noise ratios (SNR). Experimental results demonstrate that the proposed framework performs well in noisy environments.","2024-11","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","21","14","","","","","","","","","","English","","","","WOS:001351062100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","contrastive learning; data augmentation; deep learning; feature fusion; transformer; urban environmental sound recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ULHWUAPD","journalArticle","2024","Khalladi, SA; Ouessaia, A; Keche, M","Road Traffic Classification from Nighttime Videos Using the Multihead Self-Attention Vision Transformer Model and the SVM","AUTOMATIC CONTROL AND COMPUTER SCIENCES","","0146-4116","10.3103/S0146411624700652","","Intelligent transport systems (ITSs) have emerged as a groundbreaking solution to address the challenges associated with road traffic, which are enhancing road utilization efficiency, providing convenient and safe transportation, and reducing energy consumption. ITS leverages advanced technologies to collect, store, and deliver real-time road traffic information, enabling intelligent decision-making and optimizing various aspects of transportation systems. As a contribution in this matter, we propose in this paper a novel efficient macroscopic approach, based on the multihead self-attention vision transformer (MSViT), for categorizing road traffic congestion, from nighttime videos, into three classes: light, medium, and heavy. To assess the performance of our approach, we conducted experiments using the nighttime UCSD (University of California San Diego) dataset, which includes various weather conditions (clear, overcast, and rainy) and traffic scenarios (light, medium, and heavy). The classification accuracy reached a high level of 94.24%. By incorporating a support vector machine (SVM) classifier into this method, we managed to enhance this accuracy to the outstanding level of 98.92%, thus outperforming the existing state-of-the-art methods that were evaluated using the same UCSD dataset, furthermore, the execution time was optimized.","2024-10","2025-02-26 20:41:50","2025-02-26 20:41:50","","544-554","","5","58","","","","","","","","","","English","","","","WOS:001348907800005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","deep learning; macroscopic approach; nighttime road traffic classification; support vector machine (SVM); vision transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B9WAQA3L","journalArticle","2025","Chen, JD; Wang, Y; Zeb, A; Suzauddola, MD; Wen, YX; Alzheimers Dis Neuroimaging Initiative","Multimodal mixing convolutional neural network and transformer for Alzheimer's disease recognition","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.125321","","Early recognition of Alzheimer's disease (AD) and its precursor state, mild cognitive impairment (MCI), is pivotal in interrupting the progression of the disease and providing suitable treatment. Recent development in deep learning techniques has drawn great research attention for improving the efficacy of AD recognition. However, numerous current methods solely utilize data from a single auxiliary domain, limiting their ability to harness valuable intrinsic insights from multiple domains. To cope with the challenge, this paper is devoted to establishing an innovative multimodal medical data fusion model, termed as MMDF, to perform Alzheimer's disease recognition. Multimodal data including clinical records and medical images are used by the proposed approach, and backbone models are constructed using various data modalities. Specifically, a vision transformer model, which is termed as MRI_ViT, is tailored to recognize AD using brain magnetic resonance imaging (MRI) data. In parallel, a novel multi-scale attention-embedded one-dimensional (1D) convolutional neural network (MA-1DCNN) is devised for analyzing clinical records. Subsequently, these basic models are combined for creating a new data fusion model to recognize Alzheimer's disease. The experimental results reveal outstanding performance compared with state-of-the-art (SOTA) methods.","2025-01-01","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","259","","","","","","","","","","English","","","","WOS:001315913600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Alzheimer's disease recognition; CNN; Data fusion; MRI; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LBLBH79W","journalArticle","2024","Madni, HA; Umer, RM; Foresti, GL","Exploiting data diversity in multi-domain federated learning","MACHINE LEARNING-SCIENCE AND TECHNOLOGY","","2632-2153","10.1088/2632-2153/ad4768","","Federated learning (FL) is an evolving machine learning technique that allows collaborative model training without sharing the original data among participants. In real-world scenarios, data residing at multiple clients are often heterogeneous in terms of different resolutions, magnifications, scanners, or imaging protocols, and thus challenging for global FL model convergence in collaborative training. Most of the existing FL methods consider data heterogeneity within one domain by assuming same data variation in each client site. In this paper, we consider data heterogeneity in FL with different domains of heterogeneous data by raising the problems of domain-shift, class-imbalance, and missing data. We propose a method, multi-domain FL as a solution to heterogeneous training data from multiple domains by training robust vision transformer model. We use two loss functions, one for correctly predicting class labels and other for encouraging similarity and dissimilarity over latent features, to optimize the global FL model. We perform various experiments using different convolution-based networks and non-convolutional Transformer architectures on multi-domain datasets. We evaluate the proposed approach on benchmark datasets and compare with the existing FL methods. Our results show the superiority of the proposed approach which performs better in term of robust FL global model than the exiting methods.","2024-06-01","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","2","5","","","","","","","","","","English","","","","WOS:001224155100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;95</p>","","","class-imbalance; data heterogeneity; domain-shift; federated learning; multi-domain data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LS3K26U5","journalArticle","2024","Zhang, LN; Wang, KY; Wan, Y","An Efficient Transformer-CNN Network for Document Image Binarization","ELECTRONICS","","2079-9292","10.3390/electronics13122243","","Color image binarization plays a pivotal role in image preprocessing work and significantly impacts subsequent tasks, particularly for text recognition. This paper concentrates on document image binarization (DIB), which aims to separate an image into a foreground (text) and background (non-text content). We thoroughly analyze conventional and deep-learning-based approaches and conclude that prevailing DIB methods leverage deep learning technology. Furthermore, we explore the receptive fields of pre- and post-network training to underscore the Transformer model's advantages. Subsequently, we introduce a lightweight model based on the U-Net structure and enhanced with the MobileViT module to capture global information features in document images better. Given its adeptness at learning both local and global features, our proposed model demonstrates competitive performance on two standard datasets (DIBCO2012 and DIBCO2017) and good robustness on the DIBCO2019 dataset. Notably, our proposed method presents a straightforward end-to-end model devoid of additional image preprocessing or post-processing, eschewing the use of ensemble models. Moreover, its parameter count is less than one-eighth of the model, which achieves the best results on most DIBCO datasets. Finally, two sets of ablation experiments are conducted to verify the effectiveness of the proposed binarization model.","2024-06","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","12","13","","","","","","","","","","English","","","","WOS:001255729100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;88</p>","","","ALGORITHM; COMPETITION; document image binarization; MobileViT; TEXT; THRESHOLD SELECTION METHOD; transformer; U-Net","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H3QDKN92","journalArticle","2024","Zhao, F; Ai, Q; Li, XN; Wang, WH; Gao, QY; Liu, YC","TLC-XML: Transformer with Label Correlation for Extreme Multi-label Text Classification","NEURAL PROCESSING LETTERS","","1370-4621","10.1007/s11063-024-11460-z","","Extreme multi-label text classification (XMTC) annotates related labels for unknown text from large-scale label sets. Transformer-based methods have become the dominant approach for solving the XMTC task due to their effective text representation capabilities. However, the existing Transformer-based methods fail to effectively exploit the correlation between labels in the XMTC task. To address this shortcoming, we propose a novel model called TLC-XML, i.e., a Transformer with label correlation for extreme multi-label text classification. TLC-XML comprises three modules: Partition, Matcher and Ranker. In the Partition module, we exploit the semantic and co-occurrence information of labels to construct the label correlation graph, and further partition the strongly correlated labels into the same cluster. In the Matcher module, we propose cluster correlation learning, which uses the graph convolutional network (GCN) to extract the correlation between clusters. We then introduce these valuable correlations into the classifier to match related clusters. In the Ranker module, we propose label interaction learning, which aggregates the raw label prediction with the information of the neighboring labels. The experimental results on benchmark datasets show that TLC-XML significantly outperforms state-of-the-art XMTC methods.","2024-02-10","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","1","56","","","","","","","","","","English","","","","WOS:001162597000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Extreme multi-label text classification; Graph convolutional network; Label correlation; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IJFEUN46","journalArticle","2024","Yang, J; Wei, P; Ren, ZY; Zheng, NN","Gated Multi-Scale Transformer for Temporal Action Localization","IEEE TRANSACTIONS ON MULTIMEDIA","","1520-9210","10.1109/TMM.2023.3338082","","Temporal action localization (TAL) is a critical task in video understanding. Effectively utilizing multi-scale information and handling interactions across various scales have consistently posed challenging issues within the realm of TAL. In this article, we propose a novel gated multi-scale Transformer model (TransGMC) for temporal action localization. A gated control mechanism is designed to filter and aggregate the information at different scales, by which the contributions of contexts at different temporal scales are well characterized. To enhance the feature representation at each temporal scale, the rich global-local contexts are extracted at each temporal scale. A cascade attention module that contains two seamlessly integrated channel attention and moment attention is proposed for capturing global temporal contexts. We utilize a new regression loss function for locating the time boundaries. We conducted experiments on four challenging benchmark datasets, including two third-person view datasets and two first-person view datasets. Our method achieves an average mAP of 67.5% on THUMOS14, 36.1% on ActivityNet v1.3, 24.9% on EPIC-Kitchens 100, and 23.2% on Ego4D, which all outperform the previous state-of-the-arts methods. Extensive ablation studies also validate the effectiveness of the proposed method.","2024","2025-02-26 20:41:50","2025-02-26 20:41:50","","5705-5717","","","26","","","","","","","","","","English","","","","WOS:001197874100010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","gated control mechanism; multi-scale transformer; NETWORK; Temporal action localization; video understanding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TW7KPNL8","journalArticle","2024","Zarski, M; Miszczak, JA","Multi-Step Feature Fusion for Natural Disaster Damage Assessment on Satellite Images","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3459424","","Quick and accurate assessment of the damage state of buildings after natural disasters is crucial for undertaking properly targeted rescue and subsequent recovery operations, which can have a major impact on the safety of victims and the cost of disaster recovery. The quality of such a process can be significantly improved by harnessing the potential of machine learning methods in computer vision. This paper presents a novel damage assessment method using an original multi-step feature fusion network for the classification of the damage state of buildings based on pre- and post-disaster large-scale satellite images. We introduce a novel convolutional neural network (CNN) module that performs feature fusion at multiple network levels between pre- and post-disaster images in the horizontal and vertical directions of CNN network. An additional network element - Fuse Module - was proposed to adapt any CNN model to analyze image pairs in the issue of pair classification. We use, open, large-scale datasets (IDA-BD and xView2) to verify, that the proposed method is suitable to improve on existing state-of-the-art architectures. We report over a 3 percentage point increase in the accuracy of the Vision Transformer model.","2024","2025-02-26 20:41:50","2025-02-26 20:41:50","","140072-140081","","","12","","","","","","","","","","English","","","","WOS:001328983600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","Buildings; CNN; Computer vision; damage state assessment; Disasters; Feature extraction; Fuses; machine learning; Machine learning; PREDICTION; remote sensing; Remote sensing; Satellite images; Satellites; TIME-SERIES; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"65TV2RX3","journalArticle","2023","Zheng, WF; Gong, G; Tian, JW; Lu, SY; Wang, RY; Yin, ZT; Li, XL; Yin, LR","Design of a Modified Transformer Architecture Based on Relative Position Coding","INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS","","1875-6891","10.1007/s44196-023-00345-z","","Natural language processing (NLP) based on deep learning provides a positive performance for generative dialogue system, and the transformer model is a new boost in NLP after the advent of word vectors. In this paper, a Chinese generative dialogue system based on transformer is designed, which only uses a multi-layer transformer decoder to build the system and uses the design of an incomplete mask to realize one-way language generation. That is, questions can perceive context information in both directions, while reply sentences can only output one-way autoregressive. The above system improvements make the one-way generation of dialogue tasks more logical and reasonable, and the performance is better than the traditional dialogue system scheme. In consideration of the long-distance information weakness of absolute position coding, we put forward the improvement of relative position coding in theory, and verify it in subsequent experiments. In the transformer module, the calculation formula of self-attention is modified, and the relative position information is added to replace the absolute position coding of the position embedding layer. The performance of the modified model in BLEU, embedding average, grammatical and semantic coherence is ideal, to enhance long-distance attention.","2023-10-23","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","1","16","","","","","","","","","","English","","","","WOS:001090903600002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;58<br/>Total Times Cited:&nbsp;&nbsp;58<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","ATTENTION; Attention mechanism; LSTM; Natural language processing; Relative position embedding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2UNBN3F5","journalArticle","2023","Zang, CB; Turkcan, MK; Narasimhan, S; Cao, YQ; Yarali, K; Xiang, ZX; Szot, S; Ahmad, F; Choksi, S; Bitner, DP; Filicori, F; Kostic, Z","Surgical Phase Recognition in Inguinal Hernia Repair-AI-Based Confirmatory Baseline and Exploration of Competitive Models","BIOENGINEERING-BASEL","","2306-5354","10.3390/bioengineering10060654","","Video-recorded robotic-assisted surgeries allow the use of automated computer vision and artificial intelligence/deep learning methods for quality assessment and workflow analysis in surgical phase recognition. We considered a dataset of 209 videos of robotic-assisted laparoscopic inguinal hernia repair (RALIHR) collected from 8 surgeons, defined rigorous ground-truth annotation rules, then pre-processed and annotated the videos. We deployed seven deep learning models to establish the baseline accuracy for surgical phase recognition and explored four advanced architectures. For rapid execution of the studies, we initially engaged three dozen MS-level engineering students in a competitive classroom setting, followed by focused research. We unified the data processing pipeline in a confirmatory study, and explored a number of scenarios which differ in how the DL networks were trained and evaluated. For the scenario with 21 validation videos of all surgeons, the Video Swin Transformer model achieved similar to 0.85 validation accuracy, and the Perceiver IO model achieved similar to 0.84. Our studies affirm the necessity of close collaborative research between medical experts and engineers for developing automated surgical phase recognition models deployable in clinical settings.","2023-06","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","6","10","","","","","","","","","","English","","","","WOS:001016927700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","AI; computer vision; convolutional neural network; deep learning; inguinal hernia repair; robotic-assisted laparoscopic surgery; surgical phase recognition; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R2IXBMXL","journalArticle","2025","Liu, JR; Hao, RJ; Deng, FY; Fan, HL; Lou, HY","A gearbox fault diagnosis method based on Swin Transformer and Markov transform fields","ENGINEERING RESEARCH EXPRESS","","2631-8695","10.1088/2631-8695/ada71f","","To address the problems of traditional fault diagnosis methods, such as the insensitivity of fault feature extraction, strong dependence on expert experience, insufficient generalization, and low fault recognition rate in gearbox running state detection, a gearbox fault diagnosis method based on the Markov transition field (MTF) and a Swin Transformer is proposed. First, the original one-dimensional vibration signal dataset is preprocessed. then the one-dimensional vibration signal is encoded into a two-dimensional feature map by MTF, which preserves the correlation between data and time. Second, the encoded 2D feature image dataset was input into the Swin Transformer model with a moving window and hierarchical design structure for training to realize the recognition of different faults in the gearbox. Finally, the power transmission fault diagnosis test-bed (DDS) dataset was used for experimental verification, and the fault diagnosis accuracy rate was 99.69%. Experimental results show that the proposed method has higher computational efficiency, better generalization performance, and higher fault identification accuracy than the intelligent diagnosis model based on a time-frequency diagram, CWT diagram, GAF diagram, convolutional neural network (CNN), and Vision Transformer (Vi T), which can provide a reference for fault diagnosis of gearboxes in practical industries.","2025-03-31","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","1","7","","","","","","","","","","English","","","","WOS:001400641700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","attention mechanism; fault diagnosis; Gearbox; Markov transfer Field (MTF); MODE DECOMPOSITION; ROLLING ELEMENT BEARING; Swin Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TJRQW8CB","journalArticle","2024","Pelletier, MG; Wanjura, JD; Holt, GA","Vision-Transformer Model Validation Image Dataset","AGRIENGINEERING","","2624-7402","10.3390/agriengineering6040254","","The removal of plastic contamination from cotton lint is a critical issue for the U.S. cotton industry. One primary source of this contamination is the plastic wrap used on cotton modules by John Deere round module harvesters. Despite rigorous efforts by cotton ginning personnel to eliminate plastic during module unwrapping, fragments still enter the gin's processing system. To address this, we developed a machine-vision detection and removal system using low-cost color cameras to identify and expel plastic from the gin-stand feeder apron, preventing contamination. However, the system, comprising 30-50 ARM computers running Linux, poses significant challenges in terms of calibration and tuning, requiring extensive technical knowledge. This research aims to transform the system into a plug-and-play appliance by incorporating an auto-calibration algorithm that dynamically tracks cotton colors and excludes plastic images to maintain calibration integrity. We present the image dataset that was used to validate the design, consisting of several key AI Vision-Transformer image classifiers that form the heart of the auto-calibration algorithm, which is expected to reduce setup and operational overhead significantly. The auto-calibration feature will minimize the need for skilled personnel, facilitating the broader adoption of the plastic removal system in the cotton ginning industry.","2024-12","2025-02-26 20:41:50","2025-02-26 20:41:50","","4476-4479","","4","6","","","","","","","","","","English","","","","WOS:001384087000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;9</p>","","","automated inspection; cotton; INSPECTION; machine-vision; plastic contamination","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZMMJ8USP","journalArticle","2024","Liu, XX; Zhao, Y; Wang, SG; Wei, J","TransDiff: medical image segmentation method based on Swin Transformer with diffusion probabilistic model","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-024-05496-w","","Medical image segmentation can provide a reliable basis for clinical analysis and diagnosis. However, this task is challenging due to the low contrast, boundary ambiguity between organs or lesions and surrounding tissues, and noise interference of images. To address this challenge, which is unique to medical images, and further improve the segmentation accuracy and precision, a medical image segmentation model (TransDiff) is proposed from the perspective of improving model robustness and enriching semantic information. TransDiff comprises three parts: a variational autoencoder (VAE), a diffusion transformer model and a Swin Transformer. The VAE constructs a latent space to provide an environment for fully extracting and fusing features. The diffusion model predicts and removes noise by inferring semantics through the propagation of information between nodes. The Swin Transformer enriches discriminative features as a conditional part. TransDiff inherits the robustness to noise and missing data of the diffusion model and the feature enrichment of the Swin Transformer, thus exhibiting a higher understanding of semantic information. It performs well on medical datasets with three different image modalities, outperforms existing medical image segmentation methods in terms of segmentation precision and accuracy, and has good generalizability. The codes and trained models will be publicly available at https://github.com/xiaoxiao1997/TransDiff.","2024-04","2025-02-26 20:41:50","2025-02-26 20:41:50","","6543-6557","","8","54","","","","","","","","","","English","","","","WOS:001226679600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Deep learning; Diffusion probabilistic model; Medical image segmentation; Transformer; Variational autoencoder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DJ9DCGPD","journalArticle","2024","Fan, WF; He, Y; Zhu, F","RM-GPT: Enhance the comprehensive generative ability of molecular GPT model via LocalRNN and RealFormer","ARTIFICIAL INTELLIGENCE IN MEDICINE","","0933-3657","10.1016/j.artmed.2024.102827","","Due to the surging of cost, artificial intelligence -assisted de novo drug design has supplanted conventional methods and become an emerging option for drug discovery. Although there have arisen many successful examples of applying generative models to the molecular field, these methods struggle to deal with conditional generation that meet chemists' practical requirements which ask for a controllable process to generate new molecules or optimize basic molecules with appointed conditions. To address this problem, a Recurrent Molecular -Generative Pretrained Transformer model is proposed, supplemented by LocalRNN and Residual Attention Layer Transformer, referred to as RM-GPT. RM-GPT rebuilds GPT model's architecture by incorporating LocalRNN and Residual Attention Layer Transformer so that it is able to extract local information and build connectivity between attention blocks. The incorporation of Transformer in these two modules enables leveraging the parallel computing advantages of multi -head attention mechanisms while extracting local structural information effectively. Through exploring and learning in a large chemical space, RM-GPT absorbs the ability to generate drug -like molecules with conditions in demand, such as desired properties and scaffolds, precisely and stably. RM-GPT achieved better results than SOTA methods on conditional generation.","2024-04","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","150","","","","","","","","","","English","","","","WOS:001209257400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","De novo drug design; Generative pre-training model; Molecular generation; Recurrent neural networks; Residual attention mechanism; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7QGNFWPS","journalArticle","2023","Huang, Y; Huang, JB; Chen, XP; He, KN; Zhou, XC","BCGen: a comment generation method for bytecode","AUTOMATED SOFTWARE ENGINEERING","","0928-8910","10.1007/s10515-022-00374-6","","Bytecode is a form of instruction set designed for efficient execution by a software interpreter. Unlike human-readable source code, bytecode is even harder to understand for programmers and researchers. Bytecode has been widely used in various software tasks such as malware detection and clone detection. In order to understand the meaning of the bytecode more quickly and accurately and further help programmers in more software activities, we propose a bytecode comment generation method (called BCGen) using neural language model. Specifically, to get the structured information of the bytecode, we first generate the control flow graph (CFG) of the bytecode, and serialize the CFG with bytecode semantic information. Then a transformer model combining gate recurrent unit is proposed to learn the features of bytecode to generate comments. We obtain the bytecode by building the Jar packages of the well-known open-source projects in the Maven repository and construct a bytecode dataset to train and evaluate our model. Experimental results show that the BLEU of BCGen can reach 0.26, which outperforms several baselines and proves the effectiveness and practicability of our method. It is concluded that it is possible to generate natural language comments directly from the bytecode. Meanwhile, it is important to take structured and semantic information into account in generating bytecode comments.","2023-06","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","1","30","","","","","","","","","","English","","","","WOS:000896453200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Bytecode; Comments generation; Control flow graph; Program comprehension","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YKFHL2KZ","journalArticle","2024","Ding, H; Zhang, XF; Lu, WH; Yuan, FN; Luo, HX","MMAformer: Multiscale Modality-Aware Transformer for Medical Image Segmentation","ELECTRONICS","","2079-9292","10.3390/electronics13234636","","The segmentation of medical images, particularly for brain tumors, is essential for clinical diagnosis and treatment planning. In this study, we proposed MMAformer, a Multiscale Modality-Aware Transformer model, which is designed for segmenting brain tumors by utilizing multimodality magnetic resonance imaging (MRI). Complementary information between different sequences helps the model delineate tumor boundaries and distinguish different tumor tissues. To enable the model to acquire the complementary information between related sequences, MMAformer employs a multistage encoder, which uses a cross-modal downsampling (CMD) block for learning and integrating the complementary information between sequences at different scales. In order to effectively fuse the various information extracted by the encoder, the Multimodal Gated Aggregation (MGA) block combines the dual attention mechanism and multi-gated clustering to effectively fuse the spatial, channel, and modal features of different MRI sequences. In the comparison experiments on the BraTS2020 and BraTS2021 datasets, the average Dice score of MMAformer reached 86.3% and 91.53%, respectively, indicating that MMAformer surpasses the current state-of-the-art approaches. MMAformer's innovative architecture, which effectively captures and integrates multimodal information at various scales, offers a promising solution for tackling complex medical image segmentation challenges.","2024-12","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","23","13","","","","","","","","","","English","","","","WOS:001377736700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","brain tumor segmentation; cross-modal downsampling; multimodal gated aggregation; multimodality; multiscale; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VCRKJIES","journalArticle","2024","Isomura, T; Shimizu, R; Coto, M","Optimizing FT-Transformer: Sparse Attention for Improved Performance and Interpretability","INDUSTRIAL ENGINEERING AND MANAGEMENT SYSTEMS","","1598-7248","10.7232/iems.2024.23.2.253","","In recent studies, a class of deep learning models has been suggested to provide higher prediction accuracy for tabular data than gradient boosting algorithms, the current mainstream approach for such structured data. In particular, the effectiveness of FT-Transformer (FTT), which customizes the transformer model to tabular data, has been shown in recent research. Transformer was initially proposed for unstructured data and have shown high performance by sensitively considering the relationships between all features (e.g., words and patch images) through the attention mechanism. However, the relationships between input variables (features) and an output variable in tabular data can be assumed less complex than those in unstructured data. Therefore, we propose FTT+, an improved FTT suitable for tabular data that improves performance by not excessively considering the unnecessary relationship between features in the transformer's attention mechanism. In addition, we expand FTT+ as a strong explainable model by taking a novel approach based on the transfer learning method. The effectiveness and interpretability of our proposals are clarified through evaluation experiments on regression, binary classification, multi-level classification tasks, and multiple analyses of these results. With this study's contribution, the proposed models could be suggested as the new standard for all tasks using tabular data.","2024-06","2025-02-26 20:41:50","2025-02-26 20:41:50","","253-266","","2","23","","","","","","","","","","English","","","","WOS:001327179300009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Attention Mechanism; Deep Neural Network; Explainable AI; Tabular Data; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BTGQ3HBN","journalArticle","2024","Ahmad, I; Amin, J; Lali, MI; Abbas, F; Sharif, MI","A novel Deeplabv3+and vision-based transformer model for segmentation and classification of skin lesions","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2024.106084","","Skin cancer (SC) is a common disease caused due to ultraviolet radiation. Accurate SC detection is degraded due to some artifacts such as lesion variations in shape, size, color, texture, hairs, poor contrast, brightness, and irregular lesion boundaries. To solve these limitations, a deep learning-based technique is proposed that consists of segmentation and classification of SC. The DeepLabv3+ segmentation model is designed that consist of 9 convolutional neural network blocks. Each block comprises 19 convolution, 18 rectified linear units, and 18 batch normalization layers. The model is evaluated on ISIC-16, 17, 18, and PH2 datasets that provide accuracy of 98.90 %, 98.38 %, 99.45 %, and 100 %, respectively. Another Vision Transformer (ViT) model is developed for the classification of skin lesions (SL). The ViT model performs better than CNN because ViT works as a token while CNN works pixel to pixel. The ViT model consists of eight blocks, each with 17 normalization, 8 multi-head attention, 19 dense, and 19 dropout layers with a 7x7 patch size. The model is evaluated on PH2, ISIC-19, ISIC20, and HAM10000 datasets that provided an accuracy of 100 %, 96.97 %, 97.73 %, and 100 % respectively. The results are better than existing methods.","2024-06","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","92","","","","","","","","","","English","","","","WOS:001187671000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","Deeplabv3+; Dermoscopy; DIAGNOSIS; FEATURES FUSION; LOCALIZATION; Patch; Skin Lesions; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H3CZYUPD","journalArticle","2024","Hájek, A; Horák, A","CzeGPT-2-Training New Model for Czech Generative Text Processing Evaluated With the Summarization Task","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3371689","","Automatic text summarization (ATS), alongside neural machine translation or question answering, is one of the leading tasks in Natural Language Processing (NLP). In recent years, ATS has experienced significant development, especially in the English NLP world. Modern approaches are mainly based on the versatile Transformer architecture proposed by Vaswani et al. in 2017, which has revolutionized the field, and was later tuned and adjusted to various needs of different tasks. Non-mainstream languages, with Czech taken as a representative, on the other hand, are a little bit behind these efforts and tend to use lighter or heuristic methods. With the new CzeGPT-2 model and abstractive summarizer, we would like to take a step forward detailing the process of training a GPT-2 generative transformer model for a new language with a comprehensive evaluation of the task of Czech summarization and pointing out the benefits of this approach. We also present an in-depth analysis of the errors in generated summaries, allowing to locate the model's weak spots.","2024","2025-02-26 20:41:50","2025-02-26 20:41:50","","34570-34581","","","12","","","","","","","","","","English","","","","WOS:001178339600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Computational modeling; Czech; Decoding; GPT-2; large language model; Measurement; model evaluation; model training; Modeling; Natural language processing; Performance evaluation; Question answering (information retrieval); summarization; Task analysis; Text analysis; Text recognition; Training; Transformers; Vocabulary","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DNN5S2LN","journalArticle","2023","Yang, ZZ; Hsu, YC; Buehler, MJ","Generative multiscale analysis of de novo proteome-inspired molecular structures and nanomechanical optimization using a VoxelPerceiver transformer model","JOURNAL OF THE MECHANICS AND PHYSICS OF SOLIDS","","0022-5096","10.1016/j.jmps.2022.105098","","We report a method to generate de novo protein designs through a generative adversarial neural network, MolShapeGAN, that can rapidly produce a large variety of nanoarchitected material designs inspired by proteins. The proteomic molecular designs generated by MolShapeGAN model are examined using LAMMPS coarse-grained simulations by applying tensile deformation to the longest axis of each structure, to assess mechanical properties. In order to facilitate nano -mechanical optimization, we develop a transformer neural network, denoted as VoxelPerceiver, that predicts mechanical properties directly from the molecular architecture in an end-to-end fashion. The assessment of key nanomechanical properties, such as maximum tensile stress, Von Mises stress mean, and Von Mises standard deviation, offer a materiomic design paradigm by which tailored nanomechanical properties can be achieved, and by which important insights can be gained about the particularities of nanomechanical responses of molecular structures. Opti-mization to achieve desired mechanical properties is performed both using a brute-force grid search and Bayesian optimization. We also report manufactured samples of scaled-up architected models of the protein designs using 3D printing.","2023-01","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","170","","","","","","","","","","English","","","","WOS:000878848000007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;91</p>","","","Adversarial; Attention models; Bayesian optimization; Biomaterials; Category theory; Deep learning; DESIGN; DYNAMICS; FINGERPRINT SIMILARITY SEARCH; GAN; Generative design; Materiomics; Mechanics; MESH GENERATION; Natural language processing; PREDICTION; Proteins; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VGZDM62L","journalArticle","2023","Jordao, A; Souza, JPD; Kuroda, MC; Rezende, MFD; Pedrini, H; Vidal, AC","Towards automatic and accurate core-log processing","JOURNAL OF APPLIED GEOPHYSICS","","0926-9851","10.1016/j.jappgeo.2023.104990","","The analysis of rocks plays an important role in geological and petroleum-engineering problems. In these tasks, core (i.e., core-log) is a crucial element since it provides underlying information on the geophysical properties of the area. Thereby, works often leverage core data to assign the correct category from well-logs. Unfortunately, processing core is laborious and time-consuming; hence, its analysis takes long periods. For example, for a single well, a human could have to adjust thousands of core data. Besides, due to its nature, log analysis must handle noise and missing data. Given these issues, our goal is to propose an automatic (e.g., without any human intervention) and accurate core processing using the gamma-ray. To achieve this goal and additionally demonstrate the most promising pattern recognition strategies, we assess the effectiveness of several models to diagnostic the core-log. Such models include simple regressions, ensembles, gradient boosting, recurrence models and the relatively recent Transformer network. Our comprehensive evaluation is different from existing works on geoscience tasks, which evaluate a small number of models or variations of a single model. Particularly, we evaluate more than 200 unique models (i.e., models with different hyperparameters) and observe that deep learning techniques outperform other techniques by a large margin. Furthermore, we compare the compromise between predictive ability and computational cost of several models - a reliable information for real-time li-thology, which is often overlooked by previous works. According to our results, we can effectively replace the manual (i.e., by a human expert - geologist) diagnostic of core by pattern recognition methods, mainly by the Transformer model, as it aligns the cores in accordance (i.e., in the same direction) with the geologist. More specifically, given the core and gamma-ray as input, the Transformer model outputs an adjusted core obtaining an R2 of 93,63, which indicates a fine-grained adjustment. We empirically demonstrate that the success behind Transform is its effectiveness in expressing large sequences of core and well-log. On the other hand, other models such as RNN, LSTM and GRU meet collapse when processing large sequences of core-log. We further confirm that Transformers are among the top-performance models and often surpass recurrence models on several geoscience applications such as lithology and log-shape classification, and prediction of oil production. Regarding the first task, the models successfully classify different facies categories such as coarse sandstone, medium sandstone, fine sandstone, siltstone, dolomite, limestone and mudstone. In these tasks, Transformer outperforms the widely-employed LSTM by up to 14 percentage points. Our empirical observations encourage the exploration of mul-tiple models and suggest Transformers as strong baselines for future research on geoscience tasks. In this di-rection, we release all data and trained models used throughout the work. To the best of our knowledge, we are the first study exploring Transformer models on geoscience applications.","2023-05","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","212","","","","","","","","","","English","","","","WOS:000972621400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Core-log processing; FACIES CLASSIFICATION; LITHOLOGY; Machine learning; Recurrence models; Transformer network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MM75J9HB","journalArticle","2024","Kang, SB; Kim, SG; Lee, SH; Im, TH","A Study on the Automation of Fish Species Recognition and Body Length Measurement System","FISHES","","2410-3888","10.3390/fishes9090349","","The rapid depletion of fishery resources has led to the global implementation of Total Allowable Catch (TAC) systems. However, the current manual survey methods employed by land-based inspectors show limitations in accuracy and efficiency. This study proposes an automated system for fish species recognition and body length measurement, utilizing the RT-DETR (Real-Time Detection Transformer) model and ARCore technology to address these issues. The proposed system employs smartphone Time of Flight (ToF) functionality to measure object distance and automatically calculates the weight of 11 TAC-managed fish species by measuring their body length and height. Experimental results reveal that the RT-DETR-x model outperformed the YOLOv8x model by achieving an average mAP50 value 2.3% higher, with a mean recognition accuracy of 96.5% across the 11 species. Furthermore, the ARCore-based length measurement technique exhibited over 95% accuracy for all species. This system is expected to minimize data omissions and streamline labor-intensive processes, thereby contributing to the efficient operation of the TAC system and sustainable management of fishery resources. The study presents an innovative approach that significantly enhances the accuracy and efficiency of fishery resource management, providing a crucial technological foundation for the advancement of future fisheries management policies.","2024-09","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","9","9","","","","","","","","","","English","","","","WOS:001323792400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","ARCore; automated length measurement; fish species recognition; FISHERIES; RT-DETR; TAC; TAC SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UPT6QQX2","journalArticle","2024","Zaman, F; Kamiran, F; Shardlow, M; Saeed-Ul Hassan; Karim, A; Aljohani, NR","SATS: simplification aware text summarization of scientific documents","FRONTIERS IN ARTIFICIAL INTELLIGENCE","","2624-8212","10.3389/frai.2024.1375419","","Simplifying summaries of scholarly publications has been a popular method for conveying scientific discoveries to a broader audience. While text summarization aims to shorten long documents, simplification seeks to reduce the complexity of a document. To accomplish these tasks collectively, there is a need to develop machine learning methods to shorten and simplify longer texts. This study presents a new Simplification Aware Text Summarization model (SATS) based on future n-gram prediction. The proposed SATS model extends ProphetNet, a text summarization model, by enhancing the objective function using a word frequency lexicon for simplification tasks. We have evaluated the performance of SATS on a recently published text summarization and simplification corpus consisting of 5,400 scientific article pairs. Our results in terms of automatic evaluation demonstrate that SATS outperforms state-of-the-art models for simplification, summarization, and joint simplification-summarization across two datasets on ROUGE, SARI, and CSS1. We also provide human evaluation of summaries generated by the SATS model. We evaluated 100 summaries from eight annotators for grammar, coherence, consistency, fluency, and simplicity. The average human judgment for all evaluated dimensions lies between 4.0 and 4.5 on a scale from 1 to 5 where 1 means low and 5 means high.","2024-07-10","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","7","","","","","","","","","","English","","","","WOS:001275010100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;99</p>","","","AGREEMENT; deep learning; scientific documents; simplification; summarization; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FUST49J6","journalArticle","2024","Lu, RY","A novel fault diagnosis method for imbalanced datasets based on MCNN-Transformer model in industrial processes","INTERNATIONAL JOURNAL OF ADAPTIVE CONTROL AND SIGNAL PROCESSING","","0890-6327","10.1002/acs.3817","","Fault diagnosis methods based on deep learning have been extensively applied to the fault classification of rolling bearings, yielding favorable results. However, many of these methods still have substantial room for improvement in practical industrial scenarios. This article addresses the issue of imbalanced fault data categories commonly encountered in real-world contexts and discusses the characteristics of long time series data in fault signals. To tackle these challenges, a model based on multi-scale convolutional neural networks and transformer (MCNNT) is proposed. First, in the data processing stage, a diffusion model is introduced to handle the problem of data imbalance. This model learns the distribution of minority samples and generates new samples. Second, the proposed model incorporates an attention mechanism, enabling it to capture the global information of the data during the feature learning stage and effectively utilize the relationships between preceding and subsequent elements in long sequential data. This allows the model to accurately focus on key features. Experimental results demonstrate the exceptional performance of the proposed method, which is capable of generating high-quality samples and providing a solution to address challenges in practical industrial scenarios. Consequently, the proposed method exhibits significant potential for further development.","2024-04-15","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","","","","","","","","","","","English","","","","WOS:001201945500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","attention mechanisms; deep learning; fault diagnosis; imbalanced dataset","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CSKUIXUI","journalArticle","2024","Shao, YQ; Zhou, KY; Zhang, LC","CSSNet: Cascaded spatial shift network for multi-organ segmentation","COMPUTERS IN BIOLOGY AND MEDICINE","","0010-4825","10.1016/j.compbiomed.2024.107955","","Multi-organ segmentation is vital for clinical diagnosis and treatment. Although CNN and its extensions are popular in organ segmentation, they suffer from the local receptive field. In contrast, MultiLayer-Perceptronbased models (e.g., MLP-Mixer) have a global receptive field. However, these MLP-based models employ fully connected layers with many parameters and tend to overfit on sample-deficient medical image datasets. Therefore, we propose a Cascaded Spatial Shift Network, CSSNet, for multi-organ segmentation. Specifically, we design a novel cascaded spatial shift block to reduce the number of model parameters and aggregate feature segments in a cascaded way for efficient and effective feature extraction. Then, we propose a feature refinement network to aggregate multi-scale features with location information, and enhance the multi-scale features along the channel and spatial axis to obtain a high-quality feature map. Finally, we employ a self-attention-based fusion strategy to focus on the discriminative feature information for better multi-organ segmentation performance. Experimental results on the Synapse (multiply organs) and LiTS (liver & tumor) datasets demonstrate that our CSSNet achieves promising segmentation performance compared with CNN, MLP, and Transformer models. The source code will be available at https://github.com/zkyseu/CSSNet.","2024-03","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","170","","","","","","","","","","English","","","","WOS:001164538200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","Multi-scale feature aggregation; Multilayer perceptron; NET; Organ segmentation; Self-attention; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5SU8FZPA","journalArticle","2023","Liu, SC; Fan, QC; Zhao, CJ; Li, SQ","RTAD: A Real-Time Animal Object Detection Model Based on a Large Selective Kernel and Channel Pruning","INFORMATION","","2078-2489","10.3390/info14100535","","Animal resources are significant to human survival and development and the ecosystem balance. Automated multi-animal object detection is critical in animal research and conservation and ecosystem monitoring. The objective is to design a model that mitigates the challenges posed by the large number of parameters and computations in existing animal object detection methods. We developed a backbone network with enhanced representative capabilities to pursue this goal. This network combines the foundational structure of the Transformer model with the Large Selective Kernel (LSK) module, known for its wide receptive field. To further reduce the number of parameters and computations, we incorporated a channel pruning technique based on Fisher information to eliminate channels of lower importance. With the help of the advantages of the above designs, a real-time animal object detection model based on a Large Selective Kernel and channel pruning (RTAD) was built. The model was evaluated using a public animal dataset, AP-10K, which included 50 annotated categories. The results demonstrated that our model has almost half the parameters of YOLOv8-s yet surpasses it by 6.2 AP. Our model provides a new solution for real-time animal object detection.","2023-10","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","10","14","","","","","","","","","","English","","","","WOS:001093532100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","channel pruning; LSK module; real-time animal object detection; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3LKMH4U8","journalArticle","2023","Abbas, F; Yasmin, M; Fayyaz, M; Asim, U","ViT-PGC: vision transformer for pedestrian gender classification on small-size dataset","PATTERN ANALYSIS AND APPLICATIONS","","1433-7541","10.1007/s10044-023-01196-2","","Pedestrian gender classification (PGC) is a key task in full-body-based pedestrian image analysis and has become an important area in applications like content-based image retrieval, visual surveillance, smart city, and demographic collection. In the last decade, convolutional neural networks (CNN) have appeared with great potential and with reliable choices for vision tasks, such as object classification, recognition, detection, etc. But CNN has a limited local receptive field that prevents them from learning information about the global context. In contrast, a vision transformer (ViT) is a better alternative to CNN because it utilizes a self-attention mechanism to attend to a different patch of an input image. In this work, generic and effective modules such as locality self-attention (LSA), and shifted patch tokenization (SPT)-based vision transformer model are explored for the PGC task. With the use of these modules in ViT, it is successfully able to learn from stretch even on small-size (SS) datasets and overcome the lack of locality inductive bias. Through extensive experimentation, we found that the proposed ViT model produced better results in terms of overall and mean accuracies. The better results confirm that ViT outperformed state-of-the-art (SOTA) PGC methods.","2023-11","2025-02-26 20:41:50","2025-02-26 20:41:50","","1805-1819","","4","26","","","","","","","","","","English","","","","WOS:001072279000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;88</p>","","","CONVOLUTIONAL NEURAL-NETWORK; Deep CNN models; LSA and SPT; Pedestrian gender classification; RECOGNITION; SS datasets; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WBWHGJX5","journalArticle","2023","Kim, JW; Chung, H; Jung, HY","Spectral Salt-and-Pepper Patch Masking for Self-Supervised Speech Representation Learning","MATHEMATICS","","2227-7390","10.3390/math11153418","","Recent advanced systems in the speech recognition domain use large Transformer neural networks that have been pretrained on massive speech data. General methods in the deep learning area have been frequently shared across various domains, and the Transformer model can also be used effectively across speech and image. In this paper, we introduce a novel masking method for self-supervised speech representation learning with salt-and-pepper (S & P) mask which is commonly used in computer vision. The proposed scheme includes consecutive quadrilateral-shaped S & P patches randomly contaminating the input speech spectrum. Furthermore, we modify the standard S & P mask to make it appropriate for the speech domain. In order to validate the effect of the proposed spectral S & P patch masking for the self-supervised representation learning approach, we conduct the pretraining and downstream experiments with two languages, English and Korean. To this end, we pretrain the speech representation model using each dataset and evaluate the pretrained models for feature extraction and fine-tuning performance on varying downstream tasks, respectively. The experimental outcomes clearly illustrate that the proposed spectral S & P patch masking is effective for various downstream tasks when combined with the conventional masking methods.","2023-08","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","15","11","","","","","","","","","","English","","","","WOS:001046276800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","NETWORK; salt-and-pepper masking; self-supervised learning; spectrum patch masking; speech representation learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MRYPIV8K","journalArticle","2023","Nasirpour, F; Heidary, A; Niasar, MG; Lekic, A; Popov, M","High-frequency transformer winding model with adequate protection","ELECTRIC POWER SYSTEMS RESEARCH","","0378-7796","10.1016/j.epsr.2023.109637","","High local electric field intensity in transformer windings originating from transient signals is one of the reasons for transformer failures. Due to the integration of renewable energy sources into the power grids and the increased number of transients, the likelihood of transformer catastrophic failure increases accordingly. Therefore, to ensure the reliable performance of transformers and associated power networks studying their behavior during these events is required. Accordingly, there is a need for accurate modeling of transformer windings capable of simulating electromagnetic transients. Using these models, it is possible to identify frequencies that can be dangerous to the transformer windings and to study different protection schemes. This paper aims to find an accurate analytical model of transformer winding validated by experimental measurements and to study the performance of the R-L protection device during the transient phenomena. The protection device is designed based on the winding model to introduce an impedance comparable to that of the transformer winding at critical frequencies where voltage amplification in the winding is significant. This approach ensures enhanced protection against potential transformer damage to the transformer. By using this protection scheme, the high inter-turn voltage originating from transient signals may be mitigated. At the same time, it does not affect the grid's performance during normal conditions.","2023-10","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","223","","","","","","","","","","English","","","","WOS:001027374200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;17</p>","","","High-frequency transformer model; Protection; Transformer; Transient signals","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E3HGZ5ZJ","journalArticle","2023","Liu, H; Shao, MW; Wang, C; Cao, FL","Image Super-Resolution Using a Simple Transformer Without Pretraining","NEURAL PROCESSING LETTERS","","1370-4621","10.1007/s11063-022-10948-w","","Vision Transformer (ViT) has attracted tremendous attention and achieved remarkable success on high-level visual tasks. However, ViT relies on costly pre-training on large external datasets and is strict in data and calculations, making it an obstacle to running on common equipment. To address this challenge, we propose a simple and efficient Transformer namely SRT tailored for the image super-resolution (SR) reconstruction task. It is trained on a single GPU card without large-scale pre-training. At the beginning of the whole model, we introduce a convolutional stem module instead of straightforward tokenization of raw input images for low-level feature extraction and steady training. In the main Transformer learning phase, we exploit an additional head-convolution to make up for the lack of information interaction in multi-head self-attention (MHSA). Then further to strengthen the spatial correlation of neighboring tokens in MLP, a locally-enhanced feed-forward layer is thus employed to promote local dependencies. In terms of the inefficiency of Transformer, a channel reduction strategy is presented in MHSA, which dramatically reduces the complexity and space resources. Experimental results demonstrate the proposed Transformer model can rival the current state-of-the-art methods with a single GPU card.","2023-04","2025-02-26 20:41:50","2025-02-26 20:41:50","","1479-1497","","2","55","","","","","","","","","","English","","","","WOS:000824545000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Convolutional neural networks; NETWORKS; Super-resolution; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YHR4H7E8","journalArticle","2024","Berto, RP; Bugler, H; Dias, G; Oliveira, M; Ueda, L; Dertkigil, S; Costa, PDP; Rittner, L; Merkofer, JP; van de Sande, DMJ; Amirrajab, S; Drenthen, GS; Veta, M; Jansen, JFA; Breeuwer, M; van Sloun, RJG; Qayyum, A; Rodero, C; Niederer, S; Souza, R; Harris, AD","Results of the 2023 ISBI challenge to reduce GABA-edited MRS acquisition time","MAGNETIC RESONANCE MATERIALS IN PHYSICS BIOLOGY AND MEDICINE","","1352-8661","10.1007/s10334-024-01156-9","","PurposeUse a conference challenge format to compare machine learning-based gamma-aminobutyric acid (GABA)-edited magnetic resonance spectroscopy (MRS) reconstruction models using one-quarter of the transients typically acquired during a complete scan.MethodsThere were three tracks: Track 1: simulated data, Track 2: identical acquisition parameters with in vivo data, and Track 3: different acquisition parameters with in vivo data. The mean squared error, signal-to-noise ratio, linewidth, and a proposed shape score metric were used to quantify model performance. Challenge organizers provided open access to a baseline model, simulated noise-free data, guides for adding synthetic noise, and in vivo data.ResultsThree submissions were compared. A covariance matrix convolutional neural network model was most successful for Track 1. A vision transformer model operating on a spectrogram data representation was most successful for Tracks 2 and 3. Deep learning (DL) reconstructions with 80 transients achieved equivalent or better SNR, linewidth and fit error compared to conventional 320 transient reconstructions. However, some DL models optimized linewidth and SNR without actually improving overall spectral quality, indicating a need for more robust metrics.ConclusionDL-based reconstruction pipelines have the promise to reduce the number of transients required for GABA-edited MRS.","2024-07","2025-02-26 20:41:50","2025-02-26 20:41:50","","449-463","","3","37","","","","","","","","","","English","","","","WOS:001201481000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","Benchmarking; Computer; Deep learning; GAMMA-AMINOBUTYRIC-ACID; Magnetic resonance spectroscopy; MAGNETIC-RESONANCE-SPECTROSCOPY; Neural networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X38UIXKM","journalArticle","2024","Qian, LP; Cong, L","Channel Features and API Frequency-Based Transformer Model for Malware Identification","SENSORS","","1424-8220","10.3390/s24020580","","Malicious software (malware), in various forms and variants, continues to pose significant threats to user information security. Researchers have identified the effectiveness of utilizing API call sequences to identify malware. However, the evasion techniques employed by malware, such as obfuscation and complex API call sequences, challenge existing detection methods. This research addresses this issue by introducing CAFTrans, a novel transformer-based model for malware detection. We enhance the traditional transformer encoder with a one-dimensional channel attention module (1D-CAM) to improve the correlation between API call vector features, thereby enhancing feature embedding. A word frequency reinforcement module is also implemented to refine API features by preserving low-frequency API features. To capture subtle relationships between APIs and achieve more accurate identification of features for different types of malware, we leverage convolutional neural networks (CNNs) and long short-term memory (LSTM) networks. Experimental results demonstrate the effectiveness of CAFTrans, achieving state-of-the-art performance on the mal-api-2019 dataset with an F1 score of 0.65252 and an AUC of 0.8913. The findings suggest that CAFTrans improves accuracy in distinguishing between various types of malware and exhibits enhanced recognition capabilities for unknown samples and adversarial attacks.","2024-01","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","2","24","","","","","","","","","","English","","","","WOS:001151282900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","API sequence; deep learning; dynamic analysis; malware identification; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L59LQEXN","journalArticle","2024","Rosso, MM; Aloisio, A; Randazzo, V; Tanzi, L; Cirrincione, G; Marano, GC","Comparative deep learning studies for indirect tunnel monitoring with and without Fourier pre-processing","INTEGRATED COMPUTER-AIDED ENGINEERING","","1069-2509","10.3233/ICA-230709","","In the last decades, the majority of the existing infrastructure heritage is approaching the end of its nominal design life mainly due to aging, deterioration, and degradation phenomena, threatening the safety levels of these strategic routes of communications. For civil engineers and researchers devoted to assessing and monitoring the structural health (SHM) of existing structures, the demand for innovative indirect non-destructive testing (NDT) methods aided with artificial intelligence (AI) is progressively spreading. In the present study, the authors analyzed the exertion of various deep learning models in order to increase the productivity of classifying ground penetrating radar (GPR) images for SHM purposes, especially focusing on road tunnel linings evaluations. Specifically, the authors presented a comparative study employing two convolutional models, i.e. the ResNet-50 and the EfficientNet-B0, and a recent transformer model, i.e. the Vision Transformer (ViT). Precisely, the authors evaluated the effects of training the models with or without pre-processed data through the bi-dimensional Fourier transform. Despite the theoretical advantages envisaged by adopting this kind of pre-processing technique on GPR images, the best classification performances have been still manifested by the classifiers trained without the Fourier pre-processing.","2024","2025-02-26 20:41:50","2025-02-26 20:41:50","","213-232","","2","31","","","","","","","","","","English","","","","WOS:001193379000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;96</p>","","","Convolutional neural networks; Fourier transforms; ground penetrating radar systems; NEURAL-NETWORK; nondestructive examination; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KKLE49ES","journalArticle","2023","Ahmed, M; Ouda, A; Abusharkh, M; Kohli, S; Rai, K","An Optimized Approach to Translate Technical Patents from English to Japanese Using Machine Translation Models","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13127126","","This paper addresses the challenges associated with machine translation of patents from English to Japanese. This translation poses unique difficulties due to their legal nature, distinguishing them from general Japanese-to-English translation. Furthermore, the complexities inherent in the Japanese language add an additional layer of intricacy to the development of effective translation models within this specific domain. Our approach encompasses a range of essential steps, including preprocessing, data preparation, expert feedback acquisition, and linguistic analysis. These steps collectively contribute to the enhancement of machine learning model performance. The experimental results, presented in this study, evaluate three prominent alternatives considered for the final step of the transformer model. Through our methodology, which incorporates a modified version of NLP-Model-III, we achieved outstanding performance for the given problem, attaining an impressive BLEU score of 46.8. Furthermore, significant improvements of up to three points on the BLEU score were observed through hyperparameter fine-tuning. This research also involved the development of a novel dataset consisting of meticulously collected patent document data. The findings of this study provide valuable insights and contribute to the advancement of Japanese patent translation methodologies.","2023-06","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","12","13","","","","","","","","","","English","","","","WOS:001014044500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","corpus-based translation; cross-lingual information retrieval; domain adaptation; language model fine-tuning; machine translation; natural language processing; neural machine translation; technical patents; translation quality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5ZC7Y7CM","journalArticle","2023","Shi, Y; Zhang, LZ","Modelling long- and short-term multi-dimensional patterns in predictive maintenance with accumulative attention","RELIABILITY ENGINEERING & SYSTEM SAFETY","","0951-8320","10.1016/j.ress.2023.109306","","Predictive Maintenance (PdM) plays a pivotal role in safety management by planning necessary maintenance in advance to avoid future serious breakdown. Predicting the Remaining useful life (RUL) based on historical running data is an important task in PdM. One challenge of this issue is to capture both the temporal and spatial complex patterns especially in ultra-long sequences. Recent studies have demonstrated the superiority of Transformer model in capturing long-term dependencies. However, in the research field of PdM, the canonical Transformer faces with difficulties to deploy due to its limited input length, neglect of local correlations, insensitivity to input pattern and high computational cost. To tackle this, a novel lightweight RUL prediction model called TCNASA integrating temporal convolution network (TCN), accumulative self-attention layer (ASA) and autoregressive component is proposed. It uses TCN firstly to capture local correlations, prunes the redundant short-term cases when matching pairs in attention layers, accumulates global patterns through stacked self-attention layers, and lastly integrates an autoregressive component to enhance the robustness. The experimental results on several real-world PdM datasets have verified the effectiveness and efficiency of the proposed TCNASA model.","2023-09","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","237","","","","","","","","","","English","","","","WOS:000998630900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Accumulative attention mechanism; Autoregressive; CONVOLUTIONAL NEURAL-NETWORK; FAULT-DIAGNOSIS; Multi-sensor time series; Predictive maintenance; RUL prediction; Self-attention mechanism; Temporal convolution network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z8CC74TQ","journalArticle","2022","Wang, D; Xie, WJ; Cai, YC; Liu, XP","A Fast and Effective Transformer for Human Pose Estimation","IEEE SIGNAL PROCESSING LETTERS","","1070-9908","10.1109/LSP.2022.3163678","","Most of the existing human pose estimation methods improve accuracy by constantly increasing computational resources. However, balancing the efficiency and efficacy of the model is the key to enhancing the real application value. In this work, we present a Fast and Effective Transformer model to ensure the efficiency and efficacy of the model, called FET. Specifically, the FET consists of three parts: Feature Extraction Module (FEM), Feature Interaction Module (FIM) and Feature Decode Module (FDM). The FEM is used to efficiently extract low-level features from input images. Unlike CNN-based strategies, the FIM enables our model to capture global dependencies by self-attention, thus improving the accuracy for human pose estimation. The FDM is a multistage way that gradually recovers the size of the features to obtain a higher-quality target heatmap. In addition, Feature Squeeze Attention is introduced in the FET to further improve the overall performance of our model. Extensive experiments show that our method is 1.7x and 7x faster than SimpleBaseline and HRNet-32, respectively, while achieving comparable or even better results with the most state-of-the-art methods on the COCO dataset and the MPII dataset.","2022","2025-02-26 20:41:50","2025-02-26 20:41:50","","992-996","","","29","","","","","","","","","","English","","","","WOS:000788996000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Computational modeling; computational resources; Convolution; Feature extraction; Field effect transistors; Finite element analysis; Human pose estimation; Pose estimation; transformer archi- tecture; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4NQRGS2I","journalArticle","2024","Haque, ST; Debnath, M; Yasmin, A; Mahmud, T; Ngu, AHH","Experimental Study of Long Short-Term Memory and Transformer Models for Fall Detection on Smartwatches","SENSORS","","1424-8220","10.3390/s24196235","","Falls are the second leading cause of unintentional injury deaths worldwide. While numerous wearable fall detection devices incorporating AI models have been developed, none of them are used successfully in a fall detection application running on commodity-based smartwatches in real time. The system misses some falls, and generates an annoying amount of False Positives for practical use. We have investigated and experimented with an LSTM model for fall detection on a smartwatch. Even though the LSTM model has high accuracy during offline testing, the good performance of offline LSTM models cannot be translated to the equivalence of real-time performance. Transformers, on the other hand, can learn long-sequence data and patterns intrinsic to the data due to their self-attention mechanism. This paper compares three variants of LSTM and two variants of Transformer models for learning fall patterns. We trained all models using fall and activity data from three datasets, and the real-time testing of the model was performed using the SmartFall App. Our findings showed that in the offline training, the CNN-LSTM model was better than the Transformer model for all the datasets. However, the Transformer is a preferable choice for deployment in real-time fall detection applications.","2024-10","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","19","24","","","","","","","","","","English","","","","WOS:001332806700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","deep learning; fall detection; LSTM; transformers; wearables","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CPLG5GBQ","journalArticle","2024","Zhang, Q; Dong, YS; Zheng, YM; Yu, HY; Song, MP; Zhang, LF; Yuan, QQ","Three-Dimension Spatial-Spectral Attention Transformer for Hyperspectral Image Denoising","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2024.3458174","","Hyperspectral image (HSI) denoising is a crucial step for its subsequent applications. In this article, we propose TDSAT, a 3-D spatial-spectral attention Transformer model designed to effectively remove noise in HSI processing while preserving essential spectral and spatial information. The primary objective of this model is to utilize the 3-D Transformer to explore the global spectral-spatial features in HSI, learn the relationships among different bands, and preserve high-quality spectral and spatial information for denoising. The proposed method consists of three main components: the multihead spectral attention (MHSA) module, the gated-dconv feedforward network (GDFN) module, and the spectral enhancement (SpeE) module. The MHSA module learns the relationships among different bands and emphasizes the local spatial information. The GDFN module explores more expressive and discriminative spectral features. The SpeE module enhances the perception of subtle differences between different spectrums. Moreover, unlike the previous Transformer denoising method that can only handle fixed bands, the proposed method combines 3-D convolution and spectral-spatial attention Transformer blocks, enabling the denoising of HSI with an arbitrary number of bands. Experimental results demonstrate that TDSAT outperforms compared methods. The code is available at https://github.com/ Featherrain/TDSAT.","2024","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","62","","","","","","","","","","English","","","","WOS:001322218300011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","3-D; denoising; hyperspectral image (HSI); REMOVAL; spatial-spectral self-attention; THICK CLOUD; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KM92CZYN","journalArticle","2024","Liu, KH; Wang, J; Zhang, XJ","Debiased momentum contrastive learning for multimodal video similarity measures","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2023.126938","","The growing potential of multimodal short videos has contributed to a new type of recommendation. It depends on effectively measuring the similarities between the short video pairs, which consist of video frames and descriptions. Previous studies proposed using contrastive learning with in-batch negative sampling. However, such a strategy would take other semantically similar samples in the batch as negatives, leading to a biased issue. This paper proposes a debiased momentum contrastive learning (DMCL) on the unified multimodal Transformer model (VideoSim) for video similarity measures. The proposed DMCL alleviates the bias issue of negative sampling by introducing implicit knowledge of the model itself as soft labels. Instead of simply taking other samples in the batch as negatives, the proposed DMCL applies soft labels as supervision from the ground truth and the contextual semantic similarities between video-text pairs to alleviate the bias caused by negative sampling. In addition, DMCL expands the negative samples by a momentum queue strategy, which allows storing more multimodal representations to contrast more negatives. The experimental results of measuring multimodal video similarity show that the proposed DMCL outperforms all baselines in terms of Spearman's rank correlation. Ablation studies and extensive analysis further demonstrate the effectiveness of the proposed method.","2024-01-01","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","563","","","","","","","","","","English","","","","WOS:001104425300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Momentum contrastive learning; Multimodal video similarity measures; Negative sampling; United transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TTYP7LKQ","journalArticle","2023","Hinz, FB; Mahmoud, AH; Lill, MA","Prediction of molecular field points using SE(3)-transformer model","MACHINE LEARNING-SCIENCE AND TECHNOLOGY","","2632-2153","10.1088/2632-2153/ace67b","","Due to their computational efficiency, 2D fingerprints are typically used in similarity-based high-content screening. The interaction of a ligand with its target protein, however, relies on its physicochemical interactions in 3D space. Thus, ligands with different 2D scaffolds can bind to the same protein if these ligands share similar interaction patterns. Molecular fields can represent those interaction profiles. For efficiency, the extrema of those molecular fields, named field points, are used to quantify the ligand similarity in 3D. The calculation of field points involves the evaluation of the interaction energy between the ligand and a small probe shifted on a fine grid representing the molecular surface. These calculations are computationally prohibitive for large datasets of ligands, making field point representations of molecules intractable for high-content screening. Here, we overcome this roadblock by one-shot prediction of field points using generative neural networks based on the molecular structure alone. Field points are predicted by training an SE(3)-Transformer, an equivariant, attention-based graph neural network architecture, on a large set of ligands with field point data. Resulting data demonstrates the feasibility of this approach to precisely generate negative, positive and hydrophobic field points within 0.5 & ANGS; of the ground truth for a diverse set of drug-like molecules.","2023-09-01","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","3","4","","","","","","","","","","English","","","","WOS:001039397500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;13</p>","","","drug design; equivariance; field points; SE3 transformer; similarity; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"STZPRMIL","journalArticle","2023","Zhang, YS; Chen, L; Yuan, Y","Multimodal Fine-Grained Transformer Model for Pest Recognition","ELECTRONICS","","2079-9292","10.3390/electronics12122620","","Deep learning has shown great potential in smart agriculture, especially in the field of pest recognition. However, existing methods require large datasets and do not exploit the semantic associations between multimodal data. To address these problems, this paper proposes a multimodal fine-grained transformer (MMFGT) model, a novel pest recognition method that improves three aspects of transformer architecture to meet the needs of few-shot pest recognition. On the one hand, the MMFGT uses self-supervised learning to extend the transformer structure to extract target features using contrastive learning to reduce the reliance on data volume. On the other hand, fine-grained recognition is integrated into the MMFGT to focus attention on finely differentiated areas of pest images to improve recognition accuracy. In addition, the MMFGT further improves the performance in pest recognition by using the joint multimodal information from the pest's image and natural language description. Extensive experimental results demonstrate that the MMFGT obtains more competitive results compared to other excellent models, such as ResNet, ViT, SwinT, DINO, and EsViT, in pest recognition tasks, with recognition accuracy up to 98.12% and achieving 5.92% higher accuracy compared to the state-of-the-art DINO method for the baseline.","2023-06","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","12","12","","","","","","","","","","English","","","","WOS:001014308700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","few-shot learning; fine-grained image recognition; multimodal representation; pest recognition; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GIU9GAFQ","journalArticle","2023","Zou, A; Hao, WN; Chen, G; Jin, DW","DEC-transformer: deep embedded clustering with transformer on Chinese long text","PATTERN ANALYSIS AND APPLICATIONS","","1433-7541","10.1007/s10044-023-01161-z","","Long text clustering is of great significance and practical value in data mining, such as information retrieval, text integration, and data compression. Compared with short text clustering, long text clustering involves more semantic information representation and processing, making it a challenging problem. Most recent techniques merely rely on dynamic word embeddings from pre-training as a transfer learning or only based on a simple combination of transformers and traditional clustering methods, which still need to be expanded to short text due to the quadratic computational complexity. In this paper, a novel model combining transfer learning and dynamic feedback called deep embedded clustering with transformer(DEC-transformer) is proposed. To better capture the semantic relationships between sentences in documents, a novel transfer learning technology is firstly applied to long text clustering tasks for pre-training. Unlike previous papers, a two-stage training task is designed by treating semantic representation and text clustering as a united process, and the parameter is dynamically optimized by adaptive feedback to further improve efficiency. Experimental results on the test set show that the proposed model has made great progress in accuracy compared with several benchmarks. Furthermore, it also has good robustness and can get good performance on noisy datasets.","2023-08","2025-02-26 20:41:50","2025-02-26 20:41:50","","1349-1362","","3","26","","","","","","","","","","English","","","","WOS:000985234000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Bi-LSTM; CNN; DEC-transformer model; Long text clustering; NEURAL-NETWORKS; Pre-trained language model; XLNet","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z75K93TS","journalArticle","2022","Yang, HH; Guo, LF; Zhang, YM; Wu, XJ","U-shaped spatial-temporal transformer network for 3D human pose estimation","MACHINE VISION AND APPLICATIONS","","0932-8092","10.1007/s00138-022-01334-6","","3D human pose estimation has achieved much progress with the development of convolution neural networks. There still have some challenges to accurately estimate 3D joint locations from single-view images or videos due to depth ambiguity and severe occlusion. Motivated by the effectiveness of introducing vision transformer into computer vision tasks, we present a novel U-shaped spatial-temporal transformer-based network (U-STN) for 3D human pose estimation. The core idea of the proposed method is to process the human joints by designing a multi-scale and multi-level U-shaped transformer model. We construct a multi-scale architecture with three different scales based on the human skeletal topology, in which the local and global features are processed through three different scales with kinematic constraints. Furthermore, a multi-level feature representations is introduced by fusing intermediate features from different depths of the U-shaped network. With a skeletal constrained pooling and unpooling operations devised for U-STN, the network can transform features across different scales and extract meaningful semantic features at all levels. Experiments on two challenging benchmark datasets show that the proposed method achieves a good performance on 2D-to-3D pose estimation.","2022-11","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","6","33","","","","","","","","","","English","","","","WOS:000849651000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Human pose estimation; Multi-scale and multi-level feature representations; NEURAL-NETWORKS; Spatial-temporal transformer network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ASRKB8I8","journalArticle","2023","Wan, HF; Gao, L; Yuan, ZD; Qu, H; Sun, QR; Cheng, H; Wang, RB","A novel transformer model for surface damage detection and cognition of concrete bridges","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2022.119019","","Bridges play an important role in modern transportation systems and road networks, and hence it is essential to use various models based on visual inspection to detect and prevent the damages on the surface of bridge structure. However, due to the limitation of traditional models or lack of modelling data, bridge damages are often difficult to be accurately detected. This paper proposed a novel deep learning model called Bridge Detection Transformers (BR-DETR) based on Detection Transformers (DETR). Through analysis of existing bridge damage instances, we used a copy-paste data augmentation method to create new samples and significantly increased the sample size. Convolution was replaced by Deformable Conv2D, which introduces two-dimensional offsets to the regular grid sampling positions of standard convolution. Convolutional Project Attention was also added after the self-attention layer, which enabled additional modeling of local spatial context. In each encoder and decoder layer, Locally-enhanced Feed-Forward (LeFF) was used to replace the Feedforward to promote the correlation between adjacent tokens in the spatial dimension. The BR-DETR model outperformed the DETR model in detection performance with increased mAP and recall on the augmented highway bridge damage dataset and on the augmented Shandong bridge damage dataset.","2023-03-01","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","213","","","","","","","","","","English","","","","WOS:000880307500004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;44<br/>Total Times Cited:&nbsp;&nbsp;46<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Bridge surface damage; Convolutional Project Attention; Deformable Conv2D; Detection Transformer (DETR); Locally -enhanced Feed -Forward (LeFF); Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UF3A5MJK","journalArticle","2023","Wang, ZQ; El Saddik, A","DTITD: An Intelligent Insider Threat Detection Framework Based on Digital Twin and Self-Attention Based Deep Learning Models","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3324371","","Recent statistics and studies show that the loss generated by insider threats is much higher than that generated by external attacks. More and more organizations are investing in or purchasing insider threat detection systems to prevent insider risks. However, the accurate and timely detection of insider threats faces significant challenges. In this study, we proposed an intelligent insider threat detection framework based on Digital Twins and self-attentions based deep learning models. First, this paper introduces insider threats and the challenges in detecting them. Then this paper presents recent related works on solving insider threat detection problems and their limitations. Next, we propose our solutions to address these challenges: building an innovative intelligent insider threat detection framework based on Digital Twin (DT) and self-attention based deep learning models, performing insight analysis of users' behavior and entities, adopting contextual word embedding techniques using Bidirectional Encoder Representations from Transformers (BERT) model and sentence embedding technique using Generative Pre-trained Transformer 2 (GPT-2) model to perform data augmentation to overcome significant data imbalance, and adopting temporal semantic representation of users' behaviors to build user behavior time sequences. Subsequently, this study built self-attention-based deep learning models to quickly detect insider threats. This study proposes a simplified transformer model named DistilledTrans and applies the original transformer model, DistilledTrans, BERT + final layer, Robustly Optimized BERT Approach (RoBERTa) + final layer, and a hybrid method combining pre-trained (BERT, RoBERTa) with a Convolutional Neural Network (CNN) or Long Short-term Memory (LSTM) network model to detect insider threats. Finally, this paper presents experimental results on a dense dataset CERT r4.2 and augmented sporadic dataset CERT r6.2, evaluates their performance, and performs a comparison analysis with state-of-the-art models. Promising experimental results show that 1) contextual word embedding insert and substitution predicted by the BERT model, and context embedding sentences predicted by the GPT-2 model are effective data augmentation approaches to address high data imbalance; 2) DistilledTrans trained with sporadic dataset CERT r6.2 augmented by the contextual embedding sentence method predicted by GPT-2, outperforms the state-of-the-art models in terms of all evaluation metrics, including accuracy, precision, recall, F1-score, and Area Under the ROC Curve (AUC). Additionally, its structure is much simpler, and thus training time and computing cost are much less than those of recent models; 3) when trained with the dense dataset CERT r4.2, pre-trained models BERT plus a final layer or RoBERTa plus a final layer can achieve significantly higher performance than the current models with a very little sacrifice of precision. However, complex hybrid methods may not be required.","2023","2025-02-26 20:41:50","2025-02-26 20:41:50","","114013-114030","","","11","","","","","","","","","","English","","","","WOS:001091743700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","artificial intelligence; Behavioral sciences; BERT; Computational modeling; Context modeling; cybersecurity; data augmentation; Data augmentation; Data models; deep learning; Deep learning; Digital twin; Digital twins; GPT-2; insider threat; machine learning; Organizations; RoBERTa; Threat assessment; transformer; Transformers; UEBA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8RGC6EHW","journalArticle","2025","Busia, P; Scrugli, MA; Jung, VJB; Benini, L; Meloni, P","A Tiny Transformer for Low-Power Arrhythmia Classification on Microcontrollers","IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS","","1932-4545","10.1109/TBCAS.2024.3401858","","Wearable systems for the continuous and real-time monitoring of cardiovascular diseases are becoming widespread and valuable assets in diagnosis and therapy. A promising approach for real-time analysis of the electrocardiographic (ECG) signal and the detection of heart conditions, such as arrhythmia, is represented by the transformer machine learning model. Transformers are powerful models for the classification of time series, although efficient implementation in the wearable domain raises significant design challenges, to combine adequate accuracy and a suitable complexity. In this work, we present a tiny transformer model for the analysis of the ECG signal, requiring only 6k parameters and reaching 98.97% accuracy in the recognition of the 5 most common arrhythmia classes from the MIT-BIH Arrhythmia database, assessed considering 8-bit integer inference as required for efficient execution on low-power microcontroller-based devices. We explored an augmentation-based training approach for improving the robustness against electrode motion artifacts noise, resulting in a worst-case post-deployment performance assessment of 98.36% accuracy. Suitability for wearable monitoring solutions is finally demonstrated through efficient deployment on the parallel ultra-low-power GAP9 processor, where inference execution requires 4.28ms and 0.09mJ.","2025-02","2025-02-26 20:41:50","2025-02-26 20:41:50","","142-152","","1","19","","","","","","","","","","English","","","","WOS:001422058800005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Arrhythmia; Electrocardiography; Heart beat; Monitoring; Noise; Real-time systems; transformer; Transformers; wearable monitoring","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DHAIKN98","journalArticle","2025","Imran, J; Rajput, AS; Vashisht, R","Tifar-net: three-stream inception former-based action recognition network for infrared videos","SIGNAL IMAGE AND VIDEO PROCESSING","","1863-1703","10.1007/s11760-024-03796-9","","In this paper, we propose a Three-stream Inception Former-based Action Recognition Network, called TIFAR-Net to recognize actions in Infrared (IR) videos. It consists of two major stages. First, fine-tuning and feature extraction using a Inception Transformer (IFormer) network, and second, feature fusion and classification using Multi-Head Self-Attention (MHSA) network. Specifically, input IR videos are converted into compact yet effective representations referred to as Optical Flow Motion Images, Optical Flow Dynamic Images and Infrared Motion Images. The first two types of images are constructed using optical flow fields, while the third type of image is computed directly from raw IR frames. These image-based representations enable us to fine-tune a three-stream IFormer network, which is a hybrid Convolution Neural Network and Vision Transformer model. Features extracted from each stream are concatenated and passed through MHSA module to prune unimportant information and capture key global information from input images. Finally, classification is performed using fully connected and Softmax layers. Through extensive ablation experiments, we verified that our proposed TIFAR-Net improves the performance of IR action recognition and achieves state-of-the-art results on InfAR dataset (88.5%), IITR-IAR dataset (77.93%) and UNISV dataset(97.08%).","2025-02","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","2","19","","","","","","","","","","English","","","","WOS:001391633800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","ATTENTION; Convolutional neural network; Infrared action recognition; Multi-head self-attention; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VRIUB2R8","journalArticle","2025","Shi, PL; Zhang, B; Liu, YK; Fang, C","ETFRE: Entity-Type Fusing for Relation Extraction","ELECTRONICS","","2079-9292","10.3390/electronics14010205","","This paper proposes a relational extraction framework based on entity-type information fusion by Transformer model. Relational extraction, as an important part of knowledge graph construction, has been paid much attention in recent years. The existing relational extraction and joint triple extraction models rarely use the existing entity-type information, so the semantic features of the entity-type are lost, resulting in limited model performance and difficulty in solving the ambiguity problem. In order to improve this situation, this paper proposes a framework of entity-type information fusing based on a Transformer, which can generate word vector representation with entity-type information for a specific domain. There may be different entity categories for the same word, and the corresponding relationship categories are different at that time. Through deep self-attention, word vector representation is rich in entity-type information, which benefits relationship extraction and ambiguity removal. The multi-layer Transformer is used to realize the interaction between text features and generate a deep word vector representation with entity-type information, thus effectively avoiding ambiguity. Experimental results show that our model outperforms existing methods and performs well in ambiguous contexts relative to other models. We highlight the importance of entity-types in relation extraction.","2025-01","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","1","14","","","","","","","","","","English","","","","WOS:001393596500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","entity-type; knowledge graph; relation extraction; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BSH67UYL","journalArticle","2024","Song, C; Wu, J; Xian, KY; Huang, JF; Lu, L","Spatio-temporal graph learning: Traffic flow prediction of mobile edge computing in 5G/6G vehicular networks","COMPUTER NETWORKS","","1389-1286","10.1016/j.comnet.2024.110676","","Mobile Edge Computing (MEC) is a key technology that emerged to address the increasing computational demands and communication requirements of vehicular networks. It is a form of edge computing that brings cloud computing capabilities closer to end-users, specifically within the context of vehicular networks, which are part of the broader Internet of Vehicles (IoV) ecosystem. However, the dynamic nature of traffic flows in MEC in 5G/6G vehicular networks poses challenges for accurate prediction and resource allocation when aiming to provide edge service for mobile vehicles. In this paper, we present a novel approach to predict the traffic flow of MEC in 5G/6G vehicular networks using graph-based learning. In our framework, MEC servers in vehicular networks are construed as nodes to construct a dynamic similarity graph and a dynamic transition graph over a duration of multiple days. We utilize Graph Attention Networks (GAT) to learn and fuse the node embeddings of these dynamic graphs. A transformer model is subsequently employed to predict the vehicle frequency accessing the edge computing services for the next day. Our experimental results have shown that the model achieves high accuracy in predicting edge service access volumes with low error metrics.","2024-10","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","252","","","","","","","","","","English","","","","WOS:001294562600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","5G/6G vehicular networks; Graph neural network; Mobile edge computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UG49PP4F","journalArticle","2024","Ezukwoke, K; Hoayek, A; Batton-Hubert, M; Boucher, X; Gounet, P; Adrian, J","Big GCVAE: decision-making with adaptive transformer model for failure root cause analysis in semiconductor industry","JOURNAL OF INTELLIGENT MANUFACTURING","","0956-5515","10.1007/s10845-024-02346-x","","Pre-trained large language models (LLMs) have gained significant attention in the field of natural language processing (NLP), especially for the task of text summarization, generation, and question answering. The success of LMs can be attributed to the attention mechanism introduced in Transformer models, which have outperformed traditional recurrent neural network models (e.g., LSTM) in modeling sequential data. In this paper, we leverage pre-trained causal language models for the downstream task of failure analysis triplet generation (FATG), which involves generating a sequence of failure analysis decision steps for identifying failure root causes in the semiconductor industry. In particular, we conduct extensive comparative analysis of various transformer models for the FATG task and find that the BERT-GPT-2 Transformer (Big GCVAE), fine-tuned on a proposed Generalized-Controllable Variational AutoEncoder loss (GCVAE), exhibits superior performance in generating informative latent space by promoting disentanglement of latent factors. Specifically, we observe that fine-tuning the Transformer style BERT-GPT2 on the GCVAE loss yields optimal representation by reducing the trade-off between reconstruction loss and KL-divergence, promoting meaningful, diverse and coherent FATs similar to expert expectations.","2024-04-02","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","","","","","","","","","","","English","","","","WOS:001195648500002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Decision-making; Failure root cause analysis; Generalized latent space modelling; Large language model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VQAHCRG9","journalArticle","2024","Ge, D; Cheng, YH; Cao, SS; Ma, YM; Wu, YW","An enhanced abnormal information expression spatiotemporal model for anomaly detection in multivariate time-series","COMPLEX & INTELLIGENT SYSTEMS","","2199-4536","10.1007/s40747-023-01306-x","","The detection of anomalies in high-dimensional time-series has always played a crucial role in the domain of system security. Recently, with rapid advancements in transformer model and graph neural network (GNN) technologies, spatiotemporal modeling approaches for anomaly detection tasks have been greatly improved. However, most methods focus on optimizing upstream time-series prediction tasks by leveraging joint spatiotemporal features. Through experiments, we found that this modeling approach not only risks the loss of some original anomaly information during data preprocessing, but also focuses on optimizing the performance of the upstream prediction task and does not directly enhance the performance of the downstream detection task. We propose a spatiotemporal anomaly detection model that incorporates an improved attention mechanism in the process of temporal modeling. We adopt a heterogeneous graph contrastive learning approach in spatio modeling to compensate for the representation of anomalous behavioral information, thereby guiding the model through thorough training. Through validation on two widely used real-world datasets, we demonstrate that our model outperforms baseline methods. We also explore the impact of multivariate time-series prediction tasks on the detection task, and visualize the reasons behind the benefits gained by our model.","2024-04","2025-02-26 20:41:50","2025-02-26 20:41:50","","2937-2950","","2","10","","","","","","","","","","English","","","","WOS:001137196800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Abnormal information expression; Anomaly detection; Graph contrastive learning; Multivariate time-series; Spatiotemporal; TRANSFORMER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WRPW9CMK","journalArticle","2024","Liu, ZW; Zhou, SY; Chu, JQ; Chai, ZY; Chang, DD; Yuan, Y; Qin, JL; Wang, XC","Research on Arthroscopic Images Bleeding Detection Algorithm Based on ViT-ResNet50 Integrated Model and Transfer Learning","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3508797","","Arthroscopic surgery is a major technique for the treatment of joint-related diseases, however, intraoperative bleeding often produces a blood mist that severely affects the surgeon's field of vision and requires prompt high-flow drainage to remove the mist. Therefore, accurate bleeding detection is a prerequisite for effective blood mist removal. This paper proposes an arthroscopic image bleeding detection method based on the ViT-ResNet50 integrated model and transfer learning to solve the problem of relying on naked eye to identify bleeding in existing arthroscopic surgery. Firstly, Vision Transformer model and ResNet50 model are used to learn features by transfer learning on ImageNet dataset respectively. Then, a difference-enhanced proportional sampling method is proposed to enhance the unbalanced data. Finally, the two sub-network models are integrated through weighted soft voting method to realize bleeding detection in arthroscopic images. In order to evaluate the performance of the model proposed in this paper, experimental results on real data show that the integrated model is superior to a single deep learning model in various performance indicators and has good effects in detecting bleeding in arthroscopic images.","2024","2025-02-26 20:41:50","2025-02-26 20:41:50","","181436-181453","","","12","","","","","","","","","","English","","","","WOS:001375797900009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Arthroscopy surgery; bleeding detection; Convolutional neural networks; Data models; Deep learning; Feature extraction; Hemorrhaging; integrated model; Machine learning algorithms; Residual neural networks; ResNet50; Surgery; transfer learning; Transfer learning; Videos; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6YAUWSCG","journalArticle","2022","Xua, Z; Bai, YR; Zhao, R; Hu, HM; Ni, GJ; Minga, D","Decoding selective auditory attention with EEG using a transformer model","METHODS","","1046-2023","10.1016/j.ymeth.2022.04.009","","The human auditory system extracts valid information in noisy environments while ignoring other distractions, relying primarily on auditory attention. Studies have shown that the cerebral cortex responds differently to the sound source locations and that auditory attention is time-varying. In this work, we proposed a data-driven encoder-decoder architecture model for auditory attention detection (AAD), denoted as AAD-transformer. The model contains temporal self-attention and channel attention modules and could reconstruct the speech envelope by dynamically assigning weights according to the temporal self-attention and channel attention mechanisms of electroencephalogram (EEG). In addition, the model is conducted based on data-driven without additional preprocessing steps. The proposed model was validated using a binaural listening dataset, in which the speech stimulus was Mandarin, and compared with other models. The results showed that the decoding accuracy of the AADtransformer in the 0.15-second decoding time window was 76.35%, which was much higher than the accuracy of the linear model using temporal response function in the 3-second decoding time window (increased by 16.27%). This work provides a novel auditory attention detection method, and the data-driven characteristic makes it convenient for neural-steered hearing devices, especially those who speak tonal languages.","2022-08","2025-02-26 20:41:50","2025-02-26 20:41:50","","410-417","","","204","","","","","","","","","","English","","","","WOS:000809922000007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;16<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","ATTENDED SPEECH; Attention-mechanism; Auditory attention decoding; BRAIN; CONSEQUENCES; EEG; ENVELOPE; INSIGHTS; RESPONSES; TRACKING; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9L5CMGRF","journalArticle","2025","Ahmed, M; El-Sheimy, N; Leung, H","Dual-Modal Approach for Ship Detection: Fusing Synthetic Aperture Radar and Optical Satellite Imagery","SENSORS","","1424-8220","10.3390/s25020329","","The fusion of synthetic aperture radar (SAR) and optical satellite imagery poses significant challenges for ship detection due to the distinct characteristics and noise profiles of each modality. Optical imagery provides high-resolution information but struggles in adverse weather and low-light conditions, reducing its reliability for maritime applications. In contrast, SAR imagery excels in these scenarios but is prone to noise and clutter, complicating vessel detection. Existing research on SAR and optical image fusion often fails to effectively leverage their complementary strengths, resulting in suboptimal detection outcomes. This research presents a novel fusion framework designed to enhance ship detection by integrating SAR and optical imagery. This framework incorporates a detection system for optical images that utilizes Contrast Limited Adaptive Histogram Equalization (CLAHE) in combination with the YOLOv7 model to improve accuracy and processing speed. For SAR images, a customized Detection Transformer model, SAR-EDT, integrates advanced denoising algorithms and optimized pooling configurations. A fusion module evaluates the overlaps of detected bounding boxes based on intersection over union (IoU) metrics. Fused detections are generated by averaging confidence scores and recalculating bounding box dimensions, followed by robust postprocessing to eliminate duplicates. The proposed framework significantly improves ship detection accuracy across various scenarios.","2025-01","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","2","25","","","","","","","","","","English","","","","WOS:001405273200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","detection transformer; multi-modal fusion; synthetic aperture radar (SAR)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SVEQQKF4","journalArticle","2024","Onofri, VC; Maia, TAC; Cardoso, BJ","Assessment of Non-Linear Modeling of Ladle Furnace Transformer Using Finite Element Analysis","MACHINES","","2075-1702","10.3390/machines12120900","","This paper assesses a non-linear model of a three-phase Ladle Furnace Transformer, on slow front transients under no-load conditions. The model is designed to maintain accuracy and reduce complexity in estimating equivalent circuit parameters using three methods: analytical calculations, finite element analysis, and test measurement. The results reveal that analytical and finite element methods show discrepancies lower than 1%. Tests measurement, on the other hand, shows discrepancies higher than 5%, when compared to ones obtained from analytical and finite elements methods. Such discrepancy is particularly high in the estimation of leakage inductances and capacitances, and it is attributed mainly to differences between the transformer design and its actual assembly. Additionally, there are inherent inaccuracies in test procedures and instrumentation errors. The proposed model does not require difficult-to-obtain parameters and incorporates the non-linearity of magnetizing inductance, contributing to more accurate simulations. This simplified model is suitable for analyzing slow front transients and can be integrated into future studies addressing vacuum circuit breaker switching in electric arc furnace power systems, contributing to performance improvements in industrial applications. Additionally, the methodology for parameter determination can be applied to conventional power transformers, highlighting its versatility.","2024-12","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","12","12","","","","","","","","","","English","","","","WOS:001384684500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","analytical models; finite elements analysis (FEA); ladle furnace transformer; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MMS5XYAV","journalArticle","2024","Wu, XL; Wellington, S; Fu, ZC; Zhang, DG","Speech decoding from stereo-electroencephalography (sEEG) signals using advanced deep learning methods","JOURNAL OF NEURAL ENGINEERING","","1741-2560","10.1088/1741-2552/ad593a","","Objective. Brain-computer interfaces (BCIs) are technologies that bypass damaged or disrupted neural pathways and directly decode brain signals to perform intended actions. BCIs for speech have the potential to restore communication by decoding the intended speech directly. Many studies have demonstrated promising results using invasive micro-electrode arrays and electrocorticography. However, the use of stereo-electroencephalography (sEEG) for speech decoding has not been fully recognized. Approach. In this research, recently released sEEG data were used to decode Dutch words spoken by epileptic participants. We decoded speech waveforms from sEEG data using advanced deep-learning methods. Three methods were implemented: a linear regression method, an recurrent neural network (RNN)-based sequence-to-sequence model (RNN), and a transformer model. Main results. Our RNN and transformer models outperformed the linear regression significantly, while no significant difference was found between the two deep-learning methods. Further investigation on individual electrodes showed that the same decoding result can be obtained using only a few of the electrodes. Significance. This study demonstrated that decoding speech from sEEG signals is possible, and the location of the electrodes is critical to the decoding performance.","2024-06-01","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","3","21","","","","","","","","","","English","","","","WOS:001256815200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","ANATOMY; BRAIN; brain-computer interface (BCI); deep learning; LANGUAGE; speech decoding; speech prosthesis; stereo-electroencephalography (sEEG)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YD7AIA2Y","journalArticle","2024","Wang, WY; Osaragi, T","Learning Daily Human Mobility with a Transformer-Based Model","ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION","","2220-9964","10.3390/ijgi13020035","","The generation and prediction of daily human mobility patterns have raised significant interest in many scientific disciplines. Using various data sources, previous studies have examined several deep learning frameworks, such as the RNN and GAN, to synthesize human movements. Transformer models have been used frequently for image analysis and language processing, while the applications of these models on human mobility are limited. In this study, we construct a transformer model, including a self-attention-based embedding component and a Generative Pre-trained Transformer component, to learn daily movements. The embedding component takes regional attributes as input and learns regional relationships to output vector representations for locations, enabling the second component to generate different mobility patterns for various scenarios. The proposed model shows satisfactory performance for generating and predicting human mobilities, superior to a Long Short-Term Memory model in terms of several aggregated statistics and sequential characteristics. Further examination indicates that the proposed model learned the spatial structure and the temporal relationship of human mobility, which generally agrees with our empirical analysis. This observation suggests that the transformer framework can be a promising model for learning and understanding human movements.","2024-02","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","2","13","","","","","","","","","","English","","","","WOS:001170442700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","DAILY ACTIVITY SEQUENCES; daily mobility generation; mobility prediction; self-attention mechanism; Tokyo Metropolitan Area; transformer-based model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q3WVH7CX","journalArticle","2023","Zhou, XY; Zhou, WZ; Fu, XL; Hu, YC; Liu, JL","MDvT: introducing mobile three-dimensional convolution to a vision transformer for hyperspectral image classification","INTERNATIONAL JOURNAL OF DIGITAL EARTH","","1753-8947","10.1080/17538947.2023.2202423","","Hyperspectral images carry numerous spectral bands, and their wealth of band data is a valuable source of information for the accurate classification of ground objects. Three-dimensional (3D) convolution, although an excellent spectral information extraction method, is limited by its huge number of parameters and long model training time. To allow better integration of 3D convolution with the most popular transformer models currently available, a new architecture called mobile 3D convolutional vision transformer (MDvT) is proposed. The MDvT introduces inverted residual structure to reduce the number of model parameters and balance the data mining efficiency of low-dimensional data input. Simultaneously, a square patch is used to cut the sequence of tokens to accelerate the model operation. Through extensive experiments, we evaluated the classification overall performance of the proposed MDvT on the WHU-Hi and Pavia University datasets, and demonstrated significant improvements in classification accuracy and model runtime compared with classical deep learning models. It is worth noting that compared with directly integrating 3D convolution into the transformer model, the MDvT architecture improves the accuracy while reducing the time to train an epoch by approximately 58.54%. To facilitate the reproduction of the work in this paper, the model code is available at .","2023-12-31","2025-02-26 20:41:50","2025-02-26 20:41:50","","1469-1490","","1","16","","","","","","","","","","English","","","","WOS:000975488000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","ATTENTION; Classification; Convolutional neural network; FORESTS; Hyperspectral image; SPECTRAL-SPATIAL CLASSIFICATION; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K9C2KVT2","journalArticle","2023","Koohfar, S; Woldemariam, W; Kumar, A","Prediction of Electric Vehicles Charging Demand: A Transformer-Based Deep Learning Approach","SUSTAINABILITY","","2071-1050","10.3390/su15032105","","Electric vehicles have been gaining attention as a cleaner means of transportation that is low-carbon and environmentally friendly and can reduce greenhouse gas emissions and air pollution. Despite EVs' many advantages, widespread adoption will negatively affect the electric grid due to their random and volatile nature. Consequently, predicting the charging demand for electric vehicles is becoming a priority to maintain a steady supply of electric energy. Time series methodologies are applied to predict the charging demand: traditional and deep learning. RNN, LSTM, and transformers represent deep learning approaches, while ARIMA and SARIMA are traditional techniques. This research represents one of the first attempts to use the Transformer model for predicting EV charging demand. Predictions for 3-time steps are considered: 7 days, 30 days, and 90 days to address both short-term and long-term forecasting of EV charging load. RMSE and MAE were used to compare the model's performance. According to the results, the Transformer outperforms the other mentioned models in terms of short-term and long-term predictions, demonstrating its ability to address time series problems, especially EV charging predictions. The proposed Transformers framework and the obtained results can be used to manage electricity grids efficiently and smoothly.","2023-02","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","3","15","","","","","","","","","","English","","","","WOS:000930785900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;24<br/>Total Times Cited:&nbsp;&nbsp;25<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","ARIMA; deep learning; electric vehicles; IMPACTS; LSTM; machine learning; RNN; SARIMA; time series; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H982FZ9V","journalArticle","2021","Yadav, S; Mehta, RK","Modelling of magnetostrictive vibration and acoustics in converter transformer","IET ELECTRIC POWER APPLICATIONS","","1751-8660","10.1049/elp2.12025","","The converter transformers are susceptible to more noise and vibration when compared to power transformers due to the presence of DC bias in the DC transmission line. DC bias occurs mostly due to inaccuracies in valve firing resulting in a small residual DC oscillating around zero. Measurement of magnetostriction becomes significant as it influences the vibration and noise from the core. Hence, a magnetostrictive model of a high-voltage DC converter transformer has been developed. This work analyses the vibration and noise acoustics under such an occurrence. First, the core of the transformer model is designed in the stepped configuration for 240 MVA; then, magnetostrictive vibration is analysed by using suitable modules of COMSOL Multiphysics at different magnitudes of DC bias. The physics of noise has been interfaced using the Acoustics Module, and the results are recorded. Finally, artificial neural network model is developed for the prediction of vibration and noise characteristics of the model. The fitting process of neural network was then remodelled using various optimisation techniques, namely teaching-learning-based optimisation, particle swarm optimisation, biogeography-based optimisation, simulated annealing and binary coded genetic algorithm, and their results were compared to obtain the best-suited method using % mean-squared-error evaluation.","2021-03","2025-02-26 20:41:50","2025-02-26 20:41:50","","332-347","","3","15","","","","","","","","","","English","","","","WOS:000612719900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;22<br/>Total Times Cited:&nbsp;&nbsp;24<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","ELECTRICAL STEEL; HYSTERESIS; NOISE; OPTIMIZATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YZ7BP8HD","journalArticle","2024","Noorian, A","Integrating user reviews and risk factors from social networks in a multi-objective recommender system","ELECTRONIC COMMERCE RESEARCH","","1389-5753","10.1007/s10660-024-09944-0","","With the rapid expansion of location-based social networks, the significance of recommendations for tours and activities has grown significantly. However, many recommender systems overlook the valuable insights embedded in user reviews, thereby missing out on potential improvements. By incorporating review text into the recommendation process, it is possible to enhance the performance of recommender systems and tackle the Cold Start problem. In this study, a novel personalized method for recommending Points of Interest (POI) trips based on user reviews is proposed. The approach leverages a transformer model to extract semantic correlations in a multitask-learning setting, enabling predictions on crime rates and traffic flow at various POIs. Additionally, an LSTM network is employed to identify similar users based on their feedback, thereby overcoming data scarcity and the Cold Start issue. Moreover, this method incorporates multifaceted contextual information to determine user preferences accurately. Finally, a neural hybrid framework mines personalized POIs in a sequential pattern and integrates them into the recommendation process to identify the most efficient trip candidates. The proposed methodology is evaluated using datasets from Yelp, Gowalla, and Tripadvisor, and its superior performance is demonstrated across multiple evaluation metrics, including MAP, NDCG, RMSE, and F-Score.","2024-12-26","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","","","","","","","","","","","English","","","","WOS:001383449800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Multi-objective recommender system; Personalization; Risk-aware; Social networks; Transformer; User feedback","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EFNC7RQG","journalArticle","2024","Ma, ZY; Xiong, J; Gong, HJ; Wang, XH","Mission Planning of UAVs and CAVs Based on Graph Neural Network Transformer Model","IEEE INTERNET OF THINGS JOURNAL","","2327-4662","10.1109/JIOT.2024.3451248","","Efficient mission planning, including task allocation and path planning, is crucial for the successful operation of unmanned aerial vehicles (UAVs) and connected autonomous vehicles (CAVs) in complex scenarios. This article introduces an innovative mission planning approach that employs a collaborative model combining graph neural networks (GNNs) and Transformers to meet the intricate requirements of coordinating UAVs and CAVs. Our model excels in dynamic task allocation and accurate path planning, thereby boosting operational efficiency and reducing computational demands. We outline the shortcomings of current methods, notably their limited adaptability to dynamic changes and their substantial computational costs. By utilizing GNNs to capture complex interrelations and Transformers for effective information processing, our approach achieves greater adaptability and scalability. Experimental results demonstrate that our model surpasses leading methods, showing a 12% improvement in task allocation accuracy for UAVs and 10% for CAVs. Furthermore, we assess the model's performance under various conditions, confirming its robustness and adaptability. This research provides a holistic solution for mission planning in UAV and CAV systems, setting the stage for future enhancements in autonomous vehicle coordination across logistics, surveillance, and disaster management sectors.","2024-12-15","2025-02-26 20:41:50","2025-02-26 20:41:50","","40532-40546","","24","11","","","","","","","","","","English","","","","WOS:001375774000009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Adaptation models; Context modeling; Graph neural networks (GNNs); mission planning; path planning; Planning; Real-time systems; Resource management; task allocation; Task analysis; transformer-based model; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DCU2TQ8J","journalArticle","2024","Lim, YD; Li, HY; Goh, SCK; Wang, XY; Zhao, P; Tan, CS","Recognizing beam profiles from silicon photonics gratings using a transformer model","OPTICS EXPRESS","","1094-4087","10.1364/OE.539976","","Over the past decade, there has been extensive work in developing integrated silicon photonics (SiPh) gratings for the optical addressing of trapped ion qubits among the ion trap quantum computing community. However, when viewing beam profiles from gratings using infrared (IR) cameras, it is often difficult to determine the corresponding heights where the beam profiles are located. In this work, we developed transformer models to recognize the corresponding height categories of beam profiles in light from SiPh gratings. The models are trained using two techniques: (1) input patches and (2) input sequence. For the model trained with input patches, the model achieved a recognition accuracy of 0.924. Meanwhile, the model trained with input sequence shows a lower accuracy of 0.892. However, when repeating the model training for 150 cycles, a model trained with input patches shows inconsistent accuracy ranges between 0.289 to 0.959, while the model trained with input sequence shows accuracy values between 0.75 to 0.947. The obtained outcomes can be expanded to various applications, including auto-focusing of light beams and auto-adjustment of the z-axis stage to acquire desired beam profiles. (c) 2024 Optica Publishing Group under the terms of the Optica Open Access Publishing Agreement","2024-11-04","2025-02-26 20:41:50","2025-02-26 20:41:50","","41483-41499","","23","32","","","","","","","","","","English","","","","WOS:001355770900008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5AW89RIJ","journalArticle","2023","Dong, ZJ; Fan, BY; Li, F; Xu, XZ; Sun, H; Cao, WW","TCN-Informer-Based Flight Trajectory Prediction for Aircraft in the Approach Phase","SUSTAINABILITY","","2071-1050","10.3390/su152316344","","Trajectory prediction (TP) is a vital operation in air traffic control systems for flight monitoring and tracking. The approach phase of general aviation (GA) aircraft is more of a visual approach, which is related to the safety of the flight and whether to go around. Therefore, it is important to accurately predict the flight trajectory of the approach phase. Based on the historical flight trajectories of GA aircraft, a TP model is proposed with deep learning after feature extraction in this study, and the hybrid model combines a time convolution network and an improved transformer model. First, feature extraction of the spatiotemporal dimension is performed on the preprocessed flight data by using TCN; then, the extracted features are executed by adopting the Informer model for TP. The performance of the novel architecture is verified by experiments based on real flight trajectory data. The results show that the proposed TCN-Informer architecture performs better according to various evaluation metrics, which means that the prediction accuracies of the hybrid model are better than those of the typical prediction models widely used today. Moreover, it has been verified that the proposed method can provide valuable suggestions for decision-making regarding whether to go around during the approach.","2023-12","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","23","15","","","","","","","","","","English","","","","WOS:001116540900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","feature extraction; GA aircrafts; TCN-Informer; TIME; trajectory prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BBUKE2C4","journalArticle","2023","Zhu, QM; Chang, JY; Liu, T; Wang, YH; Yang, H","Transformer-based visual inspection algorithm for surface defects","OPTICAL ENGINEERING","","0091-3286","10.1117/1.OE.62.9.094102","","Industrial production often faces a variety of complex working conditions that lead to various defects, including Mura, on the surfaces of various industrial products. We propose a reconstruction network called RecTransformer, which is developed with a transformer for anomaly inpainting. RecTransformer is designed to effectively detect various types of surface defects despite using only a small number of defect samples. RecTransformer simplifies the defect detection problem to a patch-level image completion problem. Without using convolution, the given block image is processed by the transformer model to generate a defect-free reconstructed image. Herein, global semantic information is established, and an attention mechanism is built in the patch sequence, and the spatial information of the patches is determined by position encoding to complete the global image reconstruction process. With a limited number of defect samples as training data, the RecTransformer algorithm accurately reconstructs defects. It achieves an area under the receiver operating characteristic curve score of 97.6% for pixel-level segmentation on the testing dataset. Experiments conducted on a universal surface defect dataset demonstrate the effectiveness of the RecTransformer algorithm. RecTransformer can be adapted to detect various types of surface defects, including Mura in display devices, with only a small number of defect samples.","2023-09-01","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","9","62","","","","","","","","","","English","","","","WOS:001094790200008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","defect detection; few samples; mura; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4CIIHUDF","journalArticle","2022","Rahardja, S; Wang, M; Nguyen, BP; Fränti, P; Rahardja, S","A lightweight classification of adaptor proteins using transformer networks","BMC BIOINFORMATICS","","1471-2105","10.1186/s12859-022-05000-6","","Background Adaptor proteins play a key role in intercellular signal transduction, and dysfunctional adaptor proteins result in diseases. Understanding its structure is the first step to tackling the associated conditions, spurring ongoing interest in research into adaptor proteins with bioinformatics and computational biology. Our study aims to introduce a small, new, and superior model for protein classification, pushing the boundaries with new machine learning algorithms. Results We propose a novel transformer based model which includes convolutional block and fully connected layer. We input protein sequences from a database, extract PSSM features, then process it via our deep learning model. The proposed model is efficient and highly compact, achieving state-of-the-art performance in terms of area under the receiver operating characteristic curve, Matthew's Correlation Coefficient and Receiver Operating Characteristics curve. Despite merely 20 hidden nodes translating to approximately 1% of the complexity of previous best known methods, the proposed model is still superior in results and computational efficiency. Conclusions The proposed model is the first transformer model used for recognizing adaptor protein, and outperforms all existing methods, having PSSM profiles as inputs that comprises convolutional blocks, transformer and fully connected layers for the use of classifying adaptor proteins.","2022-11-04","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","1","23","","","","","","","","","","English","","","","WOS:000879029200002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","Adaptor protein; Deep learning; PREDICTION; Protein classification; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7GL4FKX7","journalArticle","2021","Chen, P; Li, D; Zuo, C; Li, ZS; Chen, DZ","A method to evaluate the plasma equivalent resistance of fusion relevant RF ion sources","FUSION ENGINEERING AND DESIGN","","0920-3796","10.1016/j.fusengdes.2021.112926","","To optimize the RF power transfer process for fusion relevant RF ion sources, the electric models evaluating the plasma equivalent resistance (PER) are used in engineering, such as the transformer model. This paper presents a method to evaluate the PER based on a FEM model, viz. the electromagnetic model describing the RF coupling and numerically solved by the finite element method (FEM). The inductively coupled plasma (ICP) is treated as a lossy dielectric. Then the ICP source loaded by the plasma is modeled in a generic electromagnetic FEM code. The method was applied to two fusion relevant ICP sources. The results showed that PER from the FEM model is quantitatively closer to PER from experiments than PER from other electrical models. Though the error in PER from the FEM model is still large, the method is an alternative to estimate the PER of fusion relevant RF ion sources. The error is mainly due to the stochastic heating model and the neglect of magnetization. Besides, for fusion relevant RF ion sources, the good-conductor approximation does not apply to the plasma and the plasma nonuniformity should be considered in electric models.","2021-12","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","","173","","","","","","","","","","English","","","","WOS:000731500000007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Inductively coupled plasma; MODEL; Plasma equivalent resistance; RF ion source; RF power transfer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SCZL3RQM","journalArticle","2025","Yu, LX; Chen, HQ; Wang, ZM; Zhan, SJ; Shao, JK; Liu, QJ; Xu, S","SpikingViT: A Multiscale Spiking Vision Transformer Model for Event-Based ObjectDetection","IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS","","2379-8920","10.1109/TCDS.2024.3422873","","Event cameras have unique advantages in object detection, capturing asynchronous events without continuous frames. They excel in dynamic range, low latency, and high-speed motion scenarios, with lower power consumption. However, aggregating event data into image frames leads to information loss and reduced detection performance. Applying traditional neural networks to event camera outputs is challenging due to event data's distinct characteristics. In this study, we present a novel spiking neural networks (SNNs)-based object detection model, the spiking vision transformer (SpikingViT) to address these issues. First, we design a dedicated event data converting module that effectively captures the unique characteristics of event data, mitigating the risk of information loss while preserving its spatiotemporal features. Second, we introduce SpikingViT, a novel object detection model that leverages SNNs capable of extracting spatiotemporal information among events data. SpikingViT combines the advantages of SNNs and transformer models, incorporating mechanisms such as attention and residual voltage memory to further enhance detection performance. Extensive experiments have substantiated the remarkable proficiency of SpikingViT in event-based object detection, positioning it as a formidable contender. Our proposed approach adeptly retains spatiotemporal information inherent in event data, leading to a substantial enhancement in detection performance.","2025-02","2025-02-26 20:41:50","2025-02-26 20:41:50","","130-146","","1","17","","","","","","","","","","English","","","","WOS:001416713800014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","Cameras; Data mining; DVS data converting; Feature extraction; NETWORKS; object detection; Object detection; OBJECT DETECTION; residual voltage memory; spiking transformer; Task analysis; Transformers; Voltage control","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FAUPEUGJ","journalArticle","2024","Lei, JR; Li, Y; Yung, LY; Leng, Y; Lin, QF; Wu, YC","Understanding Complex-Valued Transformer for Modulation Recognition","IEEE WIRELESS COMMUNICATIONS LETTERS","","2162-2337","10.1109/LWC.2024.3476137","","Complex-valued convolution neural networks (CVCNNs) have been recently applied for modulation recognition (MR), due to its ability to capture the relationship between the real and imaginary parts of the received signal. On the other hand, the transformer model has been shown to be distinguished in MR by its superior capability to extract the correlation among high-dimensional signals compared to the CNN. It is a logical next step to ask whether a fully complex-valued transformer based neural network (CVTNN) can bring further performance gain? If so, where the gain comes from? To answer these questions, this letter designs the building blocks of the CVTNN for MR, which is composed of a convolution embedding module, a complete transformer encoder, and a C2R classifier, and establishes the estimation error bound of the proposed CVTNN from an inductive bias perspective. We theoretically prove that the estimation error bound of the proposed CVTNN is lower than that of the real-valued transformer based neural network (RVTNN) for MR. Simulation results further show that the proposed CVTNN outperforms the RVTNN and other benchmarks under different settings, which corroborates the proposed theoretical analysis.","2024-12","2025-02-26 20:41:50","2025-02-26 20:41:50","","3523-3527","","12","13","","","","","","","","","","English","","","","WOS:001376014800014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","cognitive radio; Complex-valued transformer; Computer architecture; Convolution; Correlation; Estimation error; Modulation; modulation recognition; NETWORKS; Neural networks; Simulation; Training; Transformers; Vectors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RS3G9HZI","journalArticle","2024","Zhang, JN; Chen, WJ; Joshi, T; Zhang, XM; Loh, PL; Jog, V; Bruce, RJ; Garrett, JW; Mcmillan, AB","BAE-ViT: An Efficient Multimodal Vision Transformer for Bone Age Estimation","TOMOGRAPHY","","2379-1381","10.3390/tomography10120146","","This research introduces BAE-ViT, a specialized vision transformer model developed for bone age estimation (BAE). This model is designed to efficiently merge image and sex data, a capability not present in traditional convolutional neural networks (CNNs). BAE-ViT employs a novel data fusion method to facilitate detailed interactions between visual and non-visual data by tokenizing non-visual information and concatenating all tokens (visual or non-visual) as the input to the model. The model underwent training on a large-scale dataset from the 2017 RSNA Pediatric Bone Age Machine Learning Challenge, where it exhibited commendable performance, particularly excelling in handling image distortions compared to existing models. The effectiveness of BAE-ViT was further affirmed through statistical analysis, demonstrating a strong correlation with the actual ground-truth labels. This study contributes to the field by showcasing the potential of vision transformers as a viable option for integrating multimodal data in medical imaging applications, specifically emphasizing their capacity to incorporate non-visual elements like sex information into the framework. This tokenization method not only demonstrates superior performance in this specific task but also offers a versatile framework for integrating multimodal data in medical imaging applications.","2024-12","2025-02-26 20:41:50","2025-02-26 20:41:50","","2058-2072","","12","10","","","","","","","","","","English","","","","WOS:001383693800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","bone age regression; gender embedding; machine learning; multimodal data; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WMMPFTGG","journalArticle","2024","Weissbart, H; Martin, AE","The structure and statistics of language jointly shape cross-frequency neural dynamics during spoken language comprehension","NATURE COMMUNICATIONS","","2041-1723","10.1038/s41467-024-53128-1","","Humans excel at extracting structurally-determined meaning from speech despite inherent physical variability. This study explores the brain's ability to predict and understand spoken language robustly. It investigates the relationship between structural and statistical language knowledge in brain dynamics, focusing on phase and amplitude modulation. Using syntactic features from constituent hierarchies and surface statistics from a transformer model as predictors of forward encoding models, we reconstructed cross-frequency neural dynamics from MEG data during audiobook listening. Our findings challenge a strict separation of linguistic structure and statistics in the brain, with both aiding neural signal reconstruction. Syntactic features have a more temporally spread impact, and both word entropy and the number of closing syntactic constituents are linked to the phase-amplitude coupling of neural dynamics, implying a role in temporal prediction and cortical oscillation alignment during speech processing. Our results indicate that structured and statistical information jointly shape neural dynamics during spoken language comprehension and suggest an integration process via a cross-frequency coupling mechanism. This study demonstrates how, during spoken language comprehension, the brain integrates syntactic and statistical features, which mutually but differentially contribute to the phase-amplitude coupling of neural signals across space and time.","2024-10-14","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","1","15","","","","","","","","","","English","","","","WOS:001335435800007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;99</p>","","","CORTICAL OSCILLATIONS; ENTRAINMENT; INFORMATION; OPERATIONS; OSCILLATORY DYNAMICS; POWER; UNIFICATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PY498JRH","journalArticle","2024","Sun, ZY; Sun, WW; Li, SH; Yang, ZN; Zhang, MT; Yang, Y; Geng, HY; Yu, J","CrysGraphFormer: an equivariant graph transformer for prediction of lattice thermal conductivity with interpretability","JOURNAL OF MATERIALS CHEMISTRY A","","2050-7488","10.1039/d4ta04495a","","To address the challenges of high error rates and poor generalization in current deep learning models for predicting lattice thermal conductivity (LTC), we introduce CrysGraphFormer, an innovative equivariant crystal graph transformer model tailored for this task. The model incorporates an improved multi-head self-attention mechanism and human-designed feature descriptors. By utilizing a message-passing mechanism to update node information, it introduces relative coordinate differences to represent crystal symmetry, avoiding the traditionally used complex and computationally expensive higher-order representations. We constructed a comprehensive dataset containing 5729 LTC data points (300 K), including 5477 materials from AFLOW, 112 MAX and MAB phase materials calculated using VASP, and 140 for half-Heusler alloys. Experimental results demonstrate that the CrysGraphFormer model achieves state-of-the-art performance in LTC prediction tasks and excels in predicting fundamental properties. The model offers good interpretability, providing insights from chemical and materials science perspectives. Furthermore, we validated the model's application potential in the field of thermoelectric materials by predicting the LTC of 59 thermoelectric materials and 55 ternary semiconductor materials, with results consistent with DFT calculations. Finally, the uncertainty of CrysGraphFormer was assessed using the Monte Carlo Dropout method. We propose an innovative GNN model, CrysGraphFormer, which accurately predicts lattice thermal conductivity and enhances insights for material discovery.","2024-11-12","2025-02-26 20:41:50","2025-02-26 20:41:50","","30707-30721","","44","12","","","","","","","","","","English","","","","WOS:001337346800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","CRYSTALS; MOLECULES; NETWORKS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7DQMS2XM","journalArticle","2024","Zhang, RH; Jiao, LC; Li, LL; Liu, F; Liu, X; Yang, SYN","Evolutionary Dual-Stream Transformer","IEEE TRANSACTIONS ON CYBERNETICS","","2168-2267","10.1109/TCYB.2022.3213537","","Vision transformers (ViTs) are rapidly evolving and are widely used in computer vision. However, high-performance ViTs require many computations, which limit their further development in the vision field. In this article, a novel evolutionary dual-stream transformer (E-DST) model is proposed to alleviate the computational resource demand problem. A hybrid attention mechanism structure is proposed for a DST model. The DST model uses a dual-branch structure to fuse convolutional and transformer features. Combining the features learned by the transformer and convolution effectively saves model computational resources. In addition, an evolutionary optimizer is proposed to optimize the parameters of the model. The excellent search ability of the evolutionary algorithm is utilized to optimize the transformer model parameters. The convergence of the evolutionary optimizer is proved in this article. In addition, the proposed E-DST model is experimentally compared with a variety of classic models and their deformations based on three datasets. And, the evolutionary optimizer proves its generality in convolutional and recurrent neural networks. The experimental results show that the E-DST model can effectively reduce computational resources and that the evolutionary optimizer can solve large-scale optimization problems. In conclusion, our proposed method is feasible and effective.","2024-04","2025-02-26 20:41:50","2025-02-26 20:41:50","","2166-2178","","4","54","","","","","","","","","","English","","","","WOS:001189864200028","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Adaptation models; Computational modeling; Deep learning; evolutionary optimization; Feature extraction; image classification; NETWORKS; Optimization; OPTIMIZATION; Task analysis; Training; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2WZ8A77H","journalArticle","2024","Faheem, MA; Wassif, KT; Bayomi, H; Abdou, SM","Improving neural machine translation for low resource languages through non-parallel corpora: a case study of Egyptian dialect to modern standard Arabic translation","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-023-51090-4","","Machine translation for low-resource languages poses significant challenges, primarily due to the limited availability of data. In recent years, unsupervised learning has emerged as a promising approach to overcome this issue by aiming to learn translations between languages without depending on parallel data. A wide range of methods have been proposed in the literature to address this complex problem. This paper presents an in-depth investigation of semi-supervised neural machine translation specifically focusing on translating Arabic dialects, particularly Egyptian, to Modern Standard Arabic. The study employs two distinct datasets: one parallel dataset containing aligned sentences in both dialects, and a monolingual dataset where the source dialect is not directly connected to the target language in the training data. Three different translation systems are explored in this study. The first is an attention-based sequence-to-sequence model that benefits from the shared vocabulary between the Egyptian dialect and Modern Arabic to learn word embeddings. The second is an unsupervised transformer model that depends solely on monolingual data, without any parallel data. The third system starts with the parallel dataset for an initial supervised learning phase and then incorporates the monolingual data during the training process.","2024-01-27","2025-02-26 20:41:50","2025-02-26 20:41:50","","","","1","14","","","","","","","","","","English","","","","WOS:001152431000006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N2XPFCRE","journalArticle","2024","Xiang, FF; Zhang, YM; Zhang, SY; Wang, ZL; Qiu, LM; Choi, JH","Bayesian gated-transformer model for risk-aware prediction of aero-engine remaining useful life","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2023.121859","","Remaining Useful Life (RUL) prediction plays a critical role in the prognostics and health management (PHM) for aero-engines. A variety of Deep Learning (DL) approaches have emerged for RUL prediction due to their flexibility of the architectures and superiority with nonlinear responses. The mainstream DL models usually focus on overall prediction accuracy, however, model reliability is actually the key impeding industrial applications. This paper proposes the Bayesian Gated-Transformer (BGT) model for reliable RUL prediction with quantified uncertainty. The BGT model is rooted in the transformer architecture and enhanced with the gated mechanism to balance between long-term trends and short-term patterns. Both the epistemic and aleatory uncertainties are quantified through the Bayesian setup of model weights and the introduced noise channel. The training of model weights is formulated with sampling-based variational inference which approximates the posterior of model uncertainty with Gaussian distributions. The BGT model has been applied to the NASA CMAPSS and N-CMAPSS datasets. Compared with alternative DL models, the BGT model demonstrates better or similar accuracy regarding overall prediction. The BGT model is capable of effective uncertainty quantification which enables risk-aware RUL prediction.","2024-03-15","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","238","","","","","","","","","","English","","","","WOS:001098781200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;25<br/>Total Times Cited:&nbsp;&nbsp;25<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Aero-engine prognosis; Bayesian deep learning; Remaining useful life prediction; Time-series forecasting; Uncertainty quantification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UJT7Z4Y7","journalArticle","2023","Wu, CL; Hu, HQ; Lin, K; Wang, Q; Liu, TJ; Chen, GN","Attention-guided and fine-grained feature extraction from face images for gaze estimation","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2023.106994","","Research on appearance gaze estimation based on deep learning has achieved considerable results. However, a lack of information in the extracted local blocks reduces the precision of gaze estimation since CNNs do not prioritize the information within the key picture blocks for face image estimation. In this research, fine-grained visual information is extracted from local blocks using a Transformer in Transformer (TNT) model that emphasizes the interactions between local blocks. First, TNT-based gaze estimation models (GTiT-Pure and GTiTHybrid) are established with the TNT model to capture both coarse- and fine-grained visual information about the face, which are then combined to provide a feature representation for gaze regression. Then, the performance of the two models are evaluated on four gaze estimation datasets. Experimental results demonstrate that the pretrained GTiT-Pure has less gaze estimation error than the majority of CNNs and Transformer models, and that the GTiT-Hybrid model performs the best on the EyeDiap and RT-Gene datasets. The GTiT model which combines both coarse- and fine-grained gaze features in face images, can be used to further explore the advantages of the Transformer model in gaze feature extraction.","2023-11","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","126","","","","","","","","","","English","","","","WOS:001060420800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","and fine-grained; APPEARANCE; Attention mechanism; Coarse; DIFFERENCE; Gaze estimation; TNT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2GSFQVRL","journalArticle","2022","Gu, Y; Piao, Z; Yoo, SJ","STHarDNet: Swin Transformer with HarDNet for MRI Segmentation","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app12010468","","In magnetic resonance imaging (MRI) segmentation, conventional approaches utilize U-Net models with encoder-decoder structures, segmentation models using vision transformers, or models that combine a vision transformer with an encoder-decoder model structure. However, conventional models have large sizes and slow computation speed and, in vision transformer models, the computation amount sharply increases with the image size. To overcome these problems, this paper proposes a model that combines Swin transformer blocks and a lightweight U-Net type model that has an HarDNet blocks-based encoder-decoder structure. To maintain the features of the hierarchical transformer and shifted-windows approach of the Swin transformer model, the Swin transformer is used in the first skip connection layer of the encoder instead of in the encoder-decoder bottleneck. The proposed model, called STHarDNet, was evaluated by separating the anatomical tracings of lesions after stroke (ATLAS) dataset, which comprises 229 T1-weighted MRI images, into training and validation datasets. It achieved Dice, IoU, precision, and recall values of 0.5547, 0.4185, 0.6764, and 0.5286, respectively, which are better than those of the state-of-the-art models U-Net, SegNet, PSPNet, FCHarDNet, TransHarDNet, Swin Transformer, Swin UNet, X-Net, and D-UNet. Thus, STHarDNet improves the accuracy and speed of MRI image-based stroke diagnosis.","2022-01","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","1","12","","","","","","","","","","English","","","","WOS:000751044200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;28<br/>Total Times Cited:&nbsp;&nbsp;30<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","ATLAS; HarDNet; segmentation; Swin transformer; U-Net","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A22HZM26","journalArticle","2024","Potter, IY; Yeritsyan, D; Mahar, S; Kheir, N; Vaziri, A; Putman, M; Rodriguez, EK; Wu, J; Nazarian, A; Vaziri, A","Proximal femur fracture detection on plain radiography via feature pyramid networks","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-63001-2","","Hip fractures exceed 250,000 cases annually in the United States, with the worldwide incidence projected to increase by 240-310% by 2050. Hip fractures are predominantly diagnosed by radiologist review of radiographs. In this study, we developed a deep learning model by extending the VarifocalNet Feature Pyramid Network (FPN) for detection and localization of proximal femur fractures from plain radiography with clinically relevant metrics. We used a dataset of 823 hip radiographs of 150 subjects with proximal femur fractures and 362 controls to develop and evaluate the deep learning model. Our model attained 0.94 specificity and 0.95 sensitivity in fracture detection over the diverse imaging dataset. We compared the performance of our model against five benchmark FPN models, demonstrating 6-14% sensitivity and 1-9% accuracy improvement. In addition, we demonstrated that our model outperforms a state-of-the-art transformer model based on DINO network by 17% sensitivity and 5% accuracy, while taking half the time on average to process a radiograph. The developed model can aid radiologists and support on-premise integration with hospital cloud services to enable automatic, opportunistic screening for hip fractures.","2024-05-27","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","1","14","","","","","","","","","","English","","","","WOS:001233645300005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;94</p>","","","ALGORITHM; BONE; Deep learning; DENSITY; EMERGENCY-DEPARTMENT; Fracture; Hip; HIP FRACTURE; IMPACT; OSTEOPOROSIS; PELVIC FRACTURES; Plain radiography; PREVALENCE; Proximal femur; TRENDS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HWUIG8DK","journalArticle","2024","Dhakal, A; Gyawali, R; Wang, LG; Cheng, JL","CryoTransformer: a transformer model for picking protein particles from Cryo-EM micrographs","BIOINFORMATICS","","1367-4803","10.1093/bioinformatics/btae109","","Motivation: Cryo-electron microscopy (cryo-EM) is a powerful technique for determining the structures of large protein complexes. Picking single protein particles from cryo-EM micrographs (images) is a crucial step in reconstructing protein structures from them. However, the widely used template-based particle picking process requires some manual particle picking and is labor-intensive and time-consuming. Though machine learning and artificial intelligence (AI) can potentially automate particle picking, the current AI methods pick particles with low precision or low recall. The erroneously picked particles can severely reduce the quality of reconstructed protein structures, especially for the micrographs with low signal-to-noise-ratio (SNR). Results: To address these shortcomings, we devised CryoTransformer based on transformers, residual networks, and image processing techniques to accurately pick protein particles from cryo-EM micrographs. CryoTransformer was trained and tested on the largest labelled cryo-EM protein particle dataset-CryoPPP. It outperforms the current state-of-the-art machine learning methods of particle picking in terms of the resolution of 3D density maps reconstructed from the picked particles as well as F1-score, and is poised to facilitate the automation of the cryo-EM protein particle picking. Availability: The source code and data for CryoTransformer are openly available at: https://github.com/jianlin-cheng/CryoTransformer. Supplementary information are available at Bioinformatics online.","2024-03-04","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","3","40","","","","","","","","","","English","","","","WOS:001177242800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4E6DXHN9","journalArticle","2025","Guo, YP; Lan, ZP; Sun, YG; Sun, YH; Li, XX; Wang, YR; Li, B","Research on occlusion pedestrian re-identification based on ViT model","JOURNAL OF SUPERCOMPUTING","","0920-8542","10.1007/s11227-024-06831-1","","Pedestrian re-identification (Re-ID) is an important task in intelligent surveillance and public safety. Traditional pedestrian re-identification methods show obvious limitations when facing the occlusion problem, leading to a significant decrease in re-identification accuracy. For this reason, we design an occlusion perceptual attention module (OPAM), which seeks to improve the model's capacity to grasp both local and global contextual information. Secondly, we bring in an improved feature fusion module FtF (Feature to Feature), which aims to fully utilize the rich information of convolutional features to enhance the feature representation capability of the visual transformer model. Finally, this paper constructs a comprehensive loss function robust triplet loss (RTL), which combines the triad loss and occlusion perception loss to enhance the performance and efficiency of pedestrian re-recognition. We conduct experiments on two recognized occluded pedestrian datasets, with Rank-1 of 73.6% and mAP of 63.2% on the Occluded-Duke dataset, which is an increase of 2.6% and 2.2% from baseline, respectively; and Rank-1 of 90.8% and mAP of 82.4% on the DukeMTMC-reID dataset. The good performance compared with state-of-the-art methods fully validates its validity and generalizability.","2025-01","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","2","81","","","","","","","","","","English","","","","WOS:001395084700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Attention mechanism; Feature fusion; Occlusion; Pedestrian re-recognition; PERSON REIDENTIFICATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IAFD7B2P","journalArticle","2024","Lv, SR; Yang, B; Wang, RY; Lu, SY; Tian, JW; Zheng, WF; Chen, XB; Yin, LR","Dynamic Multi-Granularity Translation System: DAG-Structured Multi-Granularity Representation and Self-Attention","SYSTEMS","","2079-8954","10.3390/systems12100420","","In neural machine translation (NMT), the sophistication of word embeddings plays a pivotal role in the model's ability to render accurate and contextually relevant translations. However, conventional models with single granularity of word segmentation cannot fully embed complex languages like Chinese, where the granularity of segmentation significantly impacts understanding and translation fidelity. Addressing these challenges, our study introduces the Dynamic Multi-Granularity Translation System (DMGTS), an innovative approach that enhances the Transformer model by incorporating multi-granularity position encoding and multi-granularity self-attention mechanisms. Leveraging a Directed Acyclic Graph (DAG), the DMGTS utilizes four levels of word segmentation for multi-granularity position encoding. Dynamic word embeddings are also introduced to enhance the lexical representation by incorporating multi-granularity features. Multi-granularity self-attention mechanisms are applied to replace the conventional self-attention layers. We evaluate the DMGTS on multiple datasets, where our system demonstrates marked improvements. Notably, it achieves significant enhancements in translation quality, evidenced by increases of 1.16 and 1.55 in Bilingual Evaluation Understudy (BLEU) scores over traditional static embedding methods. These results underscore the efficacy of the DMGTS in refining NMT performance.","2024-10","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","10","12","","","","","","","","","","English","","","","WOS:001341816500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","dynamic multi-granularity translation system; dynamic word embedding; multi-granularity; natural language processing (NLP); neural machine translation; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZEYT3UUT","journalArticle","2024","Sun, Z; Song, DJ; Peng, QK; Li, HZ; Li, PL","Improving long-term electricity time series forecasting in smart grid with a three-stage channel-temporal approach","JOURNAL OF CLEANER PRODUCTION","","0959-6526","10.1016/j.jclepro.2024.143051","","-Transformer-based models have shown progress in addressing electricity time series forecasting challenges. However, as the forecasting horizon extends, the computational complexity required to capture long-term global correlations may limit their ability to utilize extensive historical data. This paper proposes a non-Transformer model named Three-Stage Channel-Temporal (TSCT), designed to be lightweight and capable of handling longer look-back windows for long-term electricity time series forecasting (LTESF) in smart grid contexts. TSCT sequentially derives feature maps along two dimensions, channel and temporal, focusing on 'which ' and 'when ', respectively. Moreover, its dynamic capacity to decompose and fuse information enables the disentanglement of intricate temporal patterns, highlighting the fundamental characteristics inherent in the time series. Extensive experiments demonstrate that our proposed TSCT outperforms state-of-the-art methods in smart grid scenarios using a commonly used Electricity dataset. Notably, the TSCT approach exhibits significantly higher efficiency compared to Transformer-based methods: an impressive 85% reduction in trainable parameters, a substantial 99% reduction in GPU memory usage, a 94% reduction in running time, and a 49% reduction in inference time. Code is available at: https://github.com/Zhao-Sun/TSCT.","2024-08-25","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","468","","","","","","","","","","English","","","","WOS:001268378200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Deep learning; Electricity forecasting; Long-term time series forecasting; Non-Transformer; PREDICTION; Smart grid","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9HPJFM2Y","journalArticle","2024","Cheng, YB; Qv, J; Feng, K; Han, T","A Bayesian adversarial probsparse Transformer model for long-term remaining useful life prediction","RELIABILITY ENGINEERING & SYSTEM SAFETY","","0951-8320","10.1016/j.ress.2024.110188","","Long-term remaining useful life (RUL) prediction is essential for the maintenance of safety -crucial engineering assets. Deep learning (DL) models, especially Transformer -based models have achieved outstanding performance in long-term RUL prediction. However, existing Transformer models neglect the impact of discrepancy loss in model training. The accumulation of the discrepancy loss during the inference will hamper the generalization of prediction model, resulting in an overfitting problem. To address the problem, this paper proposes a Bayesian Adversarial Probsparse Transformer (BAPT) model for long-term RUL prediction. Firstly, the adversarial learning method is leveraged to mitigate the impact of accumulated discrepancy loss caused by varying working conditions in long-term prediction, thus diminishing the error accumulation. Secondly, the Probsparse multi -head attention is adopted to enhance the efficiency of feature extraction. The Probsparse multi -head attention focuses on the significant degradation features in long time -series to reduce the computation complexity. Lastly, the Bayesian neural network is introduced to quantify the uncertainty in RUL prediction. The effectiveness of the proposed model is verified using two commercial aircraft turbofan engine datasets. The results indicate that BAPT model for long-term RUL prediction demonstrates better performance than the existing state-of-the-art models.","2024-08","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","248","","","","","","","","","","English","","","","WOS:001242531900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Adversarial learning; Bayesian deep-learning; Distribution discrepancy; Long time-series; Remaining useful life; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"68STGW78","journalArticle","2024","Dere, MD; Lee, B","A Novel Approach to Surface EMG-Based Gesture Classification Using a Vision Transformer Integrated With Convolutive Blind Source Separation","IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS","","2168-2194","10.1109/JBHI.2023.3330289","","A robust pattern recognition framework is required for ideal real-time human-machine interface (HMI) applications. Convolutional neural networks and recurrent neural networks have been widely used for the classification of gestures based on electromyography (EMG), but few studies have demonstrated the effectiveness of using a vision transformer for this purpose. Additionally, the accuracy achieved is influenced by the efficacy of the preprocessing pipeline. This study assessed ViT with and without an attention mechanism for precise motor intent decoding by investigating various input features and integrating convolutive blind source separation (BSS) preprocessing. All investigations were carried out with two open-access high-density surface EMG datasets of 34 and 21 hand gestures recorded from 20 and 5 healthy subjects respectively. Integration of centering and optimal extension factors resulted in better performance with raw input. However, spatial whitening increased the model's sensitivity to noise. The best-performing BSS-integrated convolution vision transformer model (BSS-CViT) model yielded an accuracy of 96.61% and 91.98% on test datasets one and two. This is a promising result for future studies in real-time HMI applications.","2024-01","2025-02-26 20:41:51","2025-02-26 20:41:51","","181-192","","1","28","","","","","","","","","","English","","","","WOS:001139615300011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","Convolutive blind source separation (BSS); DECOMPOSITION; gesture classification; high-density surface electromyography (HD-sEMG); human-machine interface (HMI); vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9XH6E8GY","journalArticle","2023","Li, HR; Yao, HX; Hou, YX","HPnet: Hybrid Parallel Network for Human Pose Estimation","SENSORS","","1424-8220","10.3390/s23094425","","Hybrid models which combine the convolution and transformer model achieve impressive performance on human pose estimation. However, the existing hybrid models on human pose estimation, which typically stack self-attention modules after convolution, are prone to mutual conflict. The mutual conflict enforces one type of module to dominate over these hybrid sequential models. Consequently, the performance of higher-precision keypoints localization is not consistent with overall performance. To alleviate this mutual conflict, we developed a hybrid parallel network by parallelizing the self-attention modules and the convolution modules, which conduce to leverage the complementary capabilities effectively. The parallel network ensures that the self-attention branch tends to model the long-range dependency to enhance the semantic representation, whereas the local sensitivity of the convolution branch contributes to high-precision localization simultaneously. To further mitigate the conflict, we proposed a cross-branches attention module to gate the features generated by both branches along the channel dimension. The hybrid parallel network achieves 75.6% and 75.4% AP on COCO validation and test-dev sets and achieves consistent performance on both higher-precision localization and overall performance. The experiments show that our hybrid parallel network is on par with the state-of-the-art human pose estimation models.","2023-04-30","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","9","23","","","","","","","","","","English","","","","WOS:000987109600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","complementary capability; cross-branches attention; human pose estimation; hybrid parallel model; semantic conflict","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U83CJ6UM","journalArticle","2022","Peng, YS; Zhang, YW; Tu, B; Li, QM; Li, WJ","Spatial-Spectral Transformer With Cross-Attention for Hyperspectral Image Classification","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2022.3203476","","Convolutional neural networks (CNNs) have been widely used in hyperspectral image (HSI) classification tasks because of their excellent local spatial feature extraction capabilities. However, because it is difficult to establish dependencies between long sequences of data for CNNs, there are limitations in the process of processing hyperspectral spectral sequence features. To overcome these limitations, inspired by the Transformer model, a spatial-spectral transformer with cross-attention (CASST) method is proposed. Overall, the method consists of a dual-branch structures, i.e., spatial and spectral sequence branches. The former is used to capture fine-grained spatial information of HSI, and the latter is adopted to extract the spectral features and establish interdependencies between spectral sequences. Specifically, to enhance the consistency among features and relieve computational burden, we design a spatial-spectral cross-attention module with weighted sharing to extract the interactive spatial-spectral fusion feature intra Transformer block, while also developing a spatial-spectral weighted sharing mechanism to capture the robust semantic feature inter Transformer block. Performance evaluation experiments are conducted on three hyperspectral classification datasets, demonstrating that the CASST method achieves better accuracy than the state-of-the-art Transformer classification models and mainstream classification networks.","2022","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","60","","","","","","","","","","English","","","","WOS:000856251200021","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;47<br/>Total Times Cited:&nbsp;&nbsp;47<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","Convolutional neural network (CNN); cross-attention; GRAPH CONVOLUTIONAL NETWORKS; hyperspectral image (HSI) classification; local spatial features; long sequence data; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TII86QQS","journalArticle","2021","Duan, GD; Yang, HB; Qin, K; Huang, TX","Improving Neural Machine Translation Model with Deep Encoding Information","COGNITIVE COMPUTATION","","1866-9956","10.1007/s12559-021-09860-7","","Availability of very high computational power along with the development of deep neural network (DNN) technology has enabled rapid progress of machine translation technology. The powerful representation ability of the deep neural network also enables the neural machine translation technology (NMT) to exploit the available large-scale bilingual parallel corpus as well as the computing power to provide a highly effective translation model. Nevertheless, the existing neural machine translation models only utilize the top layer encoder information, whereas the information available in deeper encoding layers is often ignored. This significantly constrains the performance of the translation model. To address this issue, in this paper, we propose a novel neural machine translation model which can fully exploit the deep encoding information. The core idea is to use different ways of aggregating the information from different encoding layers. We further design three different aggregation strategies including parallel layer, multi-layer, and dynamic layer encoding information aggregations. Three translation models are correspondingly trained and compared with the baseline transformer model for the Chinese-to-English translation task. The experimental results indicate that the BLEU-4 score of the proposed model has been increased by 0.89 compared with that of the benchmark model. Experiments demonstrate the effectiveness of the proposed method.","2021-07","2025-02-26 20:41:51","2025-02-26 20:41:51","","972-980","","4","13","","","","","","","","","","English","","","","WOS:000650546500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","Deep encoding information; Deep neural network; Neural machine translation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JQDVJFHW","journalArticle","2025","Arya, RK; Jain, S; Chattopadhyay, P; Srivastava, R","HSIRMamba: An effective feature learning for hyperspectral image classification using residual Mamba","IMAGE AND VISION COMPUTING","","0262-8856","10.1016/j.imavis.2024.105387","","Deep learning models have recently demonstrated outstanding results in classifying hyperspectral images (HSI). The Transformer model is among the various deep learning models that have received increasing interest due to its superior ability to simulate the long-term dependence of spatial-spectral information in HSI. Due to its selfattention mechanism, the Transformer exhibits quadratic computational complexity, which makes it heavier than other models and limits its application in the processing of HSI. Fortunately, the newly developed state space model Mamba exhibits excellent computing effectiveness and achieves Transformer-like modeling capabilities. Therefore, we propose a novel enhanced Mamba-based model called HSIRMamba that integrates residual operations into the Mamba architecture by combining the power of Mamba and the residual network to extract the spectral properties of HSI more effectively. It also includes a concurrent dedicated block for spatial analysis using a convolutional neural network. HSIRMamba extracts more accurate features with low computational power, making it more powerful than transformer-based models. HSIRMamba was tested on three majorly used HSI Datasets-Indian Pines, Pavia University, and Houston 2013. The experimental results demonstrate that the proposed method achieves competitive results compared to state-of-the-art methods.","2025-02","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","154","","","","","","","","","","English","","","","WOS:001392850600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","Classification; CNN; Feature extraction; Hyperspectral image; Mamba; NETWORKS; REPRESENTATION; State space model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XKVAWU8E","journalArticle","2024","Dawood, K; Tursun, S","Optimized gap positions for improved leakage impedance in dry-type transformer design","RESULTS IN ENGINEERING","","2590-1230","10.1016/j.rineng.2024.102632","","The power and distribution transformers must be properly designed to operate in a variety of conditions and manufactured following all applicable international standards to provide a reliable energy supply to consumers. The transformer can fail if it is improperly designed, and it cannot withstand the short-circuit condition if the short-circuit current is not calculated properly. Short-circuit current can be easily calculated by evaluating the leakage impedance. Customers can also demand the transformer companies to increase or decrease the leakage impedance. This paper evaluates the effect of the gap's position in the four different sections of the high voltage winding on the leakage impedance of the two-winding transformer and proposes effective design options for minimizing the leakage impedance. The accuracy of the finite element models was also investigated using an experimental laboratory transformer model specially designed for optimizing the leakage impedance. The experimental and finite element methods results show that the leakage impedance can be changed to the desired value and limits and easily assessed by the finite element analysis technique. The results indicate that even with the same use of the winding and core material, there was a considerable difference in the leakage impedance for each of the conditions.","2024-09","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","23","","","","","","","","","","English","","","","WOS:001290444600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","Dry type transformer; Finite element analysis; Gaps; Leakage impedance; Numerical technique; Optimization; REACTANCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NFFJF2L6","journalArticle","2024","Ju, ZX; Wang, HB; Luo, JJ; Sun, FC","Enhancing human-robot communication with a comprehensive language-conditioned imitation policy for embodied robots in smart cities","COMPUTER COMMUNICATIONS","","0140-3664","10.1016/j.comcom.2024.04.029","","Integrating Embodied Robots into a smart city's networked system can significantly enhance the city's operational efficiency. These robots can be connected to the city's network, receiving and transmitting data in real time for enhancing human-robot communications. Language -conditioned robot behavior plays a vital role in executing complex tasks by associating human commands or instructions with perception and actions. However, most language -conditioned policy -related research is limited to specific datasets and cannot generalize across different environments. In this study, we propose a novel imitation learning framework tailored for language -conditioned robotic tasks. Our framework includes specialized encoders designed for various benchmarks and utilizes two distinct models: the Transformer and Diffusion models. We rigorously evaluate this framework in three different robotic environments. Our findings indicate that the framework consistently delivers superior performance across multiple domains. Notably, we observe that the Transformer model is particularly effective in managing tasks with long trajectories, whereas the Diffusion model demonstrates enhanced proficiency in generating trajectories from limited training datasets. Our approach showcases remarkable generalization capabilities across a range of tasks and achieves significantly higher success rates in task completion.","2024-06-01","2025-02-26 20:41:51","2025-02-26 20:41:51","","177-187","","","22","","","","","","","","","","English","","","","WOS:001239499200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Embodied robot; Human-robot communication; Imitation learning; Neural network; Smart city","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XFC254RE","journalArticle","2023","Kroll, A; Ranjan, S; Engqvist, MKM; Lercher, MJ","A general model to predict small molecule substrates of enzymes based on machine and deep learning","NATURE COMMUNICATIONS","","2041-1723","10.1038/s41467-023-38347-2","","For most proteins annotated as enzymes, it is unknown which primary and/or secondary reactions they catalyze. Experimental characterizations of potential substrates are time-consuming and costly. Machine learning predictions could provide an efficient alternative, but are hampered by a lack of information regarding enzyme non-substrates, as available training data comprises mainly positive examples. Here, we present ESP, a general machine-learning model for the prediction of enzyme-substrate pairs with an accuracy of over 91% on independent and diverse test data. ESP can be applied successfully across widely different enzymes and a broad range of metabolites included in the training data, outperforming models designed for individual, well-studied enzyme families. ESP represents enzymes through a modified transformer model, and is trained on data augmented with randomly sampled small molecules assigned as non-substrates. By facilitating easy in silico testing of potential substrates, the ESP web server may support both basic and applied science. For many enzymes, it is unknown which primary and/or secondary reactions they catalyze. Here, the authors use machine and deep learning to develop a general model for the prediction of enzyme-small molecule substrate pairs and make the resulting model available through a webserver.","2023-05-15","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","1","14","","","","","","","","","","English","","","","WOS:000994445900012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;57<br/>Total Times Cited:&nbsp;&nbsp;59<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","PROMISCUITY; RESOURCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RIZRR4V4","journalArticle","2022","Wang, H; Zang, YJ; Zhao, YZ; Hao, DX; Kang, Y; Zhang, JW; Zhang, ZC; Zhang, L; Yang, ZW; Zhang, SL","Sequence Matching between Hemagglutinin and Neuraminidase through Sequence Analysis Using Machine Learning","VIRUSES-BASEL","","1999-4915","10.3390/v14030469","","To date, many experiments have revealed that the functional balance between hemagglutinin (HA) and neuraminidase (NA) plays a crucial role in viral mobility, production, and transmission. However, whether and how HA and NA maintain balance at the sequence level needs further investigation. Here, we applied principal component analysis and hierarchical clustering analysis on thousands of HA and NA sequences of A/H1N1 and A/H3N2. We discovered significant coevolution between HA and NA at the sequence level, which is closely related to the type of host species and virus epidemic years. Furthermore, we propose a sequence-to-sequence transformer model (S2STM), which mainly consists of an encoder and a decoder that adopts a multi-head attention mechanism for establishing the mapping relationship between HA and NA sequences. The training results reveal that the S2STM can effectively realize the ""translation"" from HA to NA or vice versa, thereby building a relationship network between them. Our work combines unsupervised and supervised machine learning methods to identify the sequence matching between HA and NA, which will advance our understanding of IAVs' evolution and also provide a novel idea for sequence analysis methods.","2022-03","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","3","14","","","","","","","","","","English","","","","WOS:000774335300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","FUNCTIONAL BALANCE; hemagglutinin; influenza A viruses; INFLUENZA-A VIRUSES; machine learning; neuraminidase; sequence analysis; viral evolution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BIERNZ8W","journalArticle","2024","Li, J; Wang, ZL; Zhang, SY; Lin, YC; Jiang, LF; Tan, JR","Task incremental learning-driven Digital-Twin predictive modeling for customized metal forming product manufacturing process","ROBOTICS AND COMPUTER-INTEGRATED MANUFACTURING","","0736-5845","10.1016/j.rcim.2023.102647","","Customized metal forming products entail personalized requirements in terms of dimensions, materials, and other specifications, while the processing conditions involved are subject to dynamic changes. Digital-Twin (DT) predictive models have become essential tools for optimizing the complex manufacturing process. However, the traditional approach exhibits limitations in handling dynamic data, capturing complex nonlinear relationships, and leveraging multi-source information. Additionally, retraining predictive models for novel tasks with unique operating conditions in specific scenarios can lead to substantial time and resource inefficiencies. Therefore, a task incremental learning-based approach for DT predictive modeling is proposed in this paper. Firstly, a DT framework and a comprehensive information model are established for real-time monitoring and integration of multi-source information. Moreover, the pre-trained Temporal Fusion Transformer model is utilized to capture valuable knowledge from historical tasks. Subsequently, task incremental learning is adopted to fine-tune the model using new task data, thereby enhancing adaptability and enabling rapid and scalable modeling. Finally, the effectiveness of the proposed method is validated on a customized metal tube bending forming platform, demonstrating accurate prediction of tube cross-section deformation.","2024-02","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","85","","","","","","","","","","English","","","","WOS:001082432500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;64<br/>Total Times Cited:&nbsp;&nbsp;64<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","custom product manufacturing; DESIGN; Digital -Twin; metal forming; predictive modeling; SYSTEM; task incremental learning; Temporal Fusion Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JQTBILSD","journalArticle","2023","Khalid, H; Murtaza, G; Abbas, Q","Using Data Augmentation and Bidirectional Encoder Representations from Transformers for Improving Punjabi Named Entity Recognition","ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING","","2375-4699","10.1145/3595861","","Named entity recognition (NER) is a task of proper noun identification from natural language text and classification into various types such as location, person, and organization. Due to NER's applications in different natural language processing (NLP) tasks, numerous NER approaches and benchmark datasets have been proposed. However, developing NER techniques for low-resource languages is still limited due to the absence of substantial training datasets. Punjabi is a classic example of low resource language. Although various researchers have worked on Punjabi, they focused on the Gurmukhi script. To overcome the challenges in developing NER for the Shahmukhi script, we present an improved technique for Punjabi NER for the Shahmukhi script in this paper. We firstly extend the existing dataset by adding new NER classes by leveraging a novel Pool of Words data augmentation strategy. Our extended dataset has 11,31,509 tokens and 1,25,789 labeled entities with more named entities (NEs) than the older dataset. In the next step, we fine-tuned a transformer model known as Bidirectional Encoder Representations from Transformers (BERT) for the NER task. We performed experiments using the proposed approach on a new and older dataset version, showing that our method achieved competitive results.","2023-06","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","6","22","","","","","","","","","","English","","","","WOS:001018562700025","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Asian languages; low-resource languages; named entity recognition; Punjabi; Shahmukhi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JSUFB3CJ","journalArticle","2023","Song, HT; Zhang, H; Wang, TY; Li, JJ; Wang, ZK; Ji, HY; Chen, YJ","Skip-RCNN: A Cost-Effective Multivariate Time Series Forecasting Model","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3340698","","Multivariate time series (MTS) forecasting is a crucial aspect in many classification and regression tasks. In recent years, deep learning models have become the mainstream framework for MTS forecasting. Among these deep learning methods, the transformer model has been proved particularly effective due to its ability to capture long- and short-term dependencies. However, the computational complexity of transformer-based models sets the obstacles for resource-constrained scenarios. To address this challenge, we propose a novel and efficient Skip-RCNN network that incorporates Skip-RNN and Skip-CNN modules to split the MTS into multiple frames with various time intervals. Thanks to the skipping process of Skip-RNN and Skip-CNN, the resulting network could process information with different reception field together and achieves better performance than the state-of-the-art network. We conducted comparative experiments using our proposed method and six baseline models on seven publicly available datasets. The results demonstrate that our model outperforms other baseline methods in accuracy under most conditions and surpasses the transformer-based model with 0.098 for a short interval and 0.068 for a long interval. Our Skip-RCNN network presents a promising approach to MTS forecasting that can meet the demands of resource-constrained prediction scenarios.","2023","2025-02-26 20:41:51","2025-02-26 20:41:51","","142087-142099","","","11","","","","","","","","","","English","","","","WOS:001127107300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","ANOMALY DETECTION; Deep learning; feature fusion; LSTM; multivariate time series forecasting; NETWORK","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QB37L5WN","journalArticle","2023","Zhang, Z; Huang, X; Li, JY","DWin-HRFormer: A High-Resolution Transformer Model With Directional Windows for Semantic Segmentation of Urban Construction Land","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2023.3241366","","In this article, a deep neural network for semantic segmentation of high-resolution remote sensing images is proposed for urban construction land classification. The network follows a high-resolution network (HRNet) architecture. Specifically, a directional self-attention on the paths of different resolutions is proposed, aiming to correct the directional bias caused by the attention of strip windows during the model learning, while also reducing the computational complexity, and allowing the model to improve both the accuracy and the speed. At the end of the network, a distributed alignment module with spatial information is constructed to train additional learnable parameters, to adjust the biased decision boundaries through a two-stage learning strategy, and alleviate the problem of accuracy degradation due to the unbalanced training data. We tested the proposed method and compared it with the current state-of-the-art (SOTA) semantic segmentation methods on the Luojia-fine-grained land cover (FGLC) dataset and the Wuhan Dense Labeling Dataset (WHDLD), and the proposed one obtained the best performance. We also verified the effectiveness of each component of the network through ablation experiments.","2023","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","61","","","","","","","","","","English","","","","WOS:000935399000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;18<br/>Total Times Cited:&nbsp;&nbsp;18<br/>Cited Reference Count:&nbsp;&nbsp;86</p>","","","Computational modeling; Deep learning; GROWTH; IMAGES; Monitoring; Remote sensing; remote sensing imagery; semantic segmentation; Semantic segmentation; SMOTE; Task analysis; transformer; Transformers; urban construction land; Windows","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GLFRWNIP","journalArticle","2025","Goshayesh, N; Rajabi, R; Kuhestani, A; Keshavarzi, M; Ahmadi, H","Intelligent secure transmission in untrusted relaying systems with hardware impairments","PHYSICAL COMMUNICATION","","1874-4907","10.1016/j.phycom.2024.102583","","Ensuring secure communication in wireless networks remains a significant challenge, especially in the presence of untrusted relays. This study addresses this challenge by employing an intelligent Transmit Antenna Selection (TAS) technique, integrated with machine learning (ML) and deep learning (DL) models, including the Transformer architecture, to optimize secure transmission over Rician fading channels with hardware impairments (HWIs). Simulation results demonstrate that the Transformer-based model achieves state-of-theart performance, consistently surpassing traditional ML models in classification accuracy and security metrics. Specifically, the Transformer achieves an average Area Under the Curve (AUC) of 0.90 and classification accuracy of 83.5%, significantly outperforming the Support Vector Machine (SVM) (AUC: 0.87, accuracy: 41.5%),k-nearest Neighbors (KNN) (AUC: 0.69, accuracy: 46%), and Naive Bayes (NB) (AUC: 0.53, accuracy: 18%). Furthermore, the Transformer model approximates the performance of exhaustive search methods in terms of average secrecy rate and secrecy outage probability, highlighting its ability to capture complex dependencies and adapt to diverse scenarios. These findings establish the Transformer as a robust and scalable solution for secure communication in challenging wireless environments, paving the way for future advancements in physical layer security (PLS) and intelligent TAS strategies.","2025-02","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","68","","","","","","","","","","English","","","","WOS:001390439700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","CHANNEL ESTIMATION; DESIGN; FACE; Hardware impairments (HWIs); INTERNET; MASSIVE MIMO SYSTEMS; NETWORKS; Physical layer security (PLS); SELECTION; Transformer; Transmit antenna selection (TAS)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XZTAII54","journalArticle","2025","Sa, J; Ryu, J; Kim, H","ECTFormer: An efficient Conv-Transformer model design for image recognition","PATTERN RECOGNITION","","0031-3203","10.1016/j.patcog.2024.111092","","Since the success of Vision Transformers (ViTs), there has been growing interest in combining ConvNets and Transformers in the computer vision community. While the hybrid models have demonstrated state-of-the-art performance, many of these models are too large and complex to be applied to edge devices for real-world applications. To address this challenge, we propose an efficient hybrid network called ECTFormer that leverages the strengths of ConvNets and Transformers while considering both model performance and inference speed. Specifically, our approach involves: (1) optimizing the combination of convolution kernels by dynamically adjusting kernel sizes based on the scale of feature tensors; (2) revisiting existing overlapping patchify to not only reduce the model size but also propagate fine-grained patches for the performance enhancement; and (3) introducing an efficient single-head self-attention mechanism, rather than multi-head self-attention in the base Transformer, to minimize the increase in model size and boost inference speed, overcoming bottlenecks of ViTs. In experimental results on ImageNet-1K, ECTFormer not only demonstrates comparable or higher top-1 accuracy but also faster inference speed on both GPUs and edge devices compared to other efficient networks.","2025-03","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","159","","","","","","","","","","English","","","","WOS:001349616400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Conv-Transformer network; Dynamic kernel sizes; Efficient overlapping patchify; Efficient self-attention mechanism; Lightweight architecture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W67IHKQH","journalArticle","2024","Chen, H; Xu, RH; Huang, H; Ke, XK; Du, H; Li, YZ; Huang, QF; Su, JS","Modeling and optimization of electro-mechanical converter for high-speed on/off valve based on Cauer circuits","ELECTRICAL ENGINEERING","","0948-7921","10.1007/s00202-024-02740-x","","In this paper, an equivalent circuit model of electro-mechanical converter (EMC) is developed using Cauer circuits, which can be used to improve the response speed of high-speed switching valves (HSVs), and this model can replace the transient analysis method of finite element model with high computational cost and the traditional magnetic circuit model that cannot accurately reflect the eddy current and skinning effect of coils. For EMC with high-frequency operation, the Cauer circuit can be used to describe the eddy currents on the physical layer and the skinning effect of the soft magnetic material. In this paper, a multi-field coupled EMC trapezoidal circuit simulation model is developed, and the reliability of the model is verified by experiments. The model can be used to analyze the energy consumption in order to identify the main optimized components of the EMC, and the genetic algorithm is selected as the optimization method to improve the structure, which leads to the reduction of eddy current losses and the improvement of the overall dynamic response of the EMC.","2024-09-27","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","","","","","","","","","","","English","","","","WOS:001321642100003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","Cauer circuits; Duality theorem; EDDY-CURRENT LOSSES; Electro-mechanical converter (EMC); High-speed on/off valve (HSV); MID-FREQUENCY TRANSIENTS; Structural optimization; SYSTEM; TRANSFORMER MODEL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MYB5DZUW","journalArticle","2024","Baroni, GL; Rasotto, L; Roitero, K; Tulisso, A; Di Loreto, C; Della Mea, V","Optimizing Vision Transformers for Histopathology: Pretraining and Normalization in Breast Cancer Classification","JOURNAL OF IMAGING","","2313-433X","10.3390/jimaging10050108","","This paper introduces a self-attention Vision Transformer model specifically developed for classifying breast cancer in histology images. We examine various training strategies and configurations, including pretraining, dimension resizing, data augmentation and color normalization strategies, patch overlap, and patch size configurations, in order to evaluate their impact on the effectiveness of the histology image classification. Additionally, we provide evidence for the increase in effectiveness gathered through geometric and color data augmentation techniques. We primarily utilize the BACH dataset to train and validate our methods and models, but we also test them on two additional datasets, BRACS and AIDPATH, to verify their generalization capabilities. Our model, developed from a transformer pretrained on ImageNet, achieves an accuracy rate of 0.91 on the BACH dataset, 0.74 on the BRACS dataset, and 0.92 on the AIDPATH dataset. Using a model based on the prostate small and prostate medium HistoEncoder models, we achieve accuracy rates of 0.89 and 0.86, respectively. Our results suggest that pretraining on large-scale general datasets like ImageNet is advantageous. We also show the potential benefits of using domain-specific pretraining datasets, such as extensive histopathological image collections as in HistoEncoder, though not yet with clear advantages.","2024-05","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","5","10","","","","","","","","","","English","","","","WOS:001232972700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","breast cancer; DATA-EFFICIENT; deep learning; histology; normalization; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NH5A3FP7","journalArticle","2024","Sun, QY; Zhang, J; Fang, ZJ; Gao, YB","Self-Enhanced Attention for Image Captioning","NEURAL PROCESSING LETTERS","","1370-4621","10.1007/s11063-024-11527-x","","Image captioning, which involves automatically generating textual descriptions based on the content of images, has garnered increasing attention from researchers. Recently, Transformers have emerged as the preferred choice for the language model in image captioning models. Transformers leverage self-attention mechanisms to address gradient accumulation issues and eliminate the risk of gradient explosion commonly associated with RNN networks. However, a challenge arises when the input features of the self-attention mechanism belong to different categories, as it may result in ineffective highlighting of important features. To address this issue, our paper proposes a novel attention mechanism called Self-Enhanced Attention (SEA), which replaces the self-attention mechanism in the decoder part of the Transformer model. In our proposed SEA, after generating the attention weight matrix, it further adjusts the matrix based on its own distribution to effectively highlight important features. To evaluate the effectiveness of SEA, we conducted experiments on the COCO dataset, comparing the results with different visual models and training strategies. The experimental results demonstrate that when using SEA, the CIDEr score is significantly higher compared to the scores obtained without using SEA. This indicates the successful addressing of the challenge of effectively highlighting important features with our proposed mechanism.","2024-04-01","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","2","56","","","","","","","","","","English","","","","WOS:001195375700003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Attention mechanism; CIDEr score; Image captioning; Language model; Visual model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9HRU3I7G","journalArticle","2023","Wang, DY; Zhang, BC; Xu, YS; Luo, YG; Yu, HY","SQ-Swin: Siamese Quadratic Swin Transformer for Lettuce Browning Prediction","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3332488","","Enzymatic browning is a major quality defect of packaged ""ready-to-eat"" fresh-cut lettuce salads. While there have been many research and breeding efforts to counter this problem, progress is hindered by the lack of a technology to identify and quantify browning rapidly, objectively, and reliably. Here, we report a deep learning model for lettuce browning score prediction. To the best of our knowledge, it is the first-of-its-kind on deep learning for lettuce browning prediction using a Siamese Quadratic Swin (SQ-Swin) transformer with several highlights. First, our model includes quadratic features in the transformer model which is more powerful to incorporate real world representations than the linear transformer. Second, a multi-scale training strategy is employed to augment the data and explore more of the inherent self-similarity of the lettuce images. Third, the proposed model uses a siamese architecture which learns the inter-relations among the limited training samples. Fourth, the model is pretrained on the ImageNet and then trained with the reptile meta-learning algorithm to learn higher-order gradients than a regular one. Experiment results on the fresh-cut lettuce datasets show that the proposed SQ-Swin outperforms the traditional methods and other deep learning-based backbones.","2023","2025-02-26 20:41:51","2025-02-26 20:41:51","","128724-128735","","","11","","","","","","","","","","English","","","","WOS:001106516000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","enzymatic browning; Lettuce; NEURAL-NETWORKS; quadratic; reptile; siamese model; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BFWNT96J","journalArticle","2023","Thai, HT; Le, KH; Nguyen, NLT","FormerLeaf: An efficient vision transformer for Cassava Leaf Disease detection","COMPUTERS AND ELECTRONICS IN AGRICULTURE","","0168-1699","10.1016/j.compag.2022.107518","","Leaf diseases have become more prevalent in recent years due to climate change, increased growth of outdoor air pollutants, and global warming. They may severely damage crop yield, leading to detrimental effects on global food security. The timely and precise detection of leaf diseases is thus crucial for preventing their spread and ensuring the sustainability of agricultural production. In this paper, we introduce a transformer-based leaf disease detection model, namely FormerLeaf along with two optimization methods to enhance the model performance. In more detail, we propose the Least Important Attention Pruning (LeIAP) algorithm to select the most important attention heads of each layer in the Transformer model. It could reduce the model size up to 28% and accelerate the evaluation speed by 15% with about 3% accuracy enhancement. In addition, we employ the sparse matrix-matrix multiplication (SPMM) to calculate matrix correlation in the model. This reduces the model's complexity from O(n2) to O(n2 ), resulting in lowering training time by 10% while keeping a similar performance. The evaluation results on the Cassava Leaf Disease Dataset show that our proposal outperforms the state-of-the-art models in most cases.","2023-01","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","204","","","","","","","","","","English","","","","WOS:000900074100004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;62<br/>Total Times Cited:&nbsp;&nbsp;64<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","Deep learning; Efficient vision transformer; IDENTIFICATION; Image classification; Leaf Disease detection; NEURAL-NETWORK; Precision agriculture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I4FWS66Z","journalArticle","2022","Lihua, Z","Analysis of English Translation Model Based on Artificial Intelligence Attention Mechanism","MATHEMATICAL PROBLEMS IN ENGINEERING","","1024-123X","10.1155/2022/9669152","","The particularity and quantity of English translation terms have a great impact on the quality and e,ect of machine translation and can not meet the requirements of English translation of terms. At the same time, technical exchange and communication in di,erent,elds need the expression of professional terms. In addition, although the neural machine translation model has good translation performance, it is not ideal for target languages with small translation needs and limited corpus resources. In order to solve the problems existing in the English translation model, this paper constructs the transformer model by replacing the cyclic neural network variables and introducing the attention mechanism. The term information is integrated into two pretraining models to improve the learning ability of model language sentence relationship. Maintain the integrity of terminology information by fully completing the training. The experimental results show that, compared with the other three term translation models, the translation model in this paper has the advantage of term information. At the same time, the deep neural network English term translation model can obtain more,ne-grained word relevance. In di,erent corpora, the Bleu score of the model is good, showing obvious translation performance advantages. This study provides a good professional reference value for the translation of English terms.","2022-07-06","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","2022","","","","","","","","","","English","","","","WOS:000880579500021","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CHVQ7SIT","journalArticle","2024","Tong, HZ; Kong, LY; Liu, J; Gao, SY; Xu, YL; Chen, YZ","Segmented Frequency-Domain Correlation Prediction Model for Long-Term Time Series Forecasting Using Transformer","IET SOFTWARE","","1751-8806","10.1049/2024/2920167","","Long-term time series forecasting has received significant attention from researchers in recent years. Transformer model-based approaches have emerged as promising solutions in this domain. Nevertheless, most existing methods rely on point-by-point self-attention mechanisms or employ transformations, decompositions, and reconstructions of the entire sequence to capture dependencies. The point-by-point self-attention mechanism becomes impractical for long-term time series forecasting due to its quadratic complexity with respect to the time series length. Decomposition and reconstruction methods may introduce information loss, leading to performance bottlenecks in the models. In this paper, we propose a Transformer-based forecasting model called NPformer. Our method introduces a novel multiscale segmented Fourier attention mechanism. By segmenting the long-term time series and performing discrete Fourier transforms on different segments, we aim to identify frequency-domain correlations between these segments. This allows us to capture dependencies more effectively. In addition, we incorporate a normalization module and a desmoothing factor into the model. These components address the problem of oversmoothing that arises in sequence decomposition methods. Furthermore, we introduce an isometry convolution method to enhance the prediction accuracy of the model. The experimental results demonstrate that NPformer outperforms other Transformer-based methods in long-term time series forecasting.","2024-07-08","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","2024","","","","","","","","","","English","","","","WOS:001273058500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SAZMA44J","journalArticle","2024","Shehzad, A; Rui, XT; Ding, YY; Chang, Y; Zhang, JS; Lu, HJ; Chen, YH","Tool-tip vibration prediction based on a novel convolutional enhanced transformer","INTERNATIONAL JOURNAL OF MECHANICAL SYSTEM DYNAMICS","","2767-1399","10.1002/msd2.12096","","Superior surface finish remains a fundamental criterion in precision machining operations, and tool-tip vibration is an important factor that significantly influences the quality of the machined surface. Physics-based models heavily rely on assumptions for model simplification when applied to complex high-end systems. However, these assumptions may come at the cost of compromising the model's accuracy. In contrast, data-driven techniques have emerged as an attractive alternative for tasks such as prediction and complex system analysis. To exploit the advantages of data-driven models, this study introduces a novel convolutional enhanced transformer model for tool-tip vibration prediction, referred to as CeT-TV. The effectiveness of this model is demonstrated through its successful application in ultra-precision fly-cutting (UPFC) operations. Two distinct variants of the model, namely, guided and nonguided CeT-TV, were developed and rigorously tested on a data set custom-tailored for UPFC applications. The results reveal that the guided CeT-TV model exhibits outstanding performance, characterized by the lowest mean absolute error and root mean square error values. Additionally, the model demonstrates excellent agreement between the predicted values and the actual measurements, thus underlining its efficiency and potential for predicting the tool-tip vibration in the context of UPFC.","2024-03","2025-02-26 20:41:51","2025-02-26 20:41:51","","34-47","","1","4","","","","","","","","","","English","","","","WOS:001175392600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","data-driven modeling; ROUGHNESS; SURFACE GENERATION; tool-tip vibration; transformer; ultraprecision fly cutting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YSRX4ISY","journalArticle","2024","Deng, LJ; Liu, BY; Li, ZH","Multimodal Sentiment Analysis Based on a Cross-Modal Multihead Attention Mechanism","CMC-COMPUTERS MATERIALS & CONTINUA","","1546-2218","10.32604/cmc.2023.042150","","Multimodal sentiment analysis aims to understand people's emotions and opinions from diverse data. Concatenating or multiplying various modalities is a traditional multi-modal sentiment analysis fusion method. This fusion method does not utilize the correlation information between modalities. To solve this problem, this paper proposes a model based on a multi-head attention mechanism. First, after preprocessing the original data. Then, the feature representation is converted into a sequence of word vectors and positional encoding is introduced to better understand the semantic and sequential information in the input sequence. Next, the input coding sequence is fed into the transformer model for further processing and learning. At the transformer layer, a cross-modal attention consisting of a pair of multi-head attention modules is employed to reflect the correlation between modalities. Finally, the processed results are input into the feedforward neural network to obtain the emotional output through the classification layer. Through the above processing flow, the model can capture semantic information and contextual relationships and achieve good results in various natural language processing tasks. Our model was tested on the CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI) and Multimodal EmotionLines Dataset (MELD), achieving an accuracy of 82.04% and F1 parameters reached 80.59% on the former dataset.","2024","2025-02-26 20:41:51","2025-02-26 20:41:51","","1157-1170","","1","78","","","","","","","","","","English","","","","WOS:001186529000010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","cross-modal attention mechanism; deep learning; Emotion analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2NHVW839","journalArticle","2024","Fang, X; Yang, H; Ding, D; Gao, WB; Zhang, L; Wang, YL; Shi, L","Enhancing App Usage Prediction Accuracy With GCN-Transformer Model and Meta-Path Context","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3372397","","In this paper, we introduce MP-GT, a novel Graph Neural Network model that leverages meta-path-guided optimization within the GCN-Transformer framework to enhance application (App) usage prediction accuracy. Our approach addresses issues such as suspended animation and over-smoothing by extracting both local subgraph structures and global graph structures using a combination of GCN and Transformer method. Furthermore, we enhance the capture of semantic information and App usage patterns by incorporating a meta path-guided objective function. Extensive experiments demonstrate that MP-GT outperforms the widely adopted baseline of semantic-aware representation learning via Graph Convolutional Network (SA-GCN) by 13.33% in terms of Accuracy@1. Additionally, MP-GT surpasses the popular baseline of context-aware App usage prediction with heterogeneous graph embedding (CAP) by 74.02% in the same metric. Moreover, MP-GT reduces training time by 79.47% compared to SA-GCN. These findings validate that our approach not only achieves higher prediction accuracy but also converges faster than the baseline models. Therefore, MP-GT proves to be an effective and superior solution for the App usage prediction task.","2024","2025-02-26 20:41:51","2025-02-26 20:41:51","","53031-53044","","","12","","","","","","","","","","English","","","","WOS:001204858600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","application usage modeling; Convolutional neural networks; GCN-transformer; Graph neural networks; Heterogeneous graph embedding; Linear programming; meta-path optimization; Optimization methods; Predictive models; Representation learning; Semantics; Usability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"78FAFW33","journalArticle","2024","Yang, JD; Wang, Y","Toward Auto-Modeling of Formal Verification for NextG Protocols: A Multimodal Cross- and Self-Attention Large Language Model Approach","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3366803","","This paper introduces Auto-modeling of Formal Verification with Real-world Prompting for 5G and NextG protocols (AVRE), a novel system designed for the formal verification of Next Generation (NextG) communication protocols, addressing the increasing complexity and scalability challenges in network protocol design and verification. Utilizing Large Language Models (LLMs), AVRE transforms protocol descriptions into dependency graphs and formal models, efficiently resolving ambiguities and capturing design intent. The system integrates a transformer model with LLMs to autonomously establish quantifiable dependency relationships through cross- and self-attention mechanisms. Enhanced by iterative feedback from the HyFuzz experimental platform, AVRE significantly advances the accuracy and relevance of formal verification in complex communication protocols, offering a groundbreaking approach to validating sophisticated communication systems. We compare CAL's performance with state-of-the-art LLM-based models and traditional time sequence models, demonstrating its superiority in accuracy and robustness, achieving an accuracy of 95.94% and an AUC of 0.98. This NLP-based approach enables, for the first time, the creation of exploits directly from design documents, making remarkable progress in scalable system verification and validation.","2024","2025-02-26 20:41:51","2025-02-26 20:41:51","","27858-27869","","","12","","","","","","","","","","English","","","","WOS:001173185600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","5G mobile communication; Complexity theory; cross-attention; formal flow graph; Formal verification; Iterative methods; Natural language processing; natural language protocol; Natural languages; Protocols; self-attention; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EWXGMWBZ","journalArticle","2023","Peng, B; Ding, YM; Kang, W","Metaformer: A Transformer That Tends to Mine Metaphorical-Level Information","SENSORS","","1424-8220","10.3390/s23115093","","Since introducing the Transformer model, it has dramatically influenced various fields of machine learning. The field of time series prediction has also been significantly impacted, where Transformer family models have flourished, and many variants have been differentiated. These Transformer models mainly use attention mechanisms to implement feature extraction and multi-head attention mechanisms to enhance the strength of feature extraction. However, multi-head attention is essentially a simple superposition of the same attention, so they do not guarantee that the model can capture different features. Conversely, multi-head attention mechanisms may lead to much information redundancy and computational resource waste. In order to ensure that the Transformer can capture information from multiple perspectives and increase the diversity of its captured features, this paper proposes a hierarchical attention mechanism, for the first time, to improve the shortcomings of insufficient information diversity captured by the traditional multi-head attention mechanisms and the lack of information interaction among the heads. Additionally, global feature aggregation using graph networks is used to mitigate inductive bias. Finally, we conducted experiments on four benchmark datasets, and the experimental results show that the proposed model can outperform the baseline model in several metrics.","2023-05-26","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","11","23","","","","","","","","","","English","","","","WOS:001006287300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","feature diversity; graph neural networks; hierarchical attention; information interaction; MODEL; multi-head attention","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U23ZC5KF","journalArticle","2022","Georg, R; Chadwick, AR; Dally, BB; Herdrich, G","Model for Estimating Time-Varying Properties of an Inductively Coupled Plasma","IEEE TRANSACTIONS ON PLASMA SCIENCE","","0093-3813","10.1109/TPS.2022.3166162","","A developing application of inductively coupled plasmas is in the field of electrodeless (propellant-flexible) electric propulsion. A significant issue facing this application is the need for diagnostic techniques that do not disturb the plasma (are nonintrusive), are propellant-agnostic, can resolve time variance, and are suitable for use in-flight. A new technique meeting these criteria is presented in this work. The technique makes use of the transformer model of inductive coupling to estimate the plasma impedance from the antenna current and resonant frequency, both of which can be measured nonintrusively. Having an estimate of the plasma impedance, it is possible to estimate a variety of plasma properties under the assumption of a uniform tubular plasma volume. Starting with a circuit representation of a high-power inductive plasma source, governing equations are derived and a solution method is described. Experimental data from the plasma source showing transient behavior (fluctuations within 300-Hz cycle) in oxygen plasmas with various input powers and flow rates are analyzed to demonstrate the technique and investigate trends. The technique produces results that are self-consistent and align well with previous theoretical work.","2022-05","2025-02-26 20:41:51","2025-02-26 20:41:51","","1227-1236","","5","50","","","","","","","","","","English","","","","WOS:000788968900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","Aerospace propulsion; Antenna measurements; Electron tubes; impedance; Impedance; Inductance; Integrated circuit modeling; oxygen; plasma diagnostics; plasma properties; Plasmas; Propulsion; PROPULSION SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"87M96BVF","journalArticle","2024","Fan, N; Lai, FP","Patch-Transformer Modeling for Production Forecasting in Tight Gas Reservoirs: A Case Study of the Yan'an Field","ENERGY & FUELS","","0887-0624","10.1021/acs.energyfuels.4c05443","","Accurate prediction of production rates in fractured horizontal gas wells is crucial for optimizing development strategies in tight gas reservoirs. Traditional prediction methods, such as decline curve analysis, often rely on simplifying assumptions, making it challenging to capture the complex nonlinear dynamics of tight gas production. Consequently, prediction accuracy remains limited even with extensive historical data. This study introduces a novel production forecasting model based on the Patch-Transformer architecture, leveraging five readily available production parameters: the daily production time, wellhead pressure, wellhead temperature, daily water production, and daily gas production. The model captures both local and global temporal dependencies by segmenting the data into patches, thereby enhancing the predictive accuracy. The model was trained and tested using production data from 37 fractured horizontal wells in the Yan'an gas field. The model achieved an average R 2 of 0.9984 on the training set and 0.9932 on the test set, demonstrating exceptional predictive accuracy. The Patch-Transformer model effectively captures the complex temporal dependencies and nonlinear relationships in production data, making it a powerful tool for forecasting gas well performance. By providing accurate predictions, this model has the potential to significantly enhance production optimization, decision-making, and resource management in tight gas reservoir development, ultimately leading to improved productivity.","2024-12-24","2025-02-26 20:41:51","2025-02-26 20:41:51","","432-443","","1","39","","","","","","","","","","English","","","","WOS:001382651800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9Z42E8BT","journalArticle","2024","Yin, JQ; Reshniak, V; Liu, SY; Zhang, GN; Wang, XP; Xiao, ZC; Morgan, Z; Pawledzio, S; Proffen, T; Hoffmann, C; Cao, HB; Chakoumakos, BC; Liu, YH","Integrated edge-to-exascale workflow for real-time steering in neutron scattering experiments","STRUCTURAL DYNAMICS-US","","2329-7778","10.1063/4.0000279","","We introduce a computational framework that integrates artificial intelligence (AI), machine learning, and high-performance computing to enable real-time steering of neutron scattering experiments using an edge-to-exascale workflow. Focusing on time-of-flight neutron event data at the Spallation Neutron Source, our approach combines temporal processing of four-dimensional neutron event data with predictive modeling for multidimensional crystallography. At the core of this workflow is the Temporal Fusion Transformer model, which provides voxel-level precision in predicting 3D neutron scattering patterns. The system incorporates edge computing for rapid data preprocessing and exascale computing via the Frontier supercomputer for large-scale AI model training, enabling adaptive, data-driven decisions during experiments. This framework optimizes neutron beam time, improves experimental accuracy, and lays the foundation for automation in neutron scattering. Although real-time experiment steering is still in the proof-of-concept stage, the demonstrated potential of this system offers a substantial reduction in data processing time from hours to minutes via distributed training, and significant improvements in model accuracy, setting the stage for widespread adoption across neutron scattering facilities and more efficient exploration of complex material systems. (c) 2024 Author(s). All article content, except where otherwise noted, is licensed under a Creative Commons Attribution (CC BY) license","2024-11","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","6","11","","","","","","","","","","English","","","","WOS:001386142500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","BRAGG PEAKS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UYEUTAYQ","journalArticle","2024","Ren, KY; Yan, T; Hu, ZX; Han, HG; Zhang, YL","Image attention transformer network for indoor 3D object detection","SCIENCE CHINA-TECHNOLOGICAL SCIENCES","","1674-7321","10.1007/s11431-023-2552-x","","Point clouds and RGB images are both critical data for 3D object detection. While recent multi-modal methods combine them directly and show remarkable performances, they ignore the distinct forms of these two types of data. For mitigating the influence of this intrinsic difference on performance, we propose a novel but effective fusion model named LI-Attention model, which takes both RGB features and point cloud features into consideration and assigns a weight to each RGB feature by attention mechanism. Furthermore, based on the LI-Attention model, we propose a 3D object detection method called image attention transformer network (IAT-Net) specialized for indoor RGB-D scene. Compared with previous work on multi-modal detection, IAT-Net fuses elaborate RGB features from 2D detection results with point cloud features in attention mechanism, meanwhile generates and refines 3D detection results with transformer model. Extensive experiments demonstrate that our approach outperforms state-of-the-art performance on two widely used benchmarks of indoor 3D object detection, SUN RGB-D and NYU Depth V2, while ablation studies have been provided to analyze the effect of each module. And the source code for the proposed IAT-Net is publicly available at https://github.com/wisper181/IAT-Net.","2024-07","2025-02-26 20:41:51","2025-02-26 20:41:51","","2176-2190","","7","67","","","","","","","","","","English","","","","WOS:001257463900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","3D object detection; attention mechanism; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZMGI35ZJ","journalArticle","2024","Sugimoto, T; Taniguchi, N; Yoshikura, R; Kawaguchi, H; Izumi, S","Evaluation of Patients' Levels of Walking Independence Using Inertial Sensors and Neural Networks in an Acute-Care Hospital","BIOENGINEERING-BASEL","","2306-5354","10.3390/bioengineering11060544","","This study aimed to evaluate walking independence in acute-care hospital patients using neural networks based on acceleration and angular velocity from two walking tests. Forty patients underwent the 10-m walk test and the Timed Up-and-Go test at normal speed, with or without a cane. Physiotherapists divided the patients into two groups: 24 patients who were monitored or independent while walking with a cane or without aids in the ward, and 16 patients who were not. To classify these groups, the Transformer model analyzes the left gait cycle data from eight inertial sensors. The accuracy using all the sensor data was 0.836. When sensor data from the right ankle, right wrist, and left wrist were excluded, the accuracy decreased the most. When analyzing the data from these three sensors alone, the accuracy was 0.795. Further reducing the number of sensors to only the right ankle and wrist resulted in an accuracy of 0.736. This study demonstrates the potential of a neural network-based analysis of inertial sensor data for clinically assessing a patient's level of walking independence.","2024-06","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","6","11","","","","","","","","","","English","","","","WOS:001254627200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","10-m walk test; inertial sensor; level of walking independence; neural network; timed up-and-go test","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5P6X63FW","journalArticle","2024","Zhou, ZP; Liu, BW; Yuan, CJ; Zhang, P","A Multimodal Trajectory Prediction Method for Pedestrian Crossing Considering Pedestrian Motion State","IEEE INTELLIGENT TRANSPORTATION SYSTEMS MAGAZINE","","1939-1390","10.1109/MITS.2023.3331817","","Predicting pedestrian crossing trajectories has become a primary task in aiding autonomous vehicles to assess risks in pedestrian-vehicle interactions. As agile participants with changeable behavior, pedestrians are often capable of choosing from multiple possible crossing trajectories. Current research lacks the ability to predict multimodal trajectories with interpretability, and it also struggles to capture low-probability trajectories effectively. Addressing this gap, this article proposes a multimodal trajectory prediction model that operates by first estimating potential motion trends to prompt the generation of corresponding trajectories. It encompasses three sequential stages. First, pedestrian motion characteristics are analyzed, and prior knowledge of pedestrian motion states is obtained using the Gaussian mixture clustering method. Second, a long short-term memory model is employed to predict future pedestrian motion states, utilizing the acquired prior knowledge as input. Finally, the predicted motion states are discretized into various potential motion patterns, which are then introduced as prompts to the Spatio-Temporal Graph Transformer model for trajectory prediction. Experimental results on the Euro-PVI and BPI datasets demonstrate that the proposed model achieves cutting-edge performance in predicting pedestrian crossing trajectories. Notably, it significantly enhances the diversity, accuracy, and interpretability of pedestrian crossing trajectory predictions.","2024-05","2025-02-26 20:41:51","2025-02-26 20:41:51","","82-95","","3","16","","","","","","","","","","English","","","","WOS:001125547300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Behavioral sciences; Feature extraction; Market research; MODEL; Pedestrians; Predictive models; Roads; Trajectory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M877IQPF","journalArticle","2024","Qi, JC; Nguyen, M; Yan, WQ","CISO: Co-iteration semi-supervised learning for visual object detection","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-023-16915-4","","Semi-supervised learning offers a solution to the high cost and limited availability of manually labeled samples in supervised learning. In semi-supervised visual object detection, the use of unlabeled data can significantly enhance the performance of deep learning models. In this paper, we introduce an end-to-end framework, named CISO (Co-Iteration Semi-Supervised Learning for Object Detection), which integrates a knowledge distillation approach and a collaborative, iterative semi-supervised learning strategy. To maximize the utilization of pseudo-label data and address the scarcity of pseudo-label data due to high threshold settings, we propose a mean iteration approach where all unlabeled data is applied to each training iteration. Pseudo-label data with high confidence is extracted based on an ever-changing threshold (average intersection over union of all pseudo-labeled data). This strategy not only ensures the accuracy of the pseudo-label but also optimizes the use of unlabeled data. Subsequently, we apply a weak-strong data augmentation strategy to update the model. Lastly, we evaluate CISO using Swin Transformer model and conduct comprehensive experiments on MS-COCO. Our framework showcases impressive results, outperforms the state-of-the-art methods by 2.16 mAP and 1.54 mAP with 10% and 5% labeled data, respectively.","2024-03","2025-02-26 20:41:51","2025-02-26 20:41:51","","33941-33957","","11","83","","","","","","","","","","English","","","","WOS:001069156900017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","CISO; Data augmentation; Semi-supervised; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3KP92C34","journalArticle","2022","Li, XF; Ma, J; Li, S","Intelligence customs declaration for cross-border e-commerce based on the multi-modal model and the optimal window mechanism","ANNALS OF OPERATIONS RESEARCH","","0254-5330","10.1007/s10479-022-04799-w","","This paper aims to study the intelligent customs declaration of cross-border e-commerce commodities from algorithm design and implementation. The difficulty of this issue is the recognition of commodity names, materials, and processing processes. Because the process of recognizing these three kinds of commodity information is similar, this paper chooses to identify the commodity name as the experimental research object. The algorithm in this paper is based on the premise of pre-clustering, using an optimal window mechanism to obtain the best word embedding vector representation. The Vision Transformer model extracts image features instead of traditional CNN models, and then text features are fused with image features to generate a multi-modal semantically feature vector. Finally, a deep forest classifier replaces the conventional neural network classifiers to complete the commodity name recognition task. The experimental results show that, for more than 600 different commodities on the 120,000 data records, the precision is 0.85, the recall is 0.87, and the F-1_score is 0.86. So, our algorithm can effectively and accurately recognize e-commerce commodity names and provide a new perspective on the research of e-commerce intelligence declarations.","2022-06-15","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","","","","","","","","","","","English","","","","WOS:000811423100008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","CLASSIFICATION; Commodity name recognition; Cross-border electronic commerce; Multi-modal; Optimal window mechanism; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2MTVPNZT","journalArticle","2022","Hayawi, K; Shahriar, S; Serhani, MA; Taleb; Mathew, SS","ANTi-Vax: a novel Twitter dataset for COVID-19 vaccine misinformation detection","PUBLIC HEALTH","","0033-3506","10.1016/j.puhe.2021.11.022","","Objectives: COVID-19 (SARS-CoV-2) pandemic has infected hundreds of millions and inflicted millions of deaths around the globe. Fortunately, the introduction of COVID-19 vaccines provided a glimmer of hope and a pathway to recovery. However, owing to misinformation being spread on social media and other platforms, there has been a rise in vaccine hesitancy which can lead to a negative impact on vaccine uptake in the population. The goal of this research is to introduce a novel machine learning-based COVID-19 vaccine misinformation detection framework. Study design: We collected and annotated COVID-19 vaccine tweets and trained machine learning algorithms to classify vaccine misinformation. Methods: More than 15,000 tweets were annotated as misinformation or general vaccine tweets using reliable sources and validated by medical experts. The classification models explored were XGBoost, LSTM, and BERT transformer model. Results: The best classification performance was obtained using BERT, resulting in 0.98 F1-score on the test set. The precision and recall scores were 0.97 and 0.98, respectively. Conclusion: Machine learning-based models are effective in detecting misinformation regarding COVID19 vaccines on social media platforms. (c) 2021 The Royal Society for Public Health. Published by Elsevier Ltd. All rights reserved.","2022-02","2025-02-26 20:41:51","2025-02-26 20:41:51","","23-30","","","203","","","","","","","","","","English","","","","WOS:000753810900005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;76<br/>Total Times Cited:&nbsp;&nbsp;78<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","COVID-19; DEEP; Deep learning; Misinformation detection; Natural language processing; Text classi fication; Vaccines","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HF9FRZM9","journalArticle","2024","Bai, Y; Guan, XR; He, L; Wang, Z; Li, Z; Zhu, M","Estimating Rotational Acceleration in Shoulder and Elbow Joints Using a Transformer Algorithm and a Fusion of Biosignals","SENSORS","","1424-8220","10.3390/s24061726","","In the present study, we used a transformer model and a fusion of biosignals to estimate rotational acceleration in elbow and shoulder joints. To achieve our study objectives, we proposed a mechanomyography (MMG) signal isolation technique based on a variational mode decomposition (VMD) algorithm. Our results show that the VMD algorithm delivered excellent performance in MMG signal extraction compared to the commonly used technique of empirical mode decomposition (EMD). In addition, we found that transformer models delivered estimates of joint acceleration that were more precise than those produced by mainstream time series forecasting models. The average R2 values of transformer are 0.967, 0.968, and 0.935, respectively. Finally, we found that using a fusion of signals resulted in more precise estimation performance compared to using MMG signals alone. The differences between the average R2 values are 0.041, 0.053, and 0.043, respectively. Taken together, the VMD isolation method, the transformer algorithm and the signal fusion technique described in this paper can be seen as supplying a robust framework for estimating rotational acceleration in upper-limb joints. Further study is warranted to examine the effectiveness of this framework in other musculoskeletal contexts.","2024-03","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","6","24","","","","","","","","","","English","","","","WOS:001192416000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","EMG; estimation of human joint rotational acceleration; mechanomyography; MODE; surface electromyography; transformer algorithm","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IN6JDE5H","journalArticle","2024","Gong, MG; Zhang, YQ; Gao, Y; Qin, AK; Wu, Y; Wang, SF; Zhang, YH","A Multi-Modal Vertical Federated Learning Framework Based on Homomorphic Encryption","IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY","","1556-6013","10.1109/TIFS.2023.3340994","","Federated learning has gained prominence as an effective solution for addressing data silos, enabling collaboration among multiple parties without sharing their data. However, existing federated learning algorithms often neglect the challenge posed by multi-modal data distribution. Moreover, previous pioneering work face limitations in encrypting the exponential and logarithmic operations of the objective function with multiple independent variables, and they rely on a third-party cooperator for encryption. To address these limitations, this paper introduces a universal multi-modal vertical federated learning framework. To tackle the data distribution challenge, we propose a two-step multi-modal transformer model that captures cross-domain semantic features effectively. For encryption, where traditional additively homomorphic encryption algorithms fall short by supporting only addition and multiplication, we employ bivariate Taylor series expansion to transform the objective function. Integrating these components, we present a comprehensive training and transmission protocol that eliminates the need for a third-party cooperator during the encryption process. Extensive experiments conducted on diverse video-text and image-text datasets validate the superior performance of our framework compared to state-of-the-art approaches, affirming its effectiveness in multi-modal vertical federated learning settings.","2024","2025-02-26 20:41:51","2025-02-26 20:41:51","","1826-1839","","","19","","","","","","","","","","English","","","","WOS:001142485000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","bivariate Taylor series expansion; cross-domain semantic feature extraction; homomorphic encryption; multi-modal learning; universal frame-work; Vertical federated learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CK7WVLIX","journalArticle","2024","Khalid, M; Pluempitiwiriyawej, C; Abdulkadhem, AA; Afzal, I; Truong, T","ECGConVT: A Hybrid CNN and Vision Transformer Model for Enhanced 12-Lead ECG Images Classification","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3516495","","Cardiovascular diseases, which are currently the major causes of death globally, can be largely ameliorated through early detection and categorization. Electrocardiogram (ECG) tests have emerged as widely employed, low-cost and non-invasive procedures for evaluating electrical activities of the heart and diagnosing cardiovascular ailments. In this research, by using deep learning techniques to detect specific cardiac disorders like cardiac myocardial infarction(MI), arrhythmia, past history of myocardial infarction(PMI) and normal ECG patterns on a dataset containing patients with heart disease. We propose ECGConVT framework that combines Convolutional Neural Network (CNN) module for extracting local features, and Vision Transformer (ViT) module for capturing global features. The final classification is achieved by combining the two using Multilayer Perceptron (MLP) module. The experimental results indicate promise of ECGConVT in ECG image classification where it outperforms other approaches showing an average accuracy of 98.5%, F1-score: 98.7%, Recall: 98.8% and Precision: 98.5%. In order to meet the practical needs of clinical applications, we implemented a lightweight post-processing step to reduce the size of the model.","2024","2025-02-26 20:41:51","2025-02-26 20:41:51","","193043-193056","","","12","","","","","","","","","","English","","","","WOS:001387239300032","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Accuracy; Arrhythmia; Cardiovascular diseases; Convolution; Convolutional neural networks; Deep learning; ECG images classification; electrocardiogram; Electrocardiography; Feature extraction; Heart; machine learning; Transformers; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E8HR7GWL","journalArticle","2023","Jia, CY; Tian, YK; Shi, YH; Jia, JF; Wen, J; Zeng, JC","State of health prediction of lithium-ion batteries based on bidirectional gated recurrent unit and transformer","ENERGY","","0360-5442","10.1016/j.energy.2023.129401","","Lithium-ion batteries have been widely used in various aspects of our lives, playing a crucial role in numerous applications. The state of health (SOH) serves as a pivotal indicator, and accurate prediction of SOH is essential for the safe utilization, management, and maintenance of lithium-ion batteries. In order to accurately predict SOH, a hybrid prediction model by combining bidirectional gated recurrent unit (BiGRU) and Transformer with multi-head attention mechanism (AM) is proposed, which can effectively address the challenge of long time series prediction. In the proposed prediction model, the indirect health indicator (HI), which can characterize the degradation of lithium-ion batteries, is fed into the BiGRU to learn the hidden states of the input features and thus further extract time series features. On this basis, multiple attention is given to the Transformer encoder layer and the input feature vectors, which gives it a better performance in the long-term dependence of the time series. The study based on the lithium-ion battery data from NASA Prediction Center of Excellence (PCoE) shows that the proposed BiGRU-Transformer model has higher accuracy, better robustness and generalisation capability.","2023-12-15","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","285","","","","","","","","","","English","","","","WOS:001104226800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;35<br/>Total Times Cited:&nbsp;&nbsp;38<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","BiGRU; CHARGE; DIAGNOSIS; Indirect health indicator; Lithium-ion batteries; MANAGEMENT; MODEL; PROGNOSTICS; SOH prediction; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"54E9JMJA","journalArticle","2022","Shaked, D; Holdengreber, E","Efficiency Improvement of an Electric-Grid Transformer Using the Diamagnetism Characteristics of a Bulk Superconductor","ENERGIES","","1996-1073","10.3390/en15197146","","An innovative method to improve the efficiency of a single-phase electric-grid 125 kVA, 50 Hz shell type and distribution transformer is presented. The diamagnetism characteristic of a bulk high-temperature superconductor (HTS), designed in a specific dimension, is used to construct a magnetic shield around the air gaps that form between the core joints and among the coils of the transformer. Consequently, the shielded flux engages the core area and increases the flux density in the core, resulting in an increase in the output power, and hence an improved transformer efficiency. The transformer was designed and simulated using advanced electromagnetic software. Simulation results indicate that the width and thickness of the HTS material, as its precise location placed on the air gaps around the core and the coils, can be a substantial factor in generating a magnetic shield that results in an efficiency improvement, superior compared to conventional transformers. The most enhanced performance was received for HTS thickness of 2.6 mm, around 2.4% output power improvement compared with a conventional transformer model. In a transformer of this type that efficiency improvement can lead to great energy savings, around 10,000 kWh for half a year of working under load.","2022-10","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","19","15","","","","","","","","","","English","","","","WOS:000866823900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Bulk HTS; distribution transformer; high-efficiency transformer; magnetic shielding; single-phase","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S4H248IN","journalArticle","2021","Chen, GZ; Song, Z; Qi, ZW","Transformer-convolutional neural network for surface charge density profile prediction: Enabling high-throughput solvent screening with COSMO-SAC","CHEMICAL ENGINEERING SCIENCE","","0009-2509","10.1016/j.ces.2021.117002","","A deep learning (DL) method for quickly predicting surface charge density profiles (sigma-profile) and cavity volumes (V-COSMO) of molecules for the COSMO-SAC model is developed. The molecular fingerprints are derived from the encoder state of a Transformer model pre-trained on the ChEMBL database, which allows transfer learning from large-scale unlabeled data and improve generalization performance by developing better molecular fingerprints for building models with significantly smaller datasets. Employing the pre-trained molecular fingerprints, a convolutional neural network (CNN) model for the sigma-profile and V-COSMO prediction is trained and tested on the VT-2005 database. The obtained Transformer-CNN model presents superior performance to the GC-COSMO approach and enables the pre-diction of sigma-profile and V-COSMO of millions of molecules in only a few minutes. Taking advantages of the model, a high-throughput solvent screening framework based on COSMO-SAC is further proposed and exemplified by searching sustainable solvent for the deterpenation process of citrus essential oils. (C) 2021 Elsevier Ltd. All rights reserved.","2021-12-31","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","246","","","","","","","","","","English","","","","WOS:000704401400014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;30<br/>Total Times Cited:&nbsp;&nbsp;31<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","ACTIVITY-COEFFICIENTS; AIDED MOLECULAR DESIGN; Convolutional neural networks; COSMO-SAC; DATABASE; Deep learning; EXTRACTION; High-throughput solvent screening; IONIC LIQUID DESIGN; METHODOLOGY; MODEL; Molecular fingerprints; sigma-profile prediction; SIMILARITY; SMILES; SYSTEMS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YQ2L39B2","journalArticle","2024","Li, HY; Zhang, XF","Human-Machine Collaborative Image Compression Method Based on Implicit Neural Representations","IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS","","2156-3357","10.1109/JETCAS.2024.3386639","","With the explosive increase in the volume of images intended for analysis by AI, image coding for machine have been proposed to transmit information in a machine-interpretable format, thereby enhancing image compression efficiency. However, such efficient coding schemes often lead to issues like loss of image details and features, and unclear semantic information due to high data compression ratio, making them less suitable for human vision domains. Thus, it is a critical problem to balance image visual quality and machine vision accuracy at a given compression ratio. To address these issues, we introduce a human-machine collaborative image coding framework based on Implicit Neural Representations (INR), which effectively reduces the transmitted information for machine vision tasks at the decoding side while maintaining high-efficiency image compression for human vision against INR compression framework. To enhance the model's perception of images for machine vision, we design a semantic embedding enhancement module to assist in understanding image semantics. Specifically, we employ the Swin Transformer model to initialize image features, ensuring that the embedding of the compression model are effectively applicable to downstream visual tasks. Extensive experimental results demonstrate that our method significantly outperforms other image compression methods in classification tasks while ensuring image compression efficiency.","2024-06","2025-02-26 20:41:51","2025-02-26 20:41:51","","198-208","","2","14","","","","","","","","","","English","","","","WOS:001263602100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","image coding for machine; Image compression; implicit neural representation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TBNUCI2A","journalArticle","2024","Yuan, ZF; Tian, T; Hao, FC; Li, G; Tang, R; Liu, XQ","A hybrid neural network based on variational mode decomposition denoising for predicting state-of-health of lithium-ion batteries","JOURNAL OF POWER SOURCES","","0378-7753","10.1016/j.jpowsour.2024.234697","","Accurately predicting the State of Health (SOH) of lithium -ion batteries is essential for ensuring their safe and reliable operation, and reducing maintenance and service costs for associated equipment. Nevertheless, the aging data of lithium -ion batteries displays pronounced nonlinearity and is plagued by issues such as capacity regeneration. To address this issue, this study proposes a framework for SOH prediction of lithium -ion batteries based on Variational Mode Decomposition (VMD) and CNN -Transformer. First, the original data undergoes a VMD smoothing process to eliminate capacity regeneration and a portion of the noise signals. Subsequently, Convolutional Neural Networks (CNN) is utilized for feature extraction. Then, a modified Transformer model is employed to capture the inherent correlations in the time series and map the features to future SOH values. An iterative strategy is adopted to predict SOH for each charge -discharge cycle. The experimental results on the CALCE dataset demonstrate that the proposed method can accurately predict the SOH of lithium -ion batteries using just 5 % -6 % of the complete cycle 's aging data. Additionally, comparative results on the NASA dataset show that, compared to the latest relevant literature, the proposed method achieves high prediction accuracy while maintaining exceptional generalization.","2024-07-30","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","609","","","","","","","","","","English","","","","WOS:001241100600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","CAPACITY; CNN -Transformer; Lithium -ion battery; PROGNOSTICS; SOH; VMD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GUP2CGQN","journalArticle","2024","Hu, XB","A Dual Memory Hybrid Neural Networks for Modeling and Prediction of Nonlinear Systems","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3439258","","The high-dimensional data fitting modeling based on hybrid neural network models has been a hot topic in data mining research in recent years. However, due to the curse of dimensionality and limited number of trainable samples, the model's training accuracy cannot continue to improve after reaching a certain level. In this paper, we propose a hybrid neural network model with a dual structure to further improve the training accuracy of the basic model by controlling the data dimension and adjusting the model structure. The proposed model improves the ratio of sample quantity to dimension, enhances the stability and generalization ability of the model, and shortens the training time. The test results on multiple datasets demonstrate that the comprehensive accuracy of the proposed model is 13% higher than that of the basic single-branch model. Although the current Transformer model surpasses the proposed DmHybNNs model in terms of accuracy, its model complexity is significantly higher than that of the DmHybNNs model. The low-complexity DmHybNNs model is more suitable for deployment on low-power and low-computing-power platforms. This research paper is both theoretical and practical, providing some new ideas and methods for modeling high-dimensional nonlinear systems.","2024","2025-02-26 20:41:51","2025-02-26 20:41:51","","108134-108144","","","12","","","","","","","","","","English","","","","WOS:001288146200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","accuracy; dimensionality reduction; Hybrid neural networks; long short-term memory networks; residual networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WFY5LNYY","journalArticle","2024","Ning, WY; Wang, QX; Feng, JQ; Jiang, HX; Zhang, GY; Yin, JH","Scene-Object Holistic Relation Network for Fine-Grained Airplane Detection","IEEE GEOSCIENCE AND REMOTE SENSING LETTERS","","1545-598X","10.1109/LGRS.2024.3397837","","The airplane detection and fine-grained recognition in the remote sensing images are challenging due to high interclass indistinction. The subtle distinctions between classes make it difficult to accurately classify objects based purely on bounding box features without considering the broader context. However, recent studies on remote sensing object detection focuses on refining the representation of bounding boxes while ignoring holistic context knowledge in remote sensing scenarios. This letter addresses this gap by introducing the scene-object holistic relation (SOHR) network for fine-grained airplane detection. Specifically, the SOHR network distinctively exploits global scene-object context information through a novel lightweight scene context attention (SCA) module, which aggregates scene context feature and object position information. Furthermore, the object relation transformer (ORT) is designed to model interactions among all objects within the scene explicitly, thereby increasing the model performance for ambiguous hard samples. The experimental results obtained from the FAIR1M dataset demonstrate that the proposed SOHR-Net achieves a state-of-the-art detection accuracy of 56.110% mean average precision (mAP). Compared with the baseline, SOHR-Net exhibits an increase of 2.517%.","2024","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","21","","","","","","","","","","English","","","","WOS:001248226800008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;17</p>","","","Airplane detection; Airplanes; attention mechanism; context information; Detectors; Feature extraction; fine-grained recognition; Head; Object detection; Remote sensing; remote sensing images; transformer model; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VAE8WK9Z","journalArticle","2024","Xu, C; Ye, F; Kong, FQ; Li, YS; Lv, ZJ","MSCC-ViT:A Multiscale Visual-Transformer Network Using Convolution Crossing Attention for Hyperspectral Unmixing","IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING","","1939-1404","10.1109/JSTARS.2024.3465227","","Deep-learning-based methods are increasingly being applied in hyperspectral image unmixing (HSU) tasks, among which the transformer model has shown superior performance and faster processing speed. However, recently proposed transformer-based HSU models are limited to single-scale feature learning, while ignoring the learning and interaction of image features at multiple different scales. To overcome this limitation, we propose a multiscale visual transformer network using a convolution crossing attention (CCA) (MSCC-ViT) model. MSCC-ViT aims to extract feature information from hyperspectral images (HSI) at different scales and effectively fuse them, allowing the model to simultaneously recognize parts of HSI with similar spectral features and distinguish parts with different features. In general, MSCC-ViT first utilizes a multiscale feature extraction module composed of 2-D-3-D convolutional layers to preliminarily extract HSI information, which is then input into a multiscale transformer to learn information at different scales. A CCA module is used for multiscale information fusion. Finally, the decoder utilizes a simple convolutional layer to restore the original image. The model was tested on one simulated dataset and three real datasets, and the results proved the superiority of the proposed model.","2024","2025-02-26 20:41:51","2025-02-26 20:41:51","","18070-18082","","","17","","","","","","","","","","English","","","","WOS:001336265700003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","CLASSIFICATION; Convolution crossing attention (CCA); deep learning; FAST ALGORITHM; hyperspectral unmixing; IMAGE; IMPLEMENTATION; multiscale feature extraction (MCFE); SPARSE; transformer; VERTEX COMPONENT ANALYSIS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5Z44W7Q6","journalArticle","2023","Wang, XQ; Ahsan, MU; Zhou, YY; Wang, K","Transformer-based DNA methylation detection on ionic signals from Oxford Nanopore sequencing data","QUANTITATIVE BIOLOGY","","2095-4689","10.15302/J-QB-022-0323","","Background: Oxford Nanopore long-read sequencing technology addresses current limitations for DNA methylation detection that are inherent in short-read bisulfite sequencing or methylation microarrays. A number of analytical tools, such as Nanopolish, Guppy/Tombo and DeepMod, have been developed to detect DNA methylation on Nanopore data. However, additional improvements can be made in computational efficiency, prediction accuracy, and contextual interpretation on complex genomics regions (such as repetitive regions, low GC density regions).Method: In the current study, we apply Transformer architecture to detect DNA methylation on ionic signals from Oxford Nanopore sequencing data. Transformer is an algorithm that adopts self-attention architecture in the neural networks and has been widely used in natural language processing.Results: Compared to traditional deep-learning method such as convolutional neural network (CNN) and recurrent neural network (RNN), Transformer may have specific advantages in DNA methylation detection, because the self-attention mechanism can assist the relationship detection between bases that are far from each other and pay more attention to important bases that carry characteristic methylation-specific signals within a specific sequence context.Conclusion: We demonstrated the ability of Transformers to detect methylation on ionic signal data.","2023-09","2025-02-26 20:41:51","2025-02-26 20:41:51","","287-296","","3","11","","","","","","","","","","English","","","","WOS:001119788400009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","deep learning; DNA methylation; long-read sequencing; Nanopore; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VH6MVFXS","journalArticle","2023","Zheng, H; Hu, ZD; Wang, XG; Ni, JH; Cui, MQ","VMD-CAT: A hybrid model for short-term wind power prediction","ENERGY REPORTS","","2352-4847","10.1016/j.egyr.2023.02.061","","Accurate wind power prediction is essential to optimize the wind power scheduling and maximize the profits. However, the inertia and time-varying property of the wind speed pose a challenge to the wind power prediction task. The existing prediction models fail to efficiently mitigate the negative influence of these properties on the prediction results. Therefore, their generalization abilities require a further improvement. In this paper, the historical wind power segment is decomposed into sub-signals, which are considered as the fluctuation patterns of the wind power series, the variable support then is employed to describe the inertia and time-varying properties for the fluctuation patterns. The component-attention mechanism is introduced to formulate the correlation-relationship between each fluctuation pattern and the historical wind power segment, this mechanism is used to replace the self-attention mechanism for the Transformer model. A hybrid model combined VMD and Transformer is utilized for predicting the future wind power. Experiments performed on an actual wind power series validate the efficiency of the proposed model. (c) 2023 The Author(s). Published by Elsevier Ltd. This is an open access article under theCCBY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).","2023-06","2025-02-26 20:41:51","2025-02-26 20:41:51","","199-211","","","9","","","","","","","","","","English","","","","WOS:001057956800019","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","ARIMA; Correlation relationship; DECOMPOSITION; OPTIMIZATION ALGORITHM; SPEED; Transformer; VMD; Wind power prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5P9XWAI2","journalArticle","2022","Mohanrajan, SN; Loganathan, A","Novel Vision Transformer-Based Bi-LSTM Model for LU/LC Prediction-Javadi Hills, India","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app12136387","","Continuous monitoring and observing of the earth's environment has become interactive research in the field of remote sensing. Many researchers have provided the Land Use/Land Cover information for the past, present, and future for their study areas around the world. This research work builds the Novel Vision Transformer-based Bidirectional long-short term memory model for predicting the Land Use/Land Cover Changes by using the LISS-III and Landsat bands for the forest- and non-forest-covered regions of Javadi Hills, India. The proposed Vision Transformer model achieves a good classification accuracy, with an average of 98.76%. The impact of the Land Surface Temperature map and the Land Use/Land Cover classification map provides good validation results, with an average accuracy of 98.38%, during the process of bidirectional long short-term memory-based prediction analysis. The authors also introduced an application-based explanation of the predicted results through the Google Earth Engine platform of Google Cloud so that the predicted results will be more informative and trustworthy to the urban planners and forest department to take proper actions in the protection of the environment.","2022-07","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","13","12","","","","","","","","","","English","","","","WOS:000822143300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;23<br/>Total Times Cited:&nbsp;&nbsp;23<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","Bidirectional long-short term memory; DYNAMICS; Explainable Artificial Intelligence; Google Earth Engine; Land Cover; Land Use; LAND-USE; Landsat; LISS-III; MARKOV; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VMNZNA2A","journalArticle","2022","Devadiga, AA; Jayaram, SH","Influence of pulse rise time and duty cycle on distribution of transients along the wind turbine step-up transformer windings","ELECTRIC POWER SYSTEMS RESEARCH","","0378-7796","10.1016/j.epsr.2021.107646","","A transformer is one of the most important assets in an electric power generation system. Wind turbine step-up transformers have recently seen premature failures due to high-frequency repetitive transients. The highfrequency transients under resonance can severely damage the insulation of the transformer. Thus the paper initially analyses the distribution of transformer frequency response to identify critical resonance frequencies for the two transfer function frequency responses; namely, impedance frequency response and voltage ratio response. Transformer frequency response is compared with transient response to understand the influence of repetitive transient parameters; namely applied voltage amplitude, rise time, and duty cycle, on transient distribution along the transformer winding. Based on three variable experiments, the range of rise time was considered as less than 300 ns and 1000 ns, applied voltage considered was 100 V and 1000 V, and duty cycle considered was 10% and 50%. For the current transformer model, both the experimental and PSCAD simulation results indicated that a duty cycle of 50% and rise time < 300 ns were critically damaging to transformer insulation. The research helps in designing transformer insulation stressed under different transient parameters.","2022-02","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","203","","","","","","","","","","English","","","","WOS:000718143600002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","DESIGN; FARM; Frequency response analysis; LIGHTNING IMPULSES; OVERVOLTAGE; Repetitive transient voltage; Tap-to-tap voltage; Transformers; Transient response analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R97B3929","journalArticle","2025","Yi, ZR; Meng, H; Gao, L; He, ZH; Yang, M","Efficient convolutional dual-attention transformer for automatic modulation recognition","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-024-06202-6","","Automatic modulation recognition (AMR) involves identifying the modulation of electromagnetic signals in a noncollaborative manner. Deep learning-based methods have become a focused research topic in the AMR field. Such models are frequently trained using standardized data, relying on many computational and storage resources. However, in real-world applications, the finite resources of edge devices limit the deployment of large-scale models. In addition, traditional networks cannot handle real-world signals of varying lengths and local missing data. Thus, we propose a network structure based on a convolutional Transformer with a dual-attention mechanism. This proposed structure effectively utilizes the inductive bias of the lightweight convolution and the global property of the Transformer model, thereby fusing local features with global features to get high recognition accuracy. Moreover, the model can adapt to the length of the input signals while maintaining strong robustness against incomplete signals. Experimental results on the open-source datasets RML2016.10a, RML2016.10b, and RML2018.01a demonstrate that the proposed network structure can achieve 95.05%, 94.79%, and 98.14% accuracy, respectively, with enhancement training and maintain greater than 90% accuracy when the signals are incomplete. In addition, the proposed network structure has fewer parameters and lower computational cost than benchmark methods.","2025-02","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","3","55","","","","","","","","","","English","","","","WOS:001385140000004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","CLASSIFICATION; Dual-attention mechanism; Efficient modulation recognition; Lightweight convolution; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7SQ6ALKW","journalArticle","2024","Dal Bianco, P; Rios, G; Hasperue, W; Stanchi, O; Quiroga, F; Ronchetti, F","A study on pose-based deep learning models for gloss-free Sign Language Translation","JOURNAL OF COMPUTER SCIENCE & TECHNOLOGY","","1666-6046","10.24215/16666038.24.e09","","Sign Language Translation (SLT) is a challenging task due to its cross-domain nature, different grammars and lack of data. Currently, many SLT models rely on intermediate gloss annotations as outputs or latent priors. Glosses can help models to correctly segment and align signs to better understand the video. However, the use of glosses comes with significant limitations, since obtaining annotations is quite difficult. Therefore, scaling gloss-based models to millions of samples remains impractical, specially considering the scarcity of sign language datasets. In a similar fashion, many models use video data that requires larger models which typically only work on high end GPUs, and are less invariant to signers appearance and context. In this work we propose a gloss-free pose-based SLT model. Using the extracted pose as feature allow for a sign significant reduction in the dimensionality of the data and the size of the model. We evaluate the state of the art, compare available models and develop a keypoint-based Transformer model for gloss-free SLT, trained on RWTH-Phoenix, a standard dataset for benchmarking SLT models alongside GSL, a simpler laboratory-made Greek Sign Language dataset.","2024-10","2025-02-26 20:41:51","2025-02-26 20:41:51","","99-103","","2","24","","","","","","","","","","English","","","","WOS:001359209700003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","Deep Learning; Gloss-free; Pose Estimation; Sign Language Datasets; Sign Language Translation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RJL3LMIM","journalArticle","2024","Wang, MJ; Li, ZJ; Wang, J; Zou, W; Zhou, JX; Gan, JH","TracKGE: Transformer with Relation-pattern Adaptive Contrastive Learning for Knowledge Graph Embedding","KNOWLEDGE-BASED SYSTEMS","","0950-7051","10.1016/j.knosys.2024.112218","","Knowledge Graphs, fundamental to intelligent applications, are increasingly critical in various domains, enhancing tasks like precise searching and personalized recommendation. Effectively representing entities and relationships in these graphs is key, especially as the Transformer model, despite its representational prowess, faces challenges in adapting to the graph's structure and complex relations. In this work, we present the Transformer with Relation-pattern Adaptive Contrastive Learning for Knowledge Graph Embedding (TracKGE). Specifically, TracKGE transforms the structural information of the knowledge graph into a sequence format that is more manageable for Transformers. In addition, we employ a relation-pattern adaptive contrastive learning module to capture a richer semantic and complex relationship pattern information of the knowledge graph. Lastly, by introducing a mask node model, it addresses the issue of incomplete information in the knowledge graph, further enhancing the model's capability to capture implicit relationships within it. To evaluate the performance of our model, we have chosen well-established models as baselines and executed link prediction tasks on four renowned datasets. Our experimental results reveal that our model excels in representing the semantics and intricate structures of Knowledge Graphs. It outperforms other advanced baseline models, showcasing its superior capability in handling complex data representations.","2024-10-09","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","301","","","","","","","","","","English","","","","WOS:001282489800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Contrastive learning; Knowledge graph embedding; Link prediction; NETWORK; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HPUBHVHP","journalArticle","2024","Liu, H; Wang, T; Li, WY; Ye, XF; Yuan, Q","Lane-change intention recognition considering oncoming traffic: Novel insights revealed by advances in deep learning","ACCIDENT ANALYSIS AND PREVENTION","","0001-4575","10.1016/j.aap.2024.107476","","Lane -changing (LC) intention recognition models have seen limited real -world application due to a lack of research on two-lane two-way road environments. This study constructs a high-fidelity simulated two-lane twoway road to develop a Transformer model that accurately recognizes LC intention. We propose a novel LC labelling algorithm combining vehicle dynamics and eye -tracking (VEL) and compare it against traditional time window labelling (TWL). We find the LC recognition accuracy can be further improved when oncoming vehicle features are included in the LC dataset. The Transformer demonstrates state-of-the-art performance recognizing LC 4.59 s in advance with 92.6 % accuracy using the VEL labelling method compared to GRU, LSTM and CNN + LSTM models. To interpret the Transformer's 'black box', we apply LIME model which reveals the model focuses on eye -tracking features and LC vehicle interactions with preceding and oncoming traffic during LC events. This research demonstrates that modelling additional road users and driver gaze in LC intention recognition achieves significant improvements in model performance and time -to -collision warning capabilities on two-lane two-way roads.","2024-04","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","198","","","","","","","","","","English","","","","WOS:001184717100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","ASSISTANCE; BEHAVIOR; DRIVERS; Eye-tracking features; Lane-change intention recognition; LIME; Multi-head attention mechanism; SITUATION ASSESSMENT; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NRGUMAHS","journalArticle","2024","Wang, C; Zhu, HY; Chu, KX","X-Trafformer: A Unified Variable-Term Prediction for Object-Generalized Traffic in Network Services","IEEE TRANSACTIONS ON SERVICES COMPUTING","","1939-1374","10.1109/TSC.2024.3445370","","Traffic prediction acts as a fundamental function in the management and optimization of networks and services. There are emerging requirements for extraordinary traffic prediction, including variable-term traffic series and comprehensive traffic behavior. Compared to ordinary traffic prediction, these demands call for solutions to mine rich information and predict business load under broader conditions. In this work, we propose X-Trafformer, a graph spatiotemporal transformer model, for extraordinary traffic prediction. Unlike conventional techniques that model traffic sequences, we transform traffic sequences into traffic behaviors under generalized objects, where behaviors are initiated by generalized objects and possess specific behavioral attributes. It allows for the prediction of multiple variables in traffic data across different networks and services, leveraging the matching of behavioral attributes among behavior objects and events. X-Trafformer incorporates multiple interrelated graph structures to capture fine-grained attribute spatiotemporal associations and coarse-grained object spatiotemporal distributions, forming the foundation for accurate prediction. Evaluation on real and representative traffic scenarios (communication traffic from Italian Telecom and business traffic from Tmall) demonstrates X-Trafformer's exceptional prediction performance at low computational costs.","2024-11","2025-02-26 20:41:51","2025-02-26 20:41:51","","4494-4507","","6","17","","","","","","","","","","English","","","","WOS:001386510000004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Accuracy; Correlation; Feature extraction; Generalized object modeling; multivariate time series forecasting; network service; Predictive models; Spatiotemporal phenomena; Task analysis; traffic prediction; TRANSFORMER; Transforms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"62M2EPRW","journalArticle","2024","Zhao, YX; Jin, JR; Gao, WJ; Qiao, JB; Wei, LY","Moss-m7G: A Motif-Based Interpretable Deep Learning Method for RNA N7-Methlguanosine Site Prediction","JOURNAL OF CHEMICAL INFORMATION AND MODELING","","1549-9596","10.1021/acs.jcim.4c00802","","N-7methylguanosine (m7G) modification plays a crucial role in various biological processes and is closely associated with the development and progression of many cancers. Accurate identification of m7G modification sites is essential for understanding their regulatory mechanisms and advancing cancer therapy. Previous studies often suffered from insufficient research data, underutilization of motif information, and lack of interpretability. In this work, we designed a novel motif-based interpretable method for m7G modification site prediction, called Moss-m7G. This approach enables the analysis of RNA sequences from a motif-centric perspective. Our proposed word-detection module and motif-embedding module within Moss-m7G extract motif information from sequences, transforming the raw sequences from base-level into motif-level and generating embeddings for these motif sequences. Compared with base sequences, motif sequences contain richer contextual information, which is further analyzed and integrated through the Transformer model. We constructed a comprehensive m7G data set to implement the training and testing process to address the data insufficiency noted in prior research. Our experimental results affirm the effectiveness and superiority of Moss-m7G in predicting m7G modification sites. Moreover, the introduction of the word-detection module enhances the interpretability of the model, providing insights into the predictive mechanisms.","2024-07-16","2025-02-26 20:41:51","2025-02-26 20:41:51","","6230-6240","","15","64","","","","","","","","","","English","","","","WOS:001270069300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","IDENTIFICATION; MESSENGER-RNA; MODEL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UKSFZHE5","journalArticle","2024","Murugeswari, P; Kopperundevi, N; Annalakshmi, M; Clarinda, SS","An effective reconstructed pyramid crosspoint fusion for multimodal infrared and visible images","SIGNAL IMAGE AND VIDEO PROCESSING","","1863-1703","10.1007/s11760-024-03350-7","","Fusion for multimodal infrared and visible images refers to the process of combining detail from both infrared and visible images, which holds particular importance in enhancing scene detection and tracking within video surveillance systems. However, traditional approaches for infrared and visible images fusion often struggle with preserving edges, capturing modality specific information effectively, enhancing detail across multiple scales, and efficiently optimizing fusion parameters. The proposed effective Edge preserving Gradient domain Guided image Filter with Weighting Approach method addresses these challenges by preserving edges during image decomposition and utilizing Multi Head Convolutional Split Attention networks for modality specific feature extraction. Additionally, the Pyramid Crosspoint Fusion Transformer model enhances detail and preserves crucial features through pyramid-based reconstruction, ensuring high quality representations. Employing the Humboldt squid optimization algorithm efficiently optimizes fusion parameters, further enhancing image quality. The suggested framework exhibits outstanding performance, achieving high standard deviation, mutual information, and information entropy of 85.21 nm, 16.32 bits, and 7.95 bits, respectively. This fusion model enhances scene detection and tracking in video surveillance systems by effectively combining infrared and visible images, preserving edges and details. It optimizes fusion quality through innovative techniques and evaluation metrics.","2024-09","2025-02-26 20:41:51","2025-02-26 20:41:51","","6769-6782","","10","18","","","","","","","","","","English","","","","WOS:001252132800004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Guided image filter; Humboldt squid optimization; Image fusion; Pyramid cross point fusion transformer; Split attention","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MME2SD5R","journalArticle","2024","Fan, C; Peng, YF; Shen, YP; Guo, Y; Zhao, SB; Zhou, J; Li, S","Variable scale multilayer perceptron for helicopter transmission system vibration data abnormity beyond efficient recovery","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2024.108184","","In the task of health monitoring of helicopter transmission systems, data transmission is often abnormal due to harsh working environments, sparse wire connections, and other factors. This paper addresses the problem of recovering abnormal vibration data, focusing on common Bias anomalies and precision degradation anomalies in the collected vibration data. The Transformer model has gained popularity to address time series for its ability to capture strong long-range correlations. However, it also poses intensive demands on memory and computation resources. To address this issue, an efficient model called Variable Scale Multilayer Perceptron is proposed for recovering abnormal vibration data. Initially, the input data is divided into patches of varying scales to alter the model's input view and reduce computational complexity. Subsequently, compute the relative variations in the input sequence to capture more motion information in the vibration data. Then, a simple Multilayer Perceptron (MLP) layer is employed to learn the latent relationships among the vibration data, followed by a linear mapping layer to reconstruct normal vibration data from the latent representations. Experimental evaluations were conducted on vibration datasets of bearings and gears, and the results demonstrate that our proposed method outperforms the Transformer -based and MLP-based models in terms of both performance and efficiency.","2024-07","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","133","","","","","","","","","","English","","","","WOS:001203172600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","Abnormity recovery; Helicopter transmission system; Variable scale multilayer perceptron; Vibration data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K4YZ9IY7","journalArticle","2024","Qin, FW; Yan, K; Wang, CM; Ge, RQ; Peng, Y; Zhang, K","LKFormer: large kernel transformer for infrared image super-resolution","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-024-18409-3","","Given the broad application of infrared technology across diverse fields, there is an increasing emphasis on investigating super-resolution techniques for infrared images within the realm of deep learning. Despite the impressive results of current Transformer-based methods in image super-resolution tasks, their reliance on the self-attention mechanism intrinsic to the Transformer architecture results in images being treated as one-dimensional sequences, thereby neglecting their inherent two-dimensional structure. Moreover, infrared images exhibit a uniform pixel distribution and a limited gradient range, posing challenges for the model to capture effective feature information. Consequently, we suggest a potent Transformer model, termed Large Kernel Transformer (LKFormer), to address this issue. Specifically, we have designed a Large Kernel Residual Depth-wise Convolutional Attention (LKRDA) module with linear complexity. This mainly employs depth-wise convolution with large kernels to execute non-local feature modeling, thereby substituting the standard self-attention layer. Additionally, we have devised a novel feed-forward network structure called Gated-Pixel Feed-Forward Network (GPFN) to augment the LKFormer's capacity to manage the information flow within the network. Comprehensive experimental results reveal that our method surpasses the most advanced techniques available, using fewer parameters and yielding considerably superior performance.","2024-02-06","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","","","","","","","","","","","English","","","","WOS:001157939200019","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Deep learning; Infrared image; Large kernel convolution; NETWORK; Super-resolution; THERMOGRAPHY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3QZBDQZA","journalArticle","2024","Chen, YC; Sun, Y","The Usage of Artificial Intelligence Technology in Music Education System Under Deep Learning","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3459791","","This work addresses the needs of the music generation field by developing a music generation system based on an advanced Transformer model. The system incorporates an adaptive music feature encoder and a music emotion-driven multi-task learning framework. By integrating music theory knowledge and dynamic weight adjustment, the adaptive encoder can accurately capture different music styles and emotional characteristics. The multi-task learning framework enhances the model's ability to generate music with emotional depth by using emotion tags. Experimental results show that the proposed model achieves significant performance improvements on the Lakh MIDI Dataset (LMD). This is specifically reflected in scores that are above the industry average: a Bilingual Evaluation Understudy (BLEU) score of 0.43, a Recall-Oriented Understudy for Gisting Evaluation (ROUGE-L) score of 0.63, and a Metric for Evaluation of Translation with Explicit ORdering (METEOR) score of 0.31. Additionally, teaching methods based on music generation models have shown significant advantages in enhancing students' musical skills, emotional expression abilities, and overall satisfaction. These results not only demonstrate the effectiveness of the proposed method but also highlight its potential applications in music education and automated music composition.","2024","2025-02-26 20:41:51","2025-02-26 20:41:51","","130546-130556","","","12","","","","","","","","","","English","","","","WOS:001320448500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","adaptive music feature encoder; Artificial intelligence; multi-task learning; music education; sentiment analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T3MN6X5C","journalArticle","2024","Li, DX; Liu, RY; Tang, Y; Liu, Y","PSCLI-TF: Position-Sensitive Cross-Layer Interactive Transformer Model for Remote Sensing Image Scene Classification","IEEE GEOSCIENCE AND REMOTE SENSING LETTERS","","1545-598X","10.1109/LGRS.2024.3359415","","In the scene classification task of remote sensing image (RSI), to fully perceive multiscale local objects in the image and explore their interdependencies to mine the scene semantics of RSI, this letter designs a novel position-sensitive cross-layer interactive transformer (PSCLI-TF) model to improve the accuracy of RSI scene classification. First, ResNet50 is used as the backbone to extract the multilayer feature maps of RSI. Then, to enhance the model's position sensitivity to local objects in RSI, a new position-sensitive cross-layer interactive attention (PSCLIA) mechanism is designed, and based on it a novel PSCLI-TF encoder is constructed to perform layer-by-layer interactive fusion on the multilayer feature maps to obtain the multigranularity cross-layer fusion (CLF) feature of RSI. Finally, a prototype-based self-supervised loss function (SELF) is constructed to alleviate the semantic gap problem of ""large intraclass variance and small interclass variance"" in RSI scene classification. Comparative experimental results based on three datasets (i.e., AID, NWPU, and UCM) indicate that the classification performance of the designed PSCLI-TF model is highly competitive compared with other state-of-the-art methods.","2024","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","21","","","","","","","","","","English","","","","WOS:001173361400017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","Cross layer design; Feature extraction; FEATURES; Position-sensitive transformer; Prototypes; Remote sensing; remote sensing image (RSI) classification; Scene classification; self-supervised learning; Semantics; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6ATTGKGE","journalArticle","2024","Andrade, AF; Costa, EG; Souza, JPC; Andrade, FLM; Araujo, JF","Evaluation of computational models for electromagnetic force calculation in transformer windings using finite-element method","INTERNATIONAL JOURNAL OF ELECTRICAL POWER & ENERGY SYSTEMS","","0142-0615","10.1016/j.ijepes.2023.109744","","Computer simulations are currently one of the most used methods on transformer's short circuit analysis. For them to be effective, an accurate characterization of the transformer core and geometric representation of windings is essential. Hence, this work investigated the influence of core characterization and different geometric representations on magnetic flux density (MFD) and electromagnetic forces (EF) calculated during short circuits. A comparative study using simulations based on the finite-element method (FEM) were carried out for a 180 MVA transformer model. First, the influence of the nonlinear characteristic of the core B-H curve on EF was analyzed. Then, three two-dimensional (2D) axisymmetric and one three-dimensional (3D) representations were compared. Results indicate there is no significant difference in EF with a core represented by a constant value of permeability. Also, 2D-axisymmetric geometric representations underestimate radial forces and diverge significantly on axial forces in comparison with the 3D representation. Differences up to 99% between the calculated total axial forces were obtained for the analyzed cases. In addition, representations with greater level of detail result in magnetic force density up to 5.5 times greater than that obtained with the simplified representation.","2024-02","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","156","","","","","","","","","","English","","","","WOS:001166017000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Electromagnetic force; Finite -element method; Power transformer; POWER TRANSFORMER; Short-circuit; SHORT-CIRCUIT; Transformer windings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M2UKPNCQ","journalArticle","2023","Vishwakarma, G; Nandanwar, AK; Thakur, GS","Optimized vision transformer encoder with cnn for automatic psoriasis disease detection","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-023-16871-z","","Psoriasis is a skin disorder that results in swollen skin cells and red, itchy areas on the skin. 40% of the world's population is currently affected by psoriasis. Nowadays, using skin image analysis technology is the main way for detecting psoriasis. Additionally, a number of academics have identified potential machine learning methods for categorising the psoriasis illness. However, the accuracy and computational efficiency of the model still need to be improved. Thus, in this paper, we present an optimized vision transformer for autonomous psoriasis disease detection. Following pre-processing, feature optimized image is attained using convolutional neural network (CNN) which embeds full image and concatenates to each vision transformer encoder layer. It leads the network to always ""retain"" the full image at the end of each transformer block output. In parallel, the pre-processed images are cropped into patches and these patches along with its positional encoded information are given as input to the optimized transformer encoder. To enhance the performance of transformer, the hyper-parameters of it are optimized using adaptive rabbit optimization algorithm (AROA). Results of this article confirm that the proposed optimized vision transformer model achieved better classification accuracy of 97.7% and F-Score of 96.5%.","2023-12-29","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","","","","","","","","","","","English","","","","WOS:001132108500012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","AROA; CNN; Psoriasis; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UDGHVET3","journalArticle","2023","Guo, X; Tu, JS; Zhan, SP; Zhang, WL; Ma, LX; Jia, D","A novel method for online prediction of the remaining useful life of rolling bearings based on wavelet power spectrogram and Transformer structure","ENGINEERING RESEARCH EXPRESS","","2631-8695","10.1088/2631-8695/ad08fc","","The vibration signal characteristics of rolling bearings are closely related to the performance decay process, predicting the remaining useful life (RUL) of rolling bearings by vibration signals can effectively prevent the occurrence of bearing failures. In this paper, a deep learning-based method for rolling bearing RUL prediction is proposed. The convolutional neural network (CNN), which is more effective in extracting local information, is combined with the Transformer structure, which is specialized in extracting global information, to deeply explore the complex mapping relationship between signal features in wavelet power spectrogram and bearing RUL. Meanwhile, the method of detecting the first prediction time of rolling bearings based on 3 sigma criteria is improved. The proposed method is validated with the XJTU-SY rolling element bearing accelerated life test datasets, as well as compared with other methods to prove its superiority. The results show that the proposed method can effectively extract bearing degradation information and realize the accurate prediction of rolling bearing RUL. The performance-improved rolling bearing RUL prediction model is highly robust and generalizable, which applies to other mechanical parts performance prediction and can be realized for practical applications in industrial fields.","2023-12-01","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","4","5","","","","","","","","","","English","","","","WOS:001110278200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","convolutional neural network; deep learning; rolling bearing; RUL prediction; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XZC7UH24","journalArticle","2023","Zhou, CD; Zhao, JH; Wang, HM; Yan, SN; Yan, DA","Multi-Objective Optimization Design of Linear Phase Shift Transformer Based on Improved Differential Evolutionary Algorithm","IEEJ TRANSACTIONS ON ELECTRICAL AND ELECTRONIC ENGINEERING","","1931-4973","10.1002/tee.23877","","Linear phase shifting transformer is a new type of phase shifting transformer with the advantages of simple winding structure, easy modularity, and the ability to shift phase at any angle. In order to improve the efficiency and power factor of linear phase shift transformer and reduce the weight of the body, based on the equivalent circuit, this paper first, selects the main design parameters of the linear phase shift transformer model as the optimization object, secondly, selects the constraints and objective function applicable to this model, and then, establishes the linear phase shift transformer optimization design model. Finally, a differential evolutionary algorithm with strong global search performance is used to optimize the design parameters. Taking the 1 kW linear phase shifting transformer as an example, the efficiency, power factor, and weight before and after optimization are compared using finite element simulation to verify the effectiveness of the proposed optimization method. The test results of the experimental prototype prove that the proposed method can effectively solve the optimization design problem of linear phase shifting transformers. (c) 2023 Institute of Electrical Engineer of Japan and Wiley Periodicals LLC.","2023-09","2025-02-26 20:41:51","2025-02-26 20:41:51","","1439-1450","","9","18","","","","","","","","","","English","","","","WOS:001146775400018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","differential evolutionary algorithm; finite element analysis; INDUCTION-MOTOR; linear phase shift transformer; multi-objective optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H6DINYDU","journalArticle","2025","Jeon, YJ; Hong, MJ; Ko, CS; Park, SJ; Lee, H; Lee, WG; Jung, DH","A hybrid CNN-Transformer model for identification of wheat varieties and growth stages using high-throughput phenotyping","COMPUTERS AND ELECTRONICS IN AGRICULTURE","","0168-1699","10.1016/j.compag.2024.109882","","Wheat (Triticum aestivum L.) is a major crop consumed and cultivated worldwide, with various varieties bred to meet the growth characteristics and resistances required by the climate conditions of each cultivation region. However, as global climate change accelerates, rapid environmental shifts have led to crossover interaction, where previously superior varieties undergo changes, making variety selection increasingly challenging. In particular, there is a lack of research on methods for rapidly assessing growth rate, a key characteristic of crossover interactions, during the variety selection process. This study proposes a deep learning-based model and method for identifying wheat varieties and growth stages using hyperspectral data obtained from six wheat varieties cultivated on a high-throughput phenotyping platform. The proposed model, which combines a CNN and Transformer, achieved 94.05% accuracy in variety detection, surpassing the performance of related studies, and 99.24% accuracy in growth stage detection. This model enables high-throughput monitoring of wheat variety and growth information effectively. Furthermore, if applied to the wheat breeding process, the proposed model is expected to contribute to the rapid selection of superior varieties suited to specific climate conditions.","2025-03","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","230","","","","","","","","","","English","","","","WOS:001399934000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","BREAD; Convolutional neural networks; HYPERSPECTRAL IMAGES; Hyperspectral imaging; PERFORMANCE; Phenotyping platform; Self-attention mechanism","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ITRBXRCT","journalArticle","2025","Seifaddini, N; Sekongo, B; Fofana, I; Akre, S; Chehri, A; Ouhrouche, M","Towards winding deformation assessment from vibration signals using an optical sensor","IET SCIENCE MEASUREMENT & TECHNOLOGY","","1751-8822","10.1049/smt2.12224","","In the era of Industry 4.0, there is a growing emphasis on the digitization of electrical networks. Over recent decades, the integration of interconnected digital technologies, including sensors and communication systems, within electrical substations has emerged as a significant driver. Consequently, there is an increasing need for precise online monitoring of critical assets such as power transformers to enhance grid reliability. This study utilizes an optical-based Fiber Bragg Grating (FBG) sensor to capture vibration signals from a custom-designed single-phase transformer model, specifically developed for experimental purposes. This model offers a unique advantage with its ability to interchangeably simulate healthy and distorted winding sections without causing damage. Using a high current source, the laboratory model was subjected to three different current levels across six distinct configurations to monitor winding displacements. The results from this investigation highlight the FBG sensor's capability to accurately distinguish between healthy and distorted winding sections. Furthermore, this feasibility study represents a significant step forward in the online mechanical assessment of transformer windings, moving away from traditional methods that require transformers to be taken out of service for inspection. This innovative approach shows considerable potential for implementing effective real-time monitoring of winding deformation in power transformers.","2025-01-01","2025-02-26 20:41:51","2025-02-26 20:41:51","","1-9","","1","19","","","","","","","","","","English","","","","WOS:001359777800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","FIBER; optical sensors; TEMPERATURE; transformer windings; vibration measurement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RLC2IZEZ","journalArticle","2024","Li, BW; Liu, L; Ma, RY; Guo, LF; Jiang, JW; Li, KX; Li, XJ","Siamese based few-shot learning lightweight transformer model for coagulant and disinfectant dosage simultaneous regulation","CHEMICAL ENGINEERING JOURNAL","","1385-8947","10.1016/j.cej.2024.156025","","Deep learning (DL) has emerged as a transformative and promising approach to address inefficient resource management due to imprecise chemical dosing in conventional manual-dependent drinking water treatment. However, the scarcity of high-quality data and limited computing resources of embedded devices hinder the development and deployment of state-of-the-art (SOTA) DL models. Herein, a novel lightweight Transformer (LighT) model integrated with the Siamese structure was proposed for simultaneous regulation of coagulant dosage (FeCl3 and PAC) and disinfectant dosage (NaClO) and compared with other attention-based DL models. The results demonstrate that LighT showed robust few-shot learning effectiveness and outperformed other models in multi-output prediction (R-2 values of 0.99 and RMSE of 0.20 mg/L, 0.16 mg/L and 0.45 mg/L, respectively). The LighT model also exhibited enhanced cost-effectiveness with a 79.74 % compression in model parameters and a 36.14 % decrease in inference time. The LighT-based chemical dosage prediction program was sustained for one month of operation, which can save chemical dosage by 15.81 % while maintaining satisfactory product water quality, indicating the potential of LighT for economizing chemical dosing strategy in drinking water treatment.","2024-11-01","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","499","","","","","","","","","","English","","","","WOS:001321858500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","Attention mechanism; Deep learning; Drinking water treatment; Few-shot learning; Model deployment; NEURAL-NETWORKS; PREDICTION; Time series prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I8MXCX7C","journalArticle","2024","Ramprasad, P; Pai, ND; Pan, W","Enhancing personalized gene expression prediction from DNA sequences using genomic foundation models","HUMAN GENETICS AND GENOMICS ADVANCES","","2666-2477","10.1016/j.xhgg.2024.100347","","Artificial intelligence (AI)/deep learning (DL) models that predict molecular phenotypes like gene expression directly from DNA sequences have recently emerged. While these models have proven effective at capturing the variation across genes, their ability to explain inter-individual differences has been limited. We hypothesize that the performance gap can be narrowed through the use of pre-trained embeddings from the Nucleotide Transformer, a large foundation model trained on 3,000 & thorn; genomes. We train a transformer model using the pre-trained embeddings and compare its predictive performance to Enformer, the current state-of-the-art model, using genotype and expression data from 290 individuals. Our model significantly outperforms Enformer in terms of correlation across individuals, and narrows the performance gap with an elastic net regression approach that uses just the genetic variants as predictors. Although simple regression models have their advantages in personalized prediction tasks, DL approaches based on foundation models pre-trained on diverse genomes have unique strengths in flexibility and interpretability. With further methodological and computational improvements with more training data, these models may eventually predict molecular phenotypes from DNA sequences with an accuracy surpassing that of regression-based approaches. Our work demonstrates the potential for large pre-trained AI/DL models to advance functional genomics.","2024-10-10","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","4","5","","","","","","","","","","English","","","","WOS:001313214000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","ASSOCIATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JJTFKUUE","journalArticle","2024","Zuhra, FT; Saleem, K; Naz, S","An accurate transformer-based model for transition-based dependency parsing of free word order languages","JOURNAL OF KING SAUD UNIVERSITY-COMPUTER AND INFORMATION SCIENCES","","1319-1578","10.1016/j.jksuci.2024.102107","","Transformer models are the state-of-the-art in Natural Language Processing (NLP) and the core of the Large Language Models (LLMs). We propose a transformer-based model for transition-based dependency parsing of free word order languages. We have performed experiments on five treebanks from the Universal Dependencies (UD) dataset version 2.12. Our experiments show that a transformer model, trained with the dynamic word embeddings performs better than a multilayer perceptron trained on the state-of-the-art static word embeddings even if the dynamic word embeddings have a vocabulary size ten times smaller than the static word embeddings. The results show that the transformer trained on dynamic word embeddings achieves an unlabeled attachment score (UAS) of 84.17% for Urdu language which is approximate to 3 . 6% and approximate to 1 . 9% higher than the UAS scores of 80.56857% and 82.26859% achieved by the multilayer perceptron (MLP) using two static state-ofthe-art word embeddings. The proposed approach is investigated for Arabic, Persian and Uyghur languages, in addition to Urdu, for UAS scores and the results suggest that the proposed solution outperform the MLP-based approaches.","2024-07","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","6","36","","","","","","","","","","English","","","","WOS:001261229500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","Dynamic word embeddings; Free word order languages; Natural language processing; Static word embeddings; Transformer; Transition-based dependency parsing; Unlabeled attachment score","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q4MIIJFJ","journalArticle","2024","Li, D; Hu, Y; Miao, SW; Fang, ZR; Liang, YY; He, S","Adaptive temporal transformer method for short-term wind power forecasting considering shift in time series distribution","AIP ADVANCES","","2158-3226","10.1063/5.0186628","","In wind power prediction, the input probability distributions in the different sub-periods are shifted owing to the strong randomness of the input features, such as wind speed and direction. This may violate the assumption for machine learning that the training and test data meet the condition of being independent and identically distributed, resulting in an insufficient generalization ability of the prediction model that is trained with the training data and applied to unknown test data. To address this problem, this study proposes an adaptive temporal transformer method for short-term wind power forecasting. First, a temporal transformer model with a gate recurrent unit and multi-head attention layers was used to extract the short- and long-term temporal information of the multiple input variables. Then, an adaptive learning strategy consisting of two stages-temporal distribution characterization and temporal distribution matching-was developed to explore the common knowledge hidden in each sub-period. The case results for an actual wind farm in northwest China showed that the proposed method could effectively weaken the adverse effects of the shifts in time series distribution on forecasting and improve the accuracy and generalization of short-term wind power prediction. (c) 2024 Author(s).","2024-02-01","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","2","14","","","","","","","","","","English","","","","WOS:001178239300002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","PREDICTION; SPEED","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WF63SAUB","journalArticle","2023","Sun, W; Cheng, RZ; Jiao, YQ; Gao, JB; Zheng, ZD; Lu, N","Transformer network with decoupled spatial-temporal embedding for traffic flow forecasting","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-023-05126-x","","Over the past few years, there has been significant research on applying Transformer models to time series prediction, yielding promising results. Simultaneously, researchers have begun exploring the utilization of Transformers for traffic prediction in order to mitigate the nonlinear spatial-temporal correlation inherent in traffic data. Some of these studies have attempted to characterize spatial-temporal features by incorporating embedding structures, with the goal of improving performance of the model. However, existing methods have not adequately addressed the issue of spatial-temporal correlation. To address these limitations, we propose the Transformer Network with Decoupled Spatial-Temporal Embedding (DSTET) model for traffic flow prediction. The key aspect of our model is its ability to effectively decouple the spatial and temporal embedding through the implementation of the Decoupled Spatial-Temporal Embedding structure. This structure enhances the characterization of spatial-temporal features, ultimately improving the performance of traffic prediction based on the Transformer model. Through experiments conducted on six real-world traffic datasets, our model consistently outperforms multiple baseline models, demonstrating its capability to address the identified problems. Moreover, we substantiate the efficacy of the suggested components via ablation experiments and furnish a thorough analysis of the attention weight matrix to clarify the functioning of the model.","2023-12","2025-02-26 20:41:51","2025-02-26 20:41:51","","30148-30168","","24","53","","","","","","","","","","English","","","","WOS:001101038200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Embedding; Traffic Forecasting; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7GATIR48","journalArticle","2023","Zhang, WJ; Ding, YJ; Zhang, MH; Zhang, YH; Cao, L; Huang, ZQ; Wang, J","TCPCNet: a transformer-CNN parallel cooperative network for low-light image enhancement","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-023-17527-8","","Recently, deep learning has made impressive achievements in low-light image enhancement. Most existing deep learning-based methods use convolutional neural networks (CNN) by stacking network depth and modifying network architecture to improve feature extraction capabilities and restore degraded images. However, these methods have obvious defects. Although CNN excels at extracting local features, its small receptive field is unable to capture the global brightness, leading to overexposure. The Transformer model from natural language processing has recently produced positive outcomes in a variety of computer vision issues thanks to its excellent global modeling capabilities. However, its complex modeling method makes it difficult to capture local details and takes up many computing resources, making it challenging to apply to the enhancement of low-light images, especially high-resolution images. Based on deep convolution and Transformer characteristics, this paper proposes a Transformer-CNN Parallel Cooperative Network (TCPCNet), which supplements image details and local brightness while ensuring global brightness control. We also changed the calculation method of the traditional Transformer to be applied to enhance high-resolution low-light images without affecting performance. Extensive experiments on public datasets show that the proposed TCPCNet achieves comparable performance against the state-of-the-art approaches.","2023-11-06","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","","","","","","","","","","","English","","","","WOS:001099271500010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","ILLUMINATION; Low-light image enhancement; Transformer; Transformer-CNN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AW8X9RJ2","journalArticle","2023","Ghimire, S; Nguyen-Huy, T; AL-Musaylh, MS; Deo, RC; Casillas-Pérez, D; Salcedo-Sanz, S","Integrated Multi-Head Self-Attention Transformer model for electricity demand prediction incorporating local climate variables","ENERGY AND AI","","2666-5468","10.1016/j.egyai.2023.100302","","This paper develops a trustworthy deep learning model that considers electricity demand (G) and local climate conditions. The model utilises Multi-Head Self-Attention Transformer (TNET) to capture critical information from G, to attain reliable predictions with local climate (rainfall, radiation, humidity, evaporation, and maximum and minimum temperatures) data from Energex substations in Queensland, Australia. The TNET model is then evaluated with deep learning models (Long-Short Term Memory LSTM, Bidirectional LSTM BILSTM, Gated Recurrent Unit GRU, Convolutional Neural Networks CNN, and Deep Neural Network DNN) based on robust model assessment metrics. The Kernel Density Estimation method is used to generate the prediction interval (PI) of electricity demand forecasts and derive probability metrics and results to show the developed TNET model is accurate for all the substations. The study concludes that the proposed TNET model is a reliable electricity demand predictive tool that has high accuracy and low predictive errors and could be employed as a stratagem by demand modellers and energy policy-makers who wish to incorporate climatic factors into electricity demand patterns and develop national energy market insights and analysis systems.","2023-10","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","14","","","","","","","","","","English","","","","WOS:001088541900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;97</p>","","","ALGORITHM; Artificial Intelligence; DECOMPOSITION; Deep learning; Electricity demand forecasting; FORECASTING-MODEL; GLOBAL SOLAR-RADIATION; Kernel Density Estimation; NEURAL-NETWORK; Sustainable energy; TIME-SERIES; Transformer Networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3W52WEHY","journalArticle","2023","Chi, JL; Qu, Y; Liu, T; Zheng, QH; Yin, H","SeqTrans: Automatic Vulnerability Fix Via Sequence to Sequence Learning","IEEE TRANSACTIONS ON SOFTWARE ENGINEERING","","0098-5589","10.1109/TSE.2022.3156637","","Software vulnerabilities are now reported unprecedentedly due to the recent development of automated vulnerability hunting tools. However, fixing vulnerabilities still mainly depends on programmers' manual efforts. Developers need to deeply understand the vulnerability and affect the system's functions as little as possible. In this paper, with the advancement of Neural Machine Translation (NMT) techniques, we provide a novel approach called SeqTrans to exploit historical vulnerability fixes to provide suggestions and automatically fix the source code. To capture the contextual information around the vulnerable code, we propose to leverage data-flow dependencies to construct code sequences and feed them into the state-of-the-art transformer model. The fine-tuning strategy has been introduced to overcome the small sample size problem. We evaluate SeqTrans on a dataset containing 1,282 commits that fix 624 CVEs in 205 Java projects. Results show that the accuracy of SeqTrans outperforms the latest techniques and achieves 23.3% in statement-level fix and 25.3% in CVE-level fix. In the meantime, we look deep inside the result and observe that the NMT model performs very well in certain kinds of vulnerabilities like CWE-287 (Improper Authentication) and CWE-863 (Incorrect Authorization).","2023-02-01","2025-02-26 20:41:51","2025-02-26 20:41:51","","564-585","","2","49","","","","","","","","","","English","","","","WOS:000937151900006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;20<br/>Cited Reference Count:&nbsp;&nbsp;103</p>","","","CODE; Codes; Computer bugs; Decoding; Machine learning; Maintenance engineering; neural machine translation; Predictive models; software engineering; Training; Transformers; vulnerability fix","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MA57D7ST","journalArticle","2023","Qaiser, A; Hina, S; Kazi, AK; Ahmed, S; Asif, R","Fake News Encoder Classifier (FNEC) for Online Published News Related to COVID-19 Vaccines","INTELLIGENT AUTOMATION AND SOFT COMPUTING","","1079-8587","10.32604/iasc.2023.036784","","In the past few years, social media and online news platforms have played an essential role in distributing news content rapidly. Consequently. verification of the authenticity of news has become a major challenge. During the COVID-19 outbreak, misinformation and fake news were major sources of confusion and insecurity among the general public. In the first quarter of the year 2020, around 800 people died due to fake news relevant to COVID-19. The major goal of this research was to discover the best learning model for achieving high accuracy and performance. A novel case study of the Fake News Classification using ELECTRA model, which achieved 85.11% accuracy score, is thus reported in this manuscript. In addition to that, a new novel dataset called COVAX-Reality containing COVID-19 vaccinerelated news has been contributed. Using the COVAX-Reality dataset, the performance of FNEC is compared to several traditional learning models i.e., Support Vector Machine (SVM), Naive Bayes (NB), Passive Aggressive Classifier (PAC), Long Short-Term Memory (LSTM), Bi-directional LSTM (Bi-LSTM) and Bi-directional Encoder Representations from Transformers (BERT). For the evaluation of FNEC, standard metrics (Precision, Recall, Accuracy, and F1-Score) were utilized.","2023","2025-02-26 20:41:51","2025-02-26 20:41:51","","73-90","","1","37","","","","","","","","","","English","","","","WOS:000993115400005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","classification; Deep learning; fake news detection; machine learning; TEXT; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5WRSCPR4","journalArticle","2021","Mishra, P; Diwan, C; Srinivasa, S; Srinivasaraghavan, G","Automatic Title Generation for Learning Resources and Pathways with Pre-trained Transformer Models","INTERNATIONAL JOURNAL OF SEMANTIC COMPUTING","","1793-351X","10.1142/S1793351X21400134","","To create curiosity and interest for a topic in online learning is a challenging task. A good preview that outlines the contents of a learning pathway could help learners know the topic and get interested in it. Towards this end, we propose a hierarchical title generation approach to generate semantically relevant titles for the learning resources in a learning pathway and a title for the pathway itself. Our approach to Automatic Title Generation for a given text is based on pre-trained Transformer Language Model GPT-2. A pool of candidate titles are generated and an appropriate title is selected among them which is then refined or de-noised to get the final title. The model is trained on research paper abstracts from arXiv and evaluated on three different test sets. We show that it generates semantically and syntactically relevant titles as reflected in ROUGE, BLEU scores and human evaluations. We propose an optional abstractive Summarizer module based on pre-trained Transformer model T5 to shorten medium length documents. This module is also trained and evaluated on research papers from arXiv dataset. Finally, we show that the proposed model of hierarchical title generation for learning pathways has promising results.","2021-12","2025-02-26 20:41:51","2025-02-26 20:41:51","","487-510","","04","15","","","","","","","","","","English","","","","WOS:000732500900005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","learning pathways; natural language processing; technology-enhanced learning; Title generation; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WDACVR3A","journalArticle","2021","Mombello, EE; Portillo, A; Florez, GAD","New State-Space White-Box Transformer Model for the Calculation of Electromagnetic Transients","IEEE TRANSACTIONS ON POWER DELIVERY","","0885-8977","10.1109/TPWRD.2020.3023824","","White-box models are detailed models for the investigation of the internal behavior of transformers during dielectric design. A new model of this type with significantly improved characteristics is presented in this paper. The model has been developed in state-space form, which is more flexible than an equivalent circuit and also makes it possible to optionally hide proprietary information on internal voltages. The proposed parameter determination methodology is very robust and allows the adequate representation of the damping. The methodology for determining inductive impedances and capacitances as a function of frequency using the Finite Element Method is described first. Then the fitting of the impedances obtained in the frequency domain by means of rational approximation functions is presented, which is based on the Vector Fitting algorithm in combination with Particle Swarm Optimization. The state-space model is obtained next, which is then used to perform time and frequency domain calculations. This new model has been successfully validated by comparison with measurements on a large power transformer used as case study during the activities of the JWG CIGRE A2/C4.52.","2021-10","2025-02-26 20:41:51","2025-02-26 20:41:51","","2615-2624","","5","36","","","","","","","","","","English","","","","WOS:000698898900008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","COMPUTATION; Damping; damping modeling; Equivalent circuits; Finite element analysis; IMPULSE VOLTAGE DISTRIBUTION; Integrated circuit modeling; Mathematical model; PARAMETERS; power system transients; Power transformers; RATIONAL APPROXIMATION; Transformers; white-box models; Windings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TQZJZTYI","journalArticle","2021","Zaikis, D; Vlahavas, I","TP-DDI: Transformer-based pipeline for the extraction of Drug-Drug Interactions","ARTIFICIAL INTELLIGENCE IN MEDICINE","","0933-3657","10.1016/j.artmed.2021.102153","","Drug-Drug Interaction (DDI) extraction is the task of identifying drug entities and the potential interactions between drug pairs from biomedical literature. Computer-aided extraction of DDIs is vital for drug discovery, as this process remains extremely expensive and time consuming. Therefore, Machine Learning-based approaches can reduce the laborious task during the drug development cycle. Numerous traditional and Neural Network based approaches for Drug Named Entity Recognition (DNER) and the classification of DDIs have been proposed over the years. However, despite the development of many effective methods, achieving good prediction accuracy is an area where significant improvement can be made. In this article, we present a novel end-to-end approach that tackles the overall DDI extraction task as a pipelined method via the Transformer model architecture and biomedical domain pre-trained weights. In our approach, the tasks of DNER and DDI classification are executed successively to extract the drug entities and to classify their relationship respectively. The proposed approach, TP-DDI, integrates prior knowledge by using pre-trained weights from BioBERT and improves in both the Drug Named Entity Recognition and the overall DDI extraction task over the current state-of-the-art approaches on the DDI Extraction 2013 corpus.","2021-09","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","119","","","","","","","","","","English","","","","WOS:000696969400003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Drug named entity recognition; Drug-drug interaction; Pipeline; Relation classification; Relationship extraction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5X4XKURE","journalArticle","2025","Song, XN; Tian, YB; Liu, HC; Wang, LJ; Niu, JX","PPLA-Transformer: An Efficient Transformer for Defect Detection with Linear Attention Based on Pyramid Pooling","SENSORS","","1424-8220","10.3390/s25030828","","Defect detection is crucial for quality control in industrial products. The defects in industrial products are typically subtle, leading to reduced accuracy in detection. Furthermore, industrial defect detection often necessitates high efficiency in order to meet operational demands. Deep learning-based algorithms for surface defect detection have been increasingly applied to industrial production processes. Among them, Swin-Transformer achieves remarkable success in many visual tasks. However, the computational burden imposed by numerous image tokens limits the application of Swin-Transformer. To enhance both the detection accuracy and efficiency, this paper proposes a linear attention mechanism based on pyramid pooling. It utilizes a more concise linear attention mechanism to reduce the computational load, thereby improving detection efficiency. Furthermore, it enhances global feature extraction capabilities through pyramid pooling, which improves the detection accuracy. Additionally, the incorporation of partial convolution into the model improves local feature extraction, further enhancing detection precision. Our model demonstrates satisfactory performance with minimal computational cost. It outperforms Swin-Transformer by 1.2% mAP and 52 FPS on the self-constructed SIM card slot defect dataset. When compared to the Swin-Transformer model on the public PKU-Market-PCB dataset, our model achieves an improvement of 1.7% mAP and 51 FPS. These results validate the universality of the proposed approach.","2025-02","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","3","25","","","","","","","","","","English","","","","WOS:001419638200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","attention; defect detection; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JWL3AMJT","journalArticle","2023","Dhiaf, M; Rouhou, AC; Kessentini, Y; Ben Salem, S","MSdocTr-Lite: A lite transformer for full page multi-script handwriting recognition","PATTERN RECOGNITION LETTERS","","0167-8655","10.1016/j.patrec.2023.03.020","","The Transformer has quickly become the dominant architecture for various pattern recognition tasks due to its capacity for long-range representation. However, transformers are data-hungry models and need large datasets for training. In Handwritten Text Recognition (HTR), collecting a massive amount of labeled data is a complicated and expensive task. In this paper, we propose a lite transformer architecture for full-page multi-script handwriting recognition. The proposed model comes with three advantages: First, to solve the common problem of data scarcity, we propose a lite transformer model that can be trained on a reasonable amount of data, which is the case of most HTR public datasets, without the need for external data. Second, it can learn the reading order at page-level thanks to a curriculum learning strategy, allowing it to avoid line segmentation errors, exploit a larger context and reduce the need for costly segmentation annotations. Third, it can be easily adapted to other scripts by applying a simple transferlearning process using only page-level labeled images. Extensive experiments on different datasets with different scripts (French, English, Spanish, and Arabic) show the effectiveness of the proposed model. (c) 2023 Elsevier B.V. All rights reserved.","2023-05","2025-02-26 20:41:51","2025-02-26 20:41:51","","28-34","","","169","","","","","","","","","","English","","","","WOS:000978765500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Handwritten text recognition; Multi-script; Page-level recognition; Seq2Seq model; Transfer learning; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HQCC7GFS","journalArticle","2022","Thomsen, BL; Christensen, JB; Rodenko, O; Usenov, I; Gronnemose, RB; Andersen, TE; Lassen, M","Accurate and fast identification of minimally prepared bacteria phenotypes using Raman spectroscopy assisted by machine learning","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-022-20850-z","","The worldwide increase of antimicrobial resistance (AMR) is a serious threat to human health. To avert the spread of AMR, fast reliable diagnostics tools that facilitate optimal antibiotic stewardship are an unmet need. In this regard, Raman spectroscopy promises rapid label- and culture-free identification and antimicrobial susceptibility testing (AST) in a single step. However, even though many Raman-based bacteria-identification and AST studies have demonstrated impressive results, some shortcomings must be addressed. To bridge the gap between proof-of-concept studies and clinical application, we have developed machine learning techniques in combination with a novel data-augmentation algorithm, for fast identification of minimally prepared bacteria phenotypes and the distinctions of methicillin-resistant (MR) from methicillin-susceptible (MS) bacteria. For this we have implemented a spectral transformer model for hyper-spectral Raman images of bacteria. We show that our model outperforms the standard convolutional neural network models on a multitude of classification problems, both in terms of accuracy and in terms of training time. We attain more than 96% classification accuracy on a dataset consisting of 15 different classes and 95.6% classification accuracy for six MR-MS bacteria species. More importantly, our results are obtained using only fast and easy-to-produce training and test data.","2022-09-30","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","1","12","","","","","","","","","","English","","","","WOS:000862424900061","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","ANTIMICROBIAL RESISTANCE; DIAGNOSTICS; MECHANISMS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BMAB8IA5","journalArticle","2025","Rong, J; Wang, C; Zhou, QZ; He, YX; Wu, HA","Enhancing non-intrusive load monitoring through transfer learning with transformer models","ENERGY AND BUILDINGS","","0378-7788","10.1016/j.enbuild.2025.115334","","As global energy demands continue to rise, the importance of efficient energy management systems becomes increasingly clear. Non-invasive load monitoring (NILM) technologies, which identify the energy consumption of individual loads through the analysis of aggregate mains data without physical alterations to the electrical system, are gaining widespread attention. To address persistent challenges of low prediction accuracy and weak model generalization in NILM, this paper introduces TransDisNILM-an optimized transformer based NILM model enhanced by transfer learning. First, sinusoidal encoding and improved multi-head transformer encoder layers are employed to capture richer temporal features, thereby improving prediction accuracy in complex multi-load scenarios. Second, transfer learning strategies are applied to systematically select source tasks and fine-tune the model, enabling robust generalization across diverse environments and load types. Evaluation results on multiple public datasets demonstrate that TransDisNILM significantly reduces mean absolute error and normalized signal aggregate error, outperforming state-of-the-art methods. Moreover, TransDisNILM's transfer learning strategies allow effective training across different load types without starting from scratch, thus reducing the reliance on large-scale labeled datasets. Overall, TransDisNILM not only achieves higher accuracy but also exhibits stronger generalization capabilities, advancing the practical deployment of NILM technologies.","2025-03-01","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","330","","","","","","","","","","English","","","","WOS:001405648200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","APPLIANCE CLASSIFICATION; Non-intrusive load monitoring (NILM); Smart grids; Transfer learning; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"URC3NJ5X","journalArticle","2025","Li, JY; Dong, WY; Gui, XW","uTransformer: unified spatial-temporal transformer with external factors for traffic flow forecasting","JOURNAL OF SUPERCOMPUTING","","0920-8542","10.1007/s11227-024-06774-7","","Traffic flow forecasting is essential for applications such as route planning and vehicle communication. However, dynamic traffic patterns, diverse spatial-temporal dependencies, and external factors pose significant challenges. Existing methods often model temporal, spatial, and external factors separately, failing to capture their joint effects across different spatial-temporal scales and external influences. To address these, we propose uTransformer, a unified transformer model that captures joint spatial-temporal dependencies and integrates external factors like weather and holidays. Unlike existing models, uTransformer constructs a three-dimensional spatial-temporal correlation map (STC-MAP) to model spatial-temporal interactions across various time scales, effectively capturing long-range dependencies. Additionally, it features a scalable encoding scheme that flexibly incorporates multiple types and quantities of external factors. Experimental results on NYC-BIKE and NYC-TAXI datasets show uTransformer achieves high accuracy, with RMSE improved by 10.97%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document} and MAPE by 16.06%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document}, outperforming baseline models and enhancing prediction reliability.","2025-01","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","1","81","","","","","","","","","","English","","","","WOS:001374832400007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Attention mechanism; External factor integration; MODEL; Spatial-temporal modeling; Traffic forecasting; Transformer; Unified encoding scheme","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2FA8IRRT","journalArticle","2025","Wang, L; Guo, WN; Guo, JY; Zheng, SC; Wang, ZY; Kang, HS; Li, H","An integrated deep learning model for intelligent recognition of long-distance natural gas pipeline features","RELIABILITY ENGINEERING & SYSTEM SAFETY","","0951-8320","10.1016/j.ress.2024.110664","","Pipeline feature recognition is crucial for the reliability and safety of long-distance natural gas pipelines. Utilizing manual or machine learning methods to recognize pipeline features is not only inefficient, but also has problems such as high misjudgment rate and poor robustness. To overcome the above problems, this paper proposes a pipeline feature recognition method based on Multi-scale Attention Convolutional Neural Network (MACNN) and Gated_Twins_Transformer. MACNN is used to extract multi-scale information of pipeline features, and then the attention mechanism in it to focus on the more important feature information and suppress the less important feature information. It is then transmitted to the Gated_Twins_Transformer model, which uses the gated mechanism and the twins encoder module to determine the importance of the data length and input dimensions, focusing on the feature information of both with different weights, and the Transformer enhances the extraction of global features. Finally, the measured pipeline bending strain data are used as model input, trained and tested, and compared with other advanced models, the superiority of the proposed model in this paper is verified by comparing the metrics of Accuracy, Precision, Recall and F1-score.","2025-03","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","255","","","","","","","","","","English","","","","WOS:001371283900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Bending strain; Feature recognition; Gated_Twins_Transformer; Long-distance natural gas pipelines; MACNN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5RZ2R9RI","journalArticle","2024","Singh, B; Singh, D; Kaushal, R; Halder, A; Chattopadhyay, P","GSSTU: Generative Spatial Self-Attention Transformer Unit for Enhanced Video Prediction","IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS","","2162-237X","10.1109/TNNLS.2024.3359716","","Future frame prediction is a challenging task in computer vision with practical applications in areas such as video generation, autonomous driving, and robotics. Traditional recurrent neural networks have limited effectiveness in capturing long-range dependencies between frames, and combining convolutional neural networks (CNNs) with recurrent networks has limitations in modeling complex dependencies. Generative adversarial networks have shown promising results, but they are computationally expensive and suffer from instability during training. In this article, we propose a novel approach for future frame prediction that combines the encoding capabilities of 3-D CNNs with the sequence modeling capabilities of Transformers. We also propose a spatial self-attention mechanism and a novel neighborhood pixel intensity loss to preserve structural information and local intensity, respectively. Our approach outperforms existing methods in terms of structural similarity (SSIM), peak signal-to-noise ratio (PSNR), and learned perceptual image patch similarity (LPIPS) scores on five public datasets. More precisely, our model exhibited an average improvement of 4.64%, 18.5%, and 42% concerning SSIM, PSNR, and LPIPS for the second most proficient method correspondingly, across all datasets. The results demonstrate the effectiveness of our proposed method in generating high-quality predictions of future frames.","2024-02-27","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","","","","","","","","","","","English","","","","WOS:001178962700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Computational modeling; Convolution; Encoding; Multiheaded self-attention; Predictive models; spatial self-attention; Task analysis; Training; Transformer model; Transformers; video frame prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L9IPIAHT","journalArticle","2024","Shah, HA; Saeed, F; Diyan, M; Almujally, NA; Kang, JM","ECG-TransCovNet: A hybrid transformer model for accurate arrhythmia detection using Electrocardiogram signals","CAAI TRANSACTIONS ON INTELLIGENCE TECHNOLOGY","","2468-6557","10.1049/cit2.12293","","Abnormalities in the heart's rhythm, known as arrhythmias, pose a significant threat to global health, often leading to severe cardiac conditions and sudden cardiac deaths. Therefore, early and accurate detection of arrhythmias is crucial for timely intervention and potentially life-saving treatment. Artificial Intelligence, particularly deep learning, has revolutionised the detection and diagnosis of various health conditions, including arrhythmias. A unique hybrid architecture, ECG-TransCovNet, that combines Convolutional Neural Networks and Transformer models for enhanced arrhythmia detection in Electrocardiogram signals is introduced. The authors' approach leverages the superior temporal pattern recognition capabilities of Transformers and the spatial feature extraction strengths of convolutional neural networks, providing a robust and accurate solution for arrhythmia detection. The performance and generalisability of the authors' proposed model are validated through tests on the MIT-BIH arrhythmia and PhysioNet databases. The authors conducted experimental trials using these two benchmark datasets. The authors' results demonstrate that the proposed ECG-TransCovNet model achieves state-of-the-art (SOTA) performance in terms of detection accuracy, reaching 98.6%. Additionally, the authors conducted several experiments and compared the results to the most recent techniques utilising their assessment measures. The experimental results demonstrate that the authors' model can generally produce better results.","2024-02-12","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","","","","","","","","","","","English","","","","WOS:001160429100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","artificial intelligence; biology computing; deep learning; machine learning; signal detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E83P9A3R","journalArticle","2023","Liu, BS; Liu, YJ; Zhang, WL; Tian, YR; Kong, WL","Spectral Swin Transformer Network for Hyperspectral Image Classification","REMOTE SENSING","","2072-4292","10.3390/rs15153721","","Hyperspectral images are complex images that contain more spectral dimension information than ordinary images. An increasing number of HSI classification methods are using deep learning techniques to process three-dimensional data. The Vision Transformer model is gradually occupying an important position in the field of computer vision and is being used to replace the CNN structure of the network. However, it is still in the preliminary research stage in the field of HSI. In this paper, we propose using a spectral Swin Transformer network for HSI classification, providing a new approach for the HSI field. The Swin Transformer uses group attention to enhance feature representation, and the sliding window attention calculation can take into account the contextual information of different windows, which can retain the global features of HSI and improve classification results. In our experiments, we evaluated our proposed approach on several public hyperspectral datasets and compared it with several methods. The experimental results demonstrate that our proposed model achieved test accuracies of 97.46%, 99.7%, and 99.8% on the IP, SA, and PU public HSI datasets, respectively, when using the AdamW optimizer. Our approach also shows good generalization ability when applied to new datasets. Overall, our proposed approach represents a promising direction for hyperspectral image classification using deep learning techniques.","2023-08","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","15","15","","","","","","","","","","English","","","","WOS:001046308500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","CNN; deep learning; hyperspectral image classification; SVM; Swin Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AK9PS8VV","journalArticle","2023","Yu, B; Yin, P; Chen, HC; Wang, YF; Zhao, Y; Cong, XL; Dijkstra, J; Cong, LL","Pyramid multi-loss vision transformer for thyroid cancer classification using cytological smear","KNOWLEDGE-BASED SYSTEMS","","0950-7051","10.1016/j.knosys.2023.110721","","Multi-instance learning, a commonly used technique in artificial intelligence for analyzing slides, can be applied to diagnose thyroid cancer based on cytological smears. Since smears do not have mul-tidimensional histological features similar to histopathology, mining potential contextual information and diversity of features is crucial for better classification performance. In this paper, we propose a pyramid multi-loss vision transformer model called PyMLViT, a novel algorithm with two core modules to address these issues. Specifically, we design a pyramid token extraction module to acquire potential contextual information on smears. The pyramid token structure extracts multi-scale local features, and the vision transformer structure further obtains global information through the self -attention mechanism. Furthermore, we construct multi-loss fusion module based on the conventional multi-instance learning framework. With carefully designed bag and patch weight allocation strategies, we incorporate slide-level annotations as pseudo-labels for patches to participate in training, thus enhancing the diversity of supervised information. Extensive experimental results on the real-world dataset show that PyMLViT has a high performance and a competitive number of parameters compared to popular methods for diagnosing thyroid cancer in cytological smears.& COPY; 2023 Elsevier B.V. All rights reserved.","2023-09-05","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","275","","","","","","","","","","English","","","","WOS:001034131100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Cytological smear; Multiple instance learning; Pyramid feature; Thyroid cancer; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QW53RS8P","journalArticle","2023","Flyckt, J; Andersson, F; Westphal, F; Månsson, A; Lavesson, N","Explaining rifle shooting factors through multi-sensor body tracking","INTELLIGENT DATA ANALYSIS","","1088-467X","10.3233/IDA-216457","","There is a lack of data-driven training instructions for sports shooters, as instruction has commonly been based on subjective assessments. Many studies have correlated body posture and balance to shooting performance in rifle shooting tasks, but have mostly focused on single aspects of postural control. This study has focused on finding relevant rifle shooting factors by examining the entire body over sequences of time. A data collection was performed with 13 human participants carrying out live rifle shooting scenarios while being recorded with multiple body tracking sensors. A pre-processing pipeline produced a novel skeleton sequence representation, which was used to train a transformer model. The predictions from this model could be explained on a per sample basis using the attention mechanism, and visualised in an interactive format for humans to interpret. It was possible to separate the different phases of a shooting scenario from body posture with a high classification accuracy (80%). Shooting performance could be detected to an extent by separating participants using their strong and weak shooting hand. The dataset and pre-processing pipeline, as well as the techniques for generating explainable predictions presented in this study have laid the groundwork for future research in the sports shooting domain.","2023","2025-02-26 20:41:51","2025-02-26 20:41:51","","535-554","","2","27","","","","","","","","","","English","","","","WOS:000970251100014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","BALANCE; explainable AI; KINECT; LEVEL; Machine learning; MOTION; PERFORMANCE; POSTURAL STABILITY; RELIABILITY; rifle shooting; skeleton graphs; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4VACFS6Q","journalArticle","2023","Li, Y; Zhang, ST; Li, YZ; Cao, JT; Jia, SY","PMU Measurements-Based Short-Term Voltage Stability Assessment of Power Systems via Deep Transfer Learning","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2023.3311065","","Deep learning (DL) has emerged as an effective solution for addressing the challenges of short-term voltage stability assessment (STVSA) in power systems; however, existing DL-based STVSA approaches face limitations in adapting to topological changes, sample labeling, and handling small datasets. To overcome these challenges, this article proposes a novel phasor measurement unit (PMU) measurements-based STVSA method by using deep transfer learning. The method leverages the real-time dynamic information captured by PMUs to create an initial dataset. It employs temporal ensembling for sample labeling and uses least squares generative adversarial networks (LSGANs) for data augmentation (DA), enabling effective DL on small-scale datasets. Additionally, the method enhances adaptability to topological changes by exploring connections between different faults. Experimental results on the IEEE 39-bus test system demonstrate that the proposed method improves model evaluation accuracy by approximately 20% through transfer learning (TL), exhibiting strong adaptability to topological changes. By leveraging the self-attention mechanism of the transformer model, this approach offers significant advantages over shallow learning methods and other DL-based approaches.","2023","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","72","","","","","","","","","","English","","","","WOS:001096566400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;31<br/>Total Times Cited:&nbsp;&nbsp;31<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Deep transfer learning; least squares generative adversarial networks (LSGANs); phasor measurement unit (PMU) measurements; power system stability; short-term voltage stability assessment (STVSA); temporal ensembling; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CYKSGAXH","journalArticle","2021","Wang, HB; Liu, Y; Zhen, XX; Tu, XY","Depression Speech Recognition With a Three-Dimensional Convolutional Network","FRONTIERS IN HUMAN NEUROSCIENCE","","1662-5161","10.3389/fnhum.2021.713823","","Depression has become one of the main afflictions that threaten people's mental health. However, the current traditional diagnosis methods have certain limitations, so it is necessary to find a method of objective evaluation of depression based on intelligent technology to assist in the early diagnosis and treatment of patients. Because the abnormal speech features of patients with depression are related to their mental state to some extent, it is valuable to use speech acoustic features as objective indicators for the diagnosis of depression. In order to solve the problem of the complexity of speech in depression and the limited performance of traditional feature extraction methods for speech signals, this article suggests a Three-Dimensional Convolutional filter bank with Highway Networks and Bidirectional GRU (Gated Recurrent Unit) with an Attention mechanism (in short 3D-CBHGA), which includes two key strategies. (1) The three-dimensional feature extraction of the speech signal can timely realize the expression ability of those depression signals. (2) Based on the attention mechanism in the GRU network, the frame-level vector is weighted to get the hidden emotion vector by self-learning. Experiments show that the proposed 3D-CBHGA can well establish mapping from speech signals to depression-related features and improve the accuracy of depression detection in speech signals.","2021-09-30","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","15","","","","","","","","","","English","","","","WOS:000707484100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","attention mechanism; deep learning; depression detection; EMOTION; INDICATORS; multi-channel convolution; SEVERITY; speech emotion recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HF9Q3AMI","journalArticle","2021","Kiremitçi, I; Yilmaz, Ö; Çelik, E; Shahdloo, M; Huth, AG; Çukur, T","Attentional Modulation of Hierarchical Speech Representations in a Multitalker Environment","CEREBRAL CORTEX","","1047-3211","10.1093/cercor/bhab136","","Humans are remarkably adept in listening to a desired speaker in a crowded environment, while filtering out nontarget speakers in the background. Attention is key to solving this difficult cocktail-party task, yet a detailed characterization of attentional effects on speech representations is lacking. It remains unclear across what levels of speech features and how much attentional modulation occurs in each brain area during the cocktail-party task. To address these questions, we recorded whole-brain blood-oxygen-level-dependent (BOLD) responses while subjects either passively listened to single-speaker stories, or selectively attended to a male or a female speaker in temporally overlaid stories in separate experiments. Spectral, articulatory, and semantic models of the natural stories were constructed. Intrinsic selectivity profiles were identified via voxelwise models fit to passive listening responses. Attentional modulations were then quantified based on model predictions for attended and unattended stories in the cocktail-party task. We find that attention causes broad modulations at multiple levels of speech representations while growing stronger toward later stages of processing, and that unattended speech is represented up to the semantic level in parabelt auditory cortex. These results provide insights on attentional mechanisms that underlie the ability to selectively listen to a desired speaker in noisy multispeaker environments.","2021-11","2025-02-26 20:41:51","2025-02-26 20:41:51","","4986-5005","","11","31","","","","","","","","","","English","","","","WOS:000708798900010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;114</p>","","","ACTIVATION; AUDITORY-CORTEX; COCKTAIL PARTY; cocktail-party; CONNECTIVITY; CORTICAL ORGANIZATION; dorsal and ventral stream; encoding model; fMRI; HUMAN BRAIN; LANGUAGE; LISTENING TASK; MESSAGES; natural speech; SELECTIVE ATTENTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A8Z6H8JN","journalArticle","2025","Tong, Z; Zhang, YM; Ma, T","Evidential transformer for buried object detection in ground penetrating radar signals and interval-based bounding box","COMPUTER-AIDED CIVIL AND INFRASTRUCTURE ENGINEERING","","1093-9687","10.1111/mice.13417","","Three-dimensional (3D) buried object detection using ground penetrating radar (GPR) benefits from the powerful capacity of image-wise deep neural networks. However, it still faces the challenge of information loss from raw GPR signals to two- and three-dimensional images, such as the frequency-domain information loss when normalizing GPR signals into gray-scale images and spatial information loss when using stacked B- and C-scan images to replace raw GPR signals as inputs. To solve the challenge, this study has proposed an ENNreg-transformer model, directly using raw 3D GPR signals to perform buried object detection. In the proposed model, 3D GPR signals are first converted into sequential voxelization to obtain spatiotemporal features. The features are then aggregated by an intuition-guided feature aggregation layer to simulate the expert behavior to analyze 3D GPR data. Finally, an evidential detection header outputs 3D interval-based bounding boxes for buried object detection. The experiment on two 3D GPR road datasets demonstrates that the proposed model exceeds other state-of-the-art models on the tasks thanks to raw 3D signals and intuition-guided feature aggregation. In addition, the interval-based bounding box represents the spatial bounding-box uncertainty, which derives from the inherent limitations of GPR and deep networks.","2025-01-07","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","","","","","","","","","","","English","","","","WOS:001390756800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RN98JHTY","journalArticle","2024","Liang, HJ; Wang, SH; Gao, S; Li, HL; Su, C; Lu, H; Zhang, XY; Chen, X; Chen, YA","Deephullnet: a deep learning approach for solving the convex hull and concave hull problems with transformer","INTERNATIONAL JOURNAL OF DIGITAL EARTH","","1753-8947","10.1080/17538947.2024.2358843","","Convex and concave hulls originating from computational geometry are widely applied in practice. For instance, to determine the boundaries of a geographical area within a group of cities, convex hulls can represent the approximate boundaries of the areas. Concave hulls can accurately describe the shape of the area. The traditional methods for solving two-dimensional convex hull problems include the Jarvis March algorithm and the Graham scanning algorithm. The K-nearest neighbours and alpha-shape methods are designed for solving the concave hull problem. Other than traditional algorithms, we consider using deep neural networks to handle the convex and concave hull problems. General neural networks cannot deal with the problem whose output is a variable-length sequence. Our study provides a machine-learning approach for solving the convex hull and concave hull problems. We combine the Pointer network (Ptr-Net) with the Transformer model and propose the DeepHullNet. The trained DeepHullNet can provide a feasible solution in the majority of cases. The experimental results show that DeepHullNet outperforms the original Ptr-Net regarding accuracy. Compared with traditional methods, DeepHullNet can generate a good solution quickly, and the running time is shortened by nearly 100 times based on GPU.","2024-12-31","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","1","17","","","","","","","","","","English","","","","WOS:001235802400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","ALGORITHM; concave hull problem; Convex hull problem; deep learning; GeoAI; MULTIOBJECTIVE OPTIMIZATION; POINTS; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V6LW3346","journalArticle","2024","Hong, SK; Jang, JS; Kwon, HY","Enhancing performance of transformer-based models in natural language understanding through word importance embedding","KNOWLEDGE-BASED SYSTEMS","","0950-7051","10.1016/j.knosys.2024.112404","","Transformer-based models have achieved state-of-the-art performance on natural language understanding (NLU) tasks by learning important token relationships through the attention mechanism. However, we observe that attention can become overly distributed during fine-tuning, failing to preserve the dependencies between meaningful tokens adequately. This phenomenon negatively affects the learning of token relationships in sentences. To overcome this issue, we propose a methodology that embeds the feature of word importance (WI) in the transformer-based models as a new layer, weighting the words according to their importance. Our simple yet powerful approach offers a general technique to boost transformer model capabilities on NLU tasks by mitigating the risk of attention dispersion during fine-tuning. Through extensive experiments on GLUE, SuperGLUE, and SQuAD benchmarks for pre-trained models (BERT, RoBERTa, ELECTRA, and DeBERTa), and MMLU, Big Bench Hard, and DROP benchmarks for the large language model, Llama2, we validate the effectiveness of our method in consistently enhancing performance across models with negligible overhead. Furthermore, we validate that our WI layer better preserves the dependencies between important tokens than standard fine-tuning by introducing a model classifying dependent tokens from the learned attention weights. The code is available at https://github.com/bigbases/WordImportance.","2024-11-25","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","304","","","","","","","","","","English","","","","WOS:001308252400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Natural language understanding; Transformer; Word dependency; Word importance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FQHVC4GI","journalArticle","2023","Cai, XY; Xiao, RL; Zeng, ZX; Gong, P; Ni, YC","ITran: A novel transformer-based approach for industrial anomaly detection and localization","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2023.106677","","Anomaly detection is currently an essential quality monitoring process in industrial production. It is often affected by factors such as under or over reconstruction of images and unclear criteria for feature distribution evaluation, thus making it challenging to improve detection performance. To solve the above problems, this paper proposes a novel transformer-based approach, Inductive Transformer (ITran) for industrial anomaly detection and localization, which utilizes a multi-layer pyramid structure and multi-level jump connections to extract multi-scale features of the data, putting the anomaly detection into the feature space and achieving more accurate industrial anomaly detection and localization results. It incorporates inductive bias and convolution operations into the Transformer which helps to break the myth of Transformer being ""data hungry"". Compared with the common Transformers, ITran significantly reduces the computational cost and memory usage and makes it work well on small datasets. In addition, we basically eliminate the effect of positional embedding on the proposed Transformer model. Sufficient experiments have been conducted to validate global anomaly detection on three datasets MNIST, Fashion-MNST and Cifar-10, as well as local anomaly detection on the industrial datasets MVTec AD, Concrete Crack Image and BTAD. The proposed ITran achieves outstanding results on all the above datasets.","2023-10","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","125","","","","","","","","","","English","","","","WOS:001024899600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Anomaly detection; Anomaly localization; Feature reconstruction; Industrial quality monitoring; ONE-CLASS CLASSIFICATION; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X2A9WUA2","journalArticle","2023","Luu, RK; Wysokowski, M; Buehler, MJ","Generative discovery of de novo chemical designs using diffusion modeling and transformer deep neural networks with application to deep eutectic solvents","APPLIED PHYSICS LETTERS","","0003-6951","10.1063/5.0155890","","We report a series of deep learning models to solve complex forward and inverse design problems in molecular modeling and design. Using both diffusion models inspired by nonequilibrium thermodynamics and attention-based transformer architectures, we demonstrate a flexible framework to capture complex chemical structures. First trained on the Quantum Machines 9 (QM9) dataset and a series of quantum mechanical properties (e.g., homo, lumo, free energy, and heat capacity), we then generalize the model to study and design key properties of deep eutectic solvents (DESs). In addition to separate forward and inverse models, we also report an integrated fully prompt-based multi-task generative pretrained transformer model that solves multiple forward, inverse design, and prediction tasks, flexibly and within one model. We show that the multi-task generative model has the overall best performance and allows for flexible integration of multiple objectives, within one model, and for distinct chemistries, suggesting that synergies emerge during training of this large language model. Trained jointly in tasks related to the QM9 dataset and DESs, the model can predict various quantum mechanical properties and critical properties to achieve deep eutectic solvent behavior. Several combinations of DESs are proposed based on this framework.","2023-06-05","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","23","122","","","","","","","","","","English","","","","WOS:001007710000003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;20<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","CARBOXYLIC-ACIDS; CHOLINE CHLORIDE; PREDICTION; SMILES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6WXHEUBX","journalArticle","2023","Eren, AO; Sert, M","Automated Audio Captioning With Topic Modeling","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3235733","","Automatic audio captioning (AAC) is an important area of research aimed at generating meaningful descriptions for audio clips. Most existing methods use relevant semantic information to improve AAC performance and have demonstrated the feasibility of semantic information extraction. Audio events and keywords are commonly used for this purpose. Unlike previous studies, this study proposes a framework that uses topic modeling to obtain relevant semantic content since topic models explore the main themes of the documents. To this end, we present a framework that integrates audio embeddings with audio topics in a transformer-based encoder-decoder architecture. First, we represent each audio clip with a set of topics using a pre-trained topic model, BERTopic. Then, we design a multilayer perceptron (MLP)-based multi-label classifier to predict the topics of audio clips in the testing phase. Finally, in the proposed framework, we input audio embedding and extracted topics into the transformer model to generate captions. The results show that the proposed model improves performance and competes with the most advanced methods that utilize additional external data for training. We believe that the topic modeling can be used to extract semantic content in the AAC task.","2023","2025-02-26 20:41:51","2025-02-26 20:41:51","","4983-4991","","","11","","","","","","","","","","English","","","","WOS:000917249200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Audio captioning; audio event detection; Audio systems; BERTopic; Bit error rate; Event detection; Feature extraction; PANNs; Predictive models; Semantics; topic modeling; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6FFTENE8","journalArticle","2023","Wang, B; Feng, Y; Xiong, XC; Wang, YH; Qiang, BH","Multi-modal transformer using two-level visual features for fake news detection","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-022-04055-5","","Fake news with multimedia data is ubiquitous on the Internet nowadays, and it is difficult for users to distinguish them. Therefore, it is necessary to design automatic multi-modal fake news detectors. However, the existing works make poor utilization of visual information, and do not fully consider the semantic interaction of multi-modal data. In this paper, we propose the multi-modal transformer using two-level visual features (MTTV) for fake news detection. First, we model texts and images from news uniformly as sequences that can be processed by transformer, and two-level visual features, i.e. global feature and entity-level feature, are used to improve the utilization of news images. Second, we extend the transformer model for natural language processing to multi-modal transformer which can make multi-modal data interact fully and capture the semantic relationships between them. In addition, we propose a scalable classifier to improve the classification balance of fine-grained fake news detection with the problem of class imbalance. Extensive experiments on two public datasets demonstrate that our method achieved significant performance improvement compared to the state-of-the-art methods. The source code is available at https://github.com/cqu-wb/MTTV.","2023-05","2025-02-26 20:41:51","2025-02-26 20:41:51","","10429-10443","","9","53","","","","","","","","","","English","","","","WOS:000841697900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Classification; Fake news detection; Multi-modal learning; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I2LLRPWZ","journalArticle","2022","Gu, YT; Zheng, C; Todoh, M; Zha, FS","American Sign Language Translation Using Wearable Inertial and Electromyography Sensors for Tracking Hand Movements and Facial Expressions","FRONTIERS IN NEUROSCIENCE","","1662-453X","10.3389/fnins.2022.962141","","A sign language translation system can break the communication barrier between hearing-impaired people and others. In this paper, a novel American sign language (ASL) translation method based on wearable sensors was proposed. We leveraged inertial sensors to capture signs and surface electromyography (EMG) sensors to detect facial expressions. We applied a convolutional neural network (CNN) to extract features from input signals. Then, long short-term memory (LSTM) and transformer models were exploited to achieve end-to-end translation from input signals to text sentences. We evaluated two models on 40 ASL sentences strictly following the rules of grammar. Word error rate (WER) and sentence error rate (SER) are utilized as the evaluation standard. The LSTM model can translate sentences in the testing dataset with a 7.74% WER and 9.17% SER. The transformer model performs much better by achieving a 4.22% WER and 4.72% SER. The encouraging results indicate that both models are suitable for sign language translation with high accuracy. With complete motion capture sensors and facial expression recognition methods, the sign language translation system has the potential to recognize more sentences.","2022-07-19","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","16","","","","","","","","","","English","","","","WOS:000835143500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","American sign language; electromyography; inertial measurement units; long short-term memory; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YLG7RCBG","journalArticle","2022","Fu, PB; Liu, DX; Yang, HR","LAS-Transformer: An Enhanced Transformer Based on the Local Attention Mechanism for Speech Recognition","INFORMATION","","2078-2489","10.3390/info13050250","","Recently, Transformer-based models have shown promising results in automatic speech recognition (ASR), outperforming models based on recurrent neural networks (RNNs) and convolutional neural networks (CNNs). However, directly applying a Transformer to the ASR task does not exploit the correlation among speech frames effectively, leaving the model trapped in a sub-optimal solution. To this end, we propose a local attention Transformer model for speech recognition that combines the high correlation among speech frames. Specifically, we use relative positional embedding, rather than absolute positional embedding, to improve the generalization of the Transformer for speech sequences of different lengths. Secondly, we add local attention based on parametric positional relations to the self-attentive module and explicitly incorporate prior knowledge into the self-attentive module to make the training process insensitive to hyperparameters, thus improving the performance. Experiments carried out on the LibriSpeech dataset show that our proposed approach achieves a word error rate of 2.3/5.5% by language model fusion without any external data and reduces the word error rate by 17.8/9.8% compared to the baseline. The results are also close to, or better than, other state-of-the-art end-to-end models.","2022-05","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","5","13","","","","","","","","","","English","","","","WOS:000804284300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","end-to-end model; local attention; speech recognition; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FLBBB46J","journalArticle","2023","Chan, RKW","Evidential value of voice quality acoustics in forensic voice comparison","FORENSIC SCIENCE INTERNATIONAL","","0379-0738","10.1016/j.forsciint.2023.111725","","Voice recordings in forensic voice comparison casework typically involve speech style mismatch and are separated by days or weeks, but studies that aim to empirically validate the evidential value of speech features rarely include systematic comparisons on contemporaneous vs. non-contemporaneous recordings and match vs. mismatch in speech style. This study addresses this gap and focuses on the acoustics of laryngeal voice quality, since voice quality has been reported to be one of the most popular and useful features for forensic voice comparison. 75 male speakers aged 18-45 were selected from a forensically -oriented database of Australian English speakers in Sydney/New South Wales. The evidential strength of a number of spectral tilt and additive noise parameters were tested under the Bayesian likelihood-ratio framework. Results show that system performance using these parameters as input were stable across 50 replications. When speech style is controlled for, VQ parameters yielded promising results and better system validity was achieved when using more VQ parameters. However, they offered limited speaker -discriminatory value when speech style mismatch is involved, and non-contemporaneous recordings only led to a small decline in performance. Overall, forensic practitioners should be cautious when using spectral tilt measures and additive noise measures as speaker discriminants in forensic casework.(c) 2023 Elsevier B.V. All rights reserved.","2023-07","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","348","","","","","","","","","","English","","","","WOS:001007955700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","FEMALE; Forensic voice comparison; IDENTIFICATION; Likelihood -ratio; Non -contemporaneous recordings; SPEAKER; Speech style mismatch; Voice quality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2URKNNVW","journalArticle","2023","Liu, M; Ying-Hao, A; Fa-Li, L","Robust speech recognition based on deep learning for sports game review","APPLIED MATHEMATICS AND NONLINEAR SCIENCES","","2444-8656","10.2478/amns.2023.1.00075","","To verify the feasibility of robust speech recognition based on deep learning in sports game review. In this paper, a robust speech recognition model is built based on the generative adversarial network GAN algorithm according to the deep learning model. And the loss function, optimization function and noise reduction front-end are introduced in the model to achieve the optimization of speech extraction features through denoising process to ensure that accurate speech review data can be derived even in the game scene under noisy environment. Finally, the experiments are conducted to verify the four directions of the model algorithm by comparing the speech features MFCC, FBANK and WAVE. The experimental results show that the speech recognition model trained by the GSDNet model algorithm can reach 89% accuracy, 56.24% reduction of auxiliary speech recognition word error rate, 92.61% accuracy of speech feature extraction, about 62.19% reduction of training sample data volume, and 94.75% improvement of speech recognition performance in the speech recognition task under noisy environment. It shows that the robust speech recognition based on deep learning can be applied to sports game reviews, and also can provide accurate voice review information from the noisy sports game scene, and also broaden the application area for deep learning models.","2023-04-28","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","","","","","","","","","","","English","","","","WOS:000980142200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Deep learning model; Generative adversarial network GAN algorithm; JOINT OPTIMIZATION; Loss function; NEURAL-NETWORKS; Robust speech recognition; Speech feature vector","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TE6G8ERY","journalArticle","2022","Attas, D; Power, N; Smithies, J; Bee, C; Aadahl, V; Kellett, S; Blackmore, C; Christensen, H","Automated Detection of the Competency of Delivering Guided Self-Help for Anxiety via Speech and Language Processing","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app12178608","","Speech and language play an essential role in automatically assessing several psychotherapeutic qualities. These automation procedures require translating the manual rating qualities to speech and language features that accurately capture the assessed psychotherapeutic quality. Speech features can be determined by analysing recordings of psychotherapeutic conversations (acoustics), while language-based analyses rely on the transcriptions of such psychotherapeutic conversations (linguistics). Guided self-help is a psychotherapeutic intervention that mainly relay on therapeutic competency of practitioners. This paper investigates the feasibility of automatically analysing guided self-help sessions for mild-to-moderate anxiety to detect and predict practitioner competence. This analysis is performed on sessions drawn from a patient preference randomised controlled trial using actual patient-practitioner conversations manually rated using a valid and reliable measure of competency. The results show the efficacy and potential of automatically detecting practitioners' competence using a system based on acoustic and linguistic features extracted from transcripts generated by an automatic speech recogniser. Feature extraction, feature selection and classification or regression have been implemented as blocks of the prediction model. The Lasso regression model achieved the best prediction results with an R of 0.92 and lower error rates with an MAE of 1.66 and RMSE of 2.25.","2022-09","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","17","12","","","","","","","","","","English","","","","WOS:000850951100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","automatic speech recognition; competency; EMOTION; guided self-help sessions; language processing; machine learning; QUALITY; speech processing; THERAPEUTIC ALLIANCE; THERAPIST COMPETENCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N7EPRAMI","journalArticle","2024","Choi, H; Kim, Y; Kang, H; Seo, H; Kim, M; Han, J; Kee, G; Park, S; Ko, S; Jung, H; Kim, B; Roh, JH; Jun, TJ; Kim, YH","Time series forecasting of weight for diuretic dose adjustment using bidirectional long short-term memory","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-68663-6","","Loop diuretics are prevailing drugs to manage fluid overload in heart failure. However, adjusting to loop diuretic doses is strenuous due to the lack of a diuretic guideline. Accordingly, we developed a novel clinician decision support system for adjusting loop diuretics dosage with a Long Short-Term Memory (LSTM) algorithm using time-series EMRs. Weight measurements were used as the target to estimate fluid loss during diuretic therapy. We designed the TSFD-LSTM, a bi-directional LSTM model with an attention mechanism, to forecast weight change 48 h after heart failure patients were injected with loop diuretics. The model utilized 65 variables, including disease conditions, concurrent medications, laboratory results, vital signs, and physical measurements from EMRs. The framework processed four sequences simultaneously as inputs. An ablation study on attention mechanisms and a comparison with the transformer model as a baseline were conducted. The TSFD-LSTM outperformed the other models, achieving 85% predictive accuracy with MAE and MSE values of 0.56 and 1.45, respectively. Thus, the TSFD-LSTM model can aid in personalized loop diuretic treatment and prevent adverse drug events, contributing to improved healthcare efficacy for heart failure patients.","2024-07-31","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","1","14","","","","","","","","","","English","","","","WOS:001283344000004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Clinician decision support system; Deep learning; Electronic medical records; Long Short-Term memory; MEAN ABSOLUTE ERROR; Time series forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ILC8TL5V","journalArticle","2023","Suvarna, M; Vaucher, AC; Mitchell, S; Laino, T; Pérez-Ramírez, J","Language models and protocol standardization guidelines for accelerating synthesis planning in heterogeneous catalysis","NATURE COMMUNICATIONS","","2041-1723","10.1038/s41467-023-43836-5","","Synthesis protocol exploration is paramount in catalyst discovery, yet keeping pace with rapid literature advances is increasingly time intensive. Automated synthesis protocol analysis is attractive for swiftly identifying opportunities and informing predictive models, however such applications in heterogeneous catalysis remain limited. In this proof-of-concept, we introduce a transformer model for this task, exemplified using single-atom heterogeneous catalysts (SACs), a rapidly expanding catalyst family. Our model adeptly converts SAC protocols into action sequences, and we use this output to facilitate statistical inference of their synthesis trends and applications, potentially expediting literature review and analysis. We demonstrate the model's adaptability across distinct heterogeneous catalyst families, underscoring its versatility. Finally, our study highlights a critical issue: the lack of standardization in reporting protocols hampers machine-reading capabilities. Embracing digital advances in catalysis demands a shift in data reporting norms, and to this end, we offer guidelines for writing protocols, significantly improving machine-readability. We release our model as an open-source web application, inviting a fresh approach to accelerate heterogeneous catalysis synthesis planning. Herein, the authors develop a transformer-based language model to automate synthesis protocol extraction from heterogeneous catalysis literature. Embracing digital advances in catalysis demands a shift in data reporting norms, and they offer guidelines for writing protocols, which improve machine readability.","2023-12-02","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","1","14","","","","","","","","","","English","","","","WOS:001115563700018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","SINGLE-ATOM CATALYSTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5BMMR7LP","journalArticle","2023","Chen, YH; Yan, QY; Huang, WM","MFTSC: A Semantically Constrained Method for Urban Building Height Estimation Using Multiple Source Images","REMOTE SENSING","","2072-4292","10.3390/rs15235552","","The use of remote sensing imagery has significantly enhanced the efficiency of building extraction; however, the precise estimation of building height remains a formidable challenge. In light of ongoing advancements in computer vision, numerous techniques leveraging convolutional neural networks and Transformers have been applied to remote sensing imagery, yielding promising outcomes. Nevertheless, most existing approaches directly estimate height without considering the intrinsic relationship between semantic building segmentation and building height estimation. In this study, we present a unified architectural framework that integrates the tasks of building semantic segmentation and building height estimation. We introduce a Transformer model that systematically merges multi-level features with semantic constraints and leverages shallow spatial detail feature cues in the encoder. Our approach excels in both height estimation and semantic segmentation tasks. Specifically, the coefficient of determination (R2) in the height estimation task attains a remarkable 0.9671, with a root mean square error (RMSE) of 1.1733 m. The mean intersection over union (mIoU) for building semantic segmentation reaches 0.7855. These findings underscore the efficacy of multi-task learning by integrating semantic segmentation with height estimation, thereby enhancing the precision of height estimation.","2023-12","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","23","15","","","","","","","","","","English","","","","WOS:001116609400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","DEPTH ESTIMATION; height estimation; multi-task learning; remote sensing; SAR; synthetic aperture radar; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VIWILPSJ","journalArticle","2023","Yang, YZ; Wang, HB; Xie, ZC; Li, JM; Huang, ZL","RESEARCH ON SEMANTIC SEGMENTATION OF GREENHOUSE ROAD IMAGE","INMATEH-AGRICULTURAL ENGINEERING","","2068-4215","10.35633/inmateh-71-65","","To realize the automatic driving of agricultural machinery in the greenhouse, this paper uses image acquisition equipment to collect road images in the greenhouse and makes data sets, builds SETR (SEgmentation TRansformer) model based on Transformer framework and DeepLabv3+ model based on convolution neural network for semantic segmentation of road images in the greenhouse, and verifies the semantic segmentation ability of the two models to road images in the greenhouse. Several groups of training periods are set as observation points to observe the semantic segmentation effect of the two models on the greenhouse road image, and the test set which has not been trained by the model is used as the prediction object to verify the performance of the two models on the semantic segmentation of greenhouse road image. The SETR model reached 94.64% PA (Pixel Accuracy) on the greenhouse road data set, and 82.72% mIoU (Mean Intersection over Union), DeepLabv3+ model reached 90.80% PA and 72.35% mIoU on the greenhouse road data set. Both models have excellent performance in semantic segmentation of greenhouse road images, and the performance of SETR model is slightly better than that of DeepLabv3+ model. The semantic segmentation performance of the two models for greenhouse road images can meet the needs of actual deployment.","2023-09","2025-02-26 20:41:51","2025-02-26 20:41:51","","745-754","","3","71","","","","","","","","","","English","","","","WOS:001137016300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","DeepLabv3+; road detection; semantic segmentation; SETR","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MUDCKZ4B","journalArticle","2023","Bedel, HA; Sivgin, I; Dalmaz, O; Dar, SUH; Çukur, T","BolT: Fused window transformers for fMRI time series analysis","MEDICAL IMAGE ANALYSIS","","1361-8415","10.1016/j.media.2023.102841","","Deep-learning models have enabled performance leaps in analysis of high-dimensional functional MRI (fMRI) data. Yet, many previous methods are suboptimally sensitive for contextual representations across diverse time scales. Here, we present BolT, a blood-oxygen-level-dependent transformer model, for analyzing multi-variate fMRI time series. BolT leverages a cascade of transformer encoders equipped with a novel fused window attention mechanism. Encoding is performed on temporally-overlapped windows within the time series to capture local representations. To integrate information temporally, cross-window attention is computed between base tokens in each window and fringe tokens from neighboring windows. To gradually transition from local to global representations, the extent of window overlap and thereby number of fringe tokens are progressively increased across the cascade. Finally, a novel cross-window regularization is employed to align high-level classification features across the time series. Comprehensive experiments on large-scale public datasets demonstrate the superior performance of BolT against state-of-the-art methods. Furthermore, explanatory analyses to identify landmark time points and regions that contribute most significantly to model decisions corroborate prominent neuroscientific findings in the literature.","2023-08","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","88","","","","","","","","","","English","","","","WOS:001054380100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;31<br/>Total Times Cited:&nbsp;&nbsp;31<br/>Cited Reference Count:&nbsp;&nbsp;127</p>","","","ALZHEIMERS-DISEASE; AUTISM; BRAIN; Classification; CLASSIFICATION; Connectivity; Deep learning; Explainability; Functional MRI; IDENTIFICATION; INDEPENDENT COMPONENT; MCI; NETWORKS; PATTERN-ANALYSIS; STATE FUNCTIONAL CONNECTIVITY; Time series; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7ZRZS6P3","journalArticle","2021","Usman, M; Zubair, M; Ahmad, Z; Zaidi, M; Ijyas, T; Parayangat, M; Wajid, M; Shiblee, M; Ali, SJ","Heart Rate Detection and Classification from Speech Spectral Features Using Machine Learning","ARCHIVES OF ACOUSTICS","","0137-5075","10.24425/aoa.2021.136559","","Measurement of vital signs of the human body such as heart rate, blood pressure, body temperature and respiratory rate is an important part of diagnosing medical conditions and these are usually measured using medical equipment. In this paper, we propose to estimate an important vital sign - heart rate from speech signals using machine learning algorithms. Existing literature, observation and experience suggest the existence of a correlation between speech characteristics and physiological, psychological as well as emotional conditions. In this work, we estimate the heart rate of individuals by applying machine learning based regression algorithms to Mel frequency cepstrum coefficients, which represent speech features in the spectral domain as well as the temporal variation of spectral features. The estimated heart rate is compared with actual measurement made using a conventional medical device at the time of recording speech. We obtain estimation accuracy close to 94% between the estimated and actual measured heart rate values. Binary classification of heart rate as 'normal' or 'abnormal' is also achieved with 100% accuracy. A comparison of machine learning algorithms in terms of heart rate estimation and classification accuracy is also presented. Heart rate measurement using speech has applications in remote monitoring of patients, professional athletes and can facilitate telemedicine.","2021","2025-02-26 20:41:51","2025-02-26 20:41:51","","41-53","","1","46","","","","","","","","","","English","","","","WOS:000631304400005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","EXTRACTION; heart rate from speech; machine learning; MFCC; RECOGNITION; REGRESSION; regression and classification; RESPIRATORY SINUS ARRHYTHMIA; speech as a biomedical signal","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TSSJ5D3E","journalArticle","2025","Cao, W; Meng, Z; Li, JM; Wu, J; Fan, FJ","A Remaining Useful Life Prediction Method for Rolling Bearing Based on TCN-Transformer","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2024.3502878","","Predicting the remaining useful life (RUL) of rolling bearings is crucial to ensure the stable operation of equipment. In recent years, predictive methodologies that leverage intelligent models have witnessed widespread development, significantly enhancing the precision of equipment prognostication. However, operating environments are inherently complex and can cause stochastic fluctuations in the characteristic indicators extracted during the rolling bearing degradation stage, leading to uncertainty in prediction outcomes. This study presents a TCN-transformer model and a two-stage degradation feature optimization methodology to address these challenges. The first stage uses Kalman filtering to suppress abnormal noise in the degradation index. In the second stage, a nonlinear smoothing algorithm based on degradation trends was constructed to improve the performance of degradation indicators. The proposed method constructs more stable and reliable degradation indicators. Additionally, to improve prediction accuracy, a TCN-transformer rolling bearing lifespan prediction model is proposed. Probability prediction and interval prediction are incorporated into rolling bearing RUL prediction to enhance the reliability of the model. Finally, the effectiveness of the proposed method is validated on the publicly available dataset XJTU-SY.","2025","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","74","","","","","","","","","","English","","","","WOS:001370775800023","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Data models; Degradation; Feature extraction; Fluctuations; Kalman filtering; Kalman filters; Noise; nonlinear smoothing algorithm; Optimization methods; Predictive models; Reliability; remaining useful life (RUL); rolling bearing; Rolling bearings; TCN-transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UYW3384Y","journalArticle","2025","Liu, XB; Li, HS","A study on UAV target detection and 3D positioning methods based on the improved deformable DETR model and multi-view geometry","ADVANCES IN MECHANICAL ENGINEERING","","1687-8132","10.1177/16878132251315505","","This paper addresses critical challenges in Unmanned Aerial Vehicle (UAV) target detection and 3D positioning, specifically inaccuracies in localization and lack of robustness in complex environments. The objective of this research is to improve UAV detection and positioning accuracy by proposing an enhanced Deformable DETR (Detection Transformer) model integrated with multi-view geometry theory. To achieve this, the study first preprocesses UAV-collected data, then optimizes the convolutional layers of the original DETR model to better handle object occlusion and scale variations. Furthermore, the research incorporates multi-view geometric modeling and multimodal fusion strategies to enhance detection accuracy during the target recognition process. Experimental results demonstrate that the proposed approach achieves over 70% detection accuracy, significantly outperforming traditional methods. The findings underscore the effectiveness of combining the improved Deformable DETR model with multi-view geometry for high-precision detection and 3D localization in complex environments. This research has significant implications for UAV-based applications, such as autonomous navigation, surveillance, and search-and-rescue missions, where precise target detection and 3D positioning are critical for successful operation.","2025-01","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","1","17","","","","","","","","","","English","","","","WOS:001406126400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","image denoising; improved deformable DETR model; Multiple unmanned aerial vehicle object detection; multiple view geometry; NETWORK; OBJECT DETECTION; three-dimensional positioning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SJT3LF9C","journalArticle","2024","Han, DY; Guo, CH","Automatic classification of ligneous leaf diseases via hierarchical vision transformer and transfer learning","FRONTIERS IN PLANT SCIENCE","","1664-462X","10.3389/fpls.2023.1328952","","BackgroundIdentification of leaf diseases plays an important role in the growing process of different types of plants. Current studies focusing on the detection and categorization of leaf diseases have achieved promising outcomes. However, there is still a need to enhance the performance of leaf disease categorization for practical applications within the field of Precision Agriculture.MethodsTo bridge this gap, this study presents a novel approach to classifying leaf diseases in ligneous plants by offering an improved vision transformer model. The proposed approach involves utilizing a multi-head attention module to effectively capture contextual information about the images and their classes. In addition, the multi-layer perceptron module has also been employed. To train the proposed deep model, a public dataset of leaf disease is exploited, which consists of 22 distinct kinds of images depicting ligneous leaf diseases. Furthermore, the strategy of transfer learning is employed to decrease the training duration of the proposed model.ResultsThe experimental findings indicate that the presented approach for classifying ligneous leaf diseases can achieve an accuracy of 85.0% above.DiscussionIn summary, the proposed methodology has the potential to serve as a beneficial algorithm for automated detection of leaf diseases in ligneous plants.","2024-01-12","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","14","","","","","","","","","","English","","","","WOS:001148797800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","machine vision; neural networks; precision agriculture; transfer learning; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PZIULQHS","journalArticle","2024","Liu, QG; Gao, P; Han, K; Liu, NZ; Xiang, W","Degradation-Aware Self-Attention Based Transformer for Blind Image Super-Resolution","IEEE TRANSACTIONS ON MULTIMEDIA","","1520-9210","10.1109/TMM.2024.3368923","","Compared to CNN-based methods, Transformer-based methods achieve impressive image restoration outcomes due to their ability to model remote dependencies. However, how to apply Transformer-based methods to the field of blind super-resolution (SR) and further make an SR network adaptive to degradation information is still an open problem. In this paper, we propose a new degradation-aware self-attention-based Transformer model, where we incorporate contrastive learning into the Transformer network for learning the degradation representations of input images with unknown noise. In particular, we integrate both CNN and Transformer components into the SR network, where we first use the CNN modulated by the degradation information to extract local features, and then employ the degradation-aware Transformer to extract global semantic features. We apply our proposed model to several popular large-scale benchmark datasets for testing, and achieve the state-of-the-art performance compared to existing methods. In particular, our method yields a PSNR of 32.43 dB on the Urban100 dataset at x2 scale, 0.94 dB higher than DASR, and 26.62 dB on the Urban100 dataset at x4 scale, 0.26 dB improvement over KDSR, setting a new benchmark in this area.","2024","2025-02-26 20:41:51","2025-02-26 20:41:51","","7516-7528","","","26","","","","","","","","","","English","","","","WOS:001209811000059","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","contrastive learning; degradation-aware self-attention; Super-resolution; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"362ZR7VJ","journalArticle","2023","Ye, WH; Zhou, X; Zhou, J; Chen, C; Li, KL","Accelerating Attention Mechanism on FPGAs based on Efficient Reconfigurable Systolic Array","ACM TRANSACTIONS ON EMBEDDED COMPUTING SYSTEMS","","1539-9087","10.1145/3549937","","Transformer model architectures have recently received great interest in natural language, machine translation, and computer vision, where attention mechanisms are their building blocks. However, the attention mechanism is expensive because of its intensive matrix computations and complicated data flow. The existing hardware architecture has some disadvantages for the computing structure of attention, such as inflexibility and low efficiency. Most of the existing papers accelerate attention by reducing the amount of computation through various pruning algorithms, which will affect the results to a certain extent with different sparsity. This paper proposes the hardware accelerator for the multi-head attention (MHA) on field-programmable gate arrays (FPGAs) with reconfigurable architecture, efficient systolic array, and hardware-friendly radix-2 softmax. We propose a novel method called Four inputs Processing Element (FPE) to double the computation rate of the data-aware systolic array (SA) and make it efficient and load balance. Especially, the computation framework is well designed to ensure the utilization of SA efficiently. Our design is evaluated on a Xilinx Alveo U250 card, and the proposed architecture achieves 51.3x, 17.3x improvement in latency, and 54.4x, 17.9x energy savings compared to CPU and GPU.","2023-11","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","6","22","","","","","","","","","","English","","","","WOS:001099632600005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Accelerator; attention; CNN; CO-DESIGN; FPGA; reconfigurable systolic array; softmax; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2RKC78GH","journalArticle","2023","Yang, H; Zhao, MH; Yuan, L; Yu, Y; Li, ZH; Gu, M","Memory-efficient Transformer-based network model for Traveling Salesman Problem","NEURAL NETWORKS","","0893-6080","10.1016/j.neunet.2023.02.014","","Combinatorial optimization problems such as Traveling Salesman Problem (TSP) have a wide range of real-world applications in transportation, logistics, manufacturing. It has always been a difficult problem to solve large-scale TSP problems quickly because of memory usage limitations. Recent research shows that the Transformer model is a promising approach. However, the Transformer has several severe problems that prevent it from quickly solving TSP combinatorial optimization problems, such as quadratic time complexity, especially quadratic space complexity, and the inherent limitations of the encoder and decoder itself. To address these issues, we developed a memory-efficient Transformer-based network model for TSP combinatorial optimization problems, termed Tspformer, with two distinctive characteristics: (1) a sampled scaled dot-product attention mechanism with O(L log(L)) (L is the length of input sequences) time and space complexity, which is the most different between our work and other works. (2) due to the reduced space complexity, GPU/CPU memory usage is significantly reduced. Extensive experiments demonstrate that Tspformer significantly outperforms existing methods and provides a new solution to the TSP combinatorial optimization problems. Our Pytorch code will be publicly available on GitHub https://github.com/yhnju/tspFormer.(c) 2023 Elsevier Ltd. All rights reserved.","2023-04","2025-02-26 20:41:51","2025-02-26 20:41:51","","589-597","","","161","","","","","","","","","","English","","","","WOS:000944476400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","ALGORITHMS; Combinatorial optimization; COMBINATORIAL OPTIMIZATION; Deep reinforcement learning; Transformer; TSP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2ECSUMYW","journalArticle","2023","Devi, CA; Renuka, D","Multimodal Emotion Recognition Framework Using a Decision-Level Fusion and Feature-Level Fusion Approach","IETE JOURNAL OF RESEARCH","","0377-2063","10.1080/03772063.2023.2173668","","In this manuscript, multimodal emotion recognition using a decision-level fusion and feature-level fusion approach is proposed. In the first approach, decision-level fusion approach is proposed, which is considered a late fusion, where fine-tuned models are developed for each modality. For that, the input is taken from IEMOCAP Database, initially, it is tokenized to a length of 128 tokens and given to a transformer-based BERT model. In the second approach, a feature-level fusion approach is proposed which is considered an early fusion where features from each modality are combined and then fed to the attention-based LSTM. For that, the input is taken from IEMOCAP Database, which contains three modalities: text, speech and Video. Here, text features are extracted with the CNN model, speech features are extracted using the OPENSMILE toolkit and Video features are extracted using a 3D-CNN architecture. Then the proposed approaches are simulated with python. The performance metrics, such as accuracy, sensitivity, specificity, precision, and recall, are evaluated. Then the performance of the proposed first approach is compared with the second approach. The simulation results of the second approach provide a higher accuracy of 0.98%; a higher sensitivity of 0.96%, and a higher sensitivity of 0.75% than the first approach.","2023-12-29","2025-02-26 20:41:51","2025-02-26 20:41:51","","8909-8920","","12","69","","","","","","","","","","English","","","","WOS:000940148500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Convolutional neural network; Decision-level fusion; Emotion recognition; Feature-level fusion; Long short-term memory; NETWORK","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZSF2ZX2N","journalArticle","2022","Kayesh, H; Islam, MS; Wang, JH; Ohira, R; Wang, Z","SCAN: A shared causal attention network for adverse drug reactions detection in tweets","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2022.01.019","","Twitter is a popular social media site on which people post millions of Tweets every day. As patients often share their experiences with drugs on Twitter, Tweets can also be considered as a rich alternative source of adverse drug reaction (ADR)-related information. This information can be useful for health authorities and drug manufacturing companies to monitor the post-marketing effectiveness of drugs. However, the automatic detection of ADRs in Tweets is challenging, as Tweets are informal and prone to grammatical errors. The existing approaches to automatically detecting ADRs do not consider the cause-effect relationships between a drug and an ADR. In this paper, we propose a novel shared causal attention network that exploits such cause-effect relationships to detect ADRs in Tweets. In our approach, we split a Tweet into the prefix, midfix, and postfix segments based on the position of the drug name in the Tweet and separately extract causal features from the segments. We then share these separate causal features with both word and parts-of-speech features, and apply the multi-head self-attention mechanism. We run extensive experiments on three publicly available benchmark datasets to illustrate the effectiveness of the proposed approach. (c) 2022 Elsevier B.V. All rights reserved.","2022-03-28","2025-02-26 20:41:51","2025-02-26 20:41:51","","60-74","","","479","","","","","","","","","","English","","","","WOS:000761683700006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;78</p>","","","Adverse drug reaction; ALGORITHM; ARCHITECTURES; Causality in texts; CLASSIFICATION; Deep learning; GENERATION; Multi-head self-attention; PHARMACOVIGILANCE; SOCIAL MEDIA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K43MFMUN","journalArticle","2024","Park, S; Jeon, B; Lee, S; Yoon, J","Multi-Label Emotion Recognition of Korean Speech Data Using Deep Fusion Models","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14177604","","As speech is the most natural way for humans to express emotions, studies on Speech Emotion Recognition (SER) have been conducted in various ways However, there are some areas for improvement in previous SER studies: (1) while some studies have performed multi-label classification, almost none have specifically utilized Korean speech data; (2) most studies have not utilized multiple features in combination for emotion recognition. Therefore, this study proposes deep fusion models for multi-label emotion classification using Korean speech data and follows four steps: (1) preprocessing speech data labeled with Sadness, Happiness, Neutral, Anger, and Disgust; (2) applying data augmentation to address the data imbalance and extracting speech features, including the Log-mel spectrogram, Mel-Frequency Cepstral Coefficients (MFCCs), and Voice Quality Features; (3) constructing models using deep fusion architectures; and (4) validating the performance of the constructed models. The experimental results demonstrated that the proposed model, which utilizes the Log-mel spectrogram and MFCCs with a fusion of Vision-Transformer and 1D Convolutional Neural Network-Long Short-Term Memory, achieved the highest average binary accuracy of 71.2% for multi-label classification, outperforming other baseline models. Consequently, this study anticipates that the proposed model will find application based on Korean speech, specifically mental healthcare and smart service systems.","2024-09","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","17","14","","","","","","","","","","English","","","","WOS:001311265000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","deep fusion model; FEATURES; multi-label classification; speech emotion recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XW6M87IG","journalArticle","2023","Yang, DY; Lian, T; Zheng, W; Zhao, C","Enriching Word Information Representation for Chinese Cybersecurity Named Entity Recognition","NEURAL PROCESSING LETTERS","","1370-4621","10.1007/s11063-023-11280-7","","Named entity recognition (NER) is a word-level sequence tagging task. The key of Chinese cybersecurity NER is to obtain meaningful word representations and to delicately model the inter-word relations. However, Chinese is a language of compound words and lacks morphological inflections. Moreover, the role and meaning of a word depends on the context in a complicated way. In this paper, we present an NER model named Star-HGCN, short for Star-Transformer with Hybrid embeddings and Graph Convolutional Network. To make full use of the intra-word information, we set a hybrid embedding layer at the very beginning, which enriches word representations with character-level information and part-of-speech features. More importantly, we further enhance the hybrid embeddings by modeling inter-word implicit local and long-range semantic associations using the efficient Star-Transformer architecture, and modeling the explicit syntactic dependencies between words in the dependency tree using the graph convolutional network. Experiments on the Chinese cybersecurity dataset show that our model is superior to other neural network methods for NER, and achieves a significant relative improvement of 36.59% for the class of software entities. Experiments on other public datasets also validate the effectiveness of the model on other general and specific domains.","2023-12","2025-02-26 20:41:51","2025-02-26 20:41:51","","7689-7707","","6","55","","","","","","","","","","English","","","","WOS:001045695800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Cybersecurity; EXTRACTION; Graph convolutional network; Hybrid embedding; Inter-word dependency; Named entity recognition; Star-transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PRCFYF5P","journalArticle","2022","Luo, MJ; Wang, DY; Wang, XQ; Qiao, SS; Zhou, YM","Error-Diffusion Based Speech Feature Quantization for Small-Footprint Keyword Spotting","IEEE SIGNAL PROCESSING LETTERS","","1070-9908","10.1109/LSP.2022.3179208","","Neural network based keyword spotting (KWS) system is a critical component for user interaction in current smart devices. Although small-footprint networks have been widely explored to reduce deployment overhead, low-precision input feature representation still lacks in-depth research. In this letter, an error-diffusion based speech feature quantization method is proposed. Specifically, our algorithm adapts image processing to quantize the input speech feature maps in arbitrary bits. Experiments show that in the 10-keyword KWS task, our 3-bit representation only brings a 0.45% average accuracy drop compared to the full-precision log-Mel spectrograms while others drop over 3%. In the 2 keywords task, our 3-bit representation produces no significant differences, while 1-bit quantization only leads to an average of 1.7% accuracy drop and is even capable of handling similar keywords and imbalanced data distribution. The result proves our method, to the best of our knowledge, is the first practical method that supports as low as 1-bit quantization for single-channel speech features in small-footprint KWS. In addition, we analyze the impact of error-diffusion directions and conclude that time-direction diffusion is more suitable for temporal convolutional networks.","2022","2025-02-26 20:41:51","2025-02-26 20:41:51","","1357-1361","","","29","","","","","","","","","","English","","","","WOS:000814608700002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","convolutional neural networks; error diffusion; Filter banks; image processing; Keyword spotting; Quantization (signal); Signal processing algorithms; Spectrogram; speech feature quantization; Speech processing; Standards; Task analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7JCA82HS","journalArticle","2024","Do, T; Doan, TT; Le, KM; Nguyen, T; Le, DD; Ngo, TD","Key Information Extraction and Recognition from Rich Text Images","VIETNAM JOURNAL OF COMPUTER SCIENCE","","2196-8888","10.1142/S2196888824500131","","Key information extraction and recognition from rich text images are crucial for various applications. There are two main tasks involved in this process: Line Item Recognition (LIR) and Key Information Localization and Extraction (KILE). LIR aims at identifying and interpreting data line items in a document. The essential information in each line item is then classified or extracted, a task known as KILE. A widely used approach for this problem is sequence based, which relies on the generalization of a language model and requires a significant amount of training time. We present an effective and reliable solution to the problem by using RoBERTa, a transformer model trained on a large corpus, along with the LION optimizer to improve the training process. A comprehensive evaluation was conducted on two different benchmarks, emphasizing two different languages, English and Vietnamese. Experimental results on DocILE indicate that the proposed framework significantly improves the KILE task with a 7.24% increase in accuracy compared to the baseline and also enhances the correct recognition rate at the LIR stage. On MCOCR, the method achieved a Character Error Rate (CER) of 28.6%, which is competitive with the state-of-the-art on this dataset.","2024-11","2025-02-26 20:41:51","2025-02-26 20:41:51","","569-594","","04","11","","","","","","","","","","English","","","","WOS:001261737300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Document information extraction and localization (KIE and KILE); line item recognition (LIR)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3F644YWW","journalArticle","2024","Luo, J; Zhao, YN; Liu, HQ; Zhang, YT; Shi, ZH; Li, R; Hei, XH; Ren, XR","SST: a snore shifted-window transformer method for potential obstructive sleep apnea patient diagnosis","PHYSIOLOGICAL MEASUREMENT","","0967-3334","10.1088/1361-6579/ad262b","","Objective. Obstructive sleep apnea (OSA) is a high-incidence disease that is seriously harmful and potentially dangerous. The objective of this study was to develop a noncontact sleep audio signal-based method for diagnosing potential OSA patients, aiming to provide a more convenient diagnostic approach compared to the traditional polysomnography (PSG) testing. Approach. The study employed a shifted window transformer model to detect snoring audio signals from whole-night sleep audio. First, a snoring detection model was trained on large-scale audio datasets. Subsequently, the deep feature statistical metrics of the detected snore audio were used to train a random forest classifier for OSA patient diagnosis. Main results. Using a self-collected dataset of 305 potential OSA patients, the proposed snore shifted-window transformer method (SST) achieved an accuracy of 85.9%, a sensitivity of 85.3%, and a precision of 85.6% in OSA patient classification. These values surpassed the state-of-the-art method by 9.7%, 10.7%, and 7.9%, respectively. Significance. The experimental results demonstrated that SST significantly improved the noncontact audio-based OSA diagnosis performance. The study's findings suggest a promising self-diagnosis method for potential OSA patients, potentially reducing the need for invasive and inconvenient diagnostic procedures.","2024-03-01","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","3","45","","","","","","","","","","English","","","","WOS:001182058500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","HEART-FAILURE; multiscale feature; OSA diagnosis; snoring detection; TIME; windows attention mechanism","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QZ2MHWXA","journalArticle","2024","Amellal, I; Amellal, A; Seghiouer, H; Ech-Charrat, MR","An integrated approach for modern supply chain management: Utilizing advanced machine learning models for sentiment analysis, demand forecasting, and probabilistic price prediction","DECISION SCIENCE LETTERS","","1929-5804","10.5267/dsl.2023.9.003","","In the contemporary business landscape, effective interpretation of customer sentiment, accurate demand forecasting, and precise price prediction are pivotal in making strategic decisions and efficiently allocating resources. Harnessing the vast array of data available from social media and online platforms, this paper presents an integrative approach employing machine learning, deep learning, and probabilistic models. Our methodology leverages the BERT transformer model for customer sentiment analysis, the Gated Recurrent Unit (GRU) model for demand forecasting, and the Bayesian Network for price prediction. These state-of-the-art techniques are adept at managing large-scale, high-dimensional data and uncovering hidden patterns, surpassing traditional statistical methods in performance. By bridging these diverse models, we aim to furnish businesses with a comprehensive understanding of their customer base and market dynamics, thus equipping them with insights to make informed decisions, optimize pricing strategies, and manage supply chain uncertainties effectively. The results demonstrate the strengths and areas for improvement of each model, ultimately presenting a robust and holistic approach to tackling the complex challenges of modern supply chain management.(c) 2024 by the authors; licensee Growing Science, Canada.","2024","2025-02-26 20:41:51","2025-02-26 20:41:51","","237-248","","1","13","","","","","","","","","","English","","","","WOS:001127075600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Demand Forecasting; Machine Learning; NETWORKS; Price prediction; Probabilistic Models; Sentiment Analysis; Supply Chain Management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PD8AGQDB","journalArticle","2023","Benmounah, Z; Boulesnane, A; Fadheli, A; Khial, M","Sentiment Analysis on Algerian Dialect with Transformers","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app132011157","","The task of extracting sentiment from text has been widely studied in the field of natural language processing. However, little work has been conducted specifically on the Arabic language with the Algerian dialect. In this research, we aim to make a significant contribution to the field of sentiment analysis on the Algerian dialect by creating a custom and relatively large dataset with a tailored deep learning model. The dataset was extracted from Algerian YouTube channels and manually annotated by the research team. We then utilize this dataset to train a state-of-the-art deep learning model for natural language processing called BERT, which is a type of Transformer model. Using this model, we were able to achieve an F1-score of 78.38% and an accuracy of 81.74% on the testing set. This demonstrates the effectiveness of our approach and the potential of using BERT for sentiment analysis on the Algerian dialect. Our model can be used to infer sentiment from any Algerian text, thus providing a valuable tool for understanding the opinions and emotions of the population. This research highlights the importance of studying the Algerian dialect and the potential of using state-of-the-art deep learning models for natural language processing in this area.","2023-10","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","20","13","","","","","","","","","","English","","","","WOS:001095694800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Algerian dialect; artificial intelligence; deep learning; natural language processing; sentiment analysis; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5STJ68CB","journalArticle","2024","Li, YM; Joaquim, MR; Pickup, S; Song, HK; Zhou, R; Fan, Y","Learning ADC maps from accelerated radial k-space diffusion-weighted MRI in mice using a deep CNN-transformer model","MAGNETIC RESONANCE IN MEDICINE","","0740-3194","10.1002/mrm.29833","","Purpose: To accelerate radially sampled diffusion weighted spin-echo (Rad-DW-SE) acquisition method for generating high quality ADC maps.Methods: A deep learning method was developed to generate accurate ADC maps from accelerated DWI data acquired with the Rad-DW-SE method. The deep learning method integrates convolutional neural networks (CNNs) with vision transformers to generate high quality ADC maps from accelerated DWI data, regularized by a monoexponential ADC model fitting term. A model was trained on DWI data of 147 mice and evaluated on DWI data of 36 mice, with acceleration factors of 4x and 8x compared to the original acquisition parameters.Results: Ablation studies and experimental results have demonstrated that the proposed deep learning model generates higher quality ADC maps from accelerated DWI data than alternative deep learning methods under comparison when their performance is quantified in whole images as well as in regions of interest, including tumors, kidneys, and muscles.Conclusions: The deep learning method with integrated CNNs and transformers provides an effective means to accurately compute ADC maps from accelerated DWI data acquired with the Rad-DW-SE method.","2024-01","2025-02-26 20:41:51","2025-02-26 20:41:51","","105-117","","1","91","","","","","","","","","","English","","","","WOS:001051139400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","apparent diffusion coefficient; BREAST; COEFFICIENT; convolutional neural network; diffusion weighted MRI; monoexponential model; MOTION; NEURAL-NETWORK; parametric estimation; self-attention","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3RU65TQU","journalArticle","2023","Qaisar, I; Sun, KL; Zhao, QC; Xing, T; Yan, H","Multi-Sensor-Based Occupancy Prediction in a Multi-Zone Office Building with Transformer","BUILDINGS","","2075-5309","10.3390/buildings13082002","","Buildings are responsible for approximately 40% of the world's energy consumption and 36% of the total carbon dioxide emissions. Building occupancy is essential, enabling occupant-centric control for zero emissions and decarbonization. Although existing machine learning and deep learning methods for building occupancy prediction have made notable progress, their analyses remain limited when applied to complex real-world scenarios. Moreover, there is a high expectation for Transformer algorithms to predict building occupancy accurately. Therefore, this paper presents an occupancy prediction Transformer network (OPTnet). We fused and fed multi-sensor data (building occupancy, indoor environmental conditions, HVAC operations) into a Transformer model to forecast the future occupancy presence in multiple zones. We performed experimental analyses and compared it to different occupancy prediction methods (e.g., decision tree, long short-term memory networks, multi-layer perceptron) and diverse time horizons (1, 2, 3, 5, 10, 20, 30 min). Performance metrics (e.g., accuracy and mean squared error) were employed to evaluate the effectiveness of the prediction algorithms. Our OPTnet method achieved superior performance on our experimental two-week data compared to existing methods. The improved performance indicates its potential to enhance HVAC control systems and energy optimization strategies.","2023-08","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","8","13","","","","","","","","","","English","","","","WOS:001057579600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","deep learning; ENERGY-CONSUMPTION; multi-sensor fusion; occupancy prediction; PERFORMANCE; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4RUGSIRB","journalArticle","2023","Aicha, AB; Kacem, F","Conventional Machine Learning and Feature Engineering for Vocal Fold Precancerous Lesions Detection Using Acoustic Features","CIRCUITS SYSTEMS AND SIGNAL PROCESSING","","0278-081X","10.1007/s00034-023-02551-8","","The success of laryngeal cancer treatment is significantly impacted by early-stage detection. Finding a precancerous lesion is a more difficult process than attempting to stop it from appearing. In this study, we propose a noninvasive, quick way to address that issue. When the vocal folds are affected by pathological lesions, the produced human voice becomes a pathological one. The proposed method is based on the analysis of pathological speeches. Our aim is to characterize the speech signal using a set of features. Hence, many algorithms, operating in different spaces, are used to extract speech features such as MFCC, LPC, LPCC, HNR. The speech feature extraction process is done frame by frame with a frame duration of 30 ms due to the nonstationarity of human speech. More than 170 features are computed for each speech frame. Since the extracted features can be highly correlated or nonsignificant, we have conducted a features engineering process. Feature engineering followed by principal component analysis (PCA) leads to the retention of 28 components. When using the support vector machine (SVM) technique, promising experimental results are obtained in terms of standard metrics. The obtained scores in terms of Accuracy, Recall, precision, and f(1) are, respectively, 0.94, 0.95, 0.89, and 0.92.","2023-11-21","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","","","","","","","","","","","English","","","","WOS:001103991900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","Acoustic features; CARCINOMA; CEPSTRAL PEAK PROMINENCE; FILTERBANK; KERATOSIS; Larynx precancerous lesions; Noninvasive method; PATHOLOGICAL VOICE; SVM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X3I2HIR2","journalArticle","2022","López-Espejo, I; Tan, ZH; Hansen, JHL; Jensen, J","Deep Spoken Keyword Spotting: An Overview","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2021.3139508","","Spoken keyword spotting (KWS) deals with the identification of keywords in audio streams and has become a fast-growing technology thanks to the paradigm shift introduced by deep learning a few years ago. This has allowed the rapid embedding of deep KWS in a myriad of small electronic devices with different purposes like the activation of voice assistants. Prospects suggest a sustained growth in terms of social use of this technology. Thus, it is not surprising that deep KWS has become a hot research topic among speech scientists, who constantly look for KWS performance improvement and computational complexity reduction. This context motivates this paper, in which we conduct a literature review into deep spoken KWS to assist practitioners and researchers who are interested in this technology. Specifically, this overview has a comprehensive nature by covering a thorough analysis of deep KWS systems (which includes speech features, acoustic modeling and posterior handling), robustness methods, applications, datasets, evaluation metrics, performance of deep KWS systems and audio-visual KWS. The analysis performed in this paper allows us to identify a number of directions for future research, including directions adopted from automatic speech recognition research and directions that are unique to the problem of spoken KWS.","2022","2025-02-26 20:41:51","2025-02-26 20:41:51","","4169-4199","","","10","","","","","","","","","","English","","","","WOS:000744483300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;45<br/>Total Times Cited:&nbsp;&nbsp;46<br/>Cited Reference Count:&nbsp;&nbsp;260</p>","","","acoustic model; Acoustics; ADAPTIVE NOISE CANCELLATION; ATTENTION; CHALLENGE; Computational modeling; Decoding; deep learning; ENHANCEMENT; Feature extraction; Hidden Markov models; Keyword spotting; REPRESENTATIONS; ROBUST; robustness; small footprint; SMALL-FOOTPRINT; SPEAKER VERIFICATION; SPEECH RECOGNITION; TERM DETECTION; Virtual assistants; Viterbi algorithm","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UK76AGD4","journalArticle","2021","Kent, RD; Eichhom, J; Wilson, EM; Suk, Y; Bolt, DM; Vorperian, HK","Auditory-Perceptual Features of Speech in Children and Adults With Down Syndrome: A Speech Profile Analysis","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2021_JSLHR-20-00617","","Purpose: The aim of this study was to determine how the speech disorder profiles in Down syndrome (DS) relate to reduced intelligibility, atypical overall quality, and impairments in the subsystems of speech production (phonation, articulation, resonance, and prosody). Method: Auditory-perceptual ratings of intelligibility, overall quality, and features associated with the subsystems of speech production were obtained from recordings of 79 children and adults with DS. Ratings were made for sustained vowels (62 of 79 speakers) and short sentences (79 speakers). The data were analyzed to determine the severity of the affected features in each speaking task and to detect patterns in the group data by means of principal components analysis. Results: Reduced intelligibility was noted in 90% of the speakers, and atypical overall speech quality was noted in 100%. Affected speech features were distributed across the speech production subsystems. Principal components analysis revealed four components each for the vowel and sentence tasks, showing that individuals with DS are not homogeneous in the features of their speech disorder. Discussion: The speech disorder in DS is complex in its perceptual features and reflects impairments across the subsystems of speech production, but the pattern is not uniform across individuals, indicating that attention must be given to individual variation in designing treatments.","2021-04","2025-02-26 20:41:51","2025-02-26 20:41:51","","1157-1175","","4","64","","","","","","","","","","English","","","","WOS:000640606600005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;131</p>","","","ACOUSTIC PROPERTIES; DISORDERS; HEARING-LOSS; INTELLIGIBILITY; LANGUAGE; RATING-SCALES; RELIABILITY; SKILLS; VOICE QUALITY; YOUNG-ADULTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EJ2J9UQ4","journalArticle","2025","Guo, WT; He, Q; Lin, ZY; Bu, XL; Wang, ZY; Li, D; Yang, HW","Enhancing depression recognition through a mixed expert model by integrating speaker-related and emotion-related features","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-025-88313-9","","The World Health Organization predicts that by 2030, depression will be the most common mental disorder, significantly affecting individuals, families, and society. Speech, as a sensitive indicator, reveals noticeable acoustic changes linked to physiological and cognitive variations, making it a crucial behavioral marker for detecting depression. However, existing studies often overlook the separation of speaker-related and emotion-related features in speech when recognizing depression. To tackle this challenge, we propose a Mixture-of-Experts (MoE) method that integrates speaker-related and emotion-related features for depression recognition. Our approach begins with a Time Delay Neural Network to pre-train a speaker-related feature extractor using a large-scale speaker recognition dataset while simultaneously pre-training a speaker's emotion-related feature extractor with a speech emotion dataset. We then apply transfer learning to extract both features from a depression dataset, followed by fusion. A multi-domain adaptation algorithm trains the MoE model for depression recognition. Experimental results demonstrate that our method achieves 74.3% accuracy on a self-built Chinese localized depression dataset and an MAE of 6.32 on the AVEC2014 dataset. Thus, it outperforms state-of-the-art deep learning methods that use speech features. Additionally, our approach shows strong performance across Chinese and English speech datasets, highlighting its effectiveness in addressing cultural variations.","2025-02-03","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","1","15","","","","","","","","","","English","","","","WOS:001413871500034","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7P3CYI2W","journalArticle","2022","Lutfi, RA; Pastore, T; Rodriguez, B; Yost, WA; Lee, J","Molecular analysis of individual differences in talker search at the cocktail-party","JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA","","0001-4966","10.1121/10.0014116","","A molecular (trial-by-trial) analysis of data from a cocktail-party, target-talker search task was used to test two general classes of explanations accounting for individual differences in listener performance: cue weighting models for which errors are tied to the speech features talkers have in common with the target and internal noise models for which errors are largely independent of these features. The speech of eight different talkers was played simultaneously over eight different loudspeakers surrounding the listener. The locations of the eight talkers varied at random from trial to trial. The listener's task was to identify the location of a target talker with which they had previously been familiarized. An analysis of the response counts to individual talkers showed predominant confusion with one talker sharing the same fundamental frequency and timbre as the target and, secondarily, other talkers sharing the same timbre. The confusions occurred for a roughly constant 31% of all of the trials for all of the listeners. The remaining errors were uniformly distributed across the remaining talkers and responsible for the large individual differences in performances observed. The results are consistent with a model in which largely stimulus-independent factors (internal noise) are responsible for the wide variation in performance across listeners. (C) 2022 Acoustical Society of America.","2022-09","2025-02-26 20:41:51","2025-02-26 20:41:51","","1804-1813","","3","152","","","","","","","","","","English","","","","WOS:000860911600002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","ABILITY; DECISION WEIGHTS; DISCRIMINATION; IMPACT; INTELLIGIBILITY; LISTENERS; MASKING; NOISE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6V22NIMF","journalArticle","2022","Li, CT; Yang, FR; Yang, J","The Role of Long-Term Dependency in Synthetic Speech Detection","IEEE SIGNAL PROCESSING LETTERS","","1070-9908","10.1109/LSP.2022.3169954","","Although much progress has been made in synthetic speech detection, there lacks comprehensive analysis of the essential differences between spoofed and genuine speech. We here utilize supervised contrastive loss originated from contrastive learning as an analytical tool to characterize the class similarity structure of ASVspoof 2019 logical access (LA) dataset, which shows that an ideal back-end classifier for synthetic speech detection should have the ability to capture long-term dependencies. Recently, Transformer has been found to have an excellent ability in learning long-term dependencies of input data. We hence propose a back-end classifier based on Transformer Encoder for synthetic speech detection. Convolution blocks are added before the Transformer Encoder, which leverages inductive biases to improve the generalization ability. Compared to two-dimensional convolution, one-dimensional convolution makes better architectural assumptions about the input speech features, which helps with modeling long-term dependencies and decreases the risk of overfitting. The proposed Transformer combined with one-dimensional convolution has fewer parameters than most existing back-end classifiers, and achieves an equal error rate of 1.06% and a minimum tandem detection cost function metric of 0.0345 when evaluated on ASVspoof 2019 LA dataset, which is one of the best models reported in the literature.","2022","2025-02-26 20:41:51","2025-02-26 20:41:51","","1142-1146","","","29","","","","","","","","","","English","","","","WOS:000793787300004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","ASVspoof 2019 LA; Convolution; Feature extraction; generalization ability; Principal component analysis; speaker verification; Speech synthesis; Training; transformer; Transformers; Voice activity detection; voice anti-spoofing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LAY267BH","journalArticle","2022","Briceño, NB; de Bolivar, GM; Ferrer, MLN","University assertive communication meta-capability: Analysis in nursing teachers","REVISTA PUBLICACIONES","","1577-4147","10.30827/publicaciones.v52i1.18119","","The teaching-learning process is a social phenomenon that requires an interpersonal communication between the teacher and students, therefore it ' s necessary that this is as assertive as possible, especially in university environments. Therefore, the objective was analyze the assertive communication meta-capability in the teachers of Universidad Nacional Experimental de la Fuerza Armada Bolivariana (UNEFAB), in Maracay during second period of year 2011. For this, in a sample of 172 students, a questionnaire with 63 items that presented five answer options with Likert scale (1-5) was applied, to study according to their perceptions the dimensions of communicative competence, speech features and empathy of the teachers; additionally, the students repetition effect in their perceptions about the communicative meta-capability of the teachers was studied, for which an ANOVA was applied to observe if there were differences between repeating and non-repeating students. A high level of presence in the dimensions studied was observed, that on average evidenced a high level of assertive commucative meta-capability (3.82 +/-.2) in the teachers; on the other hand, no significant differences (P >.05) in the perceptions of repeating and non-repeating students. It concludes that the nursing careers teachers of UNEFAB presented a high level of assertive communicative meta-capability, according to the students' perspective, the teachers were able to communicate openly their ideas, with respect and searching the student benefit.","2022","2025-02-26 20:41:51","2025-02-26 20:41:51","","301-318","","1","52","","","","","","","","","","English","","","","WOS:001136318200002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","communicative competence; empathy.; linguistics; nonverbal communication; paralinguistics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RR3IPKXZ","journalArticle","2024","Mohamed, NA; Allak, A; Gaanoun, K; Benelallam, I; Erraji, Z; Bahafid, A","Multilingual speech recognition initiative for African languages","INTERNATIONAL JOURNAL OF DATA SCIENCE AND ANALYTICS","","2364-415X","10.1007/s41060-024-00677-9","","This paper summarizes speech recognition systems for African languages. More precisely, we propose different approaches that address the low-resource property of these languages. For both monolingual and multilingual systems, our methods rely on self-supervised pre-trained models for multiple languages. We tested our method on 7 African languages and dialects: Amharic, Darija, Fongbe, Sudanese, Swahili, Wolof, and Yoruba. We first trained monolingual models that were used as baselines and then proposed proof-of-concepts for systems that handle multiple languages. Our multilingual contribution was based on three approaches. (a) We trained a single model by concatenating the multilingual corpora with no specific data processing. Because of confusions between the different languages, this ""na & iuml;ve approach"" led to a grapheme overlapping within the transcriptions. (b) To avoid this, we experimented a second multilingual model by feeding a one-hot encoder vector to the speech features on training. For this purpose, a language identification model is required on inference. (c) Finally, we proposed a last model that can predict the spoken language using language-specific tokens added to the text transcription. The aim of this method is to avoid the necessity to load a language identification on each inference which can be time- and resource-consuming. We also investigated the impact of lexical ambiguity by removing diacritics from text for the concerned languages.","2024-11-06","2025-02-26 20:41:51","2025-02-26 20:41:51","","","","","","","","","","","","","","","English","","","","WOS:001348699300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","African languages; Language identification; Multilingualism; Speech recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J3MP6ZZ9","journalArticle","2023","Sharma, G; Dhall, A; Cai, JF","Audio-Visual Automatic Group Affect Analysis","IEEE TRANSACTIONS ON AFFECTIVE COMPUTING","","1949-3045","10.1109/TAFFC.2021.3104170","","Affective computing has progressed well due to methods, which can identify a person's posed and spontaneous perceived affect with high accuracy. This paper focuses on group-level affect analysis on videos, which is one of the first few multimodal group-level affect analysis studies. There are many challenges on video-based group-level affect analysis as most of the work is focused on either a single person's affect recognition or image-based group affect analysis. To address this, first, we present an audio-visual perceived group affect dataset - 'Video-level Group AFfect (VGAF)'. VGAF is a large-scale dataset consisting of 4,183 group videos. The videos are collected from YouTube with large variations in the keywords for collecting data across different genders, group settings, group sizes, illuminations and poses. The variety within the dataset will help the study of perception of group affect in a real environment. The data is manually annotated for three group affect classes - positive, neutral, and negative. Further, a fusion based audio-visual method is proposed to set a benchmark performance on the proposed dataset. The experimental results show the effectiveness of facial, holistic and speech features for group-level affect analysis. The baseline code, dataset, and pre-trained models are available at [LINK].","2023-04","2025-02-26 20:41:52","2025-02-26 20:41:52","","1056-1069","","2","14","","","","","","","","","","English","","","","WOS:001000299100015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","affect recognition; affective computing; Affective computing; Cameras; COHESION; DATASET; Emotion recognition; EMOTIONS; EXPRESSIONS; Face recognition; Feature extraction; Group-level affect recognition; RECOGNITION; Speech recognition; Videos","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G88JN3L4","journalArticle","2021","Pribil, J; Pribilova, A; Frollo, I","Stress Level Detection and Evaluation from Phonation and PPG Signals Recorded in an Open-Air MRI Device","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app112411748","","This paper deals with two modalities for stress detection and evaluation-vowel phonation speech signal and photo-plethysmography (PPG) signal. The main measurement is carried out in four phases representing different stress conditions for the tested person. The first and last phases are realized in laboratory conditions. The PPG and phonation signals are recorded inside the magnetic resonance imaging scanner working with a weak magnetic field up to 0.2 T in a silent state and/or with a running scan sequence during the middle two phases. From the recorded phonation signal, different speech features are determined for statistical analysis and evaluation by the Gaussian mixture models (GMM) classifier. A database of affective sounds and two databases of emotional speech were used for GMM creation and training. The second part of the developed method gives comparison of results obtained from the statistical description of the sensed PPG wave together with the determined heart rate and Oliva-Roztocil index values. The fusion of results obtained from both modalities gives the final stress level. The performed experiments confirm our working assumption that a fusion of both types of analysis is usable for this task-the final stress level values give better results than the speech or PPG signals alone.","2021-12","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","24","11","","","","","","","","","","English","","","","WOS:000735328000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","ACOUSTIC NOISE; EMOTION RECOGNITION; FUSION; GMM-based classification; photo-plethysmographic wave analysis; SPEAKER; stress detection and evaluation; SUPPORT VECTOR MACHINES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5EW8CHPX","journalArticle","2022","Patel, P; van der Heijden, K; Bickel, S; Herrero, JL; Mehta, AD; Mesgarani, N","Interaction of bottom-up and top-down neural mechanisms in spatial multi-talker speech perception","CURRENT BIOLOGY","","0960-9822","10.1016/j.cub.2022.07.047","","How the human auditory cortex represents spatially separated simultaneous talkers and how talkers' loca-tions and voices modulate the neural representations of attended and unattended speech are unclear. Here, we measured the neural responses from electrodes implanted in neurosurgical patients as they per-formed single-talker and multi-talker speech perception tasks. We found that spatial separation between talkers caused a preferential encoding of the contralateral speech in Heschl's gyrus (HG), planum temporale (PT), and superior temporal gyrus (STG). Location and spectrotemporal features were encoded in different aspects of the neural response. Specifically, the talker's location changed the mean response level, whereas the talker's spectrotemporal features altered the variation of response around response's baseline. These components were differentially modulated by the attended talker's voice or location, which improved the population decoding of attended speech features. Attentional modulation due to the talker's voice only ap-peared in the auditory areas with longer latencies, but attentional modulation due to location was present throughout. Our results show that spatial multi-talker speech perception relies upon a separable pre -atten-tive neural representation, which could be further tuned by top-down attention to the location and voice of the talker.","2022-09-26","2025-02-26 20:41:52","2025-02-26 20:41:52","","3971-+","","18","32","","","","","","","","","","English","","","","WOS:000870234300002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;89</p>","","","COCKTAIL PARTY; FEATURES; NEURONS; PITCH; PRIMARY AUDITORY-CORTEX; REPRESENTATIONS; SELECTIVE ATTENTION; SENSITIVITY; SPECTROTEMPORAL RECEPTIVE-FIELDS; TIME","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4P3FY48R","journalArticle","2022","Zhao, P; Liu, FA; Zhuang, XQ","Speech Sentiment Analysis Using Hierarchical Conformer Networks","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app12168076","","Multimodality has been widely used for sentiment analysis tasks, especially for speech sentiment analysis. Compared with the emotion expression of most text languages, speech is more intuitive for human emotion, as speech contains more and richer emotion features. Most of the current studies mainly involve the extraction of speech features, but the accuracy and prediction rate of the models still need to be improved. To improve the extraction and fusion of speech sentiment feature information, we present a new framework. The framework adopts a hierarchical conformer model and an attention-based GRU model to increase the accuracy of the model. The method has two main parts: a local feature learning group and a global feature learning group. The local feature learning group is mainly used to learn the spatio-temporal feature information of speech emotion features through the conformer model, and a combination of convolution and transformer is used to be able to enhance the extraction of long and short-term feature information. The global features are then extracted by the AUGRU model, and the fusion of features is performed by the attention mechanism to access the weights of feature information. Finally, the sentiment is identified by a fully connected network layer, and then classified by a central loss function and a softmax function. Compared with existing speech sentiment analysis models, we obtained better sentiment classification results on the IEMOCAP and RAVDESS benchmark datasets.","2022-08","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","16","12","","","","","","","","","","English","","","","WOS:000846975200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","attention; conformer; EMOTION RECOGNITION; GRU; multimodal","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U5B4HWWQ","journalArticle","2022","Nahar, R; Miwa, S; Kai, ATHK","Domain Adaptation with Augmented Data by Deep Neural Network Based Method Using Re-Recorded Speech for Automatic Speech Recognition in Real Environment","SENSORS","","1424-8220","10.3390/s22249945","","The most effective automatic speech recognition (ASR) approaches are based on artificial neural networks (ANN). ANNs need to be trained with an adequate amount of matched conditioned data. Therefore, performing training adaptation of an ASR model using augmented data of matched condition as the real environment gives better results for real data. Real-world speech recordings can vary in different acoustic aspects depending on the recording channels and environment such as the Long Term Evolution (LTE) channel of mobile telephones, where data are transmitted with voice over LTE (VoLTE) technology, wireless pin mics in a classroom condition, etc. Acquiring data with such variation is costly. Therefore, we propose training ASR models with simulated augmented data and fine-tune them for domain adaptation using deep neural network (DNN)-based simulated data along with re-recorded data. DNN-based feature transformation creates realistic speech features from recordings of clean conditions. In this research, a comparative investigation is performed for different recording channel adaptation methods for real-world speech recognition. The proposed method yields 27.0% character error rate reduction (CERR) for the DNN-hidden Markov model (DNN-HMM) hybrid ASR approach and 36.4% CERR for the end-to-end ASR approach for the target domain of the LTE channel of telephone speech.","2022-12","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","24","22","","","","","","","","","","English","","","","WOS:000904480200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","ASR; classroom recording; data augmentation; DNN; feature transformation; real environment; recording alignment; VoLTE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z6GJMK3N","journalArticle","2021","Yerigeri, VV; Ragha, LK","Speech stress recognition using semi-eager learning","COGNITIVE SYSTEMS RESEARCH","","2214-4366","10.1016/j.cogsys.2020.10.001","","Homo-sapiens suffer from psychogenic pain due to current day lifestyle. According to psychologists, stress is the most destructive form of psychalgia and it is a vicious companion for this species. Immoderate levels of stress may lead to the death of many individuals. Normally, the presence of stress gives rise to certain emotions which can be detected to predict stress levels of a person. This paper proposes the development of mechanized and efficient Speech Emotion Recognition (SER) for stress level analysis. The paper investigates the performance of perceptual based speech features like Revised Perceptual Linear Prediction Coefficients, Bark Frequency Cepstral Coefficients, Perceptual Linear Predictive Cepstrum, Gammatone Frequency Cepstral coefficient, Mel Frequency Cepstral Coefficient, Gammatone Wavelet Cepstral Coefficient and Inverted Mel Frequency Cepstral Coefficients on SER. The novelty of this work involves application of a SemiEager (SemiE) learning algorithm for evaluating auditory cues. SemiE offers advantages over eager and lazy based learning by reducing the computational cost. Stress level recognition being the main objective, the Speech Under Simulated and Actual Stress (SUSAS) benchmark database is used for performance analysis. A comparative analysis is presented to demonstrate the improvement in the SED performance. An overall accuracy of 90.66% recognition of stress related emotions is achieved. (c) 2020 Elsevier B.V. All rights reserved.","2021-01","2025-02-26 20:41:52","2025-02-26 20:41:52","","79-97","","","65","","","","","","","","","","English","","","","WOS:000595249800009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;100</p>","","","DISORDER; EMOTION RECOGNITION; FEATURES; Gammatone Frequency Cepstral coefficient (GFCC); Perceptual Linear Predictive Cepstrum (PLPC); Revised Perceptual Linear Prediction Coefficient's (RPLP); SemiEager; Speech emotion; STATES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UUMTEX39","journalArticle","2025","Xu, XM; Li, JZ; Zhang, YQ; Tu, WP; Yang, YH","Spatial information aided speech and noise feature discrimination for Monaural speech enhancement","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.126349","","Current deep learning-based speech enhancement methods aim to establish a mapping relationship between noisy and clean speech. However, since the training target is solely clean speech and lacks knowledge of noise, these networks struggle in regions where speech and noise features are similar, leading to either insufficient or excessive noise removal. Although some methods incorporate noise as an additional training target, the unpredictability of noise signals makes effective modeling challenging. In this paper, we propose a S patial IN formation AI ded MO naural S peech E nhancement (SINAI-MoSE), a monaural speech enhancement method that utilizes spatial information to assist indiscriminating and modeling speech and noise features. Specifically, the encoder part of SINAI-MoSE adopts a progressive speech and noise feature extraction approach and establishes a mapping relationship between single-channel noisy speech and synthesized dual-channel noisy speech that is simulated via an ideal room impulse response. Additionally, the decoder reconstructs the speech features extracted by the encoder using a multi-sparsity Conformer network to handle speech details from local to global with high precision. Empirical studies underscore the effectiveness of spatial information in speech and noise feature discrimination. Consequently, SINAI-MoSE demonstrates significant advancements over recent monaural speech enhancement methods, excelling in speech quality and intelligibility.","2025-04-15","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","269","","","","","","","","","","English","","","","WOS:001397897400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;77</p>","","","Back-projection; FRAMEWORK; Monaural speech enhancement; NETWORKS; RECOGNITION; Self-attention; SEPARATION; Simulated spatial information; SUPPRESSION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DE48KKB9","journalArticle","2021","Ying, YW; Tu, YW; Zhou, H","Unsupervised Feature Learning for Speech Emotion Recognition Based on Autoencoder","ELECTRONICS","","2079-9292","10.3390/electronics10172086","","Speech signals contain abundant information on personal emotions, which plays an important part in the representation of human potential characteristics and expressions. However, the deficiency of emotion speech data affects the development of speech emotion recognition (SER), which also limits the promotion of recognition accuracy. Currently, the most effective approach is to make use of unsupervised feature learning techniques to extract speech features from available speech data and generate emotion classifiers with these features. In this paper, we proposed to implement autoencoders such as a denoising autoencoder (DAE) and an adversarial autoencoder (AAE) to extract the features from LibriSpeech for model pre-training, and then conducted experiments on the Interactive Emotional Dyadic Motion Capture (IEMOCAP) datasets for classification. Considering the imbalance of data distribution in IEMOCAP, we developed a novel data augmentation approach to optimize the overlap shift between consecutive segments and redesigned the data division. The best classification accuracy reached 78.67% (weighted accuracy, WA) and 76.89% (unweighted accuracy, UA) with AAE. Compared with state-of-the-art results to our knowledge (76.18% of WA and 76.36% of UA with the supervised learning method), we achieved a slight advantage. This suggests that using unsupervised learning benefits the development of SER and provides a new approach to eliminate the problem of data scarcity.","2021-09","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","17","10","","","","","","","","","","English","","","","WOS:000694176600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","autoencoders; deep learning; deep neural network; speech emotion recognition; unsupervised learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PPF9SECA","journalArticle","2022","Cui, SS; Huang, BY; Huang, JW; Kang, XG","Synthetic Speech Detection Based on Local Autoregression and Variance Statistics","IEEE SIGNAL PROCESSING LETTERS","","1070-9908","10.1109/LSP.2022.3183951","","With the development of speech synthesis technology, the existing synthetic speech detection (SSD) methods cannot generalize well for unknown synthesis algorithms. And thus, this kind of speech forensics task meets a great challenge and has attracted great enthusiasm. We observe that the process of speech synthesis always includes the resampling and pooling/smoothing operations, which will change the speech's local autoregressive (AR) and statistic distribution. In this paper, based on AR modeling and standard deviation statistics, we propose novel front-end speech features, i.e., ARS in short form, as the input of an SSD classifier. In addition, a new back-end classifier is constructed based on the dense convolution and short connection, and we name it scDenseNet. Experimental results on the ASVspoof2019 logical access (LA) dataset demonstrate that the ARS has a strong representation and sensitivity to spoofing attacks, and achieves promising performance on SSD. The proposed scDenseNet outperforms the previous version DenseNet on both EER and t-DCF scores, and achieves the best performance when compared with other state-of-the-art classifiers studied in this paper. Furthermore, based on the proposed scDenseNet, incorporating ARS with popular features such as the linear frequency cepstral coefficients (LFCC) significantly enhances the fusion performance and yields an EER score of 0.98%.","2022","2025-02-26 20:41:52","2025-02-26 20:41:52","","1462-1466","","","29","","","","","","","","","","English","","","","WOS:000838393600004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Autoregressive modeling; Feature extraction; Filtering; Forensics; Mel frequency cepstral coefficient; scDenseNet; speech forensics; Speech synthesis; Standards; synthetic speech detection; variance statistics; Windows","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3CUUWNER","journalArticle","2021","Pribil, J; Pribilová, A; Matousek, J","GMM-Based Evaluation of Synthetic Speech Quality Using 2D Classification in Pleasure-Arousal Scale","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app11010002","","The paper focuses on the description of a system for the automatic evaluation of synthetic speech quality based on the Gaussian mixture model (GMM) classifier. The speech material originating from a real speaker is compared with synthesized material to determine similarities or differences between them. The final evaluation order is determined by distances in the Pleasure-Arousal (P-A) space between the original and synthetic speech using different synthesis and/or prosody manipulation methods implemented in the Czech text-to-speech system. The GMM models for continual 2D detection of P-A classes are trained using the sound/speech material from the databases without any relation to the original speech or the synthesized sentences. Preliminary and auxiliary analyses show a substantial influence of the number of mixtures, the number and type of the speech features used the size of the processed speech material, as well as the type of the database used for the creation of the GMMs on the P-A classification process and on the final evaluation result. The main evaluation experiments confirm the functionality of the system developed. The objective evaluation results obtained are principally correlated with the subjective ratings of human evaluators; however, partial differences were indicated, so a subsequent detailed investigation must be performed.","2021-01","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","1","11","","","","","","","","","","English","","","","WOS:000605808900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","GMM classification; MODEL; statistical analysis; synthetic speech evaluation; text-to-speech system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JQV9FDQQ","journalArticle","2022","Núñez-Méndez, E","Variation in Spanish /s/: Overview and New Perspectives","LANGUAGES","","2226-471X","10.3390/languages7020077","","The natural tendency for language variation, intensified by Spanish's territorial growth, has driven sibilant changes and mergers across the Spanish-speaking world. This article aims to present an overview of the most significant processes undergone by sibilant /s/ in various Spanish-speaking areas: devoicing, weakening, aspiration, elision, and voicing. Geographically based phonetic variations, sociolinguistic factors, and Spanish language contact situations are considered in this study. The sibilant merger and its chronological development in modern Spanish, along with geographic expansion, have resulted in multiple contemporary dialectal variations. This historical lack of stability in these sounds has marked modern regional variations. Tracing and framing the sibilants' geo-linguistic features has received much attention from scholars, resulting in sibilants being one of the most studied variables in Spanish phonetics. In this article, we provide a concise approach that offers the reader an updated sociolinguistic view of the modern cross-dialectal realizations of /s/. It is essential to study sibilant development to describe Spanish dialects, the differences between Transatlantic and Castilian varieties, and the speech features found in Spanish speaking communities in the Americas. Examining sibilance from different approaches with a representative variety of Spanish dialects as examples advances the importance of sociolinguistic phenomena to index language changes.","2022-06","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","2","7","","","","","","","","","","English","","","","WOS:000815909900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;272</p>","","","aspiration; ASPIRATION; CONTACT; CUBAN; devoicing; elision; INTERVOCALIC S/; LENITION; MEXICAN SPANISH; PHONOLOGY; REALIZATION; s; SIBILANTS; Spanish; Spanish sibilants; SPEECH; weakening","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BMCXVVSY","journalArticle","2022","Werwach, A; Maennel, C; Obrig, H; Friederici, AD; Schaadt, G","Longitudinal trajectories of electrophysiological mismatch responses in infant speech discrimination differ across speech features","DEVELOPMENTAL COGNITIVE NEUROSCIENCE","","1878-9293","10.1016/j.dcn.2022.101127","","Infants rapidly advance in their speech perception, electrophysiologically reflected in the transition from an immature, positive-going to an adult-like, negative-going mismatch response (MMR) to auditory deviancy. Although the MMR is a common tool to study speech perception development, it is not yet completely understood how different speech contrasts affect the MMR's characteristics across development. Thus, a systematic longitudinal investigation of the MMR's maturation depending on speech contrast is necessary. We here longitudinally explored the maturation of the infant MMR to four critical speech contrasts: consonant, vowel, vowellength, and pitch. MMRs were obtained when infants (n = 58) were 2, 6 and 10 months old. To evaluate the maturational trajectory of MMRs, we applied second-order latent growth curve models. Results showed positivegoing MMR amplitudes to all speech contrasts across all assessment points that decreased over time towards an adult-like negativity. Notably, the developmental trajectories of speech contrasts differed, implying that infant speech perception matures with different rates and trajectories throughout the first year, depending on the studied auditory feature. Our results suggest that stimulus-dependent maturational trajectories need to be considered when drawing conclusions about infant speech perception development reflected by the infant MMR.","2022-08","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","56","","","","","","","","","","English","","","","WOS:000824184000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;96</p>","","","BRAIN POTENTIALS; CORTICAL RESPONSES; Developmental trajectory; Event-related potentials; GENETIC RISK; Infancy; LANGUAGE; Language development; MATURATION; Mismatch response; NEGATIVITY; PERCEPTION; PITCH CHANGE; R PACKAGE; Speech discrimination; WORD STRESS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XJMTB2FB","journalArticle","2021","Milal, AD","Teacher Talk to Accommodate Low-Proficiency Learners in EFL Classes: A Case Study","JOURNAL OF ASIA TEFL","","1738-3102","10.18823/asiatefl.2021.18.2.2.406","","Instructional design is usually focused on the presentation of materials. The principles of teachers' language-use strategies have scarcely been discussed. In an EFL context, teachers are required to use the target language to promote learners' language acquisition. What is the language like when the learners still have low language proficiency? This study aims to describe the speech features of non-native teachers of English addressed to lower-proficiency learners in EFL classes. The data were collected by observation, interview, and recording the teachers teaching English in lower classes, i.e. semester one, and its comparable counterpart of higher classes, i.e. semester five of the English Department in a public university in Malang, Indonesia, and then analyzed by describing and comparing inter-levels intra-subjects. Despite some variability among subjects, it was found that there was a tendency that the language addressed to lower-proficiency learners has specific characteristics encompassing formal, interactional, and native language features that were simpler than that to higher-proficiency learners. This study concludes a principle of instructional delivery that student's level of knowledge and language ability determined the level of teacher speech. Hence, instructional designers should also describe how a medium of instruction is used, not merely how the learning material is presented.","2021","2025-02-26 20:41:52","2025-02-26 20:41:52","","406-421","","2","18","","","","","","","","","","English","","","","WOS:000672809700002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","1ST; comprehensible; ENGLISH; FEEDBACK; FREQUENCY; INPUT; INSTRUCTION; LANGUAGE; linguistic adjustment; low-proficiency learners; SENTENCES; SPEECH RATE; STRATEGIES; teacher talk","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WWRXKZI6","journalArticle","2021","Zhou, ZY; Liu, FA","Filter gate network based on multi-head attention for aspect-level sentiment classification","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2021.02.041","","Aspect-level sentiment classification (ASC) is an important branch of sentiment analysis. Its purpose is to identify the sentiment polarity of the context for a given aspect. In recent years, ASC has received widespread attention from more and more researchers. Most of the previous work used word embedding, which was trained from large corpora, as context representation. However, this method cannot fully express the actual meaning of the context. In addition, the attention mechanism in ASC brings noise and captures context words that are irrelevant to the current aspect. Based on the above problems, we propose a novel neural network, named Filter Gate Network based on Multi-head attention (FGNMH). First, we train the context in a domain-specific corpus and integrate the part-of-speech features of the context to enrich the representation of the context. Second, we use multi-head attention mechanism to model contextual semantic information. Finally, a filter layer is designed to remove context words that are irrelevant to current aspect. To verify the effectiveness of FGNMH, we conduct a large number of experiments on SemEval2014, Restaurant15, Restaurant16 and Twitter. Experimental results show that FGNMH can reach 83.92%, 81.24%, 84.05%, 85.37%and 74.37% on five data sets, respectively. (c) 2021 Elsevier B.V. All rights reserved.","2021-06-21","2025-02-26 20:41:52","2025-02-26 20:41:52","","214-225","","","441","","","","","","","","","","English","","","","WOS:000645427700019","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","Aspect-level sentiment classification; Domain-special corpus; Filter layer; Part-of-speech; SELF-ATTENTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QXNNLUB6","journalArticle","2024","Li, Y; Jin, X; Tong, L; Zhang, LM; Yao, YQ; Yan, H","A speech enhancement model based on noise component decomposition: Inspired by human cognitive behavior","APPLIED ACOUSTICS","","0003-682X","10.1016/j.apacoust.2024.109997","","In multimedia intelligent systems, speech enhancement is commonly employed to improve the quality of speech signals, making them clearer and more natural. Current deep learning-based speech enhancement models typically treat noise as a unified entity and aim to separate it from the target speech. In this paper, inspired by the cognitive behavior of the human brain when observing noisy speech spectrograms, we decompose the spectral energy of noise into regular and random components. We propose an auxiliary-model-based speech enhancement framework that better suppresses noise components closely resembling speech features. Firstly, we introduce a voiceprint segmentation network (VSnet) that partitions noisy speech into voiceprint and non-voiceprint regions. Subsequently, we present a noise reconstruction network (NRnet) that utilizes noise information from non- voiceprint regions to reconstruct and suppress the regular noise components within the voiceprint region. Finally, we construct a combination of a model dedicated to suppressing random components (RANnet) and a speech enhancement model (SEnet), and train them synchronously. By sharing encoder parameters, SEnet is compelled to reduce the extraction of regular noise features from the original noisy speech, contributing to improving speech quality generated through the decoder. Experimental results on public Voickbank-DEMAND and DNS-challenge 2020 datasets demonstrate that our approach achieves state-of-the-art performance.","2024-05-15","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","221","","","","","","","","","","English","","","","WOS:001287320800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Convolutional neural network; CONVOLUTIONAL NEURAL-NETWORK; Logarithmic magnitude spectrogram; Natural language processing; Speech enhancement; SUPPRESSION; Voiceprint","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HLIMWZ56","journalArticle","2023","Lu, CT; Shen, JH; Castiglione, A; Chung, CH; Lu, YY","A speech denoising demonstration system using multi-model deep-learning neural networks","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-023-17655-1","","Sound noise would interfere with speech signals in natural environments, causing speech quality deterioration. Speech denoising aims to denoise effectively with the preservation of speech components. Noise estimation is critical for speech denoising. Speech components distort when overestimating the noise spectral level. On the contrary, underestimating the noise's spectral level cannot remove noise effectively. Much residual noise exists in the denoised speech, resulting in low speech quality. This article presents a multi-model deep-learning neural network (MDNN) for speech enhancement. Firstly, a harmonic-convolutional neural network (harmonic-CNN) is utilized to classify speech and noise segments by spectrograms. The target is manually labeled according to harmonic properties. A speech-deep-learning neural network (speech-DNN) improves the harmonic-CNN's recognition accuracy. Some robust speech features, including energy variation and zero-crossing rate, are also applied to classify speech and noise segments by a speech-DNN. The noise level is overestimated in speech-pause parts to suppress noise spectra effectively in the enhanced speech. Conversely, the noise level is underestimated in speech-presence frames to reduce speech distortion. The experiment results reveal that the presented MDNN accurately classifies speech and noise segments, effectively reducing interference noise.","2023-11-21","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","","","","","","","","","","","English","","","","WOS:001106086000006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","ENHANCEMENT; FRAMEWORK; GAIN FACTOR; Harmonic convolutional neural network; MASKING; Multi-model deep-learning neural network; NOISE-REDUCTION; SNR; Speech and noise separation; Speech denoising; Speech-deep-learning neural network; SUBTRACTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L59N79S6","journalArticle","2021","Hasannezhad, M; Ouyang, ZH; Zhu, WP; Champagne, B","Speech Enhancement With Phase Sensitive Mask Estimation Using a Novel Hybrid Neural Network","IEEE OPEN JOURNAL OF SIGNAL PROCESSING","","2644-1322","10.1109/OJSP.2021.3067147","","A natural choice to model strong temporal dynamics of speech is the recurrent neural network (RNN) since it can exploit the sequential information from consecutive acoustic frames and generalizes the model well to unseen speakers. Besides, the convolutional neural network (CNN) can automatically extract sophisticated speech features that can maximize the performance of a model. In this paper, we propose a hybrid neural network model integrating a new low-complexity fully-convolutional CNN and a long short-term memory (LSTM) network, a variation of RNN, to estimate a phase-sensitive mask for speech enhancement. The model is designed to take full advantages of the temporal dependencies and spectral correlations present in the input speech signal while keeping the model complexity low. Also, an attention technique is embedded to recalibrate the useful CNN-extracted features adaptively. Furthermore, a grouping strategy is employed to reduce the LSTM complexity while keeping the performance almost unchanged. Through extensive comparative experiments, we show that the proposed model significantly outperforms some known neural network-based speech enhancement methods in the presence of highly non-stationary noises, while it exhibits a relatively small number of model parameters compared to some commonly employed DNN-based methods.","2021","2025-02-26 20:41:52","2025-02-26 20:41:52","","136-150","","","2","","","","","","","","","","English","","","","WOS:000710552900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Attention technique; convolutional neural network; Estimation; Feature extraction; grouped long short-term memory; NOISE; Noise measurement; phase sensitive mask; SEPARATION; Spectrogram; speech enhancement; Speech enhancement; Speech recognition; Training","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SEJYCCMZ","journalArticle","2024","Qian, XY; Xue, W; Zhang, QQ; Tao, RJ; Li, HZ","Deep Cross-Modal Retrieval Between Spatial Image and Acoustic Speech","IEEE TRANSACTIONS ON MULTIMEDIA","","1520-9210","10.1109/TMM.2023.3323876","","Cross-modal Retrieval (CMR) is formulated for the scenarios where the queries and retrieval results are of different modalities. Existing Cross-modal Retrieval (CMR) studies mainly focus on the common contextualized information between text transcripts and images, and the synchronized event information in audio-visual recordings. Unlike all previous works, in this article, we investigate the geometric correspondence between images and speech recordings captured in the same space and formulate a novel CMR task, called Spatial Image-Acoustic Retrieval (SIAR). To this end, we first design a novel speech encoder that consists of convolution neural networks and transformer layers, to learn space-aware speech representations. Then, to eliminate the cross-modal inherent discrepancy, we propose the Contrastive Speech Image Retrieval (CSIR) method which uses supervised contrastive learning to attract the same-space cross-modal features while repelling the ones from different spaces. Finally, image and speech features are directly compared and we predict the SIAR result with the maximum similarity. Extensive experiments demonstrate that our proposed speech encoder can recognize space from human speeches with superior performance over the other prevailing networks. It also sets our penultimate goal of speech-to-speech retrieval. Furthermore, our CSIR proposal can successfully perform bi-directional SIAR between spatial images and reverberant speeches with promising results. Code and data will be available.","2024","2025-02-26 20:41:52","2025-02-26 20:41:52","","4480-4489","","","26","","","","","","","","","","English","","","","WOS:001181498100034","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","contrastive learning; Cross-modal retrieval; reverberation; space-acoustics correspondence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TKBMGSC4","journalArticle","2021","Ancilin, J; Milton, A","Improved speech emotion recognition with Mel frequency magnitude coefficient","APPLIED ACOUSTICS","","0003-682X","10.1016/j.apacoust.2021.108046","","Automatic speech emotion recognition using machine learning is a demanding research topic in the field of affective computing. Identifying the speech features for speech emotion recognition is a challenging issue as the feature needs to emphasize the information about emotion from the speech. Spectral features play a vital role in emotion recognition from speech signals. In this paper, two modifications are made in the extraction of Mel frequency cepstral coefficient, they are, using magnitude spectrum instead of energy spectrum and exclusion of discrete cosine transform and extract Mel Frequency Magnitude Coefficient. Mel frequency magnitude coefficient is the log of magnitude spectrum on a non-linear Mel scale frequency. Mel frequency magnitude coefficient and three conventional spectral features, Mel frequency cepstral coefficient, log frequency power coefficient and linear prediction cepstral coefficient are tested on Berlin, Ravdess, Savee, EMOVO, eNTERFACE and Urdu databases with multiclass support vector machine as the classifier. Mel frequency magnitude coefficient as a stand alone feature recognizes emotion with an accuracy of 81.50% for Berlin, 64.31% for Ravdess, 75.63% for Savee, 73.30% for EMOVO, 56.41% for eNTERFACE and 95.25% for Urdu databases. Mel frequency magnitude coefficient is found to be the better spectral feature for the identification of emotion from speech compared to the conventional features. (C) 2021 Elsevier Ltd. All rights reserved.","2021-08","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","179","","","","","","","","","","English","","","","WOS:000652029800012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;81<br/>Total Times Cited:&nbsp;&nbsp;83<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","CLASSIFICATION; FEATURE-SELECTION; Mel frequency magnitude coefficient; SPECTRAL FEATURES; Speech emotion recognition; Speech feature; Speech signal processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5S4ELB6F","journalArticle","2022","Mihalache, S; Burileanu, D","Using Voice Activity Detection and Deep Neural Networks with Hybrid Speech Feature Extraction for Deceptive Speech Detection","SENSORS","","1424-8220","10.3390/s22031228","","In this work, we first propose a deep neural network (DNN) system for the automatic detection of speech in audio signals, otherwise known as voice activity detection (VAD). Several DNN types were investigated, including multilayer perceptrons (MLPs), recurrent neural networks (RNNs), and convolutional neural networks (CNNs), with the best performance being obtained for the latter. Additional postprocessing techniques, i.e., hysteretic thresholding, minimum duration filtering, and bilateral extension, were employed in order to boost performance. The systems were trained and tested using several data subsets of the CENSREC-1-C database, with different simulated ambient noise conditions, and additional testing was performed on a different CENSREC-1-C data subset containing actual ambient noise, as well as on a subset of the TIMIT database. An accuracy of up to 99.13% was obtained for the CENSREC-1-C datasets, and 97.60% for the TIMIT dataset. We proceed to show how the final VAD system can be adapted and employed within an utterance-level deceptive speech detection (DSD) processing pipeline. The best DSD performance is achieved by a novel hybrid CNN-MLP network leveraging a fusion of algorithmically and automatically extracted speech features, and reaches an unweighted accuracy (UA) of 63.7% on the RLDD database, and 62.4% on the RODeCAR database.","2022-02","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","3","22","","","","","","","","","","English","","","","WOS:000759983300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","deceptive speech detection; deep neural networks; RODeCAR; voice activity detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SLL65CDV","journalArticle","2024","Svatos, J; Holub, J","Cepstral coefficients effectiveness for gunshot classifying","MEASUREMENT SCIENCE AND TECHNOLOGY","","0957-0233","10.1088/1361-6501/ad3c5d","","This paper analyses the efficiency of various frequency cepstral coefficients (FCC) in a non-speech application, specifically in classifying acoustic impulse events-gunshots. There are various methods for such event identification available. The majority of these methods are based on time or frequency domain algorithms. However, both of these domains have their limitations and disadvantages. In this article, an FCC, combining the advantages of both frequency and time domains, is presented and analyzed. These originally speech features showed potential not only in speech-related applications but also in other acoustic applications. The comparison of the classification efficiency based on features obtained using four different FCC, namely mel-FCC (MFCC), inverse mel-frequency cepstral coefficients (IMFCC), linear-frequency cepstral coefficients (LFCC), and gammatone-frequency cepstral coefficients (GTCC) is presented. An optimal frame length for an FCC calculation is also explored. Various gunshots from short guns and rifle guns of different calibers and multiple acoustic impulse events, similar to the gunshots, to represent false alarms are used. More than 600 acoustic events records have been acquired and used for training and validation of two designed classifiers, support vector machine, and neural network. Accuracy, recall and Matthew's correlation coefficient measure the classification success rate. The results reveal the superiority of GFCC to other analyzed methods.","2024-07-01","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","7","35","","","","","","","","","","English","","","","WOS:001204907200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","acoustic measurements; cepstral coefficients; CLASSIFICATION; FEATURES; gunshot detection; MFCC; multiple signal classification; neural network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ET7VEX6M","journalArticle","2022","Meng, FQ; Zheng, YJ; Bao, SB; Wang, JD; Yang, SS","Formulaic language identification model based on GCN fusing associated information","PEERJ COMPUTER SCIENCE","","2376-5992","10.7717/peerj-cs.984","","Formulaic language is a general term for ready-made structures in a language. It usually has fixed grammatical structure, stable language expression meaning and specific use context. The use of formulaic language can coordinate sentence generation in the process of writing and communication, and can significantly improve the idiomaticity and logic of machine translation, intelligent question answering and so on. New formulaic language is generated almost every day, and how to accurately identify them is a topic worthy of research. To this end, this article proposes a formulaic language identification model based on GCN fusing associated information. The innovation is that each sentence is constructed into a graph in which the nodes are part-of-speech features and semantic features of the words in the sentence and the edges between nodes are constructed according to mutual information and dependency syntactic relation. On this basis, the graph convolutional neural network is adopted to extract the associated information between words to mine deeper grammatical features. Therefore, it can improve the accuracy of formulaic language identification. The experimental results show that the model in this article is superior to the classical formulaic language identification model in terms of accuracy, recall and F1-score. It lays a foundation for the follow-up research of formulaic language identification tasks.","2022-06-03","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","8","","","","","","","","","","English","","","","WOS:000812999600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;28<br/>Total Times Cited:&nbsp;&nbsp;29<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Associated information; Dependency syntactic relation; Formulaic language; Graph convolutional neural network; LIST; Mutual information","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7NU6RDSE","journalArticle","2021","Floud, S; Balkwill, A; Sweetland, S; Brown, A; Reus, EM; Hofman, A; Blacker, D; Kivimaki, M; Green, J; Peto, R; Reeves, GK; Beral, V","Cognitive and social activities and long-term dementia risk: the prospective UK Million Women Study","LANCET PUBLIC HEALTH","","2468-2667","","","Background Although dementia is associated with non-participation in cognitive and social activities, this association might merely reflect the consequences of dementia, rather than any direct effect of non-participation on the subsequent incidence of dementia. Because of the slowness with which dementia can develop, unbiased assessment of any such direct effects must relate non-participation in such activities to dementia detection rates many years later. Prospective studies with long-term follow-up can help achieve this by analysing separately the first and second decade of follow-up. We report such analyses of a large, 20-year study. Methods The UK Million Women Study is a population-based prospective study of 1.3 million women invited for National Health Service (NHS) breast cancer screening in median year 1998 (IQR 1997-1999). In median year 2001 (IQR 2001-2003), women were asked about participation in adult education, groups for art, craft, or music, and voluntary work, and in median year 2006 (IQR 2006-2006), they were asked about reading. All participants were followed up through electronic linkage to NHS records of hospital admission with mention of dementia, the first mention of which was the main outcome. Comparing non-participation with participation in a particular activity, we used Cox regression to assess fully adjusted dementia risk ratios (RRs) during 0-4, 5-9, and 10 or more years, after information on that activity was obtained. Findings In 2001, 851 307 women with a mean age of 60 years (SD 5) provided information on participation in adult education, groups for art, craft, or music, and voluntary work. After 10 years, only 9591 (1%) had been lost to follow-up and 789 339 (93%) remained alive with no recorded dementia. Follow-up was for a mean of 16 years (SD 3), during which 31 187 (4%) had at least one hospital admission with mention of dementia, including 25 636 (3%) with a hospital admission with dementia mentioned for the first time 10 years or more after follow-up began. Nonparticipation in cognitive or social activities was associated with higher relative risks of dementia detection only during the first decade after participation was recorded. During the second decade, there was little association. This was true for non-participation in adult education (RR 1.04, 99% CI 0.98-1.09), in groups for art, craft, or music (RR 1.04, 0.99-1.09), in voluntary work (RR 0.96, 0.92-1.00), or in any of these three (RR 0.99, 0.95-1.03). In 2006, 655 118 women provided information on reading. For non-reading versus any reading, there were similar associations with dementia, again with strong attenuation over time since reading was recorded, but longer follow-up is needed to assess this reliably. Interpretation Life has to be lived forwards, but can be understood only backwards. Long before dementia is diagnosed, there is a progressive reduction in various mental and physical activities, but this is chiefly because its gradual onset causes inactivity and not because inactivity causes dementia. Copyright (C) 2021 The Author(s). Published by Elsevier Ltd.","2021-02","2025-02-26 20:41:52","2025-02-26 20:41:52","","e116-e123","","2","6","","","","","","","","","","English","","","","WOS:000615367100008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;47<br/>Total Times Cited:&nbsp;&nbsp;47<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","DECLINE; DISEASE; LEISURE ACTIVITIES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C39BB9YW","journalArticle","2025","Kumawat, P; Routray, A","Extending speech emotion recognition systems to non-prototypical emotions using mixed-emotion model","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.125358","","In the conventional approach to speech emotion recognition (SER), the classifier is usually trained on acted emotional speech data to predict individual basic emotions. In this work, we extend the SER systems with the realistic assumption of the coexistence of multiple basic emotions in an utterance. We utilize the MSPPodcast database for developing the SER system, which contains spontaneous speech utterances. From the primary and secondary emotion annotations of this database, we organize six prototypical and seven non- prototypical emotions. We then propose the mixed-emotion model and express the non-prototypical emotions as a linear combination of prototypical emotions. The combination weights of the mixed-emotion model are computed using a normalized dominance scale based algorithm inspired by the integration of basic emotion theory and dimensional emotion theory in human psychology. We first train a prototypical SER model using the ECAPA-TDNN architecture. The softmax predictions from this model serve as emotion profile inputs to the mixed-emotion model, which then predicts the non-prototypical emotions. Assuming the coexistence of multiple emotions, we only apply the utterances with uniform emotion profiles to the mixed-emotion model. The developed system continues with the conventional SER model if the emotion profile tends to delta function owing to the probable occurrence of a single prototypical emotion. We develop the proposed mixed-emotion model based SER framework using MFCC and wav2vec 2.0 extracted features. Further, we show that due to human perception variations, there exist prominent annotation variations in the non-prototypical emotion ground truths. To address that, we extend the supervised evaluation protocols in four different formulations that capture the subjective variability at different levels. The proposed system shows a best-case performance improvement of 7.10% and 8.39% over the conventional prototypical SER model for the MFCC and wav2vec 2.0 features, respectively.","2025-01-15","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","260","","","","","","","","","","English","","","","WOS:001317962000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;92</p>","","","Annotation variations; ANXIETY; CORPUS; DEPRESSION; DISAPPOINTMENT; Emotion profile; FACIAL EXPRESSIONS; FEATURES; FRAMEWORK; Mixed-emotion model; Non-prototypical emotion; PERCEPTION; PERFORMANCE; Speech emotion recognition; Wav2vec 2.0","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CTKVNWLY","journalArticle","2024","Xu, SS; Ke, XQ; Mak, MW; Wong, KH; Meng, H; Kwok, TCY; Gu, J; Zhang, J; Tao, W; Chang, CQ","Speaker-turn aware diarization for speech-based cognitive assessments","FRONTIERS IN NEUROSCIENCE","","1662-453X","10.3389/fnins.2023.1351848","","Introduction Speaker diarization is an essential preprocessing step for diagnosing cognitive impairments from speech-based Montreal cognitive assessments (MoCA).Methods This paper proposes three enhancements to the conventional speaker diarization methods for such assessments. The enhancements tackle the challenges of diarizing MoCA recordings on two fronts. First, multi-scale channel interdependence speaker embedding is used as the front-end speaker representation for overcoming the acoustic mismatch caused by far-field microphones. Specifically, a squeeze-and-excitation (SE) unit and channel-dependent attention are added to Res2Net blocks for multi-scale feature aggregation. Second, a sequence comparison approach with a holistic view of the whole conversation is applied to measure the similarity of short speech segments in the conversation, which results in a speaker-turn aware scoring matrix for the subsequent clustering step. Third, to further enhance the diarization performance, we propose incorporating a pairwise similarity measure so that the speaker-turn aware scoring matrix contains both local and global information across the segments.Results Evaluations on an interactive MoCA dataset show that the proposed enhancements lead to a diarization system that outperforms the conventional x-vector/PLDA systems under language-, age-, and microphone-mismatch scenarios.Discussion The results also show that the proposed enhancements can help hypothesize the speaker-turn timestamps, making the diarization method amendable to datasets without timestamp information.","2024-01-16","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","17","","","","","","","","","","English","","","","WOS:001151635800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","comprehensive scoring; DEMENTIA; dementia detection; IMPAIRMENT; MENTAL-STATE-EXAMINATION; MOCA; speaker diarization; speaker embedding; speaker-turn timestamps","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8F27LR4H","journalArticle","2023","Mefford, JA; Zhao, ZL; Heilier, L; Xu, M; Zhou, GF; Mace, R; Sloane, KL; Sheppard, SM; Glenn, S","Varied performance of picture description task as a screening tool across MCI subtypes","PLOS DIGITAL HEALTH","","2767-3170","10.1371/journal.pdig.0000197","","A picture description task is a component of Miro Health's platform for self-administration of neurobehavioral assessments. Picture description has been used as a screening tool for identification of individuals with Alzheimer's disease and mild cognitive impairment (MCI), but currently requires in-person administration and scoring by someone with access to and familiarity with a scoring rubric. The Miro Health implementation allows broader use of this assessment through self-administration and automated processing, analysis, and scoring to deliver clinically useful quantifications of the users' speech production, vocal characteristics, and language. Picture description responses were collected from 62 healthy controls (HC), and 33 participants with MCI: 18 with amnestic MCI (aMCI) and 15 with non-amnestic MCI (naMCI). Speech and language features and contrasts between pairs of features were evaluated for differences in their distributions in the participant subgroups. Picture description features were selected and combined using penalized logistic regression to form risk scores for classification of HC versus MCI as well as HC versus specific MCI subtypes. A picturedescription based risk score distinguishes MCI and HC with an area under the receiver operator curve (AUROC) of 0.74. When contrasting specific subtypes of MCI and HC, the classifiers have an AUROC of 0.88 for aMCI versus HC and and AUROC of 0.61 for naMCI versus HC. Tests of association of individual features or contrasts of pairs of features with HC versus aMCI identified 20 features with p-values below 5e-3 and False Discovery Rates (FDRs) at or below 0.113, and 61 contrasts with p-values below 5e-4 and FDRs at or below 0.132. Findings suggest that performance of picture description as a screening tool for MCI detection will vary greatly by MCI subtype or by the proportion of various subtypes in an undifferentiated MCI population.","2023-03","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","3","2","","","","","","","","","","English","","","","WOS:001416694800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","ALZHEIMERS-DISEASE; DEMENTIA; MILD COGNITIVE IMPAIRMENT; REGULARIZATION; SPONTANEOUS SPEECH; STROKE; TELEPHONE INTERVIEW","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TPVEF6IK","journalArticle","2022","De Clercq, LE; Prinzie, P; Swerts, C; Ortibus, E; De Pauw, SSW","""Tell Me About Your Child, The Relationship with Your Child and Your Parental Experiences"": A Qualitative Study of Spontaneous Speech Samples Among Parents Raising a Child with and without Autism Spectrum Disorder, Cerebral Palsy or Down Syndrome","JOURNAL OF DEVELOPMENTAL AND PHYSICAL DISABILITIES","","1056-263X","10.1007/s10882-021-09800-1","","Ample quantitative studies have shown that parents raising children with neurodevelopmental disabilities are prone to experience more stress and challenges in their parenthood. Notwithstanding the strength of this line of research, qualitative studies are crucial to grasp the complex reality of these parenting experiences. This qualitative study adopted the Self-Determination Theory to analyze parents' described experiences, appraising both challenges and opportunities in parents' psychological need for autonomy, relatedness, and competence. A multi-group comparative design is adopted to examine similarities and differences in the perspectives of 160 parents raising an adolescent with autism spectrum disorder, cerebral palsy, Down syndrome, or without a disability (M age child = 13.09 years, 67.5% boys). Parents' perspectives were examined through speech samples probing parents to talk spontaneously about their child, their relationship with the child, and their parental experiences. Forty samples in each group were randomly chosen from a larger dataset and were analyzed using deductive thematic analysis. Parents of children with a disability described more need-frustrating but also more autonomy-satisfying experiences compared to parents of children without a disability. Parents of children with autism spectrum disorder reported the most challenges concerning their relatedness with their child and their own parental competence. Parents raising a child with cerebral palsy expressed the most worries about their child's future and continuity of care. Parents of a child with Down syndrome described the most need-satisfying experiences in their family life. This study offers a more balanced view on the realm of parenting a child with a neurodevelopmental disability.","2022-04","2025-02-26 20:41:52","2025-02-26 20:41:52","","295-329","","2","34","","","","","","","","","","English","","","","WOS:000648282900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;93</p>","","","ADOLESCENTS; Autism Spectrum Disorder; BEHAVIOR PROBLEMS; Cerebral Palsy; DISABILITY; Down Syndrome; EXPRESSED EMOTION; FATHERS; GROSS MOTOR FUNCTION; MOTHERS; OF-LIFE; Parenting perspectives; PERSPECTIVES; Self-Determination Theory; YOUNG-CHILDREN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WR4GYQWQ","journalArticle","2024","Ali, MU; Hussain, SJ; Khalid, M; Farrash, M; Lahza, HFM; Zafar, A","MRI-Driven Alzheimer's Disease Diagnosis Using Deep Network Fusion and Optimal Selection of Feature","BIOENGINEERING-BASEL","","2306-5354","10.3390/bioengineering11111076","","Alzheimer's disease (AD) is a degenerative neurological condition characterized by cognitive decline, memory loss, and reduced everyday function, which eventually causes dementia. Symptoms develop years after the disease begins, making early detection difficult. While AD remains incurable, timely detection and prompt treatment can substantially slow its progression. This study presented a framework for automated AD detection using brain MRIs. Firstly, the deep network information (i.e., features) were extracted using various deep-learning networks. The information extracted from the best deep networks (EfficientNet-b0 and MobileNet-v2) were merged using the canonical correlation approach (CCA). The CCA-based fused features resulted in an enhanced classification performance of 94.7% with a large feature vector size (i.e., 2532). To remove the redundant features from the CCA-based fused feature vector, the binary-enhanced WOA was utilized for optimal feature selection, which yielded an average accuracy of 98.12 +/- 0.52 (mean +/- standard deviation) with only 953 features. The results were compared with other optimal feature selection techniques, showing that the binary-enhanced WOA results are statistically significant (p < 0.01). The ablation study was also performed to show the significance of each step of the proposed methodology. Furthermore, the comparison shows the superiority and high classification performance of the proposed automated AD detection approach, suggesting that the hybrid approach may help doctors with dementia detection and staging.","2024-11","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","11","11","","","","","","","","","","English","","","","WOS:001367684800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Alzheimer disease; canonical correlation analysis; deep features; dementia; feature fusion; feature selection; machine learning; optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T9X7PCH8","journalArticle","2021","Silva, LFLE; de Paula, RR","Disentangling Subject and Anacoluthon NPs in Topic: A Cognitive Grammar and Gestalt Psychology based approach","SOLETRAS","","1519-7778","10.12957/soletras.2021.54532","","In this paper we analyze NPs in Topic which can be either the subject of the verb in Comment, or autonomous items usually called anacolutha (LI; THOMPSON, 1976). It explores how these different NPs are mapped according to spontaneous speech data. Departing from Langacker's proposal (2001), in which the Topic and the subject act as trajectors of different scopes, it is argued that such a concept is adequate to the empirical data, since it allows the possibility of co-occurrence and intertwining of both categories in speech. In addition, we also investigated the difference in the cognitive processing of subject and anacoluthon NPs in Topic building upon the concepts of baseline and elaboration (LANGACKER, 2016). Through this framework, it is possible to conceive that the Topic-Comment is activated serially giving rise to the formation of structural layers in the cases that the NP in Topic is the subject of the verb in the Comment. Or it can be the result of a cumulative access via summation, if the NP is an anacoluthon. As the concepts of subject and Topic in the approach of Cognitive Grammar derive, in part, from the Gestalt psychology notions of Figure and Ground, the anacoluthon in Topic can be referred to as the Figure and the illocutionary force of the Comment would be the Ground. The only difference in relation to the visual elements is that, since they displaces through the space axis, the Figure and the Ground can be inverted depending on where the focus of attention is turned. However, as the speech is unfolded along the time axis, reversion is not possible, in such a way that an Anacoluthon in Topic will always be the Figure and the Comment will always be the Ground. In addition, the dependency relation of the Figure regarding the Ground explains the reason for a Topic cannot occur without a Comment.","2021-01","2025-02-26 20:41:52","2025-02-26 20:41:52","","315-342","","41","","","","","","","","","","","English","","","","WOS:000608483200014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Anacoluthon; Gestalt; Noun Phrase; Subject; Topic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y9JGBTNV","journalArticle","2023","Dickinson, KV; Ortiz-Ramirez, PA; Arrieta-Zamudio, A; Grinstead, J; Flores-Aalos, B","Overt Subject Pronoun Use in Switch-Reference Contexts in Child Spanish Developmental Language Disorder: A Discriminant Function Analysis","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2022_JSLHR-21-00483","","Purpose: Our study analyzes probabilistic constraints on subject expression previously found in adult Spanish in the speech of typically developing (TD) Spanish-speaking children and children with developmental language disorder (DLD). Previous work shows that children with DLD produce fewer overt sub-jects than typically developing children, and that the latter acquire constraints on subject expression as they age into adolescence. Our study complements these findings and provides further substance to the grammatical profile of children whose morphosyntactic development diverges from that of typically developing children.Method: Data are drawn from unstructured spontaneous production data from a sample of 19 monolingual Mexican, Spanish-speaking children, collected in 2006-2007. This sample includes 19 children diagnosed with DLD and 19 age -matched, typically developing children. We collected all instances of finite verbs that either did or could have occurred with a subject personal pronoun uttered by the child participants and coded them for several factors including tense- mood-aspect, switch reference, and person and number.Results: We find that children with DLD produce fewer overt subject pronouns in switch reference contexts than typically developing controls, with a significant interaction of group and switch reference. Furthermore, a discriminant function analysis shows that overt pronoun use in switch reference contexts can form part of a useful diagnostic discriminant function, with high levels of sensitivity and specificity.Conclusions: Overall, we find important differences between TD Spanish-speaking children and those diagnosed with DLD regarding rates of overt sub-jects and sensitivity to the probabilistic constraint of switch reference. This finding contributes to our understanding of the morphosyntactic profiles of children with DLD, as well as the utility of factors such as switch reference in the identifi-cation of language disorders.","2023-02","2025-02-26 20:41:52","2025-02-26 20:41:52","","605-619","","2","66","","","","","","","","","","English","","","","WOS:000975933000013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","CONTACT; CONVERGENCE; EXPRESSION; IMPAIRMENT; MARKING; NEW-YORK; SPEAKING CHILDREN; SPONTANEOUS SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F9JGV8MF","journalArticle","2021","Zhang, BL; Chang, JL; Park, J; Tan, ZJ; Tang, L; Lyu, TL; Han, Y; Fan, RW; Gao, Y; Kong, J","Uncinate fasciculus and its cortical terminals in aphasia after subcortical stroke: A multi-modal MRI study","NEUROIMAGE-CLINICAL","","2213-1582","10.1016/j.nicl.2021.102597","","Aphasia, one of the most common cognitive impairments after stroke, is commonly considered to be a cortical deficit. However, many studies have reported cases of post subcortical stroke aphasia (PSSA). The pathology and recovery mechanism of PSSA remain unclear. This study aimed to investigate PSSA mechanism through a multimodal magnetic resonance imaging (MRI) approach and a two-session study design (baseline and one month after treatment). Thirty-six PSSA patients and twenty-four matched healthy controls (HC) were included. All patients had subcortical infarctions involving left subcortical white matter for 1 to 6 months. The patients underwent MRI scan and Western Aphasia Battery (WAB) examination before and after one month's comprehensive treatment. Region-wise lesion-symptom mapping (RLSM), tractography, fractional anisotropy (FA), and amplitude of low-frequency fluctuations (ALFF) analysis were conducted. After MRI preprocessing and exclusion, FA analysis included 35 patients pre-treatment and 16 patients post-treatment. ALFF analysis included 30 patients pre-treatment and 14 patients post-treatment. We found: 1) the amount of damage in the left uncinate fasciculus (UF) was associated with WAB aphasia quotient (AQ); 2) the left UF FA and left temporal pole (TP) ALFF were decreased and positively correlated with WAB-AQ, spontaneous speech, and naming in PSSA patients; and 3) PSSA patients showed increased left TP ALFF when their language ability recovered after treatment. The left TP ALFF change was positively correlated with AQ change. Our results demonstrate the importance of left UF and left TP (one of the cortical terminals of the left UF) in PSSA pathology and recovery. These results may further provide support for the disconnection theory in the mechanism of PSSA.","2021","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","30","","","","","","","","","","English","","","","WOS:000670321800004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;16<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Aphasia; BASAL GANGLIA; DIFFUSION; Disconnection theory; FMRI; INTEGRITY; LANGUAGE; LESIONS; Multimodal MRI; NORMALIZATION; SPEECH; Subcortical stroke; Temporal pole; TEMPORAL-LOBE; Uncinate fasciculus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C6AURWLX","journalArticle","2023","Phillips, JB; Grenoble, LA; Mason, P","The unembodied metaphor: comprehension and production of tactile metaphors without somatosensation","FRONTIERS IN COMMUNICATION","","2297-900X","10.3389/fcomm.2023.1144018","","IntroductionProposals for embodied metaphor and embodied cognition have suggested abstract concepts are understood indirectly through the simulation of previous sensory experiences in a different domain. While exceptions have been observed for sensory deficits and impairments that are common, such as vision and audition, it is commonly assumed that somatosensation (proprioception, haptic touch, pain, pressure, temperature, etc.) is fundamental for the comprehension of production of sensory metaphors and much abstract thought in general. In this way, our past sensory experiences are critical to our understanding not just of the world around us but also of our sense of selves. This would suggest that Kim, who was born without somatosensation, would have difficulty understanding, using, or even thinking about many abstract concepts typically linked to different sensory experiences through metaphor, including a creation of a sense of self. MethodsTo examine her comprehension of sensory metaphors, Kim was asked to select the best sensory idiomatic expression given its context. Her friends and family as well as a representative sample of individuals online were recruited to complete the survey as controls. Additionally, we transcribed and analyzed six hours of unprompted speech to determine if Kim spontaneously uses somatosensory metaphors appropriately. ResultsResults from the idiomatic expression survey indicate that Kim performs as well as controls despite lacking any previous direct sensory experiences of these concepts. Analysis of the spontaneous speech highlights that Kim appropriately uses tactile expressions in both their concrete sensory and abstract metaphorical meanings. DiscussionTaken together, these two studies demonstrate that what is lost in sensory experiences can be made up in linguistic experiences, as Kim's understanding of tactile words was acquired in the complete absence of somatosensory experiences. This study demonstrates that individuals can comprehend and use tactile language and metaphor without recruiting past somatosensory experiences, and thus challenges a strong definition of embodied cognition which requires sensory simulations in language comprehension and abstract thought.","2023-04-17","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","8","","","","","","","","","","English","","","","WOS:000976399200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","Conceptual Metaphor Theory; embodied cognition; embodied metaphor; somatosensation; tactile perception","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9I8EL9UF","journalArticle","2021","Alighieri, C; Bettens, K; Vanoost, L; Demuynck, K; Verhaeghe, S; Van Lierde, K","Parents' perceptions on speech therapy delivery models in children with a cleft palate: A mixed methods study","INTERNATIONAL JOURNAL OF PEDIATRIC OTORHINOLARYNGOLOGY","","0165-5876","10.1016/j.ijporl.2021.110958","","Purpose: This study investigated parents' perceptions on two different speech therapy delivery models in children with a CP +/- L, namely an innovative high intensity speech intervention (i.e. HISI: 10 1-h sessions divided over 2 weeks) and a low intensity speech intervention (i.e. LISI: 10 1-h sessions divided over 10 weeks). Method: Twelve parents of 12 children who received HISI (n = 6) or LISI (n = 6) were contacted with the request to participate to this study to review their opinion on the received therapy. Participation included the completion of a questionnaire containing items related to satisfaction, speech progress, intervention intensity and frequency, transfer, and need for further speech therapy. Additionally, semi-structured interviews were carried out. The interviews were analyzed using an inductive thematic approach. Results: There were no significant differences between the two groups in satisfaction with the ""general speech therapy, ""duration of one speech therapy session"", ""total intervention duration"" and ""degree of improvement of speech intelligibility"". Following HISI, parents perceived more improvement in terms of spontaneous speech and better resolution of the speech disorders. The interviews revealed 3 themes of importance to the parents: (1) treatment-related expectations, (2) treatment-related burden, and (3) patient-therapist relationship. Parents in the HISI group reported two concerns: (1) the lack of variation when receiving daily intervention, and (2) the emotional burden when the child is confronted with his/her speech disorder on a daily basis. Conclusions: Parents were equally satisfied with the provided intervention. Parents in the HISI group perceived more speech progress following the intervention compared to parents in the LISI group. The intensive contact with the speech pathologist enhanced the patient-therapist relationship. To support a cultural shift away from low intensity therapy delivery models, it will be important to counsel and inform parents of the benefits of HISI and to counterbalance concerns.","2021-12","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","151","","","","","","","","","","English","","","","WOS:000718059900005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","ARTICULATION; Cleft palate; Evidence-based practice; LIP; MOTIVATION; Parents' perceptions; Qualitative research; SPACED PRACTICE; Speech therapy; VALIDITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X4TF4HI2","journalArticle","2022","Liu, MT; Qian, QC; Wang, W; Chen, L; Wang, LM; Zhou, YQ; Xu, SW; Wu, J; Feng, T; Zhu, ZD; Xiang, J","Improvement in language function in patients with aphasia using computer-assisted executive function training: A controlled clinical trial","PM&R","","1934-1482","10.1002/pmrj.12679","","Background Nonverbal cognitive training for aphasia has gained popularity. Prior research has found that cognitive status correlates with language function. Objective To determine whether nonverbal computer-assisted executive control training (CAET) to improve cognitive status affects language performance in patients with aphasia (PWA) and executive dysfunction. Design A single blind randomized trial. Setting Department of Rehabilitation, Affiliated Hospital of Xuzhou Medical University. Participants A total of 68 individuals were randomized, underwent treatment and were included in the analysis (CAET group, n = 33; control group, n = 35). Interventions The experimental group was treated with 4 weeks of traditional speech and language therapy (SLT) combined with CAET. The control group underwent SLT only. Main Outcome Measures Western Aphasia Battery [WAB]) with executive dysfunction (as assessed by the verbal fluency test [VFT], the Proverbs Test, the Tower of London Test [TLT], the Stroop Color and Word Test [SCWT], and the Trail Making Test [TMT]). Results Differences between pre- and posttreatment language outcomes except oral naming (group x time, p = .236) were significantly greater in the experimental group compared with the control group: spontaneous speech (group x time, p = .026), auditory comprehension (group x time, p < .001), speech repetition (group x time, p = .001), and aphasia quotient (AQ; group x time, p < .001). A similar effect was observed for cognitive function such as Trial Making Test (TMT)-A (group x time, p = .006), TMT-B (group x time, p = .005), and verbal fluency test (VFT-V; group x time, p = .018). Conclusion The study demonstrates that CAET combined with SLT can yield favorable language outcomes for PWA, especially improvements in auditory comprehension and AQ. CAET combined with SLT generates benefits in both cognitive function and language performance.","2022-08","2025-02-26 20:41:52","2025-02-26 20:41:52","","913-921","","8","14","","","","","","","","","","English","","","","WOS:000695021200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","ENRICHED ENVIRONMENT; INDUCED MOVEMENT THERAPY; MEMORY; METAANALYSIS; MIRROR THERAPY; OLDER-ADULTS; RECOVERY; STROKE PATIENTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9C97TMQZ","journalArticle","2021","Cavalcanti, JC; Eriksson, A; Barbosa, PA","Acoustic analysis of vowel formant frequencies in genetically-related and non-genetically related speakers with implications for forensic speaker comparison","PLOS ONE","","1932-6203","10.1371/journal.pone.0246645","","The purpose of this study was to explore the speaker-discriminatory potential of vowel formant mean frequencies in comparisons of identical twin pairs and non-genetically related speakers. The influences of lexical stress and the vowels' acoustic distances on the discriminatory patterns of formant frequencies were also assessed. Acoustic extraction and analysis of the first four speech formants F1-F4 were carried out using spontaneous speech materials. The recordings comprise telephone conversations between identical twin pairs while being directly recorded through high-quality microphones. The subjects were 20 male adult speakers of Brazilian Portuguese (BP), aged between 19 and 35. As for comparisons, stressed and unstressed oral vowels of BP were segmented and transcribed manually in the Praat software. F1-F4 formant estimates were automatically extracted from the middle points of each labeled vowel. Formant values were represented in both Hertz and Bark. Comparisons within identical twin pairs using the Bark scale were performed to verify whether the measured differences would be potentially significant when following a psychoacoustic criterion. The results revealed consistent patterns regarding the comparison of low-frequency and high-frequency formants in twin pairs and non-genetically related speakers, with high-frequency formants displaying a greater speaker-discriminatory power compared to low-frequency formants. Among all formants, F4 seemed to display the highest discriminatory potential within identical twin pairs, followed by F3. As for non-genetically related speakers, both F3 and F4 displayed a similar high discriminatory potential. Regarding vowel quality, the central vowel /a/ was found to be the most speaker-discriminatory segment, followed by front vowels. Moreover, stressed vowels displayed a higher inter-speaker discrimination than unstressed vowels in both groups; however, the combination of stressed and unstressed vowels was found even more explanatory in terms of the observed differences. Although identical twins displayed a higher phonetic similarity, they were not found phonetically identical.","2021-02-18","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","2","16","","","","","","","","","","English","","","","WOS:000620625100045","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","DISPERSION; ENGLISH; RANGE; SPEECH; STRESS; TWINS; VARIABILITY; VOCAL-TRACT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XP7BM6J9","journalArticle","2021","Fahmy, S; Kan, PF; Lewon, JW","The effects of theatre-based vocal empowerment on young Egyptian women's vocal and language characteristics","PLOS ONE","","1932-6203","10.1371/journal.pone.0261294","","This study investigates the impact of a theatre-based vocal empowerment program on the vocal and language characteristics and the self-perceptions of young bilingual Egyptian women. The program used applied theatre, a dramatic practice that promotes civic action by utilizing improvisational techniques to engage participants in exploring solutions to self-identified community concerns. These techniques supported participants' pursuit of vocal empowerment: the ability to comfortably express their intended content with a clear audible voice, accompanied by the belief that what they had to say was worthwhile. The program was implemented in Alexandria and Aswan, two Egyptian cities in different regions of the country, with distinct socio-economic profiles. Thirty-six young women from Aswan and nineteen from Alexandria participated. The program was facilitated in Arabic, for 90 minutes per day over twelve consecutive days in 2018. Participants in both groups spoke Arabic as a home language and studied English in school settings but differed in their educational experiences and English proficiency. The vocal and language characteristics of each participant were tested in Arabic and English pre- and post- program using a spontaneous speech task and a reading aloud task. Their self-perceptions were evaluated through a vocal self-perception survey. Results indicated that participants responded differently in each city. In Alexandria, participants showed significant improvement in language skills (e.g., mean length of utterance). In contrast, participants in Aswan showed a significant change in fundamental frequency. Overall, the self-surveys indicated that all participants experienced an increased sense of confidence, a stronger belief in self-authorship, and an increased desire to voice their opinions clearly in public; however, there were subtle differences between the groups. In analyzing these results, we conclude that to design effective vocal empowerment outreach programs internationally, it is necessary to consider participants' cultural backgrounds, language diversity, and socio-economic status.","2021-12-31","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","12","16","","","","","","","","","","English","","","","WOS:000773555700028","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","ENGLISH; FUNDAMENTAL-FREQUENCY; SPEECH PRACTICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CKXLA9SG","journalArticle","2022","Satoer, D; De Witte, E; Bulté, B; Bastiaanse, R; Smits, M; Vincent, A; Mariën, P; Visch-Brink, E","Dutch Diagnostic Instrument for Mild Aphasia (DIMA): standardisation and a first clinical application in two brain tumour patients","CLINICAL LINGUISTICS & PHONETICS","","0269-9206","10.1080/02699206.2021.1992797","","Brain tumour patients with mild language disturbances are typically underdiagnosed due to lack of sensitive tests leading to negative effects in daily communicative and social life. We aim to develop a Dutch standardised test-battery, the Diagnostic Instrument for Mild Aphasia (DIMA) to detect characteristics of mild aphasia at the main linguistic levels phonology, semantics and (morpho-)syntax in production and comprehension. We designed 4 DIMA subtests: 1) repetition (words, non-words, compounds and sentences), 2) semantic odd-picture-out (objects and actions), 3) sentence completion and 4) sentence judgment (accuracy and reaction time). A normative study was carried out in a healthy Dutch-speaking population (N = 211) divided into groups of gender, age and education. Clinical application of DIMA was demonstrated in two brain tumour patients (glioma and meningioma). Standard language tests were also administered: object naming, verbal fluency (category and letter), and Token Test. Performance was at ceiling on all sub-tests, except semantic odd-picture-out actions, with an effect of age and education on most subtests. Clinical application DIMA: repetition was impaired in both cases. Reaction time in the sentence judgment test (phonology and syntax) was impaired (not accuracy) in one patient. Standard language tests: category fluency was impaired in both cases and object naming in one patient. The Token Test was not able to detect language disturbances in both cases. DIMA seems to be sensitive to capture mild aphasic deficits. DIMA is expected to be of great potential for standard assessment of language functions in patients with also other neurological diseases than brain tumours.","2022-11-02","2025-02-26 20:41:52","2025-02-26 20:41:52","","929-953","","11","36","","","","","","","","","","English","","","","WOS:000832483800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","ARCUATE FASCICULUS; AWAKE SURGERY; brain tumour; case illustrations; ELOQUENT AREAS; GLIOMA SURGERY; Mild aphasia; neurological disease; NORMATIVE DATA; SELECTION; SPOKEN LANGUAGE; SPONTANEOUS SPEECH; standardised language test battery; SUPPLEMENTARY MOTOR AREA; VERBS; work-up awake surgery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S45A5KEX","journalArticle","2021","Pépiot, E; Arnold, A","Cross-Gender Differences in English/French Bilingual Speakers: A Multiparametric Study","PERCEPTUAL AND MOTOR SKILLS","","0031-5125","10.1177/0031512520973514","","The present study concerns speech productions of female and male English/French bilingual speakers in both reading and semi-spontaneous speech tasks. We investigated various acoustic parameters: average fundamental sound frequency (F0), F0 range, F0 variance (SD), vowel formants (F1, F2, and F3), voice onset time (VOT) and H1-H2 (intensity difference between the first and the second harmonic frequencies, used to measure phonation type) in both languages. Our results revealed a significant effect of gender and language on all parameters. Overall, average F0 was higher in French while F0 modulation was stronger in English. Regardless of language, female speakers exhibited higher F0 than male speakers. Moreover, the higher average F0 in French was larger in female speakers. On the other hand, the smaller F0 modulation in French was stronger in male speakers. The analysis of vowel formants showed that overall, female speakers exhibited higher values than males. However, we found a significant cross-gender difference on F2 of the back vowel [u:] in English, but not on the vowel [u] in French. VOT of voiceless stops was longer in Female speakers in both languages, with a greater difference in English. VOT contrast between voiceless stops and their voiced counterparts was also significantly longer in female speakers in both languages. The scope of this cross-gender difference was greater in English. H1-H2 was higher in female speakers in both languages, indicating a breathier phonation type. Furthermore, female speakers tended to exhibit smaller H1-H2 in French, while the opposite was true in males. This resulted in a smaller cross-gender difference in French for this parameter. All these data support the idea of language- and gender-specific vocal norms, to which bilingual speakers seem to adapt. This constitutes a further argument to give social factors, such as gender dynamics, more consideration in phonetic studies.","2021-02","2025-02-26 20:41:52","2025-02-26 20:41:52","","153-177","","1","128","","","","","","","","","","English","","","","WOS:000614546700010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","bilingualism; cross-language variation; FEMALE; FUNDAMENTAL-FREQUENCY; SPEECH; speech and gender; speech production; voice and gender; VOICE QUALITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8TRF9358","journalArticle","2024","Das, HC; Bhattacharjee, U","Assamese Dialect Identification Using Static and Dynamic Features from Vowel","JOURNAL OF ADVANCES IN INFORMATION TECHNOLOGY","","1798-2340","10.12720/jait.15.2.306-321","","This paper introduces a novel method for identifying Assamese dialects by analyzing the acoustic and prosodic aspects of vowel sounds in speech signals. The distinctive characteristics of these dialects are captured through the use of acoustic parameters such as formants (F1, F2, and F3), as well as prosodic features like energy, fundamental frequency (F0), and duration. To evaluate this approach, a comprehensive vowel speech corpus is collected from native Assamese speakers representing four different dialectal regions. Frame-level statistical features are extracted from vowel sounds, while temporal dynamic features are obtained from steady-state vowel segments. The data collection process involves using a phonetically rich script to record both read and spontaneous speech interactions from speakers of the four dialects. Various classification methods, including three decision tree-based classifiers, i.e., Random Forest (RF), Extreme Random Forest (ERF), and Extreme Gradient Boosting (XGB), are applied to distinguish the four dialects. The performance of each feature, whether static or dynamic, is individually evaluated. The study reveals that the identification of Assamese dialects is influenced by factors such as speech length, intensity, pitch, and formant frequencies. To assess the significance of these features in distinguishing dialects and to measure their combined impact on the identification system, single-factor Analysis of Variance (ANOVA) tests are conducted. Notably, when static features are combined with the Extreme Random Forest (ERF) ensemble model, the overall accuracy of dialect identification reaches 77%. This research demonstrates the efficacy of using acoustic and prosodic features to accurately classify Assamese dialects, shedding light on the subtle variations within them. In summary, this paper provides a robust framework for Assamese dialect identification and contributes to our understanding of dialect discrimination, paving the way for more advanced dialect identification systems.","2024","2025-02-26 20:41:52","2025-02-26 20:41:52","","306-321","","2","15","","","","","","","","","","English","","","","WOS:001195220900017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","ACCENT; ACOUSTIC DESCRIPTION; assamese dialect identification; CLASSIFICATION; dynamic features; formant frequencies; LANGUAGE IDENTIFICATION; prosodic features; RECOGNITION; statistical features","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7855BPP6","journalArticle","2024","Gupta, S; Parikh, J; Jain, R; Kashi, N; Khurana, P; Mehta, J; Hemanth, J","Dementia detection using parameter optimization for multimodal datasets","INTELLIGENT DECISION TECHNOLOGIES-NETHERLANDS","","1872-4981","10.3233/IDT-230532","","Dementia, a neurodegenerative disorder, is more prominent among elderly people. This disease is one of the primary contributors amongst other diseases having a high social impact in continents of Europe and America. Treatment of the neurological disorders of dementia patients have become possible due to the Advances in medical diagnosis as in the use of Magnetic Resonance Imaging (MRI). Artificial Intelligence (AI) and Machine Learning (ML) techniques have provided solutions that enable fast, accurate and autonomous detection of diseases at their early stage. This in turn has improvised the entire health care system. This study proposes a diagnostic method, based on ML, for detecting dementia disease. The Open Access Series of Imaging Studies (OASIS) database and Alzheimer's dataset (4 class of images) have been used for testing and training of various ML models. This involves the classification of the dependent variable into demented and non-demented patient. ML models as in Support Vector Machine (SVM), Logistic Regression, Naive Bayes, k-nearest neighbor (KNN), Random Forest, Adaptive Boosting (ADA boost), Gradient Boosting, XG Boost, were trained and tested using OASIS dataset. Models were trained with 70% of data and tested on 30% of data. Hyper tuning of parameters of these models was also carried out to check for improvement in the results. Analysis showed that Naive Bayes was the best amongst all giving 95% accuracy, 98% precision, 93% recall and 95% F1-score.","2024","2025-02-26 20:41:52","2025-02-26 20:41:52","","343-369","","1","18","","","","","","","","","","English","","","","WOS:001193416900021","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Dementia; DIAGNOSIS; feature selection; Hyper parameter tuning; Machine learning algorithms; Naive Bayes; OASIS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X9ANUAJB","journalArticle","2024","Puri, DV; Kachare, PH; Sangle, SB; Kirner, R; Jabbari, A; Al-Shourbaji, I; Abdalraheem, M; Alameen, A","LEADNet: Detection of Alzheimer's Disease Using Spatiotemporal EEG Analysis and Low-Complexity CNN","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3435768","","Clinical methods for dementia detection are expensive and prone to human errors. Despite various computer-aided methods using electroencephalography (EEG) signals and artificial intelligence, a reliable detection of Alzheimer's disease (AD) remains a challenge. The existing EEG-based machine learning models have limited performance or high computation complexity. Hence, there is a need for an optimal deep learning model for the detection of AD. This paper proposes a low-complexity EEG-based AD detection CNN called LEADNet to generate disease-specific features. LEADNet employs spatiotemporal EEG signals as input, two convolution layers for feature generation, a max-pooling layer for asymmetric spatiotemporal redundancy reduction, two fully-connected layers for nonlinear feature transformation and selection, and a softmax layer for disease probability prediction. Different quantitative measures are calculated using an open-source AD dataset to compare LEADNet and four pre-trained CNN models. The results show that the lightweight architecture of LEADNet has at least a 150-fold reduction in network parameters and the highest testing accuracy of 99.24% compared to pre-trained models. The investigation of individual layers of LEADNet showed successive improvements in feature transformation and selection for detecting AD subjects. A comparison with the state-of-the-art AD detection models showed that the highest accuracy, sensitivity, and specificity were achieved by the LEADNet model.","2024","2025-02-26 20:41:52","2025-02-26 20:41:52","","113888-113897","","","12","","","","","","","","","","English","","","","WOS:001298698300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Alzheimer's disease; BACKGROUND ACTIVITY; Brain modeling; convolutional neural network; Convolutional neural networks; electroencephalogram; ELECTROENCEPHALOGRAM; Electroencephalography; ENTROPY; Feature extraction; pre-trained models; Training","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CL6PZEML","journalArticle","2024","Shekari, E; Mehrpour, M; Joghataei, MT; Zadeh, AM; Valinejad, V; Adineh, HA; Seyfi, M; Goudarzi, S","Focusing on the locus of the breakdown for treatment of anomia: a pilot study","CLINICAL LINGUISTICS & PHONETICS","","0269-9206","10.1080/02699206.2023.2221374","","The primary goal of this study was to evaluate the treatment effects of semantic feature analysis (SFA) and phonological components analysis (PCA) on word retrieval processing in persons with aphasia (PWAs). After identifying the locus of the breakdown in lexical retrieval processing, 15 monolingual native Persian speakers with aphasia were divided into two groups. After three naming trials, participants with dominant semantic deficits received SFA, and participants with primary phonological deficits were provided with PCA three times a week for eight weeks. Both approaches improved participants' naming and performance on language tests, including spontaneous speech, repetition, comprehension, and semantic processing. However, the correct naming of treated and untreated items was higher in mild-to-moderate participants, with mostly circumlocution and semantic paraphasias in the SFA group. The same holds for mild-to-moderate participants with mostly phonemic paraphasia who received PCA therapy. Moreover, the results showed that participants' baseline naming performance and semantic abilities could be associated with the treatment outcomes. Although limited by a lack of a control group, this study provided evidence supporting the possible benefits of focusing on the locus of the breakdown for treating anomia through SFA and PCA approaches, specifically in participants with mild to moderate aphasia. However, for those with severe aphasia, the treatment choice may not be as straightforward because several variables are likely to contribute to this population's word-finding difficulties. Replication with larger, well-stratified samples, use of a within-subjects alternating treatment design and consideration of treatments' long-term effects are required to better ascertain the effects of focusing on the locus of breakdown for treatment of anomia.","2024-05-03","2025-02-26 20:41:52","2025-02-26 20:41:52","","477-507","","5","38","","","","","","","","","","English","","","","WOS:001003527600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;114</p>","","","ACUTE STROKE; anomia; ANTERIOR TEMPORAL INVOLVEMENT; Aphasia; CASE-SERIES TEST; FLUENT APHASIA; INTERACTIVE 2-STEP MODEL; LEXICAL ACCESS; NAMING DEFICITS; paraphasia; phonological component analysis (PCA); PHONOLOGICAL COMPONENTS-ANALYSIS; RETRIEVAL; SEMANTIC FEATURE ANALYSIS; semantic feature analysis (SFA)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3UMG6V5J","journalArticle","2023","Kallio, H; Kautonen, M; Kuronen, M","Prosody and fluency of Finland Swedish as a second language: Investigating global parameters for automated speaking assessment","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2023.02.003","","This study investigates prosody and fluency of Finland Swedish as a second language (L2). The main objective is to investigate global measures of prosody and fluency as predictors of overall oral proficiency, fluency, and pronunciation ratings. We analyzed parameters related to temporal fluency, timing (based on syllable durations), and f0 change from spontaneous speech produced by 30 native and 235 non-native speakers of Finland Swedish representing pro-ficiency levels from beginner to intermediate. We used pairwise comparisons to investigate the differences be-tween native speech (L1) and L2 samples from different proficiency levels. To study the predictability of ratings with acoustic parameters, we fitted a multiple linear regression model for each assessed dimension of L2 skills. The comparison of L1 and L2 samples as well as L2 samples with different proficiency and fluency levels showed clear differences in f0 change and fluency parameters. Standard deviation of syllable durations also showed differences with respect to L2 learners' fluency level. The results for multiple linear regression models, however, indicate contribution of rate-normalized standard deviation of syllable duration to fluency ratings, alongside traditionally used fluency parameters. As for proficiency ratings, f0 slope complemented fluency pa-rameters in the prediction model. The predictive power of the parameters varied depending on the assessed dimension of L2 skills. This study provides new information on the prosodic features of Finland Swedish as a second language and suggests new research on the assessment of non-dominant varieties of pluricentric languages. The results support previous findings on the importance of speed and pausing measures in predicting oral L2 skills. However, further investigation of language-specific f0 and timing parameters as part of automated or computer-assisted speaking assessment is called for.","2023-03","2025-02-26 20:41:52","2025-02-26 20:41:52","","66-80","","","148","","","","","","","","","","English","","","","WOS:000951437900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;104</p>","","","Finland Swedish; Fluency; JUDGMENTS; LANGUAGE; PROFICIENCY; Prosody; QUANTITY; RHYTHM; SPEECH; Spoken L2 assessment; UTTERANCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L7VEALVW","journalArticle","2024","Wolfberg, J; Whyte, J; Doyle, P; Gherson, S; Muise, J; Petty, B; Tolejano, CJ; Hillman, RE; Stadelman-Cohen, T; Van Stan, JH","Rehabilitation Treatment Specification System for Voice Therapy: Application to Everyday Clinical Care","AMERICAN JOURNAL OF SPEECH-LANGUAGE PATHOLOGY","","1058-0360","10.1044/2023_AJSLP-23-00283","","Purpose: Rehabilitation intervention descriptions often do not explicitly identify active ingredients or how those ingredients lead to changes in patient functioning. The Rehabilitation Treatment Specification System (RTSS) provides guidance to identify the critical aspects of any rehabilitation therapy and supported the development of standardly named ingredients and targets in voice therapy (Rehabilitation Treatment Specification System for Voice Therapy [RTSS-Voice]). This study sought to test the content validity of the RTSS-Voice and determine if the RTSS-Voice can be used to identify commonalities and differences in treatment (criterion validity) across clinicians in everyday clinical practice. Method: Five speech-language pathologists from different institutions videotaped one therapy session for 59 patients diagnosed with a voice or upper airway disorder. Specifications were created for each video, and iterative rounds of revisions were completed with the treating clinician and two RTSS experts until consensus was reached on each specification. Results: All 59 sessions were specified without the addition of any targets or ingredients. There were two frequent targets: (a) increased volition and (b) decreased strained voice quality. There were three frequent ingredients: (a) information regarding the patient's capability and motivation to perform a therapeutic behavior, (b) knowledge of results feedback, and (c) opportunities to practice voicing with improved resonance and mean airflow. Across sessions treating vocal hyperfunction, there was large variability across clinicians regarding the types and number of treatment components introduced, types of feedback provided, and vocal practice within spontaneous speech and negative practice. Conclusions: The RTSS and the RTSS-Voice demonstrated strong content validity, as they comprehensively characterized 59 therapy sessions. They also demonstrated strong criterion validity, as commonalities and differences were identified in everyday voice therapy for vocal hyperfunction across multiple clinicians. Future work to translate RTSS principles and RTSS-Voice terms into clinical documentation can help to understand how clinician and patient variability impacts outcomes and bridge the research-practice gap.","2024-03","2025-02-26 20:41:52","2025-02-26 20:41:52","","814-830","","2","33","","","","","","","","","","English","","","","WOS:001290206600020","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","BLACK-BOX; CONSENSUS; DISORDERS; EFFICACY; IMPLEMENTATION; KNOWLEDGE; PREVALENCE; QUALITY; TAXONOMY V1; VOCAL FUNCTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HTEY8E8B","journalArticle","2024","Espejo, JMR; De Maeyer, S; Gillis, S","Everything, altogether, all at once: Addressing data challenges when measuring speech intelligibility through entropy scores","BEHAVIOR RESEARCH METHODS","","1554-351X","10.3758/s13428-024-02457-6","","When investigating unobservable, complex traits, data collection and aggregation processes can introduce distinctive features to the data such as boundedness, measurement error, clustering, outliers, and heteroscedasticity. Failure to collectively address these features can result in statistical challenges that prevent the investigation of hypotheses regarding these traits. This study aimed to demonstrate the efficacy of the Bayesian beta-proportion generalized linear latent and mixed model (beta-proportion GLLAMM) (Rabe-Hesketh et al., Psychometrika, 69(2), 167-90, 2004a, Journal of Econometrics, 128(2), 301-23, 2004c, 2004b; Skrondal and Rabe-Hesketh 2004) in handling data features when exploring research hypotheses concerning speech intelligibility. To achieve this objective, the study reexamined data from transcriptions of spontaneous speech samples initially collected by Boonen et al. (Journal of Child Language, 50(1), 78-103, 2023). The data were aggregated into entropy scores. The research compared the prediction accuracy of the beta-proportion GLLAMM with the normal linear mixed model (LMM) (Holmes et al., 2019) and investigated its capacity to estimate a latent intelligibility from entropy scores. The study also illustrated how hypotheses concerning the impact of speaker-related factors on intelligibility can be explored with the proposed model. The beta-proportion GLLAMM was not free of challenges; its implementation required formulating assumptions about the data-generating process and knowledge of probabilistic programming languages, both central to Bayesian methods. Nevertheless, results indicated the superiority of the model in predicting empirical phenomena over the normal LMM, and its ability to quantify a latent potential intelligibility. Additionally, the proposed model facilitated the exploration of hypotheses concerning speaker-related factors and intelligibility. Ultimately, this research has implications for researchers and data analysts interested in quantitatively measuring intricate, unobservable constructs while accurately predicting the empirical phenomena.","2024-10","2025-02-26 20:41:52","2025-02-26 20:41:52","","8132-8154","","7","56","","","","","","","","","","English","","","","WOS:001275438800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;87</p>","","","Bayesian analysis; Bounded outcomes; Clustering; DEAF-CHILDREN; Generalized linear latent and mixed models; Heteroscedasticity; IMPACT; INFORMATION; Measurement error; MODEL; Outliers; REGRESSION; Robust regression models; SINGLE-WORD; Speech intelligibility; VARIABLES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6KZX7MP4","journalArticle","2023","Jiang, XY; Zhang, F; Yan, RX; Chen, L","Preferred argument structure in the oral narratives of adolescents with and without SLI","CLINICAL LINGUISTICS & PHONETICS","","0269-9206","10.1080/02699206.2022.2138783","","According to the theory of 'Preferred Argument Structure' (PAS), the realisation and distribution of core arguments including the subject of a transitive verb (A), the direct object of a transitive verb (O) or the subject of an intransitive verb (S) in spoken discourse are subject to both grammatical and pragmatic constraints. However, previous studies on the formulation of argument structure have largely focused on the syntactic difficulties of children with SLI. In addition, little is known about the developmental outcomes in argument structure for adolescents with SLI. In this study, we compared PAS in the narratives of 19 adolescents with SLI (Mean age = 14.3; SD = 0.64) and 19 adolescents with typical language development (TLD; Mean age = 14.5; SD = 0.84). The core arguments of the predicate in each narrative based on the wordless picture storybook 'Frog, where are you?' were coded for grammatical roles (A, O and S), referential forms (lexical forms and non-lexical form including null and pronominal forms) and information status (given, accessible and new information). The data were then analysed for conformity to the grammatical and pragmatic constraints of the PAS theory. The two groups were found to be similar in their conformity to the pragmatic constraints but differed in how they conform to the syntactic constraints. In particular, the adolescents with SLI were more likely to produce clauses with two lexical arguments, and the lexical arguments occurred significantly more frequently at the subject role of a transitive verb than the TLD groups. Our results provide further evidence that it is a persistent grammatical deficit, rather than a pragmatic deficit, which poses a special challenge for adolescents with SLI in their formulation of argument structure in narratives.","2023-06-03","2025-02-26 20:41:52","2025-02-26 20:41:52","","513-529","","4-6","37","","","","","","","","","","English","","","","WOS:000879632500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","adolescents; AGE; CHILDREN; DELAY; DISCOURSE; DLD; FOLLOW-UP; HISTORY; LANGUAGE IMPAIRMENT; oral narratives; pragmatic constraints; preferred argument structure; REALIZATION; SLI; SPONTANEOUS SPEECH; syntactic constraints","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2G3IG4KH","journalArticle","2023","Odijk, L; Gillis, S","Children steer the inflectional diversity of their parents: The role of word births and growing vocabulary","FIRST LANGUAGE","","0142-7237","10.1177/01427237231171763","","The inflectional diversity of parents' speech directed to children acquiring Dutch was investigated. Inflectional diversity is defined as the number of inflected forms of a particular lemma (e.g. singular, plural of a noun) and measured by means of Mean Size of Paradigm (MSP). Changes in the inflectional diversity of infant directed speech (IDS) were analyzed as a function of children's developing linguistic abilities. Two types of changes in the inflectional diversity of nouns and verbs were analyzed: (1) coarse tuning: changes relative to children's growing vocabulary and (2) fine lexical tuning: changes relative to children's use of specific lexical items. In addition, it was investigated if those changes were similar depending on particular characteristics of the children, namely, differences in their hearing abilities. Longitudinal recordings of spontaneous speech of 30 children (0;6-2;0) with normal hearing (NH) and 10 hearing-impaired children with a cochlear implant (CI) (0;6-2;6), and their parents were analyzed. As to coarse tuning, it was found that the inflectional diversity of IDS decreased at the beginning of the child's lexical development but increased again parallel to infants' growing cumulative vocabulary. As to fine lexical tuning, IDS showed less inflectional diversity before each child's first use of a word and gradually more inflectional diversity afterward. In addition, parents of children with CI used less inflectionally diverse speech than parents of children with NH, which suggests an adaptation to specific characteristics of the children. In conclusion, inflectional morphology in IDS appears to be tuned to children's hearing status and linguistic knowledge.","2023-10","2025-02-26 20:41:52","2025-02-26 20:41:52","","539-565","","5","43","","","","","","","","","","English","","","","WOS:001001630400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;91</p>","","","AGE; cochlear implant; COCHLEAR IMPLANTATION; DIMINUTIVES; Infant-directed speech; INFANT-DIRECTED SPEECH; inflectional diversity; language development; mean size of paradigm; MORPHOLOGY; MOTHERS SPEECH; SEGMENTATION; SPOKEN LANGUAGE-DEVELOPMENT; VARIABILITY; word acquisition; YOUNG-CHILDREN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UX6SJBYE","journalArticle","2024","Oh, TK; Song, IA","Impact of prescribed opioid use on development of dementia among patients with chronic non-cancer pain","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-53728-3","","We aimed to examine the association between opioid use and the development of dementia in patients with chronic non-cancer pain in South Korea. Data were extracted from the National Health Insurance Service database in South Korea. Adult patients diagnosed with musculoskeletal diseases with chronic non-cancer pain between 2010 and 2015 were included in the analysis. Patients who were prescribed opioids regularly and continuously for >= 90 days were classified as opioid users. In total, 1,261,682 patients with chronic non-cancer pain were included in the final analysis, of whom 21,800 (1.7%) were opioid users. From January 1, 2016 to December 31, 2020, 35,239 (2.8%) patients with chronic non-cancer pain were newly diagnosed with dementia. In the multivariable model, opioid users showed a 15% higher risk of developing dementia than the control group. Additionally, opioid users showed a 15% and 16% higher risk of developing Alzheimer's disease and unspecified dementia, respectively, than the control group, but did not show any significant differences for vascular dementia. Among adult patients with chronic non-cancer pain, opioid users were at a higher risk of developing dementia than the control group; the risk was significantly higher for Alzheimer's disease but not for vascular dementia in this study. Our results suggest that in patients with CNCP, public health strategies should target opioid users for early dementia detection and intervention.","2024-02-09","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","1","14","","","","","","","","","","English","","","","WOS:001159192500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Analgesics; Dementia; DISORDERS; FATTY LIVER-DISEASE; GUIDELINES; MANAGEMENT; MEMORY; Opioid; Pain; PREVALENCE; REGION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2ACHIP9H","journalArticle","2023","Saccone, V; Trillocco, S; Moneglia, M","Markers of schizophrenia at the prosody/pragmatics interface. Evidence from corpora of spontaneous speech interactions","FRONTIERS IN PSYCHOLOGY","","1664-1078","10.3389/fpsyg.2023.1233176","","The speech of individuals with schizophrenia exhibits atypical prosody and pragmatic dysfunctions, producing monotony. The paper presents the outcomes of corpus-based research on the prosodic features of the pathology as they manifest in real-life spontaneous interactions. The research relies on a corpus of schizophrenic speech recorded during psychiatric interviews (CIPPS) compared to a sampling of non-pathological speech derived from the LABLITA corpus of spoken Italian, which has been selected according to comparability requirements. Corpora has been intensively analyzed in the Language into Act Theory (L-AcT) frame, which links prosodic cues and pragmatic values. A cluster of linguistic parameters marked by prosody has been considered: utterance boundaries, information structure, speech disfluency, and prosodic prominence. The speech flow of patients turns out to be organized into small chunks of information that are shorter and scarcely structured, with an atypical proportion of post-nuclear information units (Appendix). It is pervasively scattered with silences, especially with long pauses between utterances and long silences at turn-taking. Fluency is hindered by retracing phenomena that characterize complex information structures. The acoustic parameters that give rise to prosodic prominence (f0 mean, f0 standard deviation, spectral emphasis, and intensity variation) have been measured considering the pragmatic roles of the prosodic units, distinguishing prominences within the illocutionary units (Comment) from those characterizing Topic units. Patients show a flattening of the Comment-prominence, reflecting impairments in performing the illocutionary activity. Reduced values of spectral emphasis and intensity variation also suggest a lack of engagement in communication. Conversely, Topic-prominence shows higher values for f0 standard deviation and spectral emphasis, suggesting effort when defining the domain of relevance of the illocutionary force. When comparing Topic and Comment-prominences of patients, the former consistently exhibit higher values across all parameters. In contrast, the non-pathological group displays the opposite pattern.","2023-10-12","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","14","","","","","","","","","","English","","","","WOS:001087550400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;78</p>","","","ABNORMALITIES; DEFINITION; disfluency; information structure; LANGUAGE; PAUSES; prominence; prosodic-pragmatic correlates; schizophrenic speech; THOUGHT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"258ZUZZ5","journalArticle","2021","Walsh, B; Christ, S; Weber, C","Exploring Relationships Among Risk Factors for Persistence in Early Childhood Stuttering","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2021_JSLHR-21-00034","","Purpose: The purpose of this study is to investigate how epidemiological and clinical factors collectively predict whether a preschooler who is stuttering will persist or recover and to provide guidance on how clinicians can use these factors to evaluate a child's risk for stuttering persistence. Method: We collected epidemiological and clinical measures from 52 preschoolers (M = 54.4 months, SD = 6.7 months; 38 boys and 14 girls) diagnosed as stuttering. We then followed these children longitudinally to document whether they eventually recovered or persisted in stuttering. Risk factors found to be significantly associated with stuttering persistence were used to build single and multiple variable predictive statistical models. Finally, we assessed each model's prediction capabilities by recording how accurate a model was in predicting a child's stuttering outcome- persisting or recovered. Results: We found that a positive family history of stuttering, poorer performance on a standardized articulation/phonological assessment, higher frequency of stuttering-like disfluencies during spontaneous speech, and lower accuracy on a nonword repetition task were all significantly associated with an increased probability of persistence. The interaction between family history of stuttering and nonword repetition performance was also significant. The full multiple regression model incorporating all these risk factors resulted in the best fitting model with the highest predictive accuracy and lowest error rate. Conclusions: For the first time, we show how multiple risk factors collectively predict the probability of stuttering persistence in 3-to 5-year-old preschool children who stutter. Using the full combination of risk factors to assess preschoolers who stutter yielded more accurate predictions of persistence compared to sparser models. A better understanding of the factors that underlie stuttering persistence will yield insight into the underpinnings of chronic stuttering and will help identify etiological targets for novel treatment approaches.","2021-08","2025-02-26 20:41:52","2025-02-26 20:41:52","","2909-2927","","8","64","","","","","","","","","","English","","","","WOS:000684551200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;21<br/>Total Times Cited:&nbsp;&nbsp;26<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","ARTICULATION; IMPACT; NONWORD REPETITION ABILITIES; PATHWAYS; PRESCHOOL-CHILDREN; RECOVERY; SPEECH; TEMPERAMENT; VARIABILITY; YOUNG-CHILDREN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SDIJ79W7","journalArticle","2024","Gu, JY; Long, W; Zeng, SQ; Li, CJ; Fang, CN; Zhang, XY","Neurologic music therapy for non-fluent aphasia: a systematic review and meta-analysis of randomized controlled trials","FRONTIERS IN NEUROLOGY","","1664-2295","10.3389/fneur.2024.1395312","","Introduction: The efficacy of neurologic music therapy (NMT) techniques for the treatment of non-fluent aphasia has been widely accepted by the rehabilitation medical community. However, consensus on which dimensions of speech function can be improved by NMT techniques and standardized intervention dosage remains elusive. This study aimed to provide evidence regarding the efficacy of NMT in improving speech function and explore the optimal intervention dose. A systematic review and meta-analysis were conducted to search for randomized clinical trials and open-label trials that evaluated speech functions after NMT. Methods: We searched all papers and reviews published from database inception to July 2023, including PubMed, Cochrane Library, Web of Science, Embase, and CNKI. Statistical analyses were mainly carried out on RevManV5.4.1 and pooled using a random-effects model. The primary outcome was the standardized mean difference (SMD) in speech functions, determined by calculating the change in speech functions score from baseline to the primary endpoint in the NMT group versus the control arm. Results: A total of 11 studies with 329 patients were included. NMT had a positive effect on repetition ability (SMD = 0.37, 95%CI [0.12, 0.62], p < 0.05), but did not lead to significant differences in naming, comprehension, spontaneous speech, or communication. When the intervention time was >20 h, NMT exhibited a significant advantage at improving repetition ability (SMD = 0.43, 95%CI [0.06, 0.79], p < 0.05). Discussion: This study provides evidence supporting the NMT enhancement of repetition ability in patients with non-fluent aphasia. Future large-sample studies are required to determine the optimal intervention dose of music therapy for different subtypes of non-fluent aphasia. Systematic review registration: PROSPERO, identifier CRD42023470313.","2024-05-23","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","15","","","","","","","","","","English","","","","WOS:001242999800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","aphasia; MELODIC INTONATION THERAPY; meta-analysis; neurologic music therapy; speech function; STROKE; systematic review","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7WCYFERS","journalArticle","2024","Lee, JY; Lee, SY","Development of an AI-Based Predictive Algorithm for Early Diagnosis of High-Risk Dementia Groups among the Elderly: Utilizing Health Lifelog Data","HEALTHCARE","","2227-9032","10.3390/healthcare12181872","","Background/Objectives: This study aimed to develop a predictive algorithm for the early diagnosis of dementia in the high-risk group of older adults using artificial intelligence technologies. The objective is to create an accessible diagnostic method that does not rely on traditional medical equipment, thereby improving the early detection and management of dementia. Methods: Lifelog data from wearable devices targeting this high-risk group were collected from the AI Hub platform. Various indicators from these data were analyzed to develop a dementia diagnostic model. Machine learning techniques such as Logistic Regression, Random Forest, LightGBM, and Support Vector Machine were employed. Data augmentation techniques were applied to address data imbalance, thereby enhancing the model performance. Results: Data augmentation significantly improved the model's accuracy in classifying dementia cases. Specifically, in gait data, the SVM model performed with an accuracy of 0.879. In sleep data, a Logistic Regression was performed, yielding an accuracy of 0.818. This indicates that the lifelog data can effectively contribute to the early diagnosis of dementia, providing a practical solution that can be easily integrated into healthcare systems. Conclusions: This study demonstrates that lifelog data, which are easily collected in daily life, can significantly enhance the accessibility and efficiency of dementia diagnosis, aiding in the effective use of medical resources and potentially delaying disease progression.","2024-09","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","18","12","","","","","","","","","","English","","","","WOS:001323940100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","ALZHEIMERS-DISEASE; artificial intelligence; BURDEN; early dementia detection; lifelog data; machine learning; wearable devices","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PLCWJJBI","journalArticle","2023","White, MJ; Southwood, F; Huddlestone, K","Children's acquisition of negation in L1 Afrikaans","FIRST LANGUAGE","","0142-7237","10.1177/01427237221112064","","Afrikaans is a West Germanic language that originated in South Africa as a descendent of Dutch. It displays discontinuous sentential negation (SN), where negation is expressed by two phonologically identical negative particles that appear in two different positions in the sentence. The negation system is argued to be an innovation that came about through the reanalysis of a discourse-dependent (pragmatically conditioned) structure in Dutch, reinforced by proponents of the standardisation of Afrikaans who prescriptively imposed a negative concord structure onto the Dutch negation system. The Afrikaans negation system is therefore argued to be artificially created, making it crosslinguistically rare and syntactically complex, the latter possibly having a delaying effect on acquisition. This study investigates both the comprehension and production of negation by young child speakers of Afrikaans. Sentences containing negative indefinites (NIs) (niks 'nothing' and geen 'no'/ 'none' with a final negative particle) are compared with those containing two negative particles (referred to as SN), which are syntactically less complex. We examined (1) whether the comprehension of sentences with NIs is more difficult to acquire than that of sentences using SN and (2) when and how negation is produced by young children. Data were collected through a picture selection task (comprehension) and recordings of spontaneous speech during free play (production). Results show that the comprehension of SN was acquired before that of NI, indicating that sentences containing NIs were indeed more difficult to comprehend than those containing SN. The production data showed that even the youngest participants (age 3;0) could produce grammatically well-formed negated constructions, but that errors occurred until age 4;3. In comparison with that found for other West Germanic languages, Afrikaans' complex system of expressing negation seems to have a delaying effect on the comprehension of negation, specifically NIs, but not on production.","2023-02","2025-02-26 20:41:52","2025-02-26 20:41:52","","22-57","","1","43","","","","","","","","","","English","","","","WOS:000834557400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Afrikaans; comprehension; COMPREHENSION; language acquisition; negative indefinites; production; sentential negation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N6VDV2M2","journalArticle","2021","Chen, QM; Shen, WJ; Sun, HW; Shen, D; Cai, XY; Ke, J; Zhang, LC; Fang, Q","Effects of mirror therapy on motor aphasia after acute cerebral infarction: A randomized controlled trial","NEUROREHABILITATION","","1053-8135","10.3233/NRE-210125","","BACKGROUND: Mirror therapy (MT) has proven to be beneficial for treating patients suffering from motor aphasia after stroke. However, the impacts of MT on neuroplasticity remain unexplored. OBJECTIVE: In this paper we conducted a randomized controlled trial to evaluate the treatment using the MT on motor aphasia following acute cerebral infarction. METHODS: We randomly assigned 30 patients into test and control groups, with test group patients treated with MT, whereas control group patients were treated with sham MT. At 24 hours prior to and after the intervention, we obtained functional magnetic resonance imaging (fMRI) data from study subjects. At baseline, after treatment and 12-week follow-up, we additionally evaluated patients with the Modified Rankin Scale (mRS), the National Institutes of Health Stroke Scale (NIHSS), and the aphasia quotient (AQ) in the western aphasia test. RESULTS: After 2 weeks of treatment, the test group demonstrated significant improvements in AQ values, naming, repetition, spontaneous speech, and mRS scores compared to the control group (P < 0.05). Furthermore, in the follow-up time point (12 weeks), we found that the test group exhibited significantly better NIHSS scores and AQ evaluation indicators than the control group (P < 0.05). Specifically, the fMRI study shows that functional connectivity significantly improved in test group patients mainly among frontal, temporal, and parietal lobes of the left hemisphere with each other than controls group. Meanwhile, we found significantly enhanced functional connectivity with the hippocampus (P < 0.01). CONCLUSIONS: Our results indicate that the MT can expedite the recovery of language function during the early phases of stroke recovery. These findings may elucidate the underlying mechanism of MT and the application of this therapy as an adjunct rehabilitation technique in language recovery.","2021","2025-02-26 20:41:52","2025-02-26 20:41:52","","103-117","","1","49","","","","","","","","","","English","","","","WOS:000687053200010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","acute cerebral infarction; functional magnetic resonance imaging; LANGUAGE RECOVERY; Mirror therapy; motor aphasia; neural mechanism; NEURON THEORY; rehabilitation; REHABILITATION; SPEECH; SUCCESS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LC77LCEE","journalArticle","2023","Tribushinina, E; Mackaaij, M","Bilingual advantages in foreign language learning: evidence from primary-school pupils with developmental language disorder","FRONTIERS IN EDUCATION","","2504-284X","10.3389/feduc.2023.1264120","","IntroductionOne of the bilingual advantages often reported in the literature on typically-developing children involves advantages in foreign language learning at school. However, it is unknown whether similar advantages hold for bilingual pupils with learning disabilities. In this study, we compare the performance of monolingual and bilingual primary-school children with developmental language disorder (DLD) learning English as a school subject in special education schools in the Netherlands.MethodsThe participants were monolingual (N = 49) and bilingual (N = 22) children with DLD attending Grade 4-6 of special education (age 9-12). The bilingual participants spoke a variety of home languages. The English tests included a vocabulary task, a grammar test and a grammaticality judgement task. The Litmus Sentence Repetition Task and the Peabody Picture Vocabulary Test were used as measures of, respectively, grammatical ability and vocabulary size in Dutch (majority/school language). In addition, samples of semi-spontaneous speech were elicited in both English and Dutch using the Multilingual Assessment Instrument for Narratives. The narratives were analysed for fluency, grammatical accuracy, lexical diversity, and syntactic complexity. A questionnaire was used to measure amount of exposure to English outside of the classroom.Results and discussionThe results for Dutch revealed no differences between monolinguals and bilinguals on the narrative measures, but monolinguals performed significantly better on both vocabulary and grammar. In contrast, bilinguals outperformed monolinguals on all English measures, except grammatical accuracy of narratives. However, some of the differences became non-significant once we controlled for amount of out-of-school exposure to English. This is the first study to demonstrate that foreign language learning advantages extend to bilingual children with DLD. The results also underline the need to control for differences in out-of-school exposure to English when comparing bilingual and monolingual pupils on foreign language outcomes.","2023-12-05","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","8","","","","","","","","","","English","","","","WOS:001126937900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;139</p>","","","ACQUISITION; bilingual children; CHILDREN; developmental language disorder; ENGLISH; English as a foreign language; IMPAIRMENT; L1; METALINGUISTIC AWARENESS; MINORITY; out-of-school exposure; PROFICIENCY; SKILLS; special education; WORKING-MEMORY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UAAALQ55","journalArticle","2022","Zhang, H; Hinzen, W","Grammar in 'agrammatical' aphasia: What's intact?","PLOS ONE","","1932-6203","10.1371/journal.pone.0278676","","BackgroundAphasia following cerebro-vascular accidents has been a primary source of insight for models of language in the brain. However, deviant language patterns in aphasia may reflect processing limitations and cognitive impairment more than language impairment per se. AimsWe sought to obtain new evidence from spontaneous speech in Broca's aphasia (BA) for the intactness of grammatical knowledge, operationalized as the preservation of the basic hierarchical structure of syntactic projections. Methods & proceduresSpeech obtained with the AphasiaBank protocol from 20 people with BA, which were independently rated as also being agrammatic, was analyzed and compared to 20 matched non-brain-damaged controls. We quantified (i) marking of Aspect, Tense, and Modality (A-T-M), which are located at specific (high) layers of the syntactic hierarchy and ordered in relation to one another ([M horizontal ellipsis [T horizontal ellipsis [A horizontal ellipsis ]]]); (ii) hierarchies of clausal units ([C horizontal ellipsis [C]]); (iii) discourse markers embedding clauses, located at the highest layer of the hierarchy; and (iv) attachment of adjuncts at different heights of a given hierarchical syntactic structure. Supplementary evidence was obtained from a typology of errors and from pauses subcategorized according to their hierarchical syntactic position. Outcomes & resultsGroups did not quantitatively differ on rates of either Aspect or Modality but underproduced T and embedded clauses. Evidence for compensatory effects was seen in both of the latter two cases. While all adjunct types were underproduced in BA, and pauses overproduced, both showed the same relative proportions within both groups. Errors were largely restricted to omissions, of a kind that would also be expected in condensed neurotypical speech. ConclusionsOverall, these patterns support the hypothesis of intactness of grammatical knowledge in BA clinically rated as agrammatic, questioning it as a disease model of language impairment.","2022-12-06","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","12","17","","","","","","","","","","English","","","","WOS:000925001500029","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;78</p>","","","AGREEMENT; COMPREHENSION DEFICITS; DIRECT SPEECH; LANGUAGE; MORPHOLOGY; QUANTITATIVE-ANALYSIS; SENSITIVITY; SENTENCE PRODUCTION; TENSE; WORD ORDER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NV7IHNR8","journalArticle","2024","Magne, V","Replication research in the domain of perceived L2 fluency: Approximate and close replications of Kormos and Dénes (2004) and Rossiter (2009)","LANGUAGE TEACHING","","0261-4448","10.1017/S0261444824000120","","The primary objective of this paper is to contribute to the advancement of second language (L2) fluency research by outlining a specific proposal for future replication studies. The overarching goal is to assess the generalisability of the original findings of the two influential studies in the area of perceived fluency: Kormos and D & eacute;nes (2004) and Rossiter (2009). This objective will be achieved by first introducing the concept of L2 fluency that often conflates two categories: (1) overall language proficiency; (2) temporal features of speech production. The paper then highlights limitations in the current fluency research paradigm emphasising the variability in the methods employed for speech analysis and rating data collection. This diversity makes it somewhat challenging to compare results across various studies. In response to these challenges, the second part of the paper proposes several close and approximate replications of the two studies.","2024-05-10","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","","","","","","","","","","","English","","","","WOS:001222167500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","2ND-LANGUAGE FLUENCY; PERCEPTIONS; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8MWQJXQ7","journalArticle","2024","Clarke, A; Tyler, LK; Marslen-Wilson, W","Hearing what is being said: the distributed neural substrate for early speech interpretation","LANGUAGE COGNITION AND NEUROSCIENCE","","2327-3798","10.1080/23273798.2024.2345308","","Speech comprehension is remarkable for the immediacy with which the listener hears what is being said. Here, we focus on the neural underpinnings of this process in isolated spoken words. We analysed source-localised MEG data for nouns using Representational Similarity Analysis to probe the spatiotemporal coordinates of phonology, lexical form, and the semantics of emerging word candidates. Phonological model fit was detectable within 40-50 ms, engaging a bilateral network including superior and middle temporal cortex and extending into anterior temporal and inferior parietal regions. Lexical form emerged within 60-70 ms, and model fit to semantics from 100-110 ms. Strikingly, the majority of vertices in a central core showed model fit to all three dimensions, consistent with a distributed neural substrate for early speech analysis. The early interpretation of speech seems to be conducted in a unified integrative representational space, in conflict with conventional views of a linguistically stratified representational hierarchy.","2024-10-20","2025-02-26 20:41:52","2025-02-26 20:41:52","","1097-1116","","9","39","","","","","","","","","","English","","","","WOS:001209161200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","Cohort; COMPETITION; CORTICAL DYNAMICS; FEATURES; GEOMETRY; MEG; PARALLEL; PERCEPTION; PHONEME; REPRESENTATION; RESPONSES; RSA; speech; WORD RECOGNITION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"53LNRXDY","journalArticle","2023","Li, XF; Shi, XH; Hu, DS; Li, YW; Zhang, QC; Wang, ZX; Unoki, M; Akagi, M","Music Theory-Inspired Acoustic Representation for Speech Emotion Recognition","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2023.3289312","","This research presents a music theory-inspired acoustic representation (hereafter, MTAR) to address improved speech emotion recognition. The recognition of emotion in speech and music is developed in parallel, yet a relatively limited understanding of MTAR for interpreting speech emotions is involved. In the present study, we use music theory to study representative acoustics associated with emotion in speech from vocal emotion expressions and auditory emotion perception domains. In experiments assessing the role and effectiveness of the proposed representation in classifying discrete emotion categories and predicting continuous emotion dimensions, it shows promising performance compared with extensively used features for emotion recognition based on the spectrogram, Mel-spectrogram, Mel-frequency cepstral coefficients, VGGish, and the large baseline feature sets of the INTERSPEECH challenges. This proposal opens up a novel research avenue in developing a computational acoustic representation of speech emotion via music theory.","2023","2025-02-26 20:41:52","2025-02-26 20:41:52","","2534-2547","","","31","","","","","","","","","","English","","","","WOS:001025466100003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;159</p>","","","acoustic representation; Affective computing; COGNITION; EXPRESSION; FEATURES; INTERVALS; KNOWLEDGE; MODALITIES; music theory and speech analysis; PATTERNS; PERCEPTION; PERSPECTIVE; PITCH; speech emotion recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4TREGAFF","journalArticle","2023","Richardson, T","Body-worn cameras as a research tool in early years settings: Strengths and weaknesses","JOURNAL OF EARLY CHILDHOOD RESEARCH","","1476-718X","10.1177/1476718X221136472","","This paper discusses the innovative research method of using body-worn cameras for capturing speech and experiences of 3- to 5-year olds in English early years settings. The strengths and weaknesses will be discussed in this multiple case study approach to capturing the quality of speech from young children (n = 43). Adopting an interactionist theoretical framework and viewing the project through an interpretive paradigm, it is asserted there is the necessity to capture data in a way that is naturalistic and ethical at all times. It is argued that that in order to gain a full and deep understanding of young children's lives, the use of body-worn cameras is pivotal in gaining the data that may not exist otherwise. It is therefore argued throughout this paper that although both strengths and weaknesses exist that weaknesses should be overcome and accommodated in order to enhance future research.","2023-03","2025-02-26 20:41:52","2025-02-26 20:41:52","","106-118","","1","21","","","","","","","","","","English","","","","WOS:000890158400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","body-worn cameras; CHILDREN; early childhood; innovative research methods; PLAY; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HSR5VCHT","journalArticle","2021","Sönmez, P; Eris, ÖÜ","Securitisation of Migration Revisited: European Union Policies Through the Lens of Syrian Refugees Living in Turkey","SIYASAL-JOURNAL OF POLITICAL SCIENCES","","2618-6330","10.26650/siyasal.2021.30.899160","","The main aim of this study is to present migration as a 'constructed' societal insecurity threat that became substantial after the Cold War before peaking in 2015. This study applies securitization theory to the ongoing refugee crisis through in-depth interviews with a sample of Syrian settlers in Turkey to determine whether their reasons for choosing to stay in Turkey are linked to their perceptions of cultural insecurity in Europe. The interviews were made in November and December 2019 in Gaziantep, Antakya and Istanbul where most of the Syrian refugees are located. In that sense, the link between the securitisation theory and the interviews made in Turkey attempts to shed light on the awareness of Syrian refugees regarding the fact that the European Union (EU) has tried to create a culturally homogenous society and any kind of difference interfering in this homogeneity can be seen as a threat.","2021","2025-02-26 20:41:52","2025-02-26 20:41:52","","225-241","","2","30","","","","","","","","","","English","","","","WOS:000716425000003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","European Union; populist parties; securitisation of migration; SECURITIZATION; speech analysis; Syrian refugees","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TFWVSSQ8","journalArticle","2022","Rodríguez, DAM","The Securitization of the Covid-19 Pandemic at the Organization of American States","REVISTA DE ESTUDIOS EN SEGURIDAD INTERNACIONAL-RESI","","2444-6157","10.18847/1.16.10","","The current paper is aimed to contribute to the International Relation ' s research agenda related with international security ' s studies linked to health. It analyzes the incorporation process of covid-19 pandemic in the Organization of American States ' security agenda, as an international health crisis, using the securitization theory and through the speech analysis. Likewise, it was used descriptive and analytic generalization methods to support the interpretation of the data obtained. As results, it was possible to confirm that, since the establishment of multidimensional security ' s concept in 2003 by the OAS, the incorporation of issues related to health at the hemispheric security agenda is increasingly frequent, being HIV/aids the first precedent. In addition, the covid-19 pandemic is positioned as a new paradigmatic example in international security studies and, therefore, as a clear antecedent for the analysis of future similar phenomena resulting from health crisis.","2022","2025-02-26 20:41:52","2025-02-26 20:41:52","","169-187","","2","8","","","","","","","","","","English","","","","WOS:000920674400010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","GLOBAL HEALTH; health; hemispheric security; intergovernmental organization; international politics; pandemics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SHD6MXNF","journalArticle","2024","Pérez-Córdoba, JL; Alías-Pujol, F; Callejas, Z","Special Issue on IberSPEECH 2022: Speech and Language Technologies for Iberian Languages","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14114505","","ThisSpecial Issue presents the latest advances in research and novel applications of speech and language technologies based on the works presented at the sixth edition of the IberSPEECH conference held in Granada in 2022, paying special attention to those focused on Iberian languages. IberSPEECH is the international conference of the Special Interest Group on Iberian Languages (SIG-IL) of the International Speech Communication Association (ISCA) and the Spanish Thematic Network on Speech Technologies (Red Tem & aacute;tica en Tecnolog & iacute;as del Habla, or RTTH for short). Several researchers were invited to extend the contributions presented at IberSPEECH2022 due to their interest and quality. As a result, the Special Issue is composed of 11 papers that cover different research topics related to speech perception, speech analysis and enhancement, speaker verification and identification, speech production and synthesis, natural language processing, together with several applications and evaluation challenges.","2024-06","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","11","14","","","","","","","","","","English","","","","WOS:001246892000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;8</p>","","","audiovisual database; deep learning; evaluation challenge; Iberianlanguages; natural language processing; neural networks; semantic representations; speaker identification; speech enhancement; speech production; speech recognition; speech synthesis; summarization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2V8NUJ7P","journalArticle","2025","Li, ZY; Chen, BB; Zhu, N; Li, WJ; Liu, TM; Guo, L; Han, JW; Zhang, T; Yan, ZQ","Epileptic Seizure Detection in SEEG Signals Using a Signal Embedding Temporal-Spatial-Spectral Transformer Model","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2025.3527489","","High-performance methods for automated detection of epileptic stereo-electroencephalography (SEEG) have important clinical research implications, improving the diagnostic efficiency and reducing physician burden. However, few studies have been able to consider the process of seizure propagation, thus failing to fully capture the deep representations and variations in SEEG in the temporal, spatial, and spectral domains. In this article, we construct a novel long-term SEEG seizure dataset (XJSZ dataset) and propose signal embedding temporal-spatial-spectral transformer (SE-TSS-Transformer) framework. First, we design signal embedding (SE) module to reduce feature dimensions and adaptively construct optimal representation for subsequent analysis. Second, we integrate unified multiscale temporal-spatial-spectral (TSS) analysis to capture multilevel, multidomain deep features. Finally, we use the transformer encoder to learn the global relevance of features, enhancing the network's ability to express SEEG features. Experimental results demonstrate state-of-the-art detection performance on the XJSZ dataset, achieving sensitivity, specificity, and accuracy of 99.03%, 99.34%, and 99.03%, respectively. Furthermore, we validate the scalability of the proposed framework on two public datasets of different signal sources, demonstrating the power of the SE-TSS-Transformer framework for capturing diverse multiscale TSS patterns in seizure detection.","2025","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","74","","","","","","","","","","English","","","","WOS:001400258200006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Brain modeling; CLASSIFICATION; Convolution; CONVOLUTIONAL NEURAL-NETWORKS; EEG SIGNALS; Electrodes; Electroencephalography; Epilepsy; Epileptic seizure detection; Feature extraction; Hospitals; multiscale analyse; Neurosurgery; Scalability; stereo-electroencephalography (SEEG); transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IV23HTWQ","journalArticle","2025","Masuda, N; Ono, K; Tawara, D; Matsuura, Y; Sakabe, K","Data-Efficient Bone Segmentation Using Feature Pyramid- Based SegFormer","SENSORS","","1424-8220","10.3390/s25010081","","The semantic segmentation of bone structures demands pixel-level classification accuracy to create reliable bone models for diagnosis. While Convolutional Neural Networks (CNNs) are commonly used for segmentation, they often struggle with complex shapes due to their focus on texture features and limited ability to incorporate positional information. As orthopedic surgery increasingly requires precise automatic diagnosis, we explored SegFormer, an enhanced Vision Transformer model that better handles spatial awareness in segmentation tasks. However, SegFormer's effectiveness is typically limited by its need for extensive training data, which is particularly challenging in medical imaging, where obtaining labeled ground truths (GTs) is a costly and resource-intensive process. In this paper, we propose two models and their combination to enable accurate feature extraction from smaller datasets by improving SegFormer. Specifically, these include the data-efficient model, which deepens the hierarchical encoder by adding convolution layers to transformer blocks and increases feature map resolution within transformer blocks, and the FPN-based model, which enhances the decoder through a Feature Pyramid Network (FPN) and attention mechanisms. Testing our model on spine images from the Cancer Imaging Archive and our own hand and wrist dataset, ablation studies confirmed that our modifications outperform the original SegFormer, U-Net, and Mask2Former. These enhancements enable better image feature extraction and more precise object contour detection, which is particularly beneficial for medical imaging applications with limited training data.","2025-01","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","1","25","","","","","","","","","","English","","","","WOS:001393823900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","feature pyramid network; Mask2Former; SegFormer; semantic segmentation; transformer block","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y2JXDB74","journalArticle","2024","Bernatavicius, A; Sícho, M; Janssen, APA; Hassen, AK; Preuss, M; van Westen, GJP","AlphaFold Meets De Novo Drug Design: Leveraging Structural Protein Information in Multitarget Molecular Generative Models","JOURNAL OF CHEMICAL INFORMATION AND MODELING","","1549-9596","10.1021/acs.jcim.4c00309","","Recent advancements in deep learning and generative models have significantly expanded the applications of virtual screening for drug-like compounds. Here, we introduce a multitarget transformer model, PCMol, that leverages the latent protein embeddings derived from AlphaFold2 as a means of conditioning a de novo generative model on different targets. Incorporating rich protein representations allows the model to capture their structural relationships, enabling the chemical space interpolation of active compounds and target-side generalization to new proteins based on embedding similarities. In this work, we benchmark against other existing target-conditioned transformer models to illustrate the validity of using AlphaFold protein representations over raw amino acid sequences. We show that low-dimensional projections of these protein embeddings cluster appropriately based on target families and that model performance declines when these representations are intentionally corrupted. We also show that the PCMol model generates diverse, potentially active molecules for a wide array of proteins, including those with sparse ligand bioactivity data. The generated compounds display higher similarity known active ligands of held-out targets and have comparable molecular docking scores while maintaining novelty. Additionally, we demonstrate the important role of data augmentation in bolstering the performance of generative models in low-data regimes. Software package and AlphaFold protein embeddings are freely available at https://github.com/CDDLeiden/PCMol.","2024-10-30","2025-02-26 20:41:52","2025-02-26 20:41:52","","8113-8122","","21","64","","","","","","","","","","English","","","","WOS:001345145800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","LEARNING-MODELS; TOOL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VPNVGWKC","journalArticle","2024","Allan-Blitz, LT; Ambepitiya, S; Prathapa, J; Rietmeijer, CA; Kularathne, Y; Klausner, JD","Synergistic pairing of synthetic image generation with disease classification modeling permits rapid digital classification tool development","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-77565-6","","Machine-learning disease classification models have the potential to support diagnosis of various diseases. Pairing classification models with synthetic image generation may overcome barriers to developing classification models and permit their use in numerous contexts. Using 10 images of penises with human papilloma virus (HPV)-related disease, we trained a denoising diffusion probabilistic model. Combined with text-to-image generation, we produced 630 synthetic images, of which 500 were deemed plausible by expert clinicians. We used those images to train a Vision Transformer model. We assessed the model's performance on clinical images of HPV-related disease (n = 70), diseases other than HPV (n = 70), and non-diseased images (n = 70), calculating recall, precision, F1-score, and Area Under the Receiver Operating Characteristics Curve (AUC). The model correctly classified 64 of 70 images of HPV-related disease, with a recall of 91.4% (95% CI 82.3%-96.8%). The precision of the model for HPV-related disease was 95.5% (95% CI 87.5%-99.1%), and the F1-score was 93.4%. The AUC for HPV-related disease was 0.99 (95% CI 0.98-1.0). Overall, the HPV-related disease classification model demonstrated excellent performance on clinical images, which was trained exclusively using synthetic images.","2024-10-27","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","1","14","","","","","","","","","","English","","","","WOS:001345832600027","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","Artificial intelligence; Denoising diffusion probabilistic modeling; Human papilloma virus; Machine-learning disease classification; Text-to-image modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2Q8L87WH","journalArticle","2024","Kuang, WR; Wang, Z; Wei, ZW; Li, YL; Ding, BL","When Transformer Meets Large Graphs: An Expressive and Efficient Two-View Architecture","IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING","","1041-4347","10.1109/TKDE.2024.3381125","","The successes of applying Transformer to graphs have been witnessed on small graphs (e.g., molecular graphs), yet two barriers prevent its adoption on large graphs (e.g., citation networks). First, despite the benefit of the global receptive field, enormous distant nodes might distract the necessary attention of each target node from its neighborhood. Second, training a Transformer model on large graphs is costly due to the node-to-node attention mechanism's quadratic computational complexity. To break down these barriers, we propose a two-view architecture Coarformer, wherein a GNN-based module captures fine-grained local information from the original graph, and a Transformer-based module captures coarse yet long-range information on the coarse graph. We further design a cross-view propagation scheme so that these two views can enhance each other. Our graph isomorphism analysis shows the complementary natures of GNN and Transformer, justifying the motivation and design of Coarformer. We conduct extensive experiments on real-world datasets, where Coarformer surpasses any single-view method that solely applies a GNN or Transformer. As an ablation, Coarformer outperforms straightforward combinations of a GNN model and a Transformer-based model, verifying the effectiveness of our coarse global view and the cross-view propagation scheme. Meanwhile, Coarformer consumes the least runtime and GPU memory than those combinations.","2024-10","2025-02-26 20:41:52","2025-02-26 20:41:52","","5440-5452","","10","36","","","","","","","","","","English","","","","WOS:001313362200028","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","Computer architecture; Encoding; Graph neural network; Graph neural networks; representation learning; Smoothing methods; Symbols; Task analysis; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J6HTC498","journalArticle","2024","Song, D; Dai, SQ; Li, WH; Ren, TW; Wei, ZQ; Liu, AA","STVformer: A spatial-temporal-variable transformer with auxiliary knowledge for sea surface temperature prediction","APPLIED OCEAN RESEARCH","","0141-1187","10.1016/j.apor.2024.104218","","Sea surface temperature (SST) is a crucial indicator among the various factors influencing ocean dynamics. It significantly impacts weather patterns, ocean circulation, and marine biodiversity. SST variation is affected by multiple factors such as solar radiation and air-sea heat exchange, which contribute to the complexity of accurately predicting sea surface temperatures. The challenges of SST prediction tasks stem from the difficulty in modeling the coupling relationships between dynamic ocean variables and capturing long-term spatiotemporal dependencies. Existing data-driven methods for SST prediction overlook the physical relationships between ocean variables, and struggle to effectively capture long-term features. In this work, we propose a spatio-temporal-variable transformer model (STVformer) consisting of multi-variable feature representation module and spatio-temporal-variable saliency modeling module for SST prediction. STVformer first models the physical relationship among auxiliary variables including short-wave radiation (SWR), long-wave radiation (LWR), latent heat flux (LHF) and sensible heat flux (SHF) based on the heat budget equation. Then, it leverages the saliency self-attention mechanism and the spatio-temporal attention mechanism to effectively learn the spatio-temporal-variable correlations and long-term dependencies. Extensive experiments are carried out on two datasets to validate the effectiveness of STVformer. The experimental results demonstrate that STVformer surpasses existing methods in SST prediction.","2024-12","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","153","","","","","","","","","","English","","","","WOS:001310719600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Auxiliary knowledge; Heat budget equation; MODEL; Sea surface temperature (SST); Self-attention; Spatio-temporal transformer; SST","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SFXD7ZUA","journalArticle","2024","Dong, XC; Tian, Y; Dai, LYR; Li, JC; Wan, LL","A New Accurate Aircraft Trajectory Prediction in Terminal Airspace Based on Spatio-Temporal Attention Mechanism","AEROSPACE","","2226-4310","10.3390/aerospace11090718","","Trajectory prediction serves as a prerequisite for future trajectory-based operation, significantly reducing the uncertainty of aircraft movement information within airspace by scientifically forecasting the three-dimensional positions of aircraft over a certain period. As convergence points in the aviation network, airport terminal airspace exhibits the most complex traffic conditions in the entire air route network. It has stronger mutual influences and interactions among aircraft compared to the en-route phase. Current research typically uses the trajectory time series information of a single aircraft as input for subsequent predictions. However, it often lacks consideration of the close-range spatial interactions between multiple aircraft in the terminal airspace. This results in a gap in the study of aircraft trajectory prediction that couples spatiotemporal features. This paper aims to predict the four-dimensional trajectories of aircraft in terminal airspace, constructing a Spatio-Temporal Transformer (ST-Transformer) prediction model based on temporal and spatial attention mechanisms. Using radar aircraft trajectory data from the Guangzhou Baiyun Airport terminal airspace, the results indicate that the proposed ST-Transformer model has a smaller prediction error compared to mainstream deep learning prediction models. This demonstrates that the model can better integrate the temporal sequence correlation of trajectory features and the potential spatial interaction information among trajectories for accurate prediction.","2024-09","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","9","11","","","","","","","","","","English","","","","WOS:001323939200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","air traffic management; aircraft trajectory prediction; attention mechanism; CONFLICT DETECTION; IMPROVE; MODEL; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M8V3NPXC","journalArticle","2024","Aldahdooh, J; Tanoli, Z; Tang, J","Mining drug-target interactions from biomedical literature using chemical and gene descriptions-based ensemble transformer model","BIOINFORMATICS ADVANCES","","2635-0041","10.1093/bioadv/vbae106","","Motivation Drug-target interactions (DTIs) play a pivotal role in drug discovery, as it aims to identify potential drug targets and elucidate their mechanism of action. In recent years, the application of natural language processing (NLP), particularly when combined with pre-trained language models, has gained considerable momentum in the biomedical domain, with the potential to mine vast amounts of texts to facilitate the efficient extraction of DTIs from the literature.Results In this article, we approach the task of DTIs as an entity-relationship extraction problem, utilizing different pre-trained transformer language models, such as BERT, to extract DTIs. Our results indicate that an ensemble approach, by combining gene descriptions from the Entrez Gene database with chemical descriptions from the Comparative Toxicogenomics Database (CTD), is critical for achieving optimal performance. The proposed model achieves an F1 score of 80.6 on the hidden DrugProt test set, which is the top-ranked performance among all the submitted models in the official evaluation. Furthermore, we conduct a comparative analysis to evaluate the effectiveness of various gene textual descriptions sourced from Entrez Gene and UniProt databases to gain insights into their impact on the performance. Our findings highlight the potential of NLP-based text mining using gene and chemical descriptions to improve drug-target extraction tasks.Availability and implementation Datasets utilized in this study are accessible at https://dtis.drugtargetcommons.org/.","2024-08-02","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","1","4","","","","","","","","","","English","","","","WOS:001281764300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JZGKPD7N","journalArticle","2024","Koike, M; Onuma, R; Adachi, R; Mineno, H","Transformer-Based Water Stress Estimation Using Leaf Wilting Computed from Leaf Images and Unsupervised Domain Adaptation for Tomato Crops","TECHNOLOGIES","","2227-7080","10.3390/technologies12070094","","Modern agriculture faces the dual challenge of ensuring sustainability while meeting the growing global demand for food. Smart agriculture, which uses data from the environment and plants to deliver water exactly when and how it is needed, has attracted significant attention. This approach requires precise water management and highly accurate real-time monitoring of crop water stress. Existing monitoring methods pose challenges such as the risk of plant damage, costly sensors, and the need for expert adjustments. Therefore, a low-cost, highly accurate water stress estimation model was developed that uses deep learning and commercially available sensors. The model uses the relative stem diameter as a water stress index and incorporates data from environmental sensors and an RGB camera, which are processed by the proposed daily normalization. In addition, domain adaptation in our Transformer model was implemented to enable robust learning in different areas. The accuracy of the model was evaluated using real cultivation data from tomato crops, achieving a coefficient of determination (R2) of 0.79 in water stress estimation. Furthermore, the model maintained a high level of accuracy when applied to different areas, with an R2 of 0.76, demonstrating its high adaptability under different conditions.","2024-07","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","7","12","","","","","","","","","","English","","","","WOS:001277308800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","AGRICULTURE; deep learning; domain adaptation; IRRIGATION MANAGEMENT; irrigation system; smart agriculture; SOIL-MOISTURE; STEM DIAMETER VARIATIONS; water stress","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N3KPZK89","journalArticle","2024","Alrayzah, A; Alsolami, F; Saleh, M","AraFast: Developing and Evaluating a Comprehensive Modern Standard Arabic Corpus for Enhanced Natural Language Processing","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14125294","","The research presented in the following paper focuses on the effectiveness of a modern standard Arabic corpus, AraFast, in training transformer models for natural language processing tasks, particularly in Arabic. In the study described herein, four experiments were conducted to evaluate the use of AraFast across different configurations: segmented, unsegmented, and mini versions. The main outcomes of the present study are as follows: Transformer models trained with larger and cleaner versions of AraFast, especially in question-answering, indicate the impact of corpus quality and size on model efficacy. Secondly, a dramatic reduction in training loss was observed with the mini version of AraFast, underscoring the importance of optimizing corpus size for effective training. Moreover, the segmented text format led to a decrease in training loss, highlighting segmentation as a beneficial strategy in Arabic NLP. In addition, using the study findings, challenges in managing noisy data derived from web sources are identified, which were found to significantly hinder model performance. These findings collectively demonstrate the critical role of well-prepared, segmented, and clean corpora in advancing Arabic NLP capabilities. The insights from AraFast's application can guide the development of more efficient NLP models and suggest directions for future research in enhancing Arabic language processing tools.","2024-06","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","12","14","","","","","","","","","","English","","","","WOS:001254634300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;79</p>","","","Arabic corpora; Arabic corpus; Arabic dataset; Arabic NLP; question answering; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WLDABYFH","journalArticle","2024","Zhao, F; Tao, R; Wang, WH; Cui, B; Xu, YT; Ai, Q","Collaborative learning of supervision and correlation for generalized zero-shot extreme multi-label learning","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-024-05498-8","","Generalized zero-shot extreme multi-label learning (GZXML) aims to predict relevant labels for unknown instances from a set of seen and unseen labels and is widely used in engineering applications. Since the supervisory information of the instances is incomplete in this task, the existing methods classify such instances based on the semantic relationships between the instances and labels. However, the supervisory information of the seen labels is also crucial for achieving high prediction performance. To bridge this gap, we propose collaborative learning of supervision and correlations for GZXML (CLSC-XML). CLSC-XML leverages both the semantic relationships between instances and labels and the supervisory information of the seen labels to enhance the prediction results for unseen labels. Specifically, CLSC-XML extracts discriminative and representational features, which are then fed into classification and correlation modules for collaborative learning. Furthermore, to enrich the incomplete supervised information, we propose the generation of features for unseen labels (GFUL) algorithm. The classifier is trained alternately with the GFUL algorithm. The classifier provides semantic guidance to the GFUL algorithm, and in turn, the GFUL algorithm helps the classification model enrich the supervised information. Experimental results show that CLSC-XML outperforms the state-of-the-art methods and requires less training time.","2024-04","2025-02-26 20:41:52","2025-02-26 20:41:52","","6285-6298","","8","54","","","","","","","","","","English","","","","WOS:001220415300004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","CLASSIFICATION; Collaborative learning; Deep neural networks; Extreme multi-label classification; Label correlation; Transformer model; Zero-shot learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JQSQR6LD","journalArticle","2023","Liu, JT; Li, SC; Ren, C; Lyu, Y; Xu, TT; Wang, ZH; Chen, W","AI Enhancements for Linguistic E-Learning System","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app131910758","","E-learning systems have been considerably developed after the COVID-19 pandemic. In our previous work, we developed a linguistic interactive E-learning system for phonetic transcription learning. In this paper, we propose three artificial-intelligence-based enhancements to this system from different aspects. Compared with the original system, the first enhancement is a disordered speech classification module; this module is driven by the MFCC-CNN model, which aims to distinguish disordered speech and nondisordered speech. The accuracy of the classification is about 83%. The second enhancement is a grapheme-to-phoneme converter. This converter is based on the transformer model and designed for teachers to better generate IPA words from the regular written text. Compared with other G2P models, our transformer-based G2P model provides outstanding PER and WER performance. The last part of this paper focuses on a Tacotron2-based IPA-to-speech synthesis system, this deep learning-based TTS system can help teacher generate high-quality speech sounds from IPA characters which significantly improve the functionality of our original system. All of these three enhancements are related to the phonetic transcription process. and this work not only provides a better experience for the users of this system but also explores the utilization of artificial intelligence technologies in the E-learning field and linguistic field.","2023-10","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","19","13","","","","","","","","","","English","","","","WOS:001084648300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","grapheme-to-phoneme; linguistic E-learning; Mel frequency cepstrum coefficient; phonetic transcription; speech synthesis; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VPW3ID2S","journalArticle","2023","Calix, RA; Javadpour, L","Unexpectedness as a Measure of Semantic Learning When Training Transformer Models","INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS","","0218-2130","10.1142/S0218213023500070","","Many problems in NLP such as language translation and sentiment analysis have shown a lot of improvement in recent years. As simpler language problems are solved or better understood, the focus shifts to more complex problems such as semantic analysis and understanding. Unfortunately, a lot of studies in the literature suffer from a too much specificity problem. The algorithms and datasets are too domain specific. In this study, we analyze and elaborate on this notion of generality. Instead of selecting a highly specialized data set for semantic analysis, we take a generic and possibly dry data set, and we study how a plain vanilla Transformer performs in learning higher level semantic patterns beyond what was obvious or expected. We tune our Transformer model on a classic language task to ensure correct performance. Once tuned, the goal is to select sentences with specific key words and study whether higher level semantic patterns may have been learned by our model. We believe that we obtained promising results. The average BLEU score for sentences less than 25 words is equal to 39.79. Our initial qualitative analysis of possible semantic content of interest shows a 17 percent rate in finding interesting semantic patterns. We provide discussion of data driven results of unexpectedness as a measure of semantic learning.","2023-02","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","01","32","","","","","","","","","","English","","","","WOS:000941389800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","attention; COMMON-SENSE; Deep learning; semantic analysis; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HCLKS3MG","journalArticle","2022","Willemink, MJ; Roth, HR; Sandfort, V","Toward Foundational Deep Learning Models for Medical Imaging in the New Era of Transformer Networks","RADIOLOGY-ARTIFICIAL INTELLIGENCE","","2638-6100","10.1148/ryai.210284","","Deep learning models are currently the cornerstone of artificial intelligence in medical imaging. While progress is still being made, the generic technological core of convolutional neural networks (CNNs) has had only modest innovations over the last several years, if at all. There is thus a need for improvement. More recently, transformer networks have emerged that replace convolutions with a complex attention mechanism, and they have already matched or exceeded the performance of CNNs in many tasks. Transformers need very large amounts of training data, even more than CNNs, but obtaining well-curated labeled data is expensive and difficult. A possible solution to this issue would be transfer learning with pretraining on a self-supervised task using very large amounts of unlabeled medical data. This pretrained network could then be fine-tuned on specific medical imaging tasks with relatively modest data requirements. The authors believe that the availability of a large-scale, three-dimension-capable, and extensively pretrained transformer model would be highly beneficial to the medical imaging and research community. In this article, authors discuss the challenges and obstacles of training a very large medical imaging transformer, including data needs, biases, training tasks, network architecture, privacy concerns, and computational requirements. The obstacles are substantial but not insurmountable for resourceful collaborative teams that may include academia and information technology industry partners.","2022-11","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","6","4","","","","","","","","","","English","","","","WOS:001048957200006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;25<br/>Total Times Cited:&nbsp;&nbsp;26<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","IDENTIFICATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XV7ZRBVD","journalArticle","2023","Yan, YY; Liu, FA; Zhuang, XQ; Ju, J","An R-Transformer_BiLSTM Model Based on Attention for Multi-label Text Classification","NEURAL PROCESSING LETTERS","","1370-4621","10.1007/s11063-022-10938-y","","Multi-label text classification task is one of the research hotspots in the field of natural language processing. However, most of the existing multi-label text classification models are only suitable for scenarios with a small number of labels and coarser granularity. Aiming at the problem of difficulty in obtaining sequence information and obvious lack of semantic information when the text sequence grows, this paper proposes an R-Transformer_BiLSTM model based on label embedding and attention mechanism for multi-label text classification. First, we use the R-Transformer model to obtain the global and local information of the text sequence in combination with part-of-speech embedding. At the same time, we use BiLSTM+CRF to obtain the entity information of the text, and use the self-attention mechanism to obtain the keywords of the entity information, and then use bidirectional attention and label embedding to further generate text representation and label representation. Finally, the classifier performs text classification according to the label representation and text representation. In order to evaluate the performance of the model, we conducted a lot of experiments on the RCV1-V2 and AAPD datasets. Experimental results show that the model can effectively improve the efficiency and accuracy of multi-label text classification task.","2023-04","2025-02-26 20:41:52","2025-02-26 20:41:52","","1293-1316","","2","55","","","","","","","","","","English","","","","WOS:000815414200002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;16<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","BiLSTM; Label embedding; Multi-label text classification; R-Transformer; Self-attention","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QGQ43PEJ","journalArticle","2021","Tan, X; Gao, KL; Liu, B; Fu, YM; Kang, L","Deep global-local transformer network combined with extended morphological profiles for hyperspectral image classification","JOURNAL OF APPLIED REMOTE SENSING","","1931-3195","10.1117/1.JRS.15.038509","","Recently, deep learning models based on convolutional neural networks (CNN) remain dominant in hyperspectral image (HSI) classification. However, there are some problems in CNN models, such as not good at modeling the long-distance dependencies and obtaining global context information. Different from the existing CNN-based models, an innovative classification method based on the transformer model is proposed to further improve the classification accuracy of HSI. Specifically, the proposed method first extracts the extended morphological profile (EMP) features of HSI to make full use of the spatial and spectral information while effectively reducing the number of bands. Next, a deep network model is constructed by introducing the transformer-IN-transformer (TNT) modules to carry out end-to-end classification. The outer and inner transformer models in the TNT module can extract the patch-level and pixel-level features, respectively, to make full use of the global and local information in the input EMP cubes. Experimental results on three public HSI data sets show that the proposed method can achieve better classification performance than the existing CNN-based models. In addition, using the transformer-based deep model without convolution to classify HSI provides a new idea for related research. (C) 2021 Society of Photo-Optical Instrumentation Engineers (SPIE)","2021-09-24","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","3","15","","","","","","","","","","English","","","","WOS:000703540400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;20<br/>Total Times Cited:&nbsp;&nbsp;20<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","ALGORITHM; CNN; deep learning; hyperspectral image classification; self attention; SPECTRAL-SPATIAL CLASSIFICATION; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M2PVZSNE","journalArticle","2024","Jeong, N; Park, S; Mahajan, S; Zhou, J; Blotevogel, J; Li, Y; Tong, TZ; Chen, YS","Elucidating governing factors of PFAS removal by polyamide membranes using machine learning and molecular simulations","NATURE COMMUNICATIONS","","2041-1723","10.1038/s41467-024-55320-9","","Per- and polyfluoroalkyl substances (PFASs) have recently garnered considerable concerns regarding their impacts on human and ecological health. Despite the important roles of polyamide membranes in remediating PFASs-contaminated water, the governing factors influencing PFAS transport across these membranes remain elusive. In this study, we investigate PFAS rejection by polyamide membranes using two machine learning (ML) models, namely XGBoost and multimodal transformer models. Utilizing the Shapley additive explanation method for XGBoost model interpretation unveils the impacts of both PFAS characteristics and membrane properties on model predictions. The examination of the impacts of chemical structure involves interpreting the multimodal transformer model incorporated with simplified molecular input line entry system strings through heat maps, providing a visual representation of the attention score assigned to each atom of PFAS molecules. Both ML interpretation methods highlight the dominance of electrostatic interaction in governing PFAS transport across polyamide membranes. The roles of functional groups in altering PFAS transport across membranes are further revealed by molecular simulations. The combination of ML with computer simulations not only advances our knowledge of PFAS removal by polyamide membranes, but also provides an innovative approach to facilitate data-driven feature selection for the development of high-performance membranes with improved PFAS removal efficiency.","2024-12-30","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","1","15","","","","","","","","","","English","","","","WOS:001386373100018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;87</p>","","","DRINKING-WATER TREATMENT; IMPLEMENTATION; NANOFILTRATION; ORGANIC-COMPOUNDS; PERFLUOROALKYL; PERFLUOROHEXANOIC ACID; PERFLUOROOCTANE SULFONATE; POLYFLUOROALKYL SUBSTANCES; REJECTION; REVERSE-OSMOSIS MEMBRANES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"55Q4Y47V","journalArticle","2024","Xiong, X; Huang, ZC; Chen, YL; Sun, J","Load Forecasting for Commercial Buildings Using BiLSTM-Transformer Network and Cyber-Physical Cognitive Control Systems","SYMMETRY-BASEL","","2073-8994","10.3390/sym16121601","","With the widespread adoption of electric vehicles (EVs), their charging and discharging schedules pose new challenges for real-time load forecasting in commercial buildings. This study proposes a prediction model based on the integration of bidirectional long short-term memory (BiLSTM) networks and Transformer architecture, along with the introduction of a cognitive control system and cyber-physical systems (CPS) to address issues such as data loss and excessive computation time during the forecasting process. The BiLSTM-Transformer model significantly improves load-forecasting accuracy and real-time performance by combining time-series modeling with global feature extraction capabilities. Additionally, the cognitive control system includes user-aware cognitive control (UACC) and Microgrid Control Center Cognitive Control (MACC). UACC quantifies information gaps in real time and adaptively adjusts strategies during communication instability, while MACC employs Q-learning algorithms to evaluate the impact of data loss on scheduling and optimize power resource allocation. The synergy between these mechanisms ensures system stability and predictive performance in scenarios involving data loss or communication disruptions. Experimental results demonstrate that the model achieves outstanding predictive accuracy under complete data conditions and significantly reduces errors in scenarios with data loss, validating its superior accuracy and robustness. This provides reliable support for load forecasting in commercial buildings.","2024-12","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","12","16","","","","","","","","","","English","","","","WOS:001386783500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","BiLSTM-Transformer; cognitive control system; cyber-physical system; load forecasting; simulated annealing algorithm","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ES94T23B","journalArticle","2024","Ogoke, F; Pak, P; Myers, A; Quirarte, G; Beuth, J; Malen, J; Farimani, AB","Deep learning for melt pool depth contour prediction from surface thermal images via vision transformers","ADDITIVE MANUFACTURING LETTERS","","2772-3690","10.1016/j.addlet.2024.100243","","Anomalous melt pools during metal additive manufacturing (AM) can lead to deteriorated mechanical and fatigue performance. In-situ monitoring of the melt pool subsurface morphology requires specialized equipment that may not be readily accessible or scalable. Therefore, we introduce a machine learning framework to correlate in-situ two-color thermal images observed via high-speed color imaging to the two-dimensional profile of the melt pool cross-section. We employ a hybrid CNN-Transformer architecture to establish a correlation between single bead off-axis thermal image sequences and melt pool cross-section contours measured via optical microscopy. Specifically, a ResNet model embeds the spatial information contained within the thermal images to a latent vector, while a Transformer model correlates the sequence of embedded vectors to extract temporal information. The performance of this model is evaluated through dimensional and geometric comparisons to the corresponding experimental no-powder melt pool observations. Our framework is able to model the curvature of the subsurface melt pool structure, with improved performance in high energy density regimes compared to analytical models. Additionally, the use of ratiometric temperature estimates improves the accuracy of the model predictions compared to monochromatic imaging. This work establishes a framework extensible towards powder-based AM builds.","2024-12","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","11","","","","","","","","","","English","","","","WOS:001333253500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Deep learning; DEFECT-DETECTION; in-situ monitoring; Lack-of-fusion; POWDER; SIMULATION; STRESS; Vision transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8TLAWDGZ","journalArticle","2024","Ye, WL; Ren, JJ; Li, C; Liu, WA; Zhang, ZY; Lu, CF","Intelligent Detection of Surface Defects in High-Speed Railway Ballastless Track Based on Self-Attention and Transfer Learning","STRUCTURAL CONTROL & HEALTH MONITORING","","1545-2255","10.1155/2024/2967927","","The detection of ballastless track surface (BTS) defects is a prerequisite for ensuring the safe operation of high-speed railways. Traditional convolutional neural networks fail to fully exploit contextual information and lack global pixel representations. The extensive stacking of convolutions leads deep learning models to play a black-box detection role, lacking interpretability. Due to the current lack of sufficient high-quality surface data for ballastless tracks, it is a severe constraint on the accurate identification of the substructure state in high-speed railways. This paper proposes an intelligent detection method for BTS defects named TrackNet based on self-attention and transfer learning. The method enhances the fusion ability of global features of BTS defects using multihead self-attention. The model's dependence on extensive defect data is reduced by transferring knowledge from large-scale publicly available datasets. Experimental results demonstrate that compared to advanced Swin Transformer model results, the TrackNet model achieves improvements in average accuracy and F1-score by 5.15% and 5.16%, respectively, on limited test data. The TrackNet model visualizes the decision regions of the model in identifying BTS defects, revealing the black-box recognition mechanism of deep learning models. This research performs engineering applications and provides valuable insights for the multiclass recognition of BTS defects in high-speed railways.","2024-05-18","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","2024","","","","","","","","","","English","","","","WOS:001230971600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EDSBZFRC","journalArticle","2024","Estrella-Ibarra, LF; de Leon-Cuevas, A; Tovar-Arriaga, S","Nested Contrastive Boundary Learning: Point Transformer Self-Attention Regularization for 3D Intracranial Aneurysm Segmentation","TECHNOLOGIES","","2227-7080","10.3390/technologies12030028","","In 3D segmentation, point-based models excel but face difficulties in precise class delineation at class intersections, an inherent challenge in segmentation models. This is particularly critical in medical applications, influencing patient care and surgical planning, where accurate 3D boundary identification is essential for assisting surgery and enhancing medical training through advanced simulations. This study introduces the Nested Contrastive Boundary Learning Point Transformer (NCBL-PT), specially designed for 3D point cloud segmentation. NCBL-PT employs contrastive learning to improve boundary point representation by enhancing feature similarity within the same class. NCBL-PT incorporates a border-aware distinction within the same class points, allowing the model to distinctly learn from both points in proximity to the class intersection and from those beyond. This reduces semantic confusion among the points of different classes in the ambiguous class intersection zone, where similarity in features due to proximity could lead to incorrect associations. The model operates within subsampled point clouds at each encoder block stage of the point transformer architecture. It applies self-attention with k = 16 nearest neighbors to local neighborhoods, aligning with NCBL calculations for consistent self-attention regularization in local contexts. NCBL-PT improves 3D segmentation at class intersections, as evidenced by a 3.31% increase in Intersection over Union (IOU) for aneurysm segmentation compared to the base point transformer model.","2024-03","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","3","12","","","","","","","","","","English","","","","WOS:001193052800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","3D point cloud segmentation; contrastive learning; intracranial aneurysm segmentation; REALITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2GX9PXJI","journalArticle","2024","Ermilova, A; Baramiia, N; Kornilov, V; Petrakov, S; Zaytsev, A","Robust Representation Learning via Sparse Attention Mechanism for Similarity Models","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3418779","","The attention-based models are widely used for time series data. However, due to the quadratic complexity of attention regarding input sequence length, the application of Transformers is limited by high resource demands. Moreover, their modifications for industrial time series need to be robust to missing or noisy values, which complicates the expansion of their application horizon. To cope with these issues, we introduce the class of efficient Transformers named Regularized Transformers (Reguformers). We implement the regularization technique inspired by the dropout ideas to improve robustness and reduce computational expenses without significantly modifying the pipeline. The focus in our experiments is on oil&gas data. For well-interval similarity task, our best Reguformer configuration reaches ROC AUC 0.97, which is comparable to Informer (0.978) and outperforms baselines: the previous LSTM model (0.934), the classical Transformer model (0.967), and three recent most promising modifications of the original Transformer, namely, Performer (0.949), LRformer (0.955), and DropDim (0.777). We also conduct the corresponding experiments on three additional datasets from different domains and obtain superior results. The increase in the quality of the best Reguformer relative to Transformer for different datasets varies from 3.7% to 9.6%, while the increase range relative to Informer is wider: from 1.7% to 18.4%.","2024","2025-02-26 20:41:52","2025-02-26 20:41:52","","97833-97850","","","12","","","","","","","","","","English","","","","WOS:001273016100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","Deep learning; efficient transformer; Meteorology; Oil insulation; representation learning; Representation learning; robust transformer; similarity learning; Task analysis; Time series analysis; Training; TRANSFORMER; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9FW8H74M","journalArticle","2024","Li, X; Yu, J; Jiang, SC; Lu, HC; Li, ZY","MSViT: Training Multiscale Vision Transformers for Image Retrieval","IEEE TRANSACTIONS ON MULTIMEDIA","","1520-9210","10.1109/TMM.2023.3304021","","The recently developed vision transformer (ViT) has achieved promising results on image retrieval compared to convolutional neural networks. However, most of these vision transformer-based image retrieval methods use the original ViT model to extract global features, ignoring the importance of local features for image retrieval. In this work, we propose a vision transformer-based multiscale feature fusion image retrieval method (MSViT) to achieve the fusion of global features with local features. The challenge of this research work is how to learn the feature representation ability of transformer model, so as to improve the performance of image retrieval model. First, a transformer-based two-branch network structure is proposed to obtain different scale features by processing image patches with different granularities. Second, we present a multiscale feature fusion strategy, which can efficiently and effectively fuse the feature information of different sizes on two branches. Finally, to more fully utilize the label information to supervise the network training process, we optimize the construction rules for the triplet data. The comparison of experimental results with ten CNN-based and six transformer-based image retrieval methods on four publicly available image datasets shows that our method outperforms the state-of-the-art methods. And ablation experiments show that the designed multiscale feature fusion strategy and improved triplet loss function have an implicit improvement on the performance of MSViT.","2024","2025-02-26 20:41:52","2025-02-26 20:41:52","","2809-2823","","","26","","","","","","","","","","English","","","","WOS:001173299400005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Image retrieval; multiscale feature; supervised deep hashing; triplet loss function; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z63788U6","journalArticle","2023","Deng, RX; Chen, ZM; Chen, HL; Hu, J","Learning to refine object boundaries","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2023.126742","","Existing Deep-Learning-based contour detectors suffer from the issues of the sharpness and the correctness of their predictions, which often need offline post-processing to sharpen the results as well as improve model performance. In this work, we present a novel method that can learn to refine object contour in training and directly output crisp object boundaries in inference. To this end, we first introduce a keypoint-focal loss that draws point-based attention to the isolated contour annotations. It allows an edge detector to jointly optimize the appearance thickness and the localization accuracy of predictions in the training procedure. Moreover, we present a regularization loss to further improve the performance of an edge detector. Lastly, we present the Contour Transformer model for precisely localizing object boundaries in images. We repurpose and integrate a Transformer-style hyper module into an encoder-decoder network, effectively aggregating global contextual information on high-level features and significantly enhancing the discriminative power for classifying foreground/background pixels. We train and test our Attention and Contour Transformer detector (ACTD) on four widely adopted datasets, i.e., BSDS500, NYUD, Multi-Cue, and RoadNet. The proposed method achieves an ODS F-score of 0.826 on BSDS500 and an ODS F-score of 0.783 on NYUD, outperforming previous top detectors.","2023-11-07","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","557","","","","","","","","","","English","","","","WOS:001073471400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Contour detection; Deep learning; Edge detection; EDGE-DETECTION; Encoder-decoder networks; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KZ8F9H3Z","journalArticle","2023","Hartout, P; Pocuca, B; Méndez-García, C; Schleberger, C","Investigating the human and nonobese diabetic mouse MHC class II immunopeptidome using protein language modeling","BIOINFORMATICS","","1367-4803","10.1093/bioinformatics/btad469","","Motivation: Identifying peptides associated with the major histocompability complex class II (MHCII) is a central task in the evaluation of the immunoregulatory function of therapeutics and drug prototypes. MHCII-peptide presentation prediction has multiple biopharmaceutical applications, including the safety assessment of biologics and engineered derivatives in silico, or the fast progression of antigen-specific immunomodulatory drug discovery programs in immune disease and cancer. This has resulted in the collection of large-scale datasets on adaptive immune receptor antigenic responses and MHC-associated peptide proteomics. In parallel, recent deep learning algorithmic advances in protein language modeling have shown potential in leveraging large collections of sequence data and improve MHC presentation prediction. Results: Here, we train a compact transformer model (AEGIS) on human and mouse MHCII immunopeptidome data, including a preclinical murine model, and evaluate its performance on the peptide presentation prediction task. We show that the transformer performs on par with existing deep learning algorithms and that combining datasets from multiple organisms increases model performance. We trained variants of the model with and without MHCII information. In both alternatives, the inclusion of peptides presented by the I-Ag7 MHC class II molecule expressed by nonobese diabetic mice enabled for the first time the accurate in silico prediction of presented peptides in a preclinical type 1 diabetes model organism, which has promising therapeutic applications.","2023-08-01","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","8","39","","","","","","","","","","English","","","","WOS:001047635500005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","COMPLEX; PEPTIDE; PREDICTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B9H2NCVC","journalArticle","2022","Li, JY","Application of Machine Learning Combined with Wireless Network in Design of Online Translation System","WIRELESS COMMUNICATIONS & MOBILE COMPUTING","","1530-8669","10.1155/2022/1266397","","The importance of translation services has become increasingly prominent with the acceleration of economic globalization. Compared with human translation, machine translation is cheaper and faster, and therefore more suitable for the current era. The current mainstream machine translation method is neural machine translation, which employs machine methods to train on parallel corpora and create translation models. Research into neural machine translation has yielded a wealth of information. Learning and generalization abilities of neural networks have substantially enhanced the effectiveness of neural machine translation. This work applies machine learning and wireless network technology to build an online translation system for real-time translation. First, this work proposes a multigranularity feature fusion method based on a directed acyclic graph, which uses a directed acyclic graph to fuse different granularities as input and obtain a position representation. Secondly, this paper improves the Transformer model and proposes multigranularity position encoding and multigranularity self-attention. Then, on the basis of multigranularity features as input, this work introduces dynamic word vectors to improve the word embedding module, and uses the ELMo model to obtain dynamic word vector embeddings. Finally, this work builds a multigranularity feature-dynamic word vector machine translation model with above strategy, deploys it on server. Users can upload the content to be translated and download the translated content through the wireless network and realize an online translation system based on machine learning and wireless network.","2022-11-21","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","2022","","","","","","","","","","English","","","","WOS:000893529600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S6MC4H5M","journalArticle","2021","Wiercioch, M; Kirchmair, J","Dealing with a data-limited regime: Combining transfer learning and transformer attention mechanism to increase aqueous solubility prediction performance","ARTIFICIAL INTELLIGENCE IN THE LIFE SCIENCES","","2667-3185","10.1016/j.ailsci.2021.100021","","Aqueous solubility is a key chemical property that drives various processes in chemistry and biology. Its computational prediction is challenging, as evidenced by the fact that it has been a subject of considerable interest for several decades. Recent work has explored fingerprint-based, feature-based and graph-based representations with different machine learning and deep learning methodologies. In general, many traditional methods have been proposed, but they rely heavily on the quality of the rule-based, hand-crafted features. On the other hand, limitations in the quality of aqueous solubility data become a handicap when training deep models. In this study, we have developed a novel structure-aware method for the prediction of aqueous solubility by introducing a new deep network architecture and then employing a transfer learning approach. The model was proven to be competitive, obtaining an RMSE of 0.587 during both cross-validation and a test on an independent dataset. To be more precise, the method is evaluated on molecules downloaded from the Online Chemical Database and Modeling Environment (OCHEM). Beyond aqueous solubility prediction, the strategy presented in this work may be useful for modeling any kind of (chemical or biological) properties for which there is a limited amount of data available for model training.","2021-12","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","1","","","","","","","","","","English","","","","WOS:001343358300016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","Aqueous solubility; Cheminformatics; Deep Learning; Drug discovery; Regression; SMILES; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3QKFYTNZ","journalArticle","2021","Wang, L; Wang, XF; Hawbani, A; Xiong, Y","End to End Alignment Learning of Instructional Videos with Spatiotemporal Hybrid Encoding and Decoding Space Reduction","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app11114954","","We solve the problem of how to densely align actions in videos at frame level, with only the order of occurring actions available, in order to save the time-consuming efforts to accurately annotate the temporal boundaries of each action. We propose three task-specific innovations under this scenario: (1) To encode fine-grained spatiotemporal local features and long-range temporal patterns simultaneously, we test three popular backbones and compare their accuracy and training times: (i) a recurrent LSTM; (ii) a fully convolutional model; and (iii) the recently proposed Transformer model. (2) To address the absence of ground truth frame-by-frame labels during training, we apply connectionist temporal classification (CTC) on top of the temporal encoder to recursively collect all theoretically valid alignments, and further weight these alignments with frame-wise visual similarities, in order to avoid a significant number of degenerated paths and improve both recognition accuracy and computation efficiency. (3) To quantitatively assess the quality of the learned alignment, we apply a comprehensive set of frame-level, segment-level, and video-level evaluation measurements. Extensive evaluations verify the effectiveness of our proposal, with performance comparable to that of fully supervised approaches across four benchmarks of different difficulty and data scale.","2021-06","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","11","11","","","","","","","","","","English","","","","WOS:000659565200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","computer vision; connectionist temporal classification (CTC); convolutional neural networks (CNNs); NETWORKS; RECOGNITION; SEGMENTATION; temporal video alignment; temporal video segmentation; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RSG6Z3RW","journalArticle","2024","Zhou, KL; Zhang, ZY","Remaining useful life prediction of lithium-ion batteries based on data denoising and improved transformer","JOURNAL OF ENERGY STORAGE","","2352-152X","10.1016/j.est.2024.113749","","Accurately predicting the remaining useful life (RUL) of lithium-ion batteries (LIBs) is essential in improving the safety and availability of energy storage systems. However, the capacity regeneration phenomenon of LIBs occurs during actual usage, seriously affecting the accuracy of LIBs' RUL prediction. This study proposes a RUL prediction method of LIBs based on mode decomposition and an improved transformer. Firstly, to mitigate the impact of capacity degradation, we use the complete ensemble empirical mode decomposition with adaptive noise (CEEMDAN) method to decompose the battery capacity degradation into multi-scale component sequences. However, some noise remains in the high-frequency data output by CEEMDAN decomposition. To minimize noise impact on the accuracy of the prediction results, a single high-frequency data is then decomposed into multiple rich-featured subsequences using the variational mode decomposition. Finally, an improved transformer model extracts global and local features from these subsequences to improve the RUL of LIBs prediction accuracy. The proposed method is validated on two widely used public datasets, NASA and CALCE. Experimental results show that the proposed method has lower errors in some evaluation metrics. Compared to the four state-of-the-art methods, the proposed method improves the R-squared metric by 23.37 % and 39.81 %, respectively.","2024-10-20","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","100","","","","","","","","","","English","","","","WOS:001317283300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Capacity regeneration; Improved transformer; Lithium-ion battery; Mode decomposition; MODE DECOMPOSITION; Remaining useful life","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FA5S9P32","journalArticle","2024","Mahdi, MA; Fati, SM; Hazber, MAG; Ahamad, S; Saad, SA","Enhancing Arabic Cyberbullying Detection with End-to-End Transformer Model","CMES-COMPUTER MODELING IN ENGINEERING & SCIENCES","","1526-1492","10.32604/cmes.2024.052291","","Cyberbullying, a critical concern for digital safety, necessitates effective linguistic analysis tools that can navigate the complexities of language use in online spaces. To tackle this challenge, our study introduces a new approach employing Bidirectional Encoder Representations from the Transformers (BERT) base model (cased), originally pretrained in English. This model is uniquely adapted to recognize the intricate nuances of Arabic online communication, a key aspect often overlooked in conventional cyberbullying detection methods. Our model is an end-to-end solution that has been fine-tuned on a diverse dataset of Arabic social media (SM) tweets showing a notable increase in detection accuracy and sensitivity compared to existing methods. Experimental results on a diverse Arabic dataset collected from the 'X platform' demonstrate a notable increase in detection accuracy and sensitivity compared to existing methods. E-BERT shows a substantial improvement in performance, evidenced by an accuracy of 98.45%, precision of 99.17%, recall of 99.10%, and an F1 score of 99.14%. The proposed E-BERT not only addresses a critical gap in cyberbullying detection in Arabic online forums but also sets a precedent for applying cross-lingual pretrained models in regional language applications, offering a scalable and effective framework for enhancing online safety across Arabic-speaking communities.","2024","2025-02-26 20:41:52","2025-02-26 20:41:52","","1651-1671","","2","141","","","","","","","","","","English","","","","WOS:001292922600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Bidirectional Encoder Representations from the Transformers (BERT); continuous bag of words; Cyberbullying; natural language processing; offensive detection; Social Media","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VWQ7L6Z4","journalArticle","2024","Luan, SY; Ding, Y; Wei, CC; Huang, Y; Yuan, ZL; Quan, H; Ma, C; Zhu, BP; Xue, XD; Wei, W; Wang, X","PRT-Net: a progressive refinement transformer for dose prediction to guide ovarian transposition","FRONTIERS IN ONCOLOGY","","2234-943X","10.3389/fonc.2024.1372424","","Introduction Young cervical cancer patients who require ovarian transposition usually have their ovaries moved away from the pelvic radiotherapy (RT) field before radiotherapy. The dose of ovaries during radiotherapy is closely related to the location of the ovaries. To protect ovarian function and avoid ovarian dose exceeding the limits, a safe location of transposed ovary must be determined prior to surgery.Methods For this purpose, we input the patient's preoperative CT into a neural network model to predict the dose distribution. Surgeons were able to quickly locate low-dose regions based on the dose distribution before surgery, thus determining the safe location of the transposed ovary. In this work, we proposed a new progressive refinement transformer model PRT-Net that can generate dose prediction at multiple scale resolutions in one forward propagation, and refine the dose prediction using prediction details from low to high resolution based on a deep supervision strategy. A multi-loss function fusion algorithm was also built to fit the prediction results under different loss dimensions. The clinical feasibility of the method was verified through an actual cases.Results and discussion Therefore, using PRT-Net to predict the dose distribution by preoperative CT in cervical cancer patients can assist clinicians to perform ovarian transposition surgery and prevent patients' ovaries from exceeding the prescribed dose limit in postoperative radiotherapy.","2024-05-16","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","14","","","","","","","","","","English","","","","WOS:001234280800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","artificial intelligence; deep learning; dose prediction; ovarian transposition; radiotherapy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NTI5HY48","journalArticle","2024","Xu, LY; Zhang, GD; Zhao, SX; Wu, YW; Xi, ZQ","Fault Diagnosis of Tractor Transmission System Based on Time GAN and Transformer","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3439017","","The transmission system of a tractor is a crucial component, so it is crucial to promptly identify and correctly diagnose faults in it. However, due to the limited samples of faults occurring during its operational processes, employing existing fault diagnosis methods directly yields unsatisfactory results. This paper proposes a fault diagnosis model combining Time Generative Adversarial Networks (Time GAN) and Transformer. To enhance diagnostic accuracy, we first employ Time GAN for data augmentation, addressing the issue of imbalanced fault samples in practical scenarios. Then, we integrate a Transformer network with improved multi-head self-attention mechanisms, leveraging the advantages of the Transformer's encoder-decoder architecture and attention mechanism to enhance diagnostic performance. Bearing data from Case Western Reserve University (CWRU) was used to validate the diagnostic performance of the proposed model, while gear data from an experimental rig built by the author was used to validate the model's generalization capability. Experimental results indicate that the accuracy reached 98.96% and 95.36% in CWRU Dataset and Self-made Dataset respectively. In strong noise environments, the accuracy remains above 93%. In conclusion, the diagnostic model presented in this paper can reliably diagnose tractor transmission system problems in few-sample conditions and noise environments compared to traditional machine learning models.","2024","2025-02-26 20:41:52","2025-02-26 20:41:52","","107153-107169","","","12","","","","","","","","","","English","","","","WOS:001288393800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Accuracy; Agricultural machinery; data augmentation; Data models; fault diagnosis; Fault diagnosis; Feature extraction; Generative adversarial networks; Time GAN; Transformer model; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DBWVUV9B","journalArticle","2023","Yan, X; Han, B; Su, ZG; Hao, JT","SignalFormer: Hybrid Transformer for Automatic Drone Identification Based on Drone RF Signals","SENSORS","","1424-8220","10.3390/s23229098","","With the growing integration of drones into various civilian applications, the demand for effective automatic drone identification (ADI) technology has become essential to monitor malicious drone flights and mitigate potential threats. While numerous convolutional neural network (CNN)-based methods have been proposed for ADI tasks, the inherent local connectivity of the convolution operator in CNN models severely constrains RF signal identification performance. In this paper, we propose an innovative hybrid transformer model featuring a CNN-based tokenization method that is capable of generating T-F tokens enriched with significant local context information, and complemented by an efficient gated self-attention mechanism to capture global time/frequency correlations among these T-F tokens. Furthermore, we underscore the substantial impact of incorporating phase information into the input of the SignalFormer model. We evaluated the proposed method on two public datasets under Gaussian white noise and co-frequency signal interference conditions, The SignalFormer model achieved impressive identification accuracy of 97.57% and 98.03% for coarse-grained identification tasks, and 97.48% and 98.16% for fine-grained identification tasks. Furthermore, we introduced a class-incremental learning evaluation to demonstrate SignalFormer's competence in handling previously unseen categories of drone signals. The above results collectively demonstrate that the proposed method is a promising solution for supporting the ADI task in reliable ways.","2023-11","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","22","23","","","","","","","","","","English","","","","WOS:001114007100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","automatic drone identification; deep learning; internet of drones; time-frequency analysis; UAV DETECTION; WI-FI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TTE8F62A","journalArticle","2025","Alvén, J; Petersen, R; Hagerman, D; Sandstedt, M; Kitslaar, P; Bergström, G; Fagman, E; Hjelmgren, O","PlaqueViT: a vision transformer model for fully automatic vessel and plaque segmentation in coronary computed tomography angiography","EUROPEAN RADIOLOGY","","0938-7994","10.1007/s00330-025-11410-w","","ObjectivesTo develop and evaluate a deep learning model for segmentation of the coronary artery vessels and coronary plaques in coronary computed tomography angiography (CCTA).Materials and methodsCCTA image data from the Swedish CardioPulmonary BioImage Study (SCAPIS) was used for model development (n = 463 subjects) and testing (n = 123) and for an interobserver study (n = 65). A dataset from Link & ouml;ping University Hospital (n = 28) was used for external validation. The model's ability to detect coronary artery disease (CAD) was tested in a separate SCAPIS dataset (n = 684). A deep ensemble (k = 6) of a customized 3D vision transformer model was used for voxelwise classification. The Dice coefficient, the average surface distance, Pearson's correlation coefficient, analysis of segmented volumes by intraclass correlation coefficient (ICC), and agreement (sensitivity and specificity) were used to analyze model performance.ResultsPlaqueViT segmented coronary plaques with a Dice coefficient = 0.55, an average surface distance = 0.98 mm and ICC = 0.93 versus an expert reader. In the interobserver study, PlaqueViT performed as well as the expert reader (Dice coefficient = 0.51 and 0.50, average surface distance = 1.31 and 1.15 mm, ICC = 0.97 and 0.98, respectively). PlaqueViT achieved 88% agreement (sensitivity 97%, specificity 76%) in detecting any coronary plaque in the test dataset (n = 123) and 89% agreement (sensitivity 95%, specificity 83%) in the CAD detection dataset (n = 684).ConclusionWe developed a deep learning model for fully automatic plaque detection and segmentation that identifies and delineates coronary plaques and the arterial lumen with similar performance as an experienced reader.Key PointsQuestionA tool for fully automatic and voxelwise segmentation of coronary plaques in coronary CTA (CCTA) is important for both clinical and research usage of the CCTA examination.FindingsSegmentation of coronary artery plaques by PlaqueViT was comparable to an expert reader's performance.Clinical relevanceThis novel, fully automatic deep learning model for voxelwise segmentation of coronary plaques in CCTA is highly relevant for large population studies such as the Swedish CardioPulmonary BioImage Study.Key PointsQuestionA tool for fully automatic and voxelwise segmentation of coronary plaques in coronary CTA (CCTA) is important for both clinical and research usage of the CCTA examination.FindingsSegmentation of coronary artery plaques by PlaqueViT was comparable to an expert reader's performance.Clinical relevanceThis novel, fully automatic deep learning model for voxelwise segmentation of coronary plaques in CCTA is highly relevant for large population studies such as the Swedish CardioPulmonary BioImage Study.Key PointsQuestionA tool for fully automatic and voxelwise segmentation of coronary plaques in coronary CTA (CCTA) is important for both clinical and research usage of the CCTA examination.FindingsSegmentation of coronary artery plaques by PlaqueViT was comparable to an expert reader's performance.Clinical relevanceThis novel, fully automatic deep learning model for voxelwise segmentation of coronary plaques in CCTA is highly relevant for large population studies such as the Swedish CardioPulmonary BioImage Study.","2025-02-05","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","","","","","","","","","","","English","","","","WOS:001415216500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","ACUTE CHEST-PAIN; Computed tomography angiography; Computer-assisted; Coronary artery disease; CT ANGIOGRAPHY; DISEASE; Radiographic image interpretation; SOCIETY; STENOSIS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KD939QYR","journalArticle","2025","Kim, B; Belkilani, K; Heilscher, G; Otto, MO; Huh, JS; Suh, D","Integrated Spatiotemporal Hybrid Solar PV Generation Forecast Between Countries on Different Continents Using Transfer Learning Method","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3514098","","Solar photovoltaic (PV) generation is a cornerstone of sustainable energy production, but predicting its capacity across countries remains challenging due to factors like climate, terrain, and population density. To address this, a recent study proposed a novel approach using transfer learning, which is particularly valuable when historical data for newly established PV plants is limited. The study evaluated four PV plants in South Korea and Germany, selected for their diverse geographical and climatic conditions. The proposed CL-Transformer model outperformed established machine learning models such as LSTM, CNN-LSTM, and Transformer, consistently demonstrating superior predictive capabilities. Notably, when trained on Korean data and applied to both South Korea and Germany, the model achieved an average R (2) (adj) improvement of 23.5 %. When trained on German data, the improvement was even more pronounced at 67.3 %. Additionally, transfer learning experiments revealed up to a 50.6 % enhancement in R (2) (adj) across different plant scales. By integrating external weather variables and satellite data, this hybrid model provides valuable insights for accurate capacity prediction and strategic planning in deploying new PV plants, contributing to greater stability and efficiency in the power industry.","2025","2025-02-26 20:41:52","2025-02-26 20:41:52","","2486-2502","","","13","","","","","","","","","","English","","","","WOS:001392836900039","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","Accuracy; Autoregressive processes; Data models; Forecasting; Geostationary satellite; Meteorology; MODELS; NETWORKS; photovoltaics; POWER-GENERATION; PREDICTION; Predictive models; region of interest extraction; Satellite images; Solar power generation; spatiotemporal; transfer learning; Transfer learning; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HBUITCUM","journalArticle","2024","Tang, JS; Guan, YL; Zhao, SH; Wang, HB; Chen, YN","DGA Domain Detection Based on Transformer and Rapid Selective Kernel Network","ELECTRONICS","","2079-9292","10.3390/electronics13244982","","Botnets pose a significant challenge in network security by leveraging Domain Generation Algorithms (DGA) to evade traditional security measures. Extracting DGA domain samples is inherently complex, and the current DGA detection models often struggle to capture domain features effectively when facing limited training data. This limitation results in suboptimal detection performance and an imbalance between model accuracy and complexity. To address these challenges, this paper introduces a novel multi-scale feature fusion model that integrates the Transformer architecture with the Rapid Selective Kernel Network (R-SKNet). The proposed model employs the Transformer's encoder to couple the single-domain character elements with the multiple types of relationships within the global domain block. This paper proposes integrating R-SKNet into DGA detection and developing an efficient channel attention (ECA) module. By enhancing the branch information guidance in the SKNet architecture, the approach achieves adaptive receptive field selection, multi-scale feature capture, and lightweight yet efficient multi-scale convolution. Moreover, the improved Feature Pyramid Network (FPN) architecture, termed EFAM, is utilized to adjust channel weights for outputs at different stages of the backbone network, leading to achieving multi-scale feature fusion. Experimental results demonstrate that, in tasks with limited training samples, the proposed method achieves lower computational complexity and higher detection accuracy compared to mainstream detection models.","2024-12","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","24","13","","","","","","","","","","English","","","","WOS:001386914000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","botnet; depthwise separable convolution; domain generation algorithm; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KNMCPYS9","journalArticle","2024","Fei, X; Wei, HJ","Research on Ferrographic Image Fault Diagnosis Based on Channel Overlapping Technique and Information Fusion Mechanism","JOURNAL OF TRIBOLOGY-TRANSACTIONS OF THE ASME","","0742-4787","10.1115/1.4064858","","Utilizing computer technology to realize the application of ferrographic intelligent fault diagnosis technology is a foundational investigation to oversee the operations of mechanical equipment. To continuously improve the accuracy of artificial intelligence recognition, the complexity and computation of the model will be increased. The proposal of the transformer model (the core technology of chatgpt) has fundamentally changed the intelligence level of artificial intelligence, but it has also greatly increased the demand for computer computing power. What's more, it is difficult to equip industrial quality inspection sites with high computing power computers. The channel overlapping technique developed in this paper is a technology to segment the three channels of image information and reserve overlapping areas for an information communication mechanism. With this mechanism, the model location channel overlapping convolutional neural network can obtain high recognition accuracy by using only one-half of the original training computing power. When channel overlapping combines with no position information, information fusion is formed. The model channel overlapping technique fusion convolutional neural network established by the information fusion mechanism will get a higher prediction accuracy through joint training with the original image. However, the computation consumption is nearly one-third of the pure traditional convolutional neural network algorithm.","2024-07-01","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","7","146","","","","","","","","","","English","","","","WOS:001230846600003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","channel overlapping; deep learning; EVOLUTION; fault diagnosis; ferrographic image; information fusion; lubricant degradation; surface fatigue and fretting; surface fracture cracking; surfaces; WEAR DEBRIS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RMPALLKI","journalArticle","2024","Tang, LF; Luan, SX","Cosimulation of Bistable Permanent Magnet Circuit Breakers","IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS","","0278-0046","10.1109/TIE.2023.3265049","","The breaking and closing coils of bistable permanent magnet circuit breaker (PMCB) shares magnetic circuit, which leads to the fast time-varying nonlinear coupling relationship between the permanent magnetic field and the electromagnetic field, and between the breaking and closing magnetic circuits, which brings difficulty to its simulation. Aiming at the difficulty, this article designs a new cosimulation method: First, the equivalent magnetic circuit of the bistable permanent magnet actuator (PMA) is established, and the ternary correspondence relationship of its electromechanical parameters is proved analytically for the first time. Then, the ""equivalent electric circuit"" of magnetic circuit in dynamic process of bistable PMA is proposed for the first time by analogy with the transformer model, and the calculation method of the time-varying parameters in this model is given. Finally, the ""equivalent electric circuit"" of magnetic circuit is used as a link, so the hardware circuit, software strategy, and PMCB are connected together to form a point-by-point closed-loop cosimulation method. This simulation method can reflect the dynamic interaction between the electromagnetic field and the permanent magnetic field of the breaking and closing magnetic circuits, and also can reflect the dynamic interaction between the control module and the PMCB. So this method lays the foundation for simulation design of the high-performance bistable PMCB.","2024-03","2025-02-26 20:41:52","2025-02-26 20:41:52","","2800-2809","","3","71","","","","","","","","","","English","","","","WOS:001080899800059","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","Bistable PMCB; cosimulation; equivalent circuit; magnetic circuit coupling; SIMULATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K76MPAAD","journalArticle","2024","Xu, CJ; Sun, WR; Li, MX","DTT: A Dual-domain Transformer model for Network Intrusion Detection","EAI ENDORSED TRANSACTIONS ON SCALABLE INFORMATION SYSTEMS","","2032-9407","10.4108/eetsis.5445","","With the rapid evolution of network technologies, network attacks have become increasingly intricate and threatening. The escalating frequency of network intrusions has exerted a profound influence on both industrial settings and everyday activities. This underscores the urgent necessity for robust methods to detect malicious network traffic. While intrusion detection techniques employing Temporal Convolutional Networks (TCN) and Transformer architectures have exhibited commendable classification efficacy, most are confined to the temporal domain. These methods frequently fall short of encompassing the entirety of the frequency spectrum inherent in network data, thereby resulting in information loss. To mitigate this constraint, we present DTT, a novel dual-domain intrusion detection model that amalgamates TCN and Transformer architectures. DTT adeptly captures both high-frequency and low-frequency information, thereby facilitating the simultaneous extraction of local and global features. Specifically, we introduce a dual-domain feature extraction (DFE) block within the model. This block effectively extracts global frequency information and local temporal features through distinct branches, ensuring a comprehensive representation of the data. Moreover, we introduce an input encoding mechanism to transform the input into a format suitable for model training. Experiments conducted on two distinct datasets address concerns regarding data duplication and diverse attack types, respectively. Comparative experiments with recent intrusion detection models unequivocally demonstrate the superior performance of the proposed DTT model.","2024","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","6","11","","","","","","","","","","English","","","","WOS:001361283800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Dual-domain Feature Extraction; Input Encoding; Network Intrusion Detection; Temporal Convolutional Networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LJMGZG68","journalArticle","2024","Qin, Z; Zhang, YQ; Li, J; Li, DM; Mo, YQ; Wang, LY; Qian, PY; Feng, L","A reconstruction and convolution operations enabled variant vision transformer with gastroscopic images for automatic locating of polyps in Internet of Medical Things","INFORMATION FUSION","","1566-2535","10.1016/j.inffus.2023.102007","","Gastric polyps are an important cause of gastric disease. At present, the computer-aided diagnosis technology based on convolutional neural network (CNN) can automatically locate the position of polyps from the gastroscopic image, which improves the efficiency of doctors. However, due to the small polyp area in the gastroscopic image, the CNN-based method has a high rate of missed detection. To solve the above problems, in this work, we propose a reconstruction and convolution operations enabled variant vision transformer (RCVViT) to automatically locate the position of polyps in gastroscopic images. The RCVViT model uses the vision transformer model as a benchmark model. By using the self-attention mechanism, contextual information can be considered, and irregularly shaped polyps or polyps with small areas can be effectively detected. The feedforward neural network (FNN) and CNN are used to flatten each image patch data into a one-dimensional vector. The advantage of combining the FNN and CNN is that the local feature information and structural information of the polyp area are considered. In addition, we use an Internet of Medical Things (IoMT) platform to collect and analyze patients' medical data to make timely diagnosis of patients' diseases. Finally, our multiple experimental results on real gastroscopic datasets demonstrate the superiority of the RCVViT model.","2024-01","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","101","","","","","","","","","","English","","","","WOS:001079799500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","Gastric polyps; GASTRIC POLYPS; Internet of Medical Things; Reconstruction and convolution operation; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ENQTFAP5","journalArticle","2023","Dönmez, E; Kiliçarslan, S; Közkurt, C; Diker, A; Demir, FB; Elen, A","Identification of haploid and diploid maize seeds using hybrid transformer model","MULTIMEDIA SYSTEMS","","0942-4962","10.1007/s00530-023-01174-y","","Increasingly, more effective breeding techniques for new variations are preferred due to population growth and climatic change, particularly the accurate identification of the target variety. Maize haploid breeding technology, which can shorten the reproductive period and improve germplasm, has become the key to new maize breeding. In this study, a method in which deep features and image patches are analyzed together was proposed using a dataset consisting of 3000 different haploid/diploid type maize seed images in total. To achieve this objective, we adopted convolutional neural networks (CNNs) to recognize haploid and diploid maize seeds automatically through a transfer learning approach. More specifically, DenseNet201, ResNet152, ResNetRS50, RegNetX002, EfficientNetV2B0, EfficientB0, EfficientB1, EfficientB2, EfficientB3, EfficientB4, EfficientB5, EfficientB6, and EfficientB7 were applied for this specific task. The proposed hybrid model is inspired by both transfer learning and vision transformers. The error, accuracy, f1-score, recall, precision, and AUC of hybrid proposed model were 0.1491, 0.9633, and 0.9712, respectively. The accuracy rate reached, and the proposed model requires less processing in terms of complexity, which reveals the need for further investigation of such hybrid models. On the other hand, with the results obtained, it has been revealed that the maize seeds can be separated as haploid and diploid with traditional methods can be done much faster and without the need for an expert decision.","2023-12","2025-02-26 20:41:52","2025-02-26 20:41:52","","3833-3845","","6","29","","","","","","","","","","English","","","","WOS:001058995100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","CNN; Deep learning; Haploid and diploid maize; KERNELS; ResMLP; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8JWZZCZ8","journalArticle","2023","Zeynali, M; Seyedarabi, H; Afrouzian, R","Classification of EEG signals using Transformer based deep learning and ensemble models","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2023.105130","","A Brain-Computer Interface (BCI) is a communication and control system designed to provide interaction be-tween a user and a computer device. This interaction is based on the brain's electrical signals that are generated when users do specific tasks. Different categories of visual stimuli evoke distinct activation patterns in the human brain. The generated patterns can be recorded with EEG signals for use in BCI applications. Recently, deep learning-based Transformer models have demonstrated significant potential for analyzing diverse data. In this paper, a new Transformer-based model has been presented that extracts temporal and spectral features from EEG signals for classification purposes. The proposed Spectral Transformer model converts the EEG signal to the frequency domain using PSD before applying Transformer models to extract frequency features. Deep ensemble learning models are used to enhance the generalization performance of the final model by combining the benefits of both deep learning models and ensemble learning. The proposed ensemble model combines Temporal and Spectral Transformers to simultaneously utilize the time and frequency features of the signal. The accuracy of 96.1 %, 94.20 %, and 93.60 % are achieved using an ensemble model, Temporal Transformer, and Spectral Transformer, respectively. These results demonstrate the effectiveness of the proposed model for accurately classifying EEG signals in BCI applications.","2023-09","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","86","","","","","","","","","","English","","","","WOS:001023612900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Brain -Computer Interface (BCI); COLOR; Electroencephalography (EEG); Ensemble learning; NEURAL-NETWORKS; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5SBSVGFB","journalArticle","2023","Zhang, F; Nghiem, L; Chen, ZX","Evaluating reservoir performance using a transformer based proxy model","GEOENERGY SCIENCE AND ENGINEERING","","2949-8929","10.1016/j.geoen.2023.211644","","In reservoir simulation, proxy models have been used to explore relationships between explanatory variables (e. g., porosity, permeability, well locations and constraints) and response variables (e.g., production rates and bottom hole pressure). Compared to traditional methods used in the proxy models such as capacitance-resistance model (CRM), and interwell numerical Simulation model (INSIM), deep learning methods such as Recurrent Neural Networks (RNNs) have achieved remarkable advancement in predicting reservoir production and assessing uncertainty. However, one limitation of the RNNs is that they are hard to parallelize, which makes their training process computationally expensive. In this paper, a Transformer based proxy model, which is effective in processing sequential data, is developed to accelerate learning and simulation processes. Different types of data are embedded and concatenated as input sequences including water injection, drilling decision, well position, porosity, and permeability. Incorporating additional important information like operational and geological data is found to improve the accuracy of simulation significantly compared to sole injection data input. The model based on a sequence-to-sequence architecture can also be extrapolated to a longer horizon. Both RNNs and Transformer models are used to compare the result accuracy and computation speed. It is found that the Transformer model can be four times faster than the RNNs model under the same order of accuracy.","2023-07","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","226","","","","","","","","","","English","","","","WOS:001053944400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","Attention mechanisms; Deep Learning; Time series; Transformer; Waterflooding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WFSNEJH9","journalArticle","2023","Akre, S; Fofana, I; Yéo, Z; Brettschneider, S; Kung, P; Sékongo, B","On the Feasibility of Monitoring Power Transformer's Winding Vibration and Temperature along with Moisture in Oil Using Optical Sensors","SENSORS","","1424-8220","10.3390/s23042310","","Despite major progress in the design of power transformers, the Achilles' heel remains the insulation system, which is affected by various parameters including moisture, heat, and vibrations. These important machines require extreme reliability to guarantee electricity distribution to end users. In this contribution, a fiber optic sensor (FOS), consisting of a Fabry-Perot cavity made up of two identical fiber Bragg gratings (FBGs), is proposed, to monitor the temperature and vibration of power transformer windings. A phase shifted gratings recoated sensor, with multilayers of polyimide films, is used to monitor the moisture content in oil. The feasibility is investigated using an experimental laboratory transformer model, especially fabricated for this application. The moisture contents are well correlated with those measured by a Karl Fisher titrator, while the values of temperature compare well with those recorded from thermocouples. It is also shown that the sensors can be used to concurrently detect vibration, as assessed by sensitivity to the loading current. The possibility of dynamically measuring humidity, vibrations, and temperatures right next to the winding, appears to be a new insight that was previously unavailable. This approach, with its triple ability, can help to reduce the required number of sensors and therefore simplify the wiring layout.","2023-02","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","4","23","","","","","","","","","","English","","","","WOS:000942084600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","FIBER; fiber Bragg grating; moisture content; power transformer; SYSTEM; temperature; vibration; WATER; winding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TZFMCL6X","journalArticle","2024","Yu, JX; Chen, Z; Wang, JK; Kong, LH; Yan, JJ; Gu, W","Enhancing Image Super-Resolution with Dual Compression Transformer","VISUAL COMPUTER","","0178-2789","10.1007/s00371-024-03696-6","","Transformer-based methods have demonstrated substantial advancements in image super-resolution (SR). However, their success requires a high computational cost. One reason is that the Transformer uses computationally expensive self-attention in its cascaded layers, which has quadratic computational complexity with respect to the number of input tokens. In this work, we propose a novel Transformer model, the dual compression Transformer (DCT), for image SR. Our DCT compresses self-attention computations within and between layers. Specifically, we propose the linear self-attention (L-SA) using a carefully designed linear approximation normalization function, which compresses the quadratic complexity within the layer to linear complexity by approximating the Softmax\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$${{\,\textrm{Softmax}\,}}$$\end{document} operation. Additionally, we propose the linear-window self-attention (LW-SA), which combines L-SA with window-based self-attention (W-SA) to better leverage the global context. Furthermore, we design an approximate attention module (AAM) to replace self-attention computations within the layer. To achieve compressed attention computations between layers, we alternate using LW-SA and AAM within the traditional cascade framework. Extensive experiments demonstrate that our DCT outperforms current state-of-the-art methods with superior performance and reduced computational complexity. The code is available at https://github.com/zhengchen1999/DCT.","2024-12-17","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","","","","","","","","","","","English","","","","WOS:001379342000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Image Super-Resolution; Linear Self-Attention; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X3QRR85H","journalArticle","2024","Dwivedi, T; Chaurasia, BK; Shukla, MM","Lightweight vision image transformer (LViT) model for skin cancer disease classification","INTERNATIONAL JOURNAL OF SYSTEM ASSURANCE ENGINEERING AND MANAGEMENT","","0975-6809","10.1007/s13198-024-02521-6","","Skin cancer (SC) is a lethal disease not only in India but also in the world; there are more than a million cases of melanoma per year in India. Early detection of skin cancer through accurate classification of skin lesions is essential for effective treatment. Visual inspection by clinical screening, dermoscopy, or histological tests is strongly emphasised in today's skin cancer diagnosis. It can be challenging to determine the kind of skin cancer, especially in the early stages, due to the resemblance among cancer types. However, the precise classification of skin lesions could be time-consuming and challenging for dermatologists. To address these issues, we propose transfer learning to accurately classify skin lesions into several forms of skin cancer using a lightweight B-16 Vision Image Transformer model (LViT). An extensive dataset is used in the experiment to verify the efficiency of the proposed LViT model. The LViT model can classify skin cancer with high accuracy, sensitivity, and specificity and generalise favourably to new images. The proposed model has a 93.17% accuracy rating for classifying SC images over 25 epochs and a remarkable accuracy of 95.82% over 100 epochs. The proposed LViT model is lightweight, requires minimal processing resources, and achieves good accuracy on small and enormous data sets.","2024-10","2025-02-26 20:41:52","2025-02-26 20:41:52","","5030-5055","","10","15","","","","","","","","","","English","","","","WOS:001316353800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","Benign; Malignant; Skin-cancer; Transfer learning; Vision transformer; ViT-B16","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L7GMETAV","journalArticle","2024","Sibilano, E; Buongiorno, D; Lassi, M; Grippo, A; Bessi, V; Sorbi, S; Mazzoni, A; Bevilacqua, V; Brunetti, A","Understanding the Role of Self-Attention in a Transformer Model for the Discrimination of SCD From MCI Using Resting-State EEG","IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS","","2168-2194","10.1109/JBHI.2024.3390606","","The identification of EEG biomarkers to discriminate Subjective Cognitive Decline (SCD) from Mild Cognitive Impairment (MCI) conditions is a complex task which requires great clinical effort and expertise. We exploit the self-attention component of the Transformer architecture to obtain physiological explanations of the model's decisions in the discrimination of 56 SCD and 45 MCI patients using resting-state EEG. Specifically, an interpretability workflow leveraging attention scores and time-frequency analysis of EEG epochs through Continuous Wavelet Transform is proposed. In the classification framework, models are trained and validated with 5-fold cross-validation and evaluated on a test set obtained by selecting 20% of the total subjects. Ablation studies and hyperparameter tuning tests are conducted to identify the optimal model configuration. Results show that the best performing model, which achieves acceptable results both on epochs' and patients' classification, is capable of finding specific EEG patterns that highlight changes in the brain activity between the two conditions. We demonstrate the potential of attention weights as tools to guide experts in understanding which disease-relevant EEG features could be discriminative of SCD and MCI.","2024-06","2025-02-26 20:41:52","2025-02-26 20:41:52","","3422-3433","","6","28","","","","","","","","","","English","","","","WOS:001242344200012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Alzheimer's disease; ALZHEIMERS ASSOCIATION WORKGROUPS; Biological system modeling; Biomarkers; Brain modeling; CLASSIFICATION; Context modeling; DIAGNOSTIC GUIDELINES; DISEASE; Electroencephalography; interpretability; multi-head attention; NATIONAL INSTITUTE; RECOMMENDATIONS; resting-state EEG; Task analysis; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"69CQCKBP","journalArticle","2024","Naidji, MR; Elberrichi, Z","A Novel Hybrid Vision Transformer CNN for COVID-19 Detection from ECG Images","COMPUTERS","","2073-431X","10.3390/computers13050109","","The emergence of the novel coronavirus in Wuhan, China since 2019, has put the world in an exotic state of emergency and affected millions of lives. It is five times more deadly than Influenza and causes significant morbidity and mortality. COVID-19 mainly affects the pulmonary system leading to respiratory disorders. However, earlier studies indicated that COVID-19 infection may cause cardiovascular diseases, which can be detected using an electrocardiogram (ECG). This work introduces an advanced deep learning architecture for the automatic detection of COVID-19 and heart diseases from ECG images. In particular, a hybrid combination of the EfficientNet-B0 CNN model and Vision Transformer is adopted in the proposed architecture. To our knowledge, this study is the first research endeavor to investigate the potential of the vision transformer model to identify COVID-19 in ECG data. We carry out two classification schemes, a binary classification to identify COVID-19 cases, and a multi-class classification, to differentiate COVID-19 cases from normal cases and other cardiovascular diseases. The proposed method surpasses existing state-of-the-art approaches, demonstrating an accuracy of 100% and 95.10% for binary and multiclass levels, respectively. These results prove that artificial intelligence can potentially be used to detect cardiovascular anomalies caused by COVID-19, which may help clinicians overcome the limitations of traditional diagnosis.","2024-05","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","5","13","","","","","","","","","","English","","","","WOS:001233716100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","cardiovascular diseases; CLASSIFICATION; COVID-19; deep learning; ECG; INTERVAL; MYOCARDIAL-INFARCTION; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L6HEPB4A","journalArticle","2023","Santos, VO; Rocha, PAC; The, JV; Gharabaghi, B","Graph-Based Deep Learning Model for Forecasting Chloride Concentration in Urban Streams to Protect Salt-Vulnerable Areas","ENVIRONMENTS","","2076-3298","10.3390/environments10090157","","In cold-climate regions, road salt is used as a deicer for winter road maintenance. The applied road salt melts ice and snow on roads and can be washed off through storm sewer systems into nearby urban streams, harming the freshwater ecosystem. Therefore, aiming to develop a precise and accurate model to determine future chloride concentration in the Credit River in Ontario, Canada, the present work makes use of a ""Graph Neural Network""-""Sample and Aggregate"" (GNN-SAGE). The proposed GNN-SAGE is compared to other models, including a Deep Neural Network-based transformer (DNN-Transformer) and a benchmarking persistence model for a 6 h forecasting horizon. The proposed GNN-SAGE surpassed both the benchmarking persistence model and the DNN-Transformer model, achieving RMSE and R2 values of 51.16 ppb and 0.88, respectively. Additionally, a SHAP analysis provides insight into the variables that influence the model's forecasting, showing the impact of the spatiotemporal neighboring data from the network and the seasonality variables on the model's result. The GNN-SAGE model shows potential for use in the real-time forecasting of water quality in urban streams, aiding in the development of regulatory policies to protect vulnerable freshwater ecosystems in urban areas.","2023-09","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","9","10","","","","","","","","","","English","","","","WOS:001078449600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","BIODIVERSITY; COVER; Credit River; graph neural networks; IMPACTS; IMPROVE; LOW-FLOW NITRATE; LSTM; machine learning; pollution; RIVER; SALINITY; SHAP analysis; WATER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z5U9TALI","journalArticle","2023","Pang, DH; Wang, H; Ma, J; Liang, D","DCTN: a dense parallel network combining CNN and transformer for identifying plant disease in field","SOFT COMPUTING","","1432-7643","10.1007/s00500-023-09071-2","","Crop diseases can have a detrimental impact on crop growth, resulting in a significant reduction in crop yield. Therefore, accurate detection of these diseases is crucial for enhancing crop productivity. Despite notable advancements in deep learning techniques for disease identification, most experiments have been conducted under simplified laboratory conditions, posing challenges for accurately identifying crop diseases in complex real-world field environments. To bridge this gap, we draw inspiration from the Transformer model's ability to capture long-range global dependencies and handle occlusion. We propose a novel approach called Dense CNNs and Transformer Network (DCTN) for accurate detection of field crop diseases. Moreover, we introduce a new attention mechanism that utilizes multi-head self-attention via deep separable convolution projection and down-sampling, significantly enhancing computational efficiency. Additionally, we have meticulously curated and cleaned a dataset of 45,547 images depicting healthy and diseased crops in real-field environments. Our proposed method demonstrates superior performance, particularly in terms of its robustness against background interference in crop disease detection. Notably, DCTN achieves accuracies of 93.01% and 99.69% on our dataset and a publicly available dataset, respectively. For those who are interested, the code for our approach will be made available on https://github.com/wh9704/DCTN.","2023-11","2025-02-26 20:41:52","2025-02-26 20:41:52","","15549-15561","","21","27","","","","","","","","","","English","","","","WOS:001056993400007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Convolutional neural networks; Deep learning; Plant pathology recognition; RECOGNITION; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W4BS7GCM","journalArticle","2023","Li, RL; Zeng, DL; Li, TT; Ti, BZ; Hu, Y","Real-time prediction of SO2 emission concentration under wide range of variable loads by convolution-LSTM VE-transformer","ENERGY","","0360-5442","10.1016/j.energy.2023.126781","","In this paper, a sulfur dioxide (SO2) emission concentration real-time dynamic prediction model is proposed to achieve the control target of ultra-low SO2 emissions , economical desulfurization system operation at a large-scale coal-fired power plant. First, a vision-expansion self-attention strategy is adopted on the Transformer al-gorithm structure for better time-series information feature extraction. Second, to adapt to the vision-expansion self-attention strategy, convolution and long short-term memory (LSTM) are combined to process input infor-mation position encoding, which can obtain long time-series information absolute position encoding. Then, a Convolution-LSTM VE-Transformer model is constructed by combining the above two proposed parts. The mutual information method and the differential evolution algorithm are combined to calculate correlations between variables and obtain the optimal delay time. Finally, a real-time dynamic prediction model of SO2 is established. In this model, the structure of the input and output variables is determined by the delay time and the influence of coal quality on the SO2 concentration. The quantitative comparison results show the superior ac-curacy and generalization ability of the proposed prediction model to related popular methods, indicating that the model has strong potential for use in further controller design and applications.","2023-04-15","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","269","","","","","","","","","","English","","","","WOS:000963440800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;18<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","COAL-FIRED BOILER; Convolution-LSTM; Convolution-LSTM VE-Transformer; Dynamic model; MODELS; NOX EMISSION; SO2 emission concentration; Vision-expansion self-attention","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"36KP4TWG","journalArticle","2022","Nogueira, AFR; Oliveira, HS; Machado, JJM; Tavares, JMRS","Transformers for Urban Sound Classification-A Comprehensive Performance Evaluation","SENSORS","","1424-8220","10.3390/s22228874","","Many relevant sound events occur in urban scenarios, and robust classification models are required to identify abnormal and relevant events correctly. These models need to identify such events within valuable time, being effective and prompt. It is also essential to determine for how much time these events prevail. This article presents an extensive analysis developed to identify the best-performing model to successfully classify a broad set of sound events occurring in urban scenarios. Analysis and modelling of Transformer models were performed using available public datasets with different sets of sound classes. The Transformer models' performance was compared to the one achieved by the baseline model and end-to-end convolutional models. Furthermore, the benefits of using pre-training from image and sound domains and data augmentation techniques were identified. Additionally, complementary methods that have been used to improve the models' performance and good practices to obtain robust sound classification models were investigated. After an extensive evaluation, it was found that the most promising results were obtained by employing a Transformer model using a novel Adam optimizer with weight decay and transfer learning from the audio domain by reusing the weights from AudioSet, which led to an accuracy score of 89.8% for the UrbanSound8K dataset, 95.8% for the ESC-50 dataset, and 99% for the ESC-10 dataset, respectively.","2022-11","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","22","22","","","","","","","","","","English","","","","WOS:000887695500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Adam optimizer; convolutional neural network; data augmentation; deep learning; urban sounds' classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VU8QQS5P","journalArticle","2022","Liu, SC; Fan, QC; Liu, SH; Zhao, CJ","DepthFormer: A High-Resolution Depth-Wise Transformer for Animal Pose Estimation","AGRICULTURE-BASEL","","2077-0472","10.3390/agriculture12081280","","Animal pose estimation has important value in both theoretical research and practical applications, such as zoology and wildlife conservation. A simple but effective high-resolution Transformer model for animal pose estimation called DepthFormer is provided in this study to address the issue of large-scale models for multi-animal pose estimation being problematic with limited computing resources. We make good use of a multi-branch parallel design that can maintain high-resolution representations throughout the process. Along with two similarities, i.e., sparse connectivity and weight sharing between self-attention and depthwise convolution, we utilize the delicate structure of the Transformer and representative batch normalization to design a new basic block for reducing the number of parameters and the amount of computation required. In addition, four PoolFormer blocks are introduced after the parallel network to maintain good performance. Benchmark evaluation is performed on a public database named AP-10K, which contains 23 animal families and 54 species, and the results are compared with the other six state-of-the-art pose estimation networks. The results demonstrate that the performance of DepthFormer surpasses that of other popular lightweight networks (e.g., Lite-HRNet and HRFormer-Tiny) when performing this task. This work can provide effective technical support to accurately estimate animal poses with limited computing resources.","2022-08","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","8","12","","","","","","","","","","English","","","","WOS:000846368700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","animal pose estimation; depthformer; depthwise convolution; multi-resolution representations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"STFHRY2J","journalArticle","2022","Jing, YT; Wang, XW; Yu, ZY; Wang, CY; Liu, ZM; Li, Y","Diagnostic Research for the Failure of Electrical Transformer Winding Based on Digital Twin Technology","IEEJ TRANSACTIONS ON ELECTRICAL AND ELECTRONIC ENGINEERING","","1931-4973","10.1002/tee.23670","","Transformer is a key equipment for constructing power system, and its safe and stable operation is the basis of power system. In order to solve the problems of difficult identification and low detection accuracy of transformer winding at operating state, in this paper, a diagnosis method based on digital twinning technique for transformer winding failure is proposed. Firstly a digital twin transformer model with high simulation degree based on transformer entities was built, and then multiple physical field simulation were used to deduce the information change of oil tank surface vibration information of digital twin transformer under different working conditions, various winding failures. Here, the vibration signal on oil tank is effectively decomposed to extract the feature vector by independent component analysis method and wavelet packet transform, which in turn is based on neural network algorithm to learn and diagnose the failure signal of winding. In order to test the accuracy and feasibility of the method, the diagnostic test of oil tank vibration signal detection of health and fault transformer is carried out on an experimental prototype of transformer with 110 kV, and the diagnostic results show that this method can diagnose the problems occurred in transformer windings with high efficiency and accuracy. (c) 2022 Institute of Electrical Engineers of Japan. Published by Wiley Periodicals LLC.","2022-11","2025-02-26 20:41:52","2025-02-26 20:41:52","","1629-1636","","11","17","","","","","","","","","","English","","","","WOS:000820131300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;15</p>","","","DEFORMATION; digital twinning technique; independent component analysis method; power transformer; VIBRATION; wavelet packet transforms; winding failure diagnosis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QJCZBFML","journalArticle","2021","Al-Ameri, SMAN; Kamarudin, MS; Yousof, MFM; Salem, AA; Banakhr, FA; Mosaad, MI; Abu-Siada, A","Understanding the Influence of Power Transformer Faults on the Frequency Response Signature Using Simulation Analysis and Statistical Indicators","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2021.3076984","","Frequency Response Analysis (FRA) is the most reliable technique currently used to evaluate the mechanical integrity of power transformers. While the measurement devices have been well developed over the past two decades, interpretation of the FRA signatures is still challenging regardless of the several papers published in this regard. This paper adds an attempt to understand the power transformer FRA signatures through experimental and simulation analyses. In this context, experimental FRA measurements are conducted on a 33/11 kV, 30 MVA transformer under various faults, including winding deformation, the short circuit turns, loss of clamping, and bushing fault. At the same time, the high-frequency transformer model that comprises series capacitance, self-inductance, series resistance, and mutual inductance is simulated using MATLAB / Simulink to compare simulation and experimental results. The correlation between physical circuit parameters and various faults facilitates a better understanding of each fault's effect on the FRA signature. To quantify the impact of such faults, correlation coefficient, the absolute sum of logarithmic error, standard deviation, and sum square error are calculated with respect to the healthy signature at three frequency regions. Results show that using statistical coefficients over three frequency ranges of the FRA signature facilitates better fault identification and quantification.","2021","2025-02-26 20:41:52","2025-02-26 20:41:52","","70935-70947","","","9","","","","","","","","","","English","","","","WOS:000652049800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;22<br/>Total Times Cited:&nbsp;&nbsp;24<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Analytical models; Capacitance; Circuit faults; fault diagnosis; frequency response analysis; Integrated circuit modeling; Oil insulation; Power transformer; Power transformer insulation; statistical indicators; Windings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WNTVG64V","journalArticle","2024","Li, HD; Huang, LS; Ruan, C; Huang, WJ; Wang, CJ; Zhao, JL","A dual-branch neural network for crop disease recognition by integrating frequency domain and spatial domain information","COMPUTERS AND ELECTRONICS IN AGRICULTURE","","0168-1699","10.1016/j.compag.2024.108843","","Crop diseases severely affect crop yield and quality, and accurate identification of crop diseases is crucial for disease management. Although deep neural networks have made progress in the task of crop disease identification, the complex environment of crop diseases, including background interference, morphological differences, and scale variations, has led to limited accuracy in disease recognition. To address these issues, this study proposes a dual-branch deep neural network for crop disease identification, integrating both frequency domain and spatial domain information. The frequency branch takes frequency domain information as input to extract rich crop disease frequency component features, while the deformable attention Transformer branch excels in representing global features and selectively focusing on local features of crop diseases. A new fusion method, Multi-Spectral Channel Attention Fusion (MSAF), is adopted to better integrate crop disease frequency and spatial features. Additionally, an improved bias loss function (cv_bias) is proposed to optimize the dual-branch network model, achieving an accuracy of 96.7 % on the test dataset, which is 2.0 % higher than the existing stateof-the-art deformable attention Transformer model. With only 14 M model parameters, this study's model provides an effective method for future applications in complex environment.","2024-04","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","219","","","","","","","","","","English","","","","WOS:001214396700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Complex environment; Crop disease; Deep neural network; Dual-branch neural network; Frequency and spatial features","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SLT9YHRK","journalArticle","2024","Huang, JH; Tang, ZC; He, XD; Zhou, J; Zhou, DF; Chen, CYC","Progressive network based on detail scaling and texture extraction: A more general framework for image deraining","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2023.127066","","Many feature extraction components have been proposed for image deraining tasks, aiming to improve feature learning. However, few models have addressed the integration of multi-scale features from derain images. The fusion of multiple features at different scales in one model has the potential to significantly enhance the authenticity and detail of rainy images restoration. This study introduces a migratable multi-scale feature blending model, which is a progressive learning model based on detail dilation and texture extraction. First, the degraded image is sent to the detail dilation module, which is designed to increase the detailed outline and obtain the coarse image features. Second, the extracted feature maps are sent to the multi-scale feature extraction (MFE) module and the multi-scale hybrid strategy (MHS) module for improved texture restoration. Third, the simple convolution modules are replaced by an optimized transformer model to more efficiently extract contextual features and multi-scale information in images. Finally, a progressive learning strategy is employed to incrementally restore the degraded images. Empirical results show that our proposed module for progressive restoration achieves near state-of-the-art performance in several rain removal tasks. In particular, our model exhibits better rain removal realism compared to state-of-the-art models. The source code is available at https://github.com/JackAILab/DTPNet.","2024-02-01","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","568","","","","","","","","","","English","","","","WOS:001126393500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","Image deraining; MODEL; Multi-scale feature blending; Progressive learning; REMOVAL; SINGLE IMAGE; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WZEFK64A","journalArticle","2023","Zhao, Q; Liu, F; Song, YD; Fan, XY; Wang, Y; Yao, YD; Mao, Q; Zhao, Z","Predicting Respiratory Rate from Electrocardiogram and Photoplethysmogram Using a Transformer-Based Model","BIOENGINEERING-BASEL","","2306-5354","10.3390/bioengineering10091024","","The respiratory rate (RR) serves as a critical physiological parameter in the context of both diagnostic and prognostic evaluations. Due to the challenges of direct measurement, RR is still predominantly measured through the traditional manual counting-breaths method in clinic practice. Numerous algorithms and machine learning models have been developed to predict RR using physiological signals, such as electrocardiogram (ECG) or/and photoplethysmogram (PPG) signals. Yet, the accuracy of these existing methods on available datasets remains limited, and their prediction on new data is also unsatisfactory for actual clinical applications. In this paper, we proposed an enhanced Transformer model with inception blocks for predicting RR based on both ECG and PPG signals. To evaluate the generalization capability on new data, our model was trained and tested using subject-level ten-fold cross-validation using data from both BIDMC and CapnoBase datasets. On the test set, our model achieved superior performance over five popular deep-learning-based methods with mean absolute error (1.2) decreased by 36.5% and correlation coefficient (0.85) increased by 84.8% compared to the best results of these models. In addition, we also proposed a new pipeline to preprocess ECG and PPG signals to improve model performance. We believe that the development of the TransRR model is expected to further expedite the clinical implementation of automatic RR estimation.","2023-09","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","9","10","","","","","","","","","","English","","","","WOS:001145113700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","deep learning; ECG; PPG; respiratory rate prediction; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ILJCFUCF","journalArticle","2023","Khanmohammadi, R; Mirshafiee, MS; Jouryabi, YR; Mirroshandel, SA","Prose2Poem: The Blessing of Transformers in Translating Prose to Persian Poetry","ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING","","2375-4699","10.1145/3592791","","Persian poetry has consistently expressed its philosophy, wisdom, speech, and rationale based on its couplets, making it an enigmatic language on its own to both native and non-native speakers. Nevertheless, the noticeable gap between Persian prose and poems has left the two pieces of literature mediumless. Having curated a parallel corpus of prose and their equivalent poems, we introduce a novel Neural Machine Translation approach for translating prose to ancient Persian poetry using transformer-based language models in an exceptionally low-resource setting. Translating input prose into ancient Persian poetry presents two primary challenges: In addition to being reasonable in conveying the same context as the input prose, the translation must also satisfy poetic standards. Hence, we designed our method consisting of three stages. First, we trained a transformer model from scratch to obtain an initial translations of the input prose. Next, we designed a set of heuristics to leverage contextually rich initial translations and produced a poetic masked template. In the last stage, we pretrained different variations of BERT on a poetry corpus to use the masked language modelling technique to obtain final translations. During the evaluation process, we considered both automatic and human assessment. The final results demonstrate the eligibility and creativity of our novel heuristically aided approach among Literature professionals and non-professionals in generating novel Persian poems.","2023-06","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","6","22","","","","","","","","","","English","","","","WOS:001018562700016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","low-resource language; Machine translation; Persian poetry; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GV94PYBG","journalArticle","2023","Wei, SQ; Wu, B; Xiang, AX; Zhu, YF; Song, CG","DGTR: Dynamic graph transformer for rumor detection","FRONTIERS IN RESEARCH METRICS AND ANALYTICS","","2504-0537","10.3389/frma.2022.1055348","","Social media rumors have the capacity to harm the public perception and the social progress. The news propagation pattern is a key clue for detecting rumors. Existing propagation-based rumor detection methods represent propagation patterns as a static graph structure. They simply consider the structure information of news distribution in social networks and disregard the temporal information. The dynamic graph is an effective modeling tool for both the structural and temporal information involved in the process of news dissemination. Existing dynamic graph representation learning approaches struggle to capture the long-range dependence of the structure and temporal sequence as well as the rich semantic association between full graph features and individual parts. We build a transformer-based dynamic graph representation learning approach for rumor identification DGTR to address the aforementioned challenges. We design a position embedding format for the graph data such that the original transformer model can be utilized for learning dynamic graph representations. The model can describe the structural long-range reliance between the dynamic graph nodes and the temporal long-range dependence between the temporal snapshots by employing a self-attention mechanism. In addition, the CLS token in transformer may model the rich semantic relationships between the complete graph and each subpart. Extensive experiments demonstrate the superiority of our model when compared to the state of the art.","2023-01-11","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","7","","","","","","","","","","English","","","","WOS:001379245000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","dynamic graph; neural network; rumor detection; rumor propagation; SOCIAL MEDIA; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3YREPXSP","journalArticle","2022","Demirkiran, F; Çayir, A; Ünal, G; Dag, H","An ensemble of pre-trained transformer models for imbalanced multiclass malware classification","COMPUTERS & SECURITY","","0167-4048","10.1016/j.cose.2022.102846","","Classification of malware families is crucial for a comprehensive understanding of how they can infect devices, computers, or systems. Hence, malware identification enables security researchers and incident responders to take precautions against malware and accelerate mitigation. API call sequences made by malware are widely utilized features by machine and deep learning models for malware classification as these sequences represent the behavior of malware. However, traditional machine and deep learning models remain incapable of capturing sequence relationships among API calls. Unlike traditional machine and deep learning models, the transformer-based models process the sequences in whole and learn relationships among API calls due to multi-head attention mechanisms and positional embeddings. Our experiments demonstrate that the Transformer model with one transformer block layer surpasses the performance of the widely used base architecture, LSTM. Moreover, BERT or CANINE, the pre-trained transformer models, outperforms in classifying highly imbalanced malware families according to evaluation metrics: F1-score and AUC score. Furthermore, our proposed bagging-based random transformer forest (RTF) model, an ensemble of BERT or CANINE, reaches the state-of-the-art evaluation scores on the three out of four datasets, specifically it captures a state-of-the-art F1-score of 0.6149 on one of the commonly used benchmark dataset. (C) 2022 Elsevier Ltd. All rights reserved.","2022-10","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","121","","","","","","","","","","English","","","","WOS:000881541300005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;20<br/>Total Times Cited:&nbsp;&nbsp;22<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","API Calls; BERT; CANINE; Ensemble; Imbalanced; Malware classification; Multiclass; Tokenization-free; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XKLIW9NR","journalArticle","2023","Heo, YJ; Yeo, WH; Kim, BG","DeepFake detection algorithm based on improved vision transformer","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-022-03867-9","","A DeepFake is a manipulated video made with generative deep learning technologies, such as generative adversarial networks or auto encoders that anyone can utilize. With the increase in DeepFakes, classifiers consisting of convolutional neural networks (CNN) that can distinguish them have been actively created. However, CNNs have a problem with overfitting and cannot consider the relation between local regions as global feature of image, resulting in misclassification. In this paper, we propose an efficient vision transformer model for DeepFake detection to extract both local and global features. We combine vector-concatenated CNN feature and patch-based positioning to interact with all positions to specify the artifact region. For the distillation token, the logit is trained using binary cross entropy through the sigmoid function. By adding this distillation, the proposed model is generalized to improve performance. From experiments, the proposed model outperforms the SOTA model by 0.006 AUC and 0.013 f1 score on the DFDC test dataset. For 2,500 fake videos, the proposed model correctly predicts 2,313 as fake, whereas the SOTA model predicts 2,276 in the best performance. With the ensemble method, the proposed model outperformed the SOTA model by 0.01 AUC. For Celeb-DF (v2) dataset, the proposed model achieves a high performance of 0.993 AUC and 0.978 f1 score, respectively.","2023-04","2025-02-26 20:41:52","2025-02-26 20:41:52","","7512-7527","","7","53","","","","","","","","","","English","","","","WOS:000830340500005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;33<br/>Total Times Cited:&nbsp;&nbsp;33<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Deep learning; Deepfake detection; Distillation; Generative adversarial network; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U27L9I4E","journalArticle","2021","Sharda, S; Singh, M; Sharma, K","RSAM: Robust Self-Attention Based Multi-Horizon Model for Solar Irradiance Forecasting","IEEE TRANSACTIONS ON SUSTAINABLE ENERGY","","1949-3029","10.1109/TSTE.2020.3046098","","With the widespread adoption of renewable energy sources in the smart grid era, there is an utmost requirement to develop prediction models that can accurately forecast solar irradiance. The stochastic nature of solar irradiance considerably affects photo-voltaic (PV) power generation. Since weather conditions have a high impact on solar irradiance; therefore, we need weather-conscious forecasting models to boost predictive accuracy. Although Recurrent Neural Networks (RNNs) has shown considerable performance in time-series forecasting problems, its sequential nature prohibits parallelized computing. Recently, architectures based on self-attention mechanism have shown remarkable success in natural language programming (NLP), while being computationally superior. In this paper, we propose an RSAM (Robust Self-Attention Multi-horizon) forecasting architecture, which mainly works in two parts: First, multi-horizon forecasting of solar irradiance using multiple weather parameters; Second, prediction interval analysis for model robustness using quantile regression. A self-attention based Transformer model belonging to the family of deep learning models has been utilized for multi-variate solar time-series forecasting. Using the National Renewable Energy Laboratory (NREL) benchmark datasets of two different sites, we demonstrate that the proposed approach exhibit enhanced performance in comparison to RNN models in terms of RMSE, MAE, MBE, and Forecast skill at each forecasted interval.","2021-04","2025-02-26 20:41:52","2025-02-26 20:41:52","","1394-1405","","2","12","","","","","","","","","","English","","","","WOS:000633439300057","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;54<br/>Total Times Cited:&nbsp;&nbsp;56<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Attention model; Computational modeling; Data models; deep learning; Deep learning; Forecasting; PREDICTION; prediction interval; Predictive models; Probabilistic logic; quantile regression; solar forecasting; transformer; Weather forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K2ZDLFU8","journalArticle","2024","Pak, P; Ogoke, F; Polonsky, A; Garland, A; Bolintineanu, DS; Moser, DR; Arnhart, M; Madison, J; Ivanoff, T; Mitchell, J; Jared, B; Salzbrenner, B; Heiden, MJ; Farimani, AB","ThermoPore: Predicting part porosity based on thermal images using deep learning","ADDITIVE MANUFACTURING","","2214-8604","10.1016/j.addma.2024.104503","","Part qualification is often a critical and labor-intensive process in additive manufacturing, particularly in the detection of defects such as porosity, which stands to benefit significantly from advancements in machine learning. We present a deep learning approach for quantifying and localizing ex-situ porosity within Laser Powder Bed Fusion fabricated samples utilizing in-situ thermal image monitoring data. Our goal is to build the real time porosity map of parts based on thermal images acquired during the build. The quantification task builds upon the established Convolutional Neural Network model architecture to predict pore count and the localization task leverages the spatial and temporal attention mechanisms of the novel Video Vision Transformer model to indicate areas of expected porosity. Our model for porosity quantification achieved a R2 score of 0.57 and our model for porosity localization produced an average Intersection over Union (IoU) score of 0.32 and a maximum of 1.0. This work is setting the foundations of part porosity ""Digital Twins""based on additive manufacturing monitoring data and can be applied downstream to reduce time-intensive post- inspection and testing activities during part qualification and certification. In addition, we seek to accelerate the acquisition of crucial insights normally only available through ex-situ part evaluation by means of machine learning analysis of in-situ process monitoring data.","2024-09-05","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","95","","","","","","","","","","English","","","","WOS:001355214900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","Deep learning; Digital twin; Laser powder bed fusion; TECHNOLOGY; Thermal imaging; Video vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3FP4A9UB","journalArticle","2024","Kwong, NW; Chan, YL; Tsang, SH; Huang, ZY; Lam, KM","Spatiotemporal feature learning for no-reference gaming content video quality assessment","JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION","","1047-3203","10.1016/j.jvcir.2024.104118","","Recently, over-the-top live gaming content video (GCV) services have significantly contributed to the overall internet traffic. Consequently, there is a growing demand of GCV quality assessment (GCVQA) to maintain service quality. Although recent literature has proposed a few GCVQA methods, these mainly focus on extracting spatial features and temporal fusion separately, limiting their performance due to the neglect of spatiotemporal feature learning, which is crucial for GCV as it typically shares spatial and temporal features across frames. To address this, we propose a novel GCVQA model, focusing on GCV spatiotemporal feature learning. First, we employ a multi-task self-supervised learning spatiotemporal pyramid convolutional neural network (STP-CNN) model to extract short-term spatiotemporal quality feature representations (STQFR) of GCVs. Our STP-CNN model specifically extracts multiscale spatiotemporal features from various temporal scales of multi-frames in pyramid mode, enabling dynamic learning of diverse spatiotemporal cues. Subsequently, we propose the differential Transformer model to process all short-term STQFR within a GCV, extracting global spatiotemporal features of GCV to assess the overall quality of GCV. To evaluate the effectiveness of our proposed method, we conducted experiments using four GCVQA datasets. The results demonstrate that our method outperforms existing approaches in predicting the perceived quality of GCV.","2024-04","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","100","","","","","","","","","","English","","","","WOS:001289122100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Gaming content video quality assessment; Multi-task learning; Self-supervised learning; Spatiotemporal features learning; STRUCTURAL SIMILARITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FRYPFNFJ","journalArticle","2024","Ji, YL; Sun, WW; Wang, YM; Lv, ZY; Yang, G; Zhan, YZ; Li, C","Domain Adaptive and Interactive Differential Attention Network for Remote Sensing Image Change Detection","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2024.3382116","","The objective of change detection (CD) is to identify the altered region between dual-temporal images. In pursuit of more precise change maps, numerous state-of-the-art (SOTA) methods design neural networks with robust discriminative capabilities. The convolutional neural network (CNN)-transformer model is specifically designed to integrate the strengths of the CNN and transformer, facilitating effective coupling of feature information. However, previous CNN-transformer studies have not effectively mitigated the interference of feature distribution differences as well as pseudovariations between two images due to cloud occlusion, imaging conditions, and other factors. In this article, we propose a domain adaptive and interactive differential attention network (DA-IDANet). This model incorporates domain adaptive constraints (DACs) to mitigate the interference of pseudovariations by mapping the two images to the same deep feature space for feature alignment. Furthermore, we designed the interactive differential attention module (IDAM), which effectively improves the feature representation and promotes the coupling of interactive differential discriminant information, thereby minimizing the impact of irrelevant information. Experiments on four datasets demonstrate the superior validity and robustness of our proposed model compared to other SOTA methods, as evident from both quantitative analysis and qualitative comparisons. The code will be available online (https://github.com/Jyl199904/DA-IDANet).","2024","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","62","","","","","","","","","","English","","","","WOS:001196725900036","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","Change detection (CD); CLASSIFICATION; convolutional neural network (CNN); domain adaptation; interactive differential attention module (IDAM); remote sensing (RS); RESOLUTION; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KE5AXVJP","journalArticle","2023","Hagendorff, T; Fabi, S; Kosinski, M","Human-like intuitive behavior and reasoning biases emerged in large language models but disappeared in ChatGPT","NATURE COMPUTATIONAL SCIENCE","","2662-8457","10.1038/s43588-023-00527-x","","We design a battery of semantic illusions and cognitive reflection tests, aimed to elicit intuitive yet erroneous responses. We administer these tasks, traditionally used to study reasoning and decision-making in humans, to OpenAI's generative pre-trained transformer model family. The results show that as the models expand in size and linguistic proficiency they increasingly display human-like intuitive system 1 thinking and associated cognitive errors. This pattern shifts notably with the introduction of ChatGPT models, which tend to respond correctly, avoiding the traps embedded in the tasks. Both ChatGPT-3.5 and 4 utilize the input-output context window to engage in chain-of-thought reasoning, reminiscent of how people use notepads to support their system 2 thinking. Yet, they remain accurate even when prevented from engaging in chain-of-thought reasoning, indicating that their system-1-like next-word generation processes are more accurate than those of older models. Our findings highlight the value of applying psychological methodologies to study large language models, as this can uncover previously undetected emergent characteristics. The reasoning capabilities of OpenAI's generative pre-trained transformer family were tested using semantic illusions and cognitive reflection tests that are typically used in human studies. While early models were prone to human-like cognitive errors, ChatGPT decisively outperformed humans, avoiding the cognitive traps embedded in the tasks.","2023-10","2025-02-26 20:41:52","2025-02-26 20:41:52","","833-+","","10","3","","","","","","","","","","English","","","","WOS:001119334100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;39<br/>Total Times Cited:&nbsp;&nbsp;40<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","COGNITIVE REFLECTION TEST; HEURISTICS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K4GSPS2N","journalArticle","2022","Shou, YT; Meng, T; Ai, W; Xie, CH; Liu, HY; Wang, YA","Object Detection in Medical Images Based on Hierarchical Transformer and Mask Mechanism","COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE","","1687-5265","10.1155/2022/5863782","","The object detection task in the medical field is challenging in terms of classification and regression. Due to its crucial applications in computer-aided diagnosis and computer-aided detection techniques, an increasing number of researchers are transferring the object detection techniques to the medical field. However, in existing work on object detection, researchers do not consider the low resolution of medical images, the high amount of noise, and the small size of the objects to be detected. Based on this, this paper proposes a new algorithmic model called the MS Transformer, where a self-supervised learning approach is used to perform a random mask on the input image to reconstruct the input features, learn a richer feature vector, and filter out excessive noise. To focus the model on the small objects that are being detected, the hierarchical transformer model is introduced in this paper, and a sliding window with a local self-attention mechanism is used to give a higher attention score to the small objects to be detected. Finally, a single-stage object detection framework is used to predict the sequence of sets at the location of the bounding box and the class of objects to be detected. On the DeepLesion and BCDD benchmark dataset, the model proposed in this paper achieves better performance improvement on multiple evaluation metric categories.","2022-08-04","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","2022","","","","","","","","","","English","","","","WOS:000860392900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TPUA6N95","journalArticle","2024","El-Dabah, MA; Agwa, AM","Identification of Transformer Parameters Using Dandelion Algorithm","APPLIED SYSTEM INNOVATION","","2571-5577","10.3390/asi7050075","","Researchers tackled the challenge of finding the right parameters for a transformer-equivalent circuit. They achieved this by minimizing the difference between actual measurements (currents, powers, secondary voltage) during a transformer load test and the values predicted by the model using different parameter settings. This process considers limitations on what values the parameters can have. This research introduces the application of a new and effective optimization algorithm called the dandelion algorithm (DA) to determine these transformer parameters. Information from real-time tests (single- and three-phase transformers) is fed into a computer program that uses the DA to find the best parameters by minimizing the aforementioned difference. Tests confirm that the DA is a reliable and accurate tool for estimating the transformer parameters. It achieves excellent performance and stability in finding the optimal values that precisely reflect how a transformer behaves. The DA achieved a significantly lower best fitness function value of 0.0136101 for the three-phase transformer case, while for the single-phase case it reached 0.601764. This indicates a substantially improved match between estimated and measured electrical parameters for the three-phase transformer model. By comparing DA with six competitive algorithms to prove how well each method minimized the difference between measurements and predictions, it could be shown that the DA outperforms these other techniques.","2024-10","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","5","7","","","","","","","","","","English","","","","WOS:001340913100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","dandelion algorithm; electrical transformer; equivalent circuit; OPTIMIZATION ALGORITHM; parameter identification; PHASE TRANSFORMERS; POWER TRANSFORMERS; squared error minimization; VOLTAGE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XCGGIYIS","journalArticle","2024","Zhang, JY; Shen, JR; Wang, ZK; Guo, QH; Yan, R; Pan, G; Tang, HJ","SpikingMiniLM: energy-efficient spiking transformer for natural language understanding","SCIENCE CHINA-INFORMATION SCIENCES","","1674-733X","10.1007/s11432-024-4101-6","","In the era of large-scale pretrained models, artificial neural networks (ANNs) have excelled in natural language understanding (NLU) tasks. However, their success often necessitates substantial computational resources and energy consumption. To address this, we explore the potential of spiking neural networks (SNNs) in NLU-a promising avenue with demonstrated advantages, including reduced power consumption and improved efficiency due to their event-driven characteristics. We propose the SpikingMiniLM, a novel spiking Transformer model tailored for natural language understanding. We first introduce a multistep encoding method to convert text embeddings into spike trains. Subsequently, we redesign the attention mechanism and residual connections to make our model operate on the pure spike-based paradigm without any normalization technique. To facilitate stable and fast convergence, we propose a general parameter initialization method grounded in the stable firing rate principle. Furthermore, we apply an ANN-to-SNN knowledge distillation to overcome the challenges of pretraining SNNs. Our approach achieves a macro-average score of 75.5 on the dev sets of the GLUE benchmark, retaining 98% of the performance exhibited by the teacher model MiniLMv2. Our smaller model also achieves similar performance to BERTMINI with fewer parameters and much lower energy consumption, underscoring its competitiveness and resource efficiency in NLU tasks.","2024-10","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","10","67","","","","","","","","","","English","","","","WOS:001319999600003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","ANN-to-SNN distillation; multi-step encoding; natural language understanding; spike-based attention; spiking neural networks; spiking Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UA8GANA2","journalArticle","2024","Fawzy, M; Tawfik, NS; Saleh, SN","Enhancing Image Copy Detection through Dynamic Augmentation and Efficient Sampling with Minimal Data","ELECTRONICS","","2079-9292","10.3390/electronics13163125","","Social networks have become deeply integrated into our daily lives, leading to an increase in image sharing across different platforms. Simultaneously, the existence of robust and user-friendly media editors not only facilitates artistic innovation, but also raises concerns regarding the ease of creating misleading media. This highlights the need for developing new advanced techniques for the image copy detection task, which involves evaluating whether photos or videos originate from the same source. This research introduces a novel application of the Vision Transformer (ViT) model to the image copy detection task on the DISC21 dataset. Our approach involves innovative strategic sampling of the extensive DISC21 training set using K-means clustering to achieve a representative subset. Additionally, we employ complex augmentation pipelines applied while training with varying intensities. Our methodology follows the instance discrimination concept, where the Vision Transformer model is used as a classifier to map different augmentations of the same image to the same class. Next, the trained ViT model extracts descriptors of original and manipulated images that subsequently underwent post-processing to reduce dimensionality. Our best-achieving model, tested on a refined query set of 10K augmented images from the DISC21 dataset, attained a state-of-the-art micro-average precision of 0.79, demonstrating the effectiveness and innovation of our approach.","2024-08","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","16","13","","","","","","","","","","English","","","","WOS:001305249500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","artificial intelligence; copy detection; deep learning; supervised learning; vision transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QCAUY6P9","journalArticle","2024","Baygi, SF; Barupal, DK","IDSL_MINT: a deep learning framework to predict molecular fingerprints from mass spectra","JOURNAL OF CHEMINFORMATICS","","1758-2946","10.1186/s13321-024-00804-5","","The majority of tandem mass spectrometry (MS/MS) spectra in untargeted metabolomics and exposomics studies lack any annotation. Our deep learning framework, Integrated Data Science Laboratory for Metabolomics and Exposomics-Mass INTerpreter (IDSL_MINT) can translate MS/MS spectra into molecular fingerprint descriptors. IDSL_MINT allows users to leverage the power of the transformer model for mass spectrometry data, similar to the large language models. Models are trained on user-provided reference MS/MS libraries via any customizable molecular fingerprint descriptors. IDSL_MINT was benchmarked using the LipidMaps database and improved the annotation rate of a test study for MS/MS spectra that were not originally annotated using existing mass spectral libraries. IDSL_MINT may improve the overall annotation rates in untargeted metabolomics and exposomics studies. The IDSL_MINT framework and tutorials are available in the GitHub repository at https://github.com/idslme/IDSL_MINT.Scientific contribution statement.Structural annotation of MS/MS spectra from untargeted metabolomics and exposomics datasets is a major bottleneck in gaining new biological insights. Machine learning models to convert spectra into molecular fingerprints can help in the annotation process. Here, we present IDSL_MINT, a new, easy-to-use and customizable deep-learning framework to train and utilize new models to predict molecular fingerprints from spectra for the compound annotation workflows.","2024-01-18","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","1","16","","","","","","","","","","English","","","","WOS:001144240000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Deep learning; LipidMaps; Lipidomics; Mass spectrometry; Metabolomics; Molecular fingerprint descriptor; PyTorch; TOOLS; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GG5W8ALB","journalArticle","2023","Zhang, B; Hu, Z; Wu, P; Huang, HW; Xiang, JS","EPT: A data-driven transformer model for earthquake prediction","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2023.106176","","The leading causes of earthquakes are crustal movements, plate movements, and collisions. In recent years, many researchers in earthquake prediction have been predicting earthquakes from historical seismic data in local areas. This approach ignores the underlying internal patterns of crustal motion, plate movement, and collisions. This paper proposes a purely data-driven deep learning model called EPT. The model uses gated feature extraction blocks (GFEB) to mine potential crustal motion and plate movement patterns from global historical seismic catalog data. It uses them to aid mainshock prediction in each local, provincial region. Experiments show that this approach improves model prediction accuracy by up to 50 percent. We also use multi-headed self-attention for the first time to capture long-term dependencies within regional time series, highlighting links between focal features and compensating for the difficulty of focusing on longer-term information in long-term time series with long short-term memory networks (LSTM). In addition, we also use the gradient harmonization mechanism classification (GHMC) loss function for the first time in earthquake prediction, effectively addressing the problem of uneven data distribution across different earthquake magnitude ranges. Finally, we validated the effectiveness of the EPT model in five provincial datasets in mainland China, and the experimental results all achieved an accuracy of over 90 percent.","2023-08","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","123","","","","","","","","","","English","","","","WOS:000968691200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Data mining; Earthquake prediction; LSTM; MAGNITUDE PREDICTION; Multi-headed self-attention; NEURAL-NETWORK; Time series prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6FNNGRVG","journalArticle","2025","Jiang, P; Li, XB; Huang, WM","Intelligent detection method for aluminum alloy TIG welding quality by fusing multimodal data features","PATTERN RECOGNITION LETTERS","","0167-8655","10.1016/j.patrec.2025.01.004","","The welding process of aluminum alloys involves various parameters and rapid operations, resulting in complexity in the precise monitoring and control of the processing. Conventional real-time monitoring methods focus on identifying welding defects by acquiring operation data from a single sensor during the welding processing. However, the welding process frequently undergoes minor yet critical quality variations due to multiple external disturbances which cannot be detected by these traditional approaches, making it impossible to establish more accurate implicit correlations that fuse the diverse data. In this paper, a Resnet-Transformer model based on multimodal data fusion is proposed to efficiently identify six welding states in Tungsten Inert Gas Welding (TIG) by combining the features of welding molten pool image, welding current and welding speed. This model incorporates the benefits of Resnet and the Transformer encoder to fuse the features of images and time-series data using the Multi-modal Factorized Bilinear (MFB) method. Through experimental studies, the proposed model achieves a classification accuracy of 98.94 %. Furthermore, to improve the processing efficiency of the model, this paper presents an automatic segmentation and cropping enhancement algorithm for welding pool images, which removes the redundant features in the original image so as to increase the accuracy by 8.6 %.","2025-03","2025-02-26 20:41:52","2025-02-26 20:41:52","","106-114","","","189","","","","","","","","","","English","","","","WOS:001413940900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","Deep learning; DEFECTS DETECTION; IMAGE; Multimodal data fusion; Quality monitoring; TIG welding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JRATHQ5I","journalArticle","2025","Zhang, HR; Liu, HR","Real-Time Power System Optimization Under Typhoon Weather Using the Smart ""Predict, Then Optimize"" Framework","ENERGIES","","1996-1073","10.3390/en18030615","","With the increase of extreme weather events caused by global climate change, the issue of power system resilience has become more and more important. Traditional power system management methods cannot cope with dynamic real-time changes, and it is difficult to effectively predict and respond to potential failures caused by extreme weather. To this end, this paper proposes a real-time power system optimization method based on the Smart ""Predict, then Optimize"" (SPO) framework. The SPO method first uses the Transformer model to predict, in real time, the future line damage states and then dynamically adjusts the optimization strategy based on the prediction results. This method can efficaciously enhance the prediction accuracy of faulty lines under extreme weather conditions and optimize generation scheduling, load management, as well as EV battery scheduling to minimize the system cost. This study proposes a solution based on the SPO loss function, artificial intelligence prediction model, and bi-level optimization model to address the dynamic optimization of power systems under extreme conditions, significantly enhancing the system's response to extreme weather events. The experimental results demonstrate that the SPO method can optimize system operation in real time, significantly reducing load shedding and total system cost during typhoon weather, which not only improves the system's economic efficiency but also effectively enhances power system resilience.","2025-02","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","3","18","","","","","","","","","","English","","","","WOS:001418505900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","extreme weather; MODEL; optimization; RELIABILITY; SPO; system resilience; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PWQ3VQ6Z","journalArticle","2025","Qian, SJ; Peng, T; He, R; Chen, J; Zhang, XD; Nazir, MS; Zhang, C","A novel ensemble framework based on intelligent weight optimization and multi-model fusion for air quality index prediction","URBAN CLIMATE","","2212-0955","10.1016/j.uclim.2024.102233","","The accuracy of air quality prediction is crucial for public health and environmental management. This paper proposes a hybrid deep learning model based on TimesNet, Crossformer and Modified Honey Badger Algorithm (MHBA) for air quality prediction. First, the original air quality index (AQI) series is decomposed using Seasonal-Trend decomposition based on Loess (STL). Then, the decomposed three components are predicted separately using TimesNet and Crossformer, while the hyperparameters of TimesNet and Crossformer are optimized using the Metis algorithm. In addition, half uniform initialization and Levy flight are added to the original HBA algorithm to make up for its shortcomings of slow optimization search speed and the tendency to fall into local optimal position, and the MHBA algorithm is obtained. Finally, the MHBA algorithm is used to weight the component prediction results of the two models, and compare the advantages and disadvantages of different weighting methods, and select the optimal weighting method to get the final AQI prediction results. The experimental results show that the STL-Metis-MHBA-TC model reduces RMSE, MAE, and MAPE by 19-34 %, 22-38 %, and 22-44 %, respectively, compared to the Transformer model. Therefore, the STL-Metis-MHBA-TC hybrid model proposed in this paper can effectively improve the AQI prediction accuracy.","2025-02","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","59","","","","","","","","","","English","","","","WOS:001389712000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Air quality index prediction; Crossformer; Intelligent weight optimization; Seasonal-trend decomposition based on Loess; TimesNet","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V4U4RP9I","journalArticle","2024","Li, RX; Liu, CS; Tang, YH; Niu, CJ; Fan, Y; Luo, QY; Hu, CH","Study on Runoff Simulation with Multi-source Precipitation Information Fusion Based on Multi-model Ensemble","WATER RESOURCES MANAGEMENT","","0920-4741","10.1007/s11269-024-03949-y","","High-quality precipitation data input and the selection of reasonable and applicable hydrological models are the main ways to improve the accuracy of runoff simulation, and are crucial for flood control, drought resistance and comprehensive water resource management in the basin. This study takes the Jingle Basin as the research area, establishing a transformer model that integrates rainfall data from multiple sources considering environmental factors. It combines six types of remote sensing data with rainfall data, which are then used as inputs for the XAJ model, LSTM model, and Prophet model, respectively. The output results are further separately using the ensemble mean method and the Bayesian mean method for ensemble forecasting. The results show that: Compared with a single precipitation product, the fusion model considering environmental factors significantly enhances the correlation between the predicted rainfall and the observed rainfall, with the CC value reaching 0.72; Compared with the other two models, the LSTM model has the NSE value of 0.89, showing a better runoff prediction effect; Compared with the LSTM model with the NSE value of 0.85 and the ensemble average method with the NSE value of 0.76, the Bayesian model averaging method demonstrates the best runoff prediction and simulation effect, with the NSE value of 0.88.","2024-12","2025-02-26 20:41:52","2025-02-26 20:41:52","","6139-6155","","15","38","","","","","","","","","","English","","","","WOS:001319503800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Bayesian averaging method; Fusion of multi-source precipitation; Hydrological model; Multi-model ensemble forecasting; PRODUCTS; Runoff simulation; SCALE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DWP38S6S","journalArticle","2024","Peng, ZQ; Wang, QB; Liu, ZR; He, RJ","Remaining Useful Life Prediction for Aircraft Engines under High-Pressure Compressor Degradation Faults Based on FC-AMSLSTM","AEROSPACE","","2226-4310","10.3390/aerospace11040293","","The healthy operation of aircraft engines is crucial for flight safety, and accurate Remaining Useful Life prediction is one of the core technologies involved in aircraft engine prognosis and health management. In recent years, deep learning-based predictive methods within data-driven approaches have shown promising performance. However, for engines experiencing a single fault, such as a High-Pressure Compressor fault, existing deep learning-based predictive methods often face accuracy challenges due to the coupling relationship between different fault modes in the training dataset that includes a mixture of multiple fault modes. In this paper, we propose the FC-AMSLSTM method, a novel approach for Remaining Useful Life prediction specifically targeting High-Pressure Compressor degradation faults. The proposed method effectively addresses the limitations of previous approaches by fault classification and decoupling fault modes from multiple operating conditions using a decline index. Then, attention mechanisms and multi-scale convolutional neural networks are employed to extract spatiotemporal features. The long short-term memory network is then utilized to model RUL estimation. The experiments are conducted using the Commercial Modular Aero-Propulsion System Simulation dataset provided by NASA. The results demonstrate that compared to other prediction models, the FC-AMSLSTM method effectively reduces RUL prediction error for HPC degradation faults under multiple operating conditions.","2024-04","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","4","11","","","","","","","","","","English","","","","WOS:001209904700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","aircraft engine; ATTENTION-BASED LSTM; deep learning; fault classification; PROGNOSTICS; remaining useful life; TRANSFORMER MODEL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7BCU74EH","journalArticle","2024","Mercier, TM; Sabet, A; Rahman, T","Vision transformer models to measure solar irradiance using sky images in temperate climates","APPLIED ENERGY","","0306-2619","10.1016/j.apenergy.2024.122967","","Solar Irradiance measurements are critical for a broad range of energy systems, including evaluating performance ratios of photovoltaic systems, as well as forecasting power generation. Using sky images to evaluate solar irradiance, allows for a low-cost, low -maintenance, and easy integration into Internet -of -things network, with minimal data loss. This work demonstrates that a vision transformer -based machine learning model can produce accurate irradiance estimates based on sky -images without any auxiliary data being used. The training data utilizes 17 years of global horizontal, diffuse and direct data, based on a high precision pyranometer and pyrheliometer sun -tracked system; in -conjunction with sky images from a standard lens and a fish-eye camera. The vision transformer -based model learns to attend to relevant features of the sky -images and to produce highly accurate estimates for both global horizontal irradiance (RMSE =52 W/m2) and diffuse irradiance (RMSE = 31 W/m2). This work compares the model's performance on wide field of view all -sky images as well as images from a standard camera and shows that the vision transformer model works best for all -sky images. For images from a normal camera both vision transformer and convolutional architectures perform similarly with the convolution -based architecture showing an advantage for direct irradiance with an RMSE of 155 W/m2.","2024-05-15","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","","362","","","","","","","","","","English","","","","WOS:001206593100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Computer vision; Machine learning; Sky imaging; Solar irradiance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JA7LM2QQ","journalArticle","2024","Ruescas-Nicolau, AV; Medina-Ripoll, E; de Rosario, H; Navarro, JS; Parrilla, E; Lizandra, MCJ","A Deep Learning Model for Markerless Pose Estimation Based on Keypoint Augmentation: What Factors Influence Errors in Biomechanical Applications?","SENSORS","","1424-8220","10.3390/s24061923","","In biomechanics, movement is typically recorded by tracking the trajectories of anatomical landmarks previously marked using passive instrumentation, which entails several inconveniences. To overcome these disadvantages, researchers are exploring different markerless methods, such as pose estimation networks, to capture movement with equivalent accuracy to marker-based photogrammetry. However, pose estimation models usually only provide joint centers, which are incomplete data for calculating joint angles in all anatomical axes. Recently, marker augmentation models based on deep learning have emerged. These models transform pose estimation data into complete anatomical data. Building on this concept, this study presents three marker augmentation models of varying complexity that were compared to a photogrammetry system. The errors in anatomical landmark positions and the derived joint angles were calculated, and a statistical analysis of the errors was performed to identify the factors that most influence their magnitude. The proposed Transformer model improved upon the errors reported in the literature, yielding position errors of less than 1.5 cm for anatomical landmarks and 4.4 degrees for all seven movements evaluated. Anthropometric data did not influence the errors, while anatomical landmarks and movement influenced position errors, and model, rotation axis, and movement influenced joint angle errors.","2024-03","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","6","24","","","","","","","","","","English","","","","WOS:001193035600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","anatomical landmark; biomechanics; DATASET; deep learning; DEFINITIONS; GAIT ANALYSIS; HIP; HUMAN MOVEMENT; human pose estimation; ISB RECOMMENDATION; JOINT COORDINATE SYSTEM; keypoint augmentation; markerless; MOTION CAPTURE; PART 1; STEREOPHOTOGRAMMETRY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PAGQNYQD","journalArticle","2024","Hu, JL; Huang, YM; Wang, N; Dong, SB","BrainNPT: Pre-Training Transformer Networks for Brain Network Classification","IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING","","1534-4320","10.1109/TNSRE.2024.3434343","","Deep learning methods have advanced quickly in brain imaging analysis over the past few years, but they are usually restricted by the limited labeled data. Pre-trained model on unlabeled data has presented promising improvement in feature learning in many domains, such as natural language processing. However, this technique is under-explored in brain network analysis. In this paper, we focused on pre-training methods with Transformer networks to leverage existing unlabeled data for brain functional network classification. First, we proposed a Transformer-based neural network, named as BrainNPT, for brain functional network classification. The proposed method leveraged <cls> token as a classification embedding vector for the Transformer model to effectively capture the representation of brain networks. Second, we proposed a pre-training framework for BrainNPT model to leverage unlabeled brain network data to learn the structure information of brain functional networks. The results of classification experiments demonstrated the BrainNPT model without pre-training achieved the best performance with the state-of-the-art models, and the BrainNPT model with pre-training strongly outperformed the state-of-the-art models. The pre-training BrainNPT model improved 8.75% of accuracy compared with the model without pre-training. We further compared the pre-training strategies and the data augmentation methods, analyzed the influence of the parameters of the model, and explained the trained model.","2024","2025-02-26 20:41:52","2025-02-26 20:41:52","","2727-2736","","","32","","","","","","","","","","English","","","","WOS:001283728000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","Brain functional networks; classification; NEURAL-NETWORKS; pre-training; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K88QKW4R","journalArticle","2024","Rizzello, V; Böck, B; Joham, M; Utschick, W","Reverse Ordering Techniques for Attention-Based Channel Prediction","IEEE OPEN JOURNAL OF SIGNAL PROCESSING","","2644-1322","10.1109/OJSP.2023.3344024","","Channel state information (CSI) is crucial for enhancing the performance of wireless systems by allowing to adjust the transmission strategies based on the current channel conditions. However, obtaining precise CSI is difficult because of the fast-changing channel conditions caused by multi-path fading. An inaccurate CSI hinders the performance of various adaptive wireless systems, highlighting the need for channel prediction techniques to effectively mitigate the drawbacks of outdated CSI. Conventional methods typically depend on assumptions regarding user velocity or require knowledge of the Doppler frequency. In contrast to existing approaches, we aim for a more robust and practical solution by training neural networks without making any assumptions about user velocity, relying solely on noisy channel observations during training. Specifically, we adapt both the sequence-to-sequence with attention (Seq2Seq-attn) and transformer models for channel prediction. Additionally, a new technique called reverse positional encoding is introduced in the transformer model to improve the robustness of the model against varying sequence lengths. Similarly, the encoder outputs of the Seq2Seq-attn model are reversed prior to the application of attention mechanisms. By means of simulations, we show that these proposed techniques enable the models to effectively capture relationships within sequences of channel snapshots without increasing the complexity. Importantly, this capability remains robust across varying sequence lengths, representing a substantial improvement over existing methodologies.","2024","2025-02-26 20:41:52","2025-02-26 20:41:52","","248-256","","","5","","","","","","","","","","English","","","","WOS:001138672900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Channel prediction; MASSIVE MIMO; MODEL; positional encoding; Seq2Seq; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8C2K7GDL","journalArticle","2024","Chen, ZR; Xie, YC; Wu, YC; Lin, YY; Tomiya, S; Lin, J","An interpretable and transferrable vision transformer model for rapid materials spectra classification","DIGITAL DISCOVERY","","2635-098X","10.1039/d3dd00198a","","Rapid analysis of materials characterization spectra is pivotal for preventing the accumulation of unwieldy datasets, thus accelerating subsequent decision-making. However, current methods heavily rely on experience and domain knowledge, which not only proves tedious but also makes it hard to keep up with the pace of data acquisition. In this context, we introduce a transferable Vision Transformer (ViT) model for the identification of materials from their spectra, including XRD and FTIR. First, an optimal ViT model was trained to predict metal organic frameworks (MOFs) from their XRD spectra. It attains prediction accuracies of 70%, 93%, and 94.9% for Top-1, Top-3, and Top-5, respectively, and a shorter training time of 269 seconds (similar to 30% faster) in comparison to a convolutional neural network model. The dimension reduction and attention weight map underline its adeptness at capturing relevant features in the XRD spectra for determining the prediction outcome. Moreover, the model can be transferred to a new one for prediction of organic molecules from their FTIR spectra, attaining remarkable Top-1, Top-3, and Top-5 prediction accuracies of 84%, 94.1%, and 96.7%, respectively. The introduced ViT-based model would set a new avenue for handling diverse types of spectroscopic data, thus expediting the materials characterization processes. An interpretable and transferrable Vision Transformer (ViT) model was developed for classifying individual materials from their XRD and FTIR spectra.","2024-02-14","2025-02-26 20:41:52","2025-02-26 20:41:52","","369-380","","2","3","","","","","","","","","","English","","","","WOS:001142708600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JQ6QAYMR","journalArticle","2024","Nisticò, S; Palopoli, L; Romano, AP","Audio super-resolution via vision transformer","JOURNAL OF INTELLIGENT INFORMATION SYSTEMS","","0925-9902","10.1007/s10844-023-00833-w","","Audio super-resolution refers to techniques that improve the audio signals quality, usually by exploiting bandwidth extension methods, whereby audio enhancement is obtained by expanding the phase and the spectrogram of the input audio traces. These techniques are therefore much significant for all those cases where audio traces miss relevant parts of the audible spectrum. In several cases, the given input signal contains the low-band frequencies (the easiest to capture with low-quality recording instruments) whereas the high-band must be generated. In this paper, we illustrate techniques implemented into a system for bandwidth extension that works on musical tracks and generates the high-band frequencies starting from the low-band ones. The system, called ViT Super-resolution (ViT-SR), features an architecture based on a Generative Adversarial Network and Vision Transformer model. In particular, two versions of the architecture will be presented in this paper, that work on different input frequency ranges. Experiments, which are accounted for in the paper, prove the effectiveness of our approach. In particular, the objective has been attained to demonstrate that it is possible to faithfully reconstruct the high-band signal of an audio file having only its low-band spectrum available as the input, therewith including the usually difficult to synthetically generate harmonics occurring in the audio tracks, which significantly contribute to the final perceived sound quality.","2024-08","2025-02-26 20:41:52","2025-02-26 20:41:52","","1071-1085","","4","62","","","","","","","","","","English","","","","WOS:001122439700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Audio Super-resolution; Generative Adversarial Networks; Music Enhancement; Transformers; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VUGSSNPU","journalArticle","2023","Li, SJ; Zhang, WX; Wang, P","TS2ARCformer: A Multi-Dimensional Time Series Forecasting Framework for Short-Term Load Prediction","ENERGIES","","1996-1073","10.3390/en16155825","","Accurately predicting power load is a pressing concern that requires immediate attention. Short-term load prediction plays a crucial role in ensuring the secure operation and analysis of power systems. However, existing research studies have limited capability in extracting the mutual relationships of multivariate features in multivariate time series data. To address these limitations, we propose a multi-dimensional time series forecasting framework called TS2ARCformer. The TS2ARCformer framework incorporates the TS2Vec layer for contextual encoding and utilizes the Transformer model for prediction. This combination effectively captures the multi-dimensional features of the data. Additionally, TS2ARCformer introduces a Cross-Dimensional-Self-Attention module, which leverages interactions across channels and temporal dimensions to enhance the extraction of multivariate features. Furthermore, TS2ARCformer leverage a traditional autoregressive component to overcome the issue of deep learning models being insensitive to input scale. This also enhances the model's ability to extract linear features. Experimental results on two publicly available power load datasets demonstrate significant improvements in prediction accuracy compared to baseline models, with reductions of 43.2% and 37.8% in the aspect of mean absolute percentage error (MAPE) for dataset area1 and area2, respectively. These findings have important implications for the accurate prediction of power load and the optimization of power system operation and analysis.","2023-08","2025-02-26 20:41:52","2025-02-26 20:41:52","","","","15","16","","","","","","","","","","English","","","","WOS:001046085400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","attention; load prediction; multivariate time series; transformer; TS2Vec; WEATHER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6DHKVVMN","journalArticle","2022","Bhowmick, RS; Ganguli, I; Sil, J","Character-level inclusive transformer architecture for information gain in low resource code-mixed language","NEURAL COMPUTING & APPLICATIONS","","0941-0643","10.1007/s00521-022-06983-2","","The use of code-mixed languages in social media platforms is very common to communicate in an informal way and has immense importance in a multilingual society, like India. Implementing various NLP tasks on code-mixed language for machine comprehension and NLP applications is the need of the hour. The implementation of complex learning models is difficult due to the scarcity of available code-mixed resources. Designing more effective architectures to perform learning from low resource dataset along with transfer learning settings are the possible solutions. We propose an improvised transformer network (Character Inclusion Transformer) that utilizes and learns character-level information available in the words of code-mixed sentences. The proposed model improves the performance of the transformer model when trained from scratch using low resource code-mixed datasets. We also propose two more architecture settings, useful for transfer learning strategy using the mBERT pre-trained model. Three basic word-level tagging NLP tasks, i.e., NER, POS Tagging, and Language Identification (LID) are considered in the paper where Language Identification is specific to code-mixed language. Six separate datasets, namely IIITH NER, LID FIRE, LID ICON, LID UD, POS ICON, POS UD, have been tested, and results are reported using weighted and macro-average while evaluating precision, recall and F1 score","2022-03-09","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","","","","","","","","","","","English","","","","WOS:000766057200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Deep learning; English-Hindi code-mixed language; LID; mBERT; NER; NLP; POS; Transformer network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"544W4D96","journalArticle","2022","Tan, YF; Connie, T; Goh, MKO; Teoh, ABJ","A Pipeline Approach to Context-Aware Handwritten Text Recognition","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app12041870","","Featured Application The proposed handwritten text recognition pipeline can be used for practical documents transcription and context recognition. Despite concerted efforts towards handwritten text recognition, the automatic location and transcription of handwritten text remain a challenging task. Text detection and segmentation methods are often prone to errors, affecting the accuracy of the subsequent recognition procedure. In this paper, a pipeline that locates texts on a page and recognizes the text types, as well as the context of the texts within the detected region, is proposed. Clinical receipts are used as the subject of study. The proposed model is comprised of an object detection neural network that extracts text sequences present on the page regardless of size, orientation, and type (handwritten text, printed text, or non-text). After that, the text sequences are fed to a Residual Network with a Transformer (ResNet-101T) model to perform transcription. Next, the transcribed text sequences are analyzed using a Named Entity Recognition (NER) model to classify the text sequences into their corresponding contexts (e.g., name, address, prescription, and bill amount). In the proposed pipeline, all the processes are implicitly learned from data. Experiments performed on 500 self-collected clinical receipts containing 15,297 text segments reported a character error rate (CER) and word error rate (WER) of 7.77% and 10.77%, respectively.","2022-02","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","4","12","","","","","","","","","","English","","","","WOS:000763040600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","handwritten text recognition; named entity recognition; object detection; Residual Network; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4Y9CUENC","journalArticle","2021","Li, HB; Wang, JC; Ren, YL; Mao, F","Intercity Online Car-Hailing Travel Demand Prediction via a Spatiotemporal Transformer Method","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app112411750","","Traffic prediction is a critical aspect of many real-world scenarios that requires accurate traffic status predictions, such as travel demand prediction. The emergence of online car-hailing activities has given people greater mobility and makes intercity travel more frequent. The increase in online car-hailing demand has often led to a supply-demand imbalance where there is a mismatch between the immediate availability of car-hailing services and the number of passengers in certain areas. Accurate prediction of online car-hailing demand promotes efficiencies and minimizes resources and time waste. However, many prior related studies often fail to fully utilize spatiotemporal characteristics. With the development of newer deep-learning models, this paper aims to solve online car-hailing problems with an ST-transformer model. The spatiotemporal characteristics of online car-hailing data are analyzed and extracted. The study region is divided into subareas, and the demand for each subarea is summed at a specific time interval. Historical demand of the areas is used to predict future demand. The results of the ST-transformer outperformed other baseline models, namely, VAR, SVR, LSTM, LSTNet, and transformers. The validated results suggest that the ST-transformer is more capable of capturing spatiotemporal characteristics compared to the other models. Additionally, compared to others, the model is less affected by data sparsity.","2021-12","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","24","11","","","","","","","","","","English","","","","WOS:000735840700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","intercity car-hailing; prediction; spatiotemporal transformer; travel demand","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FWK3JYTX","journalArticle","2025","Zhang, ZY; Liu, BT; Zhou, J; Wang, HP; Liu, XY; Lin, B; Chen, T","Masked facial expression recognition based on temporal overlap module and action unit graph convolutional network","JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION","","1047-3203","10.1016/j.jvcir.2025.104398","","Facial expressions may not truly reflect genuine emotions of people. People often use masked facial expressions (MFEs) to hide their genuine emotions. The recognition of MFEs can help reveal these emotions, which has very important practical value in the field of mental health, security and education. However, MFE is very complex and lacks of research, and the existing facial expression recognition algorithms cannot well recognize the MFEs and the hidden genuine emotions at the same time. To obtain better representations of MFE, we first use the transformer model as the basic framework and design the temporal overlap module to enhance temporal receptive field of the tokens, so as to strengthen the capture of muscle movement patterns in MFE sequences. Secondly, we design a graph convolutional network (GCN) with action unit (AU) intensity as node features and the 3D learnable adjacency matrix based on AU activation state to reduce the irrelevant identity information introduced by image input. Finally, we propose a novel end-to-end dual-stream network combining the image stream (transformer) with the AU stream (GCN) for automatic recognition of MFEs. Compared with other methods, our approach has achieved state-of-the-art results on the core tasks of Masked Facial Expression Database (MFED).","2025-03","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","107","","","","","","","","","","English","","","","WOS:001423173400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Action unit; ATTENTION; DATABASE; Graph convolutional network; Masked facial expressions; Temporal overlap module; Transformer network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZPGGPT8P","journalArticle","2025","Wang, JY; Zhao, Y; Wang, WY; Wu, ZH","Improving bearing fault diagnosis method based on the fusion of time-frequency diagram and a novel vision transformer","JOURNAL OF SUPERCOMPUTING","","0920-8542","10.1007/s11227-024-06793-4","","Bearings are indispensable components in mechanical equipment, it is crucial to realize accurate and reliable fault diagnosis of bearings. Traditional bearing fault diagnosis methods suffer from insufficient feature extraction and poor robustness. This paper presents an improved bearing fault diagnosis method based on the fusion of time-frequency diagram and a novel vision transformer. On the one hand, the method adopts continuous wavelet transform to map the time-domain feature relationship of vibration onto the time-frequency domain. On the other hand, the method designs a novel vision transformer for bearing fault diagnosis model which can effectively improve the fault diagnosis performance and reduce the computational complexity on the basis of retaining the advantage of local feature extraction and dealing with long-range feature dependencies. In this paper, a new multi-head attention module called SRWA is designed to be utilized on the novel vision transformer model. Experiments are conducted to assess and analyze the performance of the proposed models using the bearing datasets: Case Western Reserve University data set and Harbin Institute of Technology inter-shaft bearing fault diagnosis data set. The experimental results demonstrate that the classification performance of the novel model put forward in this paper surpasses the state-of-the-art bearing fault diagnosis models on different datasets, even under variable operating conditions and noise conditions.","2025-01","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","1","81","","","","","","","","","","English","","","","WOS:001373451600006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Attention module; Fault diagnosis; Time-frequency diagram; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UGDLNBLZ","journalArticle","2024","Duan, JY; Chen, JG; Li, HZ; He, ZY","A Transformer Network for Phase Unwrapping in Fiber-Optic Acoustic Sensors","JOURNAL OF LIGHTWAVE TECHNOLOGY","","0733-8724","10.1109/JLT.2024.3413798","","Fiber-optic acoustic sensors, such as interferometric fiber-optic sensor array and phase-sensitive optical time-domain reflectometry, have excellent sensitivity and have been widely adopted in applications. However, their sampling rates are limited by the round-trip time of laser in the sensor array or the sensing fiber, which finally restricts the dynamic range due to the issue of phase wrapping. Classical phase unwrapping function requires the signal to obey the Itoh condition, otherwise, the recovery of true phase for strongly-swinging signals will fail. In this work, we propose a neural network for phase unwrapping of interferometric sensing signals named Prearranged Ascending Receptive Field Transformer (PARFT). The Transformer architecture with regressive output was employed which is capable of time-domain signal processing, and 1D convolution layers with ascending kernel sizes were designed to replace the positional encoding in standard Transformer, providing particular inductive biases aiming at the phase unwrapping problem. For both simulated dataset via random matrix enlargement (RME) method and real dataset recorded by distributed acoustic sensor (DAS), the network showed high efficiency and competitive accuracy in phase-unwrapping of signals violating the Itoh condition, compared with previously proposed neural networks or handcrafted algorithms.","2024-10-01","2025-02-26 20:41:53","2025-02-26 20:41:53","","7010-7020","","19","42","","","","","","","","","","English","","","","WOS:001322635500021","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","ALGORITHM; Encoding; Interferometric fiber-optic sensor; Kernel; neural network; Optical fiber networks; Optical fiber sensors; Optical interferometry; phase unwrapping; Task analysis; Transformer model; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3YRG4XLP","journalArticle","2024","Martin-Cirera, A; Nowak, M; Norton, T; Auer, U; Oczak, M","Comparison of Transformers with LSTM for classification of the behavioural time budget in horses based on video data","BIOSYSTEMS ENGINEERING","","1537-5110","10.1016/j.biosystemseng.2024.04.014","","This study compares the performance of Transformers with LSTM for the classification of the behavioural time budget in horses based on video data. The behavioural time budget of a horse consists of amount of time of the activities such as feeding, resting, lying, and moving, which are important indicators of welfare and can be a basis of pain detection. Video technology offers a non-invasive and continuous monitoring approach for automated detection of horse behaviours. Computer vision and deep learning methods have been used for automated monitoring of animal behaviours, but accurate behaviour recognition remains a challenge. Previous studies have employed Convolutional LSTM models for behaviour classification, and more recently, Transformer-based models have shown superior performance in various tasks. This study proposes a multi-input, multi-output classification methodology to address the challenges of accurately detecting and classifying horse behaviours. The results demonstrate that the multi-input and multi-output Transformer model achieves the best performance in behaviour classification compared with single input and single output strategy. The proposed methodology provides a basis for detecting changes in behaviour time budgets related to pain and discomfort in horses, which can be valuable for monitoring and treating horse health problems.","2024-06","2025-02-26 20:41:53","2025-02-26 20:41:53","","154-168","","","242","","","","","","","","","","English","","","","WOS:001285939000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","CAMARGUE HORSES; Computer vision; Equine welfare; FORAGING ENRICHMENT; Multi-input classification; Multi-output classification; PAIN; PATTERNS; PIGS; RECOGNITION; Time budget","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5C7MMIS2","journalArticle","2024","Ashraf, MR; Hussain, M; Jaffar, MA; Ramay, WY; Faheem, M","Revolutionizing Urdu Sentiment Analysis: Harnessing the Power of XLM-R and GPT-2","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3429496","","Sentiment analysis extracts valuable insights from textual sources using computation, textual or systematic analysis, and natural language processing. It identifies and measures the attitudes, beliefs, and emotional states individuals express through text data. Recent research on sentiment analysis has largely focused on the English language; therefore, low-resource languages are getting much less attention. Conducting sentiment analysis of low-resource languages is difficult because large datasets and related repositories are unavailable. This paper creates a new dataset for low-resource language (Urdu) to address this issue. The dataset, namely LUCSA-23, consists of more than 65,000 user reviews from various genres, including food, sports, showbiz, apps, and political reviews from developing countries, i.e., Pakistan. Urdu domain experts further annotate the created dataset. This paper proposes an Urdu sentiment analysis approach leveraging the transformer model, i.e., XLM-R and GPT-2. It preprocesses the Urdu text input, generates BERT embeddings, and passes them to the proposed classifier as input for sentiment classification. The proposed classifier is compared with machine/deep/embedded classifiers to evaluate its performance. The findings show that the proposed classifiers outperform existing state-of-the-art approaches with an accuracy of 95%.","2024","2025-02-26 20:41:53","2025-02-26 20:41:53","","99779-99793","","","12","","","","","","","","","","English","","","","WOS:001276323400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Accuracy; Analytical models; BERT; classification; CLASSIFICATION; deep learning; Deep learning; Electronic mail; GPT-2; Natural language processing; Reviews; Sentiment analysis; Urdu; Video on demand; Web sites; XLM-R","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y2Z9YNZV","journalArticle","2023","Liang, YW; Gao, YF; Shen, ZY","Transformer vehicle re-identification of intelligent transportation system under carbon neutral target","COMPUTERS & INDUSTRIAL ENGINEERING","","0360-8352","10.1016/j.cie.2023.109619","","Vehicle re-identification technology plays a pivotal role in intelligent transportation systems, contributing significantly to improved traffic scheduling and reduced net-zero emissions. It holds immense potential for advancing carbon neutrality efforts. By accurately recognizing and tracking vehicles, this technology optimizes traffic flow, enhances energy efficiency, reduces carbon emissions, and fosters sustainable transportation development. However, prevailing CNN-based feature extraction methods often lack the capability to associate global features, while Transformer-based approaches tend to overlook crucial local feature differences. Effectively mining local features and integrating them with global features are critical aspects of successful vehicle re identification techniques. To tackle this challenge, we present a novel approach, the Locally Significant Feature Rearrangement (LSFR) module, based on the Swin Transformer model. This module enhances the learning of local features by initially focusing on specific regions using a single-shot multi-box detector (SSD) and employing an adaptive attention learning mechanism to highlight fine-grained local features. Subsequently, the salient local features are rearranged to prioritize their importance, and their embedding layers are fused with global features in a recombined manner. Our experimental results on the VeRi-776 and VehicleID benchmark datasets validate the effectiveness of our proposed method as a reliable technique to support intelligent transportation systems and drive progress towards traffic carbon neutralization.","2023-11","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","185","","","","","","","","","","English","","","","WOS:001086620000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","EMBEDDING NETWORK; Intelligent Transport Systems; Local salient feature rearrangement; Traffic carbon neutralization; Vehicle Re-identification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FKDC2SYN","journalArticle","2023","Tan, XM; Qi, J; Gan, JQ; Zhang, JL; Guo, C; Wan, F; Wang, K","Multi-filter semi-supervised transformer model for fault diagnosis","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2023.106498","","Dissolved Gas Analysis (DGA) is the most commonly used method for power transformer fault diagnosis. However, very few reliable and labeled fault DGA samples are available in the transformer substation whilst DGA data without labels is easier to obtain, which makes it difficult to train fault detectors in high-dimensional input space or select features using wrapper methods. Therefore, in order to improve the fault diagnosis accuracy using limited labeled DGA samples but more unlabeled DGA data, this paper proposes a novel multi filter semi-supervised feature selection method for selecting optimal DGA features and building effective fault diagnosis models. A confidence criterion is also proposed for selecting high confidence unlabeled data expand the training data set. Five filter techniques based on different evaluation criteria are employed to rank input DGA features, and a feature combination method is then applied to aggregate feature ranks by multiple filters and form a lower-dimensional candidate feature subset. The proposed method has been tested by using the IEC T10 dataset and compared with traditional supervised diagnostic models. The results show that proposed method works well in optimizing DGA features and improving fault diagnosis accuracy significantly. Besides, the robustness of the selection of optimal feature subset is validated by testing DGA samples from the local power utility.","2023-09","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","124","","","","","","","","","","English","","","","WOS:001032309100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","ACCURACY; Confidence criterion; Dissolved gas analysis; DISSOLVED-GAS ANALYSIS; Fault diagnosis; Feature selection; GRAPH; Multi-filter semi-supervised; POWER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3TKNE25A","journalArticle","2023","Jahangir, R; Nauman, MA; Alroobaea, R; Almotiri, J; Malik, MM; Alzahrani, SM","Deep Learning-based Environmental Sound Classification Using Feature Fusion and Data Enhancement","CMC-COMPUTERS MATERIALS & CONTINUA","","1546-2218","10.32604/cmc.2023.032719","","Environmental sound classification (ESC) involves the process of distinguishing an audio stream associated with numerous environmental sounds. Some common aspects such as the framework difference, overlapping of different sound events, and the presence of various sound sources during recording make the ESC task much more complicated and complex. This research is to propose a deep learning model to improve the recognition rate of environmental sounds and reduce the model training time under limited computation resources. In this research, the performance of transformer and convolutional neural networks (CNN) are investigated. Seven audio features, chromagram, Mel-spectrogram, tonnetz, Mel-Frequency Cepstral Coefficients (MFCCs), delta MFCCs, delta-delta MFCCs and spectral con-trast, are extracted from the UrbanSound8K, ESC-50, and ESC-10, databases. Moreover, this research also employed three data enhancement methods, namely, white noise, pitch tuning, and time stretch to reduce the risk of overfitting issue due to the limited audio clips. The evaluation of various experiments demonstrates that the best performance was achieved by the pro-posed transformer model using seven audio features on enhanced database. For UrbanSound8K, ESC-50, and ESC-10, the highest attained accuracies are 0.98, 0.94, and 0.97 respectively. The experimental results reveal that the proposed technique can achieve the best performance for ESC problems.","2023","2025-02-26 20:41:53","2025-02-26 20:41:53","","1069-1091","","1","74","","","","","","","","","","English","","","","WOS:000871059600007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","convolutional neural network; data augmentation; deep learning; Environmental sound classification; RECOGNITION; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ITT2Y6LN","journalArticle","2024","Zhang, M; Yousif, MZ; Yu, LQ; Lim, HC","Enhanced retrospective forecasting in dissipative dynamical systems using transformer and multi-scale ESRGAN models","RESULTS IN ENGINEERING","","2590-1230","10.1016/j.rineng.2024.103597","","Accurate characterization of complex dynamical systems is crucial for understanding their intrinsic behavior, and retrospective prediction provides a promising solution. However, traditional methods often fail to effectively predict dissipative terms, which are key in dissipative dynamical systems. This study introduces a deep learning method (DLM) that combines a Transformer model with a multiscale enhanced super-resolution generative adversarial network (MS-ESRGAN) to improve retrospective predictions by extracting implicit information from temporal evolution data. The Transformer excels at capturing past dynamics, while MS-ESRGAN refines the predicted fields, achieving resolutions on par with ground truth data. The effectiveness of the DLM is demonstrated using two canonical flow cases: forced isotropic turbulence and a transitional boundary layer. The model closely matches the velocity fields of the ground truth, with only minor deviations attributed to the nonlinearity of the governing equations and the inherent difficulty in resolving small-scale structures. In addition, the DLM has been applied to National Oceanic and Atmospheric Administration (NOAA) sea surface temperature (SST) data, demonstrating its practical utility for climate science. Despite the challenges associated with capturing small-scale structures, the data-driven DLM outperforms traditional numerical methods that either neglect the dissipative term or utilize negative dissipative coefficients, representing a significant advancement in retrospective predictions.","2024-12","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","24","","","","","","","","","","English","","","","WOS:001375726900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","ALGORITHM; BACK; Deep learning; Dissipative dynamical systems; Generative adversarial network; Retrospective prediction; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XWVJXNQH","journalArticle","2024","Mao, XH; Xiong, B; Luo, X; Yao, ZL; Huang, YP","Short-term prediction of water level based on deep learning in the downstream area of the Three Gorges Reservoir","NATURAL HAZARDS","","0921-030X","10.1007/s11069-024-06772-1","","Accurately predicting river water levels is crucial for managing water resources and controlling floods. In this study, we propose a water level prediction model based on a deep learning method (Transformer model) to improve the accuracy and efficiency of predicting inland river water levels. Water level data from seven hydrological stations were collected from the downstream area of the Three Gorges Reservoir, which confirmed the effectiveness of the model. The proposed model was improved by three main algorithms: the wavelet thresholding denoising algorithm, the maximum information coefficient (MIC) algorithm, and the linear exponential (LINEX) loss function. The results show that the proposed MIC-TF-LINEX model has achieved superior performance in predicting water levels compared to other models, such as traditional Transformer, Back Propagation Neural Network, and Bi-directional Long Short-Term Memory. Furthermore, extending the forecast period will also affect the accuracy of the water level forecasting model. When the prediction duration is 8 h, the R2 value is 0.9989, the MAE is 0.1020, the MSE is 0.0166, and the MAPE is 0.0060. When the prediction timeframe is within 56 h, the MSE of the prediction result is still less than 0.1 m. This study provides a highly accurate and well-suited method for predicting water level.","2024-12","2025-02-26 20:41:53","2025-02-26 20:41:53","","14259-14278","","15","120","","","","","","","","","","English","","","","WOS:001272241200002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Linear exponential loss; MIC; MODEL; PARAMETERS; Three Gorges Reservoir; Transformer; Water level forecast","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GXI7LG2B","journalArticle","2024","Shahzadi, I; Madni, TM; Janjua, UI; Batool, G; Naz, B; Ali, MQ","CSAMDT: Conditional Self Attention Memory-Driven Transformers for Radiology Report Generation from Chest X-Ray","JOURNAL OF IMAGING INFORMATICS IN MEDICINE","","2948-2925","10.1007/s10278-024-01126-6","","A radiology report plays a crucial role in guiding patient treatment, but writing these reports is a time-consuming task that demands a radiologist's expertise. In response to this challenge, researchers in the subfields of artificial intelligence for healthcare have explored techniques for automatically interpreting radiographic images and generating free-text reports, while much of the research on medical report creation has focused on image captioning methods without adequately addressing particular report aspects. This study introduces a Conditional Self Attention Memory-Driven Transformer model for generating radiological reports. The model operates in two phases: initially, a multi-label classification model, utilizing ResNet152 v2 as an encoder, is employed for feature extraction and multiple disease diagnosis. In the second phase, the Conditional Self Attention Memory-Driven Transformer serves as a decoder, utilizing self-attention memory-driven transformers to generate text reports. Comprehensive experimentation was conducted to compare existing and proposed techniques based on Bilingual Evaluation Understudy (BLEU) scores ranging from 1 to 4. The model outperforms the other state-of-the-art techniques by increasing the BLEU 1 (0.475), BLEU 2 (0.358), BLEU 3 (0.229), and BLEU 4 (0.165) respectively. This study's findings can alleviate radiologists' workloads and enhance clinical workflows by introducing an autonomous radiological report generation system.","2024-12","2025-02-26 20:41:53","2025-02-26 20:41:53","","2825-2837","","6","37","","","","","","","","","","English","","","","WOS:001237735900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Autonomous Radiological Report Generation; Bilingual Evaluation Understudy; Chest X-ray; Memory-driven Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ALUHHPPC","journalArticle","2024","Zhao, JL; Wang, JJ; Ruan, C; Dong, YY; Huang, LS","Dual-Branch Spectral–Spatial Attention Network for Hyperspectral Image Classification","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2024.3351997","","In order to achieve accurate hyperspectral image (HSI) classification, the convolutional neural network (CNN) has been extensively utilized. However, most existing patch-based CNN methods overlook the relationship between central pixels and their surroundings. A novel dual-branch spectral-spatial attention network (DBSSAN) is proposed, which helps suppress the impact from interference elements and enhances effective feature extraction from complex features in HSI data. The global and local spatial features are fully integrated through the proposed spatial self-attention module. More specifically, it measures the relationship between the central and surrounding pixels based on cosine similarity and Gaussian-Euclidean similarity to extract global features, while the scale information extraction (SIE) model captures the local features. Furthermore, the inclusion of Transformer model enables the extraction of spectral information from a global perspective, facilitating the capture of long-distance dependencies and nonlinear correlations in HSI. The extracted spectral and spatial features are subsequently classified using a multilayer perceptron (MLP). Five publicly available hyperspectral datasets were used to present experimental evaluations, namely, Indian Pines, Kennedy Space Center, Pavia University, Houston2013, and Houston2018. The comparative results demonstrate the superior performance of the proposed network compared to several state-of-the-art methods.","2024","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","62","","","","","","","","","","English","","","","WOS:001173248900011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Central pixels; Computational modeling; Convolutional neural networks; Data mining; Feature extraction; hyperspectral classification; Hyperspectral imaging; multilayer perceptron (MLP); Principal component analysis; spectral-spatial attention; Transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DDYPPFFZ","journalArticle","2023","Gong, B; Dai, KY; Shao, J; Jing, L; Chen, YY","Fish-TViT: A novel fish species classification method in multi water areas based on transfer learning and vision transformer","HELIYON","","2405-8440","10.1016/j.heliyon.2023.e16761","","The classification of fish species has important practical significance for both the aquaculture industry and ordinary people. However, existing methods for classifying marine and freshwater fishes have poor feature extraction ability and do not meet actual needs. To address this issue, we propose a novel method for multi-water fish classification (Fish-TViT) based on transfer learning and visual transformers. Fish-TViT uses a label smoothing loss function to solve the problem of overfitting and overconfidence of the classifier. We also employ Gradient-weighted Category Activation Mapping (Grad-CAM) technology to visualize and understand the features of the model and the areas on which the decision depends, which guides the optimization of the model architecture. We first crop and clean fish images, and then use data augmentation to expand the number of training datasets. A pre-trained visual transformer model is used to extract enhanced features of fish images, which are subsequently cropped into a series of flat patches. Finally, a multi-layer perceptron is used to predict fish species. Experimental results show that Fish-TViT achieves high classification accuracy on both low-resolution marine fish data (94.33%) and high-resolution freshwater fish data (98.34%). Compared with traditional convolutional neural networks, Fish-TViT has better performance.","2023-06","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","6","9","","","","","","","","","","English","","","","WOS:001019383500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Deep learning; Fish species classification; IDENTIFICATION; Transfer learning; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NQCC9RS7","journalArticle","2022","Chaudhary, M; Vashistha, S; Bansal, D","Automated Detection of Anti-National Textual Response to Terroristic Events on Online Media","CYBERNETICS AND SYSTEMS","","0196-9722","10.1080/01969722.2022.2044596","","The advent of internet has led to prodigious growth in popularity of social media platforms for people to communicate and opinionate on topics of their interests. And, terroristic events being a topic of national importance, receives enormous response from the citizens. Unfortunately, miscreants with anti-national agendas incite the large available audience on these platforms against the country by inducing anti-national content amid terrorist attacks. The social media platforms being of informal use are commonly observed to have users opinionating using multiple languages in same sentence called code-mixing. The over-arching goal of research done is to identify anti-national code-mix textual content on YouTube in the form of comments on terrorism-related videos. We collected YouTube comments on videos related to terroristic events in Kashmir region of India, which consisted of code-mix comments in Hindi (native language of India) and English languages. The paper presents a novel deep-learning-based transformer model HE-CM-BERT, i.e. Hindi-English code-mix BERT, where we extend the vocabulary of pre-trained multilingual BERT with code-mix vocabulary extracted from the collected data to automate the detection of anti-national code-mix text. The comparative analysis of the proposed model with the state-of-the-art machine learning and deep learning models depicts that it outperforms the existing ones.","2022-11-17","2025-02-26 20:41:53","2025-02-26 20:41:53","","702-715","","8","53","","","","","","","","","","English","","","","WOS:000761532400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Anti-national text; SENTIMENT; terrorism; text classification; USERS; YouTube","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2ECSWAKW","journalArticle","2021","Gao, L; Liu, H; Yang, MH; Chen, L; Wan, YL; Xiao, ZQ; Qian, YR","STransFuse: Fusing Swin Transformer and Convolutional Neural Network for Remote Sensing Image Semantic Segmentation","IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING","","1939-1404","10.1109/JSTARS.2021.3119654","","The applied research in remote sensing images has been pushed by convolutional neural network (CNN). Because of the fixed size of the perceptual field, CNN is unable to model global semantic relevance. Modeling global semantic information is possible with the self-attentive Transformer-based model. However, the method of patch computation used by Transformer for self-attentive computation ignores the spatial information inside each patch. To address these issues, we offer the STransFuse model as a new semantic segmentation method for remote sensing images. It is a model that combines the benefits of Transformer with CNN to improve the segmentation quality of various remote sensing images. We employ a staged model to extract coarse-grained and fine-grained feature representations at various semantic scales, unlike earlier techniques based on Transformer model fusion. In order to take full advantage of the features acquired at different stages, we designed an adaptive fusion module. This module adaptively fuses the semantic information between features at different scales employing a self-attentive mechanism. The overall accuracy (OA) of our proposed model on the Vaihingen dataset is 1.36% higher than the baseline, and 1.27% improvement in OA over baseline on the Potsdam dataset. When compared to other advanced models, the STransFuse model performs admirably.","2021","2025-02-26 20:41:53","2025-02-26 20:41:53","","10990-11003","","","14","","","","","","","","","","English","","","","WOS:000716698800009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;140<br/>Total Times Cited:&nbsp;&nbsp;149<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Computational modeling; Context modeling; Feature extraction; Image segmentation; Remote sensing; self-attention; semantic segmentation; Semantics; Transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GRYWPDQF","journalArticle","2025","Chen, YJ; Cui, H; Zhang, G; Li, X; Xie, ZG; Li, HF; Li, DR","SparseFormer: A Credible Dual-CNN Expert-Guided Transformer for Remote Sensing Image Segmentation With Sparse Point Annotation","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2024.3523537","","Although significant advances have been made in the semantic segmentation of high-resolution remote sensing (RS) images, obtaining accurate pixelwise annotations remains resource-intensive. We propose SparseFormer, a credible dual-convolutional neural network (CNN) expert-guided Transformer model designed for semantic segmentation using point-level annotations to reduce this annotation burden. SparseFormer comprises three branches, where two CNN branches employ different attention mechanisms to encourage diverse outputs. To enhance the local consistency of pseudolabels, we introduce a pixel-adaptive refinement (PAR) module that dynamically refines CNN output probabilities by incorporating image information during training. A credible assessment is then performed to combine the CNN outputs, producing high-quality pseudolabels that supervise the CNN-Transformer hybrid branch. This hybrid branch integrates global representations with local features, achieving precise segmentation. To further strengthen the CNN branches, we introduce a knowledge distillation strategy that steadily feeds back information from the hybrid branch to CNN branches, mitigating overfitting risks caused by sparse supervision. SparseFormer employs credible assessment to reduce pseudolabel uncertainty, followed by continuous interaction and dynamic information enhancement among the three branches in an end-to-end training process. Extensive experiments on two benchmark datasets demonstrate that SparseFormer significantly outperforms state-of-the-art methods. Our code is available at: https://github.com/Yujia73/SparseFormer.","2025","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","63","","","","","","","","","","English","","","","WOS:001414425700022","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","CLASSIFICATION; Knowledge distillation; point annotation; semantic segmentation; Transformer; weakly supervised (WS)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"49YI749M","journalArticle","2024","Su, ZA; Zhang, J","Weight Adjustment Framework for Self-Attention Sequential Recommendation","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14093608","","In recent years, sequential recommendation systems have become a hot topic in the field of recommendation system research. These systems predict future user actions or preferences by analyzing their historical interaction sequences, such as browsing history and purchase records, and then recommend items that users may be interested in. Among various sequential recommendation algorithms, those based on the Transformer model have become a focus of research due to their powerful self-attention mechanisms. However, one of the main challenges faced by sequential recommendation systems is the noise present in the input data, such as erroneous clicks and incidental browsing. This noise can disrupt the model's accurate allocation of attention weights, thereby affecting the accuracy and personalization of the recommendation results. To address this issue, we propose a novel method named ""weight adjustment framework for self-attention sequential recommendation"" (WAF-SR). WAF-SR mitigates the negative impact of noise on the accuracy of the attention layer weight distribution by improving the quality of the input data. Furthermore, WAF-SR enhances the model's understanding of user behavior by simulating the uncertainty of user preferences, allowing for a more precise distribution of attention weights during the training process. Finally, a series of experiments demonstrate the effectiveness of the WAF-SR in enhancing the performance of sequential recommendation systems.","2024-05","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","9","14","","","","","","","","","","English","","","","WOS:001219784200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","deep learning; denoise; self-attention mechanism; sequential recommendation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AMZ752EH","journalArticle","2023","Guo, B; Liu, HM; Niu, L","Safe physical interaction with cobots: a multi-modal fusion approach for health monitoring","FRONTIERS IN NEUROROBOTICS","","1662-5218","10.3389/fnbot.2023.1265936","","Health monitoring is a critical aspect of personalized healthcare, enabling early detection, and intervention for various medical conditions. The emergence of cloud-based robot-assisted systems has opened new possibilities for efficient and remote health monitoring. In this paper, we present a Transformer-based Multi-modal Fusion approach for health monitoring, focusing on the effects of cognitive workload, assessment of cognitive workload in human-machine collaboration, and acceptability in human-machine interactions. Additionally, we investigate biomechanical strain measurement and evaluation, utilizing wearable devices to assess biomechanical risks in working environments. Furthermore, we study muscle fatigue assessment during collaborative tasks and propose methods for improving safe physical interaction with cobots. Our approach integrates multi-modal data, including visual, audio, and sensor- based inputs, enabling a holistic assessment of an individual's health status. The core of our method lies in leveraging the powerful Transformer model, known for its ability to capture complex relationships in sequential data. Through effective fusion and representation learning, our approach extracts meaningful features for accurate health monitoring. Experimental results on diverse datasets demonstrate the superiority of our Transformer-based multi- modal fusion approach, outperforming existing methods in capturing intricate patterns and predicting health conditions. The significance of our research lies in revolutionizing remote health monitoring, providing more accurate, and personalized healthcare services.","2023-12-04","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","17","","","","","","","","","","English","","","","WOS:001129253900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","biomechanical strain; cognitive workload; human-machine; interaction cobots; muscle fatigue; RESOURCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"22TPTU3M","journalArticle","2023","Ni, SY; Lin, CB; Wang, HN; Li, Y; Liao, YR; Li, N","Learning geometric Jensen-Shannon divergence for tiny object detection in remote sensing images","FRONTIERS IN NEUROROBOTICS","","1662-5218","10.3389/fnbot.2023.1273251","","Tiny objects in remote sensing images only have a few pixels, and the detection difficulty is much higher than that of regular objects. General object detectors lack effective extraction of tiny object features, and are sensitive to the Intersection-over-Union (IoU) calculation and the threshold setting in the prediction stage. Therefore, it is particularly important to design a tiny-object-specific detector that can avoid the above problems. This article proposes the network JSDNet by learning the geometric Jensen-Shannon (JS) divergence representation between Gaussian distributions. First, the Swin Transformer model is integrated into the feature extraction stage as the backbone to improve the feature extraction capability of JSDNet for tiny objects. Second, the anchor box and ground-truth are modeled as two two-dimensional (2D) Gaussian distributions, so that the tiny object is represented as a statistical distribution model. Then, in view of the sensitivity problem faced by the IoU calculation for tiny objects, the JSDM module is designed as a regression sub-network, and the geometric JS divergence between two Gaussian distributions is derived from the perspective of information geometry to guide the regression prediction of anchor boxes. Experiments on the AI-TOD and DOTA datasets show that JSDNet can achieve superior detection performance for tiny objects compared to state-of-the-art general object detectors.","2023-11-09","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","17","","","","","","","","","","English","","","","WOS:001105060000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","deep learning; Gaussian distribution; Jensen-Shannon divergence; remote sensing images; tiny object detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M7J53G2B","journalArticle","2023","Xu, BB; Ma, BQ; Yang, Z; Chen, F; Li, XB","Cross-Component Transferable Transformer Pipeline Obeying Dynamic Seesaw for Rotating Machinery with Imbalanced Data","SENSORS","","1424-8220","10.3390/s23177431","","Due to the lack of fault data in the daily work of rotating machinery components, existing data-driven fault diagnosis procedures cannot accurately diagnose fault classes and are difficult to apply to most components. At the same time, the complex and variable working conditions of components pose a challenge to the feature extraction capability of the models. Therefore, a transferable pipeline is constructed to solve the fault diagnosis of multiple components in the presence of imbalanced data. Firstly, synchrosqueezed wavelet transforms (SWT) are improved to highlight the time-frequency feature of the signal and reduce the time-frequency differences between different signals. Secondly, we proposed a novel hierarchical window transformer model that obeys a dynamic seesaw (HWT-SS), which compensates for imbalanced samples while fully extracting key features of the samples. Finally, a transfer diagnosis between components provides a new approach to solving fault diagnosis with imbalanced data among multiple components. The comparison with the benchmark models in four datasets proves that the proposed model has the advantages of strong feature extraction capability and low influence from imbalanced data. The transfer tests between datasets and the visual interpretation of the model prove that the transfer diagnosis between components can further improve the diagnostic capability of the model for extremely imbalanced data.","2023-09","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","17","23","","","","","","","","","","English","","","","WOS:001062809500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","fault diagnosis; FAULT-DIAGNOSIS; rotating machinery; transfer learning; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VL2EJYTE","journalArticle","2023","Bonthu, S; Sree, SR; Prasad, MHMK","Improving the performance of automatic short answer grading using transfer learning and augmentation","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2023.106292","","The task of grading answers ranging from one phrase to one paragraph using computational techniques is known as Automated Short Answer Grading (ASAG). The performance of existing systems is not good enough due to limited data and the lack of availability of data in many domains. Many ASAG systems were developed as an outcome of the active research in this field. This study builds an effective system for grading short answers in the programming domain by leveraging Pre-trained Language Models and Text Augmentation. We fine-tuned three-sentence transformer models on the SPRAG corpus with five different augmentation techniques: viz., Random Deletion, Synonym Replacement, Random Swap, Backtranslation, and NLPAug. The SPRAG corpus contains student responses involving keywords and special symbols. We experimented with four different data sizes with the augmented data to determine the impact of training data on the fine-tuned sentence transformer model. this paper provides an exhaustive analysis of fine-tuning pretrained sentence transformer models with varying sizes of data by applying text augmentation techniques. we found that applying random swap and synonym replacement techniques together while fine-tuning has given a significant improvement, With a 4.91% increase in accuracy and a 3.36% increase in the F1-score. All the trained models are publicly available1.","2023-08","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","123","","","","","","","","","","English","","","","WOS:000980732300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","ASAG; Augmentation; Backtranslation; Random deletion; Random swap; SBERT; SPRAG corpus; Synonym replacement; Transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J3JGI4NS","journalArticle","2023","Moulouel, K; Chibani, A; Amirat, Y","Ontology-based hybrid commonsense reasoning framework for handling context abnormalities in uncertain and partially observable environments","INFORMATION SCIENCES","","0020-0255","10.1016/j.ins.2023.02.078","","Ambient intelligence (AmI) systems aim to provide users with context-aware assistance services intended to improve the quality of their lives in terms of autonomy, safety, and well-being. Taking the uncertainty and partial observability of these environments into account is of major importance for context recognition and, more specifically, to detect and solve context abnormalities such as those related to the user's behavior or those related to context attribute prediction. In this paper, an ontology-based framework integrating machine learning and probabilistic planning within commonsense reasoning is proposed to recognize the user's context and abnormalities associated with it. The reasoning is performed using event calculus in answer set programming (ECASP); ECASP allows for abductive and temporal reasoning, which results in an eXplainable AI (XAI) approach. A context ontology is proposed to axiomatize the reasoning and introduce the notion of probabilistic fluents into the EC formalism in order to perform probabilistic reasoning. The reasoning incorporates probabilistic planning based on a partially observable Markov decision process (POMDP) to solve knowledge incompleteness. To evaluate the proposed framework, real-life scenarios, based on the Orange4Home and SIMADL public datasets are implemented and discussed.","2023-06","2025-02-26 20:41:53","2025-02-26 20:41:53","","468-486","","","631","","","","","","","","","","English","","","","WOS:000955196300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","ACTIVITY RECOGNITION; Answer set programming; CNN-LSTM model; Deep learning; DRIVEN; Event calculus; EVENT CALCULUS; Ontology; POMDP; Probabilistic commonsense reasoning; Probabilistic planning; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"USG9XXII","journalArticle","2023","Zhang, ER; Shao, LH; Wang, Y","Unifying transformer and convolution for dam crack detection","AUTOMATION IN CONSTRUCTION","","0926-5805","10.1016/j.autcon.2022.104712","","Cracks are a serious disease that threatens the safety of a hydraulic dam. However, detecting dam cracks in time is still a challenging task. It was found that the existing methods fail to detect elongated cracks, leading to discontinuous crack detection results. Moreover, the detection accuracy is severely affected due to the diversity and complexity of cracks and backgrounds. To address these problems, we propose a pixel-level crack detection network by unifying the transformer and CNN models (UTCD-Net). Specifically, the transformer model is designed to extract the global context features for detecting long-range cracks and removing distracting background information, the CNN model is employed to extract local feature information for the detection of thin cracks, and the final segmentation result is refined by the attention fusion module. In comparison with current mainstream methods, the proposed method can capture both local and global features of cracks, which are helpful to detect thin and long cracks. The method obtained promising results on our self-built dam dataset in terms of the Intersection of Union and F1 score (IoU:64.08%, F1:49.43%). Moreover, the experimental results on the other three public crack datasets demonstrate that the proposed method is flexible for adapting to different scenarios. The self-built dam crack dataset provides a challenging benchmark for future research.","2023-03","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","147","","","","","","","","","","English","","","","WOS:000913377400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;35<br/>Total Times Cited:&nbsp;&nbsp;36<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Crack detection; Deep supervision; Feature fusion; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YUTJTE2L","journalArticle","2023","Xu, D; Xiao, XQ; Liu, J; Sui, SB","Spatio-temporal degradation modeling and remaining useful life prediction under multiple operating conditions based on attention mechanism and deep learning","RELIABILITY ENGINEERING & SYSTEM SAFETY","","0951-8320","10.1016/j.ress.2022.108886","","Accurately predicting the Remaining Useful Life (RUL) is useful to avoid unexpected significant failure of en-gineering system and reduce maintenance costs effectively. Meanwhile, the diverse operating conditions and high-dimensional feature variables from diverse sensors spatially located in the system are two main obstacles for building an accurate and stable RUL prediction model. Considering that these two obstacles have not been fully considered in the state-of-art work, a novel RUL prediction method based on the improved Transformer model is proposed in this work, which resorts to the attention mechanism and deep learning considering spatio-temporal characteristics and multiple operating conditions. First, the difference of the original sequence data caused by operating conditions is eliminated by clustering and standardization in the data preprocessing process. The future condition information is also considered in RUL prediction calculation. Meanwhile, spatio-temporal feature is extracted by self-attention to realize the information fusion of multi-dimensional sensors and long-term series, in which position encoding is designed to retain the sequence information in the original sequence data. Finally, experimental results on the C-MAPSS and N-CMAPSS datasets show that the proposed method achieves a better performance compared with other existing methods.","2023-01","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","229","","","","","","","","","","English","","","","WOS:000875540700008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;39<br/>Total Times Cited:&nbsp;&nbsp;39<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Attention mechanism; Deep learning; MACHINERY; Multiple operating conditions; PROGNOSTICS; RUL prediction; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3NEHBXKR","journalArticle","2022","Kim, YW; Cho, WH; Kim, KS; Lee, S","Inertial-Measurement-Unit-Based Novel Human Activity Recognition Algorithm Using Conformer","SENSORS","","1424-8220","10.3390/s22103932","","Inertial-measurement-unit (IMU)-based human activity recognition (HAR) studies have improved their performance owing to the latest classification model. In this study, the conformer, which is a state-of-the-art (SOTA) model in the field of speech recognition, is introduced in HAR to improve the performance of the transformer-based HAR model. The transformer model has a multi-head self-attention structure that can extract temporal dependency well, similar to the recurrent neural network (RNN) series while having higher computational efficiency than the RNN series. However, recent HAR studies have shown good performance by combining an RNN-series and convolutional neural network (CNN) model. Therefore, the performance of the transformer-based HAR study can be improved by adding a CNN layer that extracts local features well. The model that improved these points is the conformer-based-model model. To evaluate the proposed model, WISDM, UCI-HAR, and PAMAP2 datasets were used. A synthetic minority oversampling technique was used for the data augmentation algorithm to improve the dataset. From the experiment, the conformer-based HAR model showed better performance than baseline models: the transformer-based-model and the 1D-CNN HAR models. Moreover, the performance of the proposed algorithm was superior to that of algorithms proposed in recent similar studies which do not use RNN-series.","2022-05","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","10","22","","","","","","","","","","English","","","","WOS:000801303100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;18<br/>Total Times Cited:&nbsp;&nbsp;18<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","conformer; convolutional neural network; data augmentation; human activity recognition; inertial measurement unit; multi-head self-attention; SENSORS; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V2E4SIPB","journalArticle","2022","Lee, SY; Jeong, J","SSA-SL Transformer for Bearing Fault Diagnosis under Noisy Factory Environments","ELECTRONICS","","2079-9292","10.3390/electronics11091504","","Among the smart factory studies, we describe defect detection research conducted on bearings, which are elements of mechanical facilities. Bearing research has been consistently conducted in the past; however, most of the research has been limited to using existing artificial intelligence models. In addition, previous studies assumed the factories situated in the bearing defect research were insufficient. Therefore, a recent research was conducted that applied an artificial intelligence model and the factory environment. The transformer model was selected as state-of-the-art (SOTA) and was also applied to bearing research. Then, an experiment was conducted with Gaussian noise applied to assume a factory situation. The swish-LSTM transformer (Sl transformer) framework was constructed by redesigning the internal structure of the transformer using the swish activation function and long short-term memory (LSTM). Then, the data in noise were removed and reconstructed using the singular spectrum analysis (SSA) preprocessing method. Based on the SSA-Sl transformer framework, an experiment was performed by adding Gaussian noise to the Case Western Reserve University (CWRU) dataset. In the case of no noise, the Sl transformer showed more than 95% performance, and when noise was inserted, the SSA-Sl transformer showed better performance than the comparative artificial intelligence models.","2022-05","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","9","11","","","","","","","","","","English","","","","WOS:000795323000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","bearing fault diagnosis; CONVOLUTIONAL NEURAL-NETWORK; DECOMPOSITION; singular spectrum analysis; transformer; under noisy factory environments; WAVELET PACKET TRANSFORM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U8UP79LA","journalArticle","2022","Huy, PC; Minh, NQ; Tien, ND; Anh, TTQ","Short-Term Electricity Load Forecasting Based on Temporal Fusion Transformer Model","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3211941","","Electricity load forecasting plays an important role in the operation of power systems. Inaccurate forecast would reduce the safety of power supply and affect the economic and social activities as well as national defense and security. In addition, the forecast results also support decision-making on electricity generation and market transactions. Traditional methods such as AR, ARIMA, SARIMA have been widely used to forecast short term electricity load. Recently, load forecasting based on artificial and deep neural networks have shown significant accuracy improvement over traditional statistical models. In this research, a novel recurrent neural network named temporal fusion transformer (TFT) is used to forecast short-term electricity load of Hanoi city. The TFT is a newly developed model and it combines the advantages of several other RNN models such as LSTM and the self-attention mechanism. In addition to historical load data, we use temperature and humidity features, and time features such as calendar month, lunar month, days of the week, hours of the day and holidays. The forecast results of TFT are compared with traditional statistical models as well as well-known RNN models. The compared results show that the proposed method is better than other methods in both MAE and MAPE criteria.","2022","2025-02-26 20:41:53","2025-02-26 20:41:53","","106296-106304","","","10","","","","","","","","","","English","","","","WOS:000866426900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;35<br/>Total Times Cited:&nbsp;&nbsp;35<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","artificial intelligence; Artificial neural networks; Autoregressive processes; Forecasting; load forecasting; Load modeling; Logic gates; Market research; Power systems; Predictive models; recurrent neural network; Recurrent neural networks; SYSTEM; temporal fusion transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z8593B4C","journalArticle","2025","Yin, YF; Pan, YM; Bao, XJ; Huang, FL","Conversational Recommendations With User Entity Focus and Multi-Granularity Latent Variable Enhancement","IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING","","1041-4347","10.1109/TKDE.2024.3523283","","Conversational recommendation is one system that can extract the user's preferences and recommend suitable items in a similar way to human-like responses. Existing methods often use the feature extraction combined with the Transformer model to extract user preferences and make recommendations. However, these methods have two limitations. First, they do not consider the order in which entities appear, thus affecting the extraction of user preferences. Second, the generated responses lack diversity that affects the users' experience to the system. To this end, we propose a conversational recommendation model with User Entity focus and Multi-Granularity latent variable enhancement (UEMG). In UEMG, we design a novel neural network that utilizes Bi-GRU to capture the appearing orders of entities in dialogues, and leverages Transformer to capture the global dependencies of entities, and then combines them to extract user preferences. For the second issue, to improve the diversity of dialogue generation, we propose a multi-granularity latent variable mechanism, which can extract more entities from the context information and the knowledge graphs, respectively. We conducted extensive experiments on publicly available dialogue generation datasets. Experimental results demonstrate that compared to current state-of-the-art methods, UEMG achieves 9.7% improvements in recommendation performance and 23% improvements in dialogue generation.","2025-03","2025-02-26 20:41:53","2025-02-26 20:41:53","","1126-1139","","3","37","","","","","","","","","","English","","","","WOS:001410873400030","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Accuracy; Computer science; Conversational recommender systems; DIALOG; dialog generation; entity focus; Feature extraction; Knowledge graphs; latent variables; Oral communication; recommendation; Recommender systems; Timing; Training; Transformers; Vectors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VUW2JXIJ","journalArticle","2025","Marjani, M; Mohammadimanesh, F; Mahdianpari, M; Gill, EW","A novel spatio-temporal vision transformer model for improving wetland mapping using multi-seasonal sentinel data","REMOTE SENSING APPLICATIONS-SOCIETY AND ENVIRONMENT","","2352-9385","10.1016/j.rsase.2024.101401","","Wetlands mapping using remote sensing data is a challenging task due to the spectral similarity of wetlands, the fragmented nature of these landscapes, and seasonal variations in wetlands. To address these limitations, this study proposes a novel spatio-temporal vision transformer (ST-ViT) model for an accurate wetland classification using seasonal data. The ST-ViT model was trained using multi-seasonal Sentinel-1 (S1) and Sentinel-2 (S2) data acquired during the spring, summer, and fall of 2020 in a study area located in Newfoundland and Labrador, Canada. The performance of the ST-ViT model was evaluated against the validation dataset, achieving an overall accuracy (OA) of 0.950 and F1-score (F1) of 0.934, outperforming other deep learning models such as random forest (RF), hybrid spectral network (HybridSN), etc. The model demonstrated strong classification capabilities among most wetland classes, with some challenges in distinguishing between spectrally similar classes like bogs and fens. Moreover, the integration of spatio-temporal features enabled the reduction of feature mixing between wetland classes, particularly during different seasons. The ST-ViT model provides an accurate wetland distribution map in different seasons, supporting critical decision-making processes related to wetland conservation and environmental monitoring.","2025-01","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","37","","","","","","","","","","English","","","","WOS:001395327600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","CLASSIFICATION; Deep learning; NETWORK; Sentinel-1 (S1); Sentinel-2 (S2); Spatio-temporal vision transformer (ST-ViT); Wetland mapping","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KMND8YIM","journalArticle","2024","Wang, CC","Optimization model for identification of node topology relationships in an online education platform based on the IOELM-KSFTR algorithm","SERVICE ORIENTED COMPUTING AND APPLICATIONS","","1863-2386","10.1007/s11761-024-00437-4","","Online education rapidly rises, but problems also emerge, such as limited interaction between teachers and students, lack of depth in face-to-face communication, and greatly reduced learning effectiveness. To address these issues, research was conducted on key semantic feature selection based on dynamic networks, and the topological relationships between various elements in the learning content were processed using transformer models. The transformer model was introduced in this experiment, and a multi-head self-attention mechanism and single hot encoding were adopted. A new online education interactive learning model was designed. These experiments confirmed that among various latest algorithms, the proposed algorithm performed the best, with its accuracy curve converging after 150 iterations and finally converging to 98%. This not only proved the effectiveness of this algorithm, but also highlighted its superiority in handling complex problems. It is worth mentioning that the utilization rate of the system processor in this model always remained at a low-level during operation, with an average utilization rate of only 8.8%. Even at peak hours, its utilization rate was only 17.6%. This proposed model has the advantages of high accuracy and low resource consumption. Through this approach, learners can more conveniently obtain the required knowledge and improve learning efficiency and effectiveness.","2024-11-18","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","","","","","","","","","","","English","","","","WOS:001357812100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Aggregation function; ENERGY; FEATURE-EXTRACTION; GraphSAGE; Online education; TOOLS; Topological relationships; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HV2GA4QX","journalArticle","2024","Zheng, YF; Lu, J; Chen, XG; Zhang, KB; Zhou, J","MATNet: Semantic segmentation of 3D point clouds with multiscale adaptive transformer","COMPUTERS & ELECTRICAL ENGINEERING","","0045-7906","10.1016/j.compeleceng.2024.109526","","In recent years, the Transformer model has made significant progress in semantic segmentation tasks. However, existing self-attention mechanisms perform well in capturing remote dependencies and global features, but ignore local area information in point cloud data and have limitations in dealing with multi-scale features. To address this problem, this paper introduces a multiscale self-attention fusion (MSA) module, which adaptively fuses features within different scale neighborhoods and learns global contextual features by connecting local neighborhoods. Then, the multiscale channel aggregation module (MCA)is used to perform deep point-by-point and point-by-point convolution of the point cloud channel, aggregating channel features at multiple scales to extract more accurate local feature information. Finally, in this study, the multiscale adaptive fusion (MSA) module and the multiscale channel aggregation (MCA) module form a sequential network structure that adaptively and dynamically adjusts different scales of point cloud objects to enhance the perception of objects of different sizes for better segmentation performance. By testing and validating the model on the publicly available S3DIS Area 5 dataset and the ScantNetV2 dataset, the model achieves mIoU index values of 71.9% and 72.3%, respectively, which demonstrates the effectiveness and superiority of the proposed method. Code will be made publicly available at https://github.com/Cocoyufei/MAT/tree/master.","2024-10","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","119","","","","","","","","","","English","","","","WOS:001293387100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","3D point cloud; Multiscale; Selfattention; Semantic segmentation; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CDICV4G5","journalArticle","2024","Zhao, YX; Behdad, S","State of Health Estimation of Electric Vehicle Batteries Using Transformer-Based Neural Network","JOURNAL OF ENERGY RESOURCES TECHNOLOGY-TRANSACTIONS OF THE ASME","","0195-0738","10.1115/1.4065762","","Electric vehicles (EVs) are considered an environmentally friendly option compared to conventional vehicles. As the most critical module in EVs, batteries are complex electrochemical components with nonlinear behavior. On-board battery system performance is also affected by complicated operating environments. Real-time EV battery in-service status prediction is tricky but vital to enable fault diagnosis and prevent dangerous occurrences. Data-driven models with advantages in time-series analysis can be used to capture the degradation pattern from data about certain performance indicators and predict the battery states. The transformer model can capture long-range dependencies efficiently using a multi-head attention block mechanism. This paper presents the implementation of a standard transformer and an encoder-only transformer neural network to predict EV battery state of health (SOH). Based on the analysis of the lithium-ion battery from the NASA Prognostics Center of Excellence website's publicly accessible dataset, 28 features related to the charge and discharge measurement data are extracted. The features are screened using Pearson correlation coefficients. The results show that the filtered features can improve the model's accuracy and computational efficiency. The proposed standard transformer shows good performance in the SOH prediction.","2024-07-18","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","10","146","","","","","","","","","","English","","","","WOS:001359718300003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","alternative energy sources; CHARGE; electric vehicle batteries; energy storage systems; LITHIUM-ION BATTERIES; MODELS; state of health estimation; transformer networks; USEFUL LIFE PREDICTION; VALIDATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ACAS2NCL","journalArticle","2024","Wang, Z; Zhang, JD; Sun, MJ","MoCoformer: Quantifying Temporal Irregularities in Solar Wind for Long-Term Sequence Prediction","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14114775","","Long-term solar wind sequence forecasting is essential for understanding the influence of the solar wind on celestial settings, predicting variations in solar wind parameters, and identifying patterns of solar activity. The intrinsic erratic temporal features of solar wind datasets present significant challenges to the development of solar wind factor estimate techniques. In response to these challenges, we present MoCoformer, a novel model based on the Transformer model in deep learning that integrates the Multi-Mode Decomp Block and Mode Independence Attention. The Multi-Mode Decomp Block employs an optimized version of variational mode decomposition technology to flexibly handle irregular features by adaptively decomposing and modeling the impact of sudden events on the temporal dynamics, enhancing its ability to manage non-stationary and irregular features effectively. Meanwhile, the Mode Independence Attention module computes attention independently for each mode, capturing the correlation between sequences and mitigating the negative impact of irregular features on time series prediction. The experimental results on solar wind datasets demonstrate that MoCoformer significantly outperforms current state-of-the-art methods in time series forecasting, showcasing superior predictive performance. This underscores the resilience of MoCoformer in handling the intricate, irregular temporal characteristics of solar wind data, rendering it a valuable instrument for enhancing the understanding and forecasting of solar wind dynamics.","2024-06","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","11","14","","","","","","","","","","English","","","","WOS:001245792300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","CORONA; deep learning; FORECAST; long-term prediction; machine learning; MODEL; PROPAGATION; solar wind forecasting; SPEED","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T5I3VMI7","journalArticle","2024","Zhao, EZ; Guo, ZC; Shi, SZ; Li, Y; Li, J; Zhang, DZ","Boosting the Generalization Ability for Hyperspectral Image Classification Using Spectral-Spatial Axial Aggregation Transformer","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2024.3463187","","In the hyperspectral image classification (HSIC) task, the most commonly used model validation paradigm is partitioning the training-test dataset through pixelwise random sampling. By training on a small amount of data, the deep learning model can achieve almost perfect accuracy. However, in our experiments, we found that the high accuracy was reached because the training and test datasets share a lot of information. On nonoverlapping dataset partitions, well-performing models suffer significant performance degradation. To this end, we propose a spectral-spatial axial aggregation transformer model, namely, SaaFormer, which preserves generalization across dataset partitions. SaaFormer applies a multilevel spectral extraction structure to segment the spectrum into multiple spectrum clips such that the wavelength continuity of the spectrum across the channel is preserved. For each spectrum clip, the axial aggregation attention mechanism, which integrates spatial features along multiple spectral axes, is applied to mine the spectral characteristic. The multilevel spectral extraction and the axial aggregation attention emphasize spectral characteristics to improve the model generalization. The experimental results on five publicly available datasets demonstrate that our model exhibits comparable performance on the random partition while significantly outperforming other methods on nonoverlapping partitions. Moreover, SaaFormer shows excellent performance on background classification.","2024","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","62","","","","","","","","","","English","","","","WOS:001329087800009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","Analytical models; Artificial intelligence; ATTENTION; Axial aggregation; Data mining; Data models; Feature extraction; FUSION; generalization; hyperspectral image classification (HSIC); Image classification; NEURAL-NETWORKS; spectral-spatial; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3FCDEU75","journalArticle","2023","Semary, NA; Ahmed, W; Amin, K; Plawiak, P; Hammad, M","Improving sentiment classification using a RoBERTa-based hybrid model","FRONTIERS IN HUMAN NEUROSCIENCE","","1662-5161","10.3389/fnhum.2023.1292010","","IntroductionSeveral attempts have been made to enhance text-based sentiment analysis's performance. The classifiers and word embedding models have been among the most prominent attempts. This work aims to develop a hybrid deep learning approach that combines the advantages of transformer models and sequence models with the elimination of sequence models' shortcomings.MethodsIn this paper, we present a hybrid model based on the transformer model and deep learning models to enhance sentiment classification process. Robustly optimized BERT (RoBERTa) was selected for the representative vectors of the input sentences and the Long Short-Term Memory (LSTM) model in conjunction with the Convolutional Neural Networks (CNN) model was used to improve the suggested model's ability to comprehend the semantics and context of each input sentence. We tested the proposed model with two datasets with different topics. The first dataset is a Twitter review of US airlines and the second is the IMDb movie reviews dataset. We propose using word embeddings in conjunction with the SMOTE technique to overcome the challenge of imbalanced classes of the Twitter dataset.ResultsWith an accuracy of 96.28% on the IMDb reviews dataset and 94.2% on the Twitter reviews dataset, the hybrid model that has been suggested outperforms the standard methods.DiscussionIt is clear from these results that the proposed hybrid RoBERTa-(CNN+ LSTM) method is an effective model in sentiment classification.","2023-12-07","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","17","","","","","","","","","","English","","","","WOS:001128507900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","CNN plus LSTM; LSTM; RoBERTa; sentiment analysis; SMOTE; word embedding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KL8FWPX5","journalArticle","2023","Jha, K; Saha, S; Karmakar, S","Prediction of Protein-Protein Interactions Using Vision Transformer and Language Model","IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS","","1545-5963","10.1109/TCBB.2023.3248797","","The knowledge of protein-protein interaction (PPI) helps us to understand proteins' functions, the causes and growth of several diseases, and can aid in designing new drugs. The majority of existing PPI research has relied mainly on sequence-based approaches. With the availability of multi-omics datasets (sequence, 3D structure) and advancements in deep learning techniques, it is feasible to develop a deep multi-modal framework that fuses the features learned from different sources of information to predict PPI. In this work, we propose a multi-modal approach utilizing protein sequence and 3D structure. To extract features from the 3D structure of proteins, we use a pre-trained vision transformer model that has been fine-tuned on the structural representation of proteins. The protein sequence is encoded into a feature vector using a pre-trained language model. The feature vectors extracted from the two modalities are fused and then fed to the neural network classifier to predict the protein interactions. To showcase the effectiveness of the proposed methodology, we conduct experiments on two popular PPI datasets, namely, the human dataset and the S. cerevisiae dataset. Our approach outperforms the existing methodologies to predict PPI, including multi-modal approaches. We also evaluate the contributions of each modality by designing uni-modal baselines. We perform experiments with three modalities as well, having gene ontology as the third modality.","2023-09-01","2025-02-26 20:41:53","2025-02-26 20:41:53","","3215-3225","","5","20","","","","","","","","","","English","","","","WOS:001084646300054","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Language model; protein-protein interaction; SCALE; SEQUENCE; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5XHEQJK2","journalArticle","2023","Xie, FY; Wang, G; Zhu, HY; Sun, EG; Fan, QY; Wang, Y","Rolling Bearing Fault Diagnosis Based on SVD-GST Combined with Vision Transformer","ELECTRONICS","","2079-9292","10.3390/electronics12163515","","Aiming at rolling bearing fault diagnosis, the collected vibration signal contains complex noise interference, and one-dimensional information cannot be used to fully mine the data features of the problem. This paper proposes a rolling bearing fault diagnosis method based on SVD-GST combined with the Vision Transformer. Firstly, the one-dimensional vibration signal is preprocessed to reduce noise using singular value decomposition (SVD) to obtain a more accurate and useful signal. Then, the generalized S-transform (GST) is used to convert the processed one-dimensional vibration signal into a two-dimensional time-frequency image and make full use of the advantages of deep learning in image classification with higher recognition accuracy. In order to avoid the problem of limited sensory fields in CNN and the need for an RNN to compute step by step over time when processing sequence data, the use of a Vision Transformer model for pattern recognition classification is proposed. Finally, an experimental platform for the fault diagnosis of rolling bearings is built. The model is experimentally validated, achieving an average accuracy of 98.52% over multiple tests. Additionally, compared with the SVD-GST-2DCNN, STFT-CNN-LSTM, SVD-GST-LSTM, and GST-ViT fault diagnosis models, the proposed method has higher diagnostic accuracy and stability, providing a new method for rolling bearing fault diagnosis.","2023-08","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","16","12","","","","","","","","","","English","","","","WOS:001056775400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","ADAPTATION; fault diagnosis; generalized S-transform; rolling bearing; singular value decomposition; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F63XQFBN","journalArticle","2023","Wang, TT; Fang, K; Wei, W; Tian, JY; Pan, YY; Li, JQ","Microcontroller Unit Chip Temperature Fingerprint Informed Machine Learning for IIoT Intrusion Detection","IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS","","1551-3203","10.1109/TII.2022.3195287","","Physics-informed learning for industrial Internet is essential especially to safety issues. Consequently, various methods have been developed to conduct Industrial Internet of Things (IIoT) intrusion detection. However, the conventional methods usually require the help of auxiliary equipment (e.g., spectrum analyzers, log-periodic antennas), which proves to be unsuitable for general IIoT systems due to their poor versatility. Facing the dilemma mentioned above, this article proposes a microcontroller unit (MCU) chip temperature fingerprint informed machine learning method, called MTID, for IIoT intrusion detection. Specifically, first, the node's MCU temperature sequence is recorded and the relationship between the temperature sequence and the computational complexity of the node is analyzed. Then, we calculate the temperature residuals and construct a temperature residuals dataset. Finally, to identify the security status of the nodes, a self-encoder-based intrusion detection model is constructed. Furthermore, to ensure the model's applicability under the diversified deployment environment of IIoT systems, an online incremental training method is developed and applied. In the end, we use the Raspberry Pi 4B for experimental analysis when testing the performance of MTID. The results show that the accuracy of MTID for intrusion detection reaches 89%, which also demonstrates the feasibility of the intrusion detection method based on MCU temperature.","2023-02","2025-02-26 20:41:53","2025-02-26 20:41:53","","2219-2227","","2","19","","","","","","","","","","English","","","","WOS:000926964700107","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","IDENTIFICATION; Industrial Internet of Things (IIoT) intrusion detection; microcontroller unit (MCU) temperature; scientific machine learning; self-encoder; SYSTEM; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HZ3HXIH6","journalArticle","2024","Liu, YZ; He, M; Shi, MJ; Jeon, S","A Novel Model Combining Transformer and Bi-LSTM for News Categorization","IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS","","2329-924X","10.1109/TCSS.2022.3223621","","News categorization (NC), the aim of which is to identify distinct categories of news through analyzing the contents, has acquired substantial progress since deep learning was introduced into the natural language processing (NLP) field. As a state-of-art model, transformer's classification performance is not satisfied compared with recurrent neural network (RNN) and convolutional neural network (CNN) if it does not get pretrained. Based on the transformer model, this article proposes a novel framework that combines bidirectional long short-term memory (Bi-LSTM) network and transformer to solve this problem. In the suggested framework, the self-attention mechanism is substituted with Bi-LSTM to capture the semantic information from sentences. Meanwhile, an attention mechanism model is applied to focus on those important words and adjust their weights to solve the problem of long-distance information loss. With pooling network, the network complexity can be reduced and the main features can be highlighted by halving the dimension of the hidden state. Finally, after acquiring the hidden representation by the above structures, we utilize a contraction network to further capture the long-range associations from a text. Experiments on three large-scale corpora were performed to evaluate the suggested framework, and the results demonstrate that our model outperforms other models such as deep pyramid CNN (DPCNN), transformer.","2024-08","2025-02-26 20:41:53","2025-02-26 20:41:53","","4862-4869","","4","11","","","","","","","","","","English","","","","WOS:000896600300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Attention mechanism; bidirectional long short-term memory (Bi-LSTM); natural language processing (NLP); news categorization (NC); transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VH6FJP38","journalArticle","2022","Liu, Y; Xu, XT; Xiang, BJ; Chen, G; Gong, GL; Lu, HX","Transformer Based Binocular Disparity Prediction with Occlusion Predict and Novel Full Connection Layers","SENSORS","","1424-8220","10.3390/s22197577","","The depth estimation algorithm based on the convolutional neural network has many limitations and defects by constructing matching cost volume to calculate the disparity: using a limited disparity range, the authentic disparity beyond the predetermined range can not be acquired; Besides, the matching process lacks constraints on occlusion and matching uniqueness; Also, as a local feature extractor, a convolutional neural network lacks the ability of global context information perception. Aiming at the problems in the matching method of constructing matching cost volume, we propose a disparity prediction algorithm based on Transformer, which specifically comprises the Swin-SPP module for feature extraction based on Swin Transformer, Transformer disparity matching network based on self-attention and cross-attention mechanism, and occlusion prediction sub-network. In addition, we propose a double skip connection fully connected layer to solve the problems of gradient vanishing and explosion during the training process for the Transformer model, thus further enhancing inference accuracy. The proposed model in this paper achieved an EPE (Absolute error) of 0.57 and 0.61, and a 3PE (Percentage error greater than 3 px) of 1.74% and 1.56% on KITTI 2012 and KITTI 2015 datasets, respectively, with an inference time of 0.46 s and parameters as low as only 2.6 M, showing great advantages compared with other algorithms in various evaluation metrics.","2022-10","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","19","22","","","","","","","","","","English","","","","WOS:000867173300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","attention; binocular disparity; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XMZGKQFX","journalArticle","2021","Wang, LY; Niu, DT; Zhao, XJ; Wang, XY; Hao, MZ; Che, HL","A Comparative Analysis of Novel Deep Learning and Ensemble Learning Models to Predict the Allergenicity of Food Proteins","FOODS","","2304-8158","10.3390/foods10040809","","Traditional food allergen identification mainly relies on in vivo and in vitro experiments, which often needs a long period and high cost. The artificial intelligence (AI)-driven rapid food allergen identification method has solved the above mentioned some drawbacks and is becoming an efficient auxiliary tool. Aiming to overcome the limitations of lower accuracy of traditional machine learning models in predicting the allergenicity of food proteins, this work proposed to introduce deep learning model-transformer with self-attention mechanism, ensemble learning models (representative as Light Gradient Boosting Machine (LightGBM) eXtreme Gradient Boosting (XGBoost)) to solve the problem. In order to highlight the superiority of the proposed novel method, the study also selected various commonly used machine learning models as the baseline classifiers. The results of 5-fold cross-validation showed that the area under the receiver operating characteristic curve (AUC) of the deep model was the highest (0.9578), which was better than the ensemble learning and baseline algorithms. But the deep model need to be pre-trained, and the training time is the longest. By comparing the characteristics of the transformer model and boosting models, it can be analyzed that, each model has its own advantage, which provides novel clues and inspiration for the rapid prediction of food allergens in the future.","2021-04","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","4","10","","","","","","","","","","English","","","","WOS:000643013700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","allergenicity prediction; ALLERTOP; comparative analysis; deep learning; ensemble learning; food allergens; IDENTIFICATION; IN-SILICO PREDICTION; SERVER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C972PJ2A","journalArticle","2025","Liu, Y; Geng, QFB; Zhan, WH; Geng, ZX","A cascaded deep neural network for design and verification of surface lattice resonance metasurfaces biosensors","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2025.110172","","Artificial neural networks (ANNs) have gradually replaced labor-intensive tasks with their revolutionary advantages by extracting features from datasets. It has been shown that researchers can perform only one traditional finite-difference time-domain (FDTD) simulation and then utilize the neural network for data analysis. This study presents the spectral parameter multi-layer perceptron neural network (SPMLP), designed for the rapid prediction of optical responses in biosensing chips characterized by surface lattice resonance (SLR), achieving speeds thousands of times faster than conventional FDTD simulations. To obtain structures with a high- quality factor (Q) and low full width at half maximum (FWHM), multi-objective particle swarm optimization (MOPSO) techniques are employed to develop a high Q and low FWHM (HQLW) algorithm. This algorithm constructs a Transformer-based inverse network that translates structures into spectra and utilizes the spectral and sensing parameter extraction (SASPE) algorithm to derive essential parameters such as resonance wavelength (Ares), FWHM, and Q values. After structures are generated through the HQLW algorithm, spectra are obtained via the forward network, with continuous iterations refining structures until the desired parameters are achieved. Unlike previous efforts, the SLR-based neural network allows for user-defined sensing metrics and structural parameters, achieving a prediction accuracy of 97% and effective chips after 400 iterations.","2025-03-15","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","144","","","","","","","","","","English","","","","WOS:001417331400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Biosensors; Deep learning; INVERSE DESIGN; Localized surface plasmon resonance; MACHINE; Surface lattice resonance; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JLZTH6FC","journalArticle","2025","Chrisilla, S; SelvaKumari, RS","STIT-Net- A Wavelet based Convolutional Transformer Model for Motor Imagery EEG Signal Classification in the Sensorimotor Bands","CLINICAL EEG AND NEUROSCIENCE","","1550-0594","10.1177/15500594241312450","","Motor Imagery (MI) electroencephalographic (EEG) signal classification is a pioneer research branch essential for mobility rehabilitation. This paper proposes an end-to-end hybrid deep network ""Spatio Temporal Inception Transformer Network (STIT-Net)"" model for MI classification. Discrete Wavelet Transform (DWT) is used to derive the alpha (8-13) Hz and beta (13-30) Hz EEG sub bands which are dominant during motor tasks to enhance the performance of the proposed work. STIT-Net employs spatial and temporal convolutions to capture spatial dependencies and temporal information and an inception block with three parallel convolutions extracts multi-level features. Then the transformer encoder with self-attention mechanism highlights the similar task. The proposed model improves the classification of the Physionet EEG motor imagery dataset with an average accuracy of 93.52% and 95.70% for binary class in the alpha and beta bands respectively, and 85.26% and 87.34% for three class, for four class 81.95% and 82.66% were obtained in the alpha and beta band respective EEG based motor signals which is better compared to the results available in the literature. The proposed methodology is further evaluated on other motor imagery datasets, both for subject-independent and cross-subject conditions, to assess the performance of the model.","2025-01-29","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","","","","","","","","","","","English","","","","WOS:001408212700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","convolution; electroencephalogram (EEG); inception; motor imagery; NEURAL-NETWORK; transformer encoder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WXDDE4LP","journalArticle","2024","Wang, YQ; Zhao, XM; Li, Z; Zhu, WB; Gui, RZ","A novel hybrid model for multi-step-ahead forecasting of wind speed based on univariate data feature enhancement","ENERGY","","0360-5442","10.1016/j.energy.2024.133515","","Reliable multistep ahead wind speed forecasting (MAWSF) is critical for the energy management of wind farms and the long-term maintenance of wind power systems. However, relying on inherent meteorological features such as temperature and atmospheric pressure often fails to meet the deep learning model's feature requirements for accurate wind speed forecasting (WSF). This paper introduces a hybrid multistep forecasting model that constructs a univariate wind speed feature enhancement framework, combining random forest (RF) and Transformer models for WSF. Initially, the hybrid enhancement framework decomposes the univariate wind speed data and extracts time-series features, effectively mining the latent feature information. Subsequently, the RF feature selector filters out significant features contributing to WSF and eliminates redundant features to provide stable features. Finally, the Transformer model is utilized for both short-term and long-term MAWSF. This study conducted MAWSF on data with sampling intervals of 20 min, 30 min and 1 h. The results indicate that, compared to existing state-of-the-art models, the hybrid model in MAWSF tasks reduces the dependency of models on inherent meteorological features, achieving more accurate forecasting and faster computation speeds. Ultimately, the proposed model can provide reliable technical support for energy management and maintenance guidance in real-world wind farms.","2024-12-15","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","312","","","","","","","","","","English","","","","WOS:001350383200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","DECOMPOSITION; Multi-step-ahead forecasting; NETWORK; Transformer; Univariate data feature enhancement; Wind speed forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8DPJYHD8","journalArticle","2024","Boadu, F; Cheng, JL","Improving protein function prediction by learning and integrating representations of protein sequences and function labels","BIOINFORMATICS ADVANCES","","2635-0041","10.1093/bioadv/vbae120","","Motivation As fewer than 1% of proteins have protein function information determined experimentally, computationally predicting the function of proteins is critical for obtaining functional information for most proteins and has been a major challenge in protein bioinformatics. Despite the significant progress made in protein function prediction by the community in the last decade, the general accuracy of protein function prediction is still not high, particularly for rare function terms associated with few proteins in the protein function annotation database such as the UniProt.Results We introduce TransFew, a new transformer model, to learn the representations of both protein sequences and function labels [Gene Ontology (GO) terms] to predict the function of proteins. TransFew leverages a large pre-trained protein language model (ESM2-t48) to learn function-relevant representations of proteins from raw protein sequences and uses a biological natural language model (BioBert) and a graph convolutional neural network-based autoencoder to generate semantic representations of GO terms from their textual definition and hierarchical relationships, which are combined together to predict protein function via the cross-attention. Integrating the protein sequence and label representations not only enhances overall function prediction accuracy, but delivers a robust performance of predicting rare function terms with limited annotations by facilitating annotation transfer between GO terms.Availability and implementation https://github.com/BioinfoMachineLearning/TransFew.","2024-09-04","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","1","4","","","","","","","","","","English","","","","WOS:001304200100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"65LJAZE7","journalArticle","2023","Guo, YH; Jiang, RQ; Gu, X; Cheng, HD; Garg, H","A Novel Fuzzy Relative-Position-Coding Transformer for Breast Cancer Diagnosis Using Ultrasonography","HEALTHCARE","","2227-9032","10.3390/healthcare11182530","","Breast cancer is a leading cause of death in women worldwide, and early detection is crucial for successful treatment. Computer-aided diagnosis (CAD) systems have been developed to assist doctors in identifying breast cancer on ultrasound images. In this paper, we propose a novel fuzzy relative-position-coding (FRPC) Transformer to classify breast ultrasound (BUS) images for breast cancer diagnosis. The proposed FRPC Transformer utilizes the self-attention mechanism of Transformer networks combined with fuzzy relative-position-coding to capture global and local features of the BUS images. The performance of the proposed method is evaluated on one benchmark dataset and compared with those obtained by existing Transformer approaches using various metrics. The experimental outcomes distinctly establish the superiority of the proposed method in achieving elevated levels of accuracy, sensitivity, specificity, and F1 score (all at 90.52%), as well as a heightened area under the receiver operating characteristic (ROC) curve (0.91), surpassing those attained by the original Transformer model (at 89.54%, 89.54%, 89.54%, and 0.89, respectively). Overall, the proposed FRPC Transformer is a promising approach for breast cancer diagnosis. It has potential applications in clinical practice and can contribute to the early detection of breast cancer.","2023-09","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","18","11","","","","","","","","","","English","","","","WOS:001072053300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","ACCURACY; breast cancer; breast ultrasound (BUS) images; CLASSIFICATION; computer-aided diagnosis (CAD) systems; DIGITAL MAMMOGRAPHY; early detection; fuzzy relative-position coding; PERFORMANCE; transformer; ULTRASOUND IMAGES; UPDATE; US","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MI2F7QHY","journalArticle","2023","Cen, J; Yang, ZH; Wu, YB; Hu, XL; Jiang, LW; Chen, HH; Si, WW","A Mask Self-Supervised Learning-Based Transformer for Bearing Fault Diagnosis With Limited Labeled Samples","IEEE SENSORS JOURNAL","","1530-437X","10.1109/JSEN.2023.3264853","","In recent years, transformer has become an effective tool for fault diagnosis, but it has been shown that a sufficient amount of labeled data is usually required to train a transformer model. However, a few labeled data can be obtained in the actual industrial process, and labeling a large quantity of training samples is costly. To reduce the demand for training labeled samples, this article proposes a mask self-supervised learning-based transformer (MSFormer) for bearing fault diagnosis of multistage centrifugal fans in petrochemical units under the condition of limited samples. In mask self-supervised learning (SSL), unlabeled samples can be used to mine robust representations of fault signals and potential relationships between subsequences to obtain a pretrained model with well-generalized parameters. Then, a few labeled samples are utilized to fine-tune by supervised learning to enable MSFormer the discrimination ability to identify different bearing fault types. The effectiveness of the proposed method is fully validated on the multistage centrifugal fan dataset and the Case Western Reserve University (CWRU) motor bearing dataset. The experimental results demonstrate that MSFormer is effective in reducing the number of labeled training samples, and compared to state-of-the-art methods, MSFormer has superior diagnosis performance under the condition of limited labeled samples.","2023-05-15","2025-02-26 20:41:53","2025-02-26 20:41:53","","10359-10369","","10","23","","","","","","","","","","English","","","","WOS:000991857800011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;18<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Data models; Fault diagnosis; Feature extraction; limited sample; MODEL; self-supervised learning (SSL); Task analysis; Training; transformer; Transformers; Vibrations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V4AQWQU8","journalArticle","2022","Meng, LX; Tan, WJ; Ma, JG; Wang, RF; Yin, XX; Zhang, YC","Enhancing dynamic ECG heartbeat classification with lightweight transformer model","ARTIFICIAL INTELLIGENCE IN MEDICINE","","0933-3657","10.1016/j.artmed.2022.102236","","Arrhythmia is a common class of Cardiovascular disease which is the cause for over 31% of all death over the world, according to WHOs' report. Automatic detection and classification of arrhythmia, as an effective tool of early warning, has recently been received more and more attention, especially in the applications of wearable devices for data capturing. However, different from traditional application scenarios, wearable electrocardio-gram (ECG) devices have some drawbacks, such as being subject to multiple abnormal interferences, thus making accurate ventricular contraction (PVC) and supraventricular premature beat (SPB) detection to be more chal-lenging. The traditional models for heartbeat classification suffer from the problem of large-scale parameters and the performance in dynamic ECG heartbeat classification is not satisfactory. In this paper, we propose a novel light model Lightweight Fussing Transformer to address these problems. We developed a more lightweight structure named LightConv Attention (LCA) to replace the self-attention of Fussing Transformer. LCA has reached remarkable performance level equal to or higher than self-attention with fewer parameters. In particular, we designed a stronger embedding structure (Convolutional Neural Network with attention mechanism) to enhance the weight of features of internal morphology of the heartbeat. Furthermore, we have implemented the proposed methods on real datasets and experimental results have demonstrated outstanding accuracy of detecting PVC and SPB.","2022-02","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","124","","","","","","","","","","English","","","","WOS:000748991500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;59<br/>Total Times Cited:&nbsp;&nbsp;59<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","Arrhythmia detection; ARRHYTHMIA DETECTION; Attention; Deep learning; ECG classification; EXTRACTION; PERFORMANCE; SYSTEM; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IHDI9Y3T","journalArticle","2021","Alexakos, CT; Karnavas, YL; Drakaki, M; Tziafettas, IA","A Combined Short Time Fourier Transform and Image Classification Transformer Model for Rolling Element Bearings Fault Diagnosis in Electric Motors","MACHINE LEARNING AND KNOWLEDGE EXTRACTION","","2504-4990","10.3390/make3010011","","The most frequent faults in rotating electrical machines occur in their rolling element bearings. Thus, an effective health diagnosis mechanism of rolling element bearings is necessary from operational and economical points of view. Recently, convolutional neural networks (CNNs) have been proposed for bearing fault detection and identification. However, two major drawbacks of these models are (a) their lack of ability to capture global information about the input vector and to derive knowledge about the statistical properties of the latter and (b) the high demand for computational resources. In this paper, short time Fourier transform (STFT) is proposed as a pre-processing step to acquire time-frequency representation vibration images from raw data in variable healthy or faulty conditions. To diagnose and classify the vibration images, the image classification transformer (ICT), inspired from the transformers used for natural language processing, has been suitably adapted to work as an image classifier trained in a supervised manner and is also proposed as an alternative method to CNNs. Simulation results on a famous and well-established rolling element bearing fault detection benchmark show the effectiveness of the proposed method, which achieved 98.3% accuracy (on the test dataset) while requiring substantially fewer computational resources to be trained compared to the CNN approach.","2021-03","2025-02-26 20:41:53","2025-02-26 20:41:53","","228-242","","1","3","","","","","","","","","","English","","","","WOS:000682783500011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;31<br/>Total Times Cited:&nbsp;&nbsp;33<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","bearing fault; convolutional neural network; electric motors; fault diagnosis; image classification transformer; INTELLIGENT DIAGNOSIS; NETWORKS; short time fourier transform","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X55SKG2I","journalArticle","2025","Wu, YR; Lin, JY; Chen, HJ; Lan, H; Yang, L","A transformer-based double-order RFID indoor positioning system","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2025.126530","","Radio Frequency Identification (RFID) technology has recently attracted widespread attention in the indoor positioning task. Traditional indoor positioning methods typically collect target state information at multiple time points, organize it into a time series format, and then address the positioning task as a regression problem to estimate the target's location. However, these methods require multiple RFID readers for data collection, which significantly increases the overall cost of the positioning system. Furthermore, these methods often overlook the inherent dynamics within time series data, leading to a waste of valuable temporal information and suboptimal positioning accuracy. To address the challenges of high cost and low accuracy, in this paper, we propose a novel RFID indoor positioning system based on a Double-order Transformer model. Specifically, our approach leverages a single mobile RFID reader to lower data collection costs, and we design the GAIN network to mitigate data loss. By integrating first-order differentiation information, our model captures the temporal dynamics of the signal more effectively, allowing for a better understanding of signal variations over time. The Double-order Transformer processes both the original time-series data and the first-order differentiation data in parallel, enhancing the model's ability to extract meaningful spatial-temporal features. Experimental results demonstrate the superiority of our proposed model, notably enhancing localization accuracy and outperforming state-of-the-art benchmark methods across multiple metrics.","2025-05-01","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","271","","","","","","","","","","English","","","","WOS:001422269600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","Data imputation; Deep learning; Indoor positioning; RFID; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NNR5BIRM","journalArticle","2025","Yokotani, K; Yamamoto, T; Takahashi, H; Takamura, M; Abe, N","Sounds like gambling: detection of gambling venue visitation from sounds in gamblers' environments using a transformer","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-83389-1","","Objective digital measurement of gamblers visiting gambling venues is conducted using cashless cards and facial recognition systems, but these methods are confined within a single gambling venue. Hence, we propose an objective digital measurement method using a transformer, a state-of-the-art machine learning approach, to detect total gambling venue visitations for gamblers who visit multiple gambling venues using sounds in gamblers' environments. We sampled gambling and nongambling event datasets from websites to create a gambling play classifier. We also sampled gambling and nongambling location datasets for a gambling location detector. Further, we sampled practical dataset with four different recording conditions and two different recording devices. Our Swin transformer model with 54 classes (4 gambling play classes and 50 nongambling event classes) achieved highest accuracy (0.801). The gambling location detector of the Swin transformer also achieved high performance; the areas under the receiver operating characteristic curves (AUCs) for bingo, mahjong, pachinko, and electronic gambling machine plays were 0.845, 0.780, 0.826, and 0.833, respectively. Moreover, gambling visitation detector of the Swin transformer showed high performance especially in Pachinko (AUCs 0.972-0.715) regardless of their recording conditions and devices. These preliminary findings highlight the potential of environmental sounds to detect visits to gambling venues.","2025-01-02","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","1","15","","","","","","","","","","English","","","","WOS:001390087600042","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;87</p>","","","ACOUSTIC EVENT; Acoustic features; COCKTAIL-PARTY; Digital marker; DISORDER; Electronic gambling machine; Environmental sounds; Gambling venue visitation; Swin transformer; WINS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C9SJLMVV","journalArticle","2024","Kim, MJ; Chae, SG; Bae, SJ; Hwang, KG","Unsupervised few shot learning architecture for diagnosis of periodontal disease in dental panoramic radiographs","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-73665-5","","In the domain of medical imaging, the advent of deep learning has marked a significant progression, particularly in the nuanced area of periodontal disease diagnosis. This study specifically targets the prevalent issue of scarce labeled data in medical imaging. We introduce a novel unsupervised few-shot learning algorithm, meticulously crafted for classifying periodontal diseases using a limited collection of dental panoramic radiographs. Our method leverages UNet architecture for generating regions of interest (RoI) from radiographs, which are then processed through a Convolutional Variational Autoencoder (CVAE). This approach is pivotal in extracting critical latent features, subsequently clustered using an advanced algorithm. This clustering is key in our methodology, enabling the assignment of labels to images indicative of periodontal diseases, thus circumventing the challenges posed by limited datasets. Our validation process, involving a comparative analysis with traditional supervised learning and standard autoencoder-based clustering, demonstrates a marked improvement in both diagnostic accuracy and efficiency. For three real-world validation datasets, our UNet-CVAE architecture achieved up to average 14% higher accuracy compared to state-of-the-art supervised models including the vision transformer model when trained with 100 labeled images. This study not only highlights the capability of unsupervised learning in overcoming data limitations but also sets a new benchmark for diagnostic methodologies in medical AI, potentially transforming practices in data-constrained scenarios.","2024-10-05","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","1","14","","","","","","","","","","English","","","","WOS:001330396200034","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Artificial intelligence; CLASSIFICATION; Clustering algorithm; Convolutional variational autoencoder (CVAE); Deep learning; UNet","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CYWDYSRA","journalArticle","2024","Yang, K; Li, Q; Tian, CW; Zhang, HJ; Shi, AW; Li, JK","DeforT: Deformable transformer for visual tracking","NEURAL NETWORKS","","0893-6080","10.1016/j.neunet.2024.106380","","Most trackers formulate visual tracking as common classification and regression (i.e., bounding box regression) tasks. Correlation features that are computed through depth-wise convolution or channel-wise multiplication operations are input into both the classification and regression branches for inference. However, this matching computation with the linear correlation method tends to lose semantic features and obtain only a local optimum. Moreover, these trackers use an unreliable ranking based on the classification score and the intersection over union (IoU) loss for the regression training, thus degrading the tracking performance. In this paper, we introduce a deformable transformer model, which effectively computes the correlation features of the training and search sets. A new loss called the quality-aware focal loss (QAFL) is used to train the classification network; it efficiently alleviates the inconsistency between the classification and localization quality predictions. We use a new regression loss called alpha-GIoU to train the regression network, and it effectively improves localization accuracy. To further improve the tracker's robustness, the candidate object location is predicted by using a combination of online learning scores with a transformer-assisted framework and classification scores. An extensive experiment on six testing datasets demonstrates the effectiveness of our method. In particular, the proposed method attains a success score of 71.7% on the OTB-2015 dataset and an AUC score of 67.3% on the NFS30 dataset, respectively.","2024-08","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","176","","","","","","","","","","English","","","","WOS:001242423800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","Classification network; Deformable transformer; Regression network; Visual tracking","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5KUXJIRN","journalArticle","2024","Chen, XB; Zhang, HJ; Deng, FW; Liang, J; Yang, J","Stochastic Non-Autoregressive Transformer-Based Multi-Modal Pedestrian Trajectory Prediction for Intelligent Vehicles","IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS","","1524-9050","10.1109/TITS.2023.3342040","","Pedestrian trajectory prediction, which aims at predicting the future positions of all pedestrians in a crowd scene given their past trajectories, is the cornerstone of autonomous driving and intelligent transportation systems. Accurate prediction and fast inference are both indispensable for real-world applications. In this paper, we propose a stochastic non-autoregressive Transformer-based multi-modal trajectory prediction model to address the two challenges. Specifically, a novel graph attention module dedicated to joint learning of social and temporal interaction is proposed to explore the complex interaction among pedestrians while integrating sparse attention mechanism, pedestrian identity, and temporal order contained in the trajectory data. By doing so, the interaction across temporal and social dimensions can be simultaneously processed to extract abundant context features for prediction. Besides, to accelerate inference speed, we put forward a stochastic non-autoregressive Transformer model with multi-modal prediction capability where each future trajectory can be inferred in a parallel fashion, therefore, resulting in diverse trajectory predictions and less computational cost. Extensive experiments and ablation studies are performed to evaluate our approach. The empirical results demonstrate that the proposed model not only produces high prediction accuracy but also infers with fast speed. The code of the proposed method will be publicly available at https://github.com/xbchen82/SNARTF.","2024-05","2025-02-26 20:41:53","2025-02-26 20:41:53","","3561-3574","","5","25","","","","","","","","","","English","","","","WOS:001130329600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","graph attention; INTENTION; MODEL; multi-modal prediction; non-autoregressive transformer; Pedestrian trajectory prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TAH7YQDL","journalArticle","2024","Huang, WL; Deng, Y; Hui, SQ; Wu, Y; Zhou, SP; Wang, JJ","Sparse self-attention transformer for image inpainting","PATTERN RECOGNITION","","0031-3203","10.1016/j.patcog.2023.109897","","Learning-based image inpainting methods have made remarkable progress in recent years. Nevertheless, these methods still suffer from issues such as blurring, artifacts, and inconsistent contents. The use of vanilla convolution kernels, which have limited perceptual fields and spatially invariant kernel coefficients, is one of the main causes for these problems. In contrast, the multi-headed attention in the transformer can effectively model non-local relations among input features by generating adaptive attention scores. Therefore, this paper explores the feasibility of employing the transformer model for the image inpainting task. However, the multiheaded attention transformer blocks pose a significant challenge due to their overwhelming computational cost. To address this issue, we propose a novel U-Net style transformer-based network for the inpainting task, called the sparse self-attention transformer (Spa-former). The Spa-former retains the long-range modeling capacity of transformer blocks while reducing the computational burden. It incorporates a new channel attention approximation algorithm that reduces attention calculation to linear complexity. Additionally, it replaces the canonical softmax function with the ReLU function to generate a sparse attention map that effectively excludes irrelevant features. As a result, the Spa-former achieves effective long-range feature modeling with fewer parameters and lower computational resources. Our empirical results on challenging benchmarks demonstrate the superior performance of our proposed Spa-former over state-of-the-art approaches.","2024-01","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","145","","","","","","","","","","English","","","","WOS:001078661800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;38<br/>Total Times Cited:&nbsp;&nbsp;40<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Channel attention; Image inpainting; Sparse attention; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3ESNGZW3","journalArticle","2023","Vaskevicius, M; Kapociute-Dzikiene, J; Vaskevicius, A; Slepikas, L","Deep learning-based automatic action extraction from structured chemical synthesis procedures","PEERJ COMPUTER SCIENCE","","2376-5992","10.7717/peerj-cs.1511","","This article proposes a methodology that uses machine learning algorithms to extract actions from structured chemical synthesis procedures, thereby bridging the gap between chemistry and natural language processing. The proposed pipeline combines ML algorithms and scripts to extract relevant data from USPTO and EPO patents, which helps transform experimental procedures into structured actions. This pipeline includes two primary tasks: classifying patent paragraphs to select chemical procedures and converting chemical procedure sentences into a structured, simplified format. We employ artificial neural networks such as long short-term memory, bidirectional LSTMs, transformers, and fine-tuned T5. Our results show that the bidirectional LSTM classifier achieved the highest accuracy of 0.939 in the first task, while the Transformer model attained the highest BLEU score of 0.951 in the second task. The developed pipeline enables the creation of a dataset of chemical reactions and their procedures in a structured format, facilitating the application of AI-based approaches to streamline synthetic pathways, predict reaction outcomes, and optimize experimental conditions. Furthermore, the developed pipeline allows for creating a structured dataset of chemical reactions and procedures, making it easier for researchers to access and utilize the valuable information in synthesis procedures.","2023-08-18","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","9","","","","","","","","","","English","","","","WOS:001052591400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","Artificial intelligence; CHEMISTRY; Data mining; Data science; Deep learning; Machine learning; MODEL; Natural language processing; Organic chemistry; OUTCOMES; PREDICTION; Synthesis procedures; Text classification; Text generation; TRANSLATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KT32DT23","journalArticle","2025","Huang, XJ; Fang, SD; Niu, T; Chen, GH; Liao, RJ; Wang, ZR","Coordinated Voltage Regulation Strategy for an Energy Storage Integrated Distribution Network in Bidirectional Power Flow Mode","IEEE TRANSACTIONS ON INDUSTRY APPLICATIONS","","0093-9994","10.1109/TIA.2024.3430267","","The high penetration of renewable energy sources (RESs) accessed to distribution networks (DNs) causes frequent power exchanges between transmission networks (TNs) and DNs and makes voltage control more difficult. To address this issue, a coordinated voltage regulation strategy for different RES penetration levels is presented in this paper. First, a bidirectional transformer model is established to quantify the voltage control profiles when facing bidirectional power flows. Second, an energy storage system (ESS) management model considering the influence of ambient temperature on batteries is developed and acts as a key regulating approach for voltage profiles. Finally, the multi-level coordinated regulation strategy is proposed by the RES penetration levels to mitigate the voltage fluctuations during bidirectional power flow modes. The simulation analysis based on IEEE-33 system shows that traditional voltage control method, when performing in the bi-directional flow mode, results in over-voltage during 87.5% scheduling time at a RES penetration rate of 150%. But the strategy proposed in this paper can maintain voltage operation within permissible limits with penetration level ranging from 80% to 215%. Furthermore, as the penetration rate escalates, the regulation mechanisms become progressively intricate.","2025-01","2025-02-26 20:41:53","2025-02-26 20:41:53","","1556-1568","","1","61","","","","","","","","","","English","","","","WOS:001410866000006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Bidirectional control; bidirectional power flow; Distribution network (DN); energy storage system (ESS); GENERATION; Load flow; MANAGEMENT; Mathematical models; multilevel control; OLTC; OVERVOLTAGE PREVENTION; PENETRATION; PV INVERTERS; Reactive power; REACTIVE POWER; Regulation; SYSTEM; thermal management; Transformers; Voltage control; voltage regulation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2WE5AKCY","journalArticle","2024","Mao, M; Va, H; Hong, M","Video Classification of Cloth Simulations: Deep Learning and Position-Based Dynamics for Stiffness Prediction","SENSORS","","1424-8220","10.3390/s24020549","","In virtual reality, augmented reality, or animation, the goal is to represent the movement of deformable objects in the real world as similar as possible in the virtual world. Therefore, this paper proposed a method to automatically extract cloth stiffness values from video scenes, and then they are applied as material properties for virtual cloth simulation. We propose the use of deep learning (DL) models to tackle this issue. The Transformer model, in combination with pre-trained architectures like DenseNet121, ResNet50, VGG16, and VGG19, stands as a leading choice for video classification tasks. Position-Based Dynamics (PBD) is a computational framework widely used in computer graphics and physics-based simulations for deformable entities, notably cloth. It provides an inherently stable and efficient way to replicate complex dynamic behaviors, such as folding, stretching, and collision interactions. Our proposed model characterizes virtual cloth based on softness-to-stiffness labels and accurately categorizes videos using this labeling. The cloth movement dataset utilized in this research is derived from a meticulously designed stiffness-oriented cloth simulation. Our experimental assessment encompasses an extensive dataset of 3840 videos, contributing to a multi-label video classification dataset. Our results demonstrate that our proposed model achieves an impressive average accuracy of 99.50%. These accuracies significantly outperform alternative models such as RNN, GRU, LSTM, and Transformer.","2024-01","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","2","24","","","","","","","","","","English","","","","WOS:001151195700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","cloth simulation; deep learning; multi-label; position-based dynamics; Transformer; video classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9A3AS83V","journalArticle","2023","Krieger, F; Drews, P; Funk, B","Automated invoice processing: Machine learning-based information extraction for long tail suppliers","INTELLIGENT SYSTEMS WITH APPLICATIONS","","2667-3053","10.1016/j.iswa.2023.200285","","Automation of incoming invoices processing promises to yield vast efficiency improvements in accounting. Until a universal adoption of fully electronic invoice exchange formats has been achieved, machine learning can help bridge the adoption gaps in electronic invoicing by extracting structured information from unstructured invoice formats. Machine learning especially helps the processing of invoices of suppliers who only send invoices infrequently, as the models are able to capture the semantic and visual cues of invoices and generalize them to previously unknown invoice layouts. Since the population of invoices in many companies is skewed toward a few frequent suppliers and their layouts, this research examines the effects of training data taken from such populations on the predictive quality of different machine-learning approaches for the extraction of information from invoices. Comparing the different approaches, we find that they are affected to varying degrees by skewed layout populations: The accuracy gap between in-sample and out-of-sample layouts is much higher in the Chargrid and random forest models than in the LayoutLM transformer model, which also exhibits the best overall predictive quality. To arrive at this finding, we designed and implemented a research pipeline that pays special attention to the distribution of layouts in the splitting of data and the evaluation of the models.","2023-11","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","20","","","","","","","","","","English","","","","WOS:001306954600009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","Document analysis; Layout-rich documents; Natural language processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WSRYVIIU","journalArticle","2024","Radman, A; Atros, M; Duwairi, R","Neural Arabic singular-to-plural conversion using a pretrained Character-BERT and a fused transformer","NATURAL LANGUAGE ENGINEERING","","1351-3249","10.1017/S1351324923000475","","Morphological re-inflection generation is one of the most challenging tasks in the natural language processing (NLP) domain, especially with morphologically rich, low-resource languages like Arabic. In this research, we investigate the ability of transformer-based models in the singular-to-plural Arabic noun conversion task. We start with pretraining a Character-BERT model on a masked language modeling task using 1,134,950 Arabic words and then adopting the fusion technique to transfer the knowledge gained by the pretrained model to a full encoder-decoder transformer model, in one of the proposed settings. The second proposed setting directly fuses the output Character-BERT embeddings into the decoder. We then analyze and compare the performance of the two architectures and provide an interpretability section in which we track the features of attention with respect to the model. We perform the interpretation on both the macro and micro levels, providing some individual examples. Moreover, we provide a thorough error analysis showing the strengths and weaknesses of the proposed framework. To the best of our knowledge, this is the first effort in the Arabic NLP domain that adopts the development of an end-to-end fused-transformer deep learning model to address the problem of singular-to-plural conversion.","2024-09","2025-02-26 20:41:53","2025-02-26 20:41:53","","1130-1154","","5","30","","","","","","","","","","English","","","","WOS:001083620200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Arabic NLP; Character-BERT; fusion transformer; Morphological inflection generation; PAST TENSE; singular-to-plural conversion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M3J4GFCY","journalArticle","2023","Khosravi, P; Huck, NA; Shahraki, K; Hunter, SC; Danza, CN; Kim, SY; Forbes, BJ; Dai, S; Levin, AV; Binenbaum, G; Chang, PD; Suh, DW","Deep Learning Approach for Differentiating Etiologies of Pediatric Retinal Hemorrhages: A Multicenter Study","INTERNATIONAL JOURNAL OF MOLECULAR SCIENCES","","1661-6596","10.3390/ijms242015105","","Retinal hemorrhages in pediatric patients can be a diagnostic challenge for ophthalmologists. These hemorrhages can occur due to various underlying etiologies, including abusive head trauma, accidental trauma, and medical conditions. Accurate identification of the etiology is crucial for appropriate management and legal considerations. In recent years, deep learning techniques have shown promise in assisting healthcare professionals in making more accurate and timely diagnosis of a variety of disorders. We explore the potential of deep learning approaches for differentiating etiologies of pediatric retinal hemorrhages. Our study, which spanned multiple centers, analyzed 898 images, resulting in a final dataset of 597 retinal hemorrhage fundus photos categorized into medical (49.9%) and trauma (50.1%) etiologies. Deep learning models, specifically those based on ResNet and transformer architectures, were applied; FastViT-SA12, a hybrid transformer model, achieved the highest accuracy (90.55%) and area under the receiver operating characteristic curve (AUC) of 90.55%, while ResNet18 secured the highest sensitivity value (96.77%) on an independent test dataset. The study highlighted areas for optimization in artificial intelligence (AI) models specifically for pediatric retinal hemorrhages. While AI proves valuable in diagnosing these hemorrhages, the expertise of medical professionals remains irreplaceable. Collaborative efforts between AI specialists and pediatric ophthalmologists are crucial to fully harness AI's potential in diagnosing etiologies of pediatric retinal hemorrhages.","2023-10","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","20","24","","","","","","","","","","English","","","","WOS:001089773100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","artificial intelligence; ARTIFICIAL-INTELLIGENCE; deep learning; pediatrics; retinal hemorrhage; RETINOPATHY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5AUERA87","journalArticle","2024","Putro, NAS; Avian, C; Prakosa, SW; Mahali, MI; Leu, JS","Estimating finger joint angles by surface EMG signal using feature extraction and transformer-based deep learning model","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2023.105447","","Human-machine interfaces frequently use electromyography (EMG) signals. Based on previous work, feature extraction has a great deal of influence on the performance of EMG pattern recognition. Furthermore, the Deep Learning method is supposed to increase performance and not depend on feature engineering. However, directly processing raw signals will require a higher computation rate. This study proposed a new method that combines feature extraction and Deep Learning to address those issues while improving performance, reducing architecture size, and producing a more representative output. The proposed architecture employs the Transformer model as the backbone to get the correlation between elements and focus on the important information for estimating the flexion-extension of finger joint angles. This study uses experiment three of the NinaPro (Non-Invasive Adaptive Hand Prosthetics) DB5 dataset. Each experiment produces 16 Surface EMG data streams from two Myo Armbands devices representing 22 finger joint angles as output. This study compares the windowing process, feature extraction, execution time, and results with previous studies. The results show that the proposed model out-performs the previous study, from 0.957 in the previous study to become 0.970 in this study for the R-Square score. This result is obtained using 100 data points for the windowing process and Median Frequency for the best feature extraction method.","2024-01","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","87","","","","","","","","","","English","","","","WOS:001079365200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Deep learning; EMG; Feature extraction; Finger joint angles; NEURAL-NETWORKS; RECOGNITION; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L44XWKUP","journalArticle","2023","Salini, Y; Harikiran, J","Multiplicative Vector Fusion Model for Detecting Deepfake News in Social Media","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13074207","","In the digital age, social media platforms are becoming vital tools for generating and detecting deepfake news due to the rapid dissemination of information. Unfortunately, today, fake news is being developed at an accelerating rate that can cause substantial problems, such as early detection of fake news, a lack of labelled data available for training, and identifying fake news instances that still need to be discovered. Identifying false news requires an in-depth understanding of authors, entities, and the connections between words in a long text. Unfortunately, many deep learning (DL) techniques have proven ineffective with lengthy texts to address these issues. This paper proposes a TL-MVF model based on transfer learning for detecting and generating deepfake news in social media. To generate the sentences, the T5, or Text-to-Text Transfer Transformer model, was employed for data cleaning and feature extraction. In the next step, we designed an optimal hyperparameter RoBERTa model for effectively detecting fake and real news. Finally, we propose a multiplicative vector fusion model for classifying fake news from real news efficiently. A real-time and benchmarked dataset was used to test and validate the proposed TL-MVF model. For the TL-MVF model, F-score, accuracy, precision, recall, and AUC were performance evaluation measures. As a result, the proposed TL-MVF performed better than existing benchmarks.","2023-04","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","7","13","","","","","","","","","","English","","","","WOS:000971883900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","classification; deep learning; detection; fake news; TL-MVF; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7TWIVY6H","journalArticle","2023","Huang, YS; Wu, YH","Short-Term Photovoltaic Power Forecasting Based on a Novel Autoformer Model","SYMMETRY-BASEL","","2073-8994","10.3390/sym15010238","","Deep learning techniques excel at capturing and understanding the symmetry inherent in data patterns and non-linear properties of photovoltaic (PV) power, therefore they achieve excellent performance on short-term PV power forecasting. In order to produce more precise and detailed forecasting results, this research suggests a novel Autoformer model with De-Stationary Attention and Multi-Scale framework (ADAMS) for short-term PV power forecasting. In this approach, the multi-scale framework is applied to the Autoformer model to capture the inter-dependencies and specificities of each scale. Furthermore, the de-stationary attention is incorporated into an auto-correlation mechanism for more efficient non-stationary information extraction. Based on the operational data from a 1058.4 kW PV facility in Central Australia, the ADAMS model and the other six baseline models are compared with 5 min and 1 h temporal resolution PV power data predictions. The results show in terms of four performance measurements, the proposed method can handle the task of projecting short-term PV output more effectively than other methods. Taking the result of predicting the PV energy in the next 24 h based on the 1 h resolution data as an example, MSE is 0.280, MAE is 0.302, RMSE is 0.529, and adjusted R-squared is 0.824.","2023-01","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","1","15","","","","","","","","","","English","","","","WOS:000916375100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","deep learning; multi-scale analysis; nonstationarity; photovoltaic power; short-term forecasting; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PFT78FWI","journalArticle","2021","Baniata, LH; Ampomah, IKE; Park, S","A Transformer-Based Neural Machine Translation Model for Arabic Dialects That Utilizes Subword Units","SENSORS","","1424-8220","10.3390/s21196509","","Languages that allow free word order, such as Arabic dialects, are of significant difficulty for neural machine translation (NMT) because of many scarce words and the inefficiency of NMT systems to translate these words. Unknown Word (UNK) tokens represent the out-of-vocabulary words for the reason that NMT systems run with vocabulary that has fixed size. Scarce words are encoded completely as sequences of subword pieces employing the Word-Piece Model. This research paper introduces the first Transformer-based neural machine translation model for Arabic vernaculars that employs subword units. The proposed solution is based on the Transformer model that has been presented lately. The use of subword units and shared vocabulary within the Arabic dialect (the source language) and modern standard Arabic (the target language) enhances the behavior of the multi-head attention sublayers for the encoder by obtaining the overall dependencies between words of input sentence for Arabic vernacular. Experiments are carried out from Levantine Arabic vernacular (LEV) to modern standard Arabic (MSA) and Maghrebi Arabic vernacular (MAG) to MSA, Gulf-MSA, Nile-MSA, Iraqi Arabic (IRQ) to MSA translation tasks. Extensive experiments confirm that the suggested model adequately addresses the unknown word issue and boosts the quality of translation from Arabic vernaculars to Modern standard Arabic (MSA).","2021-10","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","19","21","","","","","","","","","","English","","","","WOS:000707361500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Arabic dialects; modern standard Arabic; multi-head attention; neural machine translation (NMT); self-attention; shared vocabulary; subword units; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z5LB5ZMM","journalArticle","2021","Wang, JK; Hsieh, CY; Wang, MY; Wang, XR; Wu, ZX; Jiang, DJ; Liao, BB; Zhang, XJ; Yang, B; He, QJ; Cao, DS; Chen, X; Hou, TJ","Multi-constraint molecular generation based on conditional transformer, knowledge distillation and reinforcement learning","NATURE MACHINE INTELLIGENCE","","2522-5839","10.1038/s42256-021-00403-1","","Machine learning-based generative models can generate novel molecules with desirable physiochemical and pharmacological properties from scratch. Many excellent generative models have been proposed, but multi-objective optimizations in molecular generative tasks are still quite challenging for most existing models. Here we proposed the multi-constraint molecular generation (MCMG) approach that can satisfy multiple constraints by combining conditional transformer and reinforcement learning algorithms through knowledge distillation. A conditional transformer was used to train a molecular generative model by efficiently learning and incorporating the structure-property relations into a biased generative process. A knowledge distillation model was then employed to reduce the model's complexity so that it can be efficiently fine-tuned by reinforcement learning and enhance the structural diversity of the generated molecules. As demonstrated by a set of comprehensive benchmarks, MCMG is a highly effective approach to traverse large and complex chemical space in search of novel compounds that satisfy multiple property constraints. Combining generative models and reinforcement learning has become a promising direction for computational drug design, but it is challenging to train an efficient model that produces candidate molecules with high diversity. Jike Wang and colleagues present a method, using knowledge distillation, to condense a conditional transformer model to make it usable in reinforcement learning while still generating diverse molecules that optimize multiple molecular properties.","2021-10","2025-02-26 20:41:53","2025-02-26 20:41:53","","914-922","","10","3","","","","","","","","","","English","","","","WOS:000708470700005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;100<br/>Total Times Cited:&nbsp;&nbsp;105<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","DESIGN; DRUG DISCOVERY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"94QKHHDW","journalArticle","2024","Bensalah, N; Ayad, H; Adib, A; El Farouk, AI","Contextualized dynamic meta embeddings based on Gated CNNs and self-attention for Arabic machine translation","INTERNATIONAL JOURNAL OF INTELLIGENT COMPUTING AND CYBERNETICS","","1756-378X","10.1108/IJICC-03-2024-0106","","PurposeThe paper aims to enhance Arabic machine translation (MT) by proposing novel approaches: (1) a dimensionality reduction technique for word embeddings tailored for Arabic text, optimizing efficiency while retaining semantic information; (2) a comprehensive comparison of meta-embedding techniques to improve translation quality; and (3) a method leveraging self-attention and Gated CNNs to capture token dependencies, including temporal and hierarchical features within sentences, and interactions between different embedding types. These approaches collectively aim to enhance translation quality by combining different embedding schemes and leveraging advanced modeling techniques.Design/methodology/approachRecent works on MT in general and Arabic MT in particular often pick one type of word embedding model. In this paper, we present a novel approach to enhance Arabic MT by addressing three key aspects. Firstly, we propose a new dimensionality reduction technique for word embeddings, specifically tailored for Arabic text. This technique optimizes the efficiency of embeddings while retaining their semantic information. Secondly, we conduct an extensive comparison of different meta-embedding techniques, exploring the combination of static and contextual embeddings. Through this analysis, we identify the most effective approach to improve translation quality. Lastly, we introduce a novel method that leverages self-attention and Gated convolutional neural networks (CNNs) to capture token dependencies, including temporal and hierarchical features within sentences, as well as interactions between different types of embeddings. Our experimental results demonstrate the effectiveness of our proposed approach in significantly enhancing Arabic MT performance. It outperforms baseline models with a BLEU score increase of 2 points and achieves superior results compared to state-of-the-art approaches, with an average improvement of 4.6 points across all evaluation metrics.FindingsThe proposed approaches significantly enhance Arabic MT performance. The dimensionality reduction technique improves the efficiency of word embeddings while preserving semantic information. Comprehensive comparison identifies effective meta-embedding techniques, with the contextualized dynamic meta-embeddings (CDME) model showcasing competitive results. Integration of Gated CNNs with the transformer model surpasses baseline performance, leveraging both architectures' strengths. Overall, these findings demonstrate substantial improvements in translation quality, with a BLEU score increase of 2 points and an average improvement of 4.6 points across all evaluation metrics, outperforming state-of-the-art approaches.Originality/valueThe paper's originality lies in its departure from simply fine-tuning the transformer model for a specific task. Instead, it introduces modifications to the internal architecture of the transformer, integrating Gated CNNs to enhance translation performance. This departure from traditional fine-tuning approaches demonstrates a novel perspective on model enhancement, offering unique insights into improving translation quality without solely relying on pre-existing architectures. The originality in dimensionality reduction lies in the tailored approach for Arabic text. While dimensionality reduction techniques are not new, the paper introduces a specific method optimized for Arabic word embeddings. By employing independent component analysis (ICA) and a post-processing method, the paper effectively reduces the dimensionality of word embeddings while preserving semantic information which has not been investigated before especially for MT task.","2024-07-17","2025-02-26 20:41:53","2025-02-26 20:41:53","","605-631","","3","17","","","","","","","","","","English","","","","WOS:001261888400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Arabic MT; Contextual word embeddings; Contextualized dynamic meta-embeddings; Dynamic meta-embeddings; Gated CNNs; RESOURCE-ALLOCATION; Self-attention; Static word embeddings; VEHICULAR NETWORKS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KIVF3W5H","journalArticle","2024","Ma, DJ; Gao, YC; Dai, Q","LFformer: An improved Transformer model for wind power prediction","PLOS ONE","","1932-6203","10.1371/journal.pone.0309676","","Wind power forecasting has complex nonlinear features and behavioral patterns across time scales, which is a severe test for traditional forecasting techniques. To address the multi-scale problem in wind power forecasting, this paper innovatively proposes an ultra-short-term forecasting model LFformer based on Legendre-Fourier, which firstly focuses on the important information in the input sequences by using the encoder-decoder architecture, and then scales the range of the original data with the Devlin normalization method, and then utilizes the Legendre polynomials to The data sequence is projected into a bounded dimensional space, the historical data is compressed using feature representation, then feature selection is performed using the low-rank approximation method of Fourier Transform, the prediction is inputted into the multilayer perceptron through the multi-scale mixing mechanism, and finally the results are outputted after back-normalization. The experimental results show that compared with the existing prediction methods, the model realizes the improvement of prediction accuracy and stability, especially in the ultra-short-term prediction scenario, with obvious advantages. The research results are not only valuable for improving the overall operational efficiency of the wind power system, but also help to enhance the stable operation of the power grid, which provides strong technical support and guarantee for wind power enterprises to improve the competitiveness of bidding for Internet access in the power market competition.","2024-10-25","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","10","19","","","","","","","","","","English","","","","WOS:001345620600034","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BHLEJC3U","journalArticle","2024","Lee, CC; Chuang, CC; Yeng, CH; So, EC; Chen, YJ","A Cross-Stage Partial Network and a Cross-Attention-Based Transformer for an Electrocardiogram-Based Cardiovascular Disease Decision System","BIOENGINEERING-BASEL","","2306-5354","10.3390/bioengineering11060549","","Cardiovascular disease (CVD) is one of the leading causes of death globally. Currently, clinical diagnosis of CVD primarily relies on electrocardiograms (ECG), which are relatively easier to identify compared to other diagnostic methods. However, ensuring the accuracy of ECG readings requires specialized training for healthcare professionals. Therefore, developing a CVD diagnostic system based on ECGs can provide preliminary diagnostic results, effectively reducing the workload of healthcare staff and enhancing the accuracy of CVD diagnosis. In this study, a deep neural network with a cross-stage partial network and a cross-attention-based transformer is used to develop an ECG-based CVD decision system. To accurately represent the characteristics of ECG, the cross-stage partial network is employed to extract embedding features. This network can effectively capture and leverage partial information from different stages, enhancing the feature extraction process. To effectively distill the embedding features, a cross-attention-based transformer model, known for its robust scalability that enables it to process data sequences with different lengths and complexities, is employed to extract meaningful embedding features, resulting in more accurate outcomes. The experimental results showed that the challenge scoring metric of the proposed approach is 0.6112, which outperforms others. Therefore, the proposed ECG-based CVD decision system is useful for clinical diagnosis.","2024-06","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","6","11","","","","","","","","","","English","","","","WOS:001254517600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","cardiovascular disease; cardiovascular disease decision system; cross-attention-based transformer; cross-stage partial network; electrocardiograms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QFJENRD7","journalArticle","2024","Singh, S; Trivedi, A; Saxena, D","Channel Estimation for Intelligent Reflecting Surface Aided Communication via Graph Transformer","IEEE TRANSACTIONS ON GREEN COMMUNICATIONS AND NETWORKING","","2473-2400","10.1109/TGCN.2023.3339819","","Intelligent reflecting surface (IRS) is a potential technology for enhancing communication systems' performance. Accurate cascaded channel estimation between the base station (BS), IRS, and the user is vital for optimal system performance. However, incorporating IRS increases channel estimation complexity due to additional dimensions from each element, leading to higher training overhead. To reduce training overhead, existing approaches assume the sparse cascaded channel which may not be valid in dense multipath propagation and non-line-of-sight settings. We propose a novel technique to address this issue by leveraging the spatial correlation among IRS elements' channels. By dividing the IRS surface into groups, we estimate the channel for some groups via the least square (LS) method. To estimate the channels for the remaining groups, a graph transformer-based IRS channel estimation (G-TIRC) model is proposed, which includes a graph neural network (GNN) and transformer model. The GNN finds the correlations among the different groups by embedding the channel information. Then, the attention mechanism within the transformer extracts useful correlations to accurately predict the channels for the unknown groups. The experiments demonstrate the effectiveness of the G-TIRC model in achieving accurate channel estimation with reduced pilot overhead compared to other state-of-the-art methods.","2024-06","2025-02-26 20:41:53","2025-02-26 20:41:53","","756-766","","2","8","","","","","","","","","","English","","","","WOS:001230177900005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","attention mechanism; Cascaded channel estimation; Channel estimation; Correlation; DESIGN; Estimation; graph transformer; intelligent reflecting surface (IRS); Matching pursuit algorithms; Symbols; SYSTEMS; Training; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3QN5F9GX","journalArticle","2024","Chawla, K; Clever, R; Ramirez, J; Lucas, GM; Gratch, J","Towards Emotion-Aware Agents for Improved User Satisfaction and Partner Perception in Negotiation Dialogues","IEEE TRANSACTIONS ON AFFECTIVE COMPUTING","","1949-3045","10.1109/TAFFC.2023.3238007","","Negotiation is a complex social interaction that encapsulates emotional encounters in human decision-making. Virtual agents that can negotiate with humans by the means of language are useful in pedagogy and conversational AI. To advance the development of such agents, we explore the role of emotion in the prediction of two important subjective goals in a negotiation - outcome satisfaction and partner perception. We devise ways to measure and compare different degrees of emotion expression in negotiation dialogues, consisting of emoticon, lexical, and contextual variables. Through an extensive analysis of a large-scale dataset in chat-based negotiations, we find that incorporating emotion expression explains significantly more variance, above and beyond the demographics and personality traits of the participants. Further, our temporal analysis reveals that emotive information from both early and later stages of the negotiation contributes to this prediction, indicating the need for a continual learning model of capturing emotion for automated agents. Finally, we extend our analysis to another dataset, showing promise that our findings generalize to more complex scenarios. We conclude by discussing our insights, which will be helpful for designing adaptive negotiation agents that interact through realistic communication interfaces.","2024-04","2025-02-26 20:41:53","2025-02-26 20:41:53","","433-444","","2","15","","","","","","","","","","English","","","","WOS:001236687600005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Atmospheric measurements; Emotion recognition; human-agent interaction; Metadata; multi-issue bargaining; natural language processing; negotiation dialogues; Oral communication; Particle measurements; partner perception; PERSONALITY; t5 transformer model; Task analysis; Training; user satisfaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q4L7DRLJ","journalArticle","2023","Haralabopoulos, G; Razis, G; Anagnostopoulos, I","A Modified Long Short-Term Memory Cell","INTERNATIONAL JOURNAL OF NEURAL SYSTEMS","","0129-0657","10.1142/S0129065723500399","","Machine Learning (ML), among other things, facilitates Text Classification, the task of assigning classes to textual items. Classification performance in ML has been significantly improved due to recent developments, including the rise of Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM), Gated Recurrent Units (GRUs), and Transformer Models. Internal memory states with dynamic temporal behavior can be found in these kinds of cells. This temporal behavior in the LSTM cell is stored in two different states: ""Current"" and ""Hidden"". In this work, we define a modification layer within the LSTM cell which allows us to perform additional state adjustments for either state, or even simultaneously alter both. We perform 17 state alterations. Out of these 17 single-state alteration experiments, 12 involve the Current state whereas five involve the Hidden one. These alterations are evaluated using seven datasets related to sentiment analysis, document classification, hate speech detection, and human-to-robot interaction. Our results showed that the highest performing alteration for Current and Hidden state can achieve an average F1 improvement of 0.5% and 0.3%, respectively. We also compare our modified cell performance to two Transformer models, where our modified LSTM cell is outperformed in classification metrics in 4/6 datasets, but improves upon the simple Transformer model and clearly has a better cost efficiency than both Transformer models.","2023-07","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","07","33","","","","","","","","","","English","","","","WOS:001006274100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","BERT; BIDIRECTIONAL LSTM; CLASSIFICATION; LSTM; NETWORK; RECOGNITION; SPEECH; text classification; transformer models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"THM9JL3V","journalArticle","2023","Nascimento, EGS; de Melo, TAC; Moreira, DM","A transformer-based deep neural network with wavelet transform for forecasting wind speed and wind energy","ENERGY","","0360-5442","10.1016/j.energy.2023.127678","","This work presents a novel transformer-based deep neural network architecture integrated with wavelet transform for forecasting wind speed and wind energy (power) generation for the next 6 h ahead, using multiple meteorological variables as input for multivariate time series forecasting. To evaluate the performance of the proposed model, different case studies were investigated, using data collected from anemometers installed in three different regions in Bahia, Brazil. The performance of the proposed transformer-based model with wavelet transform was compared with an LSTM (Long Short Term Memory) model as a baseline, since it has been successfully used for time series processing in deep learning, as well as with previous state-of-the-art (SOTA) similar works. Results of the forecasting performance were evaluated using statistical metrics, along with the time for training and performing inferences, both using quantitative and qualitative analysis. They showed that the proposed method is effective for forecasting wind speed and power generation, with superior performance than the baseline model and comparable performance to previous similar SOTA works, presenting potential suitability for being extended for the general purpose of multivariate time series forecasting. Furthermore, results demonstrated that the integration of the transformer model with wavelet decomposition improved the forecast accuracy.","2023-09-01","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","278","","","","","","","","","","English","","","","WOS:001006790800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;59<br/>Total Times Cited:&nbsp;&nbsp;60<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Deep learning; MODELS; Multivariate time series forecasting; Renewable energy; Transformer; Wavelet; Wind power forecasting; Wind speed forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"384RLXA2","journalArticle","2023","Montalvo-Lezama, R; Montalvo-Lezama, B; Fuentes-Pineda, G","Improving Transfer Learning for Movie Trailer Genre Classification using a Dual Image and Video Transformer","INFORMATION PROCESSING & MANAGEMENT","","0306-4573","10.1016/j.ipm.2023.103343","","In this paper, we study the transferability of ImageNet spatial and Kinetics spatio-temporal representations to multi-label Movie Trailer Genre Classification (MTGC). In particular, we present an extensive evaluation of the transferability of ConvNet and Transformer models pretrained on ImageNet and Kinetics to Trailers12k, a new manually-curated movie trailer dataset composed of 12,000 videos labeled with 10 different genres and associated metadata. We analyze different aspects that can influence transferability, such as frame rate, input video extension, and spatio-temporal modeling. In order to reduce the spatio-temporal structure gap between ImageNet/Kinetics and Trailers12k, we propose Dual Image and Video Transformer Architecture (DIViTA), which performs shot detection so as to segment the trailer into highly correlated clips, providing a more cohesive input for pretrained backbones and improving transferability (a 1.83% increase for ImageNet and 3.75% for Kinetics). Our results demonstrate that representations learned on either ImageNet or Kinetics are comparatively transferable to Trailers12k. Moreover, both datasets provide complementary information that can be combined to improve classification performance (a 2.91% gain compared to the top single pretraining). Interestingly, using lightweight ConvNets as pretrained backbones resulted in only a 3.46% drop in classification performance compared with the top Transformer while requiring only 11.82% of its parameters and 0.81% of its FLOPS.","2023-05","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","3","60","","","","","","","","","","English","","","","WOS:000967429800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;77</p>","","","Multi-label classification; Spatio-temporal analysis; Trailers12k; Transfer learning; Transformer model; Video analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J27MEL6V","journalArticle","2023","Chambon, P; Cook, TS; Langlotz, CP","Improved Fine-Tuning of In-Domain Transformer Model for Inferring COVID-19 Presence in Multi-Institutional Radiology Reports","JOURNAL OF DIGITAL IMAGING","","0897-1889","10.1007/s10278-022-00714-8","","Building a document-level classifier for COVID-19 on radiology reports could help assist providers in their daily clinical routine, as well as create large numbers of labels for computer vision models. We have developed such a classifier by fine-tuning a BERT-like model initialized from RadBERT, its continuous pre-training on radiology reports that can be used on all radiology-related tasks. RadBERT outperforms all biomedical pre-trainings on this COVID-19 task (P<0.01) and helps our fine-tuned model achieve an 88.9 macro-averaged F1-score, when evaluated on both X-ray and CT reports. To build this model, we rely on a multi-institutional dataset re-sampled and enriched with concurrent lung diseases, helping the model to resist to distribution shifts. In addition, we explore a variety of fine-tuning and hyperparameter optimization techniques that accelerate fine-tuning convergence, stabilize performance, and improve accuracy, especially when data or computational resources are limited. Finally, we provide a set of visualization tools and explainability methods to better understand the performance of the model, and support its practical use in the clinical setting. Our approach offers a ready-to-use COVID-19 classifier and can be applied similarly to other radiology report classification tasks.","2023-02","2025-02-26 20:41:53","2025-02-26 20:41:53","","164-177","","1","36","","","","","","","","","","English","","","","WOS:000877996300002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","BERT; Classification; COVID-19; Natural language processing (NLP); Radiology; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UWYT5K8G","journalArticle","2023","Nassiri, K; Akhloufi, M","Transformer models used for text-based question answering systems","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-022-04052-8","","The question answering system is frequently applied in the area of natural language processing (NLP) because of the wide variety of applications. It consists of answering questions using natural language. The problem is, in general, solved by employing a dataset that consists of an input text, a query, and the text segment or span from the input text that provides the question's answer. The ability to make human-level predictions from data has improved significantly thanks to deep learning models, particularly the Transformer architecture, which has been state-of-the-art in text-based models in recent years. This paper reviews studies related to the use of transformer models in the implementation of question-answering (QA) systems. The paper's first focus is on the attention and transformer models. A brief description of the architectures is presented by classifying them into models based on encoders, decoders, and on both Encoder-Decoder. Following that, we examine the most recent research trends in textual QA datasets by highlighting the architecture of QA systems and categorizing them according to various criteria. We survey also a significant set of evaluation metrics that have been developed in order to evaluate the models' performance. Finally, we highlight solutions built to simplify the implementation of Transformer models.","2023-05","2025-02-26 20:41:53","2025-02-26 20:41:53","","10602-10635","","9","53","","","","","","","","","","English","","","","WOS:000843265800003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;38<br/>Total Times Cited:&nbsp;&nbsp;41<br/>Cited Reference Count:&nbsp;&nbsp;270</p>","","","Deep learning; LANGUAGE; LSTM; NLP; QA datasets; Question answering; RULES; Transfer learning; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ICGXRX43","journalArticle","2024","Yan, JJ; Li, HH; Xu, FF; Zhou, XY; Liu, Y; Yang, Y","Speech Emotion Recognition Based on Temporal-Spatial Learnable Graph Convolutional Neural Network","ELECTRONICS","","2079-9292","10.3390/electronics13112010","","The Graph Convolutional Neural Networks (GCN) method has shown excellent performance in the field of deep learning, and using graphs to represent speech data is a computationally efficient and scalable approach. In order to enhance the adequacy of graph neural networks in extracting speech emotional features, this paper proposes a Temporal-Spatial Learnable Graph Convolutional Neural Network (TLGCNN) for speech emotion recognition. TLGCNN firstly utilizes the Open-SMILE toolkit to extract frame-level speech emotion features. Then, a bidirectional long short-term memory (Bi LSTM) network is used to process the long-term dependencies of speech features which can further extract deep frame-level emotion features. The extracted frame-level emotion features are then input into subsequent network through two pathways. Finally, one pathway constructs the extracted frame-level deep emotion feature vectors into a graph structure applying an adaptive adjacency matrix to catch latent spatial connections, while the other pathway concatenates emotion feature vectors with graph-level embedding obtained from learnable graph convolutional neural network for prediction and classification. Through these two pathways, TLGCNN can simultaneously obtain temporal speech emotional information through Bi-LSTM and spatial speech emotional information through Learnable Graph Convolutional Neural (LGCN) network. Experimental results demonstrate that this method achieves weighted accuracy of 66.82% and 58.35% on the IEMOCAP and MSP-IMPROV databases, respectively.","2024-06","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","11","13","","","","","","","","","","English","","","","WOS:001245604800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","adaptive adjacency matrix; bidirectional long short-term memory network; graph convolutional network; speech emotion recognition; temporal-spatial learnable graph convolutional neural network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"984XTV48","journalArticle","2022","Malmenholt, A; McAllister, A; Lohmander, A; Östberg, P","Speech feature profiles in Swedish 5-year-olds with speech sound disorder related to suspected childhood apraxia of speech or cleft palate","INTERNATIONAL JOURNAL OF SPEECH-LANGUAGE PATHOLOGY","","1754-9507","10.1080/17549507.2021.1968951","","Purpose: To study the occurrence of speech features commonly associated with Childhood Apraxia of Speech (CAS) in Swedish children with suspected CAS (sCAS) or Speech Sound Disorder (SSD) related to Cleft Palate and/or Lip (CP +/- L). Method: Thirty-four children (4.10-5.11) with SSD related to sCAS (n = 15) or repaired CP +/- L (n = 19) participated. Consensus judgement of presence/absence of CAS features in single words were based on a checklist with operationalised definitions. Speech sound production measures were based on semi-narrow phonetic transcription. Intra- and inter-transcriber agreement was determined. Result: Twelve participants (ten with sCAS (67%) and two with CP +/- L (11%)) shared a CAS profile of phonemic speech inconsistency for consonants and vowels and a set of four features: vowel error, voicing error, difficulty achieving initial articulatory configurations or transitionary movement gestures and stress errors. The most frequent speech difficulties in children with non-CAS CP +/- L (n = 17) were consonant distortion (88%) and hypernasal resonance (76%). Prosodic impairment was rare. Conclusion: A distinct CAS speech feature profile was found for children with CAS, differing in number and distribution compared to children with CP +/- L and SSD. CAS was found more frequently in CP +/- L and SSD compared to reported estimates of clinical prevalence.","2022-03-04","2025-02-26 20:41:53","2025-02-26 20:41:53","","156-167","","2","24","","","","","","","","","","English","","","","WOS:000694577700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","CHILDREN; clinical phonetics; Differential diagnosis; LANGUAGE; LIP; OUTCOMES; PREVALENCE; PRIMARY SURGERY; SCANDCLEFT RANDOMIZED-TRIALS; speech inconsistency; VELOCARDIOFACIAL SYNDROME","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6Q93MYM9","journalArticle","2021","Sun, LN; Li, MZ","Sports and Health Management Using Big Data Based on Voice Feature Processing and Internet of Things","SCIENTIFIC PROGRAMMING","","1058-9244","10.1155/2021/3271863","","With the support of big data and information technology, various sectors such as sports, health, and medical industry can realize the integration and readjustment of the existing resources, which improve the operation efficiency of the industry and tap its huge potential. With the advancement in big data analysis, voice features, and Internet of Things (IoT), personalized health management is becoming the development trend and breakthrough of sports and health industry. The application of big data will tap out the huge potential of the sports and health industry. In this paper, we have used the Mel-requency cepstrum coefficient as the speech feature processing method. When the linear frequency is transformed to the Mel frequency by Fourier transform, the calculation accuracy will decrease with the increase in the frequency, and the low-frequency signal will be retained to improve the anti-noise ability. With further study of the voice feature processing and IoT model of big data's sports and health management, a vector addition regression was developed to compare the two real scoring features of the processing results that pave the way for further analysis and result evaluation. Through experimental verification, it is proved that the method in this paper can better learn the speech features. At the same time, with the introduction of noise reduction, the big data of speech recognition in sports health management has a stronger robustness and improves the overall system performance.","2021-08-26","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","2021","","","","","","","","","","English","","","","WOS:000692938100004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","CARE; OF-THINGS; SMART; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QAMDJNT5","journalArticle","2025","Shen, RZ","Japanese waka translation supported by internet of things and artificial intelligence technology","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-025-85184-y","","With the advancement of internet of things (IoT) and artificial intelligence (AI) technology, access to large-scale bilingual parallel data has become more efficient, thereby accelerating the development and application of machine translation. Given the increasing cultural exchanges between China and Japan, many scholars have begun to study the Chinese translation of Japanese waka poetry. Based on this, the study first explores the structure of waka and the current state of its Chinese translations, analyzing existing translation disputes and introducing a data collection method for waka using IoT. Then, an optimized neural machine translation model is proposed, which integrates a Bidirectional Long Short-Term Memory (Bi-LSTM) network, vertical Tree-LSTM, and an attention mechanism into the Transformer framework. Experimental results demonstrate that the three optimized models-Transformer + Bi-LSTM, Transformer + Tree-LSTM, and Transformer + Tree-LSTM + Attention-outperform the baseline Transformer model on both public and waka datasets. The BLEU scores of the models on the public dataset were 23.71, 23.95, and 24.12, respectively. Notably, on the waka dataset, the Transformer + Tree-LSTM + Attention model achieved the highest BLEU score of 20.65, demonstrating a significant advantage in capturing waka's unique features and contextual information. This study offers new methods to enhance the quality of Chinese-Japanese translation, promoting cultural exchange and understanding.","2025-01-06","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","1","15","","","","","","","","","","English","","","","WOS:001392728800042","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Internet of things; Japanese waka; Long short-term memory network; Neural machine translation; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HYYTAQPQ","journalArticle","2024","Deng, LF; Li, W; Zhang, WQ","Intelligent prediction of rolling bearing remaining useful life based on probabilistic DeepAR-Transformer model","MEASUREMENT SCIENCE AND TECHNOLOGY","","0957-0233","10.1088/1361-6501/acf874","","Remaining useful life (RUL) prediction for rolling bearings requires highly accurate and stable long-term prediction capabilities in equipment health management, which demands that the prediction model has strong data reasoning and regression performance. However, it is difficult to accurately capture long-term dependencies via traditional convolutional neural network because the information loss and insufficient analysis are unavoidable during the feature extraction process. An end-to-end time series forecasting method called D-former for RUL prediction of rolling bearings is proposed in this paper. The method mainly consists of DeepAR and a multi-layer encoder, so it is able to extract degradation features directly from the original signal. This method has the following salient features: (1) the designed multi-head attention mechanism can highlight important feature information and realize parallel computing, so the method is extremely suitable for processing long-term time series; (2) the important time feature information is rearranged through DeepAR, so the method has the excellent domain adaptability, and it can achieve accurate prediction of rolling bearing RUL under different working conditions. The verification experiment was implemented on the IEEE PHM 2012 dataset and the XJTU-SY bearing dataset. The experimental results show that the proposed D-former method is actually superior to the existing mainstream RUL prediction methods.","2024-01-01","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","1","35","","","","","","","","","","English","","","","WOS:001075300100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","DeepAR; remaining useful life prediction; rolling bearing; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LMNDVWMR","journalArticle","2023","Xing, ZJ; Ren, J; Fan, XZ; Zhang, Y","S-DETR: A Transformer Model for Real-Time Detection of Marine Ships","JOURNAL OF MARINE SCIENCE AND ENGINEERING","","2077-1312","10.3390/jmse11040696","","Due to the ever-changing shape and scale of ships, as well as the complex sea background, accurately detecting multi-scale ships on the sea while considering real-time requirements remains a challenge. To address this problem, we propose a model called S-DETR based on the DETR framework for end-to-end detection of ships on the sea. A scale attention module is designed to effectively learn the weights of different scale information by utilizing the global information brought by global average pooling. We analyzed the potential reasons for the performance degradation of the end-to-end detector and proposed a decoder based on Dense Query. Although the computational complexity and convergence of the entire S-DETR model have not been rigorously proven mathematically, Dense Query can reduce the computational complexity of multi-head self-attention from O(N-q(2)) into O(N-q). To evaluate the performance of S-DETR, we conducted experiments on the Singapore Maritime Dataset and Marine Image Dataset. The experimental results show that the proposed method can effectively solve the problem of multi-scale ship detection in complex marine environments and achieve state-of-the-art performance. The model inference speed of S-DETR is comparable to that of single-stage target detection models and meets the real-time requirements of shoreside ship detection.","2023-04","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","4","11","","","","","","","","","","English","","","","WOS:000979912100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","dense query; DETR; multi-scale; ship detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2W29YWEL","journalArticle","2022","Zhang, RH; Ren, SP; Dai, Q; Shen, TZ; Li, XL; Li, J; Xiao, WL","InflamNat: web-based database and predictor of anti-inflammatory natural products","JOURNAL OF CHEMINFORMATICS","","1758-2946","10.1186/s13321-022-00608-5","","Natural products (NPs) are a valuable source for anti-inflammatory drug discovery. However, they are limited by the unpredictability of the structures and functions. Therefore, computational and data-driven pre-evaluation could enable more efficient NP-inspired drug development. Since NPs possess structural features that differ from synthetic compounds, models trained with synthetic compounds may not perform well with NPs. There is also an urgent demand for well-curated databases and user-friendly predictive tools. We presented a comprehensive online web platform (InflamNat, http://www.inflamnat.com/ or http://39.104.56.4/) for anti-inflammatory natural product research. InflamNat is a database containing the physicochemical properties, cellular anti-inflammatory bioactivities, and molecular targets of 1351 NPs that tested on their anti-inflammatory activities. InflamNat provides two machine learning-based predictive tools specifically designed for NPs that (a) predict the anti-inflammatory activity of NPs, and (b) predict the compound-target relationship for compounds and targets collected in the database but lacking existing relationship data. A novel multi-tokenization transformer model (MTT) was proposed as the sequential encoder for both predictive tools to obtain a high-quality representation of sequential data. The experimental results showed that the proposed predictive tools achieved an AUC value of 0.842 and 0.872 in the prediction of anti-inflammatory activity and compound-target interactions, respectively.","2022-06-04","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","1","14","","","","","","","","","","English","","","","WOS:000805933600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","Anti-inflammation; Machine learning; Natural products; Web platform","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E6BG2UUD","journalArticle","2025","Jiang, JZ; Wu, H; Zhong, CH; Song, H","Classification of power quality disturbances in microgrids using a multi-level global convolutional neural network and SDTransformer approach","PLOS ONE","","1932-6203","10.1371/journal.pone.0317050","","As the adoption of new energy sources like photovoltaic and wind power increases alongside the influx of advanced power electronic devices, there has been a significant rise in power quality disturbance events (PQDs) within power systems. These disturbances, including harmonics and voltage dips, severely impact the stability of microgrids and the efficiency of power equipment. To enhance the accuracy of identifying power quality disturbances in microgrids, this paper introduces a Multi-level Global Convolutional Neural Network combined with a Simplified double-layer Transformer model (MGCNN-SDTransformer). The model processes the input raw 1D time-series signals of power quality through multi-level convolutional and 1D-Global Attention Mechanism (1D-GAM) operations in MGCNN, which preliminarily extracts and emphasizes the key features and dynamic changes; Subsequently, the model utilizes the Multi-head Self Attention(MSA) and Multi-Layer Perceptron(MLP) components of the enhanced SDTransformer to further explore the transient local and periodic global features of the signals; The classification outcomes are then determined using a fully-connected layer and a Softmax classifier. The model effectively retains the signal's original one-dimensional temporal attributes while also delving into more complex features. This approach exhibits strong resistance to noise and enhanced generalization skills, markedly improving the detection accuracy of power quality issues within microgrids.","2025-02-12","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","2","20","","","","","","","","","","English","","","","WOS:001422038700004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","DISCRETE WAVELET TRANSFORM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AMID559D","journalArticle","2024","Dias, G; Berto, RP; Oliveira, M; Ueda, L; Dertkigil, S; Costa, PDP; Shamaei, A; Bugler, H; Souza, R; Harris, A; Rittner, L","Spectro-ViT: A vision transformer model for GABA-edited MEGA-PRESS reconstruction using spectrograms","MAGNETIC RESONANCE IMAGING","","0730-725X","10.1016/j.mri.2024.110219","","This study investigated the use of a Vision Transformer (ViT) for reconstructing GABA-edited Magnetic Resonance Spectroscopy (MRS) data from a reduced number of transients. Transients refer to the samples collected during an MRS acquisition by repeating the experiment to generate a signal of sufficient quality. Specifically, 80 transients were used instead of the typical 320 transients, aiming to reduce scan time. The 80 transients were preprocessed and converted into a spectrogram image representation using the Short-Time Fourier Transform (STFT). A pre-trained ViT, named Spectro-ViT, was fine-tuned and then tested using in-vivo GABA-edited MEGA- PRESS data. Its performance was compared against other pipelines in the literature using quantitative quality metrics and estimated metabolite concentration values, with the typical 320-transient scans serving as the reference for comparison. The Spectro-ViT model exhibited the best overall quality metrics among all other pipelines against which it was compared. The metabolite concentrations from Spectro-ViT's reconstructions for GABA+ + achieved the best average R2 2 value of 0.67 and the best average Mean Absolute Percentage Error (MAPE) value of 9.68%, with no significant statistical differences found compared to the 320-transient reference. The code to reproduce this research is available at https://github.com/MICLab-Unicamp/Spectro-ViT","2024-11","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","113","","","","","","","","","","English","","","","WOS:001286037500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Deep learning; GABA-edited MEGA-PRESS; MR SPECTROSCOPY; MRS denoising; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BKRKDJ56","journalArticle","2024","Canedo, D; Hipólito, J; Fonte, J; Dias, R; do Pereiro, T; Georgieva, P; Gonçalves-Seco, L; Vázquez, M; Pires, N; Fábrega-Alvarez, P; Menéndez-Marsh, F; Neves, AJR","The Synergy between Artificial Intelligence, Remote Sensing, and Archaeological Fieldwork Validation","REMOTE SENSING","","2072-4292","10.3390/rs16111933","","The increasing relevance of remote sensing and artificial intelligence (AI) for archaeological research and cultural heritage management is undeniable. However, there is a critical gap in this field. Many studies conclude with identifying hundreds or even thousands of potential sites, but very few follow through with crucial fieldwork validation to confirm their existence. This research addresses this gap by proposing and implementing a fieldwork validation pipeline. In northern Portugal's Alto Minho region, we employed this pipeline to verify 237 potential burial mounds identified by an AI-powered algorithm. Fieldwork provided valuable information on the optimal conditions for burial mounds and the specific factors that led the algorithm to err. Based on these insights, we implemented two key improvements to the algorithm. First, we incorporated a slope map derived from LiDAR-generated terrain models to eliminate potential burial mound inferences in areas with high slopes. Second, we trained a Vision Transformer model using digital orthophotos of both confirmed burial mounds and previously identified False Positives. This further refines the algorithm's ability to distinguish genuine sites. The improved algorithm was then tested in two areas: the original Alto Minho validation region and the Barbanza region in Spain, where the location of burial mounds was well established through prior field work.","2024-06","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","11","16","","","","","","","","","","English","","","","WOS:001246685600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","archaeology; artificial intelligence; burial mounds; fieldwork validation; LiDAR; LIDAR; object detection; remote sensing; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"55THD3J9","journalArticle","2024","Zhou, R; Zhao, BB; Ding, HF; Fu, Y; Li, HJ; Wei, YK; Xie, J; Chen, CH; Yin, FQ; Huang, DZ","Survival prediction of ovarian serous carcinoma based on machine learning combined with pathological images and clinical information","AIP ADVANCES","","2158-3226","10.1063/5.0196414","","Ovarian serous carcinoma (OSC) has high mortality, making accurate prognostic evaluation vital for treatment selection. This study develops a three-year OSC survival prediction model using machine learning, integrating pathological image features with clinical data. First, a Convolutional Neural Network (CNN) was used to classify the unlabeled pathological images and determine whether they are OSC. Then, we proposed a multi-scale CNN combined with transformer model to extract features directly. The pathological image features were selected by Elastic-Net and then combined with clinical information. Survival prediction is performed using Support Vector Machine (SVM), Random Forest (RF), and XGBoost through cross-validation. For comparison, we segmented the tumor area as the region of interest (ROI) by U-net and used the same methods for survival prediction. The results indicated that (1) the CNN-based cancer classification yielded satisfactory results; (2) in survival prediction, the RF model demonstrated the best performance, followed by SVC, and XGBoost was less effective; (3) the segmented tumor ROIs are more accurate than those predicted directly from the original pathology images; and (4) predictions combining pathological images with clinical information were superior to those solely based on pathological image features. This research provides a foundation for the diagnosis of OSC and individualized treatment, affirming that both ROI extraction and clinical information inclusion enhance the accuracy of predictions.","2024-04-01","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","4","14","","","","","","","","","","English","","","","WOS:001204074700003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","CANCER; INTEGRATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"68QP5J74","journalArticle","2023","Chen, GZ; Song, Z; Qi, ZW; Sundmacher, K","Generalizing property prediction of ionic liquids from limited labeled data: a one-stop framework empowered by transfer learning","DIGITAL DISCOVERY","","2635-098X","10.1039/d3dd00040k","","Ionic liquids (ILs) could find use in almost every chemical process due to their wide spectrum of unique properties. The crux of the matter lies in whether a task-specific IL selection from enormous chemical space can be achieved by property prediction, for which limited labeled data represents a major obstacle. Here, we propose a one-stop ILTransR (IL transfer learning of representations) that employs large-scale unlabeled data for generalizing IL property prediction from limited labeled data. By first pre-training on similar to 10 million IL-like molecules, IL representations are derived from the encoder state of a transformer model. Employing the pre-trained IL representations, convolutional neural network (CNN) models for IL property prediction are trained and tested on eleven datasets of different IL properties. The obtained ILTransR presents superior performance as opposed to state-of-the-art models in all benchmarks. The application of ILTransR is exemplified by extensive screening of CO2 absorbent from a huge database of 8 333 096 synthetically-feasible ILs. We are introducing ILTransR, a transfer learning based one-stop framework to predict ionic liquid (IL) properties. High accuracy can be achieved by pre-training the model on millions of unlabeled data and fine-tuning on limited labeled data.","2023-06-12","2025-02-26 20:41:53","2025-02-26 20:41:53","","591-601","","3","2","","","","","","","","","","English","","","","WOS:001101910500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","DESIGN; EXTENSIVE DATABASES; GROUP-CONTRIBUTION QSPRS; SMILES; SOLVENTS; STATE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8JGMYSZI","journalArticle","2023","Kumar, S; Solanki, A","An abstractive text summarization technique using transformer model with self-attention mechanism","NEURAL COMPUTING & APPLICATIONS","","0941-0643","10.1007/s00521-023-08687-7","","Creating a summarized version of a text document that still conveys precise meaning is an incredibly complex endeavor in natural language processing (NLP). Abstract text summarization (ATS) is the process of using facts from source sentences and merging them into concise representations while maintaining the content and intent of the text. Manually summarizing large amounts of text are challenging and time-consuming for humans. Therefore, text summarization has become an exciting research focus in NLP. This research paper proposed an ATS model using a Transformer Technique with Self-Attention Mechanism (T2SAM). The self-attention mechanism is added to the transformer to solve the problem of coreference in text. This makes the system to understand the text better. The proposed T2SAM model improves the performance of text summarization. It is trained on the Inshorts News dataset combined with the DUC-2004 shared tasks dataset. The performance of the proposed model has been evaluated using the ROUGE metrics, and it has been shown to outperform the existing state-of-the-art baseline models. The proposed model gives the training loss minimum to 1.8220 from 10.3058 (at the starting point) up to 30 epochs, and it achieved model accuracy 48.50% F1-Score on both the Inshorts and DUC-2004 news datasets.","2023-09","2025-02-26 20:41:53","2025-02-26 20:41:53","","18603-18622","","25","35","","","","","","","","","","English","","","","WOS:000999530500006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;80</p>","","","Abstractive text summarization; DOCUMENT; Encoder-decoder; NEURAL-NETWORK; Rouge metrics; Self-attention mechanism; T2SAM; Transformer architecture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LB2VQVD7","journalArticle","2023","Wang, X; Zeng, RH; Zou, FM; Liao, LYC; Huang, FL","STTF: An Efficient Transformer Model for Traffic Congestion Prediction","INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS","","1875-6891","10.1007/s44196-022-00177-3","","With the rapid development of economy, the sharp increase in the number of urban cars and the backwardness of urban road construction lead to serious traffic congestion of urban roads. Many scholars have tried their best to solve this problem by predicting traffic congestion. Some traditional models such as linear models and nonlinear models have been proved to have a good prediction effect. However, with the increasing complexity of urban traffic network, these models can no longer meet the higher demand of congestion prediction without considering more complex comprehensive factors, such as the spatio-temporal correlation information between roads. In this paper, we propose a traffic congestion index and devise a new traffic congestion prediction model spatio-temporal transformer (STTF) based on transformer, a deep learning model. The model comprehensively considers the traffic speed of road segments, road network structure, the spatio-temporal correlation between road sections and so on. We embed temporal and spatial information into the model through the embedding layer for learning, and use the spatio-temporal attention module to mine the hidden spatio-temporal information within the data to improve the accuracy of traffic congestion prediction. Experimental results based on real-world datasets demonstrate that the proposed model significantly outperforms state-of-the-art approaches.","2023-01-05","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","1","16","","","","","","","","","","English","","","","WOS:000909503900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","CNN; Free-stream velocity; LSTM; Road network structure; Spatio-temporal information; Traffic congestion prediction; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A2AFHXD4","journalArticle","2022","Zhang, XR; Guo, RC; Yang, Y; Hu, YD; Zhang, ZY; Li, JH; Han, XT","Partial Discharge Measurement and Analysis of Transformer Under Oscillating Lightning Impulse Voltage","IEEE TRANSACTIONS ON DIELECTRICS AND ELECTRICAL INSULATION","","1070-9878","10.1109/TDEI.2022.3205291","","Oscillating lightning impulse (OLI) voltage is recommended for on-site testing due to its high generation efficiency. In this article, partial discharge (PD) characteristics under field impulse voltage waveforms are investigated. The experiment is carried out on a scaled transformer model with a protrusion defect inside as the PD source. Both oscillating and standard lightning impulse (SLI) voltages are acquired as test waveforms. Main discharges and reverse discharges are detected simultaneously under both OLI and SLI voltage. The increasing applied voltage amplitude advances the main discharge and enlarges its amplitude, and it also prolongs the duration of the reverse discharge and increases the number. The amplitude of main discharge is related to the PD voltage, while that of reverse discharge depends on the dynamic variation of the impulse voltage. Since OLI voltage contains multiple rising edges during the oscillation period, more PDs are excited. A disruptive effect (DE) model is extended for the PD analysis to show the oscillation effect on the PD distribution. The OLI test with PD measurement performed on a 220-kV transformer proves that PD detection during impulse voltage withstand test reflects more detailed information that can be used for early diagnosis of power transformers.","2022-12","2025-02-26 20:41:53","2025-02-26 20:41:53","","2303-2311","","6","29","","","","","","","","","","English","","","","WOS:000905713700029","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","BREAKDOWN CHARACTERISTICS; Disruptive effect (DE) method; field test; GIS; INSULATION; OIL; oscillating lightning impulse (OLI); partial discharges (PDs); SF6; STRENGTH; transformers; WAVE-FORMS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A29XIT58","journalArticle","2022","Kates, JM; Arehart, KH","An overview of the HASPI and HASQI metrics for predicting speech intelligibility and speech quality for normal hearing, hearing loss, and hearing aids","HEARING RESEARCH","","0378-5955","10.1016/j.heares.2022.108608","","Alterations of the speech signal, including additive noise and nonlinear distortion, can reduce speech in-telligibility and quality. Hearing aids present an especially complicated situation since these devices may implement nonlinear processing designed to compensate for the hearing loss. Hearing-aid processing is often realized as time-varying multichannel gain adjustments, and may also include frequency reassign-ment. The challenge in designing metrics for hearing aids and hearing-impaired listeners is to accurately model the perceptual trade-offs between speech audibility and the nonlinear distortion introduced by hearing-aid processing. This paper focuses on the Hearing Aid Speech Perception Index (HASPI) and the Hearing Aid Speech Quality Index (HASQI) as representative metrics for predicting intelligibility and qual-ity. These indices start with a model of the auditory periphery that can be adjusted to represent hearing loss. The peripheral model, the speech features computed from the model outputs, and the procedures used to fit the features to subject data are described. Examples are then presented for using the metrics to measure the effects of additive noise, evaluate noise-suppression processing, and to measure the dif-ferences among commercial hearing aids. Open questions and considerations in using these and related metrics are then discussed.(c) 2022 Elsevier B.V. All rights reserved.","2022-12","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","426","","","","","","","","","","English","","","","WOS:000903731900012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;90</p>","","","AUDITORY FILTER NONLINEARITY; Auditory peripheral model; EFFERENT SUPPRESSION; FREQUENCY; Hearing aids; Hearing loss; INDEX; MODULATION; NERVE FIBERS; NOISE; PHENOMENOLOGICAL MODEL; RESPONSES; Speech intelligibility; Speech quality ratings; WORKING-MEMORY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LRNUKSBW","journalArticle","2022","Almasoud, AS; Eisa, TAE; Al-Wesabi, FN; Elsafi, A; Al Duhayyim, M; Yaseen, I; Hamza, MA; Motwakel, A","Parkinson's Detection Using RNN-Graph-LSTM with Optimization Based on Speech Signals","CMC-COMPUTERS MATERIALS & CONTINUA","","1546-2218","10.32604/cmc.2022.024596","","Early detection of Parkinson's Disease (PD) using the PD patients' voice changes would avoid the intervention before the identification of physical symptoms. Various machine learning algorithms were developed to detect PD detection. Nevertheless, these ML methods are lack in generalization and reduced classification performance due to subject overlap. To overcome these issues, this proposed work apply graph long short term memory (GLSTM) model to classify the dynamic features of the PD patient speech signal. The proposed classification model has been further improved by implementing the recurrent neural network (RNN) in batch normalization layer of GLSTM and optimized with adaptive moment estimation (ADAM) on network hidden layer. To consider the importance of feature engineering, this proposed system use Linear Discriminant analysis (LDA) for dimensionality reduction and Sparse Auto-Encoder (SAE) for extracting the dynamic speech features. Based on the computation of energy content transited from unvoiced to voice (onset) and voice to voiceless (offset), dynamic features are measured. The PD datasets is evaluated under 10 fold cross validation without sample overlap. The proposed smart PD detection method called RNN-GLSTM-ADAM is numerically experimented with persistent phonations in terms of accuracy, sensitivity, and specificity and Matthew correlation coefficient. The evaluated result of RNN-GLSTM-ADAM extremely improves the PD detection accuracy than static feature based conventional ML and DL approaches.","2022","2025-02-26 20:41:53","2025-02-26 20:41:53","","871-886","","1","72","","","","","","","","","","English","","","","WOS:000763489500015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","auto encoder; classification; CLASSIFICATION; Dimensionality reduction; DISEASE; EARLY-DIAGNOSIS; feature extraction; LDA; LSTM and optimization; NEURAL-NETWORK; recurrent neural network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PDS8VSM9","journalArticle","2024","Huang, ZW; Yi, YW","Short-Term Load Forecasting for Regional Smart Energy Systems Based on Two-Stage Feature Extraction and Hybrid Inverted Transformer","SUSTAINABILITY","","2071-1050","10.3390/su16177613","","Accurate short-term load forecasting is critical for enhancing the reliability and stability of regional smart energy systems. However, the inherent challenges posed by the substantial fluctuations and volatility in electricity load patterns necessitate the development of advanced forecasting techniques. In this study, a novel short-term load forecasting approach based on a two-stage feature extraction process and a hybrid inverted Transformer model is proposed. Initially, the Prophet method is employed to extract essential features such as trends, seasonality and holiday patterns from the original load dataset. Subsequently, variational mode decomposition (VMD) optimized by the IVY algorithm is utilized to extract significant periodic features from the residual component obtained by Prophet. The extracted features from both stages are then integrated to construct a comprehensive data matrix. This matrix is then inputted into a hybrid deep learning model that combines an inverted Transformer (iTransformer), temporal convolutional networks (TCNs) and a multilayer perceptron (MLP) for accurate short-term load forecasting. A thorough evaluation of the proposed method is conducted through four sets of comparative experiments using data collected from the Elia grid in Belgium. Experimental results illustrate the superior performance of the proposed approach, demonstrating high forecasting accuracy and robustness, highlighting its potential in ensuring the stable operation of regional smart energy systems.","2024-09","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","17","16","","","","","","","","","","English","","","","WOS:001311632400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","inverted transformer; IVY algorithm; load forecasting; multilayer perceptron; Prophet; temporal convolutional network; variational mode decomposition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TY2MRGYS","journalArticle","2024","Yu, RD; Zhang, ZS","Transformer partial discharge location technology based on gradient oil temperature","FRONTIERS IN ENERGY RESEARCH","","2296-598X","10.3389/fenrg.2024.1428012","","Introduction The traditional partial discharge localization improvement strategy mainly starts from the intelligent algorithm, but fails to consider the influence of core winding and oil temperature on partial discharge positioning.Methods This paper also considers the influence of the iron core winding and oil temperature. Through finite element simulation, a transformer model was established to analyze the propagation characteristics of ultrasonic signals generated by partial discharge under the interference of gradient oil temperature and winding. The chaotic firefly-particle swarm hybrid algorithm is proposed, and through the calculation of Shubert's multi-peak function. Finally, a partial discharge defect platform based on gradient oil temperature was built to verify the chaotic firefly-particle swarm hybrid localization algorithm.Results The ultrasonic velocity generated by partial discharge in transformers cannot be fixed, and it is suggested that ultrasonic sensors should be installed near the center of the top of the transformer. The proposed algorithm can be better optimized in the case of multiple local extreme points. Under gradient oil temperature experiments, the algorithm achieves positioning errors less than 100 and 55 mm for cases with and without winding obstruction, respectively, with average positioning errors of 74.2 and 35.2 mm.Discussion The positioning method in this paper can provide a technical reference for the partial discharge positioning of transformers in actual operation.","2024-07-31","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","12","","","","","","","","","","English","","","","WOS:001289797000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","acoustic and electric joint positioning; gradient oil temperature; partial discharge; transformer; velocity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DFWGMRXP","journalArticle","2024","Zhang, CH; Zhang, CG; Tian, GP; Gu, X","Electromechanical Coupling Model for Ionic Liquid Gel Soft Actuators","APPLIED BIONICS AND BIOMECHANICS","","1176-2322","10.1155/2024/8369544","","A soft robot is composed of soft materials, which exhibit continuous deformation and driving structure integration and can arbitrarily change shapes and sizes over wide ranges. It shows strong adaptability to unstructured environments and has broad application prospects in military reconnaissance, medical rescues, agricultural production, etc. Soft robots based on ionic electroactive polymers (EAPs) have low-driving voltages, large-actuation displacements, fast responses, light weights, and low powers and have become a hot research field of bionic robots. Ionic liquid gels (ILGs) are new ionic EAPs. In this study, a new soft actuator was designed based on an ILG, and the electromechanical coupling model of an ILG soft actuator was studied in detail. Based on the system transfer function method, a mechatronic coupling model for the soft actuator was developed. According to the material characteristics and current response law of the ILG-containing EAP, an equivalent circuit model was used to describe transfer of the output current and input voltage. Based on the equivalent transformer model for ionic polymer-metal composite (IPMC) actuators proposed by Claudia Bonomo, the electromechanical coupling equation and a driving equation of the ILG soft actuator were established. The least-squares method was used with the coupling model of an ILG soft actuator to identify the system parameters for the model, and the effects of the structural parameters on the end displacement and driving force of the soft actuator were analyzed.","2024-02-13","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","2024","","","","","","","","","","English","","","","WOS:001169842900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HKK6Y7YZ","journalArticle","2024","Shi, CC; Liu, SX","Human action recognition with transformer based on convolutional features","INTELLIGENT DECISION TECHNOLOGIES-NETHERLANDS","","1872-4981","10.3233/IDT-240159","","As one of the key research directions in the field of computer vision, human action recognition has a wide range of practical application values and prospects. In the fields of video surveillance, human-computer interaction, sports analysis, and healthcare, human action recognition technology shows a broad application prospect and potential. However, the diversity and complexity of human actions bring many challenges, such as handling complex actions, distinguishing similar actions, coping with changes in viewing angle, and overcoming occlusion problems. To address the challenges, this paper proposes an innovative framework for human action recognition. The framework combines the latest pose estimation algorithms, pre-trained CNN models, and a Vision Transformer to build an efficient system. The first step involves utilizing the latest pose estimation algorithm to accurately extract human pose information from real RGB image frames. Then, a pre-trained CNN model is used to perform feature extraction on the extracted pose information. Finally, the Vision Transformer model is applied for fusion and classification operations on the extracted features. Experimental validation is conducted on two benchmark datasets, UCF 50 and UCF 101, to demonstrate the effectiveness and efficiency of the proposed framework. The applicability and limitations of the framework in different scenarios are further explored through quantitative and qualitative experiments, providing valuable insights and inspiration for future research.","2024","2025-02-26 20:41:53","2025-02-26 20:41:53","","881-896","","2","18","","","","","","","","","","English","","","","WOS:001263717000015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","convolutional features; Human action recognition; NETWORK; pose estimation; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D6USA4IV","journalArticle","2023","Zhou, W; Hou, Y; Xu, SJ; Zhou, SL","An adaptive cross-scale transformer based on graph signal processing for person re-identification","IET IMAGE PROCESSING","","1751-9659","10.1049/ipr2.12794","","Extracting robust feature representation is one of the key challenges for person re-identification (ReID) task. Although convolution neural network (CNN)-based methods have achieved great success, they still cannot handle the part occlusion and misalignment caused by limited receptive field. Recently, pure transformer models have shown its power in the person ReID task. However, current transformer models adopt patches of equal-scale as input, and cannot solve the problem of cross-scale interaction properly. To overcome this problem, an adaptive cross-scale transformer from a perspective of the graph signal, named ACSFormer, is proposed. Specifically, the self-attention module is first treated as an undirected fully connected graph. And then, ""node variation"" is introduced as an indicator to adaptively merge neighbourhood tokens. To the best of the authors' knowledge, their ACSFormer is the first work to attempt to combine pure transformers and graph signal processing in the field of person ReID. Extensive evaluations are conducted on three person ReID datasets to validate the performance of ACSFormer. Experiments demonstrate that this ACSFormer performs on par with state-of-the-art CNN-based methods and consistently improves transformer-based baseline, for example, surpassing ViT-baseline by 2.5%, 2.7% and 4.8% mAP on Market1501, DukeMTMC-reID and MSMT17, respectively.","2023-06","2025-02-26 20:41:53","2025-02-26 20:41:53","","2321-2335","","8","17","","","","","","","","","","English","","","","WOS:000997455200003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","cross-scale interaction; graph signal processing; person re-identification; pure transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TBFWPFRD","journalArticle","2025","Bashir, T; Wang, HF; Tahir, M; Zhang, YX","Wind and solar power forecasting based on hybrid CNN-ABiLSTM, CNN-transformer-MLP models","RENEWABLE ENERGY","","0960-1481","10.1016/j.renene.2024.122055","","Accurate prediction of solar and wind power output is crucial for effective integration into the electrical grid. Existing methods, including conventional approaches, machine learning (ML), and hybrid models, have limitations such as limited adaptability, narrow generalizability, and difficulty in forecasting multiple types of renewable energy respectively. To address these challenges, this study introduces two novel hybrid models: the CNN-ABiLSTM, which integrates Convolutional Neural Networks (CNN) with Attention-based Bidirectional Long Short-Term Memory (ABiLSTM), and the CNN-Transformer-MLP, which integrates CNN with Transformers and Multi-Layer Perceptrons (MLP). In both hybrid models, the CNN captures short-term patterns in solar and wind power data, while the ABiLSTM and Transformer-MLP models address the long-term patterns. CNN, BiLSTM, and Encoder-based Transformer were taken as baseline standalone models. The proposed hybrid models and standalone baseline models were trained on quarter-hour-based real-time data. The hybrid models outperform standalone baseline models in day, week, and month-ahead forecasting. The CNN-Transformer-MLP hybrid provides more accurate day and week-ahead solar and wind power predictions with lower mean absolute error (MAE), root mean square error (RMSE), and mean square error (MSE) values. For month-ahead forecasts, the CNN-ABiLSTM hybrid excels in wind power prediction, demonstrating its strength in long-term forecasting.","2025-02-01","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","239","","","","","","","","","","English","","","","WOS:001381376100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Bidirectional long-short-term memory model; Hybrid model; Renewable energy; Solar and wind power forecasting; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WSRD9YWG","journalArticle","2024","Ying, WY; Wang, DJ; Chen, HF; Fu, YJ","Feature Selection as Deep Sequential Generative Learning","ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA","","1556-4681","10.1145/3687485","","Feature selection aims to identify the most pattern-discriminative feature subset. In prior literature, filter (e.g., backward elimination) and embedded (e.g., LASSO) methods have hyperparameters (e.g., top-k, score thresholding) and tie to specific models, thus, hard to generalize; wrapper methods search a feature subset in a huge discrete space and is computationally costly. To transform the way of feature selection, we regard a selected feature subset as a selection decision token sequence and reformulate feature selection as a deep sequential generative learning task that distills feature knowledge and generates decision sequences. Our method includes three steps: (1) We develop a deep variational transformer model over a joint of sequential reconstruction, variational, and performance evaluator losses. Our model can distill feature selection knowledge and learn a continuous embedding space to map feature selection decision sequences into embedding vectors associated with utility scores. (2) We leverage the trained feature subset utility evaluator as a gradient provider to guide the identification of the optimal feature subset embedding; (3) We decode the optimal feature subset embedding to autoregressively generate the best feature selection decision sequence with autostop. Extensive experimental results show this generative perspective is effective and generic, without large discrete search space and expert-specific hyperparameters. The code is available at http://tinyurl.com/FSDSGL.","2024-11","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","9","18","","","","","","","","","","English","","","","WOS:001363008500002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","automated feature engineering; deep sequential genera- tive model; ENSEMBLE; Feature selection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KEUEQULP","journalArticle","2024","Yang, YC; Xie, C; Tian, BS; Guo, YH; Zhu, Y; Bian, SC; Yang, Y; Zhang, M; Ruan, YM","Advanced Post-earthquake Building Damage Assessment: SAR Coherence Time Matrix with Vision Transformer","INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION","","1569-8432","10.1016/j.jag.2024.104133","","Rapid and accurate assessment of affected areas is crucial for post-earthquake rescue efforts, as earthquakes can lead to extensive damage and casualties. The post-earthquake damage assessment method based on SAR coherence is widely utilized, but issues such as inadequate consideration of decorrelation factors and underutilization of preseismic coherence can negatively impact assessment outcomes. To address these limitations and enhance accuracy while reducing false alarms, we propose a novel approach for post-earthquake building damage assessment utilizing a SAR coherence time matrix. The proposed method involves constructing time matrices by computing preseismic image coherence to maximize the utilization of preseismic coherence information. By developing a Vision Transformer model within the realm of deep learning, we aimed to extract features from these time matrices based on their unique characteristics. Through the use of predicted values obtained from the trained model to simulate coseismic coherence, a scoring metric was established as a proxy for damage. This novel method was successfully applied to evaluate the damage caused by the 2016 Italy earthquake and the 2023 Turkey earthquake, yielding improved accuracy and reduced false alarm rates. The research findings demonstrate the transferability and reliability of this method, presenting it as an accurate and dependable tool for post-earthquake building damage assessment.","2024-09","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","133","","","","","","","","","","English","","","","WOS:001309572500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Building damage assessment; Coherence matrix; Earthquake; Synthetic Aperture Radar; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BB9ZJVDW","journalArticle","2024","Ke, HC; Sun, HB; Zhao, HL; Wu, T","Ice Cover Prediction for Transmission Lines Based on Feature Extraction and an Improved Transformer Scheme","ELECTRONICS","","2079-9292","10.3390/electronics13122339","","Frequent and severe icing on transmission lines poses a serious threat to the stability and safe operation of the power system. Meteorological data, inherently stochastic and uncertain, requires effective preprocessing and feature extraction to ensure accurate and efficient prediction of transmission line icing thickness. We address this challenge by leveraging the meteorological features of icing phenomena and propose a novel feature preprocessing method that integrates Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN) and spectral clustering. This method effectively preprocesses raw time series data, extracts key features, and constructs a similarity matrix and feature vector. The resulting feature vector serves as a new data representation, facilitating cluster analysis to isolate meteorological and icing-related features specific to transmission lines. Subsequently, we introduce an enhanced Transformer model for predicting transmission line icing thickness. The proposed model leverages the extracted meteorological and icing features by independently embedding variable tokens for each input feature. This approach improves the model's prediction accuracy under multiple feature inputs, leading to more effective learning. The experimental results demonstrate that the performance of the proposed prediction algorithm is better than the three baseline algorithms (hybrid CEEMDAN and LSTM (CEEMDAN-LSTM), hybrid CEEMDAN, spectral clustering, and LSTM (CEEMDAN-SP-LSTM), and hybrid CEEMDAN, spectral clustering, and Transformer (CEEMDAN-SP-Transformer)) under multiple feature inputs and different parameter settings.","2024-06","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","12","13","","","","","","","","","","English","","","","WOS:001256098100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","feature extraction; ice cover prediction; spectral clustering; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J2FYX3P4","journalArticle","2024","Sikkandar, MY; Sundaram, SG; Alassaf, A; Almohimeed, I; Alhussaini, K; Aleid, A; Alolayan, SA; Ramkumar, P; Almutairi, MK; Begum, SS","Utilizing adaptive deformable convolution and position embedding for colon polyp segmentation with a visual transformer","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-57993-0","","Polyp detection is a challenging task in the diagnosis of Colorectal Cancer (CRC), and it demands clinical expertise due to the diverse nature of polyps. The recent years have witnessed the development of automated polyp detection systems to assist the experts in early diagnosis, considerably reducing the time consumption and diagnostic errors. In automated CRC diagnosis, polyp segmentation is an important step which is carried out with deep learning segmentation models. Recently, Vision Transformers (ViT) are slowly replacing these models due to their ability to capture long range dependencies among image patches. However, the existing ViTs for polyp do not harness the inherent self-attention abilities and incorporate complex attention mechanisms. This paper presents Polyp-Vision Transformer (Polyp-ViT), a novel Transformer model based on the conventional Transformer architecture, which is enhanced with adaptive mechanisms for feature extraction and positional embedding. Polyp-ViT is tested on the Kvasir-seg and CVC-Clinic DB Datasets achieving segmentation accuracies of 0.9891 +/- 0.01 and 0.9875 +/- 0.71 respectively, outperforming state-of-the-art models. Polyp-ViT is a prospective tool for polyp segmentation which can be adapted to other medical image segmentation tasks as well due to its ability to generalize well.","2024-03-27","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","1","14","","","","","","","","","","English","","","","WOS:001196356400073","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","ANXIETY; COVID-19; Deformable convolution; NEGATIVE AFFECT; PHYSICAL-ACTIVITY; Polyp segmentation; RUMINATION; SELF-DETERMINATION THEORY; STRUCTURAL EQUATION MODELS; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LCFUGP5B","journalArticle","2024","Entrup, E; Eppelin, A; Ewerth, R; Hartwig, J; Tullney, M; Wohlgemuth, M; Hoppe, A","Comparing different search methods for the open access journal recommendation tool B!SON","INTERNATIONAL JOURNAL ON DIGITAL LIBRARIES","","1432-5012","10.1007/s00799-023-00372-3","","Finding a suitable open access journal to publish academic work is a complex task: Researchers have to navigate a constantly growing number of journals, institutional agreements with publishers, funders' conditions and the risk of predatory publishers. To help with these challenges, we introduce a web-based journal recommendation system called B!SON. A systematic requirements analysis was conducted in the form of a survey. The developed tool suggests open access journals based on title, abstract and references provided by the user. The recommendations are built on open data, publisher-independent and work across domains and languages. Transparency is provided by its open source nature, an open application programming interface (API) and by specifying which matches the shown recommendations are based on. The recommendation quality has been evaluated using two different evaluation techniques, including several new recommendation methods. We were able to improve the results from our previous paper with a pre-trained transformer model. The beta version of the tool received positive feedback from the community and in several test sessions. We developed a recommendation system for open access journals to help researchers find a suitable journal. The open tool has been extensively tested, and we found possible improvements for our current recommendation technique. Development by two German academic libraries ensures the longevity and sustainability of the system.","2024-09","2025-02-26 20:41:53","2025-02-26 20:41:53","","505-516","","3","25","","","","","","","","","","English","","","","WOS:001029751600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Academic publishing; Open access; Paper submission; Recommendation system; Scholarly journals","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NJ63QMW4","journalArticle","2023","Greer, T; Shi, X; Ma, B; Narayanan, S","Creating musical features using multi-faceted, multi-task encoders based on transformers","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-023-36714-z","","Computational machine intelligence approaches have enabled a variety of music-centric technologies in support of creating, sharing and interacting with music content. A strong performance on specific downstream application tasks, such as music genre detection and music emotion recognition, is paramount to ensuring broad capabilities for computational music understanding and Music Information Retrieval. Traditional approaches have relied on supervised learning to train models to support these music-related tasks. However, such approaches require copious annotated data and still may only provide insight into one view of music-namely, that related to the specific task at hand. We present a new model for generating audio-musical features that support music understanding, leveraging self-supervision and cross-domain learning. After pre-training using masked reconstruction of musical input features using self-attention bidirectional transformers, output representations are fine-tuned using several downstream music understanding tasks. Results show that the features generated by our multi-faceted, multi-task, music transformer model, which we call M3BERT, tend to outperform other audio and music embeddings on several diverse music-related tasks, indicating the potential of self-supervised and semi-supervised learning approaches toward a more generalized and robust computational approach to modeling music. Our work can offer a starting point for many music-related modeling tasks, with potential applications in learning deep representations and enabling robust technology applications.","2023-07-03","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","1","13","","","","","","","","","","English","","","","WOS:001023060100011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","NEURAL-NETWORKS; NORMALIZATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CRBJDDL7","journalArticle","2023","Wang, JJ; Xie, HR; Wang, FL; Lee, LK","A transformer-convolution model for enhanced session-based recommendation","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2023.01.083","","Session-based recommendation aims to predict a user's next action based on a series of anonymous sequences and plays an essential role in various online applications, such as e-commerce and music applications. Recently, transformer-based models have obtained results that are competitive with or even surpass those of recurrent neural networks, because of the good performance of transformer models in capturing long-distance dependencies. However, a transformer has a limited ability to mine local contex-tual information, which can be regarded as collective features. Researchers are seeking to address this limitation by augmenting the contextual transition to boost session representation learning. Accordingly, in this paper, we enhance the capabilities of a transformer in a session-based recommenda-tion task by introducing convolutional neural networks (CNNs) at the stage of aggregating the item fea-tures with long-and short-distance dependencies. We first borrow a self-attention module from the classic transformer model to explore the long-distance dependencies. We next propose horizontal and vertical convolutions for enhancing the local collective information and then obtain a session represen-tation by integrating the two types of features. Extensive experiments on real-world datasets show that our method outperforms those that rely on a transformer or a CNN alone.(c) 2023 Published by Elsevier B.V.","2023-04-28","2025-02-26 20:41:53","2025-02-26 20:41:53","","21-33","","","531","","","","","","","","","","English","","","","WOS:000945054800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Convolutional neural network; Recommender system; Session -based recommendation; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"24SAQIQU","journalArticle","2023","Li, GD; Guo, LJ; Zhang, R; Qian, JB; Gao, SC","TransGait: Multimodal-based gait recognition with set transformer","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-022-03543-y","","As a biological feature that can be recognized from a distance, gait has a wide range of applications such as crime prevention, judicial identification, and social security. However, gait recognition is still a challenging task with two problems in the typical gait recognition methods. First, the existing gait recognition methods have weak robustness to the pedestrians' clothing and carryings. Second, the existing temporal modeling methods for gait recognition fail to fully exploit the temporal relationships of the sequence and require that the gait sequence maintain unnecessary sequential constraints. In this paper, we propose a new multi-modal gait recognition framework based on silhouette and pose features to overcome these problems. Joint features of silhouettes and poses provide high discriminability and robustness to the pedestrians' clothing and carryings. Furthermore, we propose a set transformer model with a temporal aggregation operation for obtaining set-level spatio-temporal features. The temporal modeling approach is unaffected by frame permutations and can seamlessly integrate frames from different videos acquired in different scenarios, such as diverse viewing angles. Experiments on two public datasets, CASIA-B and GREW, demonstrate that the proposed method provides state-of-the-art performance. Under the most challenging condition of walking in different clothes on CASIA-B, the proposed method achieves a rank-1 accuracy of 85.8%, outperforming other methods by a significant margin (> 4%).","2023-01","2025-02-26 20:41:53","2025-02-26 20:41:53","","1535-1547","","2","53","","","","","","","","","","English","","","","WOS:000788987000003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;28<br/>Total Times Cited:&nbsp;&nbsp;28<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Gait recognition; Multi-modal; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8Z8FFI87","journalArticle","2024","Klempír, O; Krupicka, R","Analyzing Wav2Vec 1.0 Embeddings for Cross-Database Parkinson's Disease Detection and Speech Features Extraction","SENSORS","","1424-8220","10.3390/s24175520","","Advancements in deep learning speech representations have facilitated the effective use of extensive unlabeled speech datasets for Parkinson's disease (PD) modeling with minimal annotated data. This study employs the non-fine-tuned wav2vec 1.0 architecture to develop machine learning models for PD speech diagnosis tasks, such as cross-database classification and regression to predict demographic and articulation characteristics. The primary aim is to analyze overlapping components within the embeddings on both classification and regression tasks, investigating whether latent speech representations in PD are shared across models, particularly for related tasks. Firstly, evaluation using three multi-language PD datasets showed that wav2vec accurately detected PD based on speech, outperforming feature extraction using mel-frequency cepstral coefficients in the proposed cross-database classification scenarios. In cross-database scenarios using Italian and English-read texts, wav2vec demonstrated performance comparable to intra-dataset evaluations. We also compared our cross-database findings against those of other related studies. Secondly, wav2vec proved effective in regression, modeling various quantitative speech characteristics related to articulation and aging. Ultimately, subsequent analysis of important features examined the presence of significant overlaps between classification and regression models. The feature importance experiments discovered shared features across trained models, with increased sharing for related tasks, further suggesting that wav2vec contributes to improved generalizability. The study proposes wav2vec embeddings as a next promising step toward a speech-based universal model to assist in the evaluation of PD.","2024-09","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","17","24","","","","","","","","","","English","","","","WOS:001311558300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;86</p>","","","classification; cross-database; DISORDERS; feature importance; MODEL; Parkinson's disease; regression; wav2vec","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3RT4UCZN","journalArticle","2024","Zheng, CD; Xie, FF; Ji, TW; Zhou, HJ; Zheng, Y","Transformer-based in-context policy learning for efficient active flow control across various airfoils","JOURNAL OF FLUID MECHANICS","","0022-1120","10.1017/jfm.2024.1133","","Active flow control based on reinforcement learning has received much attention in recent years. Indeed, the requirement for substantial data for trial-and-error in reinforcement learning policies has posed a significant impediment to their practical application, which also serves as a limiting factor in the training of cross-case agents. This study proposes an in-context active flow control policy learning framework grounded in reinforcement learning data. A transformer-based policy improvement operator is set up to model the process of reinforcement learning as a causal sequence and autoregressively give actions with sufficiently long context on new unseen cases. In flow separation problems, this framework demonstrates the capability to successfully learn and apply efficient flow control strategies across various airfoil configurations. Compared with general reinforcement learning, this learning mode without the need for updating the network parameter has even higher efficiency. This study presents an effective novel technique in using a single transformer model to address the flow separation active flow control problem on different airfoils. Additionally, the study provides an innovative demonstration of incorporating reinforcement-learning-based flow control with aerodynamic shape optimization, leading to collective enhancement in performance. This method efficiently lessens the training burden of the new flow control policy during shape optimization, and opens up a promising avenue for interdisciplinary intelligent co-design of future vehicles.","2024-12-19","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","1001","","","","","","","","","","English","","","","WOS:001379868600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","FEEDBACK-CONTROL; machine learning; REINFORCEMENT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U7B2H4G9","journalArticle","2024","Chen, ZX; Yu, J; Tan, QY; Li, S; Du, XS","DGTAD: decomposition GAN-based transformer for anomaly detection in multivariate time series data","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-024-05693-7","","The advancement of the computer and information industry has led to the emergence of new demands for multivariate time series anomaly detection (MTSAD) models, namely, the necessity for unsupervised anomaly detection that is both efficient and accurate. However, long-term time series data typically encompass a multitude of intricate temporal pattern variations and noise. Consequently, accurately capturing anomalous patterns within such data and establishing precise and rapid anomaly detection models pose challenging problems. In this paper, we propose a decomposition GAN-based transformer for anomaly detection (DGTAD) in multivariate time series data. Specifically, DGTAD integrates a time series decomposition structure into the original transformer model, further decomposing the extracted global features into deep trend information and seasonal information. On this basis, we improve the attention mechanism, which uses decomposed time-dependent features to change the traditional focus of the transformer, enabling the model to reconstruct anomalies of different types in a targeted manner. This makes it difficult for anomalous data to adapt to these changes, thereby amplifying the anomalous features. Finally, by combining the GAN structure and using multiple generators from different perspectives, we alleviate the mode collapse issue, thereby enhancing the model's generalizability. DGTAD has been validated on nine benchmark datasets, demonstrating significant performance improvements and thus proving its effectiveness in unsupervised anomaly detection.","2024-12","2025-02-26 20:41:53","2025-02-26 20:41:53","","13038-13056","","24","54","","","","","","","","","","English","","","","WOS:001335337100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Anomaly detection; GAN; Multivariate time series; NETWORKS; Transformer; Unsupervised learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6NQQ5C74","journalArticle","2023","Zhang, JS; Li, X; Tian, JL; Luo, H; Yin, S","An integrated multi-head dual sparse self-attention network for remaining useful life prediction","RELIABILITY ENGINEERING & SYSTEM SAFETY","","0951-8320","10.1016/j.ress.2023.109096","","Committed to accident prevention, prediction of remaining useful life (RUL) plays a crucial role in prognostics health management technology. Conventional convolutional neural network and long-short-term memory network have notable limitations in the size of convolution in processing temporal data and the associations between non-adjacent data when predicting the RUL, respectively. Although the proposal of the Transformer provides an opportunity to solve the shortcomings mentioned above, Transformer still has some limitations. Precisely, the Transformer model awaits in-depth research focusing on vital local regions and decreasing computational complexity. In this sense, this paper proposes a novel integrated multi-head dual sparse self-attention network (IMDSSN) based on a modified Transformer to predict the RUL. From two sparse perspectives, the proposed IMDSSN includes a multi-head ProbSparse self-attention network (MPSN) and a multi-head LogSparse self-attention network (MLSN). Specifically, MPSN is designed to filter out the primary function of the dot product operation, thereby improving computational efficiency. Furthermore, considering the data inside the whole time window, a comprehensive logarithmic-based sparse strategy in MLSN is proposed to reduce the amount of computation. An aircraft turbofan engine dataset is used to verify the proposed IMDSSN, which demonstrates that the IMDSSN is better than some conventional approaches.","2023-05","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","233","","","","","","","","","","English","","","","WOS:000925910300002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;99<br/>Total Times Cited:&nbsp;&nbsp;99<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Multi-head self-attention; Prediction; PROGNOSTICS; Remaining useful life; Sparse strategy; Transformer; TRANSFORMER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5NHW3R86","journalArticle","2025","Peng, DW; Weng, QZ; Zhong, NZ; Xie, T; Gong, C; Zhu, XW; Yuan, XL; Ouyang, MJ","LMCodec2: Ultra-low bit rate codec with causal multiple transformers","COMPUTERS & ELECTRICAL ENGINEERING","","0045-7906","10.1016/j.compeleceng.2024.109960","","In recent years, the bandwidth constraints in satellite Internet of Things (IoT) applications have spurred the development of novel methods for compressing transmitted speech. For satellite voice communications, it is essential to achieve high-quality codecs with a bit rate below 1 kbps, particularly for channels such as Beidou-3, which often operate under such limitations. Neural network-based vocoders have emerged as a promising solution within the AI community, offering high-fidelity audio compression. In this paper, we propose LMCodec2, a causal speech codec designed to operate across a range of bit rates while delivering high-quality audio at extremely low bit rates, specifically tailored for satellite voice transmission. LMCodec2 utilizes a Transformer-based language model to predict tokens frame by frame, achieving a 25 % reduction in bit rate without compromising decoded audio quality. Our experimental evaluations demonstrate that LMCodec2 produces high-quality decoded audio at 0.76 kbps and 1.15 kbps. Notably, at 0.76 kbps, LMCodec2 achieves a MUSHRA (Multi-Stimulus Test with Hidden Reference and Anchor) score that surpasses Encodec's performance at 1.5 kbps. Audio demonstrations, including real-world self-recorded speech datasets, are available at https://dingweipeng.github.io/JACK. github.io. LMCodec2 provides a new way of thinking to addressing the challenges of bandwidth-limited satellite voice communications.","2025-03","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","122","","","","","","","","","","English","","","","WOS:001390769000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","End-to-end codec; GAN; Huffman coding; NETWORKS; Transformer model; VQ-VAE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DGE997AV","journalArticle","2024","Ramoni, D; Sgura, C; Liberale, L; Montecucco, F; Ioannidis, JPA; Carbone, F","Artificial intelligence in scientific medical writing: Legitimate and deceptive uses and ethical concerns","EUROPEAN JOURNAL OF INTERNAL MEDICINE","","0953-6205","10.1016/j.ejim.2024.07.012","","The debate surrounding the integration of artificial intelligence (AI) into scientific writing has already attracted significant interest in medical and life sciences. While AI can undoubtedly expedite the process of manuscript creation and correction, it raises several criticisms. The crossover between AI and health sciences is relatively recent, but the use of AI tools among physicians and other scientists who work in the life sciences is growing very fast. Within this whirlwind, it is becoming essential to realize where we are heading and what the limits are, including an ethical perspective. Modern conversational AIs exhibit a context awareness that enables them to understand and remember any conversation beyond any predefined script. Even more impressively, they can learn and adapt as they engage with a growing volume of human language input. They all share neural networks as background mathematical models and differ from old chatbots for their use of a specific network architecture called transformer model [1]. Some of them exceed 100 terabytes (TB) (e.g., Bloom, LaMDA) or even 500 TB (e.g., Megatron-Turing NLG) of text data, the 4.0 version of ChatGPT (GPT-4) was trained with nearly 45 TB, but stays updated by the internet connection and may integrate with different plugins that enhance its functionality, making it multimodal.","2024-09","2025-02-26 20:41:53","2025-02-26 20:41:53","","31-35","","","127","","","","","","","","","","English","","","","WOS:001308962500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;15</p>","","","Artificial intelligence; Chatbots; ChatGPT; Large language models; Medical writing; Natural language understanding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TQSVLES6","journalArticle","2024","Lu, ZM; Yan, W; Huang, DZ; Tang, JJ; Ponci, F; Monti, A","Power Flow Model for Medium-voltage Distribution Systems Considering Measurement and Structure Characteristics","JOURNAL OF MODERN POWER SYSTEMS AND CLEAN ENERGY","","2196-5625","10.35833/MPCE.2023.000035","","Medium-voltage distribution systems (MVDSs) mainly consist of a feeder head, lines, distribution transformers, and the equivalent load or power supply interfaced with the distribution transformers. The information of such load or power supply can be measured via the three-wattmeter method (THM) and the two-wattmeter method (TWM). The measurements can be used to perform the control of the power supply and simulate the characteristics of the load, so the models of the load and the power supply need to consider the measurement characteristics. Existing research works on three-phase power flow (PF) just consider the measurement characteristics of THM. Hence, the PF equation of the bus measured via TWM is firstly built. Based on conventional measurements, an accurate and general model of the grounded and ungrounded slack bus is proposed. Furthermore, the influence arising from the connection type and angle shift of distribution transformers on the admittance matrix is considered, and thus a general three-phase transformer model is summarized, which is applicable for all the transformers mentioned herein. Finally, Newton's method is adopted to solve the PF calculation, and the performance of the proposed PF model is demonstrated through designed tests.","2024-03","2025-02-26 20:41:53","2025-02-26 20:41:53","","571-583","","2","12","","","","","","","","","","English","","","","WOS:001194022300017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Current measurement; distribution transformer; Load modeling; Mathematical models; measurement characteristic; Medium-voltage distribution system; Phase measurement; Power measurement; slack bus modeling; three-phase power flow calculation; Transformers; Voltage measurement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SS4FCEWS","journalArticle","2024","Xi, HX; Zhang, F; Wang, YT","Transformer Machine Translation Model Incorporating Word Alignment Structure","IEEE TRANSACTIONS ON CONSUMER ELECTRONICS","","0098-3063","10.1109/TCE.2023.3332878","","In the domain of machine translation (MT) processing, end-to-end neural machine translation (NMT) has emerged as a remarkable breakthrough, surpassing the conventional statistical MT approaches. Inspired by the Internet of Things (IoT) technology, some researchers are exploring how to integrate device-to-device communication patterns into NMT to enhance translation efficiency. However, the current state-of-the-art NMT models predominantly adopt sequence-based representations for both the source language and target language sentences. The lack of natural language sentence structure attributes leads to problems such as unfaithful translation in NMT. To enhance lexical alignment in NMT, the paper proposes a new transformer MT model that incorporates vocabulary alignment structure. The model receives external lexical alignment information during each step of the decoding process in the decoder design to alleviate the problem of missing lexical alignment structures. During the decoding phase of the model, the statistical MT system plays a crucial role by supplying relevant lexical alignment information derived from the decoding information obtained from the NMT. Additionally, the model suggests vocabulary recommendations based on this lexical alignment information. The experimental results provide evidence that this approach successfully integrates the vocabulary knowledge derived from statistical MT, leading to improved translation performance.","2024-02","2025-02-26 20:41:53","2025-02-26 20:41:53","","1010-1019","","1","70","","","","","","","","","","English","","","","WOS:001245859600315","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Acute respiratory distress syndrome; BLOCKCHAIN; Convolution; Decoding; Feeds; Statistical machine translation; Training; transformer model; Transformers; Vocabulary; vocabulary alignment; word alignment structure","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TV7RMQWM","journalArticle","2024","Kim, S; Lim, J; Jang, J","Patient-Adaptive Beat-Wise Temporal Transformer for Atrial Fibrillation Classification in Continuous Long-Term Cardiac Monitoring","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3498043","","Atrial fibrillation (AF) is a prevalent cardiac arrhythmia that requires accurate diagnosis and management, especially in long-term cardiac monitoring (LTCM) scenarios. Although ECG signal morphology can vary between patients and over time, traditional deep learning models often focus on generalized classification, potentially overlooking patient-specific differences. In this study, we developed a patient-adaptive beat-wise temporal transformer model aimed at enhancing AF classification performance using data from LTCM devices. The model introduces a symbolic token representing the ideal ECG morphology of a patient, enabling the transformer to effectively reference patient-specific information and capture temporal variations in ECG morphology. To evaluate the model's classification performance, we trained it on public databases and tested it on patch datasets. The model achieved an accuracy of 0.987, precision of 0.965, sensitivity of 0.979, specificity of 0.99, and an F1 score of 0.982 on the Patch A dataset. On the Patch B dataset, it attained an accuracy of 0.953, precision of 0.91, sensitivity of 0.971, specificity of 0.942, and an F1 score of 0.951. We anticipate that the proposed approach will be particularly beneficial for monitoring AF in real-world clinical settings, especially in LTCM scenarios.","2024","2025-02-26 20:41:53","2025-02-26 20:41:53","","172358-172367","","","12","","","","","","","","","","English","","","","WOS:001362119600024","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Atrial fibrillation; beat-wise; deep learning; electrocardiogram; long-term cardiac monitoring; mixture of experts; MODELS; patient-adaptive; patient-specific; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GPAAXWDJ","journalArticle","2024","Kim, S; Yoon, J","VAIV bio-discovery service using transformer model and retrieval augmented generation","BMC BIOINFORMATICS","","1471-2105","10.1186/s12859-024-05903-6","","Background: There has been a considerable advancement in AI technologies like LLM and machine learning to support biomedical knowledge discovery. Main body: We propose a novel biomedical neural search service called 'VAIV Bio-Discovery', which supports enhanced knowledge discovery and document search on unstructured text such as PubMed. It mainly handles with information related to chemical compound/drugs, gene/proteins, diseases, and their interactions (chemical compounds/drugs-proteins/gene including drugs-targets, drug-drug, and drug-disease). To provide comprehensive knowledge, the system offers four search options: basic search, entity and interaction search, and natural language search. We employ T5slim_dec, which adapts the autoregressive generation task of the T5 (text-to-text transfer transformer) to the interaction extraction task by removing the self-attention layer in the decoder block. It also assists in interpreting research findings by summarizing the retrieved search results for a given natural language query with Retrieval Augmented Generation (RAG). The search engine is built with a hybrid method that combines neural search with the probabilistic search, BM25. Conclusion: As a result, our system can better understand the context, semantics and relationships between terms within the document, enhancing search accuracy. This research contributes to the rapidly evolving biomedical field by introducing a new service to access and discover relevant knowledge.","2024-08-21","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","1","25","","","","","","","","","","English","","","","WOS:001295910600002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Biomedical interaction extraction; Embedding; LLM; Natural language processing; Neural search; RAG; T5; Text mining; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QYWQDNNW","journalArticle","2024","Han, B; Li, YH; Shen, YX; Ren, Y; Han, FL","Dance2MIDI: Dance-driven multi-instrument music generation","COMPUTATIONAL VISUAL MEDIA","","2096-0433","10.1007/s41095-024-0417-1","","Dance-driven music generation aims to generate musical pieces conditioned on dance videos. Previous works focus on monophonic or raw audio generation, while the multi-instrument scenario is under-explored. The challenges associated with dance-driven multi-instrument music (MIDI) generation are twofold: (i) lack of a publicly available multi-instrument MIDI and video paired dataset and (ii) the weak correlation between music and video. To tackle these challenges, we have built the first multi-instrument MIDI and dance paired dataset (D2MIDI). Based on this dataset, we introduce a multi-instrument MIDI generation framework (Dance2MIDI) conditioned on dance video. Firstly, to capture the relationship between dance and music, we employ a graph convolutional network to encode the dance motion. This allows us to extract features related to dance movement and dance style. Secondly, to generate a harmonious rhythm, we utilize a transformer model to decode the drum track sequence, leveraging a cross-attention mechanism. Thirdly, we model the task of generating the remaining tracks based on the drum track as a sequence understanding and completion task. A BERT-like model is employed to comprehend the context of the entire music piece through self-supervised learning. We evaluate the music generated by our framework trained on the D2MIDI dataset and demonstrate that our method achieves state-of-the-art performance.","2024-08","2025-02-26 20:41:53","2025-02-26 20:41:53","","791-802","","4","10","","","","","","","","","","English","","","","WOS:001281651500003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","cross-modal learning; music generation; self-supervision; symbolic music; video understanding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JFTDTQBW","journalArticle","2024","Young, A; Röst, H; Wang, B","Tandem mass spectrum prediction for small molecules using graph transformers","NATURE MACHINE INTELLIGENCE","","2522-5839","10.1038/s42256-024-00816-8","","Tandem mass spectra capture fragmentation patterns that provide key structural information about molecules. Although mass spectrometry is applied in many areas, the vast majority of small molecules lack experimental reference spectra. For over 70 years, spectrum prediction has remained a key challenge in the field. Existing deep learning methods do not leverage global structure in the molecule, potentially resulting in difficulties when generalizing to new data. In this work we propose the MassFormer model for accurately predicting tandem mass spectra. MassFormer uses a graph transformer architecture to model long-distance relationships between atoms in the molecule. The transformer module is initialized with parameters obtained through a chemical pretraining task, then fine-tuned on spectral data. MassFormer outperforms competing approaches for spectrum prediction on multiple datasets and accurately models the effects of collision energy. Gradient-based attribution methods reveal that MassFormer can identify compositional relationships between peaks in the spectrum. When applied to spectrum identification problems, MassFormer generally surpasses the performance of existing prediction-based methods. Identifying compounds in tandem mass spectrometry requires extensive databases of known compounds or computational methods to simulate spectra for samples not found in databases. Simulating tandem mass spectra is still challenging, and long-range connections in particular are difficult to model for graph neural networks. Young and colleagues use a graph transformer model to learn patterns of long-distance relations between atoms and molecules.","2024-04","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","4","6","","","","","","","","","","English","","","","WOS:001197347300003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;95</p>","","","DATABASE; LIBRARIES; RESOURCE; SPECTROMETRY DATA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AFSSINE8","journalArticle","2024","Barrere, K; Soullard, Y; Lemaitre, A; Coueasnon, B","Training transformer architectures on few annotated data: an application to historical handwritten text recognition","INTERNATIONAL JOURNAL ON DOCUMENT ANALYSIS AND RECOGNITION","","1433-2833","10.1007/s10032-023-00459-2","","Transformer-based architectures show excellent results on the task of handwritten text recognition, becoming the standard architecture for modern datasets. However, they require a significant amount of annotated data to achieve competitive results. They typically rely on synthetic data to solve this problem. Historical handwritten text recognition represents a challenging task due to degradations, specific handwritings for which few examples are available and ancient languages that vary over time. These limitations also make it difficult to generate realistic synthetic data. Given sufficient and appropriate data, Transformer-based architectures could alleviate these concerns, thanks to their ability to have a global view of textual images and their language modeling capabilities. In this paper, we propose the use of a lightweight Transformer model to tackle the task of historical handwritten text recognition. To train the architecture, we introduce realistic looking synthetic data reproducing the style of historical handwritings. We present a specific strategy, both for training and prediction, to deal with historical documents, where only a limited amount of training data are available. We evaluate our approach on the ICFHR 2018 READ dataset which is dedicated to handwriting recognition in specific historical documents. The results show that our Transformer-based approach is able to outperform existing methods.","2024-12","2025-02-26 20:41:53","2025-02-26 20:41:53","","553-566","","4","27","","","","","","","","","","English","","","","WOS:001148682600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","Few annotated data; Handwritten text recognition; Historical documents; Lightweight architecture; Neural networks; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CMAFEWJB","journalArticle","2022","Mazayev, A; Al-Tam, F; Correia, N","Attention-based model and deep reinforcement learning for distribution of event processing tasks","INTERNET OF THINGS","","2543-1536","10.1016/j.iot.2022.100563","","Event processing is the cornerstone of the dynamic and responsive Internet of Things (IoT). Recent approaches in this area are based on representational state transfer (REST) principles, which allow event processing tasks to be placed at any device that follows the same principles. However, the tasks should be properly distributed among edge devices to ensure fair resources utilization and guarantee seamless execution. This article investigates the use of deep learning to fairly distribute the tasks. An attention-based neural network model is proposed to generate efficient load balancing solutions under different scenarios. The proposed model is based on the Transformer and Pointer Network architectures, and is trained by an advantage actorcritic reinforcement learning algorithm. The model is designed to scale to the number of event processing tasks and the number of edge devices, with no need for hyperparameters re-tuning or even retraining. Extensive experimental results show that the proposed model outperforms conventional heuristics in many key performance indicators. The generic design and the obtained results show that the proposed model can potentially be applied to several other load balancing problem variations, which makes the proposal an attractive option to be used in real-world scenarios due to its scalability and efficiency.","2022-08","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","19","","","","","","","","","","English","","","","WOS:000821656600004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","Actor critic; application programming interface (APIs); Deep reinforcement leaning; Edge computing; GO; Load balancing; MOBILE EDGE; Pointer networks; Representational state transfer (REST); Resource placement; Transformer model; Web of Things (WoT)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WHH6Z89L","journalArticle","2022","Sharma, H; Jalal, AS","A framework for visual question answering with the integration of scene-text using PHOCs and fisher vectors","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2021.116159","","Text contained in an image gives useful information about that image. Consider a warning signboard with text ""high voltage""; it indicates the hazard or risk involved in the image. Thus, this semantic textual information can be very useful for better understanding of images, which is not utilized by the existing visual question answering (VQA) models. However, the presence of this textual information in images can strongly guide the VQA task. This work deal with the task of visual question answering by exploiting these textual cues together with the visual content to boost the accuracy of VQA models. In the work, a novel VQA model is proposed based on the PHOC and fisher vector based representation. Based on the PHOCs of the scene-text, we have constructed a powerful descriptor by using a Fisher Vectors. Also, the proposed model uses transformer model together with dynamic pointer networks for answer decoding process. Thus, the proposed model uses a sequence of decoding steps for answer generation instead of just assuming answer prediction as a classification problem as considered by previous works. We have shown the qualitative and quantitative results on three popular datasets: VQA 2.0, TextVQA and ST-VQA. The results show the effectiveness of the proposed model over the existing models.","2022-03-15","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","190","","","","","","","","","","English","","","","WOS:000720621200003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","ATTENTION; Computer vision; Dynamic pointer networks; Fisher vector; PHOC; RECOGNITION; Visual Question Answering (VQA)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q4VTQWEA","journalArticle","2025","Liang, YG; Fan, GS; Yu, HQ; Li, MC; Huang, ZJ","Automatic Code Summarization Using Abbreviation Expansion and Subword Segmentation","EXPERT SYSTEMS","","0266-4720","10.1111/exsy.13835","","Automatic code summarization refers to generating concise natural language descriptions for code snippets. It is vital for improving the efficiency of program understanding among software developers and maintainers. Despite the impressive strides made by deep learning-based methods, limitations still exist in their ability to understand and model semantic information due to the unique nature of programming languages. We propose two methods to boost code summarization models: context-based abbreviation expansion and unigram language model-based subword segmentation. We use heuristics to expand abbreviations within identifiers, reducing semantic ambiguity and improving the language alignment of code summarization models. Furthermore, we leverage subword segmentation to tokenize code into finer subword sequences, providing more semantic information during training and inference, thereby enhancing program understanding. These methods are model-agnostic and can be readily integrated into existing automatic code summarization approaches. Experiments conducted on two widely used Java code summarization datasets demonstrated the effectiveness of our approach. Specifically, by fusing original and modified code representations into the Transformer model, our Semantic Enhanced Transformer for Code Summarizsation (SETCS) serves as a robust semantic-level baseline. By simply modifying the datasets, our methods achieved performance improvements of up to 7.3%, 10.0%, 6.7%, and 3.2% for representative code summarization models in terms of BLEU-4, METEOR, ROUGE-L and SIDE, respectively.","2025-02","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","2","42","","","","","","","","","","English","","","","WOS:001391553300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","automatic code summarization; code abbreviation expansion; deep learning; program understanding; subword segmentation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MV8BVECU","journalArticle","2024","Gautam, Y; Jebelli, H","Design of flexible polyimide-based serpentine EMG sensor for AI-enabled fatigue detection in construction","SENSING AND BIO-SENSING RESEARCH","","2214-1804","10.1016/j.sbsr.2024.100713","","Physical fatigue and musculoskeletal disorders are critical health issues for construction workers, stemming from repetitive motions, heavy lifting, and awkward postures. These factors compromise worker well-being, productivity, and safety while increasing the risk of accidents and long-term health problems. Recent advancements in wearable health monitoring technology offer potential solutions, but current sensors encounter significant challenges in the dynamic construction environment. These include inadequate skin contact, increased contact impedance, and vulnerability to motion artifacts all of which degrade signal quality and reduce the accuracy of fatigue detection. This paper develops a fractal-based, flexible sensor for enhanced adaptability and accurate fatigue estimation. Finite element analysis compared five space-filling designs, with the serpentine curve exhibiting the highest contact area and lowest strain, making it the preferred choice for fabrication. Evaluations demonstrated significant improvements in signal-to-noise ratio (SNR) and motion artifact reduction, with the newly developed sensor achieving a 37 % to 59 % SNR improvement over commercial electrodes across different muscle groups. The developed flexible sensor was integrated with a fatigue-detecting framework based on a vision transformer model which provided an average accuracy of 87 % for fatigue detection. The developed sensor significantly enhances EMG signal quality and reliability, promising improved health monitoring and safety for construction workers.","2024-12","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","46","","","","","","","","","","English","","","","WOS:001357220100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Electromyography (EMG); Fatigue detection; Flexible sensor; Motion artifact; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DG94UDSA","journalArticle","2024","Afifi, S; Thakkar, I; Pasricha, S","ARTEMIS: A Mixed Analog-Stochastic In-DRAM Accelerator for Transformer Neural Networks","IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS","","0278-0070","10.1109/TCAD.2024.3446719","","Transformers have emerged as a powerful tool for natural language processing (NLP) and computer vision. Through the attention mechanism, these models have exhibited remarkable performance gains when compared to conventional approaches like recurrent neural networks (RNNs) and convolutional neural networks (CNNs). Nevertheless, transformers typically demand substantial execution time due to their extensive computations and large memory footprint. Processing in-memory (PIM) and near-memory computing (NMC) are promising solutions to accelerating transformers as they offer high-compute parallelism and memory bandwidth. However, designing PIM/NMC architectures to support the complex operations and massive amounts of data that need to be moved between layers in transformer neural networks remains a challenge. We propose ARTEMIS, a mixed analog-stochastic in-DRAM accelerator for transformer models. Through employing minimal changes to the conventional DRAM arrays, ARTEMIS efficiently alleviates the costs associated with transformer model execution by supporting stochastic computing for multiplications and temporal analog accumulations using a novel in-DRAM metal-on-metal capacitor. Our analysis indicates that ARTEMIS exhibits at least 3.0x speedup, and 1.8x lower energy compared to GPU, TPU, CPU, and state-of-the-art PIM transformer hardware accelerators.","2024-11","2025-02-26 20:41:53","2025-02-26 20:41:53","","3336-3347","","11","43","","","","","","","","","","English","","","","WOS:001350762100047","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Central Processing Unit; Computational modeling; Computer architecture; Graphics processing units; Hardware acceleration; In-DRAM processing; Natural language processing; processing in memory; Random access memory; Recurrent neural networks; stochastic computing (SC); Stochastic processes; transformers; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YBL4TXH5","journalArticle","2024","Xiao, YA; Luo, X; Wang, TF; Zhang, ZJ","Spatio-Temporal Transformer Networks for Inland Ship Trajectory Prediction with Practical Deficient Automatic Identification System Data","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app142210494","","Inland waterways, characterized by their complex, narrow paths, see significantly higher traffic volumes compared to maritime routes, increasing the regulatory demands on traffic management. Predictive modeling of ship traffic flows, utilizing real AIS historical data, enhances route and docking planning for ships and port managers. This approach boosts transportation efficiency and safety in inland waterway navigation. Nevertheless, AIS data are flawed, marred by noise, disjointed paths, anomalies, and inconsistent timing between points. This study introduces a data processing technique to refine AIS data, encompassing segmentation, outlier elimination, missing point interpolation, and uniform interval resampling, aiming to enhance trajectory analysis reliability. Utilizing this refined data processing approach on ship trajectory data yields independent, complete motion profiles with uniform timing. Leveraging the Transformer model, denoted TRFM, this research integrates processed AIS data from the Yangtze River to create a predictive dataset, validating the efficacy of our prediction methodology. A comparative analysis with advanced models such as LSTM and its variants demonstrates TRFM's superior accuracy, showcasing lower errors in multiple metrics. TRFM's alignment with actual trajectories underscores its potential for enhancing navigational planning. This validation not only underscores the method's precision in forecasting ship movements but also its utility in risk management and decision-making, contributing significantly to the advancement in maritime traffic safety and efficiency.","2024-11","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","22","14","","","","","","","","","","English","","","","WOS:001366723600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","big data; maritime management; traffic flow prediction; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZEM5RLCP","journalArticle","2024","Cao, ZS; Ma, C; Tang, WQ; Zhou, YX; Zhong, HT; Ye, S; Wu, KY; Chen, XD; Zheng, DY; Hou, L; Zhang, Y; Hou, MC","CoreViT: A new vision transformer model for lithofacies identification in cores","GEOENERGY SCIENCE AND ENGINEERING","","2949-8929","10.1016/j.geoen.2024.213012","","Lithofacies identification is crucial in fields such as geology, geotechnical engineering, rock mechanics, and petroleum engineering, as it reveals the physical, chemical, and mineralogical characteristics of rocks that aid in identifying oil and gas reservoir types, volumes, and productivity. Traditional methods of identifying rock types, such as manual sample identification, micrograph identification, and experimental identification, are costly and time-consuming. Several studies have endeavored to enhance the degree of lithofacies identification automation using machine learning (ML) and deep learning (DL) techniques. However, their capacity to recognize intricate data remains restricted. To overcome this challenge, we introduce CoreViT, a modified architecture of the advanced vision transformer (ViT) that includes the parallel transformer encoder (PTE) for exchanging information among image patches, and the class encoder (CE) for improved automatic lithofacies identification. Our study, focusing on core images including algal limestone, mudstone, and non-algal limestone from the Fengxi Well 1 in the Qaidam Basin, demonstrates CoreViT 's average recognition accuracy at approximately 97.5% with an average loss of 0.071. Compared with other classical convolutional neural network (CNN) models, CoreViT achieves relatively high accuracy and low loss. This study highlights the superiority of the ViT model over traditional deep convolutional neural networks (DCNNs) and suggests the great potentiality of applying the ViT model in lithofacies identification in core samples.","2024-09","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","240","","","","","","","","","","English","","","","WOS:001265473200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","AUTOMATED INFORMATION EXTRACTION; BASIN; Core images; Core vision transformer; Deep learning; INSIGHTS; Lithofacies identification; RESERVOIRS; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G5BEV5X2","journalArticle","2024","Yoon, B; Lee, A; Kim, J; Moon, GE","Exploring Attention Sparsity to Accelerate Transformer Training on GPUs","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3425638","","The computational complexity required for training a Transformer model quadratically increases as the length of the input sequence increases. Therefore, to accelerate the training of a large-scale Transformer with long sequences, it is crucial to reduce the number of operations for the multi-head attention computations, which dominate the overall Transformer training process. Previous approaches have sought to sparsify the multi-head attention before training by statically selecting the critical elements in the attention score matrix. However, since the critical elements in the attention score matrix can vary across different model tasks and datasets, dynamically considering the critical elements is essential for achieving better model quality. In this paper, we propose a new sparsity-aware Transformer that captures task- and input-dependent sparsity pattern in the attention score matrix during a small number of steps of the standard training of the Transformer. Then the identified sparsity pattern is utilized in the sparse training, transferred from the standard training, based on the degree of skewness and distance values of the attention score matrices. Experimental results demonstrate that our approach significantly reduces the number of operations in the multi-head attention operations, achieving up to 2.84x training speedup, 6.87x memory reduction and better accuracy compared to state-of-the-art sparse Transformer models.","2024","2025-02-26 20:41:53","2025-02-26 20:41:53","","131373-131384","","","12","","","","","","","","","","English","","","","WOS:001320469800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","Computational complexity; Computational modeling; Graphics processing units; MHA optimization; sparse attention; Sparse matrices; Sparse Transformer; Task analysis; Text categorization; Training; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VBSKT4WM","journalArticle","2023","Abdelhay, M; Mohammed, A; Hefny, HA","Deep learning for Arabic healthcare: MedicalBot","SOCIAL NETWORK ANALYSIS AND MINING","","1869-5450","10.1007/s13278-023-01077-w","","Since the COVID-19 pandemic, healthcare services, particularly remote and automated healthcare consultations, have gained increased attention. Medical bots, which provide medical advice and support, are becoming increasingly popular. They offer numerous benefits, including 24/7 access to medical counseling, reduced appointment wait times by providing quick answers to common questions or concerns, and cost savings associated with fewer visits or tests required for diagnosis and treatment plans. The success of medical bots depends on the quality of their learning, which in turn depends on the appropriate corpus within the domain of interest. Arabic is one of the most commonly used languages for sharing users' internet content. However, implementing medical bots in Arabic faces several challenges, including the language's morphological composition, the diversity of dialects, and the need for an appropriate and large enough corpus in the medical domain. To address this gap, this paper introduces the largest Arabic Healthcare Q &A dataset, called MAQA, consisting of over 430,000 questions distributed across 20 medical specializations. Furthermore, this paper adopts three deep learning models, namely LSTM, Bi-LSTM, and Transformers, for experimenting and benchmarking the proposed corpus MAQA. The experimental results demonstrate that the recent Transformer model outperforms the traditional deep learning models, achieving an average cosine similarity of 80.81% and a BLeU score of 58%.","2023-04-18","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","1","13","","","","","","","","","","English","","","","WOS:000974791000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Deep learning; LSTM and attention; NLP; Q&A Arabic corpus; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M532B6AE","journalArticle","2023","Zhang, FJ; Liu, J; Wan, Y; Yu, X; Liu, X; Keung, J","Diverse title generation for Stack Overflow posts with multiple-sampling-enhanced transforme","JOURNAL OF SYSTEMS AND SOFTWARE","","0164-1212","10.1016/j.jss.2023.111672","","Stack Overflow is one of the most popular programming communities where developers can seek help for their encountered problems. Nevertheless, if inexperienced developers fail to describe their problems clearly, it is hard for them to attract sufficient attention and get the anticipated answers. To address such a problem, we propose M3NSCT5, a novel approach to automatically generate multiple post titles from the given code snippets. Developers may take advantage of the generated titles to find closely related posts and complete their problem descriptions. M3NSCT5 employs the CodeT5 backbone, which is a pre-trained Transformer model with an excellent language understanding and generation ability. To alleviate the ambiguity issue that the same code snippets could be aligned with different titles under varying contexts, we propose the maximal marginal multiple nucleus sampling strategy to generate multiple high-quality and diverse title candidates at a time for the developers to choose from. We build a large-scale dataset with 890,000 question posts covering eight programming languages to validate the effectiveness of M3NSCT5. The automatic evaluation results on the BLEU and ROUGE metrics demonstrate the superiority of M3NSCT5 over six state-of-the-art baseline models. Moreover, a human evaluation with trustworthy results also demonstrates the great potential of our approach for real-world applications.(c) 2023 Elsevier Inc. All rights reserved.","2023-06","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","200","","","","","","","","","","English","","","","WOS:000955932600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;89</p>","","","CodeT5; Maximal marginal ranking; Nucleus sampling; Stack Overflow; TAG RECOMMENDATION; Title generation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3G43456S","journalArticle","2023","Sun, BW; Wang, XF; Oad, A; Pervez, A; Dong, F","Automatic Ship Object Detection Model Based on YOLOv4 with Transformer Mechanism in Remote Sensing Images","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13042488","","Despite significant advancements in object detection technology, most existing detection networks fail to investigate global aspects while extracting features from the inputs and cannot automatically adjust based on the characteristics of the inputs. The present study addresses this problem by proposing a detection network consisting of three stages: preattention, attention, and prediction. In the preattention stage, the network framework is automatically selected based on the features of the images' objects. In the attention stage, the transformer structure is introduced. Taking into account the global features of the target, this study combines a self-attention module in the transformer model and convolution operation to integrate image features from global to local and for detection, thus improving the ship target accuracy. This model uses mathematical methods to obtain results of predictive testing in the prediction stage. The above improvements are based on the You Only Look Once version 4 (YOLOv4) framework, named ""Auto-T-YOLO"". The model achieves the highest accuracy of 96.3% on the SAR Ship Detection dataset (SSDD) compared to the other state-of-the-art (SOTA) model. It achieves 98.33% and 91.78% accuracy in the offshore and inshore scenes, respectively. The experimental results verify the practicality, validity, and robustness of the proposed model.","2023-02","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","4","13","","","","","","","","","","English","","","","WOS:000938191700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","automatic detection; computer vision; detection network; domain adaptation; NETWORK; object detection; transformer structure","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IUMLU28Q","journalArticle","2021","Mojumdar, MRR; Cano, JM; Orcajo, GA","Estimation of Impedance Ratio Parameters for Consistent Modeling of Tap-Changing Transformers","IEEE TRANSACTIONS ON POWER SYSTEMS","","0885-8950","10.1109/TPWRS.2021.3050958","","Recent contributions have shown that two widely used formulations of the tap-changing transformer model are controversial, as they generate dissimilar results depending on the selected tap and operating point. In recent works, the authors proposed a new model and demonstrated its consistency to reconcile this debate. It introduces a parameter which stands for the ratio between the impedances of the nominal and tapped winding of the transformer. However, this parameter is not provided with and cannot be obtained from standard datasheets, which compels the users to rely on rough approximations. To overcome this problem, an offline state-vector-augmented parameter estimation method capable of providing accurate estimates of transformer impedance ratios is proposed in this work. It is demonstrated that their use can effectively lead state estimators to better estimates of system states. This work also contributes with the derivatives of the different measurement functions in terms of the impedance ratios, which are essential for this or any other linearized state estimator. A multi-snapshot implementation is used to obtain a twofold advantage - increased measurement redundancy and improved accuracy of the estimated parameters. A detailed formulation of the implementation and several case studies are presented to demonstrate the validity of the proposal.","2021-07","2025-02-26 20:41:53","2025-02-26 20:41:53","","3282-3292","","4","36","","","","","","","","","","English","","","","WOS:000664032400043","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","Estimation; Impedance; Impedance measurement; Maximum likelihood estimation; parameter estimation; Parameter estimation; Power systems; power transformers; Power transformers; Proposals; STATE ESTIMATION; tap changers; transformer models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3F8AV7JZ","journalArticle","2023","Chai, L; Chen, H; Du, J; Liu, QF; Lee, CH","Space-and-speaker-aware acoustic modeling with effective data augmentation for recognition of multi-array conversational speech","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2023.102958","","We propose a space-and-speaker-aware (SSA) approach to acoustic modeling (AM), denoted as SSA-AM, to improve system performances of automatic speech recognition (ASR) in distant multi-array conversational scenarios. In contrast to conventional AM which only uses spectral features from a target speaker as inputs, the inputs to SSA-AM consists of speech features from both the target and interfering speakers, which contain discriminative information from different speakers, including spatial information embedded in interaural phase differences (IPDs) between individual interfering speakers and the target speaker. In the proposed SSA-AM framework, we explore four acoustic model architectures consisting of different combinations of four neural networks, namely deep residual network, factorized time delay neural network, self-attention and residual bidirectional long short-term memory neural network. Various data augmentation techniques are adopted to expand the training data to include different options of beamformed speech obtained from multi-channel speech enhancement. Evaluated on the recent CHiME-6 Challenge Track 1, our proposed SSA-AM framework achieves consistent recognition performance improvements when compared with the official baseline acoustic models. Furthermore, SSA-AM outperforms acoustic models without explicitly using the space and speaker information. Finally, our data augmentation schemes are shown to be especially effective for compact model designs. Code is released at https://github.com/coalboss/SSA_AM.","2023-09","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","153","","","","","","","","","","English","","","","WOS:001051080500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;77</p>","","","Acoustic model architectures; BLIND SOURCE SEPARATION; CHiME-6 challenge; Conversational speech recognition; CONVOLUTIONAL NEURAL-NETWORKS; Data augmentation; DOMAIN; SSA-AM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"89EVJEHY","journalArticle","2025","Zhao, SY; Zhang, JZ; Jiang, YH; He, CK; Han, JH","Tire-Road friction coefficients adaptive estimation through image and vehicle dynamics integration","MECHANICAL SYSTEMS AND SIGNAL PROCESSING","","0888-3270","10.1016/j.ymssp.2024.112039","","Current methods for identifying tire-road friction coefficient (TRFC) often struggle with accuracy and multiple interference issues. Addressing this, this paper proposes a novel TRFC estimation method that adapts to complex road conditions and performs self-diagnosis by the fusion of image and vehicle dynamics information. First, we compiled a comprehensive database comprising numerous images of extreme road surfaces along with corresponding vehicle dynamics data. A multi-temporal image fusion method was then developed. This method enables the segmentation and integration of road surface images for both the left and right-side wheels by tracking historical data, which ensures that each image is enriched with adequate road surface details. Subsequently, the road surface condition for each side is identified using a pre-trained transformer model. Following the image analysis, the TRFC is estimated in real-time using a residual adaptive unscented Kalman filter (UKF). High-confidence image estimation results serve as key adjusters for the UKF, enhancing estimation accuracy. The real vehicle test results demonstrate that our method accurately identifies the TRFC with enhanced robustness. Additionally, these tests confirmed the adaptive estimation method's ability to detect faults and adjust steady-state values amidst model distortion, effectively maintaining accuracy despite image estimation declines caused by environmental interferences.","2025-01-01","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","224","","","","","","","","","","English","","","","WOS:001336123600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Adaptive estimation; Multi-temporal image fusion; Real-vehicle verification; Residual adaptive UKF; Tire-road friction coefficients","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y3QP6RPA","journalArticle","2024","Raghuvamsi, Y; Teeparthi, K","Distribution system state estimation with Transformer-Bi-LSTM-based imputation model for missing measurements","NEURAL COMPUTING & APPLICATIONS","","0941-0643","10.1007/s00521-023-09097-5","","The solution of the distribution system state estimation (DSSE) relies on the presence of physical measurements in real time. Sometimes, these measurements may not reach the control center due to the defects in meter functionality, the large communication time delays, and denial-of-service (DoS) attacks on communication channels. Addressing this issue, a novel deep learning (DL) approach is proposed by using a transformer model with the integration of bi-directional long short-term memory (Bi-LSTM) layer. The proposed model can be leveraged to forecast the unavailable measurement data, which maintains the observability of the system to obtain an accurate solution from DSSE. The superiority of the proposed model is probed by comparing it with other forecasting-based DL models at various percentages of missing measurement data. Further, the effectiveness of the proposed model is evaluated for forecasting the power injections of residential, commercial, and industrial loads as well as renewable energy sources. Finally, the solution of the DSSE is tested with forecasted data and compared with the results of the DSSE for the original measurement data. The simulations are performed on modified IEEE 13-node and IEEE 37-node test systems, and their corresponding results highlighted the superiority of the proposed model in the forecasting of the incomplete data.","2024-01","2025-02-26 20:41:53","2025-02-26 20:41:53","","1295-1312","","3","36","","","","","","","","","","English","","","","WOS:001090756900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","ALGORITHM; Bi-directional LSTM; Distribution system state estimation; Huber-loss function; Missing data; Smart meters; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"43AL6NXK","journalArticle","2024","Yang, M; Kim, S; Sun, X; Kim, S; Choi, J; Park, TS; Choi, JI","Deep-learning-based reduced-order modeling to optimize recuperative burner operating conditions","APPLIED THERMAL ENGINEERING","","1359-4311","10.1016/j.applthermaleng.2023.121669","","This study analyzed a recuperative burner system that is critical for energy efficiency and pollutant reduction in the firing processes required in the manufacturing industries. We aimed to optimize the operating conditions of a recuperative burner using computational fluid dynamics (CFD) combined with a novel reduced-order deep learning technique. The Reynolds-averaged Navier-Stokes model and finite-rate/eddy-dissipation models were used to generate reliable CFD simulation results considering four operating conditions (temperature and mass flow rate of air and fuel). We first validated the CFD model with two-dimensional axis-symmetric experimental burner results and created a proper orthogonal decomposition transformer model using large-scale snapshots of the CFD results and various operating conditions. Subsequently, a genetic algorithm was employed to find the optimal conditions for five different objective functions: fuel economy, decrease in carbon monoxide emissions, reduction in nitrogen oxide emissions, decrease in carbon dioxide production, and an all-encompassing view of the four objectives. Finally, by comparing our proposed approach with previous methods, we confirmed that the obtained optimal operating conditions improve the performance of the recuperative burner. This study provides an optimized framework for recuperative burners to reduce environmental pollution, with potential applications in many industries, such as ceramics, steel, and batteries.","2024-01-05","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","236","","","","","","","","","","English","","","","WOS:001088472600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","CHAMBER; COMBUSTION; Computational fluid dynamics; Genetic algorithm; NATURAL-GAS; Proper orthogonal decomposition; Recuperative burner; Reduced-order model; Transformer neural network; TURBULENT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YBT48VUT","journalArticle","2025","Balendra; Negi, PCBS; Sharma, N; Sharma, S","Scalogram sets based motor imagery EEG classification using modified vision transformer: A comparative study on scalogram sets","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2025.107640","","Nowadays, motor imagery (MI) electroencephalogram (EEG) is mainly utilized for brain computer interface (BCI) based prosthetic device developments and involves the accurate classification of EEG signals. However, the major challenges are inter-subject and intra-subject variability, presence of noise and artifacts in the acquired EEG signal, this results in low average classification accuracy. To address these issues, the present work proposes an innovative algorithm based on scalogram set formation and modified vision transformer (MViT) model for classification of EEG data. The proposed scalogram sets formed by organizing scalograms of fundamental wavelets as well as their combinations and the proposed Modified Vision Transformer model employs both serial and parallel feeding of initial patches through consecutive transformer blocks, enhancing information flow and extracting diverse features. To verify and validate the proposed methodology, the BCI Competition IV 2b dataset was utilized. The MViT with Morlet and Shannon scalogram set performed accuracies of 86.34 % for intra-subject and 76.19 % for inter-subject classification. The proposed approach performed best among state-of-the-art methods with an average improvement of 3.46 % for intra-subject and 1.75 % for inter-subject in accuracy highlighting the robustness and reliability of the proposed methodology.","2025-06","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","104","","","","","","","","","","English","","","","WOS:001420512300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","BRAIN-COMPUTER INTERFACES; Electroencephalogram (EEG); Motor Imagery; Scalogram; Vision Transformer; Wavelet Transform; WAVELET TRANSFORM; Wavelets","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TAYUPNMT","journalArticle","2025","Shou, QY; Zhao, CY; Shao, XF; Herting, MM; Wang, DJ","High resolution multi-delay arterial spin labeling with self-supervised deep learning denoising for pediatric choroid plexus perfusion MRI","NEUROIMAGE","","1053-8119","10.1016/j.neuroimage.2025.121070","","Choroid plexus (CP) is an important brain structure that produces cerebrospinal fluid (CSF). CP perfusion has been studied using multi-delay arterial spin labeling (MD-ASL) in adults but not in pediatric populations due to the challenge of small CP size in children. Here we present a high resolution (iso2 mm) MDASL protocol with 10minute scan time and performed test-retest scans on 21 typically developing children aged 8 to 17 years. We further proposed a Transformer-based deep learning (DL) model with k-space weighted image average (KWIA) denoised images as reference for training the model. The performance of the model was evaluated by the SNR, bias and repeatability of the fitted perfusion parameters of the CP and gray matter. The proposed method was compared to several benchmark methods including KWIA, joint denoising and reconstruction with total generalized variation (TGV) regularization, as well as another self-supervised method termed Noise2Void. The results show that the proposed Transformer model with KWIA reference can effectively denoise multi-delay ASL images, not only improving the SNR for perfusion images of each delay, but also improving the SNR for the fitted perfusion maps for visualizing and quantifying CP perfusion in children. This may facilitate the use of MDASL in neurodevelopmental studies to characterize the development of CP and glymphatic system.","2025-03","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","308","","","","","","","","","","English","","","","WOS:001419731800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QCK6CZ3X","journalArticle","2024","Zhou, ZH; Long, ZH; Wang, RD; Bai, ML; Liu, JF; Yu, DR","An aircraft engine remaining useful life prediction method based on predictive vector angle minimization and feature fusion gate improved transformer model","JOURNAL OF MANUFACTURING SYSTEMS","","0278-6125","10.1016/j.jmsy.2024.08.025","","Remaining useful life (RUL) prediction is crucial for achieving intelligent and predictive maintenance of aircraft engines. In practical applications, advance prediction values smaller than the true values can prevent serious deferred maintenance accidents. Using asymmetric loss functions directly leads to noticeable accuracy degradation, and existing methods often fail to satisfy accuracy and advance prediction requirements. To address this problem, this paper proposes a novel RUL prediction method based on the Prediction Vector Angle (PVA) minimization and Feature Fusion Gate (FFG) improved Transformer network. Specifically, the FFG is proposed to enhance Transformer prediction accuracy by dynamically fusing global and local features. The concept of PVA is first introduced based on the tilting properties of the RUL descent process. The target of the prediction model is cleverly transformed from error minimization to PVA minimization through the cosine similarity loss function. Various experiments on the CMAPSS dataset demonstrate the effectiveness of the proposed method in achieving high accuracy and advanced prediction. Compared to the state-of-the-art method, RMSE is reduced by at least 2.94 % and Score by 7.00 %. Finally, the PVA minimization mechanism significantly improves long short-term memory and convolutional neural network performance. The proposed method is noteworthy for its superiority and applicability.","2024-10","2025-02-26 20:41:53","2025-02-26 20:41:53","","567-584","","","76","","","","","","","","","","English","","","","WOS:001386468900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Cosine similarity; Feature fusion gate; Improved transformer; Prediction vector angle; Remaining useful life","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VQ5YPQBD","journalArticle","2024","Kongne, BBF; Mengounou, GM; Nkouetcha, ET; Imano, AM","Effect of sensor position on the measurement of acoustic wave produced by partial discharges","HELIYON","","2405-8440","10.1016/j.heliyon.2024.e25974","","This paper presents the finite element method (FEM) simulation of the propagation, measurement and evaluation of the time of arrival (TOA) of the acoustic wave created by a partial discharge (PD) in a transformer model using COMSOL multiphysics software. This model is a flat tank filled with an insulating liquid. In addition, 8 acoustic probes placed on one of the outer faces of the tank provide information on acoustic pressure levels for specific values of angles of incidence of the acoustic signal. The addition of signal transmission zones for each of the probes makes it possible to define precise paths for the acoustic signal, enabling the TOA of the acoustic wave to be evaluated for each path. The results of this study show that for angular values less than 40 degrees, the error on the TOA is practically zero, but for values greater than 40 degrees this error increases exponentially with the angle. This means that for an angle of 40.41 degrees the error is 6 mu s, corresponding to 1.7%, and for an angle of 71.70 degrees the error is 332 mu s, corresponding to 40.3%. This highlights the optimal nature of the choice of sensor position for locating partial discharge.","2024-02-29","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","4","10","","","","","","","","","","English","","","","WOS:001200529400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Acoustic wave; COMSOL multiphysics; Finite element method; LOCALIZATION; LOCATION; MODEL; Partial discharge; PD-SOURCES; Power transformer; POWER-TRANSFORMERS; PROPAGATION; SIMULATION; Time of arrival","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6D8YSCJG","journalArticle","2024","Zhao, YK; Jing, SB; Wu, HJ; Li, HH; Todoh, M","E-TRGAN: A Novel Transformer Generative Adversarial Network for High-Density Surface Electromyography Signal Reconstruction","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2024.3472778","","This study presents a novel method to tackle the difficulties in high-density surface electromyography (HD-sEMG) signal reconstruction: the electromyographic transformer generative adversarial network (E-TRGAN). Conventional techniques struggle with the intricate spatial-temporal dynamics of HD-sEMG and mostly concentrate on bipolar surface electromyography (sEMG). E-TRGAN performs exceptionally well at reconstructing HD-sEMG signals while preserving their temporal and spatial integrity by utilizing the transformer model and the structure of generative adversarial networks (GANs). We present a thorough evaluation that includes comparisons with convolutional neural network (CNN)-based methods and linear interpolation, showing that E-TRGAN performs better at recovering HD-sEMG signals in a variety of corruption conditions, such as reduced channels, random channel loss, and severe signal value loss. Metrics like mean squared error (mse), mean absolute error (MAE), root mse (RMSE), peak signal-to-noise ratio (PSNR), and structural similarity index (SSIM) show that the model regularly performs better than competing approaches. Although E-TRGAN's accuracy decreases in situations when there is simultaneous spatial and temporal signal loss, its overall efficacy represents a major breakthrough in HD-sEMG signal processing. This study highlights E-TRGAN's promise as an adaptable approach for intricate HD-sEMG signal restoration in a range of applications.","2024","2025-02-26 20:41:53","2025-02-26 20:41:53","","","","","73","","","","","","","","","","English","","","","WOS:001339149600033","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Deep learning; EMG SIGNALS; generative adversarial networks (GANs); HD-sEMG signal reconstruction; high-density surface electromyography (HD-sEMG); transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BAF4UTCH","journalArticle","2023","Chaudhary, L; Ananthanarayana, T; Hoq, E; Nwogu, I","SignNet II: A Transformer-Based Two-Way Sign Language Translation Model","IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE","","0162-8828","10.1109/TPAMI.2022.3232389","","The role of a sign interpreting agent is to bridge the communication gap between the hearing-only and Deaf or Hard of Hearing communities by translating both from sign language to text and from text to sign language. Until now, much of the AI work in automated sign language processing has focused primarily on sign language to text translation, which puts the advantage mainly on the side of hearing individuals. In this article, we describe advances in sign language processing based on transformer networks. Specifically, we introduce SignNet II, a sign language processing architecture, a promising step towards facilitating two-way sign language communication. It is comprised of sign-to-text and text-to-sign networks jointly trained using a dual learning mechanism. Furthermore, by exploiting the notion of sign similarity, a metric embedding learning process is introduced to enhance the text-to-sign translation performance. Using a bank of multi-feature transformers, we analyzed several input feature representations and discovered that keypoint-based pose features consistently performed well, irrespective of the quality of the input videos. We demonstrated that the two jointly trained networks outperformed their singly-trained counterparts, showing noteworthy enhancements in BLEU-1 - BLEU-4 scores when tested on the largest available German Sign Language (GSL) benchmark dataset.","2023-11-01","2025-02-26 20:41:53","2025-02-26 20:41:53","","12896-12907","","11","45","","","","","","","","","","English","","","","WOS:001085050900012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Assistive technologies; Decoding; dual learning; Feature extraction; Gesture recognition; metric embedded learning; Sign language translations; Three-dimensional displays; transformer model; Transformers; Videos","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YU6XD2X8","journalArticle","2023","Kumar, SAS; Rajan, R","Transformer-based Automatic Music Mood Classification Using Multi-modal Framework","JOURNAL OF COMPUTER SCIENCE & TECHNOLOGY","","1666-6046","10.24215/16666038.23.e02","","According to studies, music affects our moods, and we are also inclined to choose a theme based on our current According to studies, music affects our moods, and we are also inclined to choose a theme based on our current moods. Audio-based techniques can achieve promising results, but lyrics also give relevant information about the moods of a song which may not be present in the audio part. So a multi-modal with both textual features and acoustic features can provide enhanced accuracy. Sequential networks such as long short-term memory networks (LSTM) and gated recurrent unit networks (GRU) are widely used in the most state-of-the-art natural language processing (NLP) models. A transformer model uses self-attention to compute representations of its inputs and outputs, unlike recurrent unit networks (RNNs) that use sequences and transformers that can parallelize over input positions during training. In this work, we proposed a multi-modal music mood classification system based on transformers and compared the system's performance using a bi-directional GRU (Bi-GRU)-based system with and without attention. The performance is also analyzed for other state-of-the-art approaches. The proposed transformer-based model acquired higher accuracy than the Bi-GRU-based multimodal system with single-layer attention by providing a maximum accuracy of 77.94%.","2023-04","2025-02-26 20:41:53","2025-02-26 20:41:53","","18-34","","1","23","","","","","","","","","","English","","","","WOS:000968773800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","BERT; bidirectional GRU; music; self-attention; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TQYH7WL8","journalArticle","2024","Yoon, S; Maeng, S; Kim, R; Lee, S","Strategy for developing a speech recognition model specialized for patients with depression or Parkinson's disease with small size speech database","BIOMEDICAL ENGINEERING LETTERS","","2093-9868","10.1007/s13534-024-00389-w","","Most of speech recognition models currently in use have been dealt with speech of normal people. The speech recognition rate for patients with depression or Parkinson's disease (PD) who show differences in speech characteristics compared to normal subjects is lower than that of normal subjects. This study explores the model to enhance accuracy of speech recognition for individuals who have depression or PD, aiming to provide them more accurate service. In this study, considering the speech features of patients with depression or PD, we designed a model with the assumption that understanding the overall meaning and context of speech through the utilization of global information, rather than local information, is more effective in enhancing recognition accuracy. We propose the m-Globalformer, a model based on the Globalformer architecture that combines the squeeze-and-excitation (SE) module with the Transformer. The m-Globalformer enhances the utilization of global information by modifying the base SE module. The model employs pre-training and fine-tuning strategies, considering the limited speech data of the patients. In the initial training phase, a large-scale normal speech dataset was used, followed by fine-tuning the model with a small-scale dataset of depression or PD patients. The m-Globalformer demonstrated superior performance in our experiments, achieved character error rates (CER) of 11.28% for depression and 19.67% for PD.","2024-09","2025-02-26 20:41:53","2025-02-26 20:41:53","","1049-1055","","5","14","","","","","","","","","","English","","","","WOS:001230061600002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","Deep learning; Depression; Parkinson's disease; Speech recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PW7MSDM8","journalArticle","2024","Ma, LB; Tong, Y","TL-CStrans Net: a vision robot for table tennis player action recognition driven via CS-Transformer","FRONTIERS IN NEUROROBOTICS","","1662-5218","10.3389/fnbot.2024.1443177","","Currently, the application of robotics technology in sports training and competitions is rapidly increasing. Traditional methods mainly rely on image or video data, neglecting the effective utilization of textual information. To address this issue, we propose: TL-CStrans Net: A vision robot for table tennis player action recognition driven via CS-Transformer. This is a multimodal approach that combines CS-Transformer, CLIP, and transfer learning techniques to effectively integrate visual and textual information. Firstly, we employ the CS-Transformer model as the neural computing backbone. By utilizing the CS-Transformer, we can effectively process visual information extracted from table tennis game scenes, enabling accurate stroke recognition. Then, we introduce the CLIP model, which combines computer vision and natural language processing. CLIP allows us to jointly learn representations of images and text, thereby aligning the visual and textual modalities. Finally, to reduce training and computational requirements, we leverage pre-trained CS-Transformer and CLIP models through transfer learning, which have already acquired knowledge from relevant domains, and apply them to table tennis stroke recognition tasks. Experimental results demonstrate the outstanding performance of TL-CStrans Net in table tennis stroke recognition. Our research is of significant importance in promoting the application of multimodal robotics technology in the field of sports and bridging the gap between neural computing, computer vision, and neuroscience.","2024-10-21","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","18","","","","","","","","","","English","","","","WOS:001346653200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","computer vision; multi-modal robot; neural computing; neuroscience; table tennis stroke recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XS3IGCMC","journalArticle","2024","Zhang, B; Wu, Q; Wu, F; Huang, JJ; Wang, C","A Lightweight Pyramid Transformer for High-Resolution SAR Image-Based Building Classification in Port Regions","REMOTE SENSING","","2072-4292","10.3390/rs16173218","","Automatic classification of buildings within port areas from synthetic aperture radar (SAR) images is crucial for effective port monitoring and planning. Yet, the unique challenges of SAR imaging, such as side-looking geometry, multi-bouncing scattering, and the compact arrangement of structures, often lead to incomplete building structures and blurred boundaries in classification results. To address these issues, this paper introduces SPformer, an efficient and lightweight pyramid transformer model tailored for semantic segmentation. The SPformer utilizes a pyramid transformer encoder with spatially separable self-attention (SSSA) to refine both local and global spatial information and to process multi-scale features, enhancing the accuracy of building structure delineation. It also integrates a lightweight all multi-layer perceptron (ALL-MLP) decoder to consolidate multi-scale information across various depths and attention scopes, refining detail processing. Experimental results on the Gaofen-3 (GF-3) 1 m port building classification dataset demonstrate the effectiveness of SPformer, achieving competitive performance compared to state-of-the-art models, with mean intersection over union (mIoU) and mean F1-score (mF1) reaching 77.14% and 87.04%, respectively, while maintaining a compact model size and lower computational requirements. Experiments conducted on the entire scene of SAR images covering port area also show the good capabilities of the proposed method.","2024-09","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","17","16","","","","","","","","","","English","","","","WOS:001311605100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","building classification; deep learning; pyramid transformer; SEGMENTATION; semantic segmentation; synthetic aperture radar image","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HGQYMPFS","journalArticle","2024","Aksamit, N; Tchagang, A; Li, YF; Ombuki-Berman, B","Hybrid fragment-SMILES tokenization for ADMET prediction in drug discovery","BMC BIOINFORMATICS","","1471-2105","10.1186/s12859-024-05861-z","","Background:Drug discovery and development is the extremely costly and time-consuming process of identifying new molecules that can interact with a biomarker target to interrupt the disease pathway of interest. In addition to binding the target, a drug candidate needs to satisfy multiple properties affecting absorption, distribution, metabolism, excretion, and toxicity (ADMET). Artificial intelligence approaches provide an opportunity to improve each step of the drug discovery and development process, in which the first question faced by us is how a molecule can be informatively represented such that the in-silico solutions are optimized.Results:This study introduces a novel hybrid SMILES-fragment tokenization method, coupled with two pre-training strategies, utilizing a Transformer-based model. We investigate the efficacy of hybrid tokenization in improving the performance of ADMET prediction tasks. Our approach leverages MTL-BERT, an encoder-only Transformer model that achieves state-of-the-art ADMET predictions, and contrasts the standard SMILES tokenization with our hybrid method across a spectrum of fragment library cutoffs.Conclusion:The findings reveal that while an excess of fragments can impede performance, using hybrid tokenization with high frequency fragments enhances results beyond the base SMILES tokenization. This advancement underscores the potential of integrating fragment- and character-level molecular features within the training of Transformer models for ADMET property prediction.","2024-08-01","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","1","25","","","","","","","","","","English","","","","WOS:001282147600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","ADMET prediction; Drug discovery; Fragments; SMILES; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QQHKBMPN","journalArticle","2024","Ling, KY; Zhao, H; Fan, XM; Niu, XH; Yin, WC; Liu, Y; Wang, C; Bi, XJ","Model Touch Pointing and Detect Parkinson's Disease via a Mobile Game","PROCEEDINGS OF THE ACM ON INTERACTIVE MOBILE WEARABLE AND UBIQUITOUS TECHNOLOGIES-IMWUT","","2474-9567","10.1145/3659627","","Touch pointing is one of the primary interaction actions on mobile devices. In this research, we aim to (1) model touch pointing for people with Parkinson's Disease (PD), and (2) detect PD via touch pointing. We created a mobile game called MoleBuster in which a user performs a sequence of pointing actions. Our study with 40 participants shows that PD participants exhibited distinct pointing behavior. PD participants were much slower and had greater variances in movement time (MT), while their error rate was slightly lower than age-matched non-PD participants, indicating PD participants traded speed for accuracy. The nominal width Finger-Fitts law showed greater fitness than Fitts' law, suggesting this model should be adopted in lieu of Fitts' law to guide mobile interface design for PD users. We also proposed a CNN-Transformer-based neural network model to detect PD. Taking touch pointing data and comfort rating of finger movement as input, this model achieved an AUC of 0.97 and sensitivity of 0.95 in leave-one-user-out cross-validation. Overall, our research contributes models that reveal the temporal and spatial characteristics of touch pointing for PD users, and provide a new method (CNN-Transformer model) and a mobile game (MoleBuster) for convenient PD detection.","2024-05","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","2","8","","","","","","","","","","English","","","","WOS:001229316000033","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","Bayesian modeling; Finger-Fitts law; FITTS LAW; Fitts' law; hierarchical models; INFORMATION CAPACITY; machine learning; neural networks; SELECTION; UPDRS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MLCIWF66","journalArticle","2024","Zhao, CY; Xu, ZL; Wang, XJ; Tao, SY; MacDonald, WA; He, K; Poholek, AC; Chen, K; Huang, H; Chen, W","Innovative super-resolution in spatial transcriptomics: a transformer model exploiting histology images and spatial gene expression","BRIEFINGS IN BIOINFORMATICS","","1467-5463","10.1093/bib/bbae052","","Spatial transcriptomics technologies have shed light on the complexities of tissue structures by accurately mapping spatial microenvironments. Nonetheless, a myriad of methods, especially those utilized in platforms like Visium, often relinquish spatial details owing to intrinsic resolution limitations. In response, we introduce TransformerST, an innovative, unsupervised model anchored in the Transformer architecture, which operates independently of references, thereby ensuring cost-efficiency by circumventing the need for single-cell RNA sequencing. TransformerST not only elevates Visium data from a multicellular level to a single-cell granularity but also showcases adaptability across diverse spatial transcriptomics platforms. By employing a vision transformer-based encoder, it discerns latent image-gene expression co-representations and is further enhanced by spatial correlations, derived from an adaptive graph Transformer module. The sophisticated cross-scale graph network, utilized in super-resolution, significantly boosts the model's accuracy, unveiling complex structure-functional relationships within histology images. Empirical evaluations validate its adeptness in revealing tissue subtleties at the single-cell scale. Crucially, TransformerST adeptly navigates through image-gene co-representation, maximizing the synergistic utility of gene expression and histology images, thereby emerging as a pioneering tool in spatial transcriptomics. It not only enhances resolution to a single-cell level but also introduces a novel approach that optimally utilizes histology images alongside gene expression, providing a refined lens for investigating spatial transcriptomics.","2024-03-02","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","2","25","","","","","","","","","","English","","","","WOS:001281650100003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","CELL ATLAS; graph transformer; single-cell RNA-seq; spatial transcriptomics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3EHM6ZM2","journalArticle","2024","Tu, YS; Shen, YS; Chan, YY; Wang, L; Chen, JH","Violent Video Recognition by Using Sequential Image Collage","SENSORS","","1424-8220","10.3390/s24061844","","Identifying violent activities is important for ensuring the safety of society. Although the Transformer model contributes significantly to the field of behavior recognition, it often requires a substantial volume of data to perform well. Since existing datasets on violent behavior are currently lacking, it will be a challenge for Transformers to identify violent behavior with insufficient datasets. Additionally, Transformers are known to be computationally heavy and can sometimes overlook temporal features. To overcome these issues, an architecture named MLP-Mixer can be used to achieve comparable results with a smaller dataset. In this research, a special type of dataset to be fed into the MLP-Mixer called a sequential image collage (SIC) is proposed. This dataset is created by aggregating frames of video clips into image collages sequentially for the model to better understand the temporal features of violent behavior in videos. Three different public datasets, namely, the dataset of National Hockey League hockey fights, the dataset of smart-city CCTV violence detection, and the dataset of real-life violence situations were used to train the model. The results of the experiments proved that the model trained using the proposed SIC is capable of achieving high performance in violent behavior recognition with fewer parameters and FLOPs needed compared to other state-of-the-art models.","2024-03","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","6","24","","","","","","","","","","English","","","","WOS:001192730800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","behavioral sciences; computer architecture; FLOW; image recognition; multilayer perceptrons; neurons; training; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"35UQDPWK","journalArticle","2024","Hou, DX; Chen, JH; Cheng, RC; Hu, X; Shi, PM","A bearing remaining life prediction method under variable operating conditions based on cross-transformer fusioning segmented data cleaning","RELIABILITY ENGINEERING & SYSTEM SAFETY","","0951-8320","10.1016/j.ress.2024.110021","","Bearing remaining useful life (RUL) prediction research based on deep learning mostly emphasizes model performance and effective feature vectors, overlooking different densities of outlier distributions in vibration signals at varying degradation stages. Moreover, forecasting models focus on capturing cross -time dependencies, ignoring the dependencies between different variables. To solve these problems, this paper proposes an unsupervised segmented data cleaning algorithm and a RUL prediction framework adaptable to variable operating conditions. The method consists of four steps: (1) Multi -domain feature extraction and selection establish a feature vector space reflecting degradation trends. (2) Segmented data cleaning divides degradation stages, using different penalty factors for outlier cleaning. (3) Cleaned vibration signals undergo a second round of multidomain feature engineering and degradation -stage division. (4) A two -stage Cross -Transformer model is used for RUL prediction. The method proposed has been validated on the prognostics and health management (PHM) bearing degradation dataset. In the constant condition prediction task, the root mean square error (RMSE) and mean absolute error (MAE) were improved to 1.88 and 5.78, respectively. In the variable condition prediction task, the proposed method outperformed existing methods, with an improvement of 59.10 % in RMSE, demonstrating strong generalization performance and practical application value.","2024-05","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","245","","","","","","","","","","English","","","","WOS:001203739300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Bearing life prediction; Cross -transformer; Deep learning; Generalization performance; NETWORK; PROGNOSTICS; Segmented data cleaning; TIME-SERIES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YUEGZTNS","journalArticle","2023","Wu, T; Gao, L; Zhang, LX; Lai, YK; Zhang, H","STAR-TM: STructure Aware Reconstruction of Textured Mesh From Single Image","IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE","","0162-8828","10.1109/TPAMI.2023.3305630","","We present a novel method for single-view 3D reconstruction of textured meshes, with a focus to address the primary challenge surrounding texture inference and transfer. Our key observation is that learning textured reconstruction in a structure-aware and globally consistent manner is effective in handling the severe ill-posedness of the texturing problem and significant variations in object pose and texture details. Specifically, we perform structured mesh reconstruction, via a retrieval-and-assembly approach, to produce a set of genus-zero parts parameterized by deformable boxes and endowed with semantic information. For texturing, we first transfer visible colors from the input image onto the unified UV texture space of the deformable boxes. Then we combine a learned transformer model for per-part texture completion with a global consistency loss to optimize inter-part texture consistency. Our texture completion model operates in a VQ-VAE embedding space and is trained end-to-end, with the transformer training enhanced with retrieved texture instances to improve texture completion performance amid significant occlusion. Extensive experiments demonstrate higher-quality textured mesh reconstruction obtained by our method over state-of-the-art alternatives, both quantitatively and qualitatively, as reflected by a better recovery of texture coherence and details.","2023-12","2025-02-26 20:41:54","2025-02-26 20:41:54","","15680-15693","","12","45","","","","","","","","","","English","","","","WOS:001104973300101","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","Image reconstruction; Periodic structures; Semantics; Shape; Structure-aware single-view 3D reconstruction; texture completion; textured meshes; Three-dimensional displays; Training; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8GHHGWVV","journalArticle","2023","Dedhia, B; Balasubramanian, R; Jha, NK","SCouT: Synthetic Counterfactuals via Spatiotemporal Transformers for Actionable Healthcare","ACM TRANSACTIONS ON COMPUTING FOR HEALTHCARE","","2691-1957","10.1145/3617180","","The synthetic control method has pioneered a class of powerful data-driven techniques to estimate the counterfactual reality of a unit from donor units. At its core, the technique involves a linear model fitted on the pre-intervention period that combines donor outcomes to yield the counterfactual. However, linearly combining spatial information at each time instance using time-agnostic weights fails to capture important inter-unit and intra-unit temporal contexts and complex nonlinear dynamics of real data. We instead propose an approach to use local spatiotemporal information before the onset of the intervention as a promising way to estimate the counterfactual sequence. To this end, we suggest a Transformer model that leverages particular positional embeddings, a modified decoder attention mask, and a novel pre-training task to perform spatiotemporal sequence-to-sequence modeling. Our experiments on synthetic data demonstrate the efficacy of our method in the typical small donor pool setting and its robustness against noise. We also generate actionable healthcare insights at the population and patient levels by simulating a state-wide public health policy to evaluate its effectiveness, an in silico trial for asthma medications to support randomized controlled trials, and a medical intervention for patients with Friedreich's ataxia to improve clinical decision making and promote personalized therapy (code is available at https://github.com/JHALab/scout).","2023-10","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","4","4","","","","","","","","","","English","","","","WOS:001408795700003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","ATAXIA; Causal inference; ECONOMIC COSTS; precision medicine; randomized trials; synthetic control; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NYWJEXV4","journalArticle","2023","Im, JE; Yoon, SA; Shin, YM; Park, S","Real-Time Prediction for Neonatal Endotracheal Intubation Using Multimodal Transformer Network","IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS","","2168-2194","10.1109/JBHI.2023.3267521","","Neonates admitted to neonatal intensive care units (NICUs) are at risk for respiratory decompensation and may require endotracheal intubation. Delayed intubation is associated with increased morbidity and mortality, particularly in urgent unplanned intubation. By accurately predicting the need for intubation in real-time, additional time can be made available for preparation, thereby increasing the safety margins by avoiding high-risk late intubation. In this study, the probability of intubation in neonatal patients with respiratory problems was predicted using a deep neural network. A multimodal transformer model was developed to simultaneously analyze time-series data (1- 3 h of vital signs and FiO(2) setting value) and numeric data including initial clinical information. Over a dataset including information of 128 neonatal patients who underwent noninvasive ventilation, the proposed model successfully predicted the need for intubation 3 h in advance (area under the receiver operator characteristic curve = 0.880 +/- 0.051, F1-score = 0.864 +/- 0.031, sensitivity = 0.886 +/- 0.041, specificity = 0.849 +/- 0.035, and accuracy = 0.857 +/- 0.032). Moreover, the proposed model showed high generalization ability by achieving AUROC 0.890, F1-score 0.893, specificity 0.871, sensitivity 0.745, and accuracy 0.864 with an additional 91 dataset for testing.","2023-06","2025-02-26 20:41:54","2025-02-26 20:41:54","","2625-2634","","6","27","","","","","","","","","","English","","","","WOS:001004541400005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","ANOMALY DETECTION; deep neural network; Endotracheal intubation; multimodal transformer network; neonatal intensive care units; SYSTEM; UNPLANNED INTUBATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JPFKBZUP","journalArticle","2023","Bottieau, J; Wang, Y; De Grève, Z; Vallée, F; Toubeau, JF","Interpretable Transformer Model for Capturing Regime Switching Effects of Real-Time Electricity Prices","IEEE TRANSACTIONS ON POWER SYSTEMS","","0885-8950","10.1109/TPWRS.2022.3195970","","Real-time electricity prices are economic signals incentivizing market players to support real-time system balancing. These price signals typically switch between low- and high-price regimes depending on whether the power system is in surplus or shortage of generation, which is hard to capture. In this context, we propose a new Transformer-based model to assist the short-term trading strategies of market players. The proposed model offers high-performance probabilistic forecasts of real-time prices while providing insights into its inner decision-making process. Transformers rely on attention mechanisms solely computed via feed-forward networks to explicitly learn temporal patterns, which allows them to capture complex dependencies such as regime switching. Here, we augment Transformers with subnetworks dedicated to endogenously quantify the relative importance of each input feature. Hence, the resulting forecaster intrinsically provides the temporal attribution of each input feature, which foster trust and transparency for subsequent decision makers. Our case study on real-world market data of the Belgian power system demonstrates the ability of the proposed model to outperform state-of-the-art forecasting techniques, while shedding light on its most important drivers.","2023-05","2025-02-26 20:41:54","2025-02-26 20:41:54","","2162-2176","","3","38","","","","","","","","","","English","","","","WOS:000980444400015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Analytical models; Attention mechanism; deep learning; explainable AI; Forecasting; GAUSSIAN PROCESS; Hidden Markov models; imbalance price; LOAD; MARKETS; multi-horizon forecasting; Power systems; PREDICTION; Predictive models; real-time electricity markets; Real-time systems; RESERVE; STORAGE; Transformers; WIND POWER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HDYQXUT9","journalArticle","2023","Zhang, QY; Chen, JH; Xiao, G; He, SY; Deng, KX","TransformGraph: A novel short-term electricity net load forecasting model","ENERGY REPORTS","","2352-4847","10.1016/j.egyr.2023.01.050","","The development of the smart grid recognizes the importance of projecting electrical net load forecasting, which represents the difference between load demand and installed renewable energy sources (RES), such as wind and solar power. For net load forecasting, many approaches like statistical models, machine learning, and deep learning have been developed. Because of the significant uncertainty of RES, these models suffer from poor forecasting accuracy. In this study, we propose the TransformGraph, a novel Transformer model for electricity net load forecasting, which combines the Transformer and graph convolutional network (GCN). Firstly, the GCN is used as an input embedding layer to encode multivariate input sequences, which can fill the gap that the correlation information is not thoroughly considered in the Transformer. Then, the self-attention mechanism in the Transformer is used to capture the temporal dependence of the sequence data. Finally, the predicted load values are output using a feed forward neural network. Data from three countries derived from Open Power System Data (OPSD) sources are employed for the case study. Comparisons between the TransformGraph and the other five forecasting models demonstrate that the proposed one has higher forecasting accuracy and stability. (c) 2023 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).","2023-12","2025-02-26 20:41:54","2025-02-26 20:41:54","","2705-2717","","","9","","","","","","","","","","English","","","","WOS:000964943100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Deep learning; Electricity load forecasting; Graph convolutional network; Time series; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7LIN269J","journalArticle","2023","Shuvro, AA; Khan, MS; Rahman, M; Hussain, F; Moniruzzaman, M; Hossen, MS","Transformer Based Traffic Flow Forecasting in SDN-VANET","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3270889","","Intelligent Transportation System (ITS) provides services for proper traffic assistance. ITS helps in creating a transportation system that is smart, safe and efficient. Vehicular Ad-hoc Network supplies internet connectivity to vehicles and helps in traffic guidance. This paper uses a modified transformer architecture for time-series vehicular data to predict traffic flow. Time-series sequences are generated from the dataset for capturing temporal dependencies. Our proposed transformer-based model has been engineered to capture inter-feature correlations along with inter-sample correlations. The 2D-Transformers model has a significant decrease in error compared with Transformers and LSTM-based models. The prediction generated from the model can be transmitted throughout a network of vehicles. So, a holistic networking model is proposed where the vehicles will be connected to Road-side Units (RSUs) and the backbone network will be Software Defined Network (SDN). The traditional design principles, that incorporate data, control and management planes together in a network device, are incapable to adapt with this much data growth, bandwidth, speed, security, and scalability compared to SDN as it provides with centralized programmable mechanism reliably. The trained parameters learned using the transformer model can be passed throughout the network for traffic guidance.","2023","2025-02-26 20:41:54","2025-02-26 20:41:54","","41816-41826","","","11","","","","","","","","","","English","","","","WOS:000982328000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","attention; CHALLENGES; Computer architecture; Data models; DESIGN; encoders; Predictive models; SECURE; sequence length; Software defined networking; software-defined network; SOFTWARE-DEFINED NETWORKING; traffic flow; transformers; Transformers; Vehicular ad hoc networks; Vehicular ad-hoc network; Wireless sensor networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"APGDSTKP","journalArticle","2022","Ye, XF; Lu, YQ; Manoharan, S","Automated conversion of engineering rules: Towards flexible manufacturing collaboration","RESULTS IN ENGINEERING","","2590-1230","10.1016/j.rineng.2022.100680","","Rapid on-demand manufacturing resource sharing within and between factories are critical to achieving responsive autonomous manufacturing collaborations towards mass personalization. To this end, cloud manufacturing technologies allow resource owners/service providers to virtualize and encapsulate their resources as services accessible over the Internet. Decision-making in cloud manufacturing needs to utilize realworld engineering knowledge from different parties. Many existing systems have adopted the semantic web-based decision-making framework, in which engineering knowledge is modeled using structured syntax. However, manually converting engineering rules to semantic rules is time-consuming and error prone. This research proposes a machine learning model, based on the Transformer model, that uses neural machine translation techniques to convert engineering knowledge expressed in natural language to structured semantic rules directly. The model is implemented using neural network. The model is first trained using typical sentences that are used for describing engineering knowledge. From these sample sentences, the model learns the patterns and the meaning of the sentences. This allows the model to identify the service providers, resource users, and the resources described in the sentences. As a result, the corresponding semantic rules can be constructed. Compared with previous approaches, the proposed scheme not only improves the conversion accuracy but also reduces the amount of required human interaction, simplifying the system and its use.","2022-12","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","16","","","","","","","","","","English","","","","WOS:000928475100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Cloud manufacturing; Engineering knowledge; Machine learning; Natural language processing; Semantic web; Smart manufacturing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ISRLWUFS","journalArticle","2024","Liu, MR; Jiang, R; Yang, HW","Using Transfer Learning to Realize Low Resource Dungan Language Speech Synthesis","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14146336","","This article presents a transfer-learning-based method to improve the synthesized speech quality of the low-resource Dungan language. This improvement is accomplished by fine-tuning a pre-trained Mandarin acoustic model to a Dungan language acoustic model using a limited Dungan corpus within the Tacotron2+WaveRNN framework. Our method begins with developing a transformer-based Dungan text analyzer capable of generating unit sequences with embedded prosodic information from Dungan sentences. These unit sequences, along with the speech features, provide <unit sequence with prosodic labels, Mel spectrograms> pairs as the input of Tacotron2 to train the acoustic model. Concurrently, we pre-trained a Tacotron2-based Mandarin acoustic model using a large-scale Mandarin corpus. The model is then fine-tuned with a small-scale Dungan speech corpus to derive a Dungan acoustic model that autonomously learns the alignment and mapping of the units to the spectrograms. The resulting spectrograms are converted into waveforms via the WaveRNN vocoder, facilitating the synthesis of high-quality Mandarin or Dungan speech. Both subjective and objective experiments suggest that the proposed transfer learning-based Dungan speech synthesis achieves superior scores compared to models trained only with the Dungan corpus and other methods. Consequently, our method offers a strategy to achieve speech synthesis for low-resource languages by adding prosodic information and leveraging a similar, high-resource language corpus through transfer learning.","2024-07","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","14","14","","","","","","","","","","English","","","","WOS:001276681400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Dungan language speech synthesis; low-resource language; tacotron2; text analysis; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JCXW4TS2","journalArticle","2023","MacWhinney, B; Fromm, D","Collaborative Commentary for Understanding Communication Disorders","AMERICAN JOURNAL OF SPEECH-LANGUAGE PATHOLOGY","","1058-0360","10.1044/2023_AJSLP-22-00385","","Purpose: The goal of the Collaborative Commentary (CC) system is to make the TalkBank adult clinical databases-including AphasiaBank, DementiaBank, RHDBank, and TBIBank-open to commentary and analysis from the full community of researchers, instructors, students, and clinicians. Method: CC allows a group leader to establish a commentary group and invite colleagues or students to join as members of the group. Members can then browse through the transcript database using the TalkBank Browser. When they wish to insert a comment, they click on the utterance line number or drag the cursor across a range of utterances and a window opens to receive the comment. The comment can include open text along with codes selected from a predefined set of codes created by that commentary group. Results: CC was released for public use in August 2022. It is being used currently in five research projects and eight classes. An important feature of CC is its ability to evaluate the reliability of coding systems and to sharpen analytic categories. By familiarizing instructors and researchers with the capabilities of CC, we expect to see an increasing usage of CC for a variety of clinical and research applications. Conclusions: CC can contribute to a better understanding of connected speech features in aphasia, dementia, right hemisphere disorder, and traumatic brain injury. CC represents an extreme innovation not only for the study of adult neurogenic communication disorders but also for the study of spoken language generally.","2023-10","2025-02-26 20:41:54","2025-02-26 20:41:54","","2580-2588","","5","32","","","","","","","","","","English","","","","WOS:001087433600013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","LANGUAGE; SENTENCE PRODUCTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BZ2CT99A","journalArticle","2025","Khandokar, IA; Deshpande, P","Computer Vision-Based Framework for Data Extraction From Heterogeneous Financial Tables: A Comprehensive Approach to Unlocking Financial Insights","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3522141","","Information extraction from financial document images is crucial in computer vision and NLP, as financial data often exists in image or PDF format, enabling organizations to analyze and make informed business decisions using OCR advancements. The table contents of financial document images are one of the prominent structures to confine important portions of data of the document and many Deep learning-based methods have been proposed to detect Table regions inside document images. The shortcomings of the current approach are that it is bounded within the detection of the table region and struggles in cases such as handling different layouts and preserving the relation among the different attributes of the table. Therefore, in this work, we proposed an end-to-end architecture to extract information from Financial table images while preserving the column row structures of the attributes within the table. We divided the task into four modules and generated synthesized data with different augmentation techniques to overcome data scarcity challenges and boost the performance of the pipeline modules. In terms of information extraction, the proposed method acquired 85% accuracy in the target invoice dataset.","2025","2025-02-26 20:41:54","2025-02-26 20:41:54","","17706-17723","","","13","","","","","","","","","","English","","","","WOS:001410383800038","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","Accuracy; Computer vision; Data mining; deep learning; Feature extraction; Hidden Markov models; information extraction; Information retrieval; Layout; Optical character recognition; Pipelines; STRUCTURE RECOGNITION; Support vector machines; Text recognition; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FHMAJWYV","journalArticle","2024","Li, J; Yan, DJ; He, FZ; Dong, ZC; Jiang, MF","A Mixed-Precision Transformer Accelerator With Vector Tiling Systolic Array for License Plate Recognition in Unconstrained Scenarios","IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS","","1524-9050","10.1109/TITS.2024.3457815","","Power efficiency for license plate recognition (LPR) under unconstrained scenarios is a crucial factor in many edge-based real-world applications, e.g., autonomous vehicles whose power budget is limited. While a bulk of prior works have explored LPR approaches for unconstrained situations on CPU and GPU servers, these methods result in huge power dissipation, and are ineffective in challenging scenes. In this work, we present a mixed-precision (MP) Transformer hardware architecture to meet the requirements of power efficiency and satisfactory LPR accuracy in unconstrained scenarios, dedicated to implementing power-efficient edge accelerators for difficult LPR tasks. Firstly, MP-LPR Transformer model is proposed, where novel mixed-precision quantization and non-linear approximation techniques are tailored for low bit-width inference. Secondly, vector tiling systolic array Transformer architecture (VTSATA) is proposed with unique vector tiling systolic array (VTSA) and vector ALU (VALU) designs, where VTSA is used to accelerate matrix multiplications, and VALU is used to process non-linear operations. Finally, a FPGA accelerator prototype based on our approach is developed. Experimental results demonstrate that our hardware platform can reduce power consumption more than 20x compared to GPU platforms, and for challenge subset on CCPD dataset, our method can further improve nearly 1% accuracy with respect to the state-of-the-art performance.","2024-12","2025-02-26 20:41:54","2025-02-26 20:41:54","","20280-20294","","12","25","","","","","","","","","","English","","","","WOS:001324948000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","License plate recognition; mixed-precision transformer accelerator; unconstrained scenarios; vector tiling systolic array","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"34DTT94M","journalArticle","2024","Hou, WJ; Jin, H; Peng, C; Jiang, L","A cognitive communication jamming strategy based on Transformer and Deep Reinforcement Learning","COMPUTERS & ELECTRICAL ENGINEERING","","0045-7906","10.1016/j.compeleceng.2024.109610","","The advent of sophisticated communication technologies, such as cognitive radio and anti- jamming techniques, has significantly elevated the challenge of disrupting enemy communications. Nevertheless, the inherent openness of wireless communications remains a vulnerability that can be exploited to interfere with them. Some contemporary Reinforcement Learning (RL)based jamming strategies examine methods for rapidly identifying the optimal jamming strategy for a specific modulated signal. However, such algorithms lack the flexibility and responsiveness required to effectively counter the enemy's evolving communication strategies. To address this issue, we propose a Transformer and Deep Reinforcement Learning (DRL)-based jamming strategy that can be trained to identify jamming methods for multiple digital and analog signals. In particular, the Transformer Encoder is employed as a network for DRL to process the state information pertaining to the enemy communication. Subsequently, the decision module of the Double Deep Q Network (DDQN) is utilized to select the jamming action based on the processed information. Furthermore, we have devised a reward function and constructed an invalid jamming list, with the objective of selecting an action that requires low power consumption and enhances the convergence speed of the algorithm. The experimental results demonstrate that the algorithm proposed in this paper exhibits notable performance advantages in comparison to other networks and DRL algorithms.","2024-12","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","120","","","","","","","","","","English","","","","WOS:001312181500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","Cognitive interference; Deep Reinforcement Learning; Double Deep Q Network; SCHEME; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MURB2VBK","journalArticle","2024","Liu, DB; Yang, LT; Zhao, RA; Cui, JH; Yang, XL","An Efficient Tensor-Based Transformer for Industrial Internet of Things","IEEE TRANSACTIONS ON NETWORK SCIENCE AND ENGINEERING","","2327-4697","10.1109/TNSE.2023.3264544","","Transformer and its derivatives are widely used in industrial Internet of Things due to their excellent performance. However, the scale of these network models is exceptionally large, generating significant memory overhead and computational load during training and inference, as well as consuming large amounts of power resources. Therefore, these existing network models cannot be trained and deployed on resource-constrained industrial embedded devices, thus limiting their participation in collaborative computing and real-time applications. In this paper, we design plug-and-play lightweight multi-head attention and lightweight position-wise feed-forward networks, and propose lightweight tensorized transformer and lightweight tensorized transformer++ based on these two components. The performance of lightweight tensorized transformer and lightweight tensorized transformer++ is evaluated on real datasets. The experimental results show that efficient and lightweight tensor-coupled models can achieve comparable or even higher performance than the transformer on real tasks. Furthermore, the number of training parameters and floating-point operations for lightweight tensorized transformer and lightweight tensorized transformer++ are much lower than the transformer model, and the training time and power consumption of the model during training are also less than the transformer. Therefore, these two lightweight network models are better suited than the transformer for deployment to resource-constrained industrial embedded devices.","2024-05","2025-02-26 20:41:54","2025-02-26 20:41:54","","2574-2585","","3","11","","","","","","","","","","English","","","","WOS:001214548200020","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Biological system modeling; Computational modeling; Data models; edge computing; industrial Internet of Things; neural network model compression; Performance evaluation; SYSTEMS; Task analysis; tensor decomposition; Training; Transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PGF5SXGL","journalArticle","2025","Lee, SJ; de Villiers, R","Unveiling Emotional Intensity in Online Reviews: Adopting Advanced Machine Learning Techniques","AUSTRALASIAN MARKETING JOURNAL","","1441-3582","10.1177/14413582241244808","","The digital revolution has spurred significant growth in online reviews and user-generated content. Traditional methods used in Marketing for analysing large datasets have limitations, emphasising the need for improved analytical approaches, particularly with the advent of artificial intelligence technology. This research used a state-of-the-art transformer model to analyse extensive online book reviews to accurately identify six specific emotions in the reviews of both fiction (hedonic) and nonfiction (utilitarian) genres. This study collected 3,157,703 reviews of 15,293 books voted 'best book of the year' on GoodReads.com over the past decade. Our findings reveal noticeable differences in emotional intensity across genres, with nonfiction displaying a slightly higher level of joy, and fiction showing higher levels of anger, sadness and surprise. Joy emerged as the dominant emotion across genres; however, it does not necessarily have a direct impact on book ratings. This study emphasises the intricacies of reader emotions, serving as a significant case study for marketers and publishers aiming to optimise their strategies in the contemporary literary market. The study contributes to the literature on the impact of consumers' emotional responses, how they are reflected in social review commentary for high-involvement online products, and their impact on product ratings.","2025-02","2025-02-26 20:41:54","2025-02-26 20:41:54","","75-86","","1","33","","","","","","","","","","English","","","","WOS:001197867000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","CONSUMER REVIEWS; e-marketing; emotional analysis; ENGAGEMENT; fiction and nonfiction genres; hedonic versus utilitarian aspects; online book reviews; social persuasion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R68NHZAJ","journalArticle","2023","Pillai, J; Pillai, K","Accuracy of generative artificial intelligence models in differential diagnoses of familial Mediterranean fever and deficiency of Interleukin-1 receptor antagonist","JOURNAL OF TRANSLATIONAL AUTOIMMUNITY","","2589-9090","10.1016/j.jtauto.2023.100213","","With the increasing development of artificial intelligence, large language models (LLMs) have been utilized to solve problems in natural language processing tasks. More recently, LLMs have shown unique potential in numerous applications within medicine but have been particularly investigated for their ability in clinical reasoning. Although the diagnostic accuracy of LLMs in forming differential diagnoses has been reviewed in general internal medicine applications, much is unknown in autoinflammatory disorders. From the nature of autoinflammatory diseases, forming a differential diagnosis is challenging due to the overlapping symptoms between disorders and even more difficult without genetic screening. In this work, the diagnostic accuracy of the Generative Pre-Trained Transformer Model-4 (GPT-4), GPT-3.5, and Large Language Model Meta AI (LLaMa) were evaluated in clinical vignettes of Deficiency of Interleukin-1 Receptor Antagonist (DIRA) and Familial Mediterranean Fever (FMF). We then compared these models to a control group including one internal medicine physician. It was found that GPT-4 did not significantly differ in correctly identifying DIRA and FMF patients compared to the internist. However, the physician maintained a significantly higher accuracy than GPT-3.5 and LLaMa 2 for either disease. Overall, we explore and discuss the unique potential of LLMs in diagnostics for autoimmune diseases.","2023-12","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","7","","","","","","","","","","English","","","","WOS:001103664200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Artificial intelligence; AUTOINFLAMMATORY DISEASE; Deficiency of Interleukin-1 receptor antagonist; DELETION; DIRA; Familial Mediterranean fever; FMF; IL1RN; MUTATION; PATIENT; PUSTULOSIS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7VVXR3D5","journalArticle","2023","Liu, Y; Zhang, FQ; Yang, SP; Cao, J","Self-attention mechanism for dynamic multi-step ROP prediction under continuous learning structure","GEOENERGY SCIENCE AND ENGINEERING","","2949-8929","10.1016/j.geoen.2023.212083","","The evaluation and prediction of the rate of penetration have been long-term challenging in real-time drilling operations due to, for example, the complexity of influence parameters and uncertainties from the subsurface. In this paper, we propose a machine learning structure combining with a conceptual framework of continuous learning and a deep learning network with the self-attention mechanism to further improve the practical ROP prediction. The self-attention mechanism, also the cornerstone of the Transformer model in the recent impressive GPT3.5 and 4 (Generative Pretrained Transformer), exhibits an enhanced capability to capture the long-dependence relation within sequential data. Compared with the other commonly used recurrent neural networks, the proposed self-attention network model shows significant improvement in reliability and accuracy, especially when one tries to forward predict a long sequence of ROP. This newly presented model can predict the real-time long-term ROP value and can further improve its efficiency by adjusting the controllable drilling parameters. Moreover, the continuous learning structure allows for the extension of single well application to a field scale in a continuous manner for each network model. Field case studies demonstrate the effectiveness and stability of the newly proposed model, which reaches a higher prediction accuracy than 90% for three testing wells. Hence, the proposed structure and network model can help with predictive analysis for real-time drilling performance as an accurate and robust model.","2023-10","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","229","","","","","","","","","","English","","","","WOS:001056343900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7JUEEGRJ","journalArticle","2023","Wang, RH; Feng, YF; Sun, ML; Jiang, Y; Li, ZS; Cui, LZ; Wei, LY","MVIL6: Accurate identification of IL-6-induced peptides using multi-view feature learning","INTERNATIONAL JOURNAL OF BIOLOGICAL MACROMOLECULES","","0141-8130","10.1016/j.ijbiomac.2023.125412","","Interleukin-6 (IL-6) is a potential therapeutic target for many diseases, and it is of great significance in accurately predicting IL-6-induced peptides for IL-6 research. However, the cost of traditional wet experiments to detect IL6-induced peptides is huge, and the discovery and design of peptides by computer before the experimental stage have become a promising technology. In this study, we developed a deep learning model called MVIL6 for predicting IL-6-inducing peptides. Comparative results demonstrated the outstanding performance and robustness of MVIL6. Specifically, we employ a pre-trained protein language model MG-BERT and the Transformer model to process two different sequence-based descriptors and integrate them with a fusion module to improve the prediction performance. The ablation experiment demonstrated the effectiveness of our fusion strategy for the two models. In addition, to provide good interpretability of our model, we explored and visualized the amino acids considered important for IL-6-induced peptide prediction by our model. Finally, a case study presented using MVIL6 to predict IL-6-induced peptides in the SARS-CoV-2 spike protein shows that MVIL6 achieves higher performance than existing methods and can be useful for identifying potential IL-6-induced peptides in viral proteins.","2023-08-15","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","246","","","","","","","","","","English","","","","WOS:001034119900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Deep learning; IL-6; IL-6-induced peptides; INTERLEUKIN-6; Multi-view feature learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JXYTQTU4","journalArticle","2024","Petroi-Bock, D; Clark, HM; Stierwalt, JAG; Botha, H; Ali, F; Whitwell, JL; Josephs, KA","Influences of motor speech impairments on the presentation of dysphagia in progressive supranuclear palsy","INTERNATIONAL JOURNAL OF SPEECH-LANGUAGE PATHOLOGY","","1754-9507","10.1080/17549507.2023.2221407","","PurposeThe purpose of this study was to examine whether differences in motor speech features are related to presentations of dysphagia in progressive supranuclear palsy (PSP) given the sparsity of data examining this relationship.MethodMotor speech disorder (MSD) type and severity along with specific swallowing variables were analysed to obtain insights among these relationships in 73 participants with PSP.ResultResults revealed that most participants (93%) had dysarthria, with 19% having co-occurring apraxia of speech (AOS). Greater MSD severity was related to more severe pharyngeal phase impairments (95% CI [-0.917, -0.146], p = 0.008). While certain motor speech and swallowing scores varied minimally across participants, incremental changes in these functions were more likely to occur when specific MSD features were present. A trend for participants with spastic dysarthria and/or AOS to exhibit more severe dysphagia was observed.ConclusionThis study points to the need for thorough neurological evaluation, with inclusion of speech-language pathology consultation, in the standard of care for PSP. Comprehensive assessment of both motor speech and swallowing functions can inform differential diagnosis and assist patients/families facing decisions regarding modalities for communication and nutrition in the setting of neurodegenerative disease. Additional research may yield greater insights about relevant assessment and intervention considerations in PSP.","2024-03-03","2025-02-26 20:41:54","2025-02-26 20:41:54","","278-288","","2","26","","","","","","","","","","English","","","","WOS:001008614700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","AMYOTROPHIC LATERAL SCLEROSIS; apraxia of speech; DIAGNOSIS; DISORDERS; dysarthria; dysphagia; motor speech disorders; NATURAL-HISTORY; neurodegenerative disease; OROPHARYNGEAL DYSPHAGIA; PARKINSONS-DISEASE; PREDICTORS; PREVALENCE; Progressive supranuclear palsy; RICHARDSON-OLSZEWSKI SYNDROME; SWALLOWING FUNCTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BYSFIA6F","journalArticle","2023","Lyu, B; Fan, CX; Ming, Y; Zhao, PZ; Hu, NN","En-HACN: Enhancing Hybrid Architecture With Fast Attention and Capsule Network for End-to-end Speech Recognition","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2023.3245407","","Automatic speech recognition (ASR) is a fundamental technology in the field of artificial intelligence. End-to-end (E2E) ASR is favored for its state-of-the-art performance. However, E2E speech recognition still faces speech spatial information loss and text local information loss, which results in the increase of deletion and substitution errors during inference. To overcome this challenge, we propose a novel Enhancing Hybrid Architecture with Fast Attention and Capsule Network (termed En-HACN), which can model the position relationships between different acoustic unit features to improve the discriminability of speech features while providing the text local information during inference. Firstly, a new CNN-Capsule Network (CNN-Caps) module is proposed to capture the spatial information in the spectrogram through the capsule output and dynamic routing mechanism. Then, we design a novel hybrid structure of LocalGRU Augmented Decoder (LA-decoder) that generates text hidden representations to obtain text local information of the target sequences. Finally, we introduce fast attention instead of self-attention in En-HACN, which improves the generalization ability and efficiency of the model in long utterances. Experiments on corpora Aishell-1 and Librispeech demonstrate that our En-HACN has achieved the state-of-the-art compared with existing works. Besides, experiments on the long utterances dataset based on Aishell-1-long show that our model has a high generalization ability and efficiency.","2023","2025-02-26 20:41:54","2025-02-26 20:41:54","","1050-1062","","","31","","","","","","","","","","English","","","","WOS:000940155500006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","Automatic speech recognition; capsule network; conformer; end-to-end; fast attention mechanism; TRANSFORMER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SD99ASRD","journalArticle","2025","Li, PY; Hoi, LM; Wang, YP; Yang, X; Im, SK","Enhancing Speaker Recognition with CRET Model: a fusion of CONV2D, RESNET and ECAPA-TDNN","EURASIP JOURNAL ON AUDIO SPEECH AND MUSIC PROCESSING","","1687-4722","10.1186/s13636-025-00396-4","","In today's society, speaker recognition plays an increasingly important role. Currently, neural networks are widely employed for extracting speaker features. Although the Emphasized Channel Attention, Propagation, and Aggregation in Time Delay Neural Network (ECAPA-TDNN) model can obtain temporal context information through dilated convolution to some extent, this model falls short in acquiring fully comprehensive speech features. To further improve the accuracy of the model, better capture the temporal context information, and make ECAPA-TDNN unaffected by small offsets in the frequency domain, based on the ECAPA-TDNN model, we combine a two-dimensional convolutional network (Conv2D), a residual network (ResNet), and ECAPA-TDNN to form a novel CRET model. In this study, two CRET models are proposed, and these two models are compared with the baseline models Multi-Scale Backbone Architecture (Res2Net) and ECAPA-TDNN in different channels and different datasets. The experimental findings indicate that our proposed models exhibit strong performance across various experiments conducted on both training and test sets, even when the network layer is deep. Our model performs the best on the VoxCeleb2 dataset with 1024 channels, achieving an accuracy of 0.97828, an equal error rate (EER) of 0.03612 on the VoxCeleb1-O dataset, and a minimum detection cost function (MinDCF) of 0.43967. This technology can improve public safety and service efficiency in smart city construction, promote finance, education, and other fields, and bring more convenience to people's lives.","2025-02-14","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","1","2025","","","","","","","","","","English","","","","WOS:001421272900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Conv2D; ECAPA-TDNN; ResNet; Smart city; Speaker recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DRL7686V","journalArticle","2024","Jeong, SM; Kim, S; Lee, EC; Kim, HJ","Exploring Spectrogram-Based Audio Classification for Parkinson's Disease: A Study on Speech Classification and Qualitative Reliability Verification","SENSORS","","1424-8220","10.3390/s24144625","","Patients suffering from Parkinson's disease suffer from voice impairment. In this study, we introduce models to classify normal and Parkinson's patients using their speech. We used an AST (audio spectrogram transformer), a transformer-based speech classification model that has recently outperformed CNN-based models in many fields, and a CNN-based PSLA (pretraining, sampling, labeling, and aggregation), a high-performance model in the existing speech classification field, for the study. This study compares and analyzes the models from both quantitative and qualitative perspectives. First, qualitatively, PSLA outperformed AST by more than 4% in accuracy, and the AUC was also higher, with 94.16% for AST and 97.43% for PSLA. Furthermore, we qualitatively evaluated the ability of the models to capture the acoustic features of Parkinson's through various CAM (class activation map)-based XAI (eXplainable AI) models such as GradCAM and EigenCAM. Based on PSLA, we found that the model focuses well on the muffled frequency band of Parkinson's speech, and the heatmap analysis of false positives and false negatives shows that the speech features are also visually represented when the model actually makes incorrect predictions. The contribution of this paper is that we not only found a suitable model for diagnosing Parkinson's through speech using two different types of models but also validated the predictions of the model in practice.","2024-07","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","14","24","","","","","","","","","","English","","","","WOS:001277053300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","AST; explainable AI; Parkinson's disease; PSLA; speech classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y4IQ5Q6Z","journalArticle","2022","Wu, X; Zhou, SL; Chen, MW; Zhao, YH; Wang, YF; Zhao, XM; Li, DY; Pu, HB","Combined spectral and speech features for pig speech recognition","PLOS ONE","","1932-6203","10.1371/journal.pone.0276778","","The sound of the pig is one of its important signs, which can reflect various states such as hunger, pain or emotional state, and directly indicates the growth and health status of the pig. Existing speech recognition methods usually start with spectral features. The use of spectrograms to achieve classification of different speech sounds, while working well, may not be the best approach for solving such tasks with single-dimensional feature input. Based on the above assumptions, in order to more accurately grasp the situation of pigs and take timely measures to ensure the health status of pigs, this paper proposes a pig sound classification method based on the dual role of signal spectrum and speech. Spectrograms can visualize information about the characteristics of the sound under different time periods. The audio data are introduced, and the spectrogram features of the model input as well as the audio time-domain features are complemented with each other and passed into a pre-designed parallel network structure. The network model with the best results and the classifier were selected for combination. An accuracy of 93.39% was achieved on the pig speech classification task, while the AUC also reached 0.99163, demonstrating the superiority of the method. This study contributes to the direction of computer vision and acoustics by recognizing the sound of pigs. In addition, a total of 4,000 pig sound datasets in four categories are established in this paper to provide a research basis for later research scholars.","2022-12-01","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","12","17","","","","","","","","","","English","","","","WOS:000925734000036","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","CLASSIFICATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ING3JGD5","journalArticle","2024","Ochi, K; Kojima, M; Ono, N; Kuroda, M; Owada, K; Sagayama, S; Yamasue, H","Objective assessment of autism spectrum disorder based on performance in structured interpersonal acting-out tasks with prosodic stability and variability","AUTISM RESEARCH","","1939-3792","10.1002/aur.3080","","In this study, we sought to objectively and quantitatively characterize the prosodic features of autism spectrum disorder (ASD) via the characteristics of prosody in a newly developed structured speech experiment. Male adults with high-functioning ASD and age/intelligence-matched men with typical development (TD) were asked to read 29 brief scripts aloud in response to preceding auditory stimuli. To investigate whether (1) highly structured acting-out tasks can uncover the prosodic of difference between those with ASD and TD, and (2) the prosodic stableness and flexibleness can be used for objective automatic assessment of ASD, we compared prosodic features such as fundamental frequency, intensity, and mora duration. The results indicate that individuals with ASD exhibit stable pitch registers or volume levels in some affective vocal-expression scenarios, such as those involving anger or sadness, compared with TD and those with TD. However, unstable prosody was observed in some timing control or emphasis tasks in the participants with ASD. Automatic classification of the ASD and TD groups using a support vector machine (SVM) with speech features exhibited an accuracy of 90.4%. A machine learning-based assessment of the degree of ASD core symptoms using support vector regression (SVR) also had good performance. These results may inform the development of a new easy-to-use assessment tool for ASD core symptoms using recorded audio signals.","2024-02","2025-02-26 20:41:54","2025-02-26 20:41:54","","395-409","","2","17","","","","","","","","","","English","","","","WOS:001133103700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","ADULTS; affective vocal expression; autism; CHILDREN; COMMUNICATION; developmental disorder; INDIVIDUALS; objective assessment; prosody; speech; VERSION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NLIRUZHC","journalArticle","2022","Garg, A; Sahu, OP","Deep Convolutional Neural Network-based Speech Signal Enhancement Using Extensive Speech Features","INTERNATIONAL JOURNAL OF COMPUTATIONAL METHODS","","0219-8762","10.1142/S0219876221420056","","Speech signal often gets corrupted by different noises like airport noise, station noise, and street noise. These noises tend to degrade the quality of the speech signal, particularly in voice communication, automatic speech recognition, and speaker identification. Therefore, it is necessary for automatic speech enhancement. In this research work, a novel speech signal enhancement model is introduced with the assistance of deep learning. The proposed model includes three major phases: (a) pre-processing, (b) feature extraction, and (c) speech enhancement. In the pre-processing phase, the framing will be carried out using the Hanning window, where the input speech signals will be decomposed into a series of overlapping frames. Then, from these individual frames, the multi-features like the improved Mel-frequency cepstral coefficients (IMFCCs), fractional delta AMS, and modified STFT (M-STFT) will be extracted. Subsequently, in the speech enhancement phase, the available noise is estimated initially, and it is removed. The noise removed signals from the frames are used to determine the optimal mask of all the frames of the noisy speech signal, and the mask is employed for training the Deep Convolutional Neural Network (DCNN). The reconstructed outcomes from DCNN are the enhanced speech signal. Finally, the proposed work (multi-features+ DCNN-based Speech Enhancement) is validated over existing models in terms of certain measures, which exhibits the supremacy of the proposed work.","2022-10","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","08","19","","","","","","","","","","English","","","","WOS:000904844800007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","DCNN-based speech enhancement; FD-AMS features; FRAMEWORK; improved MFCC; MASKING; modified STFT features; NOISE; RECOGNITION; Speech enhancement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2ZULCYDX","journalArticle","2022","Wang, L","A Machine Learning Assessment System for Spoken English Based on Linear Predictive Coding","MOBILE INFORMATION SYSTEMS","","1574-017X","10.1155/2022/6131572","","In the teaching of English, there is an increasing focus on practical communication skills. As a result, the speaking test component has received more and more attention from education experts. With the rapid development of modern computer technology and network technology, the use of computers to assess the quality of spoken English has become a hot topic of research in related fields at present. A machine learning assessment system based on linear predictive coding is proposed in order to achieve automatic scoring of spoken English tests. First, the principle of linear predictive coding and decoding is analyzed, and the traditional linear predictive coding and decoding algorithm is improved by using hybrid excitation instead of the traditional binary excitation. Second, the overall structure of the machine learning assessment system is designed, which mainly includes division into four modules: acoustic model acquisition module, speech recognition module, standard pronunciation transcription module, and decision module. Then, the speech recognition module is implemented by an improved linear predictive speech coding method to acquire the feature parameters of the speech signal and generate the speech feature vector. Finally, the convolutional neural network algorithm is used to train the speech features so as to implement the acoustic model acquisition module. The experimental results show that the improved linear predictive speech coding method yields more natural and higher intelligibility speech signals. The designed machine learning evaluation system is able to accurately detect information about the quality of the learner's pronunciation.","2022-09-20","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","2022","","","","","","","","","","English","","","","WOS:000864695600006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","CNN; GMM; RECOGNITION; SPEAKING; SPEECH; VOICE CONVERSION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H9V9U2AR","journalArticle","2024","Han, ZJ; Shang, YY; Shao, ZH; Liu, JY; Guo, GD; Liu, T; Ding, H; Hu, Q","Spatial-Temporal Feature Network for Speech-Based Depression Recognition","IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS","","2379-8920","10.1109/TCDS.2023.3273614","","Depression is a serious mental disorder that has received increased attention from society. Due to the advantage of easy acquisition of speech, researchers have tried to propose various automatic depression recognition algorithms based on speech. Feature selection and algorithm design are the main difficulties in speech-based depression recognition. In our work, we propose the spatial-temporal feature network (STFN) for depression recognition, which can capture the long-term temporal dependence of audio sequences. First, to obtain a better feature representation for depression analysis, we develop a self-supervised learning framework, called vector quantized wav2vec transformer net (VQWTNet) to map speech features and phonemes with transfer learning. Second, the stacked gated residual blocks in the spatial feature extraction network are used in the model to integrate causal and dilated convolutions to capture multiscale contextual information by continuously expanding the receptive field. In addition, instead of LSTM, our method employs the hierarchical contrastive predictive coding (HCPC) loss in HCPCNet to capture the long-term temporal dependencies of speech, reducing the number of parameters while making the network easier to train. Finally, experimental results on DAIC-WOZ (Audio/Visual Emotion Challenge (AVEC) 2017) and E-DAIC (AVEC 2019) show that the proposed model significantly improves the accuracy of depression recognition. On both data sets, the performance of our method far exceeds the baseline and achieves competitive results compared to state-of-the-art methods.","2024-02","2025-02-26 20:41:54","2025-02-26 20:41:54","","308-318","","1","16","","","","","","","","","","English","","","","WOS:001167556100010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","Convolutional neural network (CNN); deep learning; depression recognition; long short-term memory network; speech recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EE3GH6SW","journalArticle","2024","Kong, SS; Li, CM; Fang, CW; Yang, P","Building a Speech Dataset and Recognition Model for the Minority Tu Language","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14156795","","Speech recognition technology has many applications in our daily life. However, for many low-resource languages without written forms, acquiring sufficient training data remains a significant challenge for building accurate ASR models. The Tu language, spoken by an ethnic minority group in Qinghai Province in China, is one such example. Due to the lack of written records and the great diversity in regional pronunciations, there has been little previous research on Tu-language speech recognition. This work seeks to address this research gap by creating the first speech dataset for the Tu language spoken in Huzhu County, Qinghai. We first formulated the relevant pronunciation rules for the Tu language based on linguistic analysis. Then, we constructed a new speech corpus, named HZ-TuDs, through targeted data collection and annotation. Based on the HZ-TuDs dataset, we designed several baseline sequence-to-sequence deep neural models for end-to-end Tu-language speech recognition. Additionally, we proposed a novel SA-conformer model, which combines convolutional and channel attention modules to better extract speech features. Experiments showed that our proposed SA-conformer model can significantly reduce the character error rate from 23% to 12%, effectively improving the accuracy of Tu language recognition compared to previous approaches. This demonstrates the effectiveness of our dataset construction and model design efforts in advancing speech recognition technology for this low-resource minority language.","2024-08","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","15","14","","","","","","","","","","English","","","","WOS:001287195500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","automatic speech recognition; conformer; low-resource language; Tu language","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LWPHCGBD","journalArticle","2022","Dua, S; Kumar, SS; Albagory, Y; Ramalingam, R; Dumka, A; Singh, R; Rashid, M; Gehlot, A; Alshamrani, SS; AlGhamdi, AS","Developing a Speech Recognition System for Recognizing Tonal Speech Signals Using a Convolutional Neural Network","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app12126223","","Deep learning-based machine learning models have shown significant results in speech recognition and numerous vision-related tasks. The performance of the present speech-to-text model relies upon the hyperparameters used in this research work. In this research work, it is shown that convolutional neural networks (CNNs) can model raw and tonal speech signals. Their performance is on par with existing recognition systems. This study extends the role of the CNN-based approach to robust and uncommon speech signals (tonal) using its own designed database for target research. The main objective of this research work was to develop a speech-to-text recognition system to recognize the tonal speech signals of Gurbani hymns using a CNN. Further, the CNN model, with six layers of 2DConv, 2DMax Pooling, and 256 dense layer units (Google's TensorFlow service) was also used in this work, as well as Praat for speech segmentation. Feature extraction was enforced using the MFCC feature extraction technique, which extracts standard speech features and features of background music as well. Our study reveals that the CNN-based method for identifying tonal speech sentences and adding instrumental knowledge performs better than the existing and conventional approaches. The experimental results demonstrate the significant performance of the present CNN architecture by providing an 89.15% accuracy rate and a 10.56% WER for continuous and extensive vocabulary sentences of speech signals with different tones.","2022-06","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","12","12","","","","","","","","","","English","","","","WOS:000816092400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;26<br/>Total Times Cited:&nbsp;&nbsp;26<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Convolutional neural network; feature extraction; machine learning; Praat; speech recognition; speech signal; word error rate","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G35Z5EKA","journalArticle","2025","Buric, F; Viknander, S; Fu, XZ; Lemke, O; Carmona, OG; Zrimec, J; Szyrwiel, L; Mülleder, M; Ralser, M; Zelezniak, A","Amino acid sequence encodes protein abundance shaped by protein stability at reduced synthesis cost","PROTEIN SCIENCE","","0961-8368","10.1002/pro.5239","","Understanding what drives protein abundance is essential to biology, medicine, and biotechnology. Driven by evolutionary selection, an amino acid sequence is tailored to meet the required abundance of a proteome, underscoring the intricate relationship between sequence and functional demand. Yet, the specific role of amino acid sequences in determining proteome abundance remains elusive. Here we show that the amino acid sequence alone encodes over half of protein abundance variation across all domains of life, ranging from bacteria to mouse and human. With an attempt to go beyond predictions, we trained a manageable-size Transformer model to interpret latent factors predictive of protein abundances. Intuitively, the model's attention focused on the protein's structural features linked to stability and metabolic costs related to protein synthesis. To probe these relationships, we introduce MGEM (Mutation Guided by an Embedded Manifold), a methodology for guiding protein abundance through sequence modifications. We find that mutations which increase predicted abundance have significantly altered protein polarity and hydrophobicity, underscoring a connection between protein structural features and abundance. Through molecular dynamics simulations we revealed that abundance-enhancing mutations possibly contribute to protein thermostability by increasing rigidity, which occurs at a lower synthesis cost.","2025-01","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","1","34","","","","","","","","","","English","","","","WOS:001374869900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;165</p>","","","CODON USAGE; CONFORMATIONAL STABILITY; deep learning; EFFICIENCY; EVOLUTION; explainable machine learning; GENE-EXPRESSION; language models; LEVEL; molecular dynamics; MOLECULAR-DYNAMICS SIMULATIONS; protein engineering; protein expression; protein sequence; protein stability; proteome; SACCHAROMYCES-CEREVISIAE; SECONDARY STRUCTURE; SELECTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZS4B6JNA","journalArticle","2025","Wang, ZY; Xu, H; Zhang, MM; Cai, ZR; Chen, YY","RFID-transformer recognition system (RTRS): enhancing privacy in facial recognition with transformer models","SENSOR REVIEW","","0260-2288","10.1108/SR-07-2024-0659","","Purpose - This paper aims to present a novel approach to facial recognition that enhances privacy by using radio frequency identification (RFID) technology combined with transformer models, eliminating the need for visual data and thus reducing privacy risks associated with traditional image-based systems. Design/methodology/approach - The proposed RFID-transformer recognition system (RTRS) uses RFID technology to capture signal features such as phase and received signal strength indicator, which are then processed by a transformer model. The model is specifically designed to handle structured RFID data, capturing subtle patterns and dependencies to achieve accurate biometric recognition. The system's performance was validated through comprehensive experiments involving different environmental conditions and user scenarios. Findings - The experimental results demonstrate that the RTRS system achieves a recognition accuracy of 98.91%, maintaining robust performance across various challenging conditions, including low-light environments and changes in face orientation. In addition, the system provides a high level of privacy preservation by avoiding the collection and storage of visual data. Originality/value - To the best of the authors' knowledge, this work introduces the first RFID-based facial recognition system that fully leverages transformer models, offering a privacy-preserving alternative to traditional image-based methods. The system's ability to perform accurately in diverse scenarios while ensuring user privacy makes it a significant advancement in biometric technology.","2025-01-02","2025-02-26 20:41:54","2025-02-26 20:41:54","","17-30","","1","45","","","","","","","","","","English","","","","WOS:001322375500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","Biometric systems; FACE RECOGNITION; Facial recognition; Privacy preservation; RFID technology; Transformer models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WI43FN9C","journalArticle","2024","Cui, XY; Sun, B; Zhu, Y; Yang, N; Zhang, HF; Cui, WC; Fan, DX; Wang, J","Enhancing efficiency and propulsion in bio-mimetic robotic fish through end-to-end deep reinforcement learning","PHYSICS OF FLUIDS","","1070-6631","10.1063/5.0192993","","Aquatic organisms are known for their ability to generate efficient propulsion with low energy expenditure. While existing research has sought to leverage bio-inspired structures to reduce energy costs in underwater robotics, the crucial role of control policies in enhancing efficiency has often been overlooked. In this study, we optimize the motion of a bio-mimetic robotic fish using deep reinforcement learning (DRL) to maximize propulsion efficiency and minimize energy consumption. Our novel DRL approach incorporates extended pressure perception, a transformer model processing sequences of observations, and a policy transfer scheme. Notably, significantly improved training stability and speed within our approach allow for end-to-end training of the robotic fish. This enables agiler responses to hydrodynamic environments and possesses greater optimization potential compared to pre-defined motion pattern controls. Our experiments are conducted on a serially connected rigid robotic fish in a free stream with a Reynolds number of 6000 using computational fluid dynamics simulations. The DRL-trained policies yield impressive results, demonstrating both high efficiency and propulsion. The policies also showcase the agent's embodiment, skillfully utilizing its body structure and engaging with surrounding fluid dynamics, as revealed through flow analysis. This study provides valuable insights into the bio-mimetic underwater robots optimization through DRL training, capitalizing on their structural advantages, and ultimately contributing to more efficient underwater propulsion systems.","2024-03","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","3","36","","","","","","","","","","English","","","","WOS:001187954900005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","CARTESIAN-GRID SIMULATIONS; MULTIJOINT; OPTIMIZATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GUFG243M","journalArticle","2024","Guven, G; Ates, HF; Ugurdag, HF","X2V: 3D Organ Volume Reconstruction From a Planar X-Ray Image With Neural Implicit Methods","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3385668","","In this work, an innovative approach is proposed for three-dimensional (3D) organ volume reconstruction from a single planar X-ray, namely X2V network. Such capability holds pivotal clinical potential, especially in real-time image-guided radiotherapy, computer-aided surgery, and patient follow-up sessions. Traditional methods for 3D volume reconstruction from X-rays often require the utilization of statistical 3D organ templates, which are employed in 2D/3D registration. However, these methods may not accurately account for the variation in organ shapes across different subjects. Our X2V model overcomes this problem by leveraging neural implicit representation. A vision transformer model is integrated as an encoder network, specifically designed to direct and enhance attention to particular regions within the X-ray image. The reconstructed meshes exhibit a similar topology to the ground truth organ volume, demonstrating the ability of X2V in accurately capturing the 3D structure from a 2D image. The effectiveness of X2V is evaluated on lung X-rays using several metrics, including volumetric Intersection over Union (IoU). X2V outperforms the state-of-the-art method in the literature for lungs (DeepOrganNet) by about 7-9% achieving IoU's between 0.892-0.942 versus DeepOrganNet's IoU of 0.815-0.888.","2024","2025-02-26 20:41:54","2025-02-26 20:41:54","","50898-50910","","","12","","","","","","","","","","English","","","","WOS:001204821600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","3D organ topology; 3D reconstruction; neural implicit methods; PLATFORM; SLICER; vision transformers; X-ray","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HWRHCKJR","journalArticle","2023","Zhang, YY; Li, YC; Qu, Q; Lin, H; Seng, D","Enhancing Drowning Surveillance with a Hybrid Vision Transformer Model: A Deep Learning Approach","TRAITEMENT DU SIGNAL","","0765-0019","10.18280/ts.400647","","Annually, drowning claims the lives of approximately 372,200 individuals worldwide, averaging 40 fatalities per hour. In response, various technological advancements have been explored, including deep learning-based video and image processing, and wearable devices integrated with human pulse sensors and Light emitting diode (LED)/Liquid-crystal display (LCD) technologies. Despite these efforts, existing solutions have yet to fully address the challenge of accurate drowning detection. This study introduces a novel approach, leveraging a hybrid model that combines a traditional Vision Transformer (ViT) with plain Convolutional Neural Networks (CNNs). This model demonstrates a notable accuracy of 91.5% on a specialized dataset comprising 14,736 images of swimming and drowning scenarios, surpassing conventional methods in efficiency and size. In contrast to larger models like Swin-B, which comprises 88M parameters and achieves a marginally higher accuracy of 92.3%, the proposed model maintains high performance with only 5.9M parameters. The model's development involved pre-training on the ImageNet1K dataset, followed by fine-tuning using the specifically curated local dataset. The resultant system offers a cost-effective, efficient, and compact solution for drowning detection, suitable for various applications. This advancement in drowning surveillance technology highlights the potential of integrating ViT with CNNs in creating effective, resource-efficient models for critical real-world applications.","2023-12","2025-02-26 20:41:54","2025-02-26 20:41:54","","2861-2867","","6","40","","","","","","","","","","English","","","","WOS:001137494800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","CNN; deep learning; drowning surveillance; machine learning; ViT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9642284C","journalArticle","2023","Tubaishat, A; Zia, T; Faiz, R; Al Obediat, F; Shah, B; Windridge, D","Discriminator-based adversarial networks for knowledge graph completion","NEURAL COMPUTING & APPLICATIONS","","0941-0643","10.1007/s00521-022-07680-w","","Knowledge graphs (KGs) inherently lack reasoning ability which limits their effectiveness for tasks such as question-answering and query expansion. KG embedding (KGE) is a predominant approach where proximity between relations and entities in the embedding space is used for reasoning over KGs. Most existing KGE approaches use structural information of triplets and disregard contextual information which could be crucial to learning long-term relations between entities. Moreover, KGE approaches mostly use discriminative models which require both positive and negative samples to learn a decision boundary. KGs, by contrast, contain only positive samples, necessitating that negative samples are generated by replacing the head/tail of predicates with randomly chosen entities. They are thus usually irrational and easily discriminable from positive samples, which can prevent the learning of sufficiently robust classifiers. To address the shortcomings, we propose to learn contextualized KGE using pre-trained adversarial networks. We assume multi-hop relational paths(mh-RPs) as textual sequences for competitively learning discriminator-based KGE against the negative mh-RP generator. We use a pre-trained ELECTRA model and feed it with relational paths. We employ a generator to corrupt randomly chosen entities with plausible alternatives and a discriminator to predict whether an entity is corrupted or not. We perform experiments on multiple benchmark knowledge graphs, and the results show that our proposed KG-ELECTRA model outperforms BERT in link prediction.","2023-04","2025-02-26 20:41:54","2025-02-26 20:41:54","","7975-7987","","11","35","","","","","","","","","","English","","","","WOS:000838484500004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Knowledge graph completion; Pre-trained language model; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NJGGDKKV","journalArticle","2021","Bai, Y; Yi, JY; Tao, JH; Tian, ZK; Wen, ZQ; Zhang, S","Fast End-to-End Speech Recognition Via Non-Autoregressive Models and Cross-Modal Knowledge Transferring From BERT","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2021.3082299","","Attention-based encoder-decoder (AED) models have achieved promising performance in speech recognition. However, because the decoder predicts text tokens (such as characters or words) in an autoregressive manner, it is difficult for an AED model to predict all tokens in parallel. This makes the inference speed relatively slow. In contrast, we propose an end-to-end non-autoregressive speech recognition model called LASO (Listen Attentively, and Spell Once). The model aggregates encoded speech features into the hidden representations corresponding to each token with attention mechanisms. Thus, the model can capture the token relations by self-attention on the aggregated hidden representations from the whole speech signal rather than autoregressive modeling on tokens. Without explicitly autoregressive language modeling, this model predicts all tokens in the sequence in parallel so that the inference is efficient. Moreover, we propose a cross-modal transfer learning method to use a text-modal language model to improve the performance of speech-modal LASO by aligning token semantics. We conduct experiments on two scales of public Chinese speech datasets AISHELL-1 and AISHELL-2. Experimental results show that our proposed model achieves a speedup of about 50x and competitive performance, compared with the autoregressive transformer models. And the cross-modal knowledge transferring from the text-modal model can improve the performance of the speech-modal model.","2021","2025-02-26 20:41:54","2025-02-26 20:41:54","","1897-1911","","","29","","","","","","","","","","English","","","","WOS:000663524400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;34<br/>Total Times Cited:&nbsp;&nbsp;39<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","ASR; attention; ATTENTION; BERT; cross-modal; end-to-end; fast; NETWORKS; non-autoregressive; Speech recognition; transfer learning; TRANSFORMER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8TLZFNH3","journalArticle","2022","Ma, RS; Ng, SI; Lee, T; Yang, YJ; Sum, RKW","Validation of a Speech Database for Assessing College Students' Physical Competence under the Concept of Physical Literacy","INTERNATIONAL JOURNAL OF ENVIRONMENTAL RESEARCH AND PUBLIC HEALTH","","1660-4601","10.3390/ijerph19127046","","This study developed a speech database for assessing one of the elements of physical literacy-physical competence. Thirty-one healthy and native Cantonese speakers were instructed to read a material aloud after various exercises. The speech database contained four types of speech, which were collected at rest and after three exercises of the Canadian Assessment of Physical Literacy 2nd Edition. To show the possibility of detecting each exercise state, a support vector machine (SVM) was trained on the acoustic features. Two speech feature sets, the extended Geneva Minimalistic Acoustic Parameter Set (eGeMAPS) and Computational Paralinguistics Challenge (ComParE), were utilized to perform speech signal processing. The results showed that the two stage four-class SVM were better than the stage one. The performances of both feature sets could achieve 70% accuracy (unweighted average recall (UAR)) in the three-class model after five-fold cross-validation. The UAR result of the resting and vigorous state on the two-class model running with the ComParE feature set was 97%, and the UAR of the resting and moderate state was 74%. This study introduced the process of constructing a speech database and a method that can achieve the short-time automatic classification of physical states. Future work on this corpus, including the prediction of the physical competence of young people, comparison of speech features with other age groups and further spectral analysis, are suggested.","2022-06","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","12","19","","","","","","","","","","English","","","","WOS:000817754800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","CROSS-VALIDATION; machine learning; MODEL; physical competence; physical literacy; RELIABILITY; speech database; STRESS; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9SQBF3TR","journalArticle","2024","Williams, K","Exploring English for academic purposes instructors' perceptions of speech fluency through developing and piloting a rating scale for a paired conversational task","SYSTEM","","0346-251X","10.1016/j.system.2024.103266","","Much research has explored how perceptions of speech fluency are influenced by a variety of temporal speech features (e.g. speech rate). However, less is known about the influence of nontemporal and conversational speech characteristics on fluency perceptions. To address this gap, this study explored English for Academic Purposes (EAP) instructors' perceptions of speech fluency through developing and piloting a rating scale for a paired conversational task for assessment for learning purposes. A two-phase mixed-methods sequential exploratory design (Creswell, 2009) was used. Seven trained EAP instructors watched videos of seven-minute conversations, elicited from 14 intermediate-to-advanced EAP learners. Afterwards, instructors were audio-recorded discussing their observations about learners' fluency. These recordings were transcribed and coded using in-vivo and pattern coding techniques (Saldan similar to a, 2009). Six themes were identified: efficiency, smoothness, sophistication, clarity, facilitating topics and turns, and supporting the conversation partner. These themes informed the development of a multi-item fluency rating scale. 35 EAP instructors then used the scale to rate eight learners' speeches. To investigate the construct-relevance of these scale items, a principal component analysis was conducted, producing two components - individual fluency and conversational fluency. Pedagogical activities aligned with the scale are provided.","2024-04","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","121","","","","","","","","","","English","","","","WOS:001198968700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Assessment for learning; CLASSROOM; Classroom -based assessment; English for academic purposes; Interactional competence; L2 FLUENCY; Language learning pedagogy; Mixed -methods; ORAL FLUENCY; PAUSES; Rater perceptions; Rating scale design; Speech fluency; Task -based pedagogy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"98JSZD54","journalArticle","2022","Dubagunta, SP; van Son, RJJH; Magimai-Doss, M","Adjustable deterministic pseudonymization of speech","COMPUTER SPEECH AND LANGUAGE","","0885-2308","10.1016/j.csl.2021.101284","","While public speech resources become increasingly available, there is a growing interest to preserve the privacy of the speakers, through methods that anonymize the speaker information from speech while preserving the spoken linguistic content. In this paper, a method for pseudonymization (reversible anonymization) of speech is presented, that allows to obfuscate the speaker identity in untranscribed running speech. The approach manipulates the spectrotemporal structure of the speech to simulate a different length and structure of the vocal tract by modifying the formant locations, as well as by altering the pitch and speaking rate. The method is deterministic and partially reversible, and the changes are adjustable on a continuous scale. The method has been evaluated in terms of (i) ABX listening experiments, and (ii) automatic speaker verification and speech recognition. ABX experimental results indicate that the speaker identifiability among forced choice pairs reduced from over 90% to less than 70% through pseudonymization, and that de-pseudonymization was partially effective. An evaluation on the VoicePrivacy 2020 challenge data showed that the proposed approach performs better than the signal processing based baseline method that uses McAdams coefficient and performs slightly worse than the neural source filtering based baseline method. Further analysis showed that the proposed approach: (i) is comparable to the neural source filtering baseline based method in terms of phone posterior feature based objective intelligibility measure, (ii) preserves formant tracks better than the McAdams based method, and (iii) preserves paralinguistic aspects such as dysarthria in several speakers.","2022-03","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","72","","","","","","","","","","English","","","","WOS:000728821200003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","ARTICULATION; IDENTIFICATION; Speech features; Speech privacy; Speech pseudonymization; Speech signal processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EL95AVB8","journalArticle","2021","Sadoughi, N; Busso, C","Speech-Driven Expressive Talking Lips with Conditional Sequential Generative Adversarial Networks","IEEE TRANSACTIONS ON AFFECTIVE COMPUTING","","1949-3045","10.1109/TAFFC.2019.2916031","","Articulation, emotion, and personality play strong roles in the orofacial movements. To improve the naturalness and expressiveness of virtual agents (VAs), it is important that we carefully model the complex interplay between these factors. This paper proposes a conditional generative adversarial network, called conditional sequential GAN (CSG), which learns the relationship between emotion, lexical content and lip movements in a principled manner. This model uses a set of spectral and emotional speech features directly extracted from the speech signal as conditioning inputs, generating realistic movements. A key feature of the approach is that it is a speech-driven framework that does not require transcripts. Our experiments show the superiority of this model over three state-of-the-art baselines in terms of objective and subjective evaluations. When the target emotion is known, we propose to create emotionally dependent models by either adapting the base model with the target emotional data (CSG-Emo-Adapted), or adding emotional conditions as the input of the model (CSG-Emo-Aware). Objective evaluations of these models show improvements for the CSG-Emo-Adapted compared with the CSG model, as the trajectory sequences are closer to the original sequences. Subjective evaluations show significantly better results for this model compared with the CSG model when the target emotion is happiness.","2021-10-01","2025-02-26 20:41:54","2025-02-26 20:41:54","","1031-1044","","4","12","","","","","","","","","","English","","","","WOS:000722000100016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;27<br/>Total Times Cited:&nbsp;&nbsp;28<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Adaptation models; Data models; expressive and naturalistic lip movements; generative adversarial network; Hidden Markov models; lip movements; Lips; Shape; Speech-driven model; Training; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6H952V3H","journalArticle","2024","Li, X; Liu, RR; Huang, HC; Wu, QY","Contrastive Learning for Target Speaker Extraction With Attention-Based Fusion","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2023.3324550","","Given a reference speech clip from the target speaker, Target Speaker Extraction (TSE) is a challenging task that involves extracting the signal of the target speaker from a multi-speaker environment. TSE networks typically comprise a main network and an auxiliary network. The former utilizes the obtained target speaker embedding to generate an appropriate mask for isolating the signal of the target speaker from those of other speakers, while the latter aims to learn deep discriminative embeddings from the signal of the target speaker. However, the TSE networks often face performance degradation when dealing with unseen speakers or speeches with short references. In this article, we propose a novel approach that leverages contrastive learning in the auxiliary network to obtain better representations of unseen speakers or speeches with short references. Specifically, we employ contrastive learning to bridge the gap between short and long speech features. In this case, the auxiliary network with the input of a short speech generates feature embeddings that are as rich as those obtained from a long speech. Therefore, improving the recognition of unseen speakers or short speeches. Moreover, we introduce an attention-based fusion method that integrates the speaker embedding into the main network in an adaptive manner for enhancing mask generation. Experimental results demonstrate the effectiveness of our proposed method in improving the performance of TSE tasks in realistic open scenarios.","2024","2025-02-26 20:41:54","2025-02-26 20:41:54","","178-188","","","32","","","","","","","","","","English","","","","WOS:001102787200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","attention; contrastive learning; Decoding; Degradation; Feature extraction; self-supervised learning; Speaker extraction; Speech enhancement; Task analysis; Transformers; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZATGGKDA","journalArticle","2024","Sen, SY; Cura, OK; Yilmaz, GC; Akan, A","Classification of Alzheimer's dementia EEG signals using deep learning","TRANSACTIONS OF THE INSTITUTE OF MEASUREMENT AND CONTROL","","0142-3312","10.1177/01423312241267046","","Alzheimer's dementia (AD) is a predominant neurological disorder arising from corruptions in brain functions and is characterized by a chronic or progressive nature. While the precise etiology of dementia remains incompletely elucidated, its manifestation is frequently associated with discernible structural and chemical alterations in the brain. Living with dementia significantly impacts individuals' daily lives due to the resultant loss of cognitive functions. This study presents a novel method to monitor and detect AD using advanced signal processing applied to electroencephalography (EEG) signals. The intrinsic time-scale decomposition (ITD) algorithm is employed to extract proper rotation components (PRCs) from EEG signals, utilizing a 5-second EEG segment duration. The proposed method is compared with the detection of 5-second raw EEG segments using a custom one-dimensional convolutional neural network (1D CNN). Additionally, four different quartiles (Quartile 1 (Q1), Q2, Q3, and Q4) of EEG signals are considered to identify the most significant contributor to AD. Experimental results demonstrate that the ITD-based approach yields better detection performance compared to using raw EEG signals. The most promising result is achieved by the EEG-PRCs method in Q1, with an accuracy of 94.00%, sensitivity of 93.50%, and specificity of 93.90%. In contrast, the highest-performing result of the raw EEG segments method is in Q2, with an accuracy of 88.40%, sensitivity of 89.10%, and specificity of 87.60% in terms of detecting AD.","2024-08-13","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","","","","","","","","","","","English","","","","WOS:001290595800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Alzheimer's dementia detection; decomposition; DECOMPOSITION; deep learning; DISEASE; EEG signals; hyper-parameter tuning; one-dimensional convolutional neural networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P9YJ4R4P","journalArticle","2025","Ishiwata, A; Nogami, A; Nishimura, T; Kanamaru, T; Suzuki, K; Suda, S","Cognitive assessment in patients with acute stroke: Exploring early intervention for dementia","CLINICAL NEUROLOGY AND NEUROSURGERY","","0303-8467","10.1016/j.clineuro.2025.108748","","Background: Early detection of cognitive impairment in patients with acute stroke could improve dementia treatment; however, such testing is uncommon. This study aimed to assess cognitive testing feasibility in patients with acute stroke and identify patient characteristics associated with testing ability. Methods: 291 patients with suspected acute stroke were admitted to our hospital between December 2016 and May 2017. Of these, 280 were diagnosed with stroke (median [interquartile range] age 73 [63-81] years; 70 % male; 11 % with prior cognitive decline) and included in the study. Patients able or unable to complete three cognitive function tests were classified as the testable or untestable group, respectively. Results: Among the 280 patients, 72 % completed all three cognitive tests a mean of 4 [3-5] days after onset. Significant differences were found between the testable and untestable groups, particularly in age (70 [61-80] vs. 77 [69-84], p < 0.0001), Informant Questionnaire on Cognitive Decline in the Elderly score (78 [78-83] vs. 84 [78-96], p = 0.012), and National Institutes of Health Stroke Scale (NIHSS) score at onset (3 [1-6] vs. 13 [4-18], p < 0.0001). Advanced age, a higher NIHSS score, and pre-stroke cognitive decline were independent risk factors for the inability to undergo testing. Conclusions: Cognitive testing was feasible in 72 % of patients with acute stroke, particularly those who were younger, had normal pre-stroke cognitive function, and experienced mild strokes. Early cognitive assessment may enable timely dementia detection and treatment.","2025-02","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","249","","","","","","","","","","English","","","","WOS:001408718000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","Acute stroke; BRIEF SCREENING TOOL; Early dementia intervention; IMPAIRMENT; ISCHEMIC-STROKE; Mini-Mental State Examination; MOCA; Montreal Cognitive Assessment; Neuropsychological examination","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PTGY49KN","journalArticle","2021","Hashim, NNWN; Ezzi, MAEA; Wilkes, MD","Mobile microphone robust acoustic feature identification using coefficient of variance","INTERNATIONAL JOURNAL OF SPEECH TECHNOLOGY","","1381-2416","10.1007/s10772-021-09877-1","","One of the most challenging techniques for speech analysis applications in mobile phones is acoustic feature extraction. The adverse environment noises, diversity of microphone specifications, and various recording software have a significant effect on the values of the extracted acoustic features. In this study, we investigate the robustness of different types of acoustic features related to time-based, frequency-based, and sustained vowel using 11 different mobile recording devices. 49 recordings of subjects reciting the Rainbow Passage and 25 recordings of sustained vowel /a/ were collected. By way of synchronous recording, we analyzed and compared the extracted 253-dimensional acoustic feature vectors in order to examine how consistent the data values between the different recording devices. The variability of data values was measured using the method of coefficient of variance. Data values with low variability were identified to be from features such as the transition parameters, amplitude modulation, contrast, Chroma, mean fundamental frequency and formants. These groups of features turn out to be more reliable than others in their dependency on the recording device specifications.","2021-12","2025-02-26 20:41:54","2025-02-26 20:41:54","","1089-1100","","4","24","","","","","","","","","","English","","","","WOS:000680375200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","Acoustic features; Microphones; RECOGNITION; Recording; Robust features; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KY2WC8GS","journalArticle","2021","Piatek, Z; Klaczynski, M","Acoustic Methods in Identifying Symptoms of Emotional States","ARCHIVES OF ACOUSTICS","","0137-5075","10.24425/aoa.2021.136580","","The study investigates the use of speech signal to recognise speakers' emotional states. The introduction includes the definition and categorization of emotions, including facial expressions, speech and physiological signals. For the purpose of this work, a proprietary resource of emotionally-marked speech recordings was created. The collected recordings come from the media, including live journalistic broadcasts, which show spontaneous emotional reactions to real-time stimuli. For the purpose of signal speech analysis, a specific script was written in Python. Its algorithm includes the parameterization of speech recordings and determination of features correlated with emotional content in speech. After the parametrization process, data clustering was performed to allows for the grouping of feature vectors for speakers into greater collections which imitate specific emotional states. Using the t-Student test for dependent samples, some descriptors were distinguished, which identified significant differences in the values of features between emotional states. Some potential applications for this research were proposed, as well as other development directions for future studies of the topic.","2021","2025-02-26 20:41:54","2025-02-26 20:41:54","","259-269","","2","46","","","","","","","","","","English","","","","WOS:000658708400007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","clustering analysis; emotion recognition; RECOGNITION; Sammon mapping; SPEECH; speech signal processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N6ZFTMJS","journalArticle","2023","Liu, LC; Li, W; Morris, S; Zhuang, MT","Knowledge-Based Features for Speech Analysis and Classification: Pronunciation Diagnoses","ELECTRONICS","","2079-9292","10.3390/electronics12092055","","Accurate pronunciation of speech sounds is essential in communication. As children learn their native language, they refine the movements necessary for intelligible speech. While there is variability in the order of acquisition of speech sounds, there are some sounds that are more complex and are later developing. The rhotic /r/ is a later-developing sound in English, and some children require intervention to achieve accurate production. Additionally, individuals learning English as a second language may have difficulty learning accurate /r/ production, especially if their native language does not have an /r/, or the /r/ they produce is at a different place of articulation. The goal of this research is to provide a novel approach on how a knowledge-based intelligence program can provide immediate feedback on the accuracy of productions. In the proposed approach, the audio signals will first be detected, after which features of audio signals will be extracted, and finally, knowledge-based intelligent classification will be performed. Based on the obtained knowledge and application scenarios, novel features are proposed and used to classify various speaker scenarios.","2023-04-29","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","9","12","","","","","","","","","","English","","","","WOS:000987187800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","analysis; CHILDREN; classification; features; feedback; knowledge; pronunciation; speech signal","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JKH2PNKD","journalArticle","2022","Gibson, J; Oh, H","A Reinforcement Learning Approach to Speech Coding","INFORMATION","","2078-2489","10.3390/info13070331","","Speech coding is an essential technology for digital cellular communications, voice over IP, and video conferencing systems. For more than 25 years, the main approach to speech coding for these applications has been block-based analysis-by-synthesis linear predictive coding. An alternative approach that has been less successful is sample-by-sample tree coding of speech. We reformulate this latter approach as a multistage reinforcement learning problem with L step lookahead that incorporates exploration and exploitation to adapt model parameters and to control the speech analysis/synthesis process on a sample-by-sample basis. The minimization of the spectrally shaped reconstruction error to finite depth manages complexity and serves as an effective stand in for the overall subjective evaluation of reconstructed speech quality and intelligibility. Different control policies that attempt to persistently excite the system states and that encourage exploration are studied and evaluated. The resulting methods produce reconstructed speech quality competitive with the most popular speech codec utilized today. This new reinforcement learning formulation provides new insights and opens up new directions for system design and performance improvement.","2022-07","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","7","13","","","","","","","","","","English","","","","WOS:000833393000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","ADAPTIVE PREDICTION; dual control; exploitation; exploration; reinforcement learning; speech coding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IXWCQBC8","journalArticle","2022","Levy, J; Naitsat, A; Zeevi, YY","Classification of audio signals using spectrogram surfaces and extrinsic distortion measures","EURASIP JOURNAL ON ADVANCES IN SIGNAL PROCESSING","","1687-6180","10.1186/s13634-022-00933-9","","Representation of one-dimensional (1D) signals as surfaces and higher-dimensional manifolds reveals geometric structures that can enhance assessment of signal similarity and classification of large sets of signals. Motivated by this observation, we propose a novel robust algorithm for extraction of geometric features, by mapping the obtained geometric objects into a reference domain. This yields a set of highly descriptive features that are instrumental in feature engineering and in analysis of 1D signals. Two examples illustrate applications of our approach to well-structured audio signals: Lung sounds were chosen because of the interest in respiratory pathologies caused by the coronavirus and environmental conditions; accent detection was selected as a challenging speech analysis problem. Our approach outperformed baseline models under all measured metrics. It can be further extended by considering higher-dimensional distortion measures. We provide access to the code for those who are interested in other applications and different setups (Code: https://github.com/jeremy-levy/Class ification-of-audio-signals-using-spectrogram-surfaces-and-extrinsic-distortion-measures).","2022-10-22","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","1","2022","","","","","","","","","","English","","","","WOS:000871192200003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","1D signal processing; Classification; DEEP NEURAL-NETWORKS; Distortions measure; Geometric feature engineering; Manifold; REPRESENTATION; Spectrogram embedding; Surfaces","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WNE7V5EC","journalArticle","2023","Spitzley, LA; Wang, XR; Chen, XY; Pentland, SJ; Nunamaker, JF; Burgoon, JK; Dunbar, NE","Non-Invasive Measurement of Trust in Group Interactions","IEEE TRANSACTIONS ON AFFECTIVE COMPUTING","","1949-3045","10.1109/TAFFC.2022.3160132","","Trust between group members has many implications for how well a group performs. In this study, we predict perceived trustworthiness of group members when there are subversive group members. We collected multimodal verbal and nonverbal data from a group interaction experiment. During the interaction, we periodically surveyed the group members about their perceptions of trustworthiness of other group members. We used this data to model the relationship between observable behavior and perceptions of trustworthiness. We report the most predictive features and describe them in the context of existing literature on verbal and nonverbal correlates of trust. This research advances the study of behavioral measurement in groups and the role of behavior on perceived trustworthiness.","2023-07","2025-02-26 20:41:54","2025-02-26 20:41:54","","2389-2401","","3","14","","","","","","","","","","English","","","","WOS:001075041900051","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Affective computing; BEHAVIOR; Complexity theory; CUES; Current measurement; DECEPTION; H.3.1.d Linguistic processing; History; IMPACT; INTIMACY; JUDGMENTS; L.2.0.u Multimodal systems; Linguistics; O.1.1 Nonverbal signals; O.1.2.b Speech analysis; O.1.2.c Paralanguage analysis; O.1.4 Multi-modal recognition; O.1.5 Recognition of group emotion; PERCEPTIONS; Task analysis; TRUSTWORTHINESS; Uncertainty; VOICE PITCH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WKJSYX43","journalArticle","2023","Braz, AC; Marques, IS","Manipulation of Facts and Opinions. The Presidential Debate between Marcelo Rebelo de Sousa and Andre Ventura (2021)","LINHA D AGUA","","0103-3638","10.11606/issn.2236-4242.v36i2p90-105","","This work aims to propose a linguistic and discursive analysis of the argumentation and persuasion strategies predominant in the debate of January 6, 2021 for the presidential elections in Portugal. The study focuses on the manipulation strategies of the speakers and candidates. We focus on the nature of manipulation objects, as well as on the configurations that this manipulation assumes in the discursive genre in question and its purposes. We examine the appeal to emotions, values and change made by the two candidates. The objects of study are the images (ethos) that political opponents build of themselves and the other in and through discourse, the emotions (pathos) that their words arouse, the main axiological values of the lexemes and expressions used, and the modes of refutation of facts and points of view convened. This study is part of the perspective of discourse analysis, as well as the framework of the study of argumentation, namely argumentation in political discourse.","2023-05","2025-02-26 20:41:54","2025-02-26 20:41:54","","90-105","","2","36","","","","","","","","","","English","","","","WOS:001124232500004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","Argumentation and Persuasion Strategies; Ethos; Pathos; Presidential elections; Speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WL6SZWZ2","journalArticle","2021","Sidorova, J; Karlsson, S; Rosander, O; Berthier, ML; Moreno-Torres, I","Towards Disorder-Independent Automatic Assessment of Emotional Competence in Neurological Patients with a Classical Emotion Recognition System: Application in Foreign Accent Syndrome","IEEE TRANSACTIONS ON AFFECTIVE COMPUTING","","1949-3045","10.1109/TAFFC.2019.2908365","","Emotive speech is a non-invasive and cost-effective biomarker in a wide spectrum of neurological disorders with computational systems built to automate the diagnosis. In order to explore the possibilities for the automation of a routine speech analysis in the presence of hard to learn pathology patterns, we propose a framework to assess the level of competence in paralinguistic communication. Initially, the assessment relies on a perceptual experiment completed by human listeners, and a model called the Aggregated Ear has been proposed that draws a conclusion about the level of competence demonstrated by the patient. Then, the automation of the Aggregated Ear has been undertaken and resulted in a computational model that summarizes the portfolio of speech evidence on the patient. The summarizing system has a classical emotion recognition system as its central component. The code and the data are available from the corresponding author on request.","2021-10-01","2025-02-26 20:41:54","2025-02-26 20:41:54","","962-973","","4","12","","","","","","","","","","English","","","","WOS:000722000100011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Biomarker; CLASSIFICATION; Computational modeling; DEVELOPMENTAL DISORDERS; Ear; emotion recognition; Emotion recognition; foreign accent syndrome; LOAD; Neurological diseases; paralinguistic competence; PARKINSONS-DISEASE; Pathology; Portfolios; speech; SPEECH; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WY8L7WA5","journalArticle","2023","Delage, H; Stanford, E; Baratti, C; Durrleman, S","Working memory training in children with developmental language disorder: Effects on complex syntax in narratives","FRONTIERS IN REHABILITATION SCIENCES","","2673-6861","10.3389/fresc.2022.1068959","","This study assesses the impact of a working memory training program on the syntactic complexity of the spontaneous speech of French-speaking children with Developmental Language Disorder (DLD). Thirty-nine 6- to 12-year-old children with DLD were allocated to a WM training (DLDMM, N = 20) or an active control group (DLDSQULA, N = 19). The computerized training sessions took place three times a week, yielding 12 training hours per participant. Syntactic complexity was assessed in storytelling, measuring mean length of utterances, use of embedded clauses and rate of errors in complex utterances. The performance of participants with DLD was first compared to previous spontaneous data of 40 typically-developing (TD) children of the same age. Then, intragroup (pre- vs. post-test) and intergroup (DLDMM vs. DLDSQULA) comparisons were made to assess the impact of the working memory training on the language measures. Global results confirmed syntactic impairment in children with DLD, as opposed to TD children, with large differences for the use of embedded clauses. Findings also suggested gains in the mastery of embedded clauses in children who participated in the WM training, whereas no gains were observed in the DLD control group. These findings confirm deficits in complex syntax in children with DLD, in particular in embedded clauses, and may encourage the clinical use of language sample analysis, which provides an ecological account of children's language performance. While our results should be replicated on a larger scale, they also suggest positive transfer effects of working memory training on the capacity of participants with DLD to produce embedded clauses, in line with previous studies showing a positive effect of WM training on tasks of expressive syntax. It thus seems that working memory training can yield benefits for language, which leaves open the door to new therapeutic approaches for children with DLD.","2023-01-04","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","3","","","","","","","","","","English","","","","WOS:001006643700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;113</p>","","","children; DEFICITS; developmental language disorder (DLD); EXECUTIVE FUNCTION; IMPAIRMENT SLI; INTERVENTION; narratives; PERFORMANCE; RELATIVE CLAUSES; REPETITION; SCHOOL-AGE-CHILDREN; SENTENCE COMPREHENSION; SHORT-TERM-MEMORY; syntax; training; working memory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F88QZS6M","journalArticle","2024","Al-Ali, A; Al-Maadeed, S; Saleh, M; Naidu, RC; Alex, ZC; Ramachandran, P; Khoodeeram, R; Kumar, MR","The Detection of Dysarthria Severity Levels Using AI Models: A Review","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3382574","","Dysarthria, a speech disorder stemming from neurological conditions, affects communication and life quality. Precise classification and severity assessment are pivotal for therapy but are often subjective in traditional speech-language pathologist evaluations. Machine learning models offer objective assessment potential, enhancing diagnostic precision. This systematic review aims to comprehensively analyze current methodologies for classifying dysarthria based on severity levels, highlighting effective features for automatic classification and optimal AI techniques. We systematically reviewed the literature on the automatic classification of dysarthria severity levels. Sources of information will include electronic databases and grey literature. Selection criteria will be established based on relevance to the research questions. The findings of this systematic review will contribute to the current understanding of dysarthria classification, inform future research, and support the development of improved diagnostic tools. The implications of these findings could be significant in advancing patient care and improving therapeutic outcomes for individuals affected by dysarthria.","2024","2025-02-26 20:41:54","2025-02-26 20:41:54","","48223-48238","","","12","","","","","","","","","","English","","","","WOS:001197754200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;108</p>","","","Artificial intelligence; artificial intelligence (AI)-based models; classification; CLASSIFICATION; Classification algorithms; DATABASE; Dysarthria; Feature extraction; FEATURES; INDIVIDUALS; intelligibility; INTELLIGIBILITY ASSESSMENT; Lips; Medical services; Neurological diseases; SELECTION; severity levels; Spectrogram; Speech analysis; Speech processing; SPEECH-INTELLIGIBILITY; TIME","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DKTM2HAP","journalArticle","2021","Huang, GX; Ni, A; Lu, WD; Peng, H; Wang, JW","Parameters Measurement of Multiple Exponentially Damped Sinusoids With Sub-Nyquist Sampling","IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS II-EXPRESS BRIEFS","","1549-7747","10.1109/TCSII.2021.3055938","","Measurement of parameters of multiple exponentially damped sinusoids (MEDS) signals is significant for nuclear magnetic resonance imaging and speech analysis systems. Traditional technologies require a large number of samples and heavy processing burden to estimate the parameters. In this brief, we propose a sub-Nyquist sampling and parameters estimation scheme for MEDS signals to address this problem. The proposed system consists of two parallel sampling channels, where the sampling clock of one channel is staggered with the other. The first sampling channel is used to estimate complex amplitudes, while the other is used to solve frequency ambiguity problem and determine the damping factors and pole frequencies. The proposed scheme enables parameters measurement of K components MEDS signals from as few as 3K samples, and it is also applicable to the scenario with unknown K. We also propose a hardware prototype to implement the proposed system. Simulation and experimental results demonstrate the effectiveness and noise robustness of the proposed scheme.","2021-07","2025-02-26 20:41:54","2025-02-26 20:41:54","","2710-2714","","7","68","","","","","","","","","","English","","","","WOS:000668856000094","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;16</p>","","","frequency ambiguity; FREQUENCY ESTIMATION; multi-channel; multiple exponentially damped sinusoids (MEDS); Parameters measurement; sub-Nyquist sampling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T5BKTA8W","journalArticle","2021","Powroznik, P; Wojcicki, P; Przylucki, SW","Scalogram as a Representation of Emotional Speech","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2021.3127581","","It is very hard to implement the emotion recognition system based on spoken text. Computer applications have a huge problem with understanding non-literal meaning of statements as well as irony or a situational joke. The article describes how to represent emotional speech in the form of scalograms which are the result of speech signal processing by Discrete Wavelet Transform (DTW). The method of processing scalograms in order to extract input data for natural language processing algorithms in order to recognise the emotional state is also presented. The following emotional states were considered during the research: joy, anger, boredom, sadness, fear and neutral state. The developed method has been tested on databases containing recordings of emotional speech in the following languages: Polish, English, German and Danish. Depending on the language and classifier used, obtained results ranged from over 62% to over 94%. The use of fuzzy classifiers greatly improves the time and efficiency of classification.","2021","2025-02-26 20:41:54","2025-02-26 20:41:54","","154044-154057","","","9","","","","","","","","","","English","","","","WOS:000721991600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","Databases; DIAGNOSIS; Discrete wavelet transforms; emotion recognition; Emotion recognition; fuzzy neural networks; Hidden Markov models; Mel frequency cepstral coefficient; RECOGNITION; speech analysis; Speech processing; Speech recognition; Task analysis; WAVELET TRANSFORM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R5QVFAL7","journalArticle","2023","Pereira, PH; Beccaro, W; Ramírez, MA","Evaluating Robustness to Noise and Compression of Deep Neural Networks for Keyword Spotting","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3280477","","Keyword Spotting (KWS) has been the subject of research in recent years given the increase of embedded systems for command recognition such as Alexa, Google Home, and Siri. Performance, model size, processing time, and robustness to noise are fundamental in these systems. Furthermore, applications in embedded systems demand computationally efficient models that can be implemented in current technology. In this work, an approach for keyword recognition is evaluated using three deep learning models namely LeNet-5, SqueezeNet, and EfficientNet-B0. We evaluate transfer learning, pruning and quantization strategies in training and test using noisy and clean speech signals. In addition, compression techniques such as pruning and quantization were assessed in terms of the size reduction of the model footprint and the accuracy obtained in each case. Using the Google's Speech Commands dataset and additive babble noise signal, our keyword recognition approach achieves an accuracy of 94.6% using an unstructured pruning of 80% of the parameters of the original SqueezeNet network with a reduction of 70% in the model size.","2023","2025-02-26 20:41:54","2025-02-26 20:41:54","","53224-53236","","","11","","","","","","","","","","English","","","","WOS:001005640600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","ALGORITHM; keyword spotting; machine learning algorithms; pruning; quantization; RECOGNITION; spectral analysis; speech analysis; Speech recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"87UHFV52","journalArticle","2021","François, J; Albakry, M","Effect of formulaic sequences on fluency of English learners in standardized speaking tests","LANGUAGE LEARNING & TECHNOLOGY","","1094-3501","","","While fluency in second language speaking can be a challenging construct to measure, it is important to identify the discourse features that contribute to it. This small-scale classroom research project examined the effect of formulaic language sequences on fluency as measured by computer-based speaking tasks of young English learners. Thirty-six speech samples were collected as apart of standard instruction in grades 5-8 in a medium-sized public school district in the Southeastern US. The speech samples were analyzed using Praat speech analysis software to identify the mean length of fluent run for fluency and coded formulaic language sequences for discourse function. Findings indicated that the use of formulaic sequences is a significant predictor of fluency in the data set (p = .015) and that the most frequently used formulaic sequences were those used for clarification and to compare and contrast. Finally, the article discusses pedagogical implications for second language instruction, specifically for improving fluency on standardized computer-based speaking assessments.","2021-06","2025-02-26 20:41:54","2025-02-26 20:41:54","","26-41","","2","25","","","","","","","","","","English","","","","WOS:000667163800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","2ND-LANGUAGE; Computer-based Speaking Assessments; Fluency; Formulaic Sequences; LANGUAGE; PROFICIENCY; SPEAKERS; SPEECH; Young English Learners","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K84EB7DN","journalArticle","2024","Liu, F","An interactional linguistics study of Shi ba in Mandarin conversation","DISCOURSE STUDIES","","1461-4456","10.1177/14614456241285897","","From the perspective of interactional linguistics and adopting the methodology of conversation analysis, this study explores some fine-grained interactional uses of shi ba in Mandarin conversation. It first classifies shi ba into unmarked and marked forms generally in terms of their prosodic manifestations with the assistance of Praat, the speech analysis tool. Then it demonstrates that the unmarked shi ba fulfills three interactional functions: requesting confirmation, seeking affiliation and maintaining floor; the marked shi ba registers dissatisfaction and displays affiliation. However, shi ba is basically a tag question, and serves to invite the recipient to proffer certain interactional response. The specific function that shi ba performs in conversation is tied to three decisive factors - its prosodic manifestations, position in specific turns and sequences as well as the relative epistemic status of interlocutors. The study also suggests that there lies a common motivation for the emergence of various interactional functions of shi ba, that is - the demand for an on-line alignment, which reflects the cross-fertilization between language and interaction.","2024-10-06","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","","","","","","","","","","","English","","","","WOS:001339898900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","epistemic status; interactional functions; ORGANIZATION; position in turns and sequences; prosodic manifestations; shi ba; TAG QUESTIONS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2UPJ3SS2","journalArticle","2024","Huang, JH; Zhou, J; Tang, ZC; Lin, JY; Chen, CYC","TMBL: Transformer-based multimodal binding learning model for multimodal sentiment analysis","KNOWLEDGE-BASED SYSTEMS","","0950-7051","10.1016/j.knosys.2023.111346","","Multimodal emotion analysis is an important endeavor in human-computer interaction research, as it enables the accurate identification of an individual's emotional state by simultaneously analyzing text, video, and sound features. Although current emotion recognition algorithms have performed well using multimodal fusion strategies, two key challenges remain. The first challenge is the efficient extraction of modalityinvariant and modality -specific features prior to fusion, which requires deep feature interactions between the different modalities. The second challenge concerns the ability to distinguish high-level semantic relations between modality features. To address these issues, we propose a new modality -binding learning framework and redesign the internal structure of the transformer model. Our proposed modality binding learning model addresses the first challenge by incorporating bimodal and trimodal binding mechanisms. These mechanisms handle modality -specific and modality -invariant features, respectively, and facilitate crossmodality interactions. Furthermore, we enhance feature interactions by introducing fine-grained convolution modules in the feedforward and attention layers of the transformer structure. To address the second issue, we introduce CLS and PE feature vectors for modality -invariant and modality -specific features, respectively. We use similarity loss and dissimilarity loss to support model convergence. Experiments on the widely used MOSI and MOSEI datasets show that our proposed method outperforms state-of-the-art multimodal sentiment classification approaches, confirming its effectiveness and superiority. The source code can be found at https://github.com/JackAILab/TMBL.","2024-02-15","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","285","","","","","","","","","","English","","","","WOS:001153463400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","Modality binding learning; Modality-invariant; Multimodal fusion; Multimodal sentiment analysis; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MTL427CC","journalArticle","2023","Liu, JZ; Yuan, HQ; Yuan, ZQ; Liu, L; Lu, B; Yu, M","Visual transformer with stable prior and patch-level attention for single image dehazing","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2023.126535","","Single-image dehazing aims to recover blurred image details and improve image quality, which is a challenging ill-posed problem due to severe information degradation. In the image dehazing task, extracting local features from adjacent regions is particularly important. However, Transformer-based methods lack relative awareness of patch-level features. Furthermore, due to the sensitivity of self-attention to textcolorreddata distribution, the model suffers severe performance degradation when migrating from synthetic domain to real domain. To alleviate the above problems, we propose visual transformer with stable prior and patch-level attention (VSPPA) for image dehazing. Firstly, we propose a region-aware patch-level attention module to obtain the positional correlation between local patches and contexts, which can enhance the concentration of local patch-related features. Next, due to the instability problem caused by distribution shifts, we introduce dataset-independent prior to guide the transformer model, thereby preventing feature drift thus to improve the robustness of the model. Finally, domain-drift leads to insufficient dehazing when the model trained on synthetic data while migrates to the real environment, we come up with a introduce a patch filling strategy (PFS) for fuzzy data to narrow the domain gap and realize the generalization in real scenes. Extensive experiments show that the model achieves State-of-the Art on the SOTS synthetic dataset and effective generalization to real-world scenarios.& COPY; 2023 Elsevier B.V. All rights reserved.","2023-09-28","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","551","","","","","","","","","","English","","","","WOS:001040094100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Patch filling strategy; Patch-level attention; Prior information; Single-image dehazing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H2T9L3W9","journalArticle","2023","Barut, O; Luo, Y; Li, PL; Zhang, T","R1DIT: Privacy-Preserving Malware Traffic Classification With Attention-Based Neural Networks","IEEE TRANSACTIONS ON NETWORK AND SERVICE MANAGEMENT","","1932-4537","10.1109/TNSM.2022.3211254","","With the advances in deep learning techniques and the increase in the volume of network traffic data, deep neural networks trained directly with the raw traffic data have become more popular and successful for malware traffic classification without explicit feature extraction. However, most of the existing studies raises privacy concerns when using the payload data and ignore the generalization of the model to the newly emerged traffic such as DDoS detection on TLS 1.3. To overcome these limitations, we introduce a malware traffic classification system, Residual 1-D Image Transformer (R1DIT) model. We first leverage network domain knowledge by carefully parsing IP, HTTP, DNS, and unencrypted TLS record headers as sequences of bytes for input without interfering with IP addresses, port numbers and the payload. Then, we apply raw data transform and attention-based modules in our deep model to classify different malware types and benign traffic. Our results on NetML dataset show that the proposed model delivers 0.972 F1 score, nearly 0.3 higher than the feature-based methods and outperforms state-of-the-art models with 0.9999 F1 score for multi-class malware classification task using CICIDS2017 dataset. The generalization of this model has been proven using the TLS 1.3 traffic obtained from CICDDoS2019 dataset with the detection rate 0.9897 using meta-learning.","2023-06","2025-02-26 20:41:54","2025-02-26 20:41:54","","2071-2085","","2","20","","","","","","","","","","English","","","","WOS:001022694300085","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","deep learning; DEEP LEARNING APPROACH; Flow-based network intrusion detection; image transformer model; malware traffic classification; meta learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JIV2DDY3","journalArticle","2023","Sun, ZX; Qu, LH; Luo, JZ; Song, ZJ; Wang, MN","Label correlation transformer for automated chest X-ray diagnosis with reliable interpretability","RADIOLOGIA MEDICA","","0033-8362","10.1007/s11547-023-01647-0","","Computer-aided diagnosis of chest X-ray (CXR) images can help reduce the huge workload of radiologists and avoid the inter-observer variability in large-scale early disease screening. Recently, most state-of-the-art studies employ deep learning techniques to address this problem through multi-label classification. However, existing methods still suffer from low classification accuracy and poor interpretability for each diagnostic task. This study aims to propose a novel transformer-based deep learning model for automated CXR diagnosis with high performance and reliable interpretability. We introduce a novel transformer architecture into this problem and utilize the unique query structure of transformer to capture the global and local information of the images and the correlation between labels. In addition, we propose a new loss function to help the model find correlations between the labels in CXR images. To achieve accurate and reliable interpretability, we generate heatmaps using the proposed transformer model and compare with the true pathogenic regions labeled by the physicians. The proposed model achieves a mean AUC of 0.831 on chest X-ray 14 and 0.875 on PadChest dataset, which outperforms existing state-of-the-art methods. The attention heatmaps show that our model could focus on the exact corresponding areas of related truly labeled pathogenic regions. The proposed model effectively improves the performance of CXR multi-label classification and the interpretability of label correlations, thus providing new evidence and methods for automated clinical diagnosis.","2023-06","2025-02-26 20:41:54","2025-02-26 20:41:54","","726-733","","6","128","","","","","","","","","","English","","","","WOS:000995291100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","Chest X-ray; CLASSIFICATION; Interpretability; Label correlation; Multi-label; NETWORK; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PMKXSKKC","journalArticle","2023","Lee, SM; Kim, DY; Woo, J","Glucose Transformer: Forecasting Glucose Level and Events of Hyperglycemia and Hypoglycemia","IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS","","2168-2194","10.1109/JBHI.2023.3236822","","To avoid the adverse consequences from abrupt increases in blood glucose, diabetic inpatients should be closely monitored. Using blood glucose data from type 2 diabetes patients, we propose a deep learning model-based framework to forecast blood glucose levels. We used continuous glucose monitoring (CGM) data collected from inpatients with type 2 diabetes for a week. We adopted the Transformer model, commonly used in sequence data, to forecast the blood glucose level over time and detect hyperglycemia and hypoglycemia in advance. We expected the attention mechanism in Transformer to reveal a hint of hyperglycemia and hypoglycemia, and performed a comparative study to determine whether Transformer was effective in the classification and regression of glucose. Hyperglycemia and hypoglycemia rarely occur and this results in an imbalance in the classification. We built a data augmentation model using the generative adversarial network. Our contributions are as follows. First, we developed a deep learning framework utilizing the encoder part of Transformer to perform the regression and classification under a unified framework. Second, we adopted a data augmentation model using the generative adversarial network suitable for time-series data to solve the data imbalance problem and to improve performance. Third, we collected data for type 2 diabetic inpatients for mid-time. Finally, we incorporated transfer learning to improve the performance of regression and classification.","2023-03","2025-02-26 20:41:54","2025-02-26 20:41:54","","1600-1611","","3","27","","","","","","","","","","English","","","","WOS:000965215800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Blood; continuous glucose monitoring; Data models; deep learning; Diabetes; Glucose; hyperglycemia; hypoglycemia; Monitoring; NEURAL-NETWORKS; Predictive models; Transformer; Transformers; Type 2 diabetes","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M5WNF92V","journalArticle","2023","Kozhirbayev, Z","Kazakh Speech Recognition: Wav2vec2.0 vs. Whisper","JOURNAL OF ADVANCES IN INFORMATION TECHNOLOGY","","1798-2340","10.12720/jait.14.6.1382-1389","","In recent years, the progress made in neural models trained on extensive multilingual text or speech data has shown great potential for improving the status of underresourced languages. This paper focuses on experimenting with three state-of-the-art speech recognition models, namely Facebook's Wav2Vec2.0 and Wav2Vec2-LS-R, OpenAI's Whisper, on the Kazakh language. The objective of this research is to investigate the effectiveness of these models in transcribing Kazakh speech and to compare their performance with existing supervised Automatic Speech Recognition (ASR) systems. The study also aims to explore the possibility of using data from other languages for pre-training and to test whether fine-tuning the target language data can improve model performance. Thus, this work can provide insights into the effectiveness of using pretrained multilingual models in underresourced language settings. The wav2vec2.0 model achieved a Character Error Rate (CER) of 2.8 and a Word Error Rate (WER) of 8.7 on the test set, which closely matches the best result achieved by the end-to-end Transformer model. The large whisper model achieves a CER of approximately 4 on the test set. The results of this study can contribute to the development of robust and efficient ASR systems for the Kazakh language, benefiting various applications, including speech-to-text translation, voice assistants, and speech-based communication tools.","2023","2025-02-26 20:41:54","2025-02-26 20:41:54","","1382-1389","","6","14","","","","","","","","","","English","","","","WOS:001167619100017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","automatic speech recognition; pretrained transformer models; speech representation models; Wav2Vec 2.0; Wav2Vec2-XLS-R; whisper","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZDTJI6N3","journalArticle","2024","Qin, F; Chen, W; Nie, X; Wu, W; Dong, YY","Broadband Port Circuit Model for Distribution Transformers Based on Frequency Impedance Analysis","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3383470","","Building a broadband equivalent circuit model of a transformer is highly significant for studying the characteristics of high-altitude electromagnetic pulse conduction environments in real scenarios and guiding the high-altitude electromagnetic pulse effect tests of power equipment. This paper utilized an impedance analyzer to obtain the port impedance characteristics of distribution transformers with two insulation forms and five capacities within the range of 20Hz to 30MHz, based on the concept of passive system circuit modelling. By analysing the impedance characteristics of passive circuit components and observing the trend of changes in the port impedance curve, broadband port circuit models were constructed for both the high-voltage and low-voltage sides of transformers. Model parameter acquisition methods using a combination of function fitting and resonance point characteristics were provided. A high-altitude electromagnetic pulse injection test platform was constructed to verify the accuracy of the transformer model through comparison. Finally, the influence of transformer capacity and insulation form on the parameters of the transformer broadband port model was summarized. The results demonstrate that the proposed broadband port equivalent circuit model is suitable for different types and capacities of distribution transformers and can be employed to investigate the characteristics of high-altitude electromagnetic pulse conduction environments in transmission and distribution lines.","2024","2025-02-26 20:41:54","2025-02-26 20:41:54","","47559-47567","","","12","","","","","","","","","","English","","","","WOS:001197743300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","broadband model; conduction environment; Distribution transformer; Equivalent circuits; high-altitude electromagnetic pulse; Impedance; Integrated circuit modeling; Oil insulation; Power transformer insulation; Resonant frequency; sweep impedance; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TEK3RF38","journalArticle","2023","Li, M; Miao, ZJ; Lu, YY","LabanFormer: Multi-scale graph attention network and transformer with gated recurrent positional encoding for labanotation generation","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2023.03.064","","Labanotation is a widely-used notation system for recording human dance movements. Automatically generating Labanotation scores from motion capture data can save significant manual effort and help the preservation of old folk dances in protecting intangible cultural heritages. Existing Labanotation gen-eration methods have limited ability to capture the flexible limb movements as well as the rich periodic, symmetric, or repeated dance steps. In this paper, we present a novel LabanFormer model including a Multi-Scale Graph Attention network (MS-GAT) and a transformer model with Gated Recurrent Positional Encoding (GRPE) to achieve more effective Labanotation generation. First, the proposed MS-GAT can capture flexible limb movements by learning feature correlations between every two joints and aggregating features of neighboring joints over multiple scales. Second, we propose a new GRPE-based transformer to learn global temporal dependencies in the output feature sequences of MS-GAT. The novel GRPE module can encode position information with learnable parameters while handling var-ious sequence lengths. As such, the periodic, symmetric, or repeated steps in dances can be accurately captured. Finally, the corresponding Laban symbols are generated by the decoder of the GRPE-based transformer. Extensive experiments on two real-world datasets show that the proposed LabanFormer model obtains remarkable performance compared with state-of-the-art approaches on the automatic Labanotation generation task. (c) 2023 Elsevier B.V. All rights reserved.","2023-06-28","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","539","","","","","","","","","","English","","","","WOS:000984984000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","FUSION; Gated recurrent positional encoding; Graph attention network; Labanotation generation; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9B8TWLKH","journalArticle","2023","Liao, JP; Li, CH; Huang, ZH","A Lightweight Swin Transformer-Based Pipeline for Optical Coherence Tomography Image Denoising in Skin Application","PHOTONICS","","2304-6732","10.3390/photonics10040468","","Optical coherence tomography (OCT) has attracted attention in dermatology applications for skin disease characterization and diagnosis because it provides high-resolution (<10 mu m) of tissue non-invasively with high imaging speed (2-8 s). However, the quality of OCT images can be significantly degraded by speckle noise, which results from light waves scattering in multiple directions. This noise can hinder the accuracy of disease diagnosis, and the conventional frame averaging method requires multiple repeated (e.g., four to six) scans, which is time consuming and introduces motion artifacts. To overcome these limitations, we proposed a lightweight U-shape Swin (LUSwin) transformer-based denoising pipeline to recover high-quality OCT images from the noisy OCT images by utilizing a fast one-repeated OCT scan. In terms of the peak signal-to-noise-ratio (PSNR) performance, the results reveal that the denoised images from the LUSwin transformer (26.92) are of a higher quality than the four-repeated frame-averaging method (26.19). Compared to the state-of-the-art networks in image denoising, the proposed LUSwin transformer has the smallest floating points operation (3.9299 G) and has the second highest PSNR results, only 0.02 lower than the Swin-UNet, which has the highest PSNR results (26.94). This study demonstrates that the transformer model has the capacity to denoise the noisy OCT image from a fast one-repeated OCT scan.","2023-04","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","4","10","","","","","","","","","","English","","","","WOS:000978008300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","ALGORITHM; deep learning; DIAGNOSIS; image denoising; optical coherence tomography (OCT)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MG3PSWUR","journalArticle","2023","Shi, LK; Zhao, RY; Pan, B; Zou, ZX; Shi, ZW","Unsupervised Multimodal Remote Sensing Image Registration via Domain Adaptation","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2023.3333889","","Registration of multimodal remote sensing images with geometric distortions is one of the fundamental applications, but it remains difficult since multimodal remote sensing images have significant differences in both radiometric and geometric features. One of the challenges is the disregarding of modality-specific information, which hinders the model from focusing on the content information of structure and texture due to differences in radiometric features. In this article, an unsupervised content-focused hierarchical alignment network (CHA-Net) is proposed, which is constructed based on the theory of domain adaptation. The kernel idea of CHA-Net is to weaken the style differences among different modal images and achieve nonrigid multimodal remote sensing image registration. CHA-Net is a hierarchical refinement model, where different scales of features are aligned, respectively, by utilizing the field calibration module (FCM) and gradually generating the registration field. To be specific, CHA-Net consists of two structures: the Siamese feature decoupling (SFD) structure and the hierarchical refinement alignment (HRA) structure. The SFD aims at reducing the style differences caused by cross-modal differences and developing a shared-weight Siamese network to map images to content feature space. The HRA enhances the ability of the network by capturing global distortions based on the transformer model. Experiments on public datasets indicate that compared with other methods, CHA-Net performs better when geometric and radiometric distortions appear.","2023","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","61","","","","","","","","","","English","","","","WOS:001142604800014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Calibration; DEEP; Distortion; Domain adaptation; FUSION; hierarchical alignment; Image registration; Imaging; multimodal image registration; Remote sensing; remote sensing images; Sensors; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IWZR4EQC","journalArticle","2022","Alotaibi, SS; Munshi, AA; Farag, AT; Rakha, OE; Al Sallab, AA; Alotaibi, M","KAB: Knowledge Augmented BERT2BERT Automated Questions-Answering system for Jurisprudential Legal Opinions","INTERNATIONAL JOURNAL OF COMPUTER SCIENCE AND NETWORK SECURITY","","1738-7906","10.22937/IJCSNS.2022.22.6.44","","The jurisprudential legal rules govern the way Muslims react and interact to daily life. This creates a huge stream of questions, that require highly qualified and well-educated individuals, called Muftis. With Muslims representing almost 25% of the planet population, and the scarcity of qualified Muftis, this creates a demand supply problem calling for Automation solutions. This motivates the application of Artificial Intelligence (AI) to solve this problem, which requires a well-designed Question-Answering (QA) system to solve it. In this work, we propose a QA system, based on retrieval augmented generative transformer model for jurisprudential legal question. The main idea in the proposed architecture is the leverage of both state-of-the art transformer models, and the existing knowledge base of legal sources and question-answers. With the sensitivity of the domain in mind, due to its importance in Muslims daily lives, our design balances between exploitation of knowledge bases, and exploration provided by the generative transformer models. We collect a custom data set of 850,000 entries, that includes the question, answer, and category of the question. Our evaluation methodology is based on both quantitative and qualitative methods. We use metrics like BERTScore and METEOR to evaluate the precision and recall of the system. We also provide many qualitative results that show the quality of the generated answers, and how relevant they are to the asked questions.","2022-06-30","2025-02-26 20:41:54","2025-02-26 20:41:54","","346-356","","6","22","","","","","","","","","","English","","","","WOS:000820962300044","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Islamic Fatwa; Natural Language Processing; Question Answering; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C5N4F564","journalArticle","2024","Rawf, KMH; Karim, SHT; Abdulrahman, AO; Ghafoor, KJ","Dataset for the recognition of Kurdish sound dialects","DATA IN BRIEF","","2352-3409","10.1016/j.dib.2024.110231","","Dialect recognition System (DRS) is a highly significant subject within the field of speech analysis. The performance of speech recognition systems is adversely impacted by factors such as the age, gender, and dialect features of the speaker. In order to address variations in dialect, it is possible to incorporate DRS into speech recognition systems. The system can be configured to utilize the appropriate speech recognition model based on the identification of the spoken dialect. Currently, there is a lack of available datasets suitable for the development of automatic dialect recognition systems specifically tailored for the Kurdish language. The proposed dataset under consideration is assessed using experimental data that has been gathered by personnel associated with the Computer Science Department at the University of Halabja. As the Kurdish language has three main dialects: Northern Kurdish (Badini variation), Central Kurdish (Sorani variant), and Hawrami, three dialects are included in the dataset. Published by Elsevier Inc. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ )","2024-04","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","53","","","","","","","","","","English","","","","WOS:001195607200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;9</p>","","","Badini; Dialect recognition; Hawrami; Kurdish dialect; Sorani","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VHQ8IRJ8","journalArticle","2022","Barretto, RS; Duarte, M; Figueiredo, AEB","13 Years Later: Dialogues on Voluntary Termination of Pregnancy in Portugal","CIENCIA & SAUDE COLETIVA","","1413-8123","10.1590/1413-81232022274.06162021","","Law 16/2007 represented a milestone in the quest for sexual and reproductive rights of Portuguese citizens, instituting the possibility of excluding all illegality for voluntary termination of pregnancy, performed until the 10th week, at the request of the women involved. Using a des-criptive-analytical research, the objective was to establish the opinion of citizens and researchers (active in the cause), in the course of this process and the transformations that resulted from it, with emphasis on the current context. Between March and September, 12 interviews were conducted, di-vided into two stages. When the Discourse Analy-sis techniques were analyzed, there were some weak points, such as the uncertainty about access, the presence of judgments and the limitations in-terposed by the conscientious objectors, which re-flect the need to expand the allowed gestational period for termination. There was recognition of security in procedures, women???s freedom in their choices, greater openness to dialogue, a fact that contributed jointly with the strengthening of fa-mily planning. In addition to these constructions, new demands were configured.","2022-04","2025-02-26 20:41:54","2025-02-26 20:41:54","","1525-1534","","4","27","","","","","","","","","","English","","","","WOS:000803756300022","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","Health; Portugal; Society; Speech analysis; Voluntary termination of pregnancy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PPIFB7SE","journalArticle","2025","O'Shaughnessy, D","Spoken language identification: An overview of past and present research trends","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2024.103167","","Identification of the language used in spoken utterances is useful for multiple applications, e.g., assist in directing or automating telephone calls, or selecting which language-specific speech recognizer to use. This paper reviews modern methods of automatic language identification. It examines what information in speech helps to distinguish among languages, and extends these ideas to dialect estimation as well. As approaches to recognize languages often share much in common with both automatic speech recognition and speaker verification, these three processes are compared. Many methods are drawn from pattern recognition research in other areas, such as image and text recognition. This paper notes how speech is different from most other signals to recognize, and how language identification differs from other speech applications. While it is mainly addressed to readers who are not experts in speech processing (as detailed algorithms, readily found in the cited literature, are omitted here), the presentation covers a wide discussion useful to experts too.","2025-02","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","167","","","","","","","","","","English","","","","WOS:001394000500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;88</p>","","","FEATURES; Machine learning; Neural networks; NEURAL-NETWORKS; Pattern recognition; RECOGNITION; REPRESENTATIONS; SPEAKER; Speech analysis; Spoken language identification; TUTORIAL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YH688ISF","journalArticle","2022","Huynh, TN; Lin, CJ; Hwang, GJ","Learner-generated material: the effects of ubiquitous photography on foreign language speaking performance","ETR&D-EDUCATIONAL TECHNOLOGY RESEARCH AND DEVELOPMENT","","1042-1629","10.1007/s11423-022-10149-1","","The widespread availability of mobile phones has facilitated mobile learning and ubiquitous learning in language education. Although numerous benefits have been documented, the evidence for speaking fluency enhancement is relatively scant. Firmly grounded in humans' cognitive structure and learners' prior knowledge, this study proposes a ubiquitous photography strategy as a form of generative learning strategy. Specifically, besides the photos in English textbooks, foreign language (FL) learners at the college level were encouraged to use their mobile phones to capture photos to practice visual prompted oral tasks. Their learning experience was measured by a self-report questionnaire, triggering their perceptions of mental effort, task complexity, and learning preferences. Their learning outcome was measured by speech analysis of their oral performance, targeting fluency, and vocabulary diversity. Data analysis revealed that ubiquitous photography induced a better learning experience and enhanced their speaking outcomes to various extents. Results contribute to the potential of integrating ubiquitous learning and generative learning strategies in FL classrooms.","2022-12","2025-02-26 20:41:54","2025-02-26 20:41:54","","2117-2143","","6","70","","","","","","","","","","English","","","","WOS:000839401000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;98</p>","","","ACHIEVEMENT; ACQUISITION; CHINESE; COGNITIVE LOAD THEORY; COMPLEXITY; ENGLISH; FLUENCY DEVELOPMENT; Generative learning; Mobile learning; Speaking; STRATEGIES; STUDENTS; TECHNOLOGY; Ubiquitous photography","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZB8JZUQW","journalArticle","2021","Wei, CB; Gong, ST; Zou, Q; Zhang, W; Kang, XC; Lu, XL; Chen, YF; Yang, YT; Wang, W; Jia, LF; Lyu, JH; Shan, BC; ADNI","A Comparative Study of Structural and Metabolic Brain Networks in Patients With Mild Cognitive Impairment","FRONTIERS IN AGING NEUROSCIENCE","","1663-4365","10.3389/fnagi.2021.774607","","Background: Changes in the metabolic and structural brain networks in mild cognitive impairment (MCI) have been widely researched. However, few studies have compared the differences in the topological properties of the metabolic and structural brain networks in patients with MCI.Methods: We analyzedmagnetic resonance imaging (MRI) and fluoro-deoxyglucose positron emission tomography (FDG-PET) data of 137 patients with MCI and 80 healthy controls (HCs). The HC group data comes from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database. The permutation test was used to compare the network parameters (characteristic path length, clustering coefficient, local efficiency, and global efficiency) between the two groups. Partial Pearson's correlation analysis was used to calculate the correlations of the changes in gray matter volume and glucose intake in the key brain regions in MCI with the Alzheimer's Disease Assessment Scale-Cognitive (ADAS-cog) sub-item scores.Results: Significant changes in the brain network parameters (longer characteristic path length, larger clustering coefficient, and lower local efficiency and global efficiency) were greater in the structural network than in the metabolic network (longer characteristic path length) in MCI patients than in HCs. We obtained the key brain regions (left globus pallidus, right calcarine fissure and its surrounding cortex, left lingual gyrus) by scanning the hubs. The volume of gray matter atrophy in the left globus pallidus was significantly positively correlated with comprehension of spoken language (p = 0.024) and word-finding difficulty in spontaneous speech item scores (p = 0.007) in the ADAS-cog. Glucose intake in the three key brain regions was significantly negatively correlated with remembering test instructions items in ADAS-cog (p = 0.020, p = 0.014, and p = 0.008, respectively).Conclusion: Structural brain networks showed more changes than metabolic brain networks in patients with MCI. Some brain regions with significant changes in betweenness centrality in both structural and metabolic networks were associated with MCI.","2021-12-06","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","13","","","","","","","","","","English","","","","WOS:000731731800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","ALZHEIMERS-DISEASE; brain network; brain regions; CONNECTIVITY; DEMENTIA; metabolism; mild cognitive impairment; SCALE; structure; TOPOLOGICAL PATTERNS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4JM87ESK","journalArticle","2024","Lu, YT; Wang, ZQ","Few Adjustable Parameters Prediction Model Based on Lightweight Prefix-Tuning: Learning Session Dropout Prediction Model Based on Parameter-Efficient Prefix-Tuning","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app142310772","","Featured Application This work can be applied to an online education platform to predict students' current learning states.Abstract In response to the challenge of low predictive accuracy in scenarios with limited data, we propose a few adjustable parameters prediction model based on lightweight prefix-tuning (FAP-Prefix). Prefix-tuning is an efficient fine-tuning method that only adjusts prefix vectors while keeping the model's original parameters frozen. In each transformer layer, the prefix vectors are connected with the internal key-value pair of the transformer structure. By training on the synthesized sequence of the prefix and original input with masked learning, the transformer model learns the features of individual learning behaviors. In addition, it can also discover hidden connections of continuous learning behaviors. During fine-tuning, all parameters of the pre-trained model are frozen, and downstream task learning is accomplished by adjusting the prefix parameters. Continuous trainable prefix vectors can influence subsequent vector representations, leading to the generation of session dropout prediction results. The experiments show that FAP-Prefix significantly outperforms traditional methods in data-limited settings, with AUC improvements of +4.58%, +3.53%, and +8.49% under 30%, 10%, and 1% data conditions, respectively. It also surpasses state-of-the-art models in prediction performance (AUC +5.42%, ACC +5.3%, F1 score +5.68%).","2024-12","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","23","14","","","","","","","","","","English","","","","WOS:001376312900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","datamining; learning session dropout prediction; limited data scenario; prefix-tuning; smart education","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N567JRGH","journalArticle","2024","Liu, YD; Zhang, LW; Wei, ZC; Wang, T; Yang, X; Tian, J; Hui, H","Transformer for low concentration image denoising in magnetic particle imaging","PHYSICS IN MEDICINE AND BIOLOGY","","0031-9155","10.1088/1361-6560/ad6ede","","Objective. Magnetic particle imaging (MPI) is an emerging tracer-based in vivo imaging technology. The use of MPI at low superparamagnetic iron oxide nanoparticle concentrations has the potential to be a promising area of clinical application due to the inherent safety for humans. However, low tracer concentrations reduce the signal-to-noise ratio of the magnetization signal, leading to severe noise artifacts in the reconstructed MPI images. Hardware improvements have high complexity, while traditional methods lack robustness to different noise levels, making it difficult to improve the quality of low concentration MPI images. Approach. Here, we propose a novel deep learning method for MPI image denoising and quality enhancing based on a sparse lightweight transformer model. The proposed residual-local transformer structure reduces model complexity to avoid overfitting, in which an information retention block facilitates feature extraction capabilities for the image details. Besides, we design a noisy concentration dataset to train our model. Then, we evaluate our method with both simulated and real MPI image data. Main results. Simulation experiment results show that our method can achieve the best performance compared with the existing deep learning methods for MPI image denoising. More importantly, our method is effectively performed on the real MPI image of samples with an Fe concentration down to 67 mu gFe ml-1. Significance. Our method provides great potential for obtaining high quality MPI images at low concentrations.","2024-09-07","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","17","69","","","","","","","","","","English","","","","WOS:001298550800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","deep learning; denoising; low concentration; magnetic particle imaging; RESOLUTION; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2TMP28I6","journalArticle","2024","Wang, J; Ignacio, MJ; Yu, S; Jin, H; Kim, YG","UET4Rec: U-net encapsulated transformer for sequential recommender","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.124781","","Recommending a tempting sequence of items according to a user's previous history of purchases and clicks, for instance, in the online shopping portals is challenging. And yet it is a crucial task for all service providers. One of the core components in the recommender systems is a sequential model with which an input sequence is transformed into the predicted items. Among many, deep neural networks, such as RNN, LSTM, and Transformer, have been favored for this purpose. However, improving the performance of these models remains an important task. To address this, we propose a novel sequential model by combining a U-net and Transformer, called U-net Encapsulated Transformer. This hybrid architecture places a transformer model between a convolutional encoder and its decoder, wherein each convolutional layer processes 1D signal, i.e. text. The primary benefit of this structure is that the computational burden is reduced since the embedding size of the input to the Transformer is drastically decreased as the signal has to go through the multi-layer convolutional encoder. This solution leverages recommendation lists for action predictions and uses user feedback as direct rewards for updating the model. In addition, the loss function mechanism is improved by including contrastive and reinforcement learning losses. Evaluation of the proposed model, including extensive ablation study, is carried out on four standard benchmark datasets, such as RC15, RetailRocket, MovieLens-1M, and Amazon-Beauty, demonstrating superior performance compared to state-of-the-art methods.","2024-12-01","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","255","","","","","","","","","","English","","","","WOS:001274474200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Contrastive learning; Recommender; Reinforcement learning; Sequential model; Transformer; U-net","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P5H23DNT","journalArticle","2024","Liu, JJ; Li, JY; Xu, YF; Low, SS; Ning, HH; Yu, SX; Xu, DF; Liu, QJ","A fused convolutional transformer for voltammetric electronic tongue analysis tasks","JOURNAL OF ENVIRONMENTAL CHEMICAL ENGINEERING","","2213-2929","10.1016/j.jece.2024.113462","","Electronic tongue and artificial intelligence have been evaluated as new rapid analysis technologies in complex solution research. The use of nanomaterials to modify the screen-printed carbon electrode (SPCE) increased the specific surface area and electrocatalytic active sites of the electrode. The voltammetric electronic tongue utilizes multiple cross sensitive sensors to describe the overall characteristics of complex samples, and the complementary information between sensors provides rich and comprehensive descriptions for analyzing various components. The use of electronic tongue for rapid analysis of water quality has gradually become a trend, but the overlapping phenomenon of peaks formed by the similar redox potential of each component in water and the interference of the substrate makes it difficult to obtain effective information of each component in water quality. Here, we propose a Fused Convolutional Transformer model (FCvT) that removes the limitation of overlapping peaks by fusing local features and global complementary features to quantify components in complex solutions. The performance of FCvT was evaluated by testing synthetic water samples consisting of four standardized substance solutions and compared with partial least squares (PLS), support vector regression (SVR), artificial neural networks (ANN), and convolutional neural networks (CNN). The results show that the FCvT obtains the lowest mean absolute percentage error in the set of independent tests.The average quantization error of FCvT is reduced by 34.4 % relative to other methods.","2024-10","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","5","12","","","","","","","","","","English","","","","WOS:001264401800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","ANTIOXIDANTS; ARTIFICIAL NEURAL-NETWORKS; Multicomponent analysis; Multidimensional interaction; PRINCIPLES; PURPOSES; Self-Attention; Voltammetric electronic tongue; WATER; Water quality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HJWTM3EJ","journalArticle","2024","Liu, YG; Yu, HL; Duan, XY; Zhang, XM; Cheng, T; Jiang, F; Tang, H; Ruan, Y; Zhang, M; Zhang, HY; Zhang, QY","TransGEM: a molecule generation model based on Transformer with gene expression data","BIOINFORMATICS","","1367-4803","10.1093/bioinformatics/btae189","","Motivation It is difficult to generate new molecules with desirable bioactivity through ligand-based de novo drug design, and receptor-based de novo drug design is constrained by disease target information availability. The combination of artificial intelligence and phenotype-based de novo drug design can generate new bioactive molecules, independent from disease target information. Gene expression profiles can be used to characterize biological phenotypes. The Transformer model can be utilized to capture the associations between gene expression profiles and molecular structures due to its remarkable ability in processing contextual information.Results We propose TransGEM (Transformer-based model from gene expression to molecules), which is a phenotype-based de novo drug design model. A specialized gene expression encoder is used to embed gene expression difference values between diseased cell lines and their corresponding normal tissue cells into TransGEM model. The results demonstrate that the TransGEM model can generate molecules with desirable evaluation metrics and property distributions. Case studies illustrate that TransGEM model can generate structurally novel molecules with good binding affinity to disease target proteins. The majority of genes with high attention scores obtained from TransGEM model are associated with the onset of the disease, indicating the potential of these genes as disease targets. Therefore, this study provides a new paradigm for de novo drug design, and it will promote phenotype-based drug discovery.Availability and implementation The code is available at https://github.com/hzauzqy/TransGEM.","2024-05-02","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","5","40","","","","","","","","","","English","","","","WOS:001215814700003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","CONNECTIVITY MAP; PROTEIN; THERAPEUTIC TARGET","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FH8UP4D6","journalArticle","2024","Hou, L; Ma, C; Tang, WQ; Zhou, YX; Ye, S; Chen, XD; Zhang, XX; Yu, CY; Chen, AQ; Zheng, DY; Cao, ZS; Zhang, Y; Hou, MC","DDViT: Advancing lithology identification on FMI image logs through a dual modal transformer model with less information drop","GEOENERGY SCIENCE AND ENGINEERING","","2949-8929","10.1016/j.geoen.2024.212662","","Lithology is an essential topic in oil and gas reservoir studies. Lithological observation lays the foundation for assessing oil and gas prospects and guides future exploration and development. Currently, the prevailing approach in lithological observation heavily depends on the manual analysis of core samples. However, such an approach is highly subjective and time-consuming. With the development of deep learning, some automated deep learning-based methods have been proposed for lithology interpretation from logging curves. However, the Fullbore Formation MicroImager (FMI) image logging, while widely used in the oil field exploration and development process, is occasionally deployed and utilized for lithology identification. In this work, we proposed a Dual-modal Drop-less-information Vision Transformer (DDViT), an FMI image lithology identification model based on transformer architecture. DDViT uses a dual-modal architecture to identify lithology using two different image modalities, namely dynamic FMI images (FMI_DYN) and static FMI images (FMI_STAT). These modalities reflect the local and overall characteristics, respectively. Furthermore, DDViT uses a less-information dropping module to drop the blank band information inherent in the FMI images to make our model more rational and stable. DDViT achieved a 90.81% lithology identification accuracy on Fengxi Well A of the western Qaidam Basin, providing a new approach to lithology identification and demonstrating the great potential of deep learning in geological images.","2024-03","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","234","","","","","","","","","","English","","","","WOS:001171013600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","BASIN; CLASSIFICATION; CONVOLUTIONAL NEURAL-NETWORKS; DEEP; Drop less information; Dual modal; FMI images; Lithology identification; OIL-FIELD; PREDICTION; RESERVOIRS; ROCKS; SEGMENTATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QY83R7B6","journalArticle","2024","Khurana, K; Bharambe, R; Dharmik, H; Rathi, K; Rawte, M","A textual question answering and handwritten answer evaluation system for hindi language","INTERNATIONAL JOURNAL OF KNOWLEDGE-BASED AND INTELLIGENT ENGINEERING SYSTEMS","","1327-2314","10.3233/KES-230188","","Textual Question Answering targets answering questions defined in natural language. Question Answering Systems offer an automated approach to procuring answers to queries expressed in natural language. The need for Multilingual Question Answering without performing machine translation is ever existing. Besides that, automating tasks with the help of technology to assist humans, has been the main aim of research in recent years. This paper presents an automated answer evaluation system for reading comprehension-based questions in the Hindi language without requiring translation in any other language. The system accepts text, question, and handwritten answer of a student in the form of an image for answer evaluation. This is accomplished by developing a textual question-answering system for reading comprehension. It is an extractive approach that utilizes RoBERTa transformer model and fine-tunes it for Hindi question-answering. The answer to the question is extracted as a span from the provided text. Further, a handwritten text recognizer model is developed employing a Convolutional Recurrent Neural Network with Connectionist Temporal Classification module along with two layers of Bidirectional LSTM. Experimentation is performed using existing as well as self-created datasets to show the effectiveness of the proposed approach. An accuracy of 98.69% is obtained on the self-created Hindi-QA dataset and the proposed system outperformed the other existing methods. The paper also discusses potential research directions in the field.","2024","2025-02-26 20:41:54","2025-02-26 20:41:54","","435-455","","3","28","","","","","","","","","","English","","","","WOS:001410615000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","machine reading comprehension; Multilingual question answering; natural language processing; optical character recognition; RECOGNITION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"355CREKK","journalArticle","2024","Liu, JJ; Liu, X; Wang, YH; Fu, H","Construction of Internet Traffic Monitoring Model Based on Improved Transformer Algorithm","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3445996","","With the popularization of the Internet, it is very important to effectively identify abnormal behaviors in network traffic. This study focuses on the construction of an internet traffic monitoring model, aiming to improve the accurate recognition rate of abnormal behavior and reduce information loss during small block segmentation. To this end, a internet traffic monitoring algorithm based on the improved Transformer is optimized. This model adopts a block segmentation algorithm that preserves important information during the segmentation process, thereby enhancing the segmentation quality and accuracy of the model. By effectively interacting with multiple receptive field information, the model reduces information loss and improves accuracy and efficiency. After experimental verification, the model performed well on CICIDS sample data, with an F1 value of 93% for normal internet traffic. The F1 value of internet attack traffic was 91%. Compared with the original Transformer model, it increased by 5% and 2.4%, respectively. On the NSLKDD sample, the improved algorithm proposed in the study had an area under the curve value of 0.90, which outperformed other models. This proves that it has significant advantages in the dual classification task of internet traffic anomaly monitoring. This study provides an effective deep learning algorithm for internet traffic anomaly monitoring, which is expected to provide strong support for network security assurance in practical application scenarios.","2024","2025-02-26 20:41:54","2025-02-26 20:41:54","","116801-116815","","","12","","","","","","","","","","English","","","","WOS:001303408500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Accuracy; ATTACKS; Attention mechanisms; block segmentation; Deep learning; Feature extraction; flow rate; internet; Internet; monitoring; Monitoring; NETWORK; Telecommunication traffic; Trans-M; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BMUTC8YA","journalArticle","2023","Toniato, A; Vaucher, AC; Schwaller, P; Laino, T","Enhancing diversity in language based models for single-step retrosynthesis","DIGITAL DISCOVERY","","2635-098X","10.1039/d2dd00110a","","Over the past four years, several research groups demonstrated the combination of domain-specific language representation with recent NLP architectures to accelerate innovation in a wide range of scientific fields. Chemistry is a great example. Among the various chemical challenges addressed with language models, retrosynthesis demonstrates some of the most distinctive successes and limitations. Single-step retrosynthesis, the task of identifying reactions able to decompose a complex molecule into simpler structures, can be cast as a translation problem, in which a text-based representation of the target molecule is converted into a sequence of possible precursors. A common issue is a lack of diversity in the proposed disconnection strategies. The suggested precursors typically fall in the same reaction family, which limits the exploration of the chemical space. We present a retrosynthesis Transformer model that increases the diversity of the predictions by prepending a classification token to the language representation of the target molecule. At inference, the use of these prompt tokens allows us to steer the model towards different kinds of disconnection strategies. We show that the diversity of the predictions improves consistently, which enables recursive synthesis tools to circumvent dead ends and consequently, suggests synthesis pathways for more complex molecules. Current Al solutions to chemical retrosynthesis focus on predicting the reported ground truth, not taking into account the ability to generate alternatives. Our work is the first Al approach tackling and analysing retrosynthetic diversity directly.","2023-04-11","2025-02-26 20:41:54","2025-02-26 20:41:54","","489-501","","2","2","","","","","","","","","","English","","","","WOS:001101812600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","NETWORKS; SMILES; TRANSFORMER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RK7QIXBH","journalArticle","2023","Du, WB; Chen, SW; Li, HT; Li, ZS; Cao, XB; Lv, YS","Airport Capacity Prediction With Multisource Features: A Temporal Deep Learning Approach","IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS","","1524-9050","10.1109/TITS.2022.3213029","","Accurate airport capacity estimation is crucial for the secure and orderly operation of the aviation system. However, such estimation is a non-trivial task as capacity depends on various meteorological and operational features. The complex coupling characteristics among these multi-source features have proved to be challenging for most of the traditional regression models. Recently, enhanced by its excellent ability to mine nonlinear relationships, the machine learning methods trigger widely applications. However, due to the imbalance of features scatter and the neglect of temporal dependences in aviation systems, existing machine learning methods for airport capacity prediction still have room for improvement. In light of these, this paper presents a novel airport capacity prediction method based on the multi-channel fusion Transformer model (MF-Transformer). Besides the commonly used aviation features, we unprecedentedly harness the power of the high-dimensional meteorological feature for accurate prediction. As to the model, we construct a multi-channel feature fusion structure, which includes a three-channel network for multi-source features extraction and an attention-based feature fusion module between channels. In each channel, the Transformer-based model is utilized to capture the temporal dependences of features. We conduct experiments on the capacity prediction tasks of the Beijing Capital International Airport which is the largest airport in China and verify that the proposed MF-Transformer outperforms benchmarks under different prediction horizons.","2023-01","2025-02-26 20:41:54","2025-02-26 20:41:54","","615-630","","1","24","","","","","","","","","","English","","","","WOS:000928006100045","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Airport capacity; deep learning; machine learning; multi-channel fusion structure; NEURAL-NETWORKS; predictive model; SYSTEMS; TRAFFIC FLOW MANAGEMENT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2DDZUFAH","journalArticle","2022","Chitty-Venkata, KT; Emani, M; Vishwanath, V; Somani, AK","Neural Architecture Search for Transformers: A Survey","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3212767","","Transformer-based Deep Neural Network architectures have gained tremendous interest due to their effectiveness in various applications across Natural Language Processing (NLP) and Computer Vision (CV) domains. These models are the de facto choice in several language tasks, such as Sentiment Analysis and Text Summarization, replacing Long Short Term Memory (LSTM) model. Vision Transformers (ViTs) have shown better model performance than traditional Convolutional Neural Networks (CNNs) in vision applications while requiring significantly fewer parameters and training time. The design pipeline of a neural architecture for a given task and dataset is extremely challenging as it requires expertise in several interdisciplinary areas such as signal processing, image processing, optimization and allied fields. Neural Architecture Search (NAS) is a promising technique to automate the architectural design process of a Neural Network in a data-driven way using Machine Learning (ML) methods. The search method explores several architectures without requiring significant human effort, and the searched models outperform the manually built networks. In this paper, we review Neural Architecture Search techniques, targeting the Transformer model and its family of architectures such as Bidirectional Encoder Representations from Transformers (BERT) and Vision Transformers. We provide an in-depth literature review of approximately 50 state-of-the-art Neural Architecture Search methods and explore future directions in this fast-evolving class of problems.","2022","2025-02-26 20:41:54","2025-02-26 20:41:54","","108374-108412","","","10","","","","","","","","","","English","","","","WOS:000870219300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;26<br/>Total Times Cited:&nbsp;&nbsp;28<br/>Cited Reference Count:&nbsp;&nbsp;253</p>","","","BERT; Bit error rate; Computational modeling; Computer architecture; Convolutional neural networks; hardware-aware NAS; multi-head self-attention; NAS; Neural architecture search; Search problems; transformers; Transformers; vision transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CVK9BJ65","journalArticle","2021","Panagiaris, N; Hart, E; Gkatzia, D","Generating unambiguous and diverse referring expressions","COMPUTER SPEECH AND LANGUAGE","","0885-2308","10.1016/j.csl.2020.101184","","Neural Referring Expression Generation (REG) models have shown promising results in generating expressions which uniquely describe visual objects. However, current REG models still lack the ability to produce diverse and unambiguous referring expressions (REs). To address the lack of diversity, we propose generating a set of diverse REs, rather than oneshot REs. To reduce the ambiguity of referring expressions, we directly optimise non -differentiable test metrics using reinforcement learning (RL), and we show that our approaches achieve better results under multiple different settings. Specifically, we initially present a novel RL approach to REG training, which instead of drawing one sample per input, it averages over multiple samples to normalize the reward during RL training. Secondly, we present an innovative REG model that utilizes an object attention mechanism that explicitly incorporates information about the target object and is optimised using our proposed RL approach. Thirdly, we propose a novel transformer model optimised with RL that exploits different levels of visual information. Our human evaluation demonstrates the effectiveness of this model, where we improve the state-of-the-art results in RefCOCO testA and testB in terms of task success from 76.95% to 81.66% and from 78.10% to 83.33% respectively. While in RefCOCO+ testA we show improvements from 58.85% to 83.33%. Finally, we present a thorough comparison of diverse decoding strategies (sampling and maximisation-based) and how they control the trade-off between the quality and diversity. (c) 2020 Elsevier Ltd. All rights reserved.","2021-07","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","68","","","","","","","","","","English","","","","WOS:000629287300002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","Natural language generation; Neural models; Referring expression generation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DNPA8RE6","journalArticle","2024","Wang, YJ; Hattori, M; Masaki, K; Sumita, YI","Detailed speech evaluation including formant 3 analysis and voice visualization in maxillofacial rehabilitation: A clinical report","JOURNAL OF PROSTHETIC DENTISTRY","","0022-3913","10.1016/j.prosdent.2023.02.022","","Objective speech evaluation such as analysis of formants 1 and 2 and nasality measurement have been used in maxillofacial rehabilitation for outcome assessment. However, in some patients, those evaluations are insufficient to assess a specific or unique problem. This report describes the use of a new speech evaluation including formant 3 analysis and voice visualization in a patient with a maxillofacial defect. The patient was a 67-year-old man who had a maxillary defect that opened to the maxillary sinus and who had an unnatural voice even when wearing an obturator. Nasality was low and the frequency of formants 1 and 2 were normal even without the obturator. However, a low frequency of formant 3 and a shifted center of voice were observed. These results indicated that the unnatural voice was related to increased resonant volume in the pharynx rather than hypernasality. This patient demonstrates that advanced speech analysis can be useful for detecting the cause of speech disorder and planning maxillofacial rehabilitation. (J Prosthet Dent 2024;132:1331.e1-e7)","2024-12","2025-02-26 20:41:54","2025-02-26 20:41:54","","1331e1-1331e7","","6","132","","","","","","","","","","English","","","","WOS:001376727900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;16</p>","","","INTELLIGIBILITY; VOWELS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T7AFRTB2","journalArticle","2024","Huang, CL; Wu, YK; Tsai, CC; Hong, JS; Li, YY","Revolutionizing Solar Power Forecasts by Correcting the Outputs of the WRF-SOLAR Model","ENERGIES","","1996-1073","10.3390/en17010088","","Climate change poses a significant threat to humanity. Achieving net-zero emissions is a key goal in many countries. Among various energy resources, solar power generation is one of the prominent renewable energy sources. Previous studies have demonstrated that post-processing techniques such as bias correction can enhance the accuracy of solar power forecasting based on numerical weather prediction (NWP) models. To improve the post-processing technique, this study proposes a new day-ahead forecasting framework that integrates weather research and forecasting solar (WRF-Solar) irradiances and the total solar power generation measurements for five cities in northern, central, and southern Taiwan. The WRF-Solar irradiances generated by the Taiwan Central Weather Bureau (CWB) were first subjected to bias correction using the decaying average (DA) method. Then, the effectiveness of this correction method was verified, which led to an improvement of 22% in the forecasting capability from the WRF-Solar model. Subsequently, the WRF-Solar irradiances after bias correction using the DA method were utilized as inputs into the transformer model to predict the day-ahead total solar power generation. The experimental results demonstrate that the application of bias-corrected WRF-Solar irradiances enhances the accuracy of day-ahead solar power forecasts by 15% compared with experiments conducted without bias correction. These findings highlight the necessity of correcting numerical weather predictions to improve the accuracy of solar power forecasts.","2024-01","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","1","17","","","","","","","","","","English","","","","WOS:001139272900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","bias correction; BIAS CORRECTION; decaying average; IRRADIANCE; NUMERICAL WEATHER PREDICTION; RADIATION; solar irradiance prediction; solar power forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HCQGJK8F","journalArticle","2023","Li, H; Qi, MY; Du, BX; Li, Q; Gao, HZ; Yu, J; Bi, CG; Yu, HL; Liang, MJ; Ye, GS; Tang, Y","Maize Disease Classification System Design Based on Improved ConvNeXt","SUSTAINABILITY","","2071-1050","10.3390/su152014858","","Maize diseases have a great impact on agricultural productivity, making the classification of maize diseases a popular research area. Despite notable advancements in maize disease classification achieved via deep learning techniques, challenges such as low accuracy and identification difficulties still persist. To address these issues, this study introduced a convolutional neural network model named Sim-ConvNeXt, which incorporated a parameter-free SimAM attention module. The integration of this attention mechanism enhanced the ability of the downsample module to extract essential features of maize diseases, thereby improving classification accuracy. Moreover, transfer learning was employed to expedite model training and improve the classification performance. To evaluate the efficacy of the proposed model, a publicly accessible dataset with eight different types of maize diseases was utilized. Through the application of data augmentation techniques, including image resizing, hue, cropping, rotation, and edge padding, the dataset was expanded to comprise 17,670 images. Subsequently, a comparative analysis was conducted between the improved model and other models, wherein the approach demonstrated an accuracy rate of 95.2%. Notably, this performance represented a 1.2% enhancement over the ConvNeXt model and a 1.5% improvement over the advanced Swin Transformer model. Furthermore, the precision, recall, and F1 scores of the improved model demonstrated respective increases of 1.5% in each metric compared to the ConvNeXt model. Notably, using the Flask framework, a website for maize disease classification was developed, enabling accurate prediction of uploaded maize disease images.","2023-10","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","20","15","","","","","","","","","","English","","","","WOS:001089905300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","CNN; data augmentation; maize disease classification; SimAM attention; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D5MTPWBK","journalArticle","2023","Cheng, MJ; Zhang, X; Wang, J; Yang, Y; Li, M; Zhao, HJ; Huang, JY; Zhang, CL; Qian, DH; Yu, HB","Prediction of orthognathic surgery plan from 3D cephalometric analysis via deep learning","BMC ORAL HEALTH","","1472-6831","10.1186/s12903-023-02844-z","","BackgroundPreoperative planning of orthognathic surgery is indispensable for achieving ideal surgical outcome regarding the occlusion and jaws' position. However, orthognathic surgery planning is sophisticated and highly experience-dependent, which requires comprehensive consideration of facial morphology and occlusal function. This study aimed to investigate a robust and automatic method based on deep learning to predict reposition vectors of jawbones in orthognathic surgery plan.MethodsA regression neural network named VSP transformer was developed based on Transformer architecture. Firstly, 3D cephalometric analysis was employed to quantify skeletal-facial morphology as input features. Next, input features were weighted using pretrained results to minimize bias resulted from multicollinearity. Through encoder-decoder blocks, ten landmark-based reposition vectors of jawbones were predicted. Permutation importance (PI) method was used to calculate contributions of each feature to final prediction to reveal interpretability of the proposed model.ResultsVSP transformer model was developed with 383 samples and clinically tested with 49 prospectively collected samples. Our proposed model outperformed other four classic regression models in prediction accuracy. Mean absolute errors (MAE) of prediction were 1.41 mm in validation set and 1.34 mm in clinical test set. The interpretability results of the model were highly consistent with clinical knowledge and experience.ConclusionsThe developed model can predict reposition vectors of orthognathic surgery plan with high accuracy and good clinically practical-effectiveness. Moreover, the model was proved reliable because of its good interpretability.","2023-03-18","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","1","23","","","","","","","","","","English","","","","WOS:000953158300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","ALGORITHM; Deep learning; Dento-maxillofacial deformity; Orthognathic surgery; Regression prediction; Transformer; Virtual surgical planning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FGJPSSD7","journalArticle","2022","Kann, K; Ebrahimi, A; Mager, M; Oncevay, A; Ortega, JE; Rios, A; Fan, AEL; Gutierrez-Vasques, X; Chiruzzo, L; Giménez-Lugo, GA; Ramos, R; Ruiz, IVM; Mager, E; Chaudhary, V; Neubig, G; Palmer, A; Coto-Solano, R; Vu, NT","AmericasNLI: Machine translation and natural language inference systems for Indigenous languages of the Americas","FRONTIERS IN ARTIFICIAL INTELLIGENCE","","2624-8212","10.3389/frai.2022.995667","","Little attention has been paid to the development of human language technology for truly low-resource languages-i.e., languages with limited amounts of digitally available text data, such as Indigenous languages. However, it has been shown that pretrained multilingual models are able to perform crosslingual transfer in a zero-shot setting even for low-resource languages which are unseen during pretraining. Yet, prior work evaluating performance on unseen languages has largely been limited to shallow token-level tasks. It remains unclear if zero-shot learning of deeper semantic tasks is possible for unseen languages. To explore this question, we present AmericasNLI, a natural language inference dataset covering 10 Indigenous languages of the Americas. We conduct experiments with pretrained models, exploring zero-shot learning in combination with model adaptation. Furthermore, as AmericasNLI is a multiway parallel dataset, we use it to benchmark the performance of different machine translation models for those languages. Finally, using a standard transformer model, we explore translation-based approaches for natural language inference. We find that the zero-shot performance of pretrained models without adaptation is poor for all languages in AmericasNLI, but model adaptation via continued pretraining results in improvements. All machine translation models are rather weak, but, surprisingly, translation-based approaches to natural language inference outperform all other models on that task.","2022-12-02","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","5","","","","","","","","","","English","","","","WOS:000913717600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;97</p>","","","low-resource languages; machine translation; model adaptation; multilingual NLP; natural language inference; natural language processing; pretrained models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"88NANQXV","journalArticle","2025","Lin, BB; Ni, JL; Xiong, X; Zhang, LL; Song, J; Wang, MX; Chai, LS; Huang, YS; Huang, J","Language function improvement and cortical activity alteration using scalp acupuncture coupled with speech-language training in post-stroke aphasia: A randomised controlled study","COMPLEMENTARY THERAPIES IN MEDICINE","","0965-2299","10.1016/j.ctim.2025.103137","","Background: Scalp acupuncture is commonly used as a complementary treatment to improve language function in patients with post-stroke aphasia. Our objectives were to evaluate the impact of scalp acupuncture on the cerebral cortex of post-stroke aphasia patients.<br /> Methods: This assessor-blinded, parallel-arm design, single-center, randomized clinical trial recruited 64 patients with post-stroke aphasia. They were randomly assigned to either the acupuncture group (n = 32) or the control group (n = 32). The primary outcome measure was the Western Aphasia Battery (WAB) score, while the secondary outcome was the oxygenated haemoglobin (OxyHb) index, which represents cortical activity as measured by functional near-infrared spectroscopy (fNIRS). All assessments were performed at baseline and post- intervention.<br /> Results: The acupuncture group showed significant improvements in WAB subscales (Spontaneous Speech, Comprehension, Repetition, Naming, and AQ) with all changes statistically significant (P < 0.001). The acupuncture group also showed higher OxyHb indices in the left frontopolar area, left fusiform gyrus, and left pars opercularis (P < 0.05). Additionally, OxyHb D-values were significantly greater in the left frontopolar area and right superior temporal gyrus (P < 0.05) compared to the control group. Among non-global aphasia patients, acupuncture improved comprehension and naming tasks, with lower OxyHb in the right visual association cortex and angular gyrus (P < 0.05). In global aphasia patients, improvements were seen in the AQ and Repetition scores, with higher OxyHb in the right inferior prefrontal gyrus (P < 0.05).<br /> Conclusion: Adjuvant scalp acupuncture enhances the effectiveness of speech-language therapy in treating repetition and naming impairments in patients with post-stroke aphasia. Additionally, it may modulate cortical activation in the left frontopolar area, left fusiform gyrus, left pars opercularis, and right superior temporal gyrus, and induces different cortical alteration patterns in global and non-global aphasia.","2025-05","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","89","","","","","","","","","","English","","","","WOS:001423549000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Acupuncture; Cortical activity; Language impairment; METAANALYSIS; Near-infrared spectroscopy; NEAR-INFRARED SPECTROSCOPY; Oxygenated haemoglobin; Post-stroke aphasia; RECOVERY; REHABILITATION; STROKE; THERAPY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NWGPILV8","journalArticle","2025","Liu, SK; Liu, K; Wang, Z; Liu, YY; Bai, B; Zhao, R","Investigation of a transformer-based hybrid artificial neural networks for climate data prediction and analysis","FRONTIERS IN ENVIRONMENTAL SCIENCE","","2296-665X","10.3389/fenvs.2024.1464241","","Introduction Climate change isone of the major challenges facing the world today, causing frequent extreme weather events that significantly impact human production, life, and the ecological environment. Traditional climate prediction models largely rely on the simulation of physical processes. While they have achieved some success, these models still face issues such as complexity, high computational cost, and insufficient handling of multivariable nonlinear relationships.Methods In light of this, this paper proposes a hybrid deep learning model based on Transformer-Convolutional Neural Network (CNN)-Long Short-Term Memory (LSTM) to improve the accuracy of climate predictions. Firstly, the Transformer model is introduced to capture the complex patterns in cimate data time series through its powerful sequence modeling capabilities. Secondly, CNN is utilized to extract local features and capture short-term changes. Lastly, LSTM is adept at handling long-term dependencies, ensuring the model can remember and utilize information over extended time spans.Results and Discussion Experiments conducted on temperature data from Guangdong Province in China validate the performance of the proposed model. Compared to four different climate prediction decomposition methods, the proposed hybrid model with the Transformer method performs the best. The resuts also show that the Transformer-CNN-LSTM hybrid model outperforms other hybrid models on five evaluation metrics, indicating that the proposed model provides more accurate predictions and more stable fitting results.","2025-01-22","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","12","","","","","","","","","","English","","","","WOS:001413039300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","climate prediction; CNN; hybrid deep learning; LSTM; sequentially; TIME-SERIES; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"64CLNTZR","journalArticle","2024","Ghazal, S; Kommineni, N; Munir, A","Comparative Analysis of Machine Learning Techniques Using RGB Imaging for Nitrogen Stress Detection in Maize","AI","","2673-2688","10.3390/ai5030062","","Proper nitrogen management in crops is crucial to ensure optimal growth and yield maximization. While hyperspectral imagery is often used for nitrogen status estimation in crops, it is not feasible for real-time applications due to the complexity and high cost associated with it. Much of the research utilizing RGB data for detecting nitrogen stress in plants relies on datasets obtained under laboratory settings, which limits its usability in practical applications. This study focuses on identifying nitrogen deficiency in maize crops using RGB imaging data from a publicly available dataset obtained under field conditions. We have proposed a custom-built vision transformer model for the classification of maize into three stress classes. Additionally, we have analyzed the performance of convolutional neural network models, including ResNet50, EfficientNetB0, InceptionV3, and DenseNet121, for nitrogen stress estimation. Our approach involves transfer learning with fine-tuning, adding layers tailored to our specific application. Our detailed analysis shows that while vision transformer models generalize well, they converge prematurely with a higher loss value, indicating the need for further optimization. In contrast, the fine-tuned CNN models classify the crop into stressed, non-stressed, and semi-stressed classes with higher accuracy, achieving a maximum accuracy of 97% with EfficientNetB0 as the base model. This makes our fine-tuned EfficientNetB0 model a suitable candidate for practical applications in nitrogen stress detection.","2024-09","2025-02-26 20:41:54","2025-02-26 20:41:54","","1286-1300","","3","5","","","","","","","","","","English","","","","WOS:001323734500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","computer vision; convolutional neural networks; DEFICIENCY; maize; nitrogen stress detection; transfer learning; vision transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J2VNCU72","journalArticle","2024","Gao, XY; Baimacheva, N; Aires-de-Sousa, J","Exploring Molecular Heteroencoders with Latent Space Arithmetic: Atomic Descriptors and Molecular Operators","MOLECULES","","1420-3049","10.3390/molecules29163969","","A variational heteroencoder based on recurrent neural networks, trained with SMILES linear notations of molecular structures, was used to derive the following atomic descriptors: delta latent space vectors (DLSVs) obtained from the original SMILES of the whole molecule and the SMILES of the same molecule with the target atom replaced. Different replacements were explored, namely, changing the atomic element, replacement with a character of the model vocabulary not used in the training set, or the removal of the target atom from the SMILES. Unsupervised mapping of the DLSV descriptors with t-distributed stochastic neighbor embedding (t-SNE) revealed a remarkable clustering according to the atomic element, hybridization, atomic type, and aromaticity. Atomic DLSV descriptors were used to train machine learning (ML) models to predict 19F NMR chemical shifts. An R2 of up to 0.89 and mean absolute errors of up to 5.5 ppm were obtained for an independent test set of 1046 molecules with random forests or a gradient-boosting regressor. Intermediate representations from a Transformer model yielded comparable results. Furthermore, DLSVs were applied as molecular operators in the latent space: the DLSV of a halogenation (H -> F substitution) was summed to the LSVs of 4135 new molecules with no fluorine atom and decoded into SMILES, yielding 99% of valid SMILES, with 75% of the SMILES incorporating fluorine and 56% of the structures incorporating fluorine with no other structural change.","2024-08","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","16","29","","","","","","","","","","English","","","","WOS:001305540700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","atomic descriptors; C-13; molecular operators; natural language models; PREDICTION; QSPR; SHIFTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2FSCXXRI","journalArticle","2024","Li, JT; Liang, XB; Wu, LJ; Wang, Y; Meng, Q; Qin, T; Zhang, M; Liu, TY","Randomness Regularization With Simple Consistency Training for Neural Networks","IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE","","0162-8828","10.1109/TPAMI.2024.3370716","","Randomness is widely introduced in neural network training to simplify model optimization or avoid the over-fitting problem. Among them, dropout and its variations in different aspects (e.g., data, model structure) are prevalent in regularizing the training of deep neural networks. Though effective and performing well, the randomness introduced by these dropout-based methods causes nonnegligible inconsistency between training and inference. In this paper, we introduce a simple consistency training strategy to regularize such randomness, namely R-Drop, which forces two output distributions sampled by each type of randomness to be consistent. Specifically, R-Drop minimizes the bidirectional KL-divergence between two output distributions produced by dropout-based randomness for each training sample. Theoretical analysis reveals that R-Drop can reduce the above inconsistency by reducing the inconsistency among the sampled sub structures and bridging the gap between the loss calculated by the full model and sub structures. Experiments on 7 widely-used deep learning tasks (23 datasets in total) demonstrate that R-Drop is universally effective for different types of neural networks (i.e., feed-forward, recurrent, and graph neural networks) and different learning paradigms (supervised, parameter-efficient, and semi-supervised). In particular, it achieves state-of-the-art performances with the vanilla Transformer model on WMT14 English -> German translation (30.91 BLEU) and WMT14 English -> French translation (43.95 BLEU), even surpassing models trained with extra large-scale data and expert-designed advanced variants of Transformer models.","2024-08","2025-02-26 20:41:54","2025-02-26 20:41:54","","5763-5778","","8","46","","","","","","","","","","English","","","","WOS:001262841000016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;115</p>","","","consistency training; DROPOUT; neural networks; Randomness; regularization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7U7LLTU9","journalArticle","2024","Kang, J; Poria, S; Herremans, D","Video2Music: Suitable music generation from videos using an Affective Multimodal Transformer model","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.123640","","Numerous studies in the field of music generation have demonstrated impressive performance, yet virtually no models are able to directly generate music to match accompanying videos. In this work, we develop a generative music AI framework, Video2Music, that can match a provided video. We first curated a unique collection of music videos. Then, we analyzed the music videos to obtain semantic, scene offset, motion, and emotion features. These distinct features are then employed as guiding input to our music generation model. We transcribe the audio files into MIDI and chords, and extract features such as note density and loudness. This results in a rich multimodal dataset, called MuVi-Sync, on which we train a novel Affective Multimodal Transformer (AMT) model to generate music given a video. This model includes a novel mechanism to enforce affective similarity between video and music. Finally, post -processing is performed based on a biGRU-based regression model to estimate note density and loudness based on the video features. This ensures a dynamic rendering of the generated chords with varying rhythm and volume. In a thorough experiment, we show that our proposed framework can generate music that matches the video content in terms of emotion. The musical quality, along with the quality of music -video matching is confirmed in a user study. The proposed AMT model, along with the new MuVi-Sync dataset, presents a promising step for the new task of music generation for videos.","2024-09-01","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","249","","","","","","","","","","English","","","","WOS:001224115100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;86</p>","","","Affective computing; Generative AI; Multimodal; Music generation; Music video matching; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2CYF45QR","journalArticle","2024","Yang, Y; Zhang, J; Shu, X; Pan, L; Zhang, M","A Lightweight Transformer Model for Defect Detection in Electroluminescence Images of Photovoltaic Cells","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3520239","","Solar panels play a crucial role in converting solar energy into electricity, with PhotoVoltaic (PV) modules being their core components. To ensure solar panels function well, efficient and accurate defect detection of PV modules is essential. Visual-based deep learning detection methods, such as Transformer and Convolutional Neural Network (CNN) models, provide a cost-effective and adaptable solution. Although the Transformer-based detectors outperform CNN-based ones in detection tasks, their complicated model structures also lead to great computational cost and latency, limiting their application in resource-constrained environments or time-sensitive tasks. To improve the real-time performance of the DEtection TRansformer (DETR) model on these edge devices, a novel Lightweight Decoder-only DETR (LD-DETR) is proposed for defect detection of PV modules, which achieves high performance and low computational cost with an easy architecture. We remove the resource-intensive Transformer Encoder structure from the DETR baseline so that the Decoder can directly utilize the finely fused features produced by a specialized lightweight convolution module that includes an upsample operation to preprocess the features. Experiments demonstrate that the proposed LD-DETR achieves competitive performance on the PV cell dataset of ElectroLuminescence (EL) images with an accuracy of 87.4% and an inference time of 6.1ms on GPU as well as 1.1s on embedded CPU. Our source code is available at https://github.com/SeveralYang/LD-DETR.","2024","2025-02-26 20:41:54","2025-02-26 20:41:54","","194922-194931","","","12","","","","","","","","","","English","","","","WOS:001385614200048","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Accuracy; Computational modeling; Computer architecture; Decoding; Defect detection; detection transformer; Detectors; electroluminescence; Feature extraction; LD-DETR; Microprocessors; Neck; photovoltaic; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QHJWL3TI","journalArticle","2023","Piao, S; Choi, J; Seo, S; Park, S","SELF-EdiT: Structure-constrained molecular optimisation using SELFIES editing transformer","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-023-04915-8","","Structure-constrained molecular optimisation aims to improve the target pharmacological properties of input molecules through small perturbations of the molecular structures. Previous studies have exploited various optimisation techniques to satisfy the requirements of structure-constrained molecular optimisation tasks. However, several studies have encountered difficulties in producing property-improved and synthetically feasible molecules. To achieve both property improvement and synthetic feasibility of molecules, we proposed a molecular structure editing model called SELF-EdiT that uses self-referencing embedded strings (SELFIES) and Levenshtein transformer models. The SELF-EdiT generates new molecules that resemble the seed molecule by iteratively applying fragment-based deletion-and-insertion operations to SELFIES. The SELF-EdiT exploits a grammar-based SELFIES tokenization method and the Levenshtein transformer model to efficiently learn deletion-and-insertion operations for editing SELFIES. Our results demonstrated that SELF-EdiT outperformed existing structure-constrained molecular optimisation models by a considerable margin of success and total scores on the two benchmark datasets. Furthermore, we confirmed that the proposed model could improve the pharmacological properties without large perturbations of the molecular structures through edit-path analysis. Moreover, our fragment-based approach significantly relieved the SELFIES collapse problem compared to the existing SELFIES-based model. SELF-EdiT is the first attempt to apply editing operations to the SELFIES to design an effective editing-based optimisation, which can be helpful for fellow researchers planning to utilise the SELFIES.","2023-11","2025-02-26 20:41:54","2025-02-26 20:41:54","","25868-25880","","21","53","","","","","","","","","","English","","","","WOS:001046948300004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Deep learning; DESIGN; Drug design; Levenshtein transformer; Molecular optimisation; SELFIES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YPW8YRT6","journalArticle","2023","Riedmann, C; Schichler, U; Häusler, W; Neuhold, W","Gas Losses in Transformers-Influences and Consideration","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3285413","","Dissolved gas analysis (DGA) is frequently used for the condition assessment and monitoring of transformers. In the case of free-breathing transformers, gas losses may occur at the phase interface due to the chaotic molecular movement of the dissolved gas molecules. These gas losses and the resulting distortion of the interpretation basis for the DGA can lead to a false assessment of the condition. Furthermore, the relative ratios may shift, which in turn can lead to the misclassification of the present defect. This paper deals with the influences on gas losses and describes a possible consideration for use in the condition assessment. It begins with an explanation of the gas losses problem in more detail based on theoretical considerations and summarised in hypotheses. In addition to the experimental methods used, theoretical model considerations for taking gas losses into account are described below. The results deal on the one hand with the influences on the gas losses (geometry and temperature) and the other hand with the application of the developed model for the consideration of the gas losses. In detail, the results of the gassing behaviour of different complex geometries- simple phase interfaces, a transformer model and a distribution transformer- are described in more detail and it is shown that a correction of the degassing with the model is possible within certain limits. Furthermore, the methodologies for determining the model are discussed in this paper.","2023","2025-02-26 20:41:54","2025-02-26 20:41:54","","58654-58663","","","11","","","","","","","","","","English","","","","WOS:001017317200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","dissolved gas analysis; gas losses; gas management; molecular movement; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XU3L3QYS","journalArticle","2023","Kumar, P; Pathania, K; Raman, B","Zero-shot learning based cross-lingual sentiment analysis for sanskrit text with insufficient labeled data","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-022-04046-6","","In this paper, a novel method for analyzing the sentiments portrayed by Sanskrit text has been proposed. Sanskrit is one of the world's most ancient languages; however, natural language processing tasks such as machine translation and sentiment analysis have not been explored for it to the full potential because of the unavailability of sufficient labeled data. We solved this issue using a zero-shot learning-based cross-lingual sentiment analysis (CLSA) approach. The CLSA uses the resources from the source language to enhance the sentiment analysis of the target language having insufficient resources. The proposed work translates the text from Sanskrit, a language with insufficient labeled data, to English, with sufficient labeled data for sentiment analysis using a transformer model. A generative adversarial network-based strategy has been proposed to evaluate the maturity of the translations. Then a bidirectional long short-term memory-based model has been implemented to classify the sentiments using the embeddings obtained through translations. The proposed technique has achieved 87.50% accuracy for machine translation and 92.83% accuracy for sentiment classification. Sanskrit-English translations used in this work have been collected through web scraping techniques. In the absence of the ground-truth sentiment class labels, a strategy for evaluating the sentiment scores of the proposed sentiment analysis model has also been presented. A new dataset of Sanskrit text, along with their English translations and sentiment scores, has been constructed.","2023-05","2025-02-26 20:41:54","2025-02-26 20:41:54","","10096-10113","","9","53","","","","","","","","","","English","","","","WOS:000840620400003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","Cross-lingual sentiment analysis; Labeled data insufficiency; Machine translation; Sanskrit language analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J6CM5S67","journalArticle","2025","Ahn, S; Kim, J; Shin, C; Hong, JH","Visualizing speech styles in captions for deaf and hard-of-hearing viewers","INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES","","1071-5819","10.1016/j.ijhcs.2024.103386","","Speech styles such as extension, emphasis, and pause play an important role in capturing the audience's attention and conveying a message accurately. Unfortunately, it is challenging for Deaf and Hard-of-Hearing (DHH) people to enjoy these benefits when watching lectures with common captions. In this paper, we propose a new caption system that automatically analyzes speech styles from audio and visualizes them using visualization elements such as punctuation, paint-on, color, and boldness. We conducted a comparative study with 26 DHH viewers and found that the proposed caption system enabled them to recognize the speaker's speech style in lectures. As a result, the DHH viewers were able to watch lecture videos more vividly and were more engaged with the lectures. In particular, punctuation can be a practical solution to visualize speech styles and ensure legibility. Participants expressed a desire to use our caption system in their daily lives, providing valuable insights for future soundvisualized caption research.","2025-02","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","194","","","","","","","","","","English","","","","WOS:001340029700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","Caption system; Deaf and hard-of-hearing; LANGUAGE; PERCEPTION; Punctuation; Speech analysis; Speech style; TEXT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LY76DV4R","journalArticle","2024","Shrivas, A; Deshpande, S; Gidaye, G","Wavelet-based methodology for non-invasive detection and multiclass classification of voice disorders: a comprehensive study across multilingual datasets","INTERNATIONAL JOURNAL OF BIOMEDICAL ENGINEERING AND TECHNOLOGY","","1752-6418","10.1504/IJBET.2024.143289","","Impaired voice function affects 1.2% of the global population and is often diagnosed through invasive procedures. Past efforts in automated voice disorder detection mainly tackled the binary 'healthy vs. unhealthy' classification. In this study, we suggest a non-invasive alternative based on speech analysis, diverging from the conventional invasive surgical methods. Both binary and multiclass classification is carried out in the present work by decomposing the speech signal extracted from German, Spanish, English, and Arabic datasets using discrete wavelet transform (DWT). The impact of varying decomposition levels on detection and classification accuracy is evident, with the fifth level of decomposition demonstrating the highest recognition rate of 90% to 99% for tasks involving voice disorder identification and multiclass classification. Results indicate that energy and statistical features derived from DWT offer richer information on pathological voices. Consequently, the proposed system could serve as a valuable adjunct for clinical diagnosis of laryngeal pathologies.","2024","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","4","46","","","","","","","","","","English","","","","WOS:001376994400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","AUTOMATIC DETECTION; COMPLEXITY-MEASURES; DYSPHONIA; FEATURES; IDENTIFICATION; IMPAIRMENTS; multiclass classification; PATHOLOGY DETECTION; POPULATION; PREVALENCE; SPEECH; statistical features; voice disorder; wavelet transform","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"63YNZ2NA","journalArticle","2025","Wang, F; Ma, ZM","Transmission Line Icing Prediction Based on Physically Guided Fast-Slow Transformer","ENERGIES","","1996-1073","10.3390/en18030695","","To improve the accuracy of the icing prediction model for overhead transmission lines, a physics-guided Fast-Slow Transformer icing prediction model for overhead transmission lines is proposed, which is based on the icing prediction model with meteorological input characteristics. First, the ice cover data is segmented into different time resolutions through Fourier transform; a transformer model based on Fourier transform is constructed to capture the local and global correlations of the ice cover data; then, according to the calculation model of the comprehensive load on the conductor and the conductor state equation, the variation law of ice thickness, temperature, wind speed, and tension is analyzed, and the model loss function is constructed according to the variation law to guide the training process of the model. Finally, the sample mixing enhancement algorithm is used to reduce the overfitting problem and improve the generalization performance of the prediction model. The results show that the proposed prediction model can consider the mechanical constraints in the ice growth process and accurately capture the dependence between ice cover and meteorology. Compared with traditional prediction models such as LSTM (Long Short-Term Memory) networks, its mean square error, mean absolute error, and mean absolute percentage error are reduced by 0.464-0.674, 0.41-0.53, and 8.87-11.5%, respectively, while the coefficient of determination (R2) is increased by 0.2-0.29.","2025-02","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","3","18","","","","","","","","","","English","","","","WOS:001418508000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","attention mechanism; Fourier transform; icing prediction; Mixup; physical guidance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XGZ92GM5","journalArticle","2025","Wang, RD; Xi, L; Ye, JL; Zhang, FB; Yu, X; Xu, LW","Adaptive Spatio-Temporal Relation Based Transformer for Traffic Flow Prediction","IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY","","0018-9545","10.1109/TVT.2024.3390997","","As network and autonomous driving technologies rapidly advance, traffic flow prediction has become a crucial area of research. It plays a significant role in optimizing urban traffic management and enhancing road safety, drawing increasing attention from researchers. As a specific form of time-series data, traffic flow data is often used in prediction tasks utilizing large language models. Recent developments in graph data and improvements in graph neural networks have led researchers to employ methods like adjacency and Laplacian matrices for addressing relational issues among distant nodes. However, most existing methods focus on enhancing prediction performance through network architectures or using adaptive matrices to capture spatiotemporal relationships, with limited exploration into the impact of input embedding. This paper introduces an innovative approach to traffic flow prediction, the ASTRformer, which emphasizes the fusion of spatial and temporal information in historical data through an adaptive spatio-temporal relation learning mechanism. This mechanism integrates feature embedding with adaptive spatial and temporal embeddings. A learnable spatio-temporal fusion network then parameterizes these embeddings, producing the input representations. Subsequently, a transformer model captures these representations to predict future traffic flows. Experimental results on six datasets demonstrate that our method effectively captures spatio-temporal dependencies, achieving state-of-the-art performance across various prediction metrics.","2025-02","2025-02-26 20:41:54","2025-02-26 20:41:54","","2220-2230","","2","74","","","","","","","","","","English","","","","WOS:001422041300012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","Adaptation models; AVERAGE MODEL; Data models; Forecasting; GRAPH NEURAL-NETWORKS; Multivariate time series forecasting; Predictive models; spatio-temporal prediction; Time series analysis; traffic flow prediction; transformer; Transformers; Vehicle dynamics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4K942WPM","journalArticle","2025","Liu, Y; Liu, SM; Zhang, JF; Cao, J","Real-time estimation of geomechanical characteristics using drilling parameter data and LWD","GEOENERGY SCIENCE AND ENGINEERING","","2949-8929","10.1016/j.geoen.2024.213450","","In the pursuit of real-time estimation of geomechanical characteristics, this study integrates surface drilling telemetry with Logging While Drilling (LWD) to predict shear wave velocity (Vs) and other essential elastic properties of rock formations. Real-time prediction of these parameters is crucial for enhancing wellbore stability, fracture propagation, and geosteering operations, thereby improving both safety and operational efficiency. Traditional methods, which rely solely on conventional well-logging data, often fail to incorporate the dynamic information embedded within drilling mechanics, limiting their applicability in real-time decision- making. Empirical validation using real drilling data from the Volve oil field demonstrated the enhanced performance of our self-attention-based Transformer model through the integration of drilling engineering parameters. In the initial testing, the model significantly improved the accuracy of predicting Vs , increasing it from 92% to 97.2%, alongside notable improvements in elastic property predictions. Specifically, the mean absolute error (MAE) for shear modulus decreased from 0.186 to 0.059, and bulk modulus from 0.189 to 0.040. Additionally, cross- validation using well F11A further confirmed the model's robustness, with the MAE for shear modulus decreasing from 0.134 to 0.053 upon incorporating drilling data. Compared to traditional LSTM-based models, the Transformer exhibited superior capability in extracting temporal features, validating its effectiveness in realtime elastic property prediction. These results underscore the model's capacity to enhance real-time decision- making in drilling operations.","2025-01","2025-02-26 20:41:54","2025-02-26 20:41:54","","","","","244","","","","","","","","","","English","","","","WOS:001350255900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","Drilling telemetry integration; LWD data Enhancement; Real-time geomechanical analysis; Shear wave velocity prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FGT98KKE","journalArticle","2024","Lv, ZL; Yan, R; Lin, YX; Gao, L; Zhang, F; Wang, Y","A Disentangled Representation-Based Multimodal Fusion Framework Integrating Pathomics and Radiomics for KRAS Mutation Detection in Colorectal Cancer","BIG DATA MINING AND ANALYTICS","","2096-0654","10.26599/BDMA.2024.9020012","","Kirsten rat sarcoma viral oncogene homolog (namely KRAS) is a key biomarker for prognostic analysis and targeted therapy of colorectal cancer. Recently, the advancement of machine learning, especially deep learning, has greatly promoted the development of KRAS mutation detection from tumor phenotype data, such as pathology slides or radiology images. However, there are still two major problems in existing studies: inadequate single-modal feature learning and lack of multimodal phenotypic feature fusion. In this paper, we propose a Disentangled Representation-based Multimodal Fusion framework integrating Pathomics and Radiomics (DRMF-PaRa) for KRAS mutation detection. Specifically, the DRMF-PaRa model consists of three parts: (1) the pathomics learning module, which introduces a tissue-guided Transformer model to extract more comprehensive and targeted pathological features; (2) the radiomics learning module, which captures the generic hand-crafted radiomics features and the task-specific deep radiomics features; (3) the disentangled representation-based multimodal fusion module, which learns factorized subspaces for each modality and provides a holistic view of the two heterogeneous phenotypic features. The proposed model is developed and evaluated on a multi modality dataset of 111 colorectal cancer patients with whole slide images and contrast-enhanced CT. The experimental results demonstrate the superiority of the proposed DRMF-PaRa model with an accuracy of 0.876 and an AUC of 0.865 for KRAS mutation detection.","2024-09","2025-02-26 20:41:55","2025-02-26 20:41:55","","590-602","","3","7","","","","","","","","","","English","","","","WOS:001306486900006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","CLASSIFICATION; Feature extraction; HISTOPATHOLOGY; IMAGES; KRAS mutation detection; multimodal feature fusion; Pathology; pathomics; PREDICTION; Predictive models; radiomics; Radiomics; Representation learning; Transformers; Tumors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CPT7A748","journalArticle","2024","Xu, S; Li, YW; Li, QY","A Deep Reinforcement Learning Method Based on a Transformer Model for the Flexible Job Shop Scheduling Problem","ELECTRONICS","","2079-9292","10.3390/electronics13183696","","The flexible job shop scheduling problem (FJSSP), which can significantly enhance production efficiency, is a mathematical optimization problem widely applied in modern manufacturing industries. However, due to its NP-hard nature, finding an optimal solution for all scenarios within a reasonable time frame faces serious challenges. This paper proposes a solution that transforms the FJSSP into a Markov Decision Process (MDP) and employs deep reinforcement learning (DRL) techniques for resolution. First, we represent the state features of the scheduling environment using seven feature vectors and utilize a transformer encoder as a feature extraction module to effectively capture the relationships between state features and enhance representation capability. Second, based on the features of the jobs and machines, we design 16 composite dispatching rules from multiple dimensions, including the job completion rate, processing time, waiting time, and manufacturing resource utilization, to achieve flexible and efficient scheduling decisions. Furthermore, we project an intuitive and dense reward function with the objective of minimizing the total idle time of machines. Finally, to verify the performance and feasibility of the algorithm, we evaluate the proposed policy model on the Brandimarte, Hurink, and Dauzere datasets. Our experimental results demonstrate that the proposed framework consistently outperforms traditional dispatching rules, surpasses metaheuristic methods on larger-scale instances, and exceeds the performance of existing DRL-based scheduling methods across most datasets.","2024-09","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","18","13","","","","","","","","","","English","","","","WOS:001323847200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","deep reinforcement learning; dispatching rules; flexible job shop scheduling problem; HYBRID; Markov Decision Process; SEARCH; SWARM OPTIMIZATION ALGORITHM; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"563PN3Y2","journalArticle","2024","Dong, XL; Shi, PC; Tang, YY; Yang, L; Yang, AX; Liang, TN","Vehicle Classification Algorithm Based on Improved Vision Transformer","WORLD ELECTRIC VEHICLE JOURNAL","","2032-6653","10.3390/wevj15080344","","Vehicle classification technology is one of the foundations in the field of automatic driving. With the development of deep learning technology, visual transformer structures based on attention mechanisms can represent global information quickly and effectively. However, due to direct image segmentation, local feature details and information will be lost. To solve this problem, we propose an improved vision transformer vehicle classification network (IND-ViT). Specifically, we first design a CNN-In D branch module to extract local features before image segmentation to make up for the loss of detail information in the vision transformer. Then, in order to solve the problem of misdetection caused by the large similarity of some vehicles, we propose a sparse attention module, which can screen out the discernible regions in the image and further improve the detailed feature representation ability of the model. Finally, this paper uses the contrast loss function to further increase the intra-class consistency and inter-class difference of classification features and improve the accuracy of vehicle classification recognition. Experimental results show that the accuracy of the proposed model on the datasets of vehicle classification BIT-Vehicles, CIFAR-10, Oxford Flower-102, and Caltech-101 is higher than that of the original vision transformer model. Respectively, it increased by 1.3%, 1.21%, 7.54%, and 3.60%; at the same time, it also met a certain real-time requirement to achieve a balance of accuracy and real time.","2024-08","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","8","15","","","","","","","","","","English","","","","WOS:001307508700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","contrast loss; local detail features; sparse attention module; vehicle classification; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RCMMGRHE","journalArticle","2024","Kim, S; Kim, J; Sul, HK; Hong, Y","An adaptive dual-level reinforcement learning approach for optimal trade execution","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.124263","","The purpose of this research is to devise a tactic that can closely track the daily cumulative volume -weighted average price (VWAP) using reinforcement learning while minimizing the deviation from the VWAP. Previous studies often choose a relatively short trading horizon to implement their models, making it difficult to accurately track the daily cumulative VWAP since the stock price movement is often insignificant within the short trading horizon. On the other hand, training reinforcement learning models directly over a longer, daily horizon is burdensome due to extensive sequence length. Hence, there is a need for a method that can divide the long daily horizon into smaller, more manageable segments. We propose a method that leverages the U-shaped pattern of intraday stock trade volumes and uses Proximal Policy Optimization (PPO) as the learning algorithm. Our method follows a dual -level approach: a Transformer model that captures the overall (global) distribution of daily volumes in a U -shape, and a LSTM model that handles the distribution of orders within smaller (local) time intervals. The results from our experiments suggest that this dual -level architecture improves cumulative VWAP tracking accuracy compared to previous reinforcement learning approaches. The key finding is that explicitly accounting for the U-shaped intraday volume pattern leads to better performance in approximating the cumulative daily VWAP. This has implications for developing trading strategies that need to efficiently track VWAP over a full trading day.","2024-10-15","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","252","","","","","","","","","","English","","","","WOS:001245090900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Markov decision process; Optimal trade execution; Proximal policy optimization; Reinforcement learning; Volume-weighted average price","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZU6Z8RLM","journalArticle","2024","Suresh, A; Bolla, DR; Kalpana, YB; Jawahar, JG; Shareef, RMM; Vignesh, RS","Analysing the impact on groundwater quality using dynamic programming and vision transformer","GROUNDWATER FOR SUSTAINABLE DEVELOPMENT","","2352-801X","10.1016/j.gsd.2024.101159","","The demand for sustainable water sources has intensified the focus on ground water harvesting, necessitating rigorous quality analysis for diverse applications. The existing methods for ground water quality analysis are briefly discussed, revealing a research gap in optimizing the sampling and testing process. To address this gap, we employ Dynamic Programming, which is utilized to streamline the sampling and testing process by selecting optimal locations and times. This study proposes a new methodology that combines Dynamic Programming (DP) and the Vision Transformer (ViT) model to evaluate the impact on ground water quality efficiently. This optimization not only enhances data comprehensiveness but also minimizes resource utilization, a crucial aspect in resource -constrained environments. The incorporation of the Vision Transformer model into the methodology brings a novel dimension to ground water quality analysis. ViT, a cutting -edge deep learning model for image analysis, is adapted to process visual data from ground water samples. This includes identifying contaminants, suspended solids, and microbial content, providing a more holistic understanding of ground water quality than traditional methods. Results from our integrated approach demonstrate its efficiency and accuracy in assessing ground water quality. It achieves a 10 - 15% boost in sampling optimization efficiency, 5 - 10% improvement in visual data accuracy, and 5 - 10% increase in precision. DP-ViT reduces resource utilization by 15 - 20% and consistently offers 5 - 10% higher data coverage.","2024-05","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","25","","","","","","","","","","English","","","","WOS:001224077500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","Dynamic programming; Ground water quality; POLLUTION; RAINWATER; Resource optimization; Sustainability; Vision transformer; Water analysis; Water safety","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TN9N2FNE","journalArticle","2024","Yuan, Q; Zhu, M; Li, YS; Liu, HZ; Guo, S","Feature-Interaction-Enhanced Sequential Transformer for Click-Through Rate Prediction","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14072760","","Click-through rate (CTR) prediction plays a crucial role in online services and applications, such as online shopping and advertising. The performance of CTR prediction can have a direct impact on user experience and the revenue of the online platforms. For CTR prediction models, self-attention-based methods have been widely applied to this field. Recent works generally adopted the Transformer architecture, where the self-attention mechanism can capture the global dependencies of the user's historical interactions and predict the next item. Despite the effectiveness of self-attention methods in modeling sequential user behaviors, most sequential recommenders hardly exploit feature interaction techniques to extract high-order feature combinations. In this paper, we propose a Feature-Interaction-Enhanced Sequence Model (FESeq), which integrates feature interaction and the sequential recommendation model in a cascading structure. Specifically, the interacting layer in FESeq is an automatic feature engineering step for the Transformer model. Then, we add a linear time interval embedding layer and a positional embedding layer to the Transformer in the sequence-refiner layer to learn both the time intervals and the position information in the user's sequence behaviors. We also design an attention-based sequence pooling layer that can model the relevance of the user's historical behaviors and the target item representation through scaled bilinear attention. Our experiments show that the proposed method beats all the baselines on both public and industrial datasets.","2024-04","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","7","14","","","","","","","","","","English","","","","WOS:001200892600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","click-through-rate prediction; feature interaction; self-attention; sequence pooling; sequential recommendation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3F7H6ISH","journalArticle","2024","Liu, F; Fan, ZM; Hu, W; Xu, D; Peng, M; He, J; He, YX","Vision Transformer-based overlay processor for Edge Computing","APPLIED SOFT COMPUTING","","1568-4946","10.1016/j.asoc.2024.111421","","Accelerating Visual Neural Networks in Edge Computing environments is crucial for processing image and video data. Visual Neural Networks, including Convolutional Neural Networks and Vision Transformers, are central to image recognition, video analysis, and object detection tasks. Deploying these networks on edge devices and accelerating them can significantly enhance data processing speed and efficiency. The large number of parameters, complex computational flows, and various structural variants of Transformer models present both opportunities and challenges. We propose Vis-TOP (Vision Transformer Overlay Processor) , an overlay processor designed for all types of Vision Transformer models. Vis-TOP, distinct from coarse -grained general-purpose accelerators like GPUs and fine-grained custom designs, encapsulates Vision Transformer characteristics into a three -layer, two -level mapping structure, enabling flexible model switching without hardware architecture modifications. Concurrently, we designed a corresponding instruction bundle and hardware architecture within this mapping structure. We implemented the overlay processor design on the ZCU102 after quantizing the Swin Transformer model to 8 -bit fixed points (fix_8). Experimentally, our throughput surpasses GPU implementation by 1.5 times. Our throughput per DSP is 2.2 to 11.7 times higher than that of existing Transformer -like accelerators. Overall, our approach satisfies real-time AI requirements in resource consumption and inference speed. Vis-TOP offers a cost-effective image processing solution for Edge Computing on reconfigurable devices, enhancing computational resource utilization, saving data transfer time and costs, and reducing latency.","2024-05","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","156","","","","","","","","","","English","","","","WOS:001221535700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Edge computing; Neural networks; OPU; Overlay processor; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EGBUGGMC","journalArticle","2024","Ferdous, GJ; Sathi, KA; Hossain, MA; Dewan, MAA","SPT-Swin: A Shifted Patch Tokenization Swin Transformer for Image Classification","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3448304","","Recently, the transformer-based model e.g., the vision transformer (ViT) has been extensively used in computer vision tasks. The superior performance of the ViT leads to the requirement of an enormous dataset and the complexity of calculating self-attention between patches is quadratic in nature. To acknowledge these two concerns, this paper proposes a novel shifted patch tokenization swin transformer (SPT-Swin) for the image classification task. The shifted patch tokenization (SPT) compensates for the data deficiency by increasing the data samples based on spatial information of the image patches while the swin transformer provides linear computational complexity by calculating self-attention between the shifted window based patches. For model validation, the SPT-Swin framework is trained on popular benchmark image datasets such as ImageNet-1K, CIFAR-10 and CIFAR-100, and the classification accuracies are found 89.45%, 95.67% and 92.95% respectively. Moreover, the comparative analysis of the proposed model with the existing state-of-the-art models shows that the classification performances are improved by 7.05%, 4.14%, and 8.30% for the ImageNet-1K, CIFAR-10 and CIFAR-100 datasets respectively. Therefore, our proposed SPT-based data augmentation technique with the core swin transformer model could be a data-efficient linear complex-able model for future computer vision tasks.","2024","2025-02-26 20:41:55","2025-02-26 20:41:55","","117617-117626","","","12","","","","","","","","","","English","","","","WOS:001303425900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Computational modeling; Computer vision; Data efficiency; Data integrity; Data models; Feature extraction; image classification; Image classification; linear complexity; shifted patch tokenization; swin transformer; Tokenization; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CZBA5ILJ","journalArticle","2024","Xu, ZQ; Du, MY; Zhang, YJ; Miao, Q","DTST: A Dual-Aspect Time Series Transformer Model for Fault Diagnosis of Space Power System","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2024.3396856","","Fault diagnosis is one of the key technologies for maintaining the reliability and safety of space power systems. High-precision fault diagnosis is crucial to ensuring the normal operation of the system. In recent years, fault diagnosis methods based on traditional deep learning models have matured, but these models have problems capturing long distance dependencies in sequences and are limited to modeling in the temporal dimension. To address these challenges, this article proposes a novel fault diagnosis method for space power systems, namely dual-aspect time series transformer (DTST). DTST first adopts a token sequence generation method to decompose the data into two sets of sequence tokens in the temporal and spatial dimensions. Then, by introducing the Transformer, it obtains class tokens for these two sets of sequence tokens and merges them into a global class token for performing fault diagnosis tasks. To validate the rationality of the DTST structural design, this article conducts comprehensive experiments on the space power system dataset and real telemetry dataset. The experimental results show that, compared to single-structure models, DTST with a dual-structure design performs superiorly in diagnostic performance. Meanwhile, the fusion of dual-structure design has also been adequately demonstrated. Compared to traditional deep learning models and Transformer variant models, DTST demonstrates superior performance and robustness.","2024","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","73","","","","","","","","","","English","","","","WOS:001227320200011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Fault diagnosis; Feature extraction; Power systems; robustness; Sensor fusion; Sensors; space power system; Time series analysis; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MEZ9AEKQ","journalArticle","2024","Wang, HY; Gao, S; Zhang, XM","A method for analyzing handwritten program flowchart based on detection transformer and logic rules","INTERNATIONAL JOURNAL ON DOCUMENT ANALYSIS AND RECOGNITION","","1433-2833","10.1007/s10032-024-00506-6","","Handwritten program flowcharts can describe program design ideas and algorithms, which is helpful for users to understand and analyze the execution process of programs. Hence, accurately recognizing and analyzing handwritten program flowcharts is essential. However, there are still some challenges in the process of recognizing and analyzing the handwritten program flowcharts, such as accurately recognizing the borders, avoiding potential confusion between the borders and the text, and understanding the logical structure information of the flowchart. To address these issues, this paper introduces a method for recognizing and analyzing handwritten program flowcharts. Specifically, we propose integrating the learnable reference boxes mechanism and semantic alignment mechanism into the Detection Transformer model (LS-DETR) to enhance its performance in recognizing borders in a flowchart. In addition, a strategy for analyzing the logic structure of flowcharts based on logic rules has been proposed, which can check the execution logical structure of program flowcharts and examines the number of loops and the execution times of loop bodies within them. The logic rules are derived from knowledge related to flowchart construction principles, program execution principles, and other relevant information. Experimental results demonstrate that the LS-DETR exhibits a 2.39% increase in Average Precision (AP) compared to the DETR, while also achieving nearly 8.3 times faster convergence speed. The example demonstrates that the execution process of a flowchart can be accurately analyzed and judged based on logic rules.","2024-11-06","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","","","","","","","","","","","English","","","","WOS:001348619700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Detection transformer; Handwritten program flowchart; Logic rules; Structure analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"23MDPI7N","journalArticle","2024","Khoshkhahtinat, A; Zafari, A; Mehta, PM; Nasrabadi, NM; Thompson, BJ; Kirk, MSF; da Silva, DE","Neural-Based Video Compression on Solar Dynamics Observatory Images","IEEE TRANSACTIONS ON AEROSPACE AND ELECTRONIC SYSTEMS","","0018-9251","10.1109/TAES.2024.3409524","","NASA's Solar Dynamics Observatory (SDO) mission collects extensive data to monitor the Sun's daily activity. In the realm of space mission design, data compression plays a crucial role in addressing the challenges posed by limited telemetry rates. The primary objective of data compression is to facilitate efficient data management and transmission to work within the constrained bandwidth, thereby ensuring that essential information is captured while optimizing the utilization of available resources. This article introduces a neural video compression technique that achieves a high compression ratio for the SDO's image data collection. The proposed approach focuses on leveraging both temporal and spatial redundancies in the data, leading to a more efficient compression. In this work, we introduce an architecture based on the transformer model, which is specifically designed to capture both local and global information from input images in an effective and efficient manner. In addition, our network is equipped with an entropy model that can accurately model the probability distribution of the latent representations and improves the speed of the entropy decoding step. The entropy model leverages a channel-dependent approach and utilizes checkerboard-shaped local and global spatial contexts. By combining the transformer-based video compression network with our entropy model, the proposed compression algorithm demonstrates superior performance over traditional video codecs like H.264 and H.265, as confirmed by our experimental results.","2024-10","2025-02-26 20:41:55","2025-02-26 20:41:55","","6685-6701","","5","60","","","","","","","","","","English","","","","WOS:001338570700025","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;84</p>","","","Adaptation models; Context modeling; Decoding; Entropy; Entropy model; Image coding; neural video compression; Solar Dynamics Observatory (SDO); Transform coding; transformer; Video compression","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ET4WB7IY","journalArticle","2024","Yan, BY; Tian, JL; Wan, J; Qiu, Y; Chen, WM","Real-time prediction of horizontal drilling pressure based on convolutional Transformer","CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE","","1532-0626","10.1002/cpe.8006","","During horizontal drilling operations, real-time prediction of drilling pressure during the drilling process can help the drilling team cope with the complex and changing working environment downhole, adjust the parameters of the drilling rig promptly, make correct decisions, reduce the probability of drilling accidents, and avoid affecting the duration and cost of the project. This study provides a method for real-time prediction of the drilling pressure of horizontal drilling rigs. A deep learning model based on a convolutional Transformer is trained for accurate real-time prediction by extracting real-time operating data of the horizontal drilling rig from the data acquisition system. The method proposed in this study can be a useful tool to improve the performance of horizontal drilling rigs and can assist the drilling team in operating horizontal drilling rigs. The results of the case study show that: (1) the proposed convolutional Transformer model provides reliable real-time prediction with an MAE of 0.304 MPa and an RMSE of 0.508 MPa; (2) the proposed method can quickly and accurately predict the trend of drilling pressure change in the next period based on the current change of drilling pressure, and grasp the dynamics of drilling pressure of horizontal drilling rigs in advance. Further research could focus on assisted decision-making and intelligent optimization to provide solutions for preventing drilling accidents and improving horizontal rig performance based on the prediction.","2024-05-01","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","10","36","","","","","","","","","","English","","","","WOS:001135780700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","ALGORITHM; deep learning; drilling process; horizontal drilling rig; NETWORKS; predictive model; real-time prediction; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3SMM5PVM","journalArticle","2024","Shamim, R; Shaikh, A","Harnessing the power of hugging face's multilingual transformers: unravelling the code-mixed named entity recognition enigma","INTERNATIONAL JOURNAL OF INTELLIGENT ENGINEERING INFORMATICS","","1758-8715","10.1504/IJIEI.2024.140171","","Named entity recognition (NER) in code-mixed documents, which have different languages, is hard for natural language processing. In this paper, we use hugging face's multilingual transformers to come up with a way to do code-mixed NER without any problems. Our work tries to solve the problems that come up when you try to recognise named entities in more than one language within the same text. We did thorough tests by fine-tuning the multilingual transformer model on a dataset with mixed codes. With an F1-score of 0.85, we got great results. This works better than previous methods and proves that our model can accurately find named items. We also examine at how well the model works with other language pairs and code-mixed patterns. This shows how well the model can handle different language situations. Our study helps us understand how to handle data in multiple languages, makes code-mixed NER techniques better, and shows how multilingual transformers can help break down language barriers. The research has implications for areas that need to understand more than one language, such as analysing social media, creating language-specific customer service systems, and finding information across languages. Speaking different languages can communicate more easily and effectively in these fields, which encourage inclusion.","2024","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","3","12","","","","","","","","","","English","","","","WOS:001279069100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","code-mixed texts; cross-lingual knowledge transfer; evaluation metrics; fine-tuning; hugging face's multilingual transformers; named entity recognition; NER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"94UILTVN","journalArticle","2023","Zhao, ZP; Hao, K; Liu, XF; Zheng, TC; Xu, JJ; Cui, SY; He, C; Zhou, J; Zhao, GM","MCANet: Hierarchical cross-fusion lightweight transformer based on multi-ConvHead attention for object detection","IMAGE AND VISION COMPUTING","","0262-8856","10.1016/j.imavis.2023.104715","","The visual Transformer model based on self-attention has achieved better performance than convolutional neural networks in object detection tasks. However, existing visual Transformer models are typically heavy-weight to extract global features. In contrast, CNNs can extract features with fewer parameters and computational costs. To combine the advantages of convolutional processing at the local level with the advantages of the Trans-former's global interaction, this paper proposes MCANet, a Hierarchical Cross-Fusion Lightweight Transformer Based on Multi-ConvHead Attention for Object Detection. To bi-directionally fuse local and global features, MCANet adds two improved transformers (MCA-Former) for global interaction and two novel feature fusion modules MCA-CSP. MCA-Former uses a novel self-attention computation method named Multi-ConvHead Atten-tion(MCA) based on multi-scale depth-separable convolution, which reduces the computational cost by 2/3. Meanwhile, the number of model parameters is reduced to 9.49 M by using channel segmentation and multi-layer cross-fusion strategies. On the Pascal VOC and COCO datasets, the proposed model outperforms YOLOv4-Tiny in terms of AP by 2.43% and 1.8%, respectively. Additionally, MCANet is also superior to many latest light-weight object detection models. Results of various ablation experiments also verify the effectiveness of the pro-posed method. & COPY; 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).","2023-08","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","136","","","","","","","","","","English","","","","WOS:001021487600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Attention mechanism; Feature fusion; Object detection; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6L79UX6P","journalArticle","2022","Kumar, A; Bhalja, BR; Kumbhar, GB","Approach for Identification of Inter-Turn Fault Location in Transformer Windings Using Sweep Frequency Response Analysis","IEEE TRANSACTIONS ON POWER DELIVERY","","0885-8977","10.1109/TPWRD.2021.3092397","","As inter-turn faults in transformer windings are the most severe, their delayed detection and localization may create extensive damage to the winding. Therefore, a new inter-turn fault localization methodology based on sweep frequency response analysis (SFRA) through calculation of Pre-fault Inter-Turn Fault Factor (ITFFpre) for all possible fault locations by estimating the values of series and shunt capacitance of the windings during healthy conditions is presented. For a faulty transformer, Post-fault Inter-Turn Fault Factor (ITFFpost) is calculated by determining the value of equivalent capacitance using SFRA. The exact fault location in the faulty transformer is obtained by comparing the single calculated value of ITFFpost of the faulty transformer with the values stored in the lookup table. The efficacy of the suggested approach is verified by performing faults at various locations on the transformer model developed in the laboratory. Its authenticity is also verified on an existing 400 kVA, 11 kV/440 V distribution transformer installed in the real field. The results indicate that the suggested method is capable to identify inter-turn fault location with the minimum ladder network parameters. Finally, a relative assessment of the suggested approach with numerous other methods confirms the superiority in terms of inter-turn fault localization.","2022-06","2025-02-26 20:41:55","2025-02-26 20:41:55","","1539-1548","","3","37","","","","","","","","","","English","","","","WOS:000800228100022","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Capacitance; CAPACITANCE; CIRCUIT; Circuit faults; CONSTRUCTION; FAILURES; fault location; Fault location; FRA; Frequency response; Impedance; Location awareness; parameter estimation; Power transformer insulation; POWER TRANSFORMERS; STATISTICAL APPROACH; transformer winding; Windings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ILRPQGP3","journalArticle","2025","Alshawabkeh, S; Wu, L; Dong, DJ; Cheng, Y; Li, LP","A Hybrid Approach for Pavement Crack Detection Using Mask R-CNN and Vision Transformer Model","CMC-COMPUTERS MATERIALS & CONTINUA","","1546-2218","10.32604/cmc.2024.057213","","Detecting pavement cracks is critical for road safety and infrastructure management. Traditional methods, relying on manual inspection and basic image processing, are time-consuming and prone to errors. Recent deep-learning (DL) methods automate crack detection, but many still struggle with variable crack patterns and environmental conditions. This study aims to address these limitations by introducing the MaskerTransformer, a novel hybrid deep learning model that integrates the precise localization capabilities of Mask Region-based Convolutional Neural Network (Mask R-CNN) with the global contextual awareness of Vision Transformer (ViT). The research focuses on leveraging the strengths of both architectures to enhance segmentation accuracy and adaptability across different pavement conditions. We evaluated the performance of the MaskerTransformer against other state-of-the(Swin-UNETr), You Only Look Once version 8 (YoloV8), and Mask R-CNN using two benchmark datasets: Crack500 and DeepCrack. The findings reveal that the MaskerTransformer significantly outperforms the existing models, achieving the highest Dice Similarity Coefficient (DSC), precision, recall, and F1-Score across both datasets. Specifically, the model attained a DSC of 80.04% on Crack500 and 91.37% on DeepCrack, demonstrating superior segmentation accuracy and reliability. The high precision and recall rates further substantiate its effectiveness in real-world applications, suggesting that the MaskerTransformer can serve as a robust tool for automated pavement crack detection, potentially replacing more traditional methods.","2025","2025-02-26 20:41:55","2025-02-26 20:41:55","","561-577","","1","82","","","","","","","","","","English","","","","WOS:001397768600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","deep learning; image segmentation; Mask R-CNN; Pavement crack segmentation; transportation; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QQH5DJP3","journalArticle","2024","Shen, JL; Hai, YM; Lin, CY","CT-UFormer: an improved hybrid decoder for image segmentation","VISUAL COMPUTER","","0178-2789","10.1007/s00371-024-03726-3","","Segmentation of lung nodules in medical images is crucial for early detection and treatment planning of lung cancer. The nnU-Net has achieved significant success in numerous medical image segmentation tasks due to its efficient design. However, nnU-Net demonstrates limitations in capturing long-range dependencies. In contrast, the Transformer model effectively manages long-range dependencies through global self-attention mechanisms. In this paper, we propose an improved nnU-Net with a Transformer decoder to segment lung nodules and identify regions of interest. The data augmentation module can increase the amount of available data. It includes two key components: 1) GAN generates lung nodules to increase the number of available datasets; 2) hybrid decoder captures multi-scale feature maps to enable the refinement of ""organ label sets."" Our extensive evaluations on two datasets of different sizes, MSD-Lung and LIDC-IDRI, reveal the effectiveness of our contributions in terms of both efficiency and accuracy. Our results are superior to commonly used state-of-the-art works. Compared to the results of existing improved Transformers, our method performs excellently in terms of DSC, MASD, and HD95 metrics. This study proposes a new lung nodule segmentation method, which has higher accuracy and robustness compared to commonly used methods. The method automatically performs effective data augmentation on input data and balances global features and local details through a hybrid decoder. Code is available at https://github.com/andou6/CT-UFormer.","2024-12-05","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","","","","","","","","","","","English","","","","WOS:001370713500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Data augmentation; Decoder; Lung nodule segmentation; NETWORK; PLUS PLUS; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HEW6HHZS","journalArticle","2024","Peng, H; Moore, C; Saha, D; Jiang, S; Timmerman, R","Understanding the PULSAR effect in combined radiotherapy and immunotherapy using transformer-based attention mechanisms","FRONTIERS IN ONCOLOGY","","2234-943X","10.3389/fonc.2024.1497351","","PULSAR (personalized, ultra-fractionated stereotactic adaptive radiotherapy) is the adaptation of stereotactic ablative radiotherapy towards personalized cancer management. It has potential to harness the synergy between radiation therapy and immunotherapy, such as immune checkpoint inhibitors to amplify the anti-tumor immune response. For the first time, we applied a transformer-based attention mechanism to investigate the underlying interactions between combined PULSAR and PD-L1 blockade immunotherapy, based on the preliminary experimental results of a murine cancer model (Lewis Lung Carcinoma, LLC). The radiation and administration of alpha-PD-L1 were viewed as two external stimulation signals occurring in a temporal sequence. Our study demonstrates the utility of a transformer model in 1) predicting tumor changes in response to specific treatment schemes, and 2) generating self-attention and cross-attention maps. The cross-attention maps serve as a biological representation of the semantic similarity between source and target sentences in neural translation, offering insights into the causal relationships of the PULSAR effect. Our model offers a unique perspective with the potential to enhance the understanding of the temporal dependencies of the PULSAR effect on time, dose, and T cell dynamics. In a broader context, our proposed framework offers the potential to explore varying intervals and doses for subsequent treatments while monitoring the biological parameters impacted by these perturbations. This approach can lead to more personalized and rational radiation or drug interactions.","2024-12-02","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","14","","","","","","","","","","English","","","","WOS:001377706900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","AI; ANTITUMOR IMMUNITY; BALANCE; BODY IRRADIATION; immunotherapy; PULSAR; RADIATION-THERAPY; radiotherapy; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T7WH95T3","journalArticle","2024","Li, D; Tang, JQ; Zhou, B; Cao, P; Hu, J; Leung, MF; Wang, YG","Toward Resilient Electric Vehicle Charging Monitoring Systems: Curriculum Guided Multi-Feature Fusion Transformer","IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS","","1524-9050","10.1109/TITS.2024.3456843","","With the booming adoption of Electric Vehicles (EVs) globally, the need for reliable and resilient EV Charging Monitoring (EVCM) systems has become crucial. A major challenge in real-time EVCM is the handling of missing data caused by unexpected events, which can impair both real-time monitoring and its downstream applications. To address this vital yet underexplored issue, we propose a curriculum guided multi-feature fusion transformer (CurriFusFormer) learning framework - a novel approach designed to enhance the resilience of EVCM systems against real-time information omissions. Our framework integrates curriculum learning with a multi-feature fusion transformer model, capable of handling various patterns and rates of missing data, ranging from random to block omissions. This innovative approach leverages spatial, temporal, and static features to generate accurate real-time estimations for missing values in diverse scenarios. Extensive experiments on a real-world EVCM dataset demonstrate that CurriFusFormer can perform well with R-2 ranging from 0.92 to 0.83 given the rising missing rate from 30-90%, outperforming seven popular and state-of-the-art methods, especially in scenarios with high missing rates and complex patterns, such as, at 90% missing rate, kNN (R-2 = 0.65), XGBoost (R-2 = 0.78), BRITS (R-2 = 0.79), TFT (R-2 = 0.80), and GRIN (R-2 = 0.82). All results suggest that the proposed framework could be a promising solution for developing future resilient EVCM networks.","2024-12","2025-02-26 20:41:55","2025-02-26 20:41:55","","21356-21366","","12","25","","","","","","","","","","English","","","","WOS:001329035400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Electric vehicle; EV charging infrastructure; feature fusion; IMPUTATION; resilience; spatio-temporal data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SKNZLWUV","journalArticle","2024","Zipoli, F; Ayadi, Z; Schwaller, P; Laino, T; Vaucher, AC","Completion of partial chemical equations","MACHINE LEARNING-SCIENCE AND TECHNOLOGY","","2632-2153","10.1088/2632-2153/ad5413","","Inferring missing molecules in chemical equations is an important task in chemistry and drug discovery. In fact, the completion of chemical equations with necessary reagents is important for improving existing datasets by detecting missing compounds, making them compatible with deep learning models that require complete information about reactants, products, and reagents in a chemical equation for increased performance. Here, we present a deep learning model to predict missing molecules using a multi-task approach, which can ultimately be viewed as a generalization of the forward reaction prediction and retrosynthesis models, since both can be expressed in terms of incomplete chemical equations. We illustrate that a single trained model, based on the transformer architecture and acting on reaction SMILES strings, can address the prediction of products (forward), precursors (retro) or any other molecule in arbitrary positions such as solvents, catalysts or reagents (completion). Our aim is to assess whether a unified model trained simultaneously on different tasks can effectively leverage diverse knowledge from various prediction tasks within the chemical domain, compared to models trained individually on each application. The multi-task models demonstrate top-1 performance of 72.4%, 16.1%, and 30.5% for the forward, retro, and completion tasks, respectively. For the same model we computed round-trip accuracy of 83.4%. The completion task exhibiting improvements due to the multi-task approach.","2024-06-01","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","2","5","","","","","","","","","","English","","","","WOS:001249926300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;84</p>","","","artificial intelligence in chemistry; CLASSIFICATION; DESIGN; LANGUAGE; machine learning; missing compounds inference; MODELS; NEURAL-NETWORKS; PERFORMANCE; PREDICTION; RETROSYNTHESIS; SMILES; TRANSFORMER; transformer model; unified chemical model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GZ43IU9D","journalArticle","2024","Zhao, J; Qiu, ZY; Hu, HQ; Sun, SL","HWLane: HW-Transformer for Lane Detection","IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS","","1524-9050","10.1109/TITS.2024.3386531","","Lane detection is one of the most fundamental tasks in autonomous driving perception, but it still faces many challenges in some special driving scenarios. For example, in dazzling light, crowded roads, etc., lane detection is very dependent on surrounding visual cues. Previous segmentation-based lane detection methods have not paid enough attention to the surrounding visual range, resulting in poor performance. In this paper, we design a novel lane detection network namely HW-Transformer, which is based on row and column multi-head self-attention. It restricts the attention only to their respective rows and columns, and transfers information across rows and columns by intersection features. In this way, the attention to the visual range around the lane is greatly expanded, and the communication of global information can be achieved through intersecting features. In addition, we further propose a self-attention knowledge distillation (SAKD) method for the Transformer model, where higher-level attention guides lower-level attention to learn. SAKD not only helps to improve the performance of lane detection, but also has universality in better learning semantic features from general images. Extensive experiments on BDD100K, TuSimple, CULane, and VIL100 datasets demonstrate that our method outperforms the state-of-the-art segmentation-based lane detection methods. We also apply the proposed SAKD to DeiT-tiny, and it achieves 1.51 Top-1 accuracy improvement on ImageNet-1K dataset. Our code will be available at https://github.com/Cuibaby/HWLane.","2024-08","2025-02-26 20:41:55","2025-02-26 20:41:55","","9321-9331","","8","25","","","","","","","","","","English","","","","WOS:001208858800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","Deep learning; lane detection; self-knowledge distillation; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S6MSH6B5","journalArticle","2024","Tipirneni, S; Zhu, M; Reddy, CK","StructCoder: Structure-Aware Transformer for Code Generation","ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA","","1556-4681","10.1145/3636430","","There has been a recent surge of interest in automating software engineering tasks using deep learning. This article addresses the problem of code generation, in which the goal is to generate target code given source code in a different language or a natural language description. Most state-of-the-art deep learning models for code generation use training strategies primarily designed for natural language. However, understanding and generating code requires a more rigorous comprehension of the code syntax and semantics. With this motivation, we develop an encoder-decoder Transformer model in which both the encoder and decoder are explicitly trained to recognize the syntax and dataflow in the source and target codes, respectively. We not only make the encoder structure aware by leveraging the source code's syntax tree and dataflow graph, but we also support the decoder in preserving the syntax and dataflow of the target code by introducing two novel auxiliary tasks: Abstract Syntax Tree (AST) path prediction and dataflow prediction. To the best of our knowledge, this is the first work to introduce a structure-aware Transformer decoder that models both syntax and dataflow to enhance the quality of generated code. The proposed StructCoder model achieves state-ofthe-art performance on code translation and text-to-code generation tasks in the CodeXGLUE benchmark and improves over baselines of similar size on the APPS code generation benchmark. Our code is publicly available at https://github.com/reddy- lab-code- research/StructCoder/.","2024-04","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","3","18","","","","","","","","","","English","","","","WOS:001168400500023","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","code generation; Deep learning; language models; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C45MH3EC","journalArticle","2024","Alabbas, A; Alomar, K","Tayseer: A Novel AI-Powered Arabic Chatbot Framework for Technical and Vocational Student Helpdesk Services and Enhancing Student Interactions","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14062547","","The rise of conversational agents (CAs) like chatbots in education has increased the demand for advisory services. However, student-college admission interactions remain manual and burdensome for staff. Leveraging CAs could streamline the admission process, providing efficient advisory support. Moreover, limited research has explored the role of Arabic chatbots in education. This study introduces Tayseer, an Arabic AI-powered web chatbot that enables instant access to college information and communication between students and colleges. This study aims to improve the abilities of chatbots by integrating features into one model, including responding with audiovisuals, various interaction modes (menu, text, or both), and collecting survey responses. Tayseer uses deep learning models within the RASA framework, incorporating a customized Arabic natural language processing pipeline for intent classification, entity extraction, and response retrieval. Tayseer was deployed at the Technical College for Girls in Najran (TCGN). Over 200 students used Tayseer during the first semester, demonstrating its efficiency in streamlining the advisory process. It identified over 50 question types from inputs with a 90% precision in intent and entity predictions. A comprehensive evaluation illuminated Tayseer's proficiency as well as areas requiring improvement. This study developed an advanced CA to enhance student experiences and satisfaction while establishing best practices for education chatbot interfaces by outlining steps to build an AI-powered chatbot from scratch using techniques adaptable to any language.","2024-03","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","6","14","","","","","","","","","","English","","","","WOS:001191595600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","Arabic chatbot; DIET; RASA; transformer model; vocational education","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W64RBUF3","journalArticle","2024","Zhang, YZ; Li, YC","APT Attack Detection of a New Power System based on DPI-transformer","RECENT ADVANCES IN ELECTRICAL & ELECTRONIC ENGINEERING","","2352-0965","10.2174/2352096516666230504111123","","Introduction: In recent years, the frequent occurrence of network security attacks in the power field has brought huge risks to the production, transmission, and supply of power systems, and Advanced Persistent Threat (APT) is a covert advanced network security attack, which has become one of the network security risks that cannot be ignored in the construction of new power systems. Objective: This study aims to resist the increasing risk of APT attacks in the construction of new power systems, this paper proposes an attack detection model based on Deep Packet Inspection (DPI) and Transformer. Methods: Firstly, we extracted 606 traffic characteristics from the original traffic data through the extended CIC Flowmeter and used them all to train the Transformer network. Then, we used the DPI-Transformer model and traffic labels to perform feature analysis on the traffic data and finally obtained the APT-Score. If the APT-Score is greater than the threshold, the alarm module is triggered. Results: By analyzing the headers and payloads of the network traffic in the APT-2020 dataset, the experimental results show that the detection accuracy of APT attacks by the DPI-Transformer detection model is significantly higher than that of the current mainstream APT attack detection algorithms. Conclusion: Combined with the characteristics of the new power system and APT attacks, this paper proposes an attack detection model DPI-Transformer, which proves that the model has greatly improved the detection accuracy.","2024","2025-02-26 20:41:55","2025-02-26 20:41:55","","99-106","","2","17","","","","","","","","","","English","","","","WOS:001262120800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","advanced persistent threat; attacks; deep packet inspection; New power system; transformer; transmission","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"27IYFTNX","journalArticle","2023","de Zarzà, I; de Curtò, J; Roig, G; Calafate, CT","LLM Multimodal Traffic Accident Forecasting","SENSORS","","1424-8220","10.3390/s23229225","","With the rise in traffic congestion in urban centers, predicting accidents has become paramount for city planning and public safety. This work comprehensively studied the efficacy of modern deep learning (DL) methods in forecasting traffic accidents and enhancing Level-4 and Level-5 (L-4 and L-5) driving assistants with actionable visual and language cues. Using a rich dataset detailing accident occurrences, we juxtaposed the Transformer model against traditional time series models like ARIMA and the more recent Prophet model. Additionally, through detailed analysis, we delved deep into feature importance using principal component analysis (PCA) loadings, uncovering key factors contributing to accidents. We introduce the idea of using real-time interventions with large language models (LLMs) in autonomous driving with the use of lightweight compact LLMs like LLaMA-2 and Zephyr-7b-alpha. Our exploration extends to the realm of multimodality, through the use of Large Language-and-Vision Assistant (LLaVA)-a bridge between visual and linguistic cues by means of a Visual Language Model (VLM)-in conjunction with deep probabilistic reasoning, enhancing the real-time responsiveness of autonomous driving systems. In this study, we elucidate the advantages of employing large multimodal models within DL and deep probabilistic programming for enhancing the performance and usability of time series forecasting and feature weight importance, particularly in a self-driving scenario. This work paves the way for safer, smarter cities, underpinned by data-driven decision making.","2023-11","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","22","23","","","","","","","","","","English","","","","WOS:001119927100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;20<br/>Total Times Cited:&nbsp;&nbsp;20<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","accident forecasting; LLaVA; LLM; PCA loadings; time series analysis; transformers; VLM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"98CJBTK6","journalArticle","2023","Lotfipoor, A; Patidar, S; Jenkins, DP","Transformer network for data imputation in electricity demand data","ENERGY AND BUILDINGS","","0378-7788","10.1016/j.enbuild.2023.113675","","Load forecasting necessitates a significant amount of smart meter data. Several elements in this process, including device malfunctions and signal transmission issues, produce missing data gaps. Missing values in the dataset significantly influence the learning ability of machine learning algorithms, and they must be infilled before proceeding with any statistical analysis. This paper investigates the handling of missing values in demand data, and a new approach is developed for improving the performance of demand analytics, such as energy forecasting. The proposed model uses a transformer neural network to impute the missing values at various rates in the demand profile. Our model uses a k-means algorithm to fill in the missing values with proxy values in the dataset. The model is applied to two case-study residential house located in Cornwall and Fintry, United Kingdom. The developed algorithm is assessed for it potential for infilling missing values for three widely understood missing value scenarios: missing completely at random (MCAR), missing at random (MAR), and missing not at random (MNAR). The proposed model's imputed outputs are compared to the original dataset to assess model performance. The performance of the framework is compared with a selection of widely used statistical and machine learning models. The proposed transformer model shows significant improvements over the common linear method in all three scenarios (with 30% missing values), with percentage improvements ranging from approximately 49.71% to 57.52% for Cornwall dataset.","2023-12-01","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","300","","","","","","","","","","English","","","","WOS:001102575800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Clustering; Deep learning; Energy consumption data; Missing value imputation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TCMWLDGI","journalArticle","2024","Varshney, D; Singh, A; Ekbal, A","Aspect-level sentiment-controlled knowledge grounded multimodal dialog generation using generative models for reviews","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-023-16720-z","","During a conversation, it is critical for participants to establish what they both agree on, also known as the common ground. Grounding implies recognizing that the listener has understood what the speaker has said, considering several factors. This can be accomplished by basing dialog models on various features like aspects, sentiments, images, and unstructured knowledge documents. The key innovation lies in our novel multi-modal knowledge-grounded context-aware transformer model, which enables a seamless fusion of textual and visual information. We introduce an effective technique for generating reviews based on the user's aspect and sentiment (i.e., aspect-level sentiment-controllable reviews), which serves as the relevant external knowledge for the dialog systems. Our work highlights the importance of incorporating review expertise in knowledge-based multi-modal dialog generation. We utilize the Knowledge Grounded Multi-Modal Dialog (KGMMD) dataset, which includes dial og utterances accompanied by images, aspects, sentiment, and unstructured knowledge in the form of several long hotel reviews for different hotels mentioned in the dataset. The overall framework consists of a dialog encoder, a review generator, and a response decoder, all of which complement one another by generating appropriate reviews, which eventually assist in generating an adequate response. The proposed model outperforms the baseline models for aspect-level sentiment-controlled knowledge-based multimodal response generation with a significant increase in F1-score (13.3%) and BLEU-4 (5.3%) on the KGMMD dataset.","2024-03","2025-02-26 20:41:55","2025-02-26 20:41:55","","29197-29219","","10","83","","","","","","","","","","English","","","","WOS:001063370800004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","Aspect; Dialog generation; Knowledge-grounded; Multimodal; Sentiment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CKG3C65H","journalArticle","2023","Fu, RL; Wang, H; Zhang, XJ; Zhou, J; Yan, YH","SYNED: A SYNTAX-BASED LOW-RESOURCE EVENT DETECTION METHOD FOR NEW EVENT TYPES","INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL","","1349-4198","10.24507/ijicic.19.01.47","","Event detection (ED) is an important and challenging information extrac-tion task, which aims to identify triggers from unstructured text and classify them into an event type. Most of the current supervised ED methods rely heavily on high-quality annotation data and are difficult to use with new types. In order to solve the event detec-tion task of new types in low-resource scenarios, we proposed SynED, a low-resource ED system based on syntactic embedding. We first obtain syntactic information through nat-ural language processing (NLP) tools and combine them into syntactic embeddings which are then sent to a syntactic-gated Transformer model to extract event triggers. To create the appropriate event type ontology, we combine the syntactic and textual embeddings of event triggers. Through the correlation of event types, we realize the knowledge transfer from the seen event type ontology to the new event type ontology. Experimental results on the ACE 2005 and MAVEN datasets show that the SynED model based on syntactic embedding achieves state-of-the-art performance for new event types without annotation. Compared with the previous low-resource ED methods, our proposed SynED model has more overt benefits in the case of fewer training data and has a greater capacity for application expansion. We also explored the role of syntactic and textual embeddings in low-resource ED, demonstrating the significance of introducing syntactic information.","2023-02","2025-02-26 20:41:55","2025-02-26 20:41:55","","47-60","","1","19","","","","","","","","","","English","","","","WOS:000960548700004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Event detection; Knowledge transfer; Low-resource; Natural language processing; ONTOILPER; Syntactics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BCAFCR22","journalArticle","2022","Guo, JY; Cai, Q; An, JP; Chen, PY; Ma, C; Wan, JH; Gao, ZK","A Transformer based neural network for emotion recognition and visualizations of crucial EEG channels","PHYSICA A-STATISTICAL MECHANICS AND ITS APPLICATIONS","","0378-4371","10.1016/j.physa.2022.127700","","With the rapid development of artificial intelligence and sensor technology, electroencephalogram-based (EEG) emotion recognition has attracted extensive atten-tion. Various deep neural networks have been applied to it and achieved excellent results in classification accuracy. Except for classification accuracy, the interpretability of the feature extraction process is also considerable for model design for emotion recognition. In this study, we propose a novel neural network model (DCoT) with depthwise convolution and Transformer encoders for EEG-based emotion recognition by exploring the dependence of emotion recognition on each EEG channel and visualizing the captured features. Then we conduct subject-dependent and subject-independent experiments on a benchmark dataset, SEED, which contains EEG data of positive, neutral, and negative emotions. For subject-dependent experiments, the average accuracy of three classification tasks is 93.83%. For subject-independent experiments, the average accuracy of three classification tasks is 83.03%. Additionally, we assess the importance of each EEG channel in emotional activities by the DCoT model and visualize it as brain maps. Furthermore, satisfactory results are obtained by utilizing eight selected crucial EEG channels: FT7, T7, TP7, P3, FC6, FT8, T8, and F8, both in two classification tasks and three classification tasks. Using a small number of EEG channels for emotion recognition can reduce equipment costs and computing costs, which is suitable for practical applications. (C) 2022 Elsevier B.V. All rights reserved.","2022-10-01","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","603","","","","","","","","","","English","","","","WOS:000864174500003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;30<br/>Total Times Cited:&nbsp;&nbsp;31<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","Deep learning; EEG; Emotion recognition; SIGNALS; Time series analysis; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X5IZVWX8","journalArticle","2024","Huang, L; Yan, JT; Chen, SHK","Combining low-technology augmentative and alternative communication with regular aphasia treatment: interim findings of a hospital-based RCT in post-stroke patients","APHASIOLOGY","","0268-7038","10.1080/02687038.2024.2406592","","BackgroundPrevious research indicates that low-technology (low-tech) augmentative and alternative communication interventions (AACT) can enhance communication skills in individuals with post-stroke aphasia in China. However, there is limited evidence for low-tech AACT in inpatient settings.AimThis study aims to evaluate the impact of low-tech AACT combined with speech-language therapy (SLT) on communication skills related to basic needs, quality of life, and spoken language function among individuals with post-stroke aphasia in an inpatient setting.Methods & ProceduresTwelve participants with aphasia having difficulty in daily communication were randomly assigned to an experimental group, receiving 30 minutes of SLT and 30 minutes of low-tech AACT per session (AACT + SLT), or a control group, receiving 60 minutes of SLT per session (SLT), over ten sessions in two weeks. Primary outcomes were measured using the basic needs (CBN) domain of the functional assessment of communication skills for adults (FACS). Secondary outcomes included scores from the Chinese version of the stroke-specific quality of life scale (SS-QOL) and subtests of spoken language production and comprehension from the aphasia battery of Chinese (ABC). The study was registered in the Chinese clinical trial registry (ChiCTR2000028870).ResultsThe results indicated a significant improvement in the CBN domain of FACS in the AACT + SLT group, with larger clinically significant changes compared to the SLT group. The AACT+ SLT group also showed significantly higher overall scores on the SS-QOL and more significant improvements in the content of spontaneous speech than the SLT group after intervention. Comparable improvements were observed in other subtests of the ABC between the two groups.ConclusionsIncorporating low-tech AACT into regular SLT in inpatient settings can improve communication for basic needs in an in-patient setting, facilitate language recovery, and potentially support the overall quality of life, compared to SLT alone, for people with post-stroke aphasia. This combined approach demonstrates preliminary feasibility in hospital settings, suggesting the value of low-tech AACT in aphasia rehabilitation.","2024-09-29","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","","","","","","","","","","","English","","","","WOS:001322325400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","AAC RESEARCH; ADULTS; aphasia; Augmentative communication; CARE; hospitalization; LANGUAGE; PEOPLE; post-stroke; QUALITY-OF-LIFE; REHABILITATION; speech-language pathology; VISUAL SCENE DISPLAYS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"869HG6YV","journalArticle","2025","Rehman, MZU; Islam, SMS; Ul-Haq, A; Blake, D; Janjua, N","Effective Land Use Classification Through Hybrid Transformer Using Remote Sensing Imagery","IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING","","1939-1404","10.1109/JSTARS.2024.3494258","","Recent advances in deep learning for hyperspectral image classification have shown exceptional performance in resource management and environmental planning through land use classification. Despite these successes, challenges continue to persist in land use classification due to the complex topology of natural and man-made structures. The uneven distribution of land cover introduces spectral-spatial variability, causing inter- and intra-class similarity. To address this issue, this study adopts a hybrid approach that combines convolutional neural networks and a transformer model. The technique comprises three key components: a spectral-spatial convolutional module (SSCM), a spatial attention module (SAM), and a transformer module (TM). Each component facilitates the others in the process of classification. SSCM is used to extract shallow features with the help of dilated convolutional layers, while the SAM enhances spatial features for further processing. In addition, a TM with a local neighborhood attention mechanism is employed to extract local semantic information. Several experiments conducted on the Indian Pines and Pavia University hyperspectral datasets validate the performance of the proposed technique, demonstrating higher classification accuracy compared to recent methods in the literature. The technique achieves average accuracies of 97.24% and 99.33% on the Indian Pines and Pavia University datasets, respectively, thus demonstrating its effectiveness for land resource management and environmental planning.","2025","2025-02-26 20:41:55","2025-02-26 20:41:55","","2252-2268","","","18","","","","","","","","","","English","","","","WOS:001385590900007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","ATTENTION; Australia; classification hyperspectral imaging; Convolutional neural networks; Correlation; Data mining; deep learning; Deep learning; Feature extraction; HYPERSPECTRAL DATA; Hyperspectral imaging; NETWORK; Remote sensing; Semantics; spatial attention; Three-dimensional displays; transformers; Transformers; TRENDS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P7GMUWCH","journalArticle","2024","Liang, YC; Wang, YQ; Gu, CY; Tang, J; Pang, XJ","Fog computing-enabled adaptive prognosis of cutting tool remaining life through multi-source data","JOURNAL OF COMPUTATIONAL DESIGN AND ENGINEERING","","2288-5048","10.1093/jcde/qwae098","","Predicting cutting tool remaining life is important to sustainable machining. Accurate wear assessment improves efficiency, reduces waste , and lowers costs by minimizing tool failure . Traditional prognosis methods are often crippled by the inability to adapt to diverse working conditions across the machining process lifecycle. This paper introduces a fog computing-enabled adaptive prognosis framework utilizing multi-source data to address these challenges effectively. The key innovations include the following: (1) the proposed system integrates power and vibration data collected from LGMazak VTC-16A and IRON MAN QM200 machines. A standardized data fusion method combines multi-source data to enhance robustness and accuracy. (2) The transformer model is employed to improve prognosis accuracy of cutting tool remaining life; best accuracy of 98.24% and an average accuracy of 97.63% are achieved. (3) Finite element analysis is incorporated to validate the model's predictions to validate reliability of deep learning model. (4) The fog computing optimization mechanism based on the bees algorithm, which shows fitness value of 0.92 and convergence within 15 iterations. The proposed method reduces total data volume in cloud by 54.12%, prediction time by 33.64%, and time complexity in the cloud layer by 4.62%. The effectiveness of fog computing in improving the operational efficiency and reliability of manufacturing systems is validated through the integration of advanced data analytics and deep learning techniques.","2024-11-20","2025-02-26 20:41:55","2025-02-26 20:41:55","","180-192","","6","11","","","","","","","","","","English","","","","WOS:001360368600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","adaptive prognosis; bees algorithm; cutting tool life prediction; FAULT-DIAGNOSIS; fog computing; MACHINE; multi-source data fusion; SYSTEMS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VJVGPM7L","journalArticle","2024","Cai, YT; Lv, J; Li, R; Huang, XW; Wang, S; Bao, ZM; Zeng, QF","Deqformer: high-definition and scalable deep learning probe design method","BRIEFINGS IN BIOINFORMATICS","","1467-5463","10.1093/bib/bbae007","","Target enrichment sequencing techniques are gaining widespread use in the field of genomics, prized for their economic efficiency and swift processing times. However, their success depends on the performance of probes and the evenness of sequencing depth among each probe. To accurately predict probe coverage depth, a model called Deqformer is proposed in this study. Deqformer utilizes the oligonucleotides sequence of each probe, drawing inspiration from Watson-Crick base pairing and incorporating two BERT encoders to capture the underlying information from the forward and reverse probe strands, respectively. The encoded data are combined with a feed-forward network to make precise predictions of sequencing depth. The performance of Deqformer is evaluated on four different datasets: SNP panel with 38 200 probes, lncRNA panel with 2000 probes, synthetic panel with 5899 probes and HD-Marker panel for Yesso scallop with 11 000 probes. The SNP and synthetic panels achieve impressive factor 3 of accuracy (F3acc) of 96.24% and 99.66% in 5-fold cross-validation. F3acc rates of over 87.33% and 72.56% are obtained when training on the SNP panel and evaluating performance on the lncRNA and HD-Marker datasets, respectively. Our analysis reveals that Deqformer effectively captures hybridization patterns, making it robust for accurate predictions in various scenarios. Deqformer leads to a novel perspective for probe design pipeline, aiming to enhance efficiency and effectiveness in probe design tasks.","2024-01-22","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","2","25","","","","","","","","","","English","","","","WOS:001177227400005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","DNA; DNA sequence; ENRICHMENT; probe design; REGIONS; TARGET; target enrichment genotyping; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QMHDNJQW","journalArticle","2024","Qin, HF; Xiong, ZP; Li, YT; El-Yacoubi, MA; Wang, J","Attention BLSTM-Based Temporal-Spatial Vein Transformer for Multi-View Finger-Vein Recognition","IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY","","1556-6013","10.1109/TIFS.2024.3468898","","Finger-vein biometrics has recently gained significant attention due to its robust privacy and high security features. Despite notable advancements, most existing methods focus on extracting features from a 2-dimensional (2D) image projected from 3D vein vessels with a single view. However, recognition based on a single view is prone to errors due to variations in finger positioning, especially those caused by finger roll movements, which can degrade recognition performance. To address this challenge, we propose ABLSTM-TSVT, an Attention Bidirectional LSTM-based Temporal-Spatial Vein Transformer for multi-view finger-vein recognition. First, we enhance LSTM with an attention mechanism to create an attention LSTM for extracting temporal features. We further improve this by introducing a local attention module, which learns temporal dependencies between a patch (token) and its adjacent patches across multiple views, integrating it with the attention LSTM to form a temporal attention module. Second, we develop a spatial attention module that captures the spatial dependencies of patches within an image. Finally, merging the temporal and the spatial attention modules, we create our temporal-spatial transformer model, which effectively represents features from multi-view images. Experimental results on two multi-view datasets demonstrate that our approach outperforms state-of-the-art approaches in enhancing identification accuracy and reducing verification errors in vein classifiers.","2024","2025-02-26 20:41:55","2025-02-26 20:41:55","","9330-9343","","","19","","","","","","","","","","English","","","","WOS:001336007900008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;78</p>","","","attention BLSTM; AUTHENTICATION; deep learning; Feature extraction; Finger-vein recognition; Fingers; FUSION; Image recognition; IMAGE-RESTORATION; Long short term memory; multiple views; ROI LOCALIZATION; temporal-spatial transformer; Three-dimensional displays; Transformers; Veins; VERIFICATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RR8YVAF2","journalArticle","2023","Graham, MS; Tudosiu, PD; Wright, P; Pinaya, WHL; Teikari, P; Patel, A; U-King-Im, JM; Mah, YH; Teo, JT; Jäger, HR; Werring, D; Rees, G; Nachev, P; Ourselin, S; Cardoso, MJ","Latent Transformer Models for out-of-distribution detection","MEDICAL IMAGE ANALYSIS","","1361-8415","10.1016/j.media.2023.102967","","Any clinically-deployed image-processing pipeline must be robust to the full range of inputs it may be presented with. One popular approach to this challenge is to develop predictive models that can provide a measure of their uncertainty. Another approach is to use generative modelling to quantify the likelihood of inputs. Inputs with a low enough likelihood are deemed to be out-of-distribution and are not presented to the downstream predictive model. In this work, we evaluate several approaches to segmentation with uncertainty for the task of segmenting bleeds in 3D CT of the head. We show that these models can fail catastrophically when operating in the far out-of-distribution domain, often providing predictions that are both highly confident and wrong. We propose to instead perform out-of-distribution detection using the Latent Transformer Model: a VQ-GAN is used to provide a highly compressed latent representation of the input volume, and a transformer is then used to estimate the likelihood of this compressed representation of the input. We demonstrate this approach can identify images that are both far-and near-out-of-distribution, as well as provide spatial maps that highlight the regions considered to be out-of-distribution. Furthermore, we find a strong relationship between an image's likelihood and the quality of a model's segmentation on it, demonstrating that this approach is viable for filtering out unsuitable images.","2023-12","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","90","","","","","","","","","","English","","","","WOS:001086674900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Out-of-distribution detection; Segmentation; Transformers; Uncertainty","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V5QTVRTQ","journalArticle","2023","Liu, H; Ge, Y","Job and Employee Embeddings: A Joint Deep Learning Approach","IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING","","1041-4347","10.1109/TKDE.2022.3180593","","The accumulated massive job and employee data at various platforms such as LinkedIn and Glassdoor are very valuable for many online applications such as job/employee search and recommendations. In order to exploit these data, an interesting and practical problem is how to learn effective job and employee representations, which could be further utilized for many computing tasks such as searching for similar jobs and employees. Yet this problem is very challenging because these user-generated job and employee data are semi-structured and created without standards, which makes them very messy, sparse, and difficult to model. Developing novel and advanced methods to learn job and employee representations has become an urgent need. To this end, in this paper, we develop a novel neural network model for job and employee embeddings. Our proposed approach consists of three components to model career data from three levels of granularity: job content, job context, and job sequence. We fine-tune a transformer model to learn the semantics of massive text in job content, build a shallow neural network to accumulate contextual information in job sequences, and develop an RNN encoder-decoder model to learn representations of employees' career paths. To evaluate the proposed method, we conduct two experimental tasks: job similarity and employee similarity searches. The experimental results with a real-world dataset demonstrate the superiority of the developed approach.","2023-07-01","2025-02-26 20:41:55","2025-02-26 20:41:55","","7056-7067","","7","35","","","","","","","","","","English","","","","WOS:001004293600038","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Career path; Companies; Context modeling; Data models; employee embedding; employee similarity search; Engineering profession; job embedding; job similarity search; Software; Task analysis; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S9XFJB7J","journalArticle","2023","He, SM; Yang, HQ; Zhang, XY; Li, XY","MFTransNet: A Multi-Modal Fusion with CNN-Transformer Network for Semantic Segmentation of HSR Remote Sensing Images","MATHEMATICS","","2227-7390","10.3390/math11030722","","Due to the inherent inter-class similarity and class imbalance of remote sensing images, it is difficult to obtain effective results in single-source semantic segmentation. We consider applying multi-modal data to the task of the semantic segmentation of HSR (high spatial resolution) remote sensing images, and obtain richer semantic information by data fusion to improve the accuracy and efficiency of segmentation. However, it is still a great challenge to discover how to achieve efficient and useful information complementarity based on multi-modal remote sensing image semantic segmentation, so we have to seriously examine the numerous models. Transformer has made remarkable progress in decreasing model complexity and improving scalability and training efficiency in computer vision tasks. Therefore, we introduce Transformer into multi-modal semantic segmentation. In order to cope with the issue that the Transformer model requires a large amount of computing resources, we propose a model, MFTransNet, which combines a CNN (convolutional neural network) and Transformer to realize a lightweight multi-modal semantic segmentation structure. To do this, a small convolutional network is first used for performing preliminary feature extraction. Subsequently, these features are sent to the multi-head feature fusion module to achieve adaptive feature fusion. Finally, the features of different scales are integrated together through a multi-scale decoder. The experimental results demonstrate that MFTransNet achieves the best balance among segmentation accuracy, memory-usage efficiency and inference speed.","2023-02","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","3","11","","","","","","","","","","English","","","","WOS:000930336900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","high spatial resolution remote sensing images; multi-modal; semantic segmentation; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CSGMKR78","journalArticle","2022","Kim, SJ; Chung, YJ","Multi-Scale Features for Transformer Model to Improve the Performance of Sound Event Detection","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app12052626","","To alleviate the problem of performance degradation due to the varied sound durations of competing classes in sound event detection, we propose a method that utilizes multi-scale features for sound event detection. We employed a feature-pyramid component in a deep neural network architecture based on the Transformer encoder that is used to efficiently model the time correlation of sound signals because of its superiority over conventional recurrent neural networks, as demonstrated in recent studies. We used layers of convolutional neural networks to produce two-dimensional acoustic features that are input into the Transformer encoders. The outputs of the Transformer encoders at different levels of the network are combined to obtain the multi-scale features to feed the fully connected feed-forward neural network, which acts as the final classification layer. The proposed method is motivated by the idea that multi-scale features make the network more robust against the dynamic duration of the sound signals depending on their classes. We also applied the proposed method to a mean-teacher model, based on the Transformer encoder, to demonstrate its effectiveness on a large set of unlabeled data. We conducted experiments using the DCASE 2019 Task 4 dataset to evaluate the performance of the proposed method. The experimental results show that the proposed architecture outperforms the baseline network without multi-scale features.","2022-03","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","5","12","","","","","","","","","","English","","","","WOS:000771525300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","attention model; convolutional neural network; feature-pyramid; mean-teacher model; NEURAL-NETWORKS; sound event detection; transformer encoder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N5EMHYB7","journalArticle","2024","Liu, H; Chen, GG; Liu, M; Nie, LQ","Pre-Trained Transformer-Based Parallel Multi-Channel Adaptive Image Sequence Interpolation Network","IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY","","1051-8215","10.1109/TCSVT.2024.3409395","","Image sequence interpolation is a critical research area in computer vision with broad applications in video frame interpolation and medical image interlayer interpolation. Traditional deep learning-based methods in this domain predominantly rely on deep convolutional neural networks (CNNs), which, despite their effectiveness, are limited by the inherent constraints of CNN architecture, impacting their interpolation accuracy. To address these limitations, we introduce the Pre-ISIformer, a parallel multi-channel adaptive image sequence interpolation network founded on pre-trained transformers. This innovative network is composed of three integral modules: 1) Global feature extraction module is designed to extract primary features from the input images using a pre-trained Swin-transformer model, ensuring comprehensive global feature coverage. 2) Feature sequence construction module adaptively decomposes the object's motion path across different frames, facilitating a detailed analysis of motion dynamics. And 3) Intermediate image reconstruction module is responsible for accurately capturing target displacements. Furthermore, we incorporate distinct metrics for pixel loss and gradient loss to meticulously reconstruct the texture and contours of the intermediate images. Our network has been rigorously tested on various datasets for two primary applications: video frame interpolation and interlayer interpolation in medical imaging. The results from these experiments showcase the superior performance and effectiveness of the Pre-ISIformer, establishing it as a significant advancement in the field of image sequence interpolation.","2024-10","2025-02-26 20:41:55","2025-02-26 20:41:55","","10464-10478","","10","34","","","","","","","","","","English","","","","WOS:001346503100016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Computational modeling; Computer vision; Feature extraction; Image sequence interpolation; Image sequences; interlayer interpolation; Interpolation; parallel convolutional blocks; pretrained transformers; Task analysis; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"562RK9NR","journalArticle","2024","Honarjoo, A; Darvishan, E; Rezazadeh, H; Kosarieh, AH","SigBERT: vibration-based steel frame structural damage detection through fine-tuning BERT","INTERNATIONAL JOURNAL OF STRUCTURAL INTEGRITY","","1757-9864","10.1108/IJSI-04-2024-0065","","Purpose - This article introduces SigBERT, a novel approach that fine-tunes bidirectional encoder representations from transformers (BERT) for the purpose of distinguishing between intact and impaired structures by analyzing vibration signals. Structural health monitoring (SHM) systems are crucial for identifying and locating damage in civil engineering structures. The proposed method aims to improve upon existing methods in terms of cost-effectiveness, accuracy and operational reliability. Design/methodology/approach - SigBERT employs a fine-tuning process on the BERT model, leveraging its capabilities to effectively analyze time-series data from vibration signals to detect structural damage. This study compares SigBERT's performance with baseline models to demonstrate its superior accuracy and efficiency. Findings - The experimental results, obtained through the Qatar University grandstand simulator, show that SigBERT outperforms existing models in terms of damage detection accuracy. The method is capable of handling environmental fluctuations and offers high reliability for non-destructive monitoring of structural health. The study mentions the quantifiable results of the study, such as achieving a 99% accuracy rate and an F-1 score of 0.99, to underline the effectiveness of the proposed model. Originality/value - SigBERT presents a significant advancement in SHM by integrating deep learning with a robust transformer model. The method offers improved performance in both computational efficiency and diagnostic accuracy, making it suitable for real-world operational environments.","2024-09-30","2025-02-26 20:41:55","2025-02-26 20:41:55","","851-872","","5","15","","","","","","","","","","English","","","","WOS:001310394300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Damage detection; Deep learning; Fine-tuning BERT; Non-destructive monitoring; Signal analysis; Structural health monitoring","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"54JITAIK","journalArticle","2024","Xiao, HG; Li, L; Liu, QY; Zhang, QH; Liu, JQ; Liu, Z","Context-aware and local-aware fusion with transformer for medical image segmentation","PHYSICS IN MEDICINE AND BIOLOGY","","0031-9155","10.1088/1361-6560/ad14c6","","Objective. Convolutional neural networks (CNNs) have made significant progress in medical image segmentation tasks. However, for complex segmentation tasks, CNNs lack the ability to establish long-distance relationships, resulting in poor segmentation performance. The characteristics of intra-class diversity and inter-class similarity in images increase the difficulty of segmentation. Additionally, some focus areas exhibit a scattered distribution, making segmentation even more challenging. Approach. Therefore, this work proposed a new Transformer model, FTransConv, to address the issues of inter-class similarity, intra-class diversity, and scattered distribution in medical image segmentation tasks. To achieve this, three Transformer-CNN modules were designed to extract global and local information, and a full-scale squeeze-excitation module was proposed in the decoder using the idea of full-scale connections. Main results. Without any pre-training, this work verified the effectiveness of FTransConv on three public COVID-19 CT datasets and MoNuSeg. Experiments have shown that FTransConv, which has only 26.98M parameters, outperformed other state-of-the-art models, such as Swin-Unet, TransAttUnet, UCTransNet, LeViT-UNet, TransUNet, UTNet, and SAUNet++. This model achieved the best segmentation performance with a DSC of 83.22% in COVID-19 datasets and 79.47% in MoNuSeg. Significance. This work demonstrated that our method provides a promising solution for regions with high inter-class similarity, intra-class diversity and scatter distribution in image segmentation.","2024-01-21","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","2","69","","","","","","","","","","English","","","","WOS:001139760600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","context-aware information; local-aware information; medical image segmentation; NET; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TY7ZQZ64","journalArticle","2024","Zheng, K; Tian, L; Li, ZC; Li, H; Zhang, JJ","Incorporating eyebrow and eye state information for facial expression recognition in mask-obscured scenes","ELECTRONIC RESEARCH ARCHIVE","","2688-1594","10.3934/era.2024124","","Facial expression recognition plays a crucial role in human -computer intelligent interaction. Due to the problem of missing facial information caused by face masks, the average accuracy of facial expression recognition algorithms in mask -obscured scenes is relatively low. At present, most deep learning -based facial expression recognition methods primarily focus on global facial features, thus they are less suitable for scenarios where facial expressions are obscured by masks. Therefore, this paper proposes a facial expression recognition method, TransformerKNN (TKNN), which integrates eyebrow and eye state information in mask -obscured scenes. The proposed method utilizes facial feature points in the eyebrow and eye regions to calculate various relative distances and angles, capturing the state information of eyebrows and eyes. Subsequently, the original face images with masks are used to train a Swin-transformer model, and the eyebrow and eye state information is used to train a k -Nearest Neighbor (KNN) model. These models are then fused at the decision layer to achieve automated emotion computation in situations when facial expressions are obscured by masks. The TKNN method offers a novel approach by leveraging both local and global facial features, thereby enhancing the performance of facial expression recognition in mask -obscured scenes. Experimental results demonstrate that the average accuracy of the TKNN method is 85.8% and 70.3%, respectively. This provides better support for facial expression recognition in scenarios when facial information is partially obscured.","2024","2025-02-26 20:41:55","2025-02-26 20:41:55","","2745-2771","","4","32","","","","","","","","","","English","","","","WOS:001198156900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","eyebrow and eye state; facial expression recognition; local and global facial features; mask-obscured","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MZJ844VA","journalArticle","2024","Ekanayake, M; Pawar, K; Harandi, M; Egan, G; Chen, ZL","McSTRA: A multi-branch cascaded swin transformer for point spread function-guided robust MRI reconstruction","COMPUTERS IN BIOLOGY AND MEDICINE","","0010-4825","10.1016/j.compbiomed.2023.107775","","Deep learning MRI reconstruction methods are often based on Convolutional neural network (CNN) models; however, they are limited in capturing global correlations among image features due to the intrinsic locality of the convolution operation. Conversely, the recent vision transformer models (ViT) are capable of capturing global correlations by applying self-attention operations on image patches. Nevertheless, the existing transformer models for MRI reconstruction rarely leverage the physics of MRI. In this paper, we propose a novel physicsbased transformer model titled, the Multi-branch Cascaded Swin Transformers (McSTRA) for robust MRI reconstruction. McSTRA combines several interconnected MRI physics-related concepts with the Swin transformers: it exploits global MRI features via the shifted window self-attention mechanism; it extracts MRI features belonging to different spectral components via a multi-branch setup; it iterates between intermediate de-aliasing and data consistency via a cascaded network with intermediate loss computations; furthermore, we propose a point spread function-guided positional embedding generation mechanism for the Swin transformers which exploit the spread of the aliasing artifacts for effective reconstruction. With the combination of all these components, McSTRA outperforms the state-of-the-art methods while demonstrating robustness in adversarial conditions such as higher accelerations, noisy data, different undersampling protocols, out-of-distribution data, and abnormalities in anatomy.","2024-01","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","168","","","","","","","","","","English","","","","WOS:001159701600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Accelerated MRI; COMPRESSED SENSING MRI; Deep learning; Image reconstruction; IMAGE-RECONSTRUCTION; k-space; NETWORK; Physics-based; Point spread function; Swin transformer; Undersampled","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"84VVVBTG","journalArticle","2023","Wang, FL; Ji, J; Wang, Y","DSViT: Dynamically Scalable Vision Transformer for Remote Sensing Image Segmentation and Classification","IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING","","1939-1404","10.1109/JSTARS.2023.3285259","","The relationship between the foreground target and the background of remote sensing image is very complex. The vision task of remote sensing image faces the problems of complex targets and unbalanced categories. These problems make the modeling method have further improvement space. Therefore, this article proposes a dynamically scalable attention model that combines convolutional features and Transformer features. It can dynamically select the model depth according to the size of the input image, which alleviates the problem of insufficient global information extraction of the single convolution model and the computational overhead limitation of the pure Transformer model. We validated the model on two public remote sensing image classifications and two remote sensing image segmentation datasets. The accuracy and mean pixel accuracy (mPA) of the method in this article reached 96.16% and 93.44%, respectively, on the university of california (UC) Merced classification dataset. Compared with some recent work, the method has a net improvement of 5.0% and 4.82% over the pyramid vision transformer (PVT) model. On the Potsdam segmentation dataset, the accuracy and F1 of the transformer and CNN hybrid neural network (TCHNN) model are 91.5% and 92.86%, respectively. The performance of the method has improved 0.64% and 1.0%, and the other two datasets have also achieved the best results.","2023","2025-02-26 20:41:55","2025-02-26 20:41:55","","5441-5452","","","16","","","","","","","","","","English","","","","WOS:001021365700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","classification; CNN; Computational modeling; Convolution; Convolutional neural networks; Feature extraction; Remote sensing; remote sensing image; semantic segmentation; Task analysis; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QLK2VPP2","journalArticle","2023","Zhao, HS; Wu, YC; Ma, LB; Pan, SC","Spatial and Temporal Attention-Enabled Transformer Network for Multivariate Short-Term Residential Load Forecasting","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2023.3305655","","Short-term residential load forecasting (STRLF) is critical for the safe and stable operation of the microgrid system. Due to shred conditions such as temperature and holiday impacts, households in the same region may exhibit similar consumption patterns. However, existing STRLF methods focus mainly on exploring the temporal patterns of a single household; the spatial correlations between multiple households are generally ignored. To address this challenge, a spatial and temporal attention-enabled transformer model, STformer, is proposed to extract the dynamic spatial and nonlinear temporal correlations between residential units and perform joint predictions of multivariate residential loads. The combination of improved temporal attention and spatial attention mechanisms allows the proposed method to capture complex spatial and temporal factors without prior geographical information. The Monte Carlo (MC) dropout method is utilized to further extend the proposed model to multitask residential probabilistic load forecasting. Compared to Transformer, the proposed model improves the point forecast accuracy of individual New York (NY), USA, and Los Angeles (LA), USA, by 16.54% and 6.95%, and the combined point forecast accuracy by 22.46% and 11.86%, respectively. In addition, the proposed model improved the residential probabilistic load prediction accuracy by 10.21% and 11.07% in NY and LA, respectively, compared to SGPR.","2023","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","72","","","","","","","","","","English","","","","WOS:001063248800008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Autocorrelation; Load forecasting; Load modeling; Market research; Monte Carlo (MC) dropout; NEURAL-NETWORK; PREDICTION; Predictive models; probabilistic forecasting; Probabilistic logic; residential load forecasting; spatial-temporal correlation; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4GQ7YMCA","journalArticle","2021","Ivanova, MV; Zhong, A; Turken, A; Baldo, JV; Dronkers, NF","Functional Contributions of the Arcuate Fasciculus to Language Processing","FRONTIERS IN HUMAN NEUROSCIENCE","","1662-5161","10.3389/fnhum.2021.672665","","Current evidence strongly suggests that the arcuate fasciculus (AF) is critical for language, from spontaneous speech and word retrieval to repetition and comprehension abilities. However, to further pinpoint its unique and differential role in language, its anatomy needs to be explored in greater detail and its contribution to language processing beyond that of known cortical language areas must be established. We address this in a comprehensive evaluation of the specific functional role of the AF in a well-characterized cohort of individuals with chronic aphasia (n = 33) following left hemisphere stroke. To evaluate macro- and microstructural integrity of the AF, tractography based on the constrained spherical deconvolution model was performed. The AF in the left and right hemispheres were then manually reconstructed using a modified 3-segment model (Catani et al., 2005), and a modified 2-segment model (Glasser and Rilling, 2008). The normalized volume and a measure of microstructural integrity of the long and the posterior segments of the AF were significantly correlated with language indices while controlling for gender and lesion volume. Specific contributions of AF segments to language while accounting for the role of specific cortical language areas - inferior frontal, inferior parietal, and posterior temporal - were tested using multiple regression analyses. Involvement of the following tract segments in the left hemisphere in language processing beyond the contribution of cortical areas was demonstrated: the long segment of the AF contributed to naming abilities; anterior segment - to fluency and naming; the posterior segment - to comprehension. The results highlight the important contributions of the AF fiber pathways to language impairments beyond that of known cortical language areas. At the same time, no clear role of the right hemisphere AF tracts in language processing could be ascertained. In sum, our findings lend support to the broader role of the left AF in language processing, with particular emphasis on comprehension and naming, and point to the posterior segment of this tract as being most crucial for supporting residual language abilities.","2021-06-25","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","15","","","","","","","","","","English","","","","WOS:000671390800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;54<br/>Total Times Cited:&nbsp;&nbsp;61<br/>Cited Reference Count:&nbsp;&nbsp;80</p>","","","ANATOMY; aphasia; APHASIA; arcuate fasciculus; BRAINS; DAMAGE; diffusion MRI; DIFFUSION-TENSOR; language; LESION LOAD; PATHWAYS; SPEECH PRODUCTION; stroke; tractography; TRACTOGRAPHY; WHITE-MATTER TRACTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3G7C2P8F","journalArticle","2022","Koga, S; Murakami, A; Josephs, KA; Dickson, DW","Diffuse Lewy body disease presenting as Parkinson's disease with progressive aphasia","NEUROPATHOLOGY","","0919-6544","10.1111/neup.12780","","Primary progressive aphasia (PPA) is a progressive language disorder often due to an underlying neurodegenerative disease. The most common pathologies associated with PPA include frontotemporal lobar degeneration (FTLD)-tau, FTLD-associated with transactivation response DNA-binding protein of 43 kDa (TDP-43) (FTLD-TDP), and Alzheimer's disease (AD). Accumulating evidence has suggested that Lewy body disease (LBD) can also be associated with PPA. We herein report a 78-year-old Caucasian woman who initially presented with levodopa-responsive parkinsonism at age 67 and later developed cognitive impairment, visual hallucinations, rapid eye movement sleep behavior disorder, and progressive aphasia, characterized by reduced spontaneous speech, word-finding difficulty, and difficulties in writing and reading. (18)Fluorodeoxyglucoase (FDG)-positron emission tomography (PET) performed at the age of 73 years identified hypometabolism in the frontal (right > left), temporal (left > right), and parietal (left > right) lobes. Neuropathological assessment revealed diffuse LBD (DLBD), AD, and TDP-43 stage 6 with prehippocampal sclerosis. Senile plaques were numerous, but only a few neurofibrillary tangles were present in the neocortex. The Braak neurofibrillary tangle stage was IV, and the Thal amyloid phase was 3. Lewy-related pathology was severe in the neocortex, as well as limbic cortices, basal forebrain, amygdala, and brainstem. Compared to 166 DLBD cases with a clinical diagnosis of dementia with Lewy bodies (DLB), the Lewy body count of the patient in this report was highest in the inferior parietal cortex, followed by midfrontal and superior temporal cortices. The findings suggest that severe cortical LBD pathology has contributed to her progressive aphasia. Autopsy cases of LBD presenting as PPA have been reported, but patients with PD and autopsy-proven DLBD who later developed progressive aphasia have not been reported. Our findings indicate that PD can be associated with progressive aphasia later in the disease course. Although uncommon, LBD should be considered as a differential diagnosis of progressive aphasia.","2022-02","2025-02-26 20:41:55","2025-02-26 20:41:55","","82-89","","1","42","","","","","","","","","","English","","","","WOS:000742173400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Alzheimer's disease; BODIES; BRAIN; DEMENTIA; DIAGNOSIS; Lewy body disease; Parkinson's disease; PATHOLOGY; prehippocampal sclerosis; progressive aphasia; TDP-43","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H279RJML","journalArticle","2025","Wu, HZ; Cheng, C; Peng, T; Zhou, HZ; Chen, T","Combining transformer with a latent variable model for radio tomography based robust device-free localization","COMPUTER COMMUNICATIONS","","0140-3664","10.1016/j.comcom.2024.108022","","Radio tomographic imaging (RTI) is a promising device-free localization (DFL) method for reconstructing the signal attenuation caused by physical objects in wireless networks. In this paper, we use the received signal strength (RSS) difference between the current and baseline measurements captured by a wireless network to achieve the RTI based DFL in a predefined monitoring area. RTI is formulated as solving a badly conditioned problem under complex noise. And the end-to-end deep learning method based on Transformers and latent variable models (LVMs) is considered to address the RTI problem. The data grouping strategy is designed to divide the RSS data into multiple spatially-correlated groups, and a Transformer-based convolutional neural network (TCNN) model is firstly developed for RTI, in which the Transformer blocks are able to help the model learn the more expressive feature for the environmental image reconstruction task. The RTI system is influenced by both sensor noise and environmental noise simultaneously. In order to improve the performance of the RTI method, a Transformer-based latent variable model (TLVM) is proposed further, where the robustness to interference can be enhanced by controlling the capacity of the latent variables. The comparative numerical experiments are conducted for RTI based DFL, and the efficacy of the proposed TCNN and TLVM based RTI methods is verified by the experimental results.","2025-02-01","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","231","","","","","","","","","","English","","","","WOS:001385719700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Deep learning; Device-free localization (DFL); Latent variable model (LVM); Radio tomographic imaging (RTI); Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GZL8M26Y","journalArticle","2024","Yang, SS; Ding, LJ; Li, WT; Sun, W; Li, QY","Fishing risky behavior recognition based on adaptive transformer, reinforcement learning and stochastic configuration networks","INFORMATION SCIENCES","","0020-0255","10.1016/j.ins.2023.120074","","The fishing behavior in a high -voltage environment may lead to electric shock accidents. This paper proposes a fishing risky behavior recognition method based on adaptive Transformer, reinforcement learning and stochastic configuration networks (SCNs). Firstly, the fishing behavior image sample training set is evaluated using the actor network based on linear entropy in the reinforcement learning module to select suitable training samples that possess abundant straightline elements. Subsequently, the selected training samples are fed into a multi -scale spatial deep convolution to extract continuous spatial features of elongated objects. The deformable Transformer network, enhanced with adaptive encoding and decoding layers through SCNs, is used to obtain the position and detection results of the fishing rod. The trained Transformer model is evaluated by a defined credibility evaluation metric for acquiring rewards to update the training sample set iteratively. Then, an adaptive adjustment mechanism is constructed for the encoding and decoding layers of the adaptive Transformer network to establish a library of adaptive Transformer models with different encoding and decoding layer levels to accommodate the feature requirements of training samples in various scenarios. Finally, the blending learning method for combining the detection results from the model library is integrated with human body object detection and pose estimation methods, and a predefined expert system is utilized for logic reasoning on fishing risky behavior. Experimental results demonstrate the effectiveness of the proposed method in this paper.","2024-02","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","659","","","","","","","","","","English","","","","WOS:001152722200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Adaptive transformer; DEEP; Fishing behavior recognition; OBJECT DETECTION; Reinforcement learning; Stochastic configuration networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"36XGHIGA","journalArticle","2023","Wang, Z; Gao, YP; Xu, XM; Dong, W; Jiang, TQ","Risk Classification Assessment and Early Warning of Heavy Metal Contamination in Meat Products","SUSTAINABILITY","","2071-1050","10.3390/su152115558","","Risk classification assessment and early warning systems are indispensable tools and technologies in the realm of regulatory control. Evaluating and issuing early warnings regarding heavy metal contaminants in meat products play a pivotal role in ensuring public safety and maintaining societal stability. In this study, we focused on heavy metal pollutants such as lead, cadmium, chromium, and arsenic. We collected national inspection data for meat products from 20 provinces in 2020. Combining dietary structure data, toxicology information, and dietary exposure assessment methods, we constructed a risk assessment model for heavy metal contaminants in food. Furthermore, we employed an entropy weight-based analytic hierarchy process (AHP-EW) to classify the results of the risk assessment for heavy metal contaminants in food. This involved determining risk rating levels and thresholds. Finally, we constructed a multi-step food contaminant risk prediction model based on the Transformer framework. To validate the model's performance, comparative assessments were conducted across 20 datasets using various models. The results clearly indicate that the Transformer model outperformed the others in 14 datasets, excelling in its ability to provide advanced warnings for heavy metal risks in meat products. This empowers relevant authorities to strengthen their regulatory oversight of meat products based on the procedures and models proposed in this study, ultimately enhancing the efficiency of food safety risk management.","2023-11","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","21","15","","","","","","","","","","English","","","","WOS:001100376900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","ANALYTIC HIERARCHY PROCESS; CHINA; CHROMIUM; CONSUMPTION; FOOD; heavy metal; meat products; multi-step time series prediction; POLLUTION; risk assessment; SOILS; TRACE-ELEMENTS; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FPPVLVAC","journalArticle","2022","Yao, JY; Jin, SG","Multi-Category Segmentation of Sentinel-2 Images Based on the Swin UNet Method","REMOTE SENSING","","2072-4292","10.3390/rs14143382","","Medium-resolution remote sensing satellites have provided a large amount of long time series and full coverage data for Earth surface monitoring. However, the different objects may have similar spectral values and the same objects may have different spectral values, which makes it difficult to improve the classification accuracy. Semantic segmentation of remote sensing images is greatly facilitated via deep learning methods. For medium-resolution remote sensing images, the convolutional neural network-based model does not achieve good results due to its limited field of perception. The fast-emerging vision transformer method with self-attentively capturing global features well provides a new solution for medium-resolution remote sensing image segmentation. In this paper, a new multi-class segmentation method is proposed for medium-resolution remote sensing images based on the improved Swin UNet model as a pure transformer model and a new pre-processing, and the image enhancement method and spectral selection module are designed to achieve better accuracy. Finally, 10-categories segmentation is conducted with 10-m resolution Sentinel-2 MSI (Multi-Spectral Imager) images, which is compared with other traditional convolutional neural network-based models (DeepLabV3+ and U-Net with different backbone networks, including VGG, ResNet50, MobileNet, and Xception) with the same sample data, and results show higher Mean Intersection Over Union (MIOU) (72.06%) and better accuracy (89.77%) performance. The vision transformer method has great potential for medium-resolution remote sensing image segmentation tasks.","2022-07","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","14","14","","","","","","","","","","English","","","","WOS:000832139000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","remote sensing; semantic segmentation; Sentinel-2; Swin Transformer; Swin UNet; WATER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QFNKPFYA","journalArticle","2021","Kokkinos, V; Selviaridis, P; Seimenis, I","Feasibility, Contrast Sensitivity and Network Specificity of Language fMRI in Presurgical Evaluation for Epilepsy and Brain Tumor Surgery","BRAIN TOPOGRAPHY","","0896-0267","10.1007/s10548-021-00839-z","","Language fMRI has become an integral part of the planning process in brain surgery. However, fMRI may suffer from confounding factors both on the patient side, as well as on the provider side. In this study, we investigate how patient-related confounds affect the ability of the patient to perform language fMRI tasks (feasibility), the task sensitivity from an image contrast point of view, and the anatomical specificity of expressive and receptive language fMRI protocols. 104 patients were referred for language fMRI in the context of presurgical procedures for epilepsy and brain tumor surgery. Four tasks were used: (1) a verbal fluency (VF) task to map vocabulary use, (2) a semantic description (SD) task to map sentence formation/semantic integration skills, (3) a reading comprehension (RC) task and (4) a listening comprehension (LC) task. Feasibility was excellent in the LC task (100%), but in the acceptable to mediocre range for the rest of the tasks (SD: 87.50%, RC: 85.57%, VF: 67.30%). Feasibility was significantly confounded by age (p = 0.020) and education level (p = 0.003) in VF, by education level (p = 0.004) and lesion laterality (p = 0.019) in SD and by age (p = 0.001), lesion laterality (p = 0.007) and lesion severity (p = 0.048) in RC. All tasks were comparable regarding sensitivity in generating statistically significant image contrast (VF: 90.00%, SD: 92.30%, RC: 93.25%, LC: 88.46%). The lobe of the lesion (p = 0.005) and the age (p = 0.009) confounded contrast sensitivity in the VF and SD tasks respectively. Both VF and LC tasks demonstrated unilateral lateralization of posterior language areas; only the LC task showed unilateral lateralization of anterior language areas. Our study highlights the effects of patient-related confounding factors on language fMRI and proposes LC as the most feasible, less confounded, and efficiently lateralizing task in the clinical presurgical context.","2021-07","2025-02-26 20:41:55","2025-02-26 20:41:55","","511-524","","4","34","","","","","","","","","","English","","","","WOS:000638807100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;108</p>","","","Brain surgery; Brain tumor; Broca’; CHILDREN; CLINICAL FMRI; Epilepsy surgery; FMRI; FUNCTIONAL MRI; HEMISPHERIC DOMINANCE; LATERALIZATION; MEMORY; NARRATIVE COMPREHENSION; PREOPERATIVE ANXIETY; s; SPONTANEOUS SPEECH; Wernicke’; WORD GENERATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PI5KN3RN","journalArticle","2023","Yastrebov-Pestritsky, MS","TROUBLED MINORS AND SOCIAL NETWORKS: ""NEWSPAPER FOR A NARROW CIRCLE"" (Cultural research in the linguistic aspect)","VESTNIK SLAVIANSKIKH KULTUR-BULLETIN OF SLAVIC CULTURES-SCIENTIFIC AND INFORMATIONAL JOURNAL","","2073-9567","10.37816/2073-9567-2023-68-8-17","","It often happens that a community of regular respondents on certain forums is formed in social networks. Visitors, usually referred to as persons with deviant behavior in educational institutions, often settle in such anonymous communities. They are attracted in electronic communication by the opportunity to correspond with an opponent (often with everyone at once), without restraining their emotions, and to use rude words and expressions, up to the most extreme. It is especially difficult, almost impossible, to draw such an interlocutor out and to frankly talk about anything, be it sports, politics, education, or any other topic of everyday discussions. A person (let's call him a subject) only pretends to be interested in a particular topic, but his real purpose is to get involved in a conversation, briefly, quickly and roughly covering as many respondents as possible with an answer. Thus, he constantly brightens up his loneliness. As a rule, the respondent of this type does not linger on any one interlocutor: his method is ""self-affirmation by mass character"". However, we managed, with the help of patient explanatory work, to continue correspondence with ""I.G."" until the moment of full understanding of the young man's inability to have a healthy discussion: the source of swear words has dried up, and the subject simply did not maintain other types of communication. Nevertheless, he undoubtedly is worldly-wise: he tries not to discuss those areas in which rude judgments can be fraught with prosecution, in general, he avoids reporting at least some data about himself, hiding behind rudeness and swearing the fear of giving them away accidentally. But people who have been visiting the same social media pages for years, against their desire, give indirect hints about their personality and their lifestyle. Actually, the study is about the fact that, despite the respondent's desire (unwillingness), his language (spontaneous speech presented in the form of an electronic text) can tell a lot.","2023","2025-02-26 20:41:55","2025-02-26 20:41:55","","8-17","","","68","","","","","","","","","","English","","","","WOS:001043087300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;4</p>","","","Electronic Correspondence; Euphemisms; Invective Words; Pejorative Assessment; Respondent; Social Networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YD8RMTQQ","journalArticle","2022","Saban-Dülger, NS; Turan, F; Özcebe, E","The Adaptation of Developmental Sentence Scoring and Index of Productive Syntax to Turkish","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2021_JSLHR-20-00637","","Purpose: Language sampling analysis (LSA) plays an important role in evaluating language skills; hence, the study aimed to develop new assessment measures for the LSA in Turkish as alternatives to mean length of utterance (MLU) and the Language Assessment, Remediation and Screening Procedure. With this aim, Developmental Sentence Scoring (DSS) and the Index of Productive Syntax (IPSyn) were adapted to Turkish. Method: Eighty monolingual Turkish children were included in the study, and the age range was from 2;0 to 5;11 (years;months). The children were grouped with 6-month intervals, and each group had an equal number of participants in terms of gender. Their general and language development were tested with standardized tests, and language sampling was recorded during play with farm toys for 15-20 min. Reviewing literature and observing participants' production schemas were created for DSS for Turkish (DSS-TR) and the IPSyn for Turkish (IPSyn-TR) separately, and final versions were determined in consultation with experts. Results: DSS-TR and IPSyn-TR were significantly correlated with standardized tests, and MLU values were statistically significant (p .05). Total scores increased with age; however, grammatical categories did not go up. No difference was observed between genders (p .05). In DSS-TR, the ""sentence point"" did not affect the participants' total scores because of language characteristics (p > .05). Finally, DSS-TR and IPSyn-TR were seen to be correlated with each other (p < .05). Conclusions: DSS-TR and IPSyn-TR are valid, being correlated with other assessment tools, and reliable, showing a high correlation with other raters, to reflect morphosyntactic skills. Therefore, they both are alternative assessment measures that will be used in LSA and give an opportunity to clinicians to plan their intervention goals. Also, they enable clinicians to observe progress not only specific to grammatical category but also in the total scores of the children either during or at the end of the therapy.","2022-03","2025-02-26 20:41:55","2025-02-26 20:41:55","","1001-1024","","3","65","","","","","","","","","","English","","","","WOS:000767494300013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;122</p>","","","3-YEAR-OLDS; AGE; CHILDREN; COMPLEXITY; GRAMMATICAL DEVELOPMENT; LANGUAGE-ACQUISITION; MEAN LENGTH; RELIABILITY; SPONTANEOUS SPEECH; UTTERANCE LENGTH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NK3M8DCZ","journalArticle","2023","Cristia, A; Gautheron, L; Colleran, H","Vocal input and output among infants in a multilingual context: Evidence from long-form recordings in Vanuatu","DEVELOPMENTAL SCIENCE","","1363-755X","10.1111/desc.13375","","What are the vocal experiences of children growing up on Malakula island, Vanuatu, where multilingualism is the norm? Long-form audio-recordings captured spontaneous speech behavior by, and around, 38 children (5-33 months, 23 girls) from 11 villages. Automated analyses revealed most children's vocal input came from female adults and other children's voices, with small contributions from male adult voices. The greatest changes with age involved an increase in the input vocalizations from other children. Total input (collapsing across child-directed and overheard speech, and across languages) was similar to 11 min per hour, which was at least 5 min (31%) lower than that found in other populations studied using comparable methods in previous literature, as well as in archival American data analyzed with the same algorithm. In contrast, children's own vocalization counts were two to four times higher than previous reports for North-American English-learning monolingual infants at matched ages, and comparable to estimates from archival American data, consistent with a resilient language-learning cognitive system for this aspect of vocal development. The strongest association between input and output was with vocalizations by other children, rather than those by adults, which is consistent with research in anthropology but less so with current theoretical trends in developmental psychology. These results invite further research in populations that are under-represented in developmental science. Research HighlightsCombining long-form recordings with automated analyses, we estimated infants potentially exposed to similar to 2.6 languages heard similar to 11 min of speech per hour.Infants' input was dominated by vocalizations from female adults and from other children, particularly for the oldest infants in our sample.The strongest association between children's own vocalization counts and input counts was with those of other children, and not those with adults.Results invite further research on individual, group, and population variability in input quantity and composition, and its potential effects on vocal development.","2023-07","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","4","26","","","","","","","","","","English","","","","WOS:000947268200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","infant-directed speech; language acquisition; LANGUAGE INPUT; long-form recordings; multilingualism","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X4PVQN2Q","journalArticle","2022","Bohan, M; Navalna, M; Istomine, A","Individual Verbal Codes of Spontaneous Emotional Psychoregulation of Modern Ukrainian Youth","PSYCHOLINGUISTICS","","2309-1797","10.31470/2309-1797-2022-31-2-6-32","","The purpose of the article is to analyze the ways of verbal emotional regulation of modern Ukrainian youth and to outline ways to improve their psycholinguistic hygiene. To achieve this goal, the following tasks were performed: (1) the typical verbal reactions of modern Ukrainian youth to stressful stimuli were clarified; (2) the features of youth spontaneous response to stress were compared with the usual formulas of Ukrainian linguistic culture of psychological self-defense. Methods and Techniques. The investigation is grounded on the methods of analysis, synthesis, induction, deduction, descriptive, questionnaire, communicative-pragmatic analysis, comparative method (to compare different verbal reactions of respondent), and the quantitative method (to determine the dominant forms of emotional response of young people). The comprehensive methodology was used: monitoring of scientific sources, experimental modeling of stressful situations, interviewing students, analysis of their spontaneous reactions, testing of various forms of influence on youth emotional verbal reactions, formulation of conclusions. Results. Based on the questionnaire, the author concludes about the mostly unconscious attitude of modern Ukrainian youth to forms of emotional response, as their spontaneous speech shows widespread use of non-normative, stylistically reduced units and limited use of traditional emotional exclamations, paremias or ironic expressions. Young people show more empathy in the psychoregulation of others than in relation to themselves. The author recommends cultivating in the youth environment communicative tactics of support, inspiration, outlining a positive perspective, emotional empathy and explaining the ineffectiveness of devaluation tactics, correcting of the addressee's behavior by a negative imperative. Conclusions. The article substantiates the importance of forming emotional competence of modern Ukrainian youth in higher education institutions, diversification and modernization of educational material, giving more attention to tactics and strategies of communication and analysis virtual forms of communication. The author emphasizes the need to develop students' meaningful attitude to their own speech and apply an active and creative approach to finding expressive and at the same time acceptable codes of emotional self-expression. The paper suggests practical recommendations to weaning students from vulgar and non-normative emotional reactions.","2022","2025-02-26 20:41:55","2025-02-26 20:41:55","","6-32","","2","31","","","","","","","","","","English","","","","WOS:000805675000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","communicative tactics; profanity; psycholinguistic hygiene; psychoregulation; spontaneous emotional reaction; verbal codes; youth speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LLDWUG8V","journalArticle","2022","Sakai, M; Ihori, N; Nishikawa, T","Pitch accent disorder observed in a Japanese patient due to traumatic head injury","APHASIOLOGY","","0268-7038","10.1080/02687038.2021.1978382","","Background: Suprasegmental features are often affected by brain damage, and are typically accompanied by motor speech disorders such as dysarthria, apraxia of speech (AOS), and foreign accent syndrome (FAS). However, there is no report of a selective pitch accent disorder without motor speech impairments or FAS. Aims: We describe a female Japanese patient who developed a selective pitch accent disorder without motor speech impairments or FAS, with accompanying mild Wernicke's aphasia due to head injury, in order to investigate the mechanism of pitch accent disorder based on speech production models. Methods & Procedures: We analysed her spontaneous speech, confrontation naming, repetition, reading aloud, and the error patterns in her pitch accents in two sessions. Additionally, we gave her a reading aloud test of homonyms with different accent patterns and an auditory discrimination task of pitch accents. Outcomes & Results: The patient exhibited a significant recovery from aphasia, and paraphasia was observed to almost disappear, although the pitch accent errors remained in all speech modalities. While she was able to auditorily distinguish between correct and incorrect pitch accents, she was unaware of her own abnormally accented speech. The results of the analysis of the error patterns in her pitch accents revealed that they, even if incorrect for the selected words, did not actually deviate from the correct patterns in the Osaka dialect, her native dialect. Conclusions: Our observations suggest that the process of pitch accent production may be independent of that of phoneme production. Moreover, it may be that her accent abnormalities were not produced randomly during the process of articulation, but instead may have been due to a problem in selecting pitch accent patterns from the repertoire of Osaka accent patterns allocated to the corresponding words. This suggests that the patient's pitch accent disorder was a problem in a higher level of linguistic processing, i.e., lexical pitch accent encoding, rather than the motor control of speech production.","2022-12-02","2025-02-26 20:41:55","2025-02-26 20:41:55","","1520-1534","","12","36","","","","","","","","","","English","","","","WOS:000702189500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","APHASIA; foreign accent syndrome; lexical pitch accent encoding; Pitch accent disorder; prosody; STRESS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"649YYFDN","journalArticle","2024","Richard, H; Dornheim, P; Weber, T","Using AI to Improve Risk Management: A Case Study of a Leading Telecommunications Provider","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3488321","","In the dynamic and competitive telecommunications industry, effective risk management is critical. Traditional methods are often manual and labor-intensive, prone to inaccuracies and inefficiencies. This paper addresses these challenges by integrating advanced machine learning algorithms to automate and improve the risk management process at a large telecommunications company, hereafter referred to as TP. The study applies state-of-the-art transformer-based machine learning models - BERT, RoBERTa, DeBERTa, and ERNIE 2.0 - alongside a classical support vector machine (SVM) for comparative analysis. The approach leverages the Cross-Industry Standard Process for Data Mining (CRISP-DM) model, emphasizes text classification algorithms to categorize risk events, and introduces a one-class SVM for novelty detection to identify unprecedented risk events. The results show that transformer-based models achieve superior prediction accuracy over traditional SVMs, with the best-performing transformer model (DeBERTa) achieving an F1 score of 92.5%, significantly improving the risk classification accuracy. In addition, the novelty detection mechanism successfully identifies novel risk events with an accuracy of 77.2% and an AUROC of 79.2%. This integration streamlines risk management processes and provides operational benefits to telecommunications companies. By providing insight into these technologies' economic and operational benefits, this study contributes to the practical application of AI in telecommunications, particularly in risk event assessment and natural language processing.","2024","2025-02-26 20:41:55","2025-02-26 20:41:55","","165068-165080","","","12","","","","","","","","","","English","","","","WOS:001354628000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","Accuracy; Adaptation models; Anomaly detection; Artificial intelligence; Biological system modeling; Computational modeling; Data models; machine learning; Machine learning; novelty detection; risk management; Risk management; telecommunications; Telecommunications; text classification; transformer models; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H37PILV7","journalArticle","2024","Yuan, HX; Li, HB; Zhang, Y; Wei, CX; Gao, RY","Complex-Valued Multiscale Vision Transformer on Space Target Recognition by ISAR Image Sequence","IEEE GEOSCIENCE AND REMOTE SENSING LETTERS","","1545-598X","10.1109/LGRS.2024.3388427","","In recent years, research on the recognition for inverse synthetic aperture radar (ISAR) images continues to deepen, while most methods only use the amplitude information of the ISAR image data. Besides, high-order terms in the complex-valued (CV) received signals for maneuvering space targets will cause defocusing on the ISAR images, which affects the accuracy of the recognition. For a steadily rotating maneuvering target, its high-order phase information between frames is relevant, and this information can be used to facilitate recognition. To this end, this letter proposes an end-to-end recognition framework in the CV domain based on the transformer model. It uses a multiscale feature extraction strategy and a CV attention mechanism to get the local and global hybrid feature. Besides, a spatiotemporal transformer (STT) block is proposed to obtain the spatiotemporal correlation between image frames to assist recognition. Finally, a residual convolutional neural network (CNN) block is introduced to promote diversity in the captured representations. In the experimental part, the recognition results of the proposed method on the real and simulated datasets are better than those of other methods. Compared with the classic sequence recognition method CV long short-term memory (CVLSTM), the recognition accuracy and kappa coefficient of the proposed method are increased by approximately 5.6% and 5.4%, respectively.","2024","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","21","","","","","","","","","","English","","","","WOS:001221540500010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","Complex-valued (CV) network; Convolutional neural networks; Correlation; deep learning; image recognition; Image recognition; Image sequences; inverse synthetic aperture radar (ISAR); Target recognition; Transformers; Vectors; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZVETHY3H","journalArticle","2024","Li, Y; Li, JW; Wang, HJ; Liu, CB; Tan, J","Knowledge enhanced ensemble method for remaining useful life prediction under variable working conditions","RELIABILITY ENGINEERING & SYSTEM SAFETY","","0951-8320","10.1016/j.ress.2023.109748","","Remaining useful life (RUL) prediction is essential in enhancing the safety and reliability of rotating machinery. Deep learning techniques have been extensively researched and demonstrated promising results in RUL prediction tasks. But most existing models are designed for machinery equipment in a specific condition. In this case, a novel prediction method, knowledge-enhanced convolutional Transformer ensemble model (KE-CTEM), is proposed in this study. First, a feature extraction neural network (FENN) is introduced to extract features and transfer the working conditions information of existing datasets as knowledge to downstream RUL prediction tasks. Then, a convolutional Transformer model is leveraged to capture the input data degradation patterns and predict RUL values. Finally, knowledge-enhanced strategy and ensemble strategy are proposed to enhance the robustness of the model and improve the prediction accuracy.To verify the practicality and effectiveness of the proposed method, run-to-failure data of bearings from PRONOSTIA platform are utilized for RUL prognostics. Compared with several representative and stateof-the-art methods, the experimental results demonstrate the superiority and feasibility of the proposed method. And ablation study indicates the high efficiency and robustness of each module within the proposed model. Compared with representative RUL prediction methods, the proposed KE-CTEM demonstrates superior performance in terms of RMSE and MAPE with a reduction of 32.0% and 16.2%, respectively.","2024-02","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","242","","","","","","","","","","English","","","","WOS:001108579900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Attention mechanism; Convolutional neural network; Ensemble learning; MODEL; NEURAL-NETWORK; Remaining useful life; Transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6WKZIL33","journalArticle","2023","Liu, Y; Li, C; Guo, Z; Ren, FQ; Liu, F; Fu, YZ; Zhu, YS; Wang, XL","Broadband Modelling of Power Transformers for Sweep Frequency Impedance Studies on Winding Short-Circuit Faults","ELECTRONICS","","2079-9292","10.3390/electronics12194068","","To study sweep frequency impedance (SFI) features of short-circuit (SC) faults easily, this paper proposes a broadband electric circuit model of a transformer winding and solves its three key problems. The first problem is the calculation of lumped-circuit parameters considering frequency-dependent complex anisotropic permeabilities (FDCAPs), which are caused by the physical characteristics, such as skin, proximity, and geometrical effects and anisotropic properties, of the transformer core and winding materials. The other issue is the establishment of the electric circuit model based on the SFI measurement connection mode, the transformer winding parameters, and a double-ladder network (DLN). Another issue is the construction of the state-space model of the electric circuit toward different SFI values to obtain all network branch voltages and currents. The accuracy of the proposed model is assessed by comparing its SFI signatures with those of the simulation model, without considering FDCAPs under healthy winding, and the corresponding physical transformer model during healthy winding and SC faults. It is observed that the SFI results of the proposed model are closer to the experimental measurements, and the model can be effectively used to study the SFI features of SC faults. Moreover, the impacts of different types of SC faults on the SFI data are concluded in this paper.","2023-10","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","19","12","","","","","","","","","","English","","","","WOS:001083336100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","ALGORITHM; AXIAL DISPLACEMENT; FEM modelling; NETWORK PARAMETERS IDENTIFICATION; power transformer winding; RESPONSE ANALYSIS; short-circuit faults; sweep frequency impedance; transformer broadband model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TFZ4NGNU","journalArticle","2022","Li, XT; Qiu, B; Cao, GL; Wu, C; Zhang, LW","A Novel Method for Ground-Based Cloud Image Classification Using Transformer","REMOTE SENSING","","2072-4292","10.3390/rs14163978","","In recent years, convolutional neural networks (CNNs) have achieved competitive performance in the field of ground-based cloud image (GCI) classification. Proposed CNN-based methods can fully extract the local features of images. However, due to the locality of the convolution operation, they cannot well establish the long-range dependencies between the images, and thus they cannot extract the global features of images. Transformer has been applied to computer vision with great success due to its powerful global modeling capability. Inspired by it, we propose a Transformer-based GCI classification method that combines the advantages of the CNN and Transformer models. Firstly, the CNN model acts as a low-level feature extraction tool to generate local feature sequences of images. Then, the Transformer model is used to learn the global features of the images by efficiently extracting the long-range dependencies between the sequences. Finally, a linear classifier is used for GCI classification. In addition, we introduce a center loss function to address the problem of the simple cross-entropy loss not adequately supervising feature learning. Our method is evaluated on three commonly used datasets: ASGC, CCSN, and GCD. The experimental results show that the method achieves 94.24%, 92.73%, and 93.57% accuracy, respectively, outperforming other state-of-the-art methods. It proves that Transformer has great potential to be applied to GCI classification tasks.","2022-08","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","16","14","","","","","","","","","","English","","","","WOS:000845308700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","COLOR; convolutional neural network (CNN); FEATURE-EXTRACTION; global features; ground-based cloud image (GCI) classification; local features; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I6IHRREG","journalArticle","2024","Han, G; Ma, JS; Li, ZY; Zhao, HT","A Two-Stage Foveal Vision Tracker Based on Transformer Model","IEEE TRANSACTIONS ON COGNITIVE AND DEVELOPMENTAL SYSTEMS","","2379-8920","10.1109/TCDS.2024.3377642","","With the development of transformer visual models, attention-based trackers have shown highly competitive performance in the field of object tracking. However, in some tracking scenarios, especially those with multiple similar objects, the performance of existing trackers is often not satisfactory. In order to improve the performance of trackers in such scenarios, inspired by the fovea vision structure and its visual characteristics, this article proposes a novel foveal vision tracker (FVT). FVT combines the process of human eye fixation and object tracking, pruning based on the distance to the object rather than attention scores. This pruning method allows the receptive field of the feature extraction network to focus on the object, excluding background interference. FVT divides the feature extraction network into two stages: local and global, and introduces the local recursive module (LRM) and the view elimination module (VEM). LRM is used to enhance foreground features in the local stage, while VEM generates circular fovea-like visual field masks in the global stage and prunes tokens outside the mask, guiding the model to focus attention on high-information regions of the object. Experimental results on multiple object tracking datasets demonstrate that the proposed FVT achieves stronger object discrimination capability in the feature extraction stage, improves tracking accuracy and robustness in complex scenes, and achieves a significant accuracy improvement with an area overlap (AO) of 72.6% on the generic object tracking (GOT)-10k dataset.","2024-08","2025-02-26 20:41:55","2025-02-26 20:41:55","","1575-1588","","4","16","","","","","","","","","","English","","","","WOS:001292741200016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Feature extraction; Foveal vision; object tracking; Object tracking; Predictive models; single stream tracker; Task analysis; Transformers; vision transformer; Visual systems; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AX54YRME","journalArticle","2024","Martin, J; Mateos, ML; Onuchic, JN; Coluzza, I; Morcos, F","Machine learning in biological physics: From biomolecular prediction to design","PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA","","0027-8424","10.1073/pnas.2311807121","","Machine learning has been proposed as an alternative to theoretical modeling when dealing with complex problems in biological physics. However, in this perspective, we argue that a more successful approach is a proper combination of these two methodologies. We discuss how ideas coming from physical modeling neuronal processing led to early formulations of computational neural networks, e.g., Hopfield networks. We then show how modern learning approaches like Potts models, Boltzmann machines, and the transformer architecture are related to each other, specifically, through a shared energy representation. We summarize recent efforts to establish these connections and provide examples on how each of these formulations integrating physical modeling and machine learning have been successful in tackling recent problems in biomolecular structure, dynamics, function, evolution, and design. Instances include protein structure prediction; improvement in computational complexity and accuracy of molecular dynamics simulations; better inference of the effects of mutations in proteins leading to improved evolutionary modeling and finally how machine learning is revolutionizing protein engineering and design. Going beyond naturally existing protein sequences, a connection to protein design is discussed where synthetic sequences are able to fold to naturally occurring motifs driven by a model rooted in physical principles. We show that this model is ""learnable"" and propose its future use a target structure.","2024-07-02","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","27","121","","","","","","","","","","English","","","","WOS:001263367200004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;110</p>","","","ASSOCIATIVE MEMORY; CONTACTS; DEPENDENCE; DIRECT-COUPLING ANALYSIS; INFERENCE; LANDSCAPES; MODELS; Potts model; protein design; protein evolution; protein structure and dynamics; PROTEIN-STRUCTURE PREDICTION; SEQUENCE-SPACE; SYSTEMS; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XINUG2IF","journalArticle","2024","Ahsan, MU; Gouru, A; Chan, J; Zhou, WD; Wang, K","A signal processing and deep learning framework for methylation detection using Oxford Nanopore sequencing","NATURE COMMUNICATIONS","","2041-1723","10.1038/s41467-024-45778-y","","Oxford Nanopore sequencing can detect DNA methylations from ionic current signal of single molecules, offering a unique advantage over conventional methods. Additionally, adaptive sampling, a software-controlled enrichment method for targeted sequencing, allows reduced representation methylation sequencing that can be applied to CpG islands or imprinted regions. Here we present DeepMod2, a comprehensive deep-learning framework for methylation detection using ionic current signal from Nanopore sequencing. DeepMod2 implements both a bidirectional long short-term memory (BiLSTM) model and a Transformer model and can analyze POD5 and FAST5 signal files generated on R9 and R10 flowcells. Additionally, DeepMod2 can run efficiently on central processing unit (CPU) through model pruning and can infer epihaplotypes or haplotype-specific methylation calls from phased reads. We use multiple publicly available and newly generated datasets to evaluate the performance of DeepMod2 under varying scenarios. DeepMod2 has comparable performance to Guppy and Dorado, which are the current state-of-the-art methods from Oxford Nanopore Technologies that remain closed-source. Moreover, we show a high correlation (r = 0.96) between reduced representation and whole-genome Nanopore sequencing. In summary, DeepMod2 is an open-source tool that enables fast and accurate DNA methylation detection from whole-genome or adaptive sequencing data on a diverse range of flowcell types. The authors present DeepMod2, a deep-learning based computational method that allows fast and accurate detection of DNA methylation and epihaplotypes from Oxford Nanopore sequencing data.","2024-02-16","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","1","15","","","","","","","","","","English","","","","WOS:001164810100025","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;18<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","CANCER; DNA METHYLATION; GENOME","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LY4BVYFZ","journalArticle","2023","Wang, YJ; Dong, MZ; Shen, J; Luo, YM; Lin, YM; Ma, PC; Petridis, S; Pantic, M","Self-Supervised Video-Centralised Transformer for Video Face Clustering","IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE","","0162-8828","10.1109/TPAMI.2023.3243812","","This article presents a novel method for face clustering in videos using a video-centralised transformer. Previous works often employed contrastive learning to learn frame-level representation and used average pooling to aggregate the features along the temporal dimension. This approach may not fully capture the complicated video dynamics. In addition, despite the recent progress in video-based contrastive learning, few have attempted to learn a self-supervised clustering-friendly face representation that benefits the video face clustering task. To overcome these limitations, our method employs a transformer to directly learn video-level representations that can better reflect the temporally-varying property of faces in videos, while we also propose a video-centralised self-supervised framework to train the transformer model. We also investigate face clustering in egocentric videos, a fast-emerging field that has not been studied yet in works related to face clustering. To this end, we present and release the first large-scale egocentric video face clustering dataset named EasyCom-Clustering. We evaluate our proposed method on both the widely used Big Bang Theory (BBT) dataset and the new EasyCom-Clustering dataset. Results show the performance of our video-centralised transformer has surpassed all previous state-of-the-art methods on both benchmarks, exhibiting a self-attentive understanding of face videos.","2023-11-01","2025-02-26 20:41:55","2025-02-26 20:41:55","","12944-12959","","11","45","","","","","","","","","","English","","","","WOS:001258161200004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;85</p>","","","Contrastive learning; egocentric video analysis; Face recognition; Faces; OBJECTS; self-supervised learning; Streaming media; Task analysis; transformer in vision; Transformers; TV; video centralised learning; video face clustering; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UMV9X89N","journalArticle","2023","Yang, YQ; He, P; Wang, SR; Tian, Y; Zhang, W","DB-TASNet for disease diagnosis and lesion segmentation in medical images","JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION","","1047-3203","10.1016/j.jvcir.2023.103896","","Deep learning algorithms have been successfully used in the field of medical image analysis and have greatly improved application of intelligent algorithms to medical diagnosis. However, existing deep-learning-based diagnostic methods still suffer from several drawbacks: (1) In most medical image multi-tasking methods, focus segmentation and disease classification are often performed linearly, resulting in excessive reliance on the final results of focus segmentation. (2) The computational cost of the traditional attention mechanism for performing the segmentation task is very high and the convolutional architecture cannot be used to model long-distance dependencies, which in turn affects the segmentation accuracy. To address these issues, we propose a disease diagnosis and lesion segmentation model, Dual-Branch with Transformer Axial-attention Segmentation Net (DB-TASNet). DB-TASNet is built by the DenseNet-121 classification network and U-Net segmentation network improved using an axial-attention transformer model. Moreover, DB-TASNet also includes a lesion integration module to integrate segmentation results with the classification network in order to increase its attention to lesions and improve the diagnosis results. Experimental results on the Pneumothorax dataset provided by the Society for Imaging Informatics in Medicine (SIIM) show that the average AUC of the DB-TASNet classification task reaches 0.939, and the DICE coefficient of the segmentation task reaches 0.886. Such performance suggests that the proposed model may provide an efficient and effective diagnosis tool for medical personnel.","2023-09","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","95","","","","","","","","","","English","","","","WOS:001048341500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","DB-TASNet; Disease diagnosis; Lesion segmentation; NETWORK; Transformer; TRANSFORMER; U-Net","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BNQGFI7V","journalArticle","2021","Ferreira, RSD; Picher, P; Ezzaidi, H; Fofana, I","A Machine-Learning Approach to Identify the Influence of Temperature on FRA Measurements","ENERGIES","","1996-1073","10.3390/en14185718","","Frequency response analysis (FRA) is a powerful and widely used tool for condition assessment in power transformers. However, interpretation schemes are still challenging. Studies show that FRA data can be influenced by parameters other than winding deformation, including temperature. In this study, a machine-learning approach with temperature as an input attribute was used to objectively identify faults in FRA traces. To the best knowledge of the authors, this has not been reported in the literature. A single-phase transformer model was specifically designed and fabricated for use as a test object for the study. The model is unique in that it allows the non-destructive interchange of healthy and distorted winding sections and, hence, reproducible and repeatable FRA measurements. FRA measurements taken at temperatures ranging from -40 degrees C to 40 degrees C were used first to describe the impact of temperature on FRA traces and then to test the ability of the machine learning algorithms to discriminate between fault conditions and temperature variation. The results show that when temperature is not considered in the training dataset, the algorithm may misclassify healthy measurements, taken at different temperatures, as mechanical or electrical faults. However, once the influence of temperature was considered in the training set, the performance of the classifier as studied was restored. The results indicate the feasibility of using the proposed approach to prevent misclassification based on temperature changes.","2021-09","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","18","14","","","","","","","","","","English","","","","WOS:000699480700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","comparative standard deviation; frequency response analysis interpretation; FREQUENCY-RESPONSE ANALYSIS; machine learning; support vector machine; transformer condition monitoring","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YBMQVWHW","journalArticle","2023","Ali, G; Malik, MSI","Rumour identification on Twitter as a function of novel textual and language-context features","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-022-13595-4","","Social microblogs are one of the popular platforms for information spreading. However, with several advantages, these platforms are being used for spreading rumours. At present, the majority of existing approaches identify rumours at the topic level instead of at the tweet/post level. Moreover, prior studies used the sentiment and linguistic features for rumours identification without considering discrete positive and negative emotions and effective part-of-speech features in content-based approaches. Similarly, the majority of prior studies used content-based approaches for feature generation, and recent context-based approaches were not explored. To cope with these challenges, a robust framework for rumour detection at the tweet level is designed in this paper. The model used word2vec embeddings and bidirectional encoder representations from transformers method (BERT) from context-based and discrete emotions, linguistic, and metadata characteristics from content-based approaches. According to our knowledge, we are the first ones who used these features for rumour identification at the tweet/post level. The framework is tested on four real-life twitter microblog datasets. The results show that the detection model is capable of detecting 97%, 86%, 85%, and 80% of rumours on four datasets respectively. In addition, the proposed framework outperformed the three latest state-of-the-art baselines. BERT model presented the best performance among context-based approaches, and linguistic features are best performing among content-based approaches as a stand-alone model. Moreover, the utilization of two-step feature selection further improves the detection model performance.","2023-02","2025-02-26 20:41:55","2025-02-26 20:41:55","","7017-7038","","5","82","","","","","","","","","","English","","","","WOS:000839516800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Classification; Detection; Language context; Rumour; Twitter","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SX62PGMT","journalArticle","2024","Khan, MA","A Comparative Study on Imputation Techniques: Introducing a Transformer Model for Robust and Efficient Handling of Missing EEG Amplitude Data","BIOENGINEERING-BASEL","","2306-5354","10.3390/bioengineering11080740","","In clinical datasets, missing data often occur due to various reasons including non-response, data corruption, and errors in data collection or processing. Such missing values can lead to biased statistical analyses, reduced statistical power, and potentially misleading findings, making effective imputation critical. Traditional imputation methods, such as Zero Imputation, Mean Imputation, and k-Nearest Neighbors (KNN) Imputation, attempt to address these gaps. However, these methods often fall short of accurately capturing the underlying data complexity, leading to oversimplified assumptions and errors in prediction. This study introduces a novel Imputation model employing transformer-based architectures to address these challenges. Notably, the model distinguishes between complete EEG signal amplitude data and incomplete data in two datasets: PhysioNet and CHB-MIT. By training exclusively on complete amplitude data, the TabTransformer accurately learns and predicts missing values, capturing intricate patterns and relationships inherent in EEG amplitude data. Evaluation using various error metrics and R2 score demonstrates significant enhancements over traditional methods such as Zero, Mean, and KNN imputation. The Proposed Model achieves impressive R2 scores of 0.993 for PhysioNet and 0.97 for CHB-MIT, highlighting its efficacy in handling complex clinical data patterns and improving dataset integrity. This underscores the transformative potential of transformer models in advancing the utility and reliability of clinical datasets.","2024-08","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","8","11","","","","","","","","","","English","","","","WOS:001305651900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","attention; big data; CHB-MIT; clinical data; deep learning; EEG; imputation; machine learning; PhysioNet; TabTransformer; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9UGBZL45","journalArticle","2024","Jiang, WJ; Liu, B; Liang, Y; Gao, HX; Lin, PF; Zhang, DQ; Hu, G","Applicability analysis of transformer to wind speed forecasting by a novel deep learning framework with multiple atmospheric variables","APPLIED ENERGY","","0306-2619","10.1016/j.apenergy.2023.122155","","Accurate wind speed forecasting plays a crucial role in the efficient and economical management of power supply systems. In this study, a novel framework combining variational mode decomposition (VMD), graph neural network (GNN) and temporal forecasting component is proposed for wind speed forecasting using mul-tiple atmospheric variables. VMD is employed to decompose atmospheric variables into distinct subsequences at various frequencies, and GNN is utilized to effectively pass, aggregate, and update variable features, thus enabling the extraction of pairwise dependencies among the different variables. Subsequently, the transformer model is used as the temporal forecasting component in the proposed framework. Compared with several state -of-the-art transformer-based models and baseline models in AI field, the superior performance of our hybrid framework is observed. Lastly, several other deep learning models, including multi-layer perceptrons (MLP), long short-term memory (LSTM), and gated recurrent unit (GRU), are selected as forecasting component for assessing the applicability of the transformer. Interestingly, the transformer exhibits the lowest performance, while the GRU demonstrates the most promising results, with the mean absolute error (MAE) of 0.1356 m/s and 0.1085 m/s for one-step ahead forecasting, respectively. Overall, this research provides valuable insights into a novel framework and the applicability of the transformer for wind speed forecasting.","2024-01-01","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","353","","","","","","","","","","English","","","","WOS:001108155800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;24<br/>Total Times Cited:&nbsp;&nbsp;24<br/>Cited Reference Count:&nbsp;&nbsp;82</p>","","","ATTENTION; ENERGY; Graph neural network; MODEL; Multiple atmospheric variables; NETWORKS; PREDICTION; Short-term forecasting; Transformer; Variational mode decomposition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6XLJHMBI","journalArticle","2023","Li, DP; Peng, YJ; Sun, JD; Guo, YF","A task-unified network with transformer and spatial-temporal convolution for left ventricular quantification","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-023-40841-y","","Quantification of the cardiac function is vital for diagnosing and curing the cardiovascular diseases. Left ventricular function measurement is the most commonly used measure to evaluate the function of cardiac in clinical practice, how to improve the accuracy of left ventricular quantitative assessment results has always been the subject of research by medical researchers. Although considerable efforts have been put forward to measure the left ventricle (LV) automatically using deep learning methods, the accurate quantification is yet a challenge work as a result of the changeable anatomy structure of heart in the systolic diastolic cycle. Besides, most methods used direct regression method which lacks of visual based analysis. In this work, a deep learning segmentation and regression task-unified network with transformer and spatial-temporal convolution is proposed to segment and quantify the LV simultaneously. The segmentation module leverages a U-Net like 3D Transformer model to predict the contour of three anatomy structures, while the regression module learns spatial-temporal representations from the original images and the reconstruct feature map from segmentation path to estimate the finally desired quantification metrics. Furthermore, we employ a joint task loss function to train the two module networks. Our framework is evaluated on the MICCAI 2017 Left Ventricle Full Quantification Challenge dataset. The results of experiments demonstrate the effectiveness of our framework, which achieves competitive cardiac quantification metric results and at the same time produces visualized segmentation results that are conducive to later analysis.","2023-08-19","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","1","13","","","","","","","","","","English","","","","WOS:001052369000012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","AUTOMATED SEGMENTATION; CARDIAC BIVENTRICULAR VOLUMES; HEART; REGRESSION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"69Q6FXJI","journalArticle","2023","Yücel, Z; Akal, F; Oltulu, P","Mitotic cell detection in histopathological images of neuroendocrine tumors using improved YOLOv5 by transformer mechanism","SIGNAL IMAGE AND VIDEO PROCESSING","","1863-1703","10.1007/s11760-023-02642-8","","Automatic analysis of pathological images is important for the diagnosis and treatment of diseases. The use of computerized systems in this field is becoming increasingly common. Due to evolving technology and the speed of information needed, it is desirable for computers to be able to recognize objects like humans. Deep learning methods, which are a subfield of artificial intelligence, and image processing algorithms that recognize objects from images have been used in many fields in recent years, including healthcare. The aim of this study is to detect the mitoses in the histopathological images of neuroendocrine tumors using image processing methods based on deep learning. In our study, You Only Look Once-v5 (YOLOv5), the most widely used object recognition method, was used by combining the YOLOv5 transform module. YOLOv5 recognized mitotic cells with an accuracy of 0.80, a recall of 0.67, and an F1 score of 0.73, while the YOLOv5 transformer model recognized mitotic cells with an accuracy of 0.89, a recall of 0.68, and an F1 score of 0.77. The acceleration of the process and the objective evaluation will contribute significantly to an accurate and fast diagnosis. Another advantage is the time saved for pathologists, who can concentrate on important cases. In summary, automatic mitotic cell detection will facilitate tumor grade determination, treatment, and patient monitoring.","2023-11","2025-02-26 20:41:55","2025-02-26 20:41:55","","4107-4114","","8","17","","","","","","","","","","English","","","","WOS:001012575100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Biomedical image processing; DEEP LEARNING FRAMEWORK; DIAGNOSIS; Histopathological images; Mitosis detection; MITOSIS DETECTION; OBJECT DETECTION; Transformer; YOLOv5","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZCEHRCVU","journalArticle","2023","Hossain, S; Reza, MT; Chakrabarty, A; Jung, YJ","Aggregating Different Scales of Attention on Feature Variants for Tomato Leaf Disease Diagnosis from Image Data: A Transformer Driven Study","SENSORS","","1424-8220","10.3390/s23073751","","Tomato leaf diseases can incur significant financial damage by having adverse impacts on crops and, consequently, they are a major concern for tomato growers all over the world. The diseases may come in a variety of forms, caused by environmental stress and various pathogens. An automated approach to detect leaf disease from images would assist farmers to take effective control measures quickly and affordably. Therefore, the proposed study aims to analyze the effects of transformer-based approaches that aggregate different scales of attention on variants of features for the classification of tomato leaf diseases from image data. Four state-of-the-art transformer-based models, namely, External Attention Transformer (EANet), Multi-Axis Vision Transformer (MaxViT), Compact Convolutional Transformers (CCT), and Pyramid Vision Transformer (PVT), are trained and tested on a multiclass tomato disease dataset. The result analysis showcases that MaxViT comfortably outperforms the other three transformer models with 97% overall accuracy, as opposed to the 89% accuracy achieved by EANet, 91% by CCT, and 93% by PVT. MaxViT also achieves a smoother learning curve compared to the other transformers. Afterwards, we further verified the legitimacy of the results on another relatively smaller dataset. Overall, the exhaustive empirical analysis presented in the paper proves that the MaxViT architecture is the most effective transformer model to classify tomato leaf disease, providing the availability of powerful hardware to incorporate the model.","2023-04","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","7","23","","","","","","","","","","English","","","","WOS:000969163600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","attention; CCT; EANet; MaxViT; PVT; tomato leaf disease; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CPN6XCS3","journalArticle","2023","Zhu, SR; Liao, B; Hua, Y; Zhang, CL; Wan, FY; Qing, XL","A transformer model with enhanced feature learning and its application in rotating machinery diagnosis","ISA TRANSACTIONS","","0019-0578","10.1016/j.isatra.2022.07.016","","Deep learning has become the prevailing trend of intelligent fault diagnosis for rotating machines. Compared to early-stage methods, deep learning methods use automatic feature extraction instead of manual feature design. However, conventional intelligent diagnosis models are trapped by a dilemma that simple models are unable to tackle difficult cases, while complicated models are likely to over-parameterize. In this paper, a transformer-based model, Periodic Representations for Transformers (PRT) is proposed. PRT uses a dense-overlapping split strategy to enhance the feature learning inside sequence patches. Combined with the inherent capability of capturing long range dependencies of transformer, and the further information extraction of class-attention, PRT has excellent feature extraction abilities and could capture characteristic features directly from raw vibration signals. Moreover, PRT adopts a two-stage positional encoding method to encode position information both among and inside patches, which could adapt to different input lengths. A novel inference method to use larger inference sample sizes is further proposed to improve the performance of PRT. The effectiveness of PRT is verified on two datasets, where it achieves comparable and even better accuracies than the benchmark and state-of-the-art methods. PRT has the least FLOPs among the best performing models and could be further improved by the inference strategy, reaching an accuracy near 100%.(c) 2022 ISA. Published by Elsevier Ltd. All rights reserved.","2023-02","2025-02-26 20:41:55","2025-02-26 20:41:55","","1-12","","","133","","","","","","","","","","English","","","","WOS:000948610200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","BEARING FAULT-DIAGNOSIS; Intelligent fault diagnosis; Patch splitting; Positional encoding; Transformer; Varying-size inference; VIBRATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A8KTIF7L","journalArticle","2022","Song, ZW; Huang, XB; Ji, C; Zhang, Y","Double-Attention YOLO: Vision Transformer Model Based on Image Processing Technology in Complex Environment of Transmission Line Connection Fittings and Rust Detection","MACHINES","","2075-1702","10.3390/machines10111002","","Transmission line fittings have been exposed to complex environments for a long time. Due to the interference of haze and other environmental factors, it is often difficult for the camera to obtain high quality on-site images, and the traditional image processing technology and convolution neural networks find it difficult to effectively deal with the dense detection task of small targets with occlusion interference. Therefore, an image processing method based on an improved dark channel defogging algorithm, the fusion channel spatial attention mechanism, Vision Transformer, and the GhostNet model compression method is proposed in this paper. Based on the global receptive field of the saliency region capture and enhancement model, a small target detection network Double-attention YOLO for complex environments is constructed. The experimental results show that embedding a multi-head self-attention component into a convolutional neural network can help the model to better interpret the multi-scale global semantic information of images. In this way, the model learns more easily the distinguishable features in the image representation. Embedding an attention mechanism module can make the neural network pay more attention to the salient region of image. Dual attention fusion can balance the global and local characteristics of the model, to improve the performance of model detection.","2022-11","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","11","10","","","","","","","","","","English","","","","WOS:000912420700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","attention mechanism; DARK CHANNEL PRIOR; image defogging technology; model compression and optimization; multi-scale target detection; REMOVAL; transmission line connection fittings; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CRQIBCTV","journalArticle","2025","Zhang, Q; Zhu, J; Dong, YS; Zhao, EY; Song, MP; Yuan, QQ","10-minute forest early wildfire detection: Fusing multi-type and multi-source information via recursive transformer","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2024.128963","","Forest wildfire has great impacts on both nature and human society. While disrupts the ecosystems, wildfire leads to significant economic loss and poses a threat to local communities. To detect forest wildfire, remote sensing technology has become an essential and powerful tool. Compared with polar-orbiting satellite, the new generation of geostationary satellite provides higher temporal resolution and faster response capability. In this study, we utilize the near real-time data of Himawari-8/9 satellite, to achieve 10-min forest early wildfire detection. A recursive transformer model is proposed in this work. It fuses multi-type and multisource information for Himawari-8/9 satellite. By leveraging the spectral, temporal and spatial features of fire pixels and considering land cover information, the proposed method reduces interference factors like cloud and terrain, resulting in minute-level and near real-time detection of forest wildfire. In 21 ground truth forest wildfire scenarios and MODIS-based cross-validation dataset, the proposed method achieves better results compared to the JAXA wildfire product, in terms of overall fire detection accuracy, early fire detection rate, omission rate, and real-time performance. Furthermore, the proposed framework effectively lowers the emergency response time for early forest wildfire detection, thereby reducing the loss caused by forest wildfire.","2025-02-01","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","616","","","","","","","","","","English","","","","WOS:001396008800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","FIRE DETECTION ALGORITHM; Forest early wildfire detection; Himawari-8/9; IMAGERY; Information fusion; Minute-level; Near real-time; PRODUCT; Recursive transformer; REMOVAL; THICK CLOUD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NSXWX4KT","journalArticle","2024","Zhu, R; Pan, WX; Liu, JX; Shang, JL","Epileptic seizure prediction via multidimensional transformer and recurrent neural network fusion","JOURNAL OF TRANSLATIONAL MEDICINE","","1479-5876","10.1186/s12967-024-05678-7","","BackgroundEpilepsy is a prevalent neurological disorder in which seizures cause recurrent episodes of unconsciousness or muscle convulsions, seriously affecting the patient's work, quality of life, and health and safety. Timely prediction of seizures is critical for patients to take appropriate therapeutic measures. Accurate prediction of seizures remains a challenge due to the complex and variable nature of EEG signals. The study proposes an epileptic seizure model based on a multidimensional Transformer with recurrent neural network(LSTM-GRU) fusion for seizure classification of EEG signals.MethodologyFirstly, a short-time Fourier transform was employed in the extraction of time-frequency features from EEG signals. Second, the extracted time-frequency features are learned using the Multidimensional Transformer model. Then, LSTM and GRU are then used for further learning of the time and frequency characteristics of the EEG signals. Next, the output features of LSTM and GRU are spliced and categorized using the gating mechanism. Subsequently, seizure prediction is conducted.ResultsThe model was tested on two datasets: the Bonn EEG dataset and the CHB-MIT dataset. On the CHB-MIT dataset, the average sensitivity and average specificity of the model were 98.24% and 97.27%, respectively. On the Bonn dataset, the model obtained about 99% and about 98% accuracy on the binary classification task and the tertiary upper classification task, respectively.ConclusionThe findings of the experimental investigation demonstrate that our model is capable of exploiting the temporal and frequency characteristics present within EEG signals.","2024-10-04","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","1","22","","","","","","","","","","English","","","","WOS:001328966400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","CLASSIFICATION; EEG signals; Epilepsy prediction; Recurrent neural network; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RBCAWV9Z","journalArticle","2024","Zhang, T; Fu, MY; Song, WJ; Yang, Y; Alahi, A","Dynamic Voxels Based on Ego-Conditioned Prediction: An Integrated Spatio-Temporal Framework for Motion Planning","IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS","","1524-9050","10.1109/TITS.2024.3398008","","Prediction is a vital component of motion planning for autonomous vehicles (AVs). By reasoning about the possible behavior of other target agents, the ego vehicle (EV) can navigate safely, efficiently, and politely. However, most of the existing work overlooks the interdependencies of the prediction and planning module, only connecting them in a sequential pipeline or underexploring the prediction results in the planning module. In this work, we propose a framework that integrates the prediction and planning module with three highlights. First, we propose an ego-conditioned model for causal prediction, with the introduced edge-featured graph transformer model, the impact the ego future maneuver poses to the target vehicles is demonstrated. Second, we develop a motion planner based on 'dynamic voxels' in the spatio-temporal domain, enabling the time-to-collision criterion evaluation and the optimal trajectory generation in continuous space. Third, the prediction and planning modules are coupled in a closed-loop and efficient form. Specifically, taking each maneuver as a cluster, representative trajectory primitives are generated for conditional prediction, and conversely, prediction results are used to score the primitives as guidance, which alleviates the duplicated callback of the prediction module. The simulations are conducted in overtaking, merging, unprotected left turns, and also scenarios with imperfect social behaviors. The comparison studies demonstrate the better safety assurance and efficiency of the proposed model, and the ablation experiments further reveal the effectiveness of the new ideas.","2024-10","2025-02-26 20:41:55","2025-02-26 20:41:55","","14973-14985","","10","25","","","","","","","","","","English","","","","WOS:001230780200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","conditional prediction; motion planning; Spatio-temporal; voxel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K7ANW4G3","journalArticle","2024","Zhang, AW; Xu, JP; Liu, ZQ; Zhang, YW","Microstrip Quasi-Elliptic Absorptive Bandpass Filter with Ultra-Wide Reflectionless Range and Compact Size","ELECTRONICS","","2079-9292","10.3390/electronics13101841","","Absorptive bandpass filters (ABPFs) are highly attractive in modern microwave communication systems due to their ability to internally absorb the harmful stopband RF-power reflections. This paper reports an approach to designing quasi-elliptic ABPFs with ultra-wide reflectionless range, enhanced selectivity, and compact size. The method is realized based on a fourth-order quasi-elliptic absorptive lowpass filter (ALPF) prototype with a simplified structure. This ALPF prototype exhibits both good impedance-matching over the whole normalized frequency domain and an adjustable transmission zero close to the passband. By applying an equivalent impedance transformer model, a coupled-line-based ABPF scheme is devised from the ALPF prototype, which eliminates conventional dispersive transmission line inverters, resulting in an ultra-wide reflectionless range and a compact size. Closed-form equations are derived to support the filter synthesis. A 2.45 GHz microstrip ABPF with 30% fractional bandwidth is designed for verification. The measured minimum in-band insertion loss is 0.83 dB and the reflectionless range of return loss better than 10 dB is from DC to 12.88 GHz. Both the upper and lower stopband suppression exceed 20 dB, with the upper stopband extending up to 6.80 GHz. The upper and lower out-of-band roll-off rates are 93.9 and 121.4 dB/GHz, respectively. The overall circuit size is 0.12 lambda g2.","2024-05","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","10","13","","","","","","","","","","English","","","","WOS:001233074600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","absorptive filter; bandpass filter; quasi-elliptic filter; reflectionless range; transmission zero","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YDIIUV6S","journalArticle","2022","Yao, JP; Wang, YJ; Li, XJ; Yuan, C; Cheng, KY","TERQA: Question answering over knowledge graph considering precise dependencies of temporal information on vectors","DISPLAYS","","0141-9382","10.1016/j.displa.2022.102269","","Time questions involve explicit and implicit constraints as well as complex time interval interactions, making them critical criteria for measuring the effect of knowledge base question answering. Although attention to temporal questions has spurred the development of temporal knowledge graphs, existing studies have focused on the simple splicing and fusion of temporal information with question or knowledge base embeddings, losing sight of the hidden interaction features between temporal information and embedded vectors. In this paper, we proposed TERQA, a temporal knowledge base question-answering approach to explore precise spatial de-pendencies between temporal information and embedded vectors. The exploration of the deep dependency be-tween time and embedded vectors was divided into two stages. In the first stage, the Transformer model of depth extraction was employed to extract richer features from questions and the representation was enhanced with temporal information; in the second stage, high-level capsules were adopted to extract the low-level vector features for detailed pose determination, allowing a more precise deep dependency of temporal facts on embedded vectors. We conducted an experiment using two temporal question answering datasets, TempQues-tions and CronQuestions, and the results showed that accuracy for TERQA improved 11.3% from baseline on the dataset TempQuestions with higher annotated information. Additionally, the adapted TERQA also showed varying degrees of improvements over the baseline in the larger but simply annotated dataset CronQuestions.","2022-09","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","74","","","","","","","","","","English","","","","WOS:000833923500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Knowledge graph question answering; Precise dependency; Temporal information enhancement; Temporal knowledge graph","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UHTVW3G3","journalArticle","2022","Harsuko, R; Alkhalifah, TA","StorSeismic: A New Paradigm in Deep Learning for Seismic Processing","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2022.3216660","","Machine learned tasks on seismic data are often trained sequentially and separately, even though they utilize the same features (i.e., geometrical) of the data. We present StorSeismic as a dataset-centric framework for seismic data processing, which consists of neural network (NN) pretraining and fine-tuning procedures. We, specifically, utilize a NN as a preprocessing tool to extract and store seismic data features of a particular dataset for any downstream tasks. After pretraining, the resulting model can be utilized later, through a fine-tuning procedure, to perform different tasks using limited additional training. Used often in natural language processing (NLP) and lately in vision tasks, bidirectional encoder representations from transformer (BERT), a form of a transformer model, provides an optimal platform for this framework. The attention mechanism of BERT, applied here on a sequence of traces within the shot gather, is able to capture and store key geometrical features of the seismic data. We pretrain StorSeismic on field data, along with synthetically generated ones, in the self-supervised step. Then, we use the labeled synthetic data to fine-tune the pretrained network in a supervised fashion to perform various seismic processing tasks, such as denoising, velocity estimation, first arrival picking, and normal moveout (NMO). Finally, the fine-tuned model is used to obtain satisfactory inference results on the field data.","2022","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","60","","","","","","","","","","English","","","","WOS:000880753700025","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;29<br/>Total Times Cited:&nbsp;&nbsp;29<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Bit error rate; Computer architecture; INTERPOLATION; Inversion; machine learning (ML); Machine learning algorithms; Natural language processing; seismic processing; self-supervised learning; Task analysis; Training; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NIYL4S5F","journalArticle","2024","Igarashi, T; Iijima, K; Nitta, K; Chen, Y","Qualitative Analysis of Responses in Estimating Older Adults Cognitive Functioning in Spontaneous Speech: Comparison of Questions Asked by AI Agents and Humans","HEALTHCARE","","2227-9032","10.3390/healthcare12212112","","Background/Objectives: Artificial Intelligence (AI) technology is gaining attention for its potential in cognitive function assessment and intervention. AI robots and agents can offer continuous dialogue with the elderly, helping to prevent social isolation and support cognitive health. Speech-based evaluation methods are promising as they reduce the burden on elderly participants. AI agents could replace human questioners, offering efficient and consistent assessments. However, existing research lacks sufficient comparisons of elderly speech content when interacting with AI versus human partners, and detailed analyses of factors like cognitive function levels and dialogue partner effects on speech elements such as proper nouns and fillers. Methods: This study investigates how elderly individuals' cognitive functions influence their communication patterns with both human and AI conversational partners. A total of 34 older people (12 men and 22 women) living in the community were selected from a silver human resource centre and day service centre in Tokyo. Cognitive function was assessed using the Mini-Mental State Examination (MMSE), and participants engaged in semi-structured daily conversations with both human and AI partners. Results: The study examined the frequency of fillers, proper nouns, and ""listen back"" in conversations with AI and humans. Results showed that participants used more fillers in human conversations, especially those with lower cognitive function. In contrast, proper nouns were used more in AI conversations, particularly by those with higher cognitive function. Participants also asked for explanations more often in AI conversations, especially those with lower cognitive function. These findings highlight differences in conversation patterns based on cognitive function and the conversation partner being either AI or human. Conclusions: These results suggest that there are differences in conversation patterns depending on the cognitive function of the participants and whether the conversation partner is a human or an AI. This study aims to provide new insights into the effective use of AI agents in dialogue with the elderly, contributing to the improvement of elderly welfare.","2024-11","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","21","12","","","","","","","","","","English","","","","WOS:001351128700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","AI agents; Alzheimer's disease; cognitive function estimation; LANGUAGE; natural language processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9YLFBKSS","journalArticle","2025","Wang, YS; Guo, MY; Chen, XM; Ai, DM","Screening of multi deep learning-based de novo molecular generation models and their application for specific target molecular generation","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-025-86840-z","","Traditional virtual screening methods need to explore expanse and vast chemical spaces and need to be based on existing chemical libraries. With the development of deep learning techniques for the de novo generation of molecules, also known as inverse molecular design, the increasingly widespread application of various types of deep learning algorithms has led to revolutionary changes in de novo molecular generation research. In particular, the emergence of a novel natural language processing (NLP) architecture called the transformer has improved the state-of-the-art performance of existing AI technologies. In this study, we modified one top-performing molecular generation model on the basis of the generative pretraining transformer (GPT) architecture in three directions. Moreover, we propose an integrated end-to-end neural network learning framework based on one complete encoder-decoder architecture transformer model: Transfer Text-to-Text Transformer (T5), by learning the embedding vector representation space of conditional molecular properties to encode and guide the vector representation of SMILES sequences, resulting in the output of the final decoder block with a softmax output (maximum likelihood objective). Moreover, we evaluated the performance of these NLP-based generation models and another new model architecture based on a selective state space and selected the best approach jointing a transfer learning strategy for de novo drug discovery to target L858R/T790M/C797S-mutant EGFR in non-small cell lung cancer.","2025-02-05","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","1","15","","","","","","","","","","English","","","","WOS:001415468600021","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","GEGLU; Generative pretraining transformer (GPT); Mamba; NSCLC; RoPE; T5; Transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MQT9MKPY","journalArticle","2025","Chowa, SS; Bhuiyan, MRI; Payel, IJ; Karim, A; Khan, IU; Montaha, S; Hasan, MZ; Jonkman, M; Azam, S","A Low Complexity Efficient Deep Learning Model for Automated Retinal Disease Diagnosis","JOURNAL OF HEALTHCARE INFORMATICS RESEARCH","","2509-4971","10.1007/s41666-024-00182-5","","The identification and early treatment of retinal disease can help to prevent loss of vision. Early diagnosis allows a greater range of treatment options and results in better outcomes. Optical coherence tomography (OCT) is a technology used by ophthalmologists to detect and diagnose certain eye conditions. In this paper, human retinal OCT images are classified into four classes using deep learning. Several image preprocessing techniques are employed to enhance the image quality. An augmentation technique, called generative adversarial network (GAN), is utilized in the Drusen and DME classes to address data imbalance issues, resulting in a total of 130,649 images. A lightweight optimized compact convolutional transformers (OCCT) model is developed by conducting an ablation study on the initial CCT model for categorizing retinal conditions. The proposed OCCT model is compared with two transformer-based models: vision Transformer (ViT) and Swin Transformer. The models are trained and evaluated with 32 x 32 sized images of the GAN-generated enhanced dataset. Additionally, eight transfer learning models are presented with the same input images to compare their performance with the OCCT model. The proposed model's stability is assessed by decreasing the number of training images and evaluating the performance. The OCCT model's accuracy is 97.09%, and it outperforms the two transformer models. The result further indicates that the OCCT model sustains its performance, even if the number of images is reduced.","2025-03","2025-02-26 20:41:55","2025-02-26 20:41:55","","1-40","","1","9","","","","","","","","","","English","","","","WOS:001388965700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","Ablation studies; Compact convolutional transformer (CCT); Generative adversarial network (GAN); Optical coherence tomography (OCT); Retinal disease; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S6X24MXD","journalArticle","2024","Kim, HG; Song, S; Cho, BH; Jang, DP","Deep learning-based stress detection for daily life use using single-channel EEG and GSR in a virtual reality interview paradigm","PLOS ONE","","1932-6203","10.1371/journal.pone.0305864","","This research aims to establish a practical stress detection framework by integrating physiological indicators and deep learning techniques. Utilizing a virtual reality (VR) interview paradigm mirroring real-world scenarios, our focus is on classifying stress states through accessible single-channel electroencephalogram (EEG) and galvanic skin response (GSR) data. Thirty participants underwent stress-inducing VR interviews, with biosignals recorded for deep learning models. Five convolutional neural network (CNN) architectures and one Vision Transformer model, including a multiple-column structure combining EEG and GSR features, showed heightened predictive capabilities and an enhanced area under the receiver operating characteristic curve (AUROC) in stress prediction compared to single-column models. Our experimental protocol effectively elicited stress responses, observed through fluctuations in stress visual analogue scale (VAS), EEG, and GSR metrics. In the single-column architecture, ResNet-152 excelled with a GSR AUROC of 0.944 (+/- 0.027), while the Vision Transformer performed well in EEG, achieving peak AUROC values of 0.886 (+/- 0.069) respectively. Notably, the multiple-column structure, based on ResNet-50, achieved the highest AUROC value of 0.954 (+/- 0.018) in stress classification. Through VR-based simulated interviews, our study induced social stress responses, leading to significant modifications in GSR and EEG measurements. Deep learning models precisely classified stress levels, with the multiple-column strategy demonstrating superiority. Additionally, discreetly placing single-channel EEG measurements behind the ear enhances the convenience and accuracy of stress detection in everyday situations.","2024-07-03","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","7","19","","","","","","","","","","English","","","","WOS:001267636600017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QTIR52Y7","journalArticle","2024","She, JP; Wang, XJ; Liu, FK; Wu, ZG; Hu, HC","Fault prediction of gyrotron system on test bench using a deep learning algorithm","FUSION ENGINEERING AND DESIGN","","0920-3796","10.1016/j.fusengdes.2024.114186","","The gyrotron system is an essential component of the Electron Cyclotron Resonance Heating (ECRH) system, generating high-power millimeter waves that can be utilized for plasma heating and current drive in magnetically confined nuclear fusion. During high-power long-pulse operation, the gyrotron is prone to faults such as arcing, mode jump, and overcurrent, leading to interruptions in continuous system output. These faults not only endanger the safety of the gyrotron but also reduce the overall efficiency and performance of the system. Addressing this issue, we have employed deep learning methods to predict faults that may occur during the gyrotron's long pulse operation. Using experimental data collected from the megawatt-level continuous wave (CW) gyrotron test bench since 2019, we constructed a dataset comprising 52,772 data points, including 23,241 instances of faulty data. We trained a model based on the Transformer encoder architecture and compared its performance against classical CNN and LSTM models. The results demonstrated that the Transformer model exhibited superior performance in this context, achieving an AUC value of 0.869. The True Positive Rate (TPR) and False Positive Rate (FPR) reached 85.2% and 18.2%, respectively. Subsequent offline testing verified that the trained model could successfully predict faults in advance with second-level accuracy, laying the groundwork for future gyrotron operation management. In conclusion, deep learning has demonstrated its potential application in the prediction of operational faults in the gyrotron system.","2024-03","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","200","","","","","","","","","","English","","","","WOS:001171687000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","Deep learning; ECRH system; Fault prediction; Gyrotron system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RGETB8AB","journalArticle","2024","Krepsz, V; Horváth, V; Huszár, A; Neuberger, T; Gyarmathy, D","'Should we laugh?' Acoustic features of (in)voluntary laughters in spontaneous conversations","COGNITIVE PROCESSING","","1612-4782","10.1007/s10339-023-01168-8","","Laughter is one of the most common non-verbal features; however, contrary to the previous assumptions, it may also act as signals of bonding, affection, emotional regulation agreement or empathy (Scott et al. Trends Cogn Sci 18:618-620, 2014). Although previous research agrees that laughter does not form a uniform group in many respects, different types of laughter have been defined differently by individual research. Due to the various definitions of laughter, as well as their different methodologies, the results of the previous examinations were often contradictory. The analysed laughs were often recorded in controlled, artificial situations; however, less is known about laughs from social conversations. Thus, the aim of the present study is to examine the acoustic realisation, as well as the automatic classification of laughter that appear in human interactions according to whether listeners consider them to be voluntary or involuntary. The study consists of three parts using a multi-method approach. Firstly, in the perception task, participants had to decide whether the given laughter seemed to be rather involuntary or voluntary. In the second part of the experiment, those sound samples of laughter were analysed that were considered to be voluntary or involuntary by at least 66.6% of listeners. In the third part, all the sound samples were grouped into the two categories by an automatic classifier. The results showed that listeners were able to distinguish laughter extracted from spontaneous conversation into two different types, as well as the distinction was possible on the basis of the automatic classification. In addition, there were significant differences in acoustic parameters between the two groups of laughter. The results of the research showed that, although the distinction between voluntary and involuntary laughter categories appears based on the analysis of everyday, spontaneous conversations in terms of the perception and acoustic features, there is often an overlap in the acoustic features of voluntary and involuntary laughter. The results will enrich our previous knowledge of laughter and help to describe and explore the diversity of non-verbal vocalisations.","2024-02","2025-02-26 20:41:55","2025-02-26 20:41:55","","89-106","","1","25","","","","","","","","","","English","","","","WOS:001105587600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Laughter; Non-verbal feature; Speech perception; Speech production; Spontaneous speech; Voluntary-involuntary","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5ZNBBLMK","journalArticle","2023","Fusaroli, R; Weed, E; Rocca, R; Fein, D; Naigles, L","Repeat After Me? Both Children With and Without Autism Commonly Align Their Language With That of Their Caregivers","COGNITIVE SCIENCE","","0364-0213","10.1111/cogs.13369","","Linguistic repetitions in children are conceptualized as negative in children with autism - echolalia, without communicative purpose - and positive in typically developing (TD) children - linguistic alignment involved in shared engagement, common ground and language acquisition. To investigate this apparent contradiction we analyzed spontaneous speech in 67 parent-child dyads from a longitudinal corpus (30 minutes of play activities at 6 visits over 2 years). We included 32 children with autism and 35 linguistically matched TD children (mean age at recruitment 32.76 and 20.27 months). We found a small number of exact repetitions in both groups (roughly 1% of utterances across visits), which increased over time in children with autism and decreased in the TD group. Partial repetitions were much more frequent: children reused caregivers' words at high rates regardless of diagnostic group (24% of utterances at first visit), and this increased in frequency (but not level) over time, faster for TD children (at final visit: 33% for autism, 40% for TD). The same happened for partial repetition of syntax and semantic alignment. However, chance alignment (as measured by surrogate pairs) also increased and findings for developmental changes were reliable only for syntactic and semantic alignment. Children with richer linguistic abilities also displayed a higher tendency to partially re-use their caregivers' language (alignment rates and semantic alignment). This highlights that all children commonly re-used the words, syntax, and topics of their caregivers, albeit with some quantitative differences, and that most repetition was at least potentially productive, with repeated language being re-contextualized and integrated with non-repeated language. The salience of echolalia in ASD might be partially explained by slight differences in frequency, amplified by lower semantic alignment, persistence over time, and expectations of echolalia. More in-depth qualitative and quantitative analyses of how repetitions are used and received in context are needed.","2023-11","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","11","47","","","","","","","","","","English","","","","WOS:001093952700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;97</p>","","","ACQUISITION; Autism; COORDINATION; DYNAMICS; Echolalia; IMMEDIATE ECHOLALIA; Individual differences; Language development; LEXICAL ALIGNMENT; Linguistic alignment; REPETITIVE SPEECH; Social interaction; SPECTRUM DISORDER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NFJCLDJC","journalArticle","2022","Rodríguez-Ordóñez, I","The role of frequency in the acquisition of structured variation: The case of Basque ergativity","INTERNATIONAL JOURNAL OF BILINGUALISM","","1367-0069","10.1177/13670069221110401","","Aims and objectives: This study examines the extent to which new speakers use the Basque ergative case marking (-k) in the nominal inflection. I specifically ask whether frequency-based factors (language use and lexical frequency) play a role in its use by also considering speakers' self-claimed Basque identities. Design/methodology/approach: The spontaneous speech of 39 Basque-Spanish bilinguals was collected by means of sociolinguistic interviews. Participants were self-stratified according to categories of Basque speakerhood (euskaldunberri ""new speaker""; euskaldun ""Basque speaker""; euskaldunzahar ""native speaker""). We also considered their proficiency, language use, and sex. Data and analysis: In total, 2,755 tokens were extracted for the presence/absence of ergative -k and coded for the following four linguistic factors: verb type, animacy person and number, phonological context, and type of NP. Lexical frequency was operationalized in terms of overall token frequency of lexical verb. Data were analyzed using mixed-effects models in R. Findings and conclusions: Results indicate that despite higher incidence of ergative omissions among new speakers, they show (1) consistent mastery of core internal constraints (verb type, phonological context) and (2) gradual structuring based on lexical frequency effects. These omissions occur in pragmatically structured conditions (topic shift, emphasis, and introducing self in narrative) alongside extensions of -k to unaccusative contexts (focus and topicalization). No independent effects of language use were found. Originality: This study is the first to examine of Basque ergativity among adult Basque speakers, taking also into account discourse factors, lexical frequency, and speakers' social identities and proficiencies. Significance and implications: First, the mediating effects of lexical frequency are indicative that that sociolinguistic variation is acquired in a piece-meal fashion and that such patterns emerge from discourse as they are used in context. Second, it is argued that the new speakers' kind of social practices hold key in explaining the reallocation of linguistic constraints in their variable production.","2022-10","2025-02-26 20:41:55","2025-02-26 20:41:55","","656-672","","5","26","","","","","","","","","","English","","","","WOS:000827206900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","Basque; BILINGUALISM; ergativity; lexical frequency; new speakers; PRONOUN EXPRESSION; SPANISH; TERM LANGUAGE CONTACT; variation; WELSH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L8FC67BP","journalArticle","2024","Urena, K; Stark, BC","Characterizing iconic gesture during narratives in chronic traumatic brain injury recovery","FRONTIERS IN HUMAN NEUROSCIENCE","","1662-5161","10.3389/fnhum.2024.1393284","","Introduction It is known that co-speech hand gestures increase and supplement speech in individuals with language impairment after brain injury, e.g., post-stroke aphasia. Traumatic Brain Injury (TBI) provides a unique avenue to evaluate gestures as TBI often presents with both anomia (word-finding impairments) and cognitive impairments, resulting in a cognitive-communicative disorder. However, there is a great need for evaluation of gestures in TBI during typical spontaneous speech and across the recovery trajectory (from sub-acute to chronic stages). In a large population (N = 54) of persons with moderate-severe TBI, who were examined at 3 months post-TBI whilst telling a procedural narrative (""how to make a sandwich""), we examined three aims: (1) characterize the extent to which adults with moderate-severe TBI produce iconic gestures; (2) identify the extent to which language impairment relates to iconic gesturing in TBI; and (3) characterize the extent to which iconic gesturing changes across TBI recovery.Methods In a subpopulation (Group 1, N = 14) who were examined at three- and 24-months (sub-acute and substantially chronic), and in a smaller subpopulation (Group 2, N = 6) who had data for five timepoints (three-, six-, nine-, 12-, and 24-months), we used paired tests to examine and characterize longitudinal changes in iconic gesturing.Results The large group analysis suggested that individuals with TBI use iconic gesture during narrative, which take several different iconic forms (e.g., enacting use of an object), and that a minority employed gestures that supplemented (added to, disambiguated, or replaced) speech. The subpopulation analyses suggested that participants did not produce iconic gestures significantly differently across the 2-year recovery timeframe. Case examination of a participant with moderate-severe aphasia suggested a relationship between language impairment and gesture, with this individual producing the highest proportion of supplemental gesturing of the entire group. This finding aligns with research from the post-stroke aphasia field.Discussion Broadly, this study significantly extends prior research on the relationship between gesturing, language, and brain injury.","2024-11-25","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","18","","","","","","","","","","English","","","","WOS:001372207500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;77</p>","","","""iconic gesture""; ""traumatic brain injury""; APHASIA CONVEY; CHILDREN; communication; COMMUNICATION; DISCOURSE; gesture; INFORMATION; language; LANGUAGE; longitudinal; narrative; PEOPLE; SPEAKING; SPEECH INTEGRATION; WORKING-MEMORY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"THANKXCH","journalArticle","2023","Andrade, EIN; Manxhari, C; Smith, KM","Pausing before verb production is associated with mild cognitive impairment in Parkinson's disease","FRONTIERS IN HUMAN NEUROSCIENCE","","1662-5161","10.3389/fnhum.2023.1102024","","BackgroundCognitive dysfunction and communication impairment are common and disabling symptoms in Parkinson's Disease (PD). Action verb deficits occur in PD, but it remains unclear if these impairments are related to motor system dysfunction and/or cognitive decline. The objective of our study was to evaluate relative contributions of cognitive and motor dysfunction to action verb production in naturalistic speech of patients with PD. We proposed that pausing before action-related language is associated with cognitive dysfunction and may serve as a marker of mild cognitive impairment in PD. MethodParticipants with PD (n = 92) were asked to describe the Cookie Theft picture. Speech files were transcribed, segmented into utterances, and verbs classified as action or non-action (auxiliary). We measured silent pauses before verbs and before utterances containing verbs of different classes. Cognitive assessment included Montreal Cognitive Assessment (MoCA) and neuropsychological tests to categorize PD participants as normal cognition (PD-NC) or mild cognitive impairment (PD-MCI) based on Movement Disorders Society (MDS) Task Force Tier II criteria. Motor symptoms were assessed using MDS-UPDRS. We performed Wilcoxon rank sum tests to identify differences in pausing between PD-NC and PD-MCI. Logistic regression models using PD-MCI as dependent variables were used to evaluate the association between pause variables and cognitive status. ResultsParticipants with PD-MCI demonstrated more pausing before and within utterances compared to PD-NC, and the duration of these pauses were correlated with MoCA but not motor severity (MDS-UPDRS). Logistic regression models demonstrated that pauses before action utterances were associated with PD-MCI status, whereas pauses before non-action utterances were not significantly associated with cognitive diagnosis. ConclusionWe characterized pausing patterns in spontaneous speech in PD-MCI, including analysis of pause location with respect to verb class. We identified associations between cognitive status and pausing before utterances containing action verbs. Evaluation of verb-related pauses may be developed into a potentially powerful speech marker tool to detect early cognitive decline in PD and better understand linguistic dysfunction in PD.","2023-04-11","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","17","","","","","","","","","","English","","","","WOS:000973427800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","cognition; COMPREHENSION; DYSARTHRIA; GENERATION; IMPACT; language; MCI (mild cognitive impairment); MOTOR; Parkinson's disease; PAUSES; SPEECH; speech markers; SYNTAX; verb","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"49KDMH2J","journalArticle","2024","Bilel, A","Forecasting agricultures security indices: Evidence from transformers method","JOURNAL OF FORECASTING","","0277-6693","10.1002/for.3113","","In recent years, ensuring food security has become a global concern, necessitating accurate forecasting of agriculture security to aid in policymaking and resource allocation. This article proposes the utilization of transformers, a powerful deep learning technique, for predicting the Agriculture Security Index ( ASI$$ ASI $$). The ASI$$ ASI $$ is a comprehensive metric that evaluates the stability and resilience of agricultural systems. By harnessing the temporal dependencies and complex patterns present in historical ASI$$ ASI $$ data, transformers offer a promising approach for accurate and reliable forecasting. The transformer architecture, renowned for its ability to capture long-range dependencies, is tailored to suit the ASI$$ ASI $$ forecasting task. The model is trained using a combination of supervised learning and attention mechanisms to identify salient features and capture intricate relationships within the data. To evaluate the performance of the proposed method, various evaluation metrics, including mean absolute error, root mean square error, and coefficient of determination, are employed to assess the accuracy, robustness, and generalizability of the transformer-based forecasting approach. The results obtained demonstrate the efficacy of transformers in forecasting the ASI$$ ASI $$, outperforming traditional time series forecasting methods. The transformer model showcases its ability to capture both short-term fluctuations and long-term trends in the ASI$$ ASI $$, allowing policymakers and stakeholders to make informed decisions. Additionally, the study identifies key factors that significantly influence agriculture security, providing valuable insights for proactive intervention and resource allocation.","2024-09","2025-02-26 20:41:55","2025-02-26 20:41:55","","1733-1746","","6","43","","","","","","","","","","English","","","","WOS:001174590400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Agriculture Security Index; deep learning; forecasting; MEDIA; MODEL; NEWS; SENTIMENT; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SLC6ZM58","journalArticle","2022","Dan, YP; Zhu, ZN; Jin, WS; Li, Z","PF-ViT: Parallel and Fast Vision Transformer for Offline Handwritten Chinese Character Recognition","COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE","","1687-5265","10.1155/2022/8255763","","Recently, Vision Transformer (ViT) has been widely used in the field of image recognition. Unfortunately, the ViT model repeatedly stacks 12-layer encoders, resulting in a large number of model computations, many parameters, and slow training speed, making it difficult to deploy on mobile devices. In order to reduce the computational complexity of the model and improve the training speed, a parallel and fast Vision Transformer method for offline handwritten Chinese character recognition is proposed. The method adds parallel branches of the encoder module to the structure of the Vision Transformer model. Parallel modes include two-way parallel, four-way parallel, and seven-way parallel. The original picture is fed to the encoder module after flattening and linear embedding processing operations. The core step in the encoder is the multihead attention mechanism. Multihead self-attention can learn the interdependence between image sequence blocks. In addition, the use of data expansion strategies increases the diversity of data. In the two-way parallel experiment, when the model is 98.1% accurate on the dataset, the number of parameters and the number of FLOPs are 43.11 million and 4.32 G, respectively. Compared with the ViT model, whose parameters and FLOPs are 86 million and 16.8 G, respectively, the two-way parallel model has a 50.1% decrease in parameters and a 34.6% decrease in FLOPs. This method has been demonstrated to effectively reduce the computational complexity of the model while indirectly improving image recognition speed.","2022-09-28","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","2022","","","","","","","","","","English","","","","WOS:000869058500012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G3E2F4LW","journalArticle","2022","Mombello, EE","New Compact White-Box Transformer Model for the Calculation of Electromagnetic Transients","IEEE TRANSACTIONS ON POWER DELIVERY","","0885-8977","10.1109/TPWRD.2021.3119272","","In a recent work, a successful power transformer white-box model for the calculation of electromagnetic transients has been presented. Although this model gives very satisfactory results, when applied to large transformers it requires a large number of auxiliary loops to model the damping. This can be problematic as it not only requires more computational effort, but the size of the input data may even preclude its use with ATP-EMTP and perhaps with other EMTP-based software that have limitations in this regard. In this work a new reduced model which enables its use with ATP-EMTP is presented. This model requires a much smaller number of circuit components than the original model, which allows the data size and simulation time to be substantially reduced without practically affecting the calculation results. This has been achieved through the reduction of the rank of the sub-matrices that characterize the inductive coupling between the main winding sections and the auxiliary loops used to model the damping. The new model has been validated by making comparisons of the frequency responses calculated using the new compact model with the ones calculated with the original model developed for the case study used by the CIGRE JWG A2/C4.52 to test the accuracy of various types of transformer models.","2022-08","2025-02-26 20:41:55","2025-02-26 20:41:55","","2921-2931","","4","37","","","","","","","","","","English","","","","WOS:000846890500052","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","Damping; damping modeling; Impedance; Inductance; Integrated circuit modeling; Mathematical models; model reduction; power system transients; Power transformers; Transformers; white-box models; Windings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FA54KWNZ","journalArticle","2021","Qiu, L; Li, S; Sung, Y","DBTMPE: Deep Bidirectional Transformers-Based Masked Predictive Encoder Approach for Music Genre Classification","MATHEMATICS","","2227-7390","10.3390/math9050530","","Music is a type of time-series data. As the size of the data increases, it is a challenge to build robust music genre classification systems from massive amounts of music data. Robust systems require large amounts of labeled music data, which necessitates time- and labor-intensive data-labeling efforts and expert knowledge. This paper proposes a musical instrument digital interface (MIDI) preprocessing method, Pitch to Vector (Pitch2vec), and a deep bidirectional transformers-based masked predictive encoder (MPE) method for music genre classification. The MIDI files are considered as input. MIDI files are converted to the vector sequence by Pitch2vec before being input into the MPE. By unsupervised learning, the MPE based on deep bidirectional transformers is designed to extract bidirectional representations automatically, which are musicological insight. In contrast to other deep-learning models, such as recurrent neural network (RNN)-based models, the MPE method enables parallelization over time-steps, leading to faster training. To evaluate the performance of the proposed method, experiments were conducted on the Lakh MIDI music dataset. During MPE training, approximately 400,000 MIDI segments were utilized for the MPE, for which the recovery accuracy rate reached 97%. In the music genre classification task, the accuracy rate and other indicators of the proposed method were more than 94%. The experimental results indicate that the proposed method improves classification performance compared with state-of-the-art models.","2021-03","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","5","9","","","","","","","","","","English","","","","WOS:000628363600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;20<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","MIDI; music genre classification; transformer model; unsupervised learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H6A5JXPY","journalArticle","2024","Fontan, L; Prince, T; Nowakowska, A; Sahraoui, H; Martinez-Ferreiro, S","Automatically measuring speech fluency in people with aphasia: first achievements using read-speech data","APHASIOLOGY","","0268-7038","10.1080/02687038.2023.2244728","","BackgroundSpeech and language pathologists (SLPs) often rely on judgements of speech fluency for diagnosing or monitoring patients with aphasia. However, such subjective methods have been criticised for their lack of reliability and their clinical cost in terms of time.AimsThis study aims at assessing the relevance of a signal-processing algorithm, initially developed in the field of language acquisition, for the automatic measurement of speech fluency in people with aphasia (PWA).Methods & ProceduresTwenty-nine PWA and five control participants were recruited via non-profit organizations and SLP networks. All participants were recorded while reading out loud a set of sentences taken from the French version of the Boston Diagnostic Aphasia Examination. Three trained SLPs assessed the fluency of each sentence on a five-point qualitative scale. A forward-backward divergence segmentation and a clustering algorithm were used to compute, for each sentence, four automatic predictors of speech fluency: pseudo-syllable rate, speech ratio, rate of silent breaks, and standard deviation of pseudo-syllable length. The four predictors were finally combined into multivariate regression models (a multiple linear regression - MLR, and two non-linear models) to predict the average SLP ratings of speech fluency, using a leave-one-speaker-out validation scheme.Outcomes & ResultsAll models achieved accurate predictions of speech fluency ratings, with average root-mean-square errors as low as 0.5. The MLR yielded a correlation coefficient of 0.87 with reference ratings at the sentence level, and of 0.93 when aggregating the data for each participant. The inclusion of an additional predictor sensitive to repetitions improved further the predictions with a correlation coefficient of 0.91 at the sentence level, and of 0.96 at the participant level.ConclusionsThe algorithms used in this study can constitute a cost-effective and reliable tool for the assessment of the speech fluency of patients with aphasia in read-aloud tasks. Perspectives for the assessment of spontaneous speech are discussed.","2024-05-03","2025-02-26 20:41:55","2025-02-26 20:41:55","","939-956","","5","38","","","","","","","","","","English","","","","WOS:001043569900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","2ND-LANGUAGE LEARNERS FLUENCY; aphasia; automatic assessment; JAPANESE LEARNERS; QUANTITATIVE ASSESSMENT; RECOGNITION; speech fluency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZSA65MJJ","journalArticle","2024","Shang, JL; Yu, JB","A residual autoencoder-based transformer for fault detection of multivariate processes","APPLIED SOFT COMPUTING","","1568-4946","10.1016/j.asoc.2024.111896","","The complexity of high-dimensional and noisy process signals reduces the effectiveness of conventional fault detection methods in industrial processes. Based on the hypothesis that data collected from normal and faulty processes has different characteristics, unsupervised deep neural networks, e.g., autoencoders, have been widely applied in process fault detection and achieved good performance. Many variants have been proposed to improve feature learning by combining different network structures. In this paper, a new transformer model, residual autoencoder-based transformer, is proposed for process fault detection. Firstly, autoencoder and transformer are integrated for better unsupervised feature learning of process signals. Secondly, linear embedding and attention mechanisms with bias are proposed to generate effective features from process signals. Finally, residual connections are constructed between the encoder and decoder of RATransformer to address overfitting in training. Four industrial cases are used to test the performance of RATransformer for process fault detection. The results show that the fault detection rate of RATransformer is at least 1 % higher than other comparison methods. Moreover, the testing results show that the model structure improves the fault detection performance of RATransformer. The complex models like RATransformer can be used in the industrial process when sufficient normal process data is available. An end-to-end training method can be further developed to improve the applicability of RATransformer in process fault detection in the future.","2024-09","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","163","","","","","","","","","","English","","","","WOS:001264310800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Autoencoder; DIAGNOSIS; Feature learning; Industrial process; Process fault detection; Residual learning; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C6N9Y8PL","journalArticle","2023","Daud, MM; Abualqumssan, A; Rashid, F'N; Saad, MHM; Zaki, WMDW; Satar, NSM","Durian Disease Classification using Vision Transformer for Cutting-Edge Disease Control","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","durian fruit holds a prominent position as a beloved fruit not only in ASEAN countries but also in European nations. Its significant potential for contributing to economic growth in the agricultural sector is undeniable. However, the prevalence of durian leaf diseases in various ASEAN countries, including Malaysia, Indonesia, the Philippines, and Thailand, presents formidable challenges. Traditionally, the identification of these leaf diseases has relied on manual visual inspection, a laborious and time-consuming process. In response to this challenge, an innovative approach is presented for the classification and recognition of durian leaf diseases, delves into cutting-edge disease control strategies using vision transformer. The diseases include the classes of leaf spot, blight sport, algal leaf spot and healthy class. Our methodology incorporates the utilization of well-established deep learning models, specifically vision transformer model, with meticulous fine-tuning of hyperparameters such as epochs, optimizers, and maximum learning rates. Notably, our research demonstrates an outstanding achievement: vision transformer attains an impressive accuracy rate of 94.12% through the hyperparameter of the Adam optimizer with a maximum learning rate of 0.001. This work not only provides a robust solution for durian disease control but also showcases the potential of advanced deep learning techniques in agricultural practices. Our work contributes to the broader field of precision agriculture and underscores the critical role of technology in securing the future of durian farming.","2023-12","2025-02-26 20:41:55","2025-02-26 20:41:55","","446-452","","12","14","","","","","","","","","","English","","","","WOS:001244766300015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","-Vision transformer; deep learning; disease control; durian disease","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y6BQY4GE","journalArticle","2023","Qian, J; Pu, N; Qian, L; Xue, XB; Bi, YH; Norra, S","Identification of driving factors of algal growth in the South-to-North Water Diversion Project by Transformer-based deep learning","WATER BIOLOGY AND SECURITY","","2097-4132","10.1016/j.watbs.2023.100184","","Accurate and credible identification of the drivers of algal growth is essential for sustainable utilization and scientific management of freshwater. In this study, we developed a deep learning-based Transformer model, named Bloomformer-1, for end-to-end identification of the drivers of algal growth without the needing extensive a priori knowledge or prior experiments. The Middle Route of the South-to-North Water Diversion Project (MRP) was used as the study site to demonstrate that Bloomformer-1 exhibited more robust performance (with the highest R2, 0.80 to 0.94, and the lowest RMSE, 0.22-0.43 mu g/L) compared to four widely used traditional machine learning models, namely extra trees regression (ETR), gradient boosting regression tree (GBRT), support vector regression (SVR), and multiple linear regression (MLR). In addition, Bloomformer-1 had higher interpretability (including higher transferability and understandability) than the four traditional machine learning models, which meant that it was trustworthy and the results could be directly applied to real scenarios. Finally, it was determined that total phosphorus (TP) was the most important driver for the MRP, especially in Henan section of the canal, although total nitrogen (TN) had the highest effect on algal growth in the Hebei section. Based on these results, phosphorus loading controlling in the whole MRP was proposed as an algal control strategy.","2023-07","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","3","2","","","","","","","","","","English","","","","WOS:001129893300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Algal growth; CHLOROPHYLL-A; Deep learning; Driving factor determination; FRESH-WATER; Model interpretability; PHYTOPLANKTON; RIVER; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SBVA9Z9M","journalArticle","2023","Alassi, A; Feng, ZW; Ahmed, K; Syed, M; Egea-Alvarez, A; Foote, C","Grid-forming VSM control for black-start applications with experimental PHiL validation","INTERNATIONAL JOURNAL OF ELECTRICAL POWER & ENERGY SYSTEMS","","0142-0615","10.1016/j.ijepes.2023.109119","","The rising penetration of power converters interfaced generation into the electrical grid is leading to a paradigm shift where distributed resources are expected to provide ancillary services. The voltage-source behavior of grid -forming converter (GFC) makes it an attractive black-start provision alternative. This paper thus proposes a modified grid-forming virtual synchronous machine (VSM) control that is tailored for black-start applications. Voltage and power loops in the proposed controller are modified to provide soft energization to mitigate transformers inrush current, in addition to improved voltage support for the restored AC network and a smooth synchronization with neighboring islands or the main grid after a black-start event. The VSM control perfor-mance is first validated through simulations. Then, Power Hardware-in-the-Loop (PHiL) technique is used to validate the ability of a hardware GFC equipped with the modified VSM controller to restore a simulated network in a digital real-time simulator (DRTS) platform. Current-type Ideal Transformer Model (I-ITM) interface tech-nique is successfully used in the experiment with time-delay impact compensation in the synchronous dq0 frame. The novel presented PHiL demonstration in this paper paves the way for similar testing of industrial GFCs for black-start and ancillary services provision under flexible network restoration conditions and complexity.","2023-09","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","151","","","","","","","","","","English","","","","WOS:000984898700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Black-start; CONVERTERS; DESIGN; Grid synchronization; Grid-forming converter; INRUSH CURRENT REDUCTION; INTERFACE ALGORITHM; INVERTERS; POWER; Power hardware-in-the-loop; SIMULATION; SYNCHRONIZATION; Virtual synchronous machine","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P7EBI2M4","journalArticle","2023","Abebe, E; Kebede, H; Kevin, M; Demissie, Z","Earthquakes magnitude prediction using deep learning for the Horn of Africa","SOIL DYNAMICS AND EARTHQUAKE ENGINEERING","","0267-7261","10.1016/j.soildyn.2023.107913","","Earthquakes are vibrations of the Earth's surface that can cause ground shaking, fires, tsunamis, landslides and fissures. These natural phenomena can cause destruction and kill lives. When there is a possibility of an earth-quake, an accurate prediction can save lives and avoid infrastructure damage. Due to the probabilistic nature of an earthquake occurring and the challenge of achieving an efficient and dependable model for an earthquake prediction, efforts to predict earthquakes have been met with mixed results. Therefore, new methods are constantly sought. A deep learning-based technique, specifically a transformer algorithm, was applied to predict earthquake magnitudes using available data for the Horn of Africa. The problem was formulated as multi-variant time series regression, and predictions were made for earthquakes magnitudes greater than or equal to 3 for the next three months. A comparison of the results was made with the output obtained from long short-term memory (LSTM), bidirectional long short-term memory (BILSTM), and bidirectional long short-term memory with attention (BILSTM-AT) models. The results showed that the transformer model outperformed the other three models with 0.276, 0.147, 0.383, 28.868% mean absolute error (MAE), mean squared error (MSE), root mean squared error (RMSE) and mean absolute percentage error (MAPE) respectively in predicting earthquake mag-nitudes in the Horn of Africa.","2023-07","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","170","","","","","","","","","","English","","","","WOS:000963921300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","Baseline models; Earthquake prediction; Horn of Africa; Performance metrics; Time series prediction; Transformer deep learning algorithm","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VE8XAHTT","journalArticle","2023","Alamri, F; Dutta, A","Implicit and explicit attention mechanisms for zero-shot learning","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2023.03.009","","Zero-Shot Learning (ZSL) aims to recognise unseen object classes which are not observed during the training phase. Most of the existing methods on ZSL focus on learning a compatibility function between the image representation and class semantic information. Few others concentrate on learning image representation by combining local and global features. However, the existing approaches still fail to address the bias issue towards the seen classes. This paper proposes implicit and explicit attention mechanisms to address the existing bias problem in generalised ZSL models. We formulate the implicit attention mechanism with a self-supervised image angle rotation task, which focuses on specific image features aiding in solving the task. On the other hand, the explicit attention mechanism is composed via the consideration of a multi-headed self-attention mechanism in the Vision Transformer model, which learns to attend important image locations and map global image features to semantic space during the training stage. We have conducted comprehensive experiments on three popular benchmarks: AWA2, CUB and SUN, where the effectiveness of our proposed attention mechanisms is shown in both discriminative and generative settings. Our extensive experiments show that our method has achieved state-of-the-art performance obtaining the highest harmonic mean on all three datasets, which is very encouraging to consider the ViT-based attention mechanisms for ZSL tasks in the future.(c) 2023 Elsevier B.V. All rights reserved.","2023-05-14","2025-02-26 20:41:55","2025-02-26 20:41:55","","55-66","","","534","","","","","","","","","","English","","","","WOS:000972613000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","Attention mechanism; Self -supervised learning; TRANSFORMER; Vision transformer; Zero -shot learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N94BUQS5","journalArticle","2023","Lin, P; Yan, YM; Huang, SY","DeepHomo2.0: improved protein-protein contact prediction of homodimers by transformer -enhanced deep learning","BRIEFINGS IN BIOINFORMATICS","","1467-5463","10.1093/bib/bbac499","","Protein-protein interactions play an important role in many biological processes. However, although structure prediction for monomer proteins has achieved great progress with the advent of advanced deep learning algorithms like AlphaFold, the structure prediction for protein-protein complexes remains an open question. Taking advantage of the Transformer model of ESM-MSA, we have developed a deep learning -based model, named DeepHomo2.0, to predict protein-protein interactions of homodimeric complexes by leveraging the direct-coupling analysis (DCA) and Transformer features of sequences and the structure features of monomers. DeepHomo2.0 was extensively evaluated on diverse test sets and compared with eight state-of-the-art methods including protein language model based, DCA-based and machine learning -based methods. It was shown that DeepHomo2.0 achieved a high precision of >70% with experimental monomer structures and >60% with predicted monomer structures for the top 10 predicted contacts on the test sets and outperformed the other eight methods. Moreover, even the version without using structure information, named DeepHomoSeq, still achieved a good precision of >55% for the top 10 predicted contacts. Integrating the predicted contacts into protein docking significantly improved the structure prediction of realistic Critical Assessment of Protein Structure Prediction homodimeric complexes. DeepHomo2.0 and DeepHomoSeq are available at http://huanglab.phys.hust.edu.cn/DeepHomo2/.","2023","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","1","24","","","","","","","","","","English","","","","WOS:000892395600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;82</p>","","","COEVOLUTION; CRYO-EM; deep learning; DOCKING; homo-oligomers; IDENTIFICATION; PRINCIPLES; protein-protein interaction; RESIDUE CONTACTS; residue-residue contact prediction; SYMMETRY; transformer features","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q86WWY2D","journalArticle","2023","Qin, Y; Xie, HM; Ding, SX; Tan, BY; Li, YJ; Zhao, B; Ye, M","Bar transformer: a hierarchical model for learning long-term structure and generating impressive pop music","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-022-04049-3","","Recently many deep learning-based automatic music generation models have been proposed. How to generate long pieces of pop music with distinctive musical characteristics remains a challenging problem, as it relies heavily on musical structures. Some transformer-based models take advantage of self-attention for generating long-sequence music; however, most pay little attention to well-organized musical structures. In this article, we propose a novel note-to-bar hierarchical model named the Bar Transformer to address long-term dependency issues and generate impressive and structurally meaningful music. In particular, we propose a novel note-to-bar approach that pre-processes the notes within each individual bar to provide a strong structural constraint to increase our model's awareness of the note-to-bar structure in music. The Bar Transformer is constructed using an encoder-decoder framework, including a two-layer encoder and an arrangement decoder. In the two-layer encoder, the bottom is a note-level encoder, which outputs embeddings by learning the relation between notes within an individual bar, and the top is a bar-level encoder, which uses these embeddings to encode each bar from the melody and chord. The decoder is an arrangement decoder used to generalize the interrelationships among the bars and simultaneously generate melodies and chords. The experimental results of the structural analysis and the aural evaluations demonstrate that our approach outperforms the Music Transformer model and other regressive models used for music generation.","2023-05","2025-02-26 20:41:55","2025-02-26 20:41:55","","10130-10148","","9","53","","","","","","","","","","English","","","","WOS:000840620400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Hierarchical; Impressive; Long-term structure; Music generation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IDWJJPT7","journalArticle","2021","Roy, A; Saffar, M; Vaswani, A; Grangier, D","Efficient Content-Based Sparse Attention with Routing Transformers","TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS","","2307-387X","10.1162/tacl_a_00353","","Self-attention has recently been adopted for a wide range of sequence modeling problems. Despite its effectiveness, self-attention suffers from quadratic computation and memory requirements with respect to sequence length. Successful approaches to reduce this complexity focused on attending to local sliding windows or a small set of locations independent of content. Our work proposes to learn dynamic sparse attention patterns that avoid allocating computation and memory to attend to content unrelated to the query of interest. This work builds upon two lines of research: It combines the modeling flexibility of prior work on content-based sparse attention with the efficiency gains from approaches based on local, temporal sparse attention. Our model, the Routing Transformer, endows self-attention with a sparse routing module based on online k-means while reducing the overall complexity of attention to O(n(1.5)d) from O(n(2)d) for sequence length n and hidden dimension d. We show that our model outperforms comparable sparse attention models on language modeling on Wikitext-103 (15.8 vs 18.3 perplexity), as well as on image generation on ImageNet-64 (3.43 vs 3.44 bits/dim) while using fewer self-attention layers. Additionally, we set a new state-of-the-art on the newly released PG-19 data-set, obtaining a test perplexity of 33.2 with a 22 layer Routing Transformer model trained on sequences of length 8192. We open-source the code for Routing Transformer in Tensorflow.(1)","2021","2025-02-26 20:41:55","2025-02-26 20:41:55","","53-68","","","9","","","","","","","","","","English","","","","WOS:000751952200004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;209<br/>Total Times Cited:&nbsp;&nbsp;218<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"97QRGD9M","journalArticle","2024","Bacevic, J","No Such Thing as Free Speech? Performativity, Free Speech, and Academic Freedom in the UK","LAW AND CRITIQUE","","0957-8536","10.1007/s10978-023-09373-2","","The relationship between academic freedom and freedom of speech features prominently in public and political discussions concerning the role of universities in Western liberal democracies. Recently, these debates have attracted increased attention, owing in part to media framing of a 'free speech crisis', especially in UK and US universities. One type of response is to regulate academic expression through legislation, such as the UK's 2023 Higher Education (Freedom of Speech) Act. This article offers a critical analysis of the assumptions concerning the performativity of speech in this kind of legal intervention. It extends Judith Butler's discussion of the concept of 'harmful speech' as reported by Butler (Excitable speech: a politics of the performative, Routledge Classics, London, 1997) to conceptualize speech-acts as performative not only when it comes to populations, but also when it comes to institutions. Reconceptualizing universities as producing as well as being constituted by speech-acts, the article argues that the effects of free speech legislation need to be considered in the context of the transformation of universities and other political actors (including governments and student unions) in the second half of the twentieth and the beginning of the twenty-first century. It argues that legal enforcement of free speech at universities further obscures the distinction between negative and positive liberties identified by Isaiah Berlin (Two Concepts of Liberty, Oxford University Press, Oxford, 1958), and considers this shift as part of the reconfiguration of political ontology in late modernity.","2024-01-17","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","","","","","","","","","","","English","","","","WOS:001142904000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","Academic freedom; Austin; Free speech; No-platforming; PERSPECTIVE; POWER; Speech-acts; Universities","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MSHKKACB","journalArticle","2025","Sellappan, S; Sethuraman, R; Subbaraj, S; Shunmugiah, J","Efficient Data Communication in SIoT: Hybrid Channel Attention Recurrent Transformer-Based Adaptive Marine Predator Algorithm for Reduced Energy Consumption","INTERNATIONAL JOURNAL OF COMMUNICATION SYSTEMS","","1074-5351","10.1002/dac.70022","","The rapid development of technologies has attracted significant attention, with the social web and big data becoming key drivers of modern innovation. Although big data in the Social Internet of Things presents various energy-saving merits, problems such as network congestion and data communication reliability occur. In this article, a hybrid channel attention recurrent transformer-based adaptive marine predator algorithm is introduced to solve these problems. The main purpose of this approach is to improve the robustness and performance of SIoT systems. The hybrid channel attention recurrent transformer-based adaptive marine predator algorithm combines a hybrid recurrent neural network, a channel attention mechanism, and a transformer classifier. In this work, four datasets, including the water treatment plant, GPS trajectories, hepatitis dataset, and Twitter for sentiment analysis in Arabic are employed in validating the performance of a proposed model. The Savitzky-Golay filter is applied to reduce noise and eliminate unnecessary or irrelevant data. After data pre-processing, the hybrid channel attention recurrent transformer-based adaptive marine predator was introduced for classification, and this model is fine-tuned by the adaptive marine predator algorithm. In addition, the proposed model demonstrates strong scalability and applicability in real-world applications, making it an ideal solution for future Social Internet of Things systems.","2025-03-25","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","5","38","","","","","","","","","","English","","","","WOS:001423779100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","adaptive marine predator algorithm; ATTACKS; channel attention mechanism Savitzky-Golay filter; hybrid recurrent neural network; intelligent systems; network congestion; social internet of things; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YB2VDJH8","journalArticle","2025","Sun, YZ; Pang, SC; Li, HX; Qiao, SB; Zhang, YG","Enhanced Lithology Classification Using an Interpretable SHAP Model Integrating Semi-Supervised Contrastive Learning and Transformer with Well Logging Data","NATURAL RESOURCES RESEARCH","","1520-7439","10.1007/s11053-024-10452-z","","In petroleum and natural gas exploration, lithology identification-analyzing rock types beneath the Earth's surface-is crucial for assessing hydrocarbon reservoirs and optimizing drilling strategies. Traditionally, this process relies on logging data such as gamma rays and resistivity, which often require manual interpretation, making it labor-intensive and prone to errors. To address these challenges, we propose a novel machine learning framework-contrastive learning-transformer-leveraging self-attention mechanisms to enhance the accuracy of lithology identification. Our method first extracts unlabeled samples from logging data while obtaining labeled core sample data. Through self-supervised contrastive learning and a transformer backbone network, we optimize performance using techniques like batch normalization. After pretraining, the model is fine-tuned with a limited number of labeled samples to improve accuracy and significantly reduce reliance on large labeled datasets, thereby lowering the costs associated with drilling core annotations. Additionally, our research incorporates shapley additive explanations (SHAP) technology to enhance the transparency of the model's decision-making process, facilitating the analysis of the contribution of each feature to lithology predictions. The model also learns time-reversal invariance by reversing sequential data, ensuring reliable identification even with variations in data sequences. Experimental results demonstrate that our transformer model, combined with semi-supervised contrastive learning, significantly outperforms traditional methods, achieving more precise lithology identification, especially in complex geological environments.","2025-01-17","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","","","","","","","","","","","English","","","","WOS:001399404800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Contrastive learning; Lithology prediction; Logging parameters; Machine learning; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CWQFB9KU","journalArticle","2024","Li, Y; Liu, YF","HPE Transformer: Learning to Optimize Multi-Group Multicast Beamforming Under Nonconvex QoS Constraints","IEEE TRANSACTIONS ON COMMUNICATIONS","","0090-6778","10.1109/TCOMM.2024.3385919","","This paper studies the quality-of-service (QoS) constrained multi-group multicast beamforming design problem, where each multicast group is composed of a number of users requiring the same content. Due to the nonconvex QoS constraints, this problem is nonconvex and NP-hard. While existing optimization-based iterative algorithms can obtain a suboptimal solution, their iterative nature results in large computational complexity and delay. To facilitate real-time implementations, this paper proposes a deep learning-based approach, which consists of a beamforming structure assisted problem transformation and a customized neural network architecture named hierarchical permutation equivariance (HPE) transformer. The proposed HPE transformer is proved to be permutation equivariant with respect to the users within each multicast group, and also permutation equivariant with respect to different multicast groups. Simulation results demonstrate that the proposed HPE transformer outperforms state-of-the-art optimization-based and deep learning-based approaches for multi-group multicast beamforming design in terms of the total transmit power, the constraint violation, and the computational time. In addition, the proposed HPE transformer achieves pretty good generalization performance on different numbers of users, different numbers of multicast groups, and different signal-to-interference-plus-noise ratio targets.","2024-09","2025-02-26 20:41:55","2025-02-26 20:41:55","","5581-5594","","9","72","","","","","","","","","","English","","","","WOS:001319557300035","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","ALLOCATION; APPROXIMATION BOUNDS; Array signal processing; BACKHAUL; hierarchical permutation equivariance (HPE); Multi-group multicast beamforming; neural networks; NEURAL-NETWORKS; NONORTHOGONAL MULTICAST; Quality of service; quality-of-service (QoS) constraints; Real-time systems; self-attention mechanism; Training; transformer model; Transformers; UNICAST TRANSMISSION; Vectors; Wireless communication","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E9CKLWQ2","journalArticle","2024","Xu, ZF; Chen, ZW; Yang, L; Zhang, SY","State of health estimation for lithium-ion batteries based on incremental capacity analysis and Transformer modeling","APPLIED SOFT COMPUTING","","1568-4946","10.1016/j.asoc.2024.112072","","As an important performance indicator of battery management systems, lithium-ion battery state of health (SOH) information is crucial to ensure battery safety and extend battery lifetime. Aiming at the problems of feature extraction difficulty, low accuracy of long-term prediction, and poor parallel computing capability of general data-driven methods, this paper proposes a SOH estimation method for lithium-ion batteries based on incremental capacity analysis (ICA) and Transformer. First, the original incremental capacity (IC) curve of the battery is extracted based on the ICA method, and the original IC curve is processed using the dual filtering method of moving average smoothing filter plus Gaussian smoothing filter, which in turn extracts the peak features of the curve. Then, the Transformer network model based on the multi-head attention mechanism is built. Finally, the extracted peak features of the IC curve are used as model inputs, and the Transformer model is utilized to realize the SOH estimation of lithium-ion batteries. In this paper, experiments based on different input features, prediction starting points, and ambient temperatures are conducted using experimental data of lithium-ion batteries from three sources and analyzed in comparison with commonly used machine learning methods. The experimental results show that the SOH estimation method proposed in this paper has higher long-term prediction accuracy and better temperature adaptability than commonly used machine learning methods.","2024-11","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","165","","","","","","","","","","English","","","","WOS:001295088700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","ATTENTION; Incremental capacity analysis; Lithium-ion battery; Multi-head attention mechanism; State of health estimation; Transformer; USEFUL LIFE ESTIMATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XQ93DEQS","journalArticle","2024","Wang, JJ; Huang, JX; Tu, XH; Wang, JM; Huang, AJ; Laskar, MTR; Bhuiyan, A","Utilizing BERT for Information Retrieval: Survey, Applications, Resources, and Challenges","ACM COMPUTING SURVEYS","","0360-0300","10.1145/3648471","","Recent years have witnessed a substantial increase in the use of deep learning to solve various natural language processing (NLP) problems. Early deep learning models were constrained by their sequential or unidirectional nature, such that they struggled to capture the contextual relationships across text inputs. The introduction of bidirectional encoder representations from transformers (BERT) leads to a robust encoder for the transformer model that can understand the broader context and deliver state-of-the-art performance across various NLP tasks. This has inspired researchers and practitioners to apply BERT to practical problems, such as information retrieval (IR). A survey that focuses on a comprehensive analysis of prevalent approaches that apply pretrained transformer encoders like BERT to IR can thus be useful for academia and the industry. In light of this, we revisit a variety of BERT-based methods in this survey, cover a wide range of techniques of IR, and group them into six high-level categories: (i) handling long documents, (ii) integrating semantic information, (iii) balancing effectiveness and efficiency, (iv) predicting the weights of terms, (v) query expansion, and (vi) document expansion. We also provide links to resources, including datasets and toolkits, for BERT-based IR systems. Additionally, we highlight the advantages of employing encoder-based BERT models in contrast to recent large language models like ChatGPT, which are decoder-based and demand extensive computational resources. Finally, we summarize the comprehensive outcomes of the survey and suggest directions for future research in the area.","2024-07","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","7","56","","","","","","","","","","English","","","","WOS:001208811000024","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;155</p>","","","artificial intelligence; BERT; information retrieval; natural language processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AI9NNW8T","journalArticle","2024","Yan, J; Lin, T; Zhao, S","Migration Learning and Multi-View Training for Low-Resource Machine Translation","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","This paper discusses the main challenges and solution strategies of low-resource machine translation, and proposes a novel translation method combining migration learning and multi-view training. In a low-resource environment, neural machine translation models are prone to problems such as insufficient generalization performance, inaccurate translation of long sentences, difficulty in processing unregistered words, and inaccurate translation of domain-specific terms due to their heavy reliance on massively parallel corpora. Migration learning gradually adapts to the translation tasks of low-resource languages in the process of fine-tuning by borrowing the general translation knowledge of high-resource languages and utilizing pre-training models such as BERT, XLM-R, and so on. Multiperspective training, on the other hand, emphasizes the integration of source and target language features from multiple levels, such as word level, syntax and semantics, in order to enhance the model's comprehension and translation ability under limited data conditions. In the experiments, the study designed an experimental scheme containing pre-training model selection, multi-perspective feature construction, and migration learning and multi-perspective fusion, and compared the performance with randomly initialized Transformer model, pre-training-only model, and traditional statistical machine translation model. The experiments demonstrate that the model with multi-view training strategy significantly outperforms the baseline model in evaluation metrics such as BLEU, TER, and ChrF, and exhibits stronger robustness and accuracy in processing complex language structures and domain-specific terminology.","2024-05","2025-02-26 20:41:55","2025-02-26 20:41:55","","719-728","","5","15","","","","","","","","","","English","","","","WOS:001343952700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","continual pretraining; Low-resource machine translation; migration learning; multi-view training; multidimensional linguistic feature integration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FW5VE9XQ","journalArticle","2024","Yao, XZ; Li, TW; Ding, P; Wang, F; Zhao, L; Gong, AM; Nan, WY; Fu, YF","Emotion Classification Based on Transformer and CNN for EEG Spatial-Temporal Feature Learning","BRAIN SCIENCES","","2076-3425","10.3390/brainsci14030268","","Objectives: The temporal and spatial information of electroencephalogram (EEG) signals is crucial for recognizing features in emotion classification models, but it excessively relies on manual feature extraction. The transformer model has the capability of performing automatic feature extraction; however, its potential has not been fully explored in the classification of emotion-related EEG signals. To address these challenges, the present study proposes a novel model based on transformer and convolutional neural networks (TCNN) for EEG spatial-temporal (EEG ST) feature learning to automatic emotion classification. Methods: The proposed EEG ST-TCNN model utilizes position encoding (PE) and multi-head attention to perceive channel positions and timing information in EEG signals. Two parallel transformer encoders in the model are used to extract spatial and temporal features from emotion-related EEG signals, and a CNN is used to aggregate the EEG's spatial and temporal features, which are subsequently classified using Softmax. Results: The proposed EEG ST-TCNN model achieved an accuracy of 96.67% on the SEED dataset and accuracies of 95.73%, 96.95%, and 96.34% for the arousal-valence, arousal, and valence dimensions, respectively, for the DEAP dataset. Conclusions: The results demonstrate the effectiveness of the proposed ST-TCNN model, with superior performance in emotion classification compared to recent relevant studies. Significance: The proposed EEG ST-TCNN model has the potential to be used for EEG-based automatic emotion recognition.","2024-03","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","3","14","","","","","","","","","","English","","","","WOS:001191808600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","CNN; EEG; emotion classification; multi-head attention; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RXMQ3WUV","journalArticle","2023","Liang, HR; Wang, HQ; Mao, L; Liu, R; Wang, Z; Wang, K","Bone Stick Image Classification Study Based on C3CA Attention Mechanism Enhanced Deep Cascade Network","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3310472","","A large number of bone stick cultural relics have been unearthed in Weiyang Palace of Han Period Chang'an City, Xi'an City, Shaanxi Province, China. Utilizing deep learning-based image classification methods can improve the efficiency of categorizing bone stick fracture locations and colors. However, due to factors such as variations in surface texture features and different degrees of wear on the bone sticks, the classification accuracy of the model is low. To address this issue, this paper proposes a bone stick image classification method using the YOLOv5s-ViT cascade model. The method incorporates the C3CA attention module to enhance the model's recognition of fracture areas, reduce interference from the image background, and improve the effectiveness of the Vision Transformer self-attention mechanism. Furthermore, Increase the learning rate by comparing the training data of the test to improve the training efficiency of the model. Lastly, the Batch Normalization layer is introduced to normalize the output of the encoder, suppress model training divergence, and enhance generalization ability. The experimental results show that the average recognition accuracy of the bone stick fracture region features of this paper reaches 97.6%, the average recall rate reaches 93.3%, which is 2.1% and 6.0% higher than the YOLOv5s model, respectively, and the average classification accuracy reaches 88.7%, which is 7.9% higher than the Vision Transformer model, and can effectively improve the classification accuracy of bone stick images.","2023","2025-02-26 20:41:55","2025-02-26 20:41:55","","94057-94068","","","11","","","","","","","","","","English","","","","WOS:001064475400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Bone stick images; deep learning; image classification; vision transformer; YOLOv5s","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GDSQMVM5","journalArticle","2022","Tougui, I; Jilbab, A; El Mhamdi, J","Machine Learning Smart System for Parkinson Disease Classification Using the Voice as a Biomarker","HEALTHCARE INFORMATICS RESEARCH","","2093-3681","10.4258/hir.2022.28.3.210","","Objectives: This study presents PD Predict, a machine learning system for Parkinson disease classification using voice as a biomarker. Methods: We first created an original set of recordings from the mPower study, and then extracted several audio features, such as mel-frequency cepstral coefficient (MFCC) components and other classical speech features, using a win-dowing procedure. The generated dataset was then divided into training and holdout sets. The training set was used to train two machine learning pipelines, and their performance was estimated using a nested subject-wise cross-validation approach. The holdout set was used to assess the generalizability of the pipelines for unseen data. The final pipelines were implemented in PD Predict and accessed through a prediction endpoint developed using the Django REST Framework. PD Predict is a two-component system: a desktop application that records audio recordings, extracts audio features, and makes predictions; and a server-side web application that implements the machine learning pipelines and processes incoming requests with the extracted audio features to make predictions. Our system is deployed and accessible via the following link: https://pdpredict. herokuapp.com/. Results: Both machine learning pipelines showed moderate performance, between 65% and 75% using the nested subject-wise cross-validation approach. Furthermore, they generalized well to unseen data and they did not overfit the training set. Conclusions: The architecture of PD Predict is clear, and the performance of the implemented machine learning pipelines is promising and confirms the usability of smartphone microphones for capturing digital biomarkers of disease.","2022-07","2025-02-26 20:41:55","2025-02-26 20:41:55","","210-221","","3","28","","","","","","","","","","English","","","","WOS:000878910200004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Computer-Assisted; Diagnosis; DIAGNOSIS; Machine Learning; Medical Informatics Applications; Parkinson Disease; SELECTION; Voice Disorders","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E3BE7IXJ","journalArticle","2024","Mori, D; Ohta, K; Nishimura, R; Ogawa, A; Kitaoka, N","Recognition of target domain Japanese speech using language model replacement","EURASIP JOURNAL ON AUDIO SPEECH AND MUSIC PROCESSING","","1687-4722","10.1186/s13636-024-00360-8","","End-to-end (E2E) automatic speech recognition (ASR) models, which consist of deep learning models, are able to perform ASR tasks using a single neural network. These models should be trained using a large amount of data; however, collecting speech data which matches the targeted speech domain can be difficult, so speech data is often used that is not an exact match to the target domain, resulting in lower performance. In comparison to speech data, in-domain text data is much easier to obtain. Thus, traditional ASR systems use separately trained language models and HMM-based acoustic models. However, it is difficult to separate language information from an E2E ASR model because the model learns both acoustic and language information in an integrated manner, making it very difficult to create E2E ASR models for specialized target domain which are able to achieve sufficient recognition performance at a reasonable cost. In this paper, we propose a method of replacing the language information within pre-trained E2E ASR models in order to achieve adaptation to a target domain. This is achieved by deleting the ""implicit"" language information contained within the ASR model by subtracting the source-domain language model trained with a transcription of the ASR's training data in a logarithmic domain. We then integrate a target domain language model through addition in the logarithmic domain. This subtraction and addition to replace of the language model is based on Bayes' theorem. In our experiment, we first used two datasets of the Corpus of Spontaneous Japanese (CSJ) to evaluate the effectiveness of our method. We then we evaluated our method using the Japanese Newspaper Article Speech (JNAS) and CSJ corpora, which contain audio data from the read speech and spontaneous speech domain, respectively, to test the effectiveness of our proposed method at bridging the gap between these two language domains. Our results show that our proposed language model replacement method achieved better ASR performance than both non-adapted (baseline) ASR models and ASR models adapted using the conventional Shallow Fusion method.","2024-07-20","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","1","2024","","","","","","","","","","English","","","","WOS:001272748400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","End-to-end speech reccognition; Implicit language information; Language model replacement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UYQ6GESP","journalArticle","2021","Kristinsson, S; Basilakos, A; Elm, J; Spell, LA; Bonilha, L; Rorden, C; den Ouden, DB; Cassarly, C; Sen, S; Hillis, A; Hickok, G; Fridriksson, J","Individualized response to semantic versus phonological aphasia therapies in stroke","BRAIN COMMUNICATIONS","","2632-1297","10.1093/braincomms/fcab174","","Attempts to personalize aphasia treatment to the extent where it is possible to reliably predict individual response to a particular treatment have yielded inconclusive results. The current study aimed to (i) compare the effects of phonologically versus semantically focussed naming treatment and (ii) examine biographical and neuropsychological baseline factors predictive of response to each treatment. One hundred and four individuals with chronic post-stroke aphasia underwent 3 weeks of phonologically focussed treatment and 3 weeks of semantically focussed treatment in an unblinded cross-over design. A linear mixed-effects model was used to compare the effects of treatment type on proportional change in correct naming across groups. Correlational analysis and stepwise regression models were used to examine biographical and neuropsychological predictors of response to phonological and semantic treatment across all participants. Last, chi-square tests were used to explore the association between treatment response and phonological and semantic deficit profiles. Semantically focussed treatment was found to be more effective at the group-level, independently of treatment order (P = 0.041). Overall, milder speech and language impairment predicted good response to semantic treatment (r range: 0.256-0.373) across neuropsychological tasks. The Western Aphasia Battery-Revised Spontaneous Speech score emerged as the strongest predictor of semantic treatment response (R-2 = 0.188). Severity of stroke symptoms emerged as the strongest predictor of phonological treatment response (R-2 = 0.103). Participants who showed a good response to semantic treatment were more likely to present with fluent speech compared to poor responders (P = 0.005), whereas participants who showed a good response to phonological treatment were more likely to present with apraxia of speech (P = 0.020). These results suggest that semantic treatment may be more beneficial to the improvement of naming performance in aphasia than phonological treatment, at the group-level. In terms of personalized predictors, participants with relatively mild impairments and fluent speech responded better to semantic treatment, while phonological treatment benefitted participants with more severe impairments and apraxia of speech.","2021","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","3","3","","","","","","","","","","English","","","","WOS:000734327400046","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;34<br/>Total Times Cited:&nbsp;&nbsp;35<br/>Cited Reference Count:&nbsp;&nbsp;119</p>","","","ANOMIA TREATMENT; aphasia; aphasia therapy; COMPONENTS-ANALYSIS; LANGUAGE; LEXICAL ACCESS; LONG-TERM RECOVERY; NAMING DISORDERS; phonological therapy; POSTSTROKE APHASIA; QUALITY-OF-LIFE; semantic therapy; SENTENCE PRODUCTION; stroke; VERB RETRIEVAL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R7JJBI7K","journalArticle","2021","Yue, TY","English spoken stress recognition based on natural language processing and endpoint detection algorithm (Publication with Expression of Concern)","INTERNATIONAL JOURNAL OF ELECTRICAL ENGINEERING EDUCATION","","0020-7209","10.1177/0020720920983536","","Nowadays, there are more and more researches on the application of natural language processing technology in computer-aided language system, which can provide a good assistant role for foreign language learners. However, in the research of computer-aided language system, there are still some deficiencies in the recognition of English spoken stress nodes, which cannot be well recognized. Based on this, this paper proposes a method of English spoken accent recognition based on natural language processing and endpoint detection algorithm, which aims to promote the accuracy of accent recognition in the computer-aided language system and improve the performance of the computer-aided language system. In order to avoid the interference of background noise, this paper proposes a short-term time-frequency endpoint detection algorithm which can accurately judge the beginning and end of speech in complex environment. Then, on the basis of traditional speech feature extraction and fractal dimension theory, a nonlinear fractal dimension speech feature is extracted. Finally, RankNet is used to process the extracted features to realize the recognition of English spoken stress nodes. In the simulation analysis, the application effect of the short-term time-frequency endpoint detection algorithm proposed in this paper in the complex background noise and the effect of non-linear fractal dimension speech features on the recognition of English spoken stress nodes are verified. Finally, the performance and good application effect of the method designed in this paper are illustrated.","2021-02-24","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","","","","","","","","","","","","English","","","","WOS:000635293300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","endpoint detection algorithm; English spoken stress node; fractal dimension theory; natural language processing; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HWKYSZXR","journalArticle","2022","Tichenor, SE; Walsh, B; Gerwin, KL; Tian, FH","Consistency of children's hemodynamic responses during spontaneous speech","NEUROPHOTONICS","","2329-423X","10.1117/1.NPh.9.1.015003","","Significance: Hemodynamic responses (HRs) are typically averaged across experimental sessions based on the assumption that brain activation is consistent over multiple trials. This may not be a safe assumption, especially in pediatric populations, due to unaccounted effects of inattention, fatigue, or habituation. Aim: The purpose of this study was to quantify the consistency of the HR over speech and language brain regions during speech production in typically developing school-aged children. Approach: Brain activity over speech and language regions of interest (ROIs) was recorded with functional near-infrared spectroscopy during a picture description paradigm with 37 children (aged 7 to 12 years). We divided the 30 experimental trials, each 5 s long, into three segments of 10 trials each corresponding with early (trials 1 to 10), middle (trials 11 to 20), and late (trials 21 to 30) trials. We then compared oxygenated (HbO) and deoxygenated (HbR) hemoglobin concentrations averaged across each 10 trial segment to overall concentrations averaged across all 30 trials. We also compared differential hemoglobin (HbD) across ROIs. Results: HbO and HbR averaged across all experimental trials most strongly correlated with HbO and HbR from early trials. HbD values from channels over most speech and language regions did not appreciably change throughout the experimental session. The exception was HbD values from channels over the dorsal inferior frontal gyms (dIFG). This region showed significantly higher activation over the left hemisphere during the first segment of the experiment. Conclusions: Our findings suggest that brain activity from speech and language ROIs was relatively consistent over the experimental session. The exception was increased activation of left dIFG during earlier experimental trials. We suggest that researchers critically evaluate the consistency of HRs from different brain regions to determine the reliability of HRs recorded during experimental sessions. This step is instrumental in ensuring that uncontrolled effects do not mask patterns of task-related activation. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 International License.","2022-01-01","2025-02-26 20:41:55","2025-02-26 20:41:55","","","","1","9","","","","","","","","","","English","","","","WOS:000776555900003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","ARTIFACTS; children; CORTEX; FMRI; functional near-infrared spectroscopy; HABITUATION; language; MEMORY; MODEL; NEAR-INFRARED SPECTROSCOPY; speech; WORD PRODUCTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EK38W5QQ","journalArticle","2025","Yu, CP; Fang, X; Tian, SY; Liu, H","A unified cross-attention model for predicting antigen binding specificity to both HLA and TCR molecules","NATURE MACHINE INTELLIGENCE","","2522-5839","10.1038/s42256-024-00973-w","","The immune checkpoint inhibitors have demonstrated promising clinical efficacy across various tumour types, yet the percentage of patients who benefit from them remains low. The bindings between tumour antigens and human leukocyte antigen class I/T cell receptor molecules determine the antigen presentation and T cell activation, thereby playing an important role in the immunotherapy response. In this paper, we propose UnifyImmun, a unified cross-attention transformer model designed to simultaneously predict the bindings of peptides to both receptors, providing more comprehensive evaluation of antigen immunogenicity. We devise a two-phase strategy using virtual adversarial training that enables these two tasks to reinforce each other mutually, by compelling the encoders to extract more expressive features. Our method demonstrates superior performance in predicting both peptide-HLA and peptide-TCR binding on multiple independent and external test sets. Notably, on a large-scale COVID-19 peptide-TCR binding test set without any seen peptide in the training set, our method outperforms the current state-of-the-art methods by more than 10%. The predicted binding scores significantly correlate with the immunotherapy response and clinical outcomes on two clinical cohorts. Furthermore, the cross-attention scores and integrated gradients reveal the amino acid sites critical for peptide binding to receptors. In essence, our approach marks an essential step towards comprehensive evaluation of antigen immunogenicity.","2025-01-28","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","","","","","","","","","","","","English","","","","WOS:001407518600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;84</p>","","","DATABASE; LIGANDS; MHC-BINDING; MOTIF; PEPTIDE BINDING; SEQUENCE; SHOW; T-CELL REPERTOIRE; TRANSFORMER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6I7AMDVK","journalArticle","2024","Tran, QBH; Waheed, AA; Chung, ST","Robust Text-to-Cypher Using Combination of BERT, GraphSAGE, and Transformer (CoBGT) Model","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14177881","","Graph databases have become essential for managing and analyzing complex data relationships, with Neo4j emerging as a leading player in this domain. Neo4j, a high-performance NoSQL graph database, excels in efficiently handling connected data, offering powerful querying capabilities through its Cypher query language. However, due to Cypher's complexities, making it more accessible for nonexpert users requires translating natural language queries into Cypher. Thus, in this paper, we propose a text-to-Cypher model to effectively translate natural language queries into Cypher. In our proposed model, we combine several methods to enable nonexpert users to interact with graph databases using the English language. Our approach includes three modules: key-value extraction, relation-properties prediction, and Cypher query generation. For key-value extraction and relation-properties prediction, we leverage BERT and GraphSAGE to extract features from natural language. Finally, we use a Transformer model to generate the Cypher query from these features. Additionally, due to the lack of text-to-Cypher datasets, we introduced a new dataset that contains English questions querying information within a graph database, paired with corresponding Cypher query ground truths. This dataset aids future model learning, validation, and comparison on text-to-Cypher task. Through experiments and evaluations, we demonstrate that our model achieves high accuracy and efficiency when comparing with some well-known seq2seq model such as T5 and GPT2, with an 87.1% exact match score on the dataset.","2024-09","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","17","14","","","","","","","","","","English","","","","WOS:001311015700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","CQL; Cypher; graph database; GraphSAGE; natural language processing; sematic parsing; text-to-Cypher","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8KVDJ69N","journalArticle","2024","Gao, Y; Cheng, ZX","M4EEG: MATCHING NETWORK-BASED MENTAL HEALTH STATUS ASSESSMENT MODEL USING EEG SIGNALS","JOURNAL OF MECHANICS IN MEDICINE AND BIOLOGY","","0219-5194","10.1142/S0219519424400372","","Mental health is critical to an individual's life and social functioning and affects emotions, cognition and behavior. Mental health status assessments can help individuals understand their own psychological status, identify potential problems in real-time and implement effective interventions to promote favorable mental health. In this study, a deep learning approach was used to construct a simple-minded and flexible model for electroencephalogram (EEG)-based mental health status assessment to construct the corresponding M4EEG model. This model is suitable not only for supervised learning tasks containing a large amount of labeled data but also for few-shot classification tasks in special cases. During execution, certain components of a pretrained transformer model are utilized as the model's foundation. After deriving feature values from different inputs, these features are decoupled by cross-connecting them into the relation module. Finally, the correlation between the outputs and the classification results are determined by a relation score. In experiments, the Database for Emotion Analysis using Physiological Signals (DEAP) and Affective Mood and Interpersonal Goals in the School Environment (AMIGOS) datasets were partitioned into K-Shot files as the input information, and the classification results were derived from the M4EEG model. These results showed that the M4EEG model is capable of assessing mental health status through EEG, and the model can obtain results that cannot be achieved by existing models that do not apply comparable data labeling.","2024-10","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","08","24","","","","","","","","","","English","","","","WOS:001305391600008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","ATTENTION; EEG; matching network; mental health assessment; RECOGNITION; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J6NXGCHZ","journalArticle","2023","Zhang, JX; Matsuda, Y; Fujimoto, M; Suwa, H; Yasumoto, K","Movement recognition via channel-activation-wise sEMG attention","METHODS","","1046-2023","10.1016/j.ymeth.2023.06.011","","Context: Surface electromyography (sEMG) signals contain rich information recorded from muscle movements and therefore reflect the user's intention. sEMG has seen dominant applications in rehabilitation, clinical diagnosis as well as human engineering, etc. However, current feature extraction methods for sEMG signals have been seriously limited by their stochasticity, transiency, and non-stationarity.Objective: Our objective is to combat the difficulties induced by the aforementioned downsides of sEMG and thereby extract representative features for various downstream movement recognition.Method: We propose a novel 3-axis view of sEMG features composed of temporal, spatial, and channel-wise summary. We leverage the state-of-the-art architecture Transformer to enforce efficient parallel search and to get rid of limitations imposed by previous work in gesture classification. The transformer model is designed on top of an attention-based module, which allows for the extraction of global contextual relevance among channels and the use of this relevance for sEMG recognition.Results: We compared the proposed method against existing methods on two Ninapro datasets consisting of data from both healthy people and amputees. Experimental results show the proposed method attains the state-of-the-art (SOTA) accuracy on both datasets. We further show that the proposed method enjoys strong generalization ability: a new SOTA is achieved by pretraining the model on a different dataset followed by fine-tuning it on the target dataset.","2023-10","2025-02-26 20:41:56","2025-02-26 20:41:56","","39-47","","","218","","","","","","","","","","English","","","","WOS:001052480000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","DECOMPOSITION; EMG; Gestures classification; HAND GESTURE RECOGNITION; Movement recognition; PROSTHESES; sEMG; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E39APFFG","journalArticle","2023","Xu, YT; Zhao, K; Zhang, LA; Zhu, MY; Zeng, D","Hyperspectral anomaly detection with vision transformer and adversarial refinement","INTERNATIONAL JOURNAL OF REMOTE SENSING","","0143-1161","10.1080/01431161.2023.2229495","","Hyperspectral images (HSIs) record the electromagnetic energy from the visible to infrared bands, which can obtain rich spectral and spatial information. HSI is a three-dimensional volume, which combines one-dimensional spectral feature and two-dimensional spatial information. Hyperspectral anomaly detection aims at detecting the objects where the spectral or spatial features are significantly different from the neighbouring background when the targets or background priors are unknown, which is a special kind of anomaly detection. In this paper, we propose a hyperspectral anomaly detector based on vision-transformer. We cast anomaly detection as an image inpainting problem, and the background is reconstructed by the inpainting-transformer model, whereas the anomaly is detected by a morphological filter. Since the background is large, whereas the anomaly area is relatively smaller, we randomly mask out some areas and train the network to recover these areas based on the background context, and the network mainly learns the background feature from the surroundings, thus the background area is reconstructed at first. Then, we remove the background from the input image and use the morphological filter to extract small areas, which enhances the detection results. Finally, we use an adversarial strategy to suppress the reconstruction of anomalies and refine the results based on suppressed images. Extensive experiments on two HSI dataset with 15 images demonstrate that our method outperforms state-of-the-art competitors.","2023-07-03","2025-02-26 20:41:56","2025-02-26 20:41:56","","4034-4057","","13","44","","","","","","","","","","English","","","","WOS:001025152700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","ALGORITHM; anomaly detection; Hyperspectral image; IMAGE CLASSIFICATION; morphological filtering; REPRESENTATION; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U4DA8YDS","journalArticle","2022","Huang, P; Chen, Q; Wang, D; Wang, MQ; Wu, X; Huang, XM","TripleConvTransformer: A deep learning vessel trajectory prediction method fusing discretized meteorological data","FRONTIERS IN ENVIRONMENTAL SCIENCE","","2296-665X","10.3389/fenvs.2022.1012547","","The shipping industry is increasingly threatened by global climate change. Reliable trajectory prediction can be used to perceive potential risks and ensure navigation efficiency. However, many existing studies have not fully considered the impact of complex ocean environmental factors and have only focused on local regions, which are difficult to extend to a global scale. To this end, we propose a deep learning vessel trajectory prediction method fusing discretized meteorological data (TripleConvTransformer). First, we clean the automatic identification system data to form a high-quality spatiotemporal trajectory dataset. Then, we fuse the trajectory data with the meteorological data after feature discretization to deeply mine the motion information of ocean-going ships. Finally, we design three modules, the global convolution, local convolution, and trend convolution modules, based on the simplified transformer model to capture multiscale features. We compare TripleConvTransformer with state-of-the-art prediction models. The experimental results show that in the prediction of the trajectory points in the next 90 min, the smallest root mean square error in terms of longitude and latitude and the highest overall prediction accuracy are achieved using TripleConvTransformer. Our method not only fully considers the influence of meteorological factors in the ocean-going process but also effectively extracts the important information hidden in the data, thus achieving accurate trajectory prediction on a global scale.","2022-09-15","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","","10","","","","","","","","","","English","","","","WOS:000862307700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","automatic identification system; CLIMATE-CHANGE; deep learning; feature discretization; global climate change; TIME; trajectory prediction; WEATHER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z4YKTPGQ","journalArticle","2024","Yang, F; Wang, B","Dual Channel-Spatial Self-Attention Transformer and CNN synergy network for 3D medical image segmentation","APPLIED SOFT COMPUTING","","1568-4946","10.1016/j.asoc.2024.112255","","Even though the Vision Transformer leverages the self-attention mechanism to capture long-range dependencies, showing significant potential in medical image segmentation, the limited annotations in the image dataset make it difficult for the Transformer model to extract different global features, resulting in attention collapse and generating similar or identical attention maps. Previous studies have attempted to solve the problem by integrating convolutional neural layers into Transformer-based architectures. However, improper integration may lead to the inability of the model to effectively capture local and global information in both spatial and channel dimensions. To address the above issue, we propose a hybrid architecture using the Dual Channel-Spatial SelfAttention Transformer and CNN Synergy Network (DTC-SUNETR) for medical image segmentation. Specifically, we redesigned the self-attention mechanism. A novel Channel-Spatial Self-Attention (CSSA) block is introduced to integrate the enhanced channel and spatial self-attention mechanism to capture the global relationship and local structure among image features. This helps the model to more comprehensively understand the interdependencies between different channels and capture the relationships between different pixels, thus enhancing the feature representation of the corresponding dimensions. Simultaneously, it also improves the overall computational efficiency of the network. Extensive experiments on four different medical image segmentation datasets, including Synapse, ACDC, Brain Tumor, and Lung Tumor, demonstrate the superiority of the proposed DTC-SUNETR over state-of-the-art methods.","2024-12","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","","167","","","","","","","","","","English","","","","WOS:001342484800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","3D medical image segmentation; Attention collapse; Convolutional neural layers; Self-attention mechanism; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HKNAKFSZ","journalArticle","2025","Huang, YJ; Zeng, TC; Jia, ML; Yang, JR; Xu, WG; Lu, S","Fusing Transformer and diffusion for high-resolution prediction of daylight illuminance and glare based on sparse ceiling-mounted input","BUILDING AND ENVIRONMENT","","0360-1323","10.1016/j.buildenv.2024.112163","","Accurate prediction of workplane daylight illuminance and eye-height glare is crucial for lighting control. Existing studies used machine learning to predict illuminance at predetermined locations based on indoor sensors, but they may encounter challenges in scenarios 1) with flexible seating arrangements, 2) with dynamic shading devices, and 3) requiring the prediction of glare. To address these challenges, we proposed a novel method fusing Transformer and Diffusion models, with the input being data collected from sparse ceilingmounted illuminance sensors, and the outputs being high-resolution workplane illuminance and glare. The model works well for rooms without and with dynamic roller shades. For the former, the mean absolute errors for illuminance below 3000 lx and Daylight Glare Index (DGI) are only 20.77 lx and 0.20, and the error rates in detecting illuminance <500 lx and DGI>22 are only 0.85 % and 5.55 %. For the more complicated latter case, the aforementioned four numbers are 34.78 lx, 0.59, 2.47 % and 23.13 %. The model significantly outperforms the linear and the ANN models, particularly in glare prediction. The influence of sensor number and placement strategy on model performance was also revealed. The model can potentially enhance lighting control, especially in cases with dynamic shading, with flexible seating arrangements, and where glare is of interest.","2025-01-01","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","","267","","","","","","","","","","English","","","","WOS:001334863000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","(DDPM); Ceiling-mounted sensor; Daylight performance prediction; Denoising diffusion probabilistic model; DESIGN; DISCOMFORT GLARE; EFFICIENCY; Lighting control; LIGHTING CONTROL; MOOD; OFFICE BUILDINGS; PERFORMANCE; PHOTOSENSORS; Transformer model; VIEW","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VLVICA7H","journalArticle","2024","Lin, RH; Hu, HF","Dynamically Shifting Multimodal Representations via Hybrid-Modal Attention for Multimodal Sentiment Analysis","IEEE TRANSACTIONS ON MULTIMEDIA","","1520-9210","10.1109/TMM.2023.3303711","","In the field of multimodal machine learning, multimodal sentiment analysis task has been an active area of research. The predominant approaches focus on learning efficient multimodal representations containing intra- and inter-modality information. However, the heterogeneous nature of different modalities brings great challenges to multimodal representation learning. In this article, we propose a multi-stage fusion framework to dynamically fine-tune multimodal representations via a hybrid-modal attention mechanism. Previous methods mostly only fine-tune the textual representation due to the success of large corpus pre-trained models and neglect the inconsistency problem of different modality spaces. Thus, we design a module called the Multimodal Shifting Gate (MSG) to fine-tune the three modalities by modeling inter-modality dynamics and shifting representations. We also adopt a module named Masked Bimodal Adjustment (MBA) on the textual modality to improve the inconsistency of parameter spaces and reduce the modality gap. In addition, we utilize syntactic-level and semantic-level textual features output from different layers of the Transformer model to sufficiently capture the intra-modality dynamics. Moreover, we construct a Shifting HuberLoss to robustly introduce the variation of the shifting value into the training process. Extensive experiments on the public datasets, including CMU-MOSI and CMU-MOSEI, demonstrate the efficacy of our approach.","2024","2025-02-26 20:41:56","2025-02-26 20:41:56","","2740-2755","","","26","","","","","","","","","","English","","","","WOS:001173299400013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","Acoustics; Feature extraction; FUSION; hybrid-modal attention; intra- and inter-modality dynamics; LANGUAGE; Logic gates; Multi-stage fusion framework; multimodal representations shifting; PREDICTION; Sentiment analysis; SPEECH; Task analysis; Transformers; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SBXE2K8X","journalArticle","2023","Deng, KK; Zhao, D; Han, QY; Zhang, ZH; Wang, SY; Zhou, AF; Ma, HD","Midas: Generating mmWave Radar Data from Videos for Training Pervasive and Privacy-preserving Human Sensing Tasks","PROCEEDINGS OF THE ACM ON INTERACTIVE MOBILE WEARABLE AND UBIQUITOUS TECHNOLOGIES-IMWUT","","2474-9567","10.1145/3580872","","Millimeter wave radar is a promising sensing modality for enabling pervasive and privacy-preserving human sensing. However, the lack of large-scale radar datasets limits the potential of training deep learning models to achieve generalization and robustness. To close this gap, we resort to designing a software pipeline that leverages wealthy video repositories to generate synthetic radar data, but it confronts key challenges including i) multipath reflection and attenuation of radar signals among multiple humans, ii) unconvertible generated data leading to poor generality for various applications, and iii) the class-imbalance issue of videos leading to low model stability. To this end, we design Midas to generate realistic, convertible radar data from videos via two components: (i) a data generation network (DG-Net) combines several key modules, depth prediction, human mesh fitting and multi-human reflection model, to simulate the multipath reflection and attenuation of radar signals to output convertible coarse radar data, followed by a Transformer model to generate realistic radar data; (ii) a variant Siamese network (VS-Net) selects key video clips to eliminate data redundancy for addressing the class-imbalance issue. We implement and evaluate Midas with video data from various external data sources and real-world radar data, demonstrating its great advantages over the state-of-the-art approach for both activity recognition and object detection tasks.","2023-03","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","1","7","","","","","","","","","","English","","","","WOS:000957429700009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;82</p>","","","cross domain translation; data generation; human activity recognition; radar sensing; RECOGNITION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4NGT8RH3","journalArticle","2023","Manzari, ON; Kashiani, H; Dehkordi, HA; Shokouhi, SB","Robust transformer with locality inductive bias and feature normalization","ENGINEERING SCIENCE AND TECHNOLOGY-AN INTERNATIONAL JOURNAL-JESTECH","","2215-0986","10.1016/j.jestch.2022.101320","","Vision transformers have been demonstrated to yield state-of-the-art results on a variety of computer vision tasks using attention-based networks. However, research works in transformers mostly do not investigate robustness/accuracy trade-off, and they still struggle to handle adversarial perturbations. In this paper, we explore the robustness of vision transformers against adversarial perturbations and try to enhance their robustness/accuracy trade-off in white box attack settings. To this end, we propose Locality iN Locality (LNL) transformer model. We prove that the locality introduction to LNL contributes to the robustness performance since it aggregates local information such as lines, edges, shapes, and even objects. In addition, to further improve the robustness performance, we encourage LNL to extract training signal from the moments (a.k.a., mean and standard deviation) and the normalized features. We validate the effectiveness and generality of LNL by achieving state-of-the-art results in terms of accuracy and robustness metrics on German Traffic Sign Recognition Benchmark (GTSRB) and Canadian Institute for Advanced Research (CIFAR-10). More specifically, for traffic sign classification, the proposed LNL yields gains of 1.1% and 35% in terms of clean and robustness accuracy compared to the state-of-the-art studies.(c) 2022 Karabuk University. Publishing services by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).","2023-02","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","","38","","","","","","","","","","English","","","","WOS:000974635600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","Adversarial attacks; Robustness; Traffic sign classification; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UNSHBXDD","journalArticle","2023","Hung, ALY; Zheng, HX; Miao, Q; Raman, SS; Terzopoulos, D; Sung, KYHY","CAT-Net: A Cross-Slice Attention Transformer Model for Prostate Zonal Segmentation in MRI","IEEE TRANSACTIONS ON MEDICAL IMAGING","","0278-0062","10.1109/TMI.2022.3211764","","Prostate cancer is the second leading cause of cancer death among men in the United States. The diagnosis of prostate MRI often relies on accurate prostate zonal segmentation. However, state-of-the-art automatic segmentation methods often fail to produce well-contained volumetric segmentation of the prostate zones since certain slices of prostate MRI, such as base and apex slices, are harder to segment than other slices. This difficulty can be overcome by leveraging important multi-scale image-based information from adjacent slices, but current methods do not fully learn and exploit such cross-slice information. In this paper, we propose a novel cross-slice attention mechanism, which we use in a Transformer module to systematically learn cross-slice information at multiple scales. The module can be utilized in any existing deep-learning-based segmentation framework with skip connections. Experiments show that our cross-slice attention is able to capture cross-slice information significant for prostate zonal segmentation in order to improve the performance of current state-of-the-art methods. Cross-slice attention improves segmentation accuracy in the peripheral zones, such that segmentation results are consistent across all the prostate slices (apex, mid-gland, and base). The code for the proposed model is available at https://bit.ly/CAT-Net.","2023-01","2025-02-26 20:41:56","2025-02-26 20:41:56","","291-303","","1","42","","","","","","","","","","English","","","","WOS:000907160700024","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;29<br/>Total Times Cited:&nbsp;&nbsp;30<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","Attention mechanism; Decoding; deep learning; Image resolution; Image segmentation; magnetic resonance imaging; Magnetic resonance imaging; NETWORK; prostate zonal segmentation; Standards; Three-dimensional displays; transformer network; Transformers; U-NET","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q4K66C9D","journalArticle","2023","Dubey, S; Olimov, F; Rafique, MA; Kim, J; Jeon, M","Label-attention transformer with geometrically coherent objects for image captioning","INFORMATION SCIENCES","","0020-0255","10.1016/j.ins.2022.12.018","","Encoder-decoder-based image captioning techniques are generally utilized to describe meaningful information present in an image. In this work, we investigate two unexplored ideas for image captioning using the transformer: 1) an object-focused label attention module (LAM), and 2) a geometrically coherent proposal (GCP) module that focuses on the scale and position of objects to benefit the transformer model by attaining better image perception. These modules demonstrate the enforcement of objects' relevance in the sur-rounding environment. Furthermore, they explore the effectiveness of learning an explicit association between vision and language constructs. LAM and GCP tolerate the variation in objects' class and its association with labels in multi-label classification. The proposed framework, label-attention transformer with geometrically coherent objects (LATGeO), acquires proposals of geometrically coherent objects using a deep neural network (DNN) and generates captions by investigating their relationships using LAM. The module LAM associates the extracted objects classes to the available dictionary using self-attention lay-ers. Object coherence is acquired in the GCP module using the localized ratio of the propos-als' geometrical features. In this study, experimentation results are performed on MSCOCO dataset. The evaluation of LATGeO on MSCOCO advocates that objects' relevance in sur-roundings and their visual features binding with geometrically localized ratios and associ-ated labels generate improved and meaningful captions.(c) 2022 Published by Elsevier Inc.","2023-04","2025-02-26 20:41:56","2025-02-26 20:41:56","","812-831","","","623","","","","","","","","","","English","","","","WOS:000920304800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;22<br/>Total Times Cited:&nbsp;&nbsp;22<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Geometrically coherent proposals; Image captioning; Label-attention; Memory-augmented-attention; Self-attention; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6LN57RFB","journalArticle","2024","Dadure, P; Pakray, P; Bandyopadhyay, S","MathUSE: Mathematical information retrieval system using universal sentence encoder model","JOURNAL OF INFORMATION SCIENCE","","0165-5515","10.1177/01655515221077335","","In the scientific field, mathematical formulae are a significant factor in communicating the ideas and the fundamental principles of any scientific knowledge. Nowadays, the scientific research community generates a huge number of documents that comprise both textual and mathematical formulae. For the retrieval of textual information, numerous retrieval systems are present that generate excellent results. Nevertheless, these textual information retrieval systems are insufficient to handle the structure and scripting styles of the mathematical formulae. The recent past has perceived the research, which intends to retrieve the textual and mathematical formulae, but their impoverished results are symptomatic to the scope of improvement. In this article, we have implemented the formula-embedding approach, which encodes the formulae into fixed dimensional embedding vectors. For encoding of formula, we have used universal sentence encoder-based sentence-embedding model, which relies on transformer architecture and deep averaging network. The proposed models take the latex formula as an input and produce an output of fixed dimensional embedding representation. To achieve more promising results, the transformer model follows stacked self-attentions, point-wise fully connected layers and positional encoding for both the encoder and decoder. The obtained results have been compared with state-of-the-art existing approaches, and the comparison study revealed that the proposed approach offers better retrieval accuracy in terms of nDCG' = 0.217, MAP' = 0.178 and P@10 = 0.378 measures.","2024-02","2025-02-26 20:41:56","2025-02-26 20:41:56","","66-84","","1","50","","","","","","","","","","English","","","","WOS:000765800700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Deep averaging network; embedding; information retrieval; REPRESENTATION; transformer architecture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S5J7NI9Y","journalArticle","2024","Cheng, JH; Luo, X; Jin, Z","Integrating domain knowledge into transformer for short-term wind power forecasting","ENERGY","","0360-5442","10.1016/j.energy.2024.133511","","Wind energy is an environmentally friendly source of energy and serves as an efficient supplement to conventional energy resources. Accurate wind power forecasting is crucial for effective decision-making in the daily operation of wind power plants. However, due to the heavy dependence on weather conditions, the variability and uncertainty associated with weather pose significant challenges to wind power forecasting. In this study, we propose a domain-knowledge integrated Transformer (DKFormer) model for short-term wind power forecasting. The proposed model integrates domain knowledge of wind power generation through three portable modules that play essential roles in data pre-processing, model training, and forecasting stages respectively. Additionally, by constructing boundary constraints that simultaneously utilize the data of both measured wind power and numerical weather prediction (NWP), the DKFormer model further reduces errors in multi-step wind power forecasting and improves overall forecast performance, particularly when input wind speed data exhibits dramatic variations. Furthermore, transfer learning techniques are employed to enhance the forecast capability of the DKFormer model using limited training data. Real-life datasets are used to evaluate the performance of the proposed DKFormer, demonstrating its superiority over conventional statistical models and DL models in short-term wind forecasting. Specifically, in day-ahead wind power forecasting experiments, our proposed DKFormer model achieves a 22.0% reduction in mean absolute error (MAE) while also exhibiting improved forecast stability compared to the conventional Transformer model.","2024-12-15","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","","312","","","","","","","","","","English","","","","WOS:001350269900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Deep learning; Domain knowledge; Domain-knowledge integrated transformer; MODE DECOMPOSITION; model; PREDICTION; Wind power forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5W8Y2YZZ","journalArticle","2024","Slim, A; Melouah, A","Low Resource Arabic Dialects Transformer Neural Machine Translation Improvement through Incremental Transfer of Shared Linguistic Features","ARABIAN JOURNAL FOR SCIENCE AND ENGINEERING","","2193-567X","10.1007/s13369-023-08543-9","","Neural machine translation (NMT) is a complex process that deals with many grammatical complexities. Today, transfer learning (TL) has emerged as a leading method in machine translation, enhancing accuracy with ample source data for limited target data. Yet, low-resource languages such as Arabic dialects lack substantial source data. This study aims to enable an NMT model, trained on a sparse Arabic dialect corpus, to translate a precise dialect with a limited corpus, addressing this gap. This paper introduces an incremental transfer learning approach tailored for translating low-resource language. The method utilizes various related language corpora, employing an incremental fine-tuning strategy to transfer linguistic features from a grand-parent model to a child model. In our case, Knowledge is transferred from a broad set of Arabic dialects to the Maghrebi dialects subset and then to specific low-resource dialects such as Algerian, Tunisian, and Moroccan, employing Transformer and attentional sequence-to-sequence models. The evaluation of the proposed strategy on Algerian, Tunisian, and Moroccan dialects demonstrates superior translation performance compared to traditional TL methods. Using the Transformer model, it shows improvements of 80%, 62%, and 58% for Algerian, Tunisian, and Moroccan dialects, respectively. Similarly, with the Attentional seq2seq model, there's an enhancement of 98% in BLEU score results for Algerian, Tunisian, and Moroccan dialects.","2024-09","2025-02-26 20:41:56","2025-02-26 20:41:56","","12393-12409","","9","49","","","","","","","","","","English","","","","WOS:001152594300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Arabic dialects; Domain specialization; Neural machine translation (NMT); Shared linguistic features; Transfer learning (TL); Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HIWYVGZE","journalArticle","2023","Ock, J; Guntuboina, C; Farimani, AB","Catalyst Energy Prediction with CatBERTa: Unveiling Feature Exploration Strategies through Large Language Models","ACS CATALYSIS","","2155-5435","10.1021/acscatal.3c04956","","Efficient catalyst screening necessitates predictive models for adsorption energy, which is a key descriptor of reactivity. Prevailing methods, notably graph neural networks (GNNs), demand precise atomic coordinates for constructing graph representations, while the integration of observable attributes remains challenging. This research introduces CatBERTa, an energy prediction Transformer model that uses textual inputs. Built on a Transformer encoder pretrained for language modeling purposes, CatBERTa processes human-interpretable text, incorporating target features. Attention score analysis reveals CatBERTa's focus on tokens related to adsorbates, bulk composition, and their interacting atoms. Moreover, interacting atoms emerge as effective descriptors for adsorption configurations, while factors such as the bond length and atomic properties of these atoms offer limited predictive contributions. In predicting the adsorption energy from textual representations of initial structures, CatBERTa exhibits a precision comparable to that of conventional GNNs. Notably, in subsets recognized for their high accuracy with GNNs, CatBERTa consistently achieves a mean absolute error of 0.35 eV. Furthermore, the subtraction of the CatBERTa-predicted energies effectively cancels out their systematic errors by as much as 19.3% for chemically similar systems, surpassing the error reduction observed in GNNs. This outcome highlights its potential to enhance the accuracy of the energy difference predictions. This research establishes a fundamental framework for text-based catalyst property prediction without relying on graph representations while also unveiling intricate feature-property relationships.","2023-11-30","2025-02-26 20:41:56","2025-02-26 20:41:56","","16032-16044","","24","13","","","","","","","","","","English","","","","WOS:001141366800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","catalyst screening; computational catalysis; DESIGN; large language model; machine learning; renewable energy; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TWI4PL9Q","journalArticle","2023","Liu, LQ; Xu, XL","Self-attention Mechanism at the Token Level: Gradient Analysis and Algorithm Optimization","KNOWLEDGE-BASED SYSTEMS","","0950-7051","10.1016/j.knosys.2023.110784","","The self-attention mechanism is a feature processing mechanism for structured data in deep learning models. It has been widely used in transformer-based deep learning models and has demonstrated superior performance in various fields, such as machine translation, speech recognition, text-to-text conversion, and computer vision. The self-attention mechanism mainly focuses on the surface structure of structured data, but it also involves attention between basic data units and self-attention of basic data units in the deeper structure of the data. In this paper, we investigate the forward attention flow and backward gradient flow in the self-attention module of the transformer model based on the sequence-to-sequence data structure used in machine translation tasks. We found that this combination produces a ""gradient distortion""phenomenon at the token level of basic data units. We consider this phenomenon a defect and propose a series of solutions to address it theoretically. Furthermore, we conduct experiments and select the most robust solution as the Unevenness-Reduced Self-Attention (URSA) module, which replaces the original self-attention module. The experimental results demonstrate that the ""gradient distortion""phenomenon exists both theoretically and numerically, and the URSA module enables the self-attention mechanism to achieve consistent, stable, and effective optimization across different models, tasks, corpora, and evaluation metrics. The URSA module is both simple and highly portable.& COPY; 2023 Elsevier B.V. All rights reserved.","2023-10-09","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","","277","","","","","","","","","","English","","","","WOS:001058183900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Gradient distortion; Self-attention mechanism; Token level; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W678YB2N","journalArticle","2024","Edgar, EV; Mcguire, K; Pelphrey, KA; Ventola, P; van Noordt, S; Crowley, MJ","Early- and Late-Stage Auditory Processing of Speech Versus Non-Speech Sounds in Children With Autism Spectrum Disorder: An ERP and Oscillatory Activity Study","DEVELOPMENTAL PSYCHOBIOLOGY","","0012-1630","10.1002/dev.22552","","Individuals with autism spectrum disorder (ASD) often exhibit greater sensitivity to non-speech sounds, reduced sensitivity to speech, and increased variability in cortical activity during auditory speech processing. We assessed differences in cortical responses and variability in early and later processing stages of auditory speech versus non-speech sounds in typically developing (TD) children and children with ASD. Twenty-eight 4- to 9-year-old children (14 ASDs) listened to speech and non-speech sounds during an electroencephalography session. We measured peak amplitudes for early (P2) and later (P3a) stages of auditory processing and inter-trial theta phase coherence as a marker of cortical variability. TD children were more sensitive to speech sounds during early and later processing stages than ASD children, reflected in larger P2 and P3a amplitudes. Individually, twice as many TD children showed reliable differentiation between speech and non-speech sounds compared to children with ASD. Children with ASD showed greater intra-individual variability in theta responses to speech sounds during early and later processing stages. Children with ASD show atypical auditory processing of fundamental speech sounds, perhaps due to reduced and more variable cortical activation. These atypicalities in the consistency of cortical responses to fundamental speech features may impact the development of cortical networks and have downstream effects on more complex forms of language processing.","2024-12","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","8","66","","","","","","","","","","English","","","","WOS:001368747100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;99</p>","","","ATTENTION; auditory speech processing; autism spectrum disorder; childhood; DISCRIMINATION; event-related potentials; EVOKED POTENTIALS; inter-trial phase coherence; LANGUAGE; NONSPEECH STIMULI; PATTERNS; PERCEPTION; RESPONSES; THETA; VERBAL-ABILITIES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EWQLDKGK","journalArticle","2024","Zhang, FC; Tong, LL; Shi, C; Zuo, R; Wang, LW; Wang, Y","Deep Learning in Predicting Preterm Birth: A Comparative Study of Machine Learning Algorithms","MATERNAL-FETAL MEDICINE","","2096-6954","10.1097/FM9.0000000000000236","","ObjectiveTo determine whether deep learning algorithms are suitable for predicting preterm birth.MethodsA retrospective study was conducted at Peking University Third Hospital from January 2018 to June 2023. Birth data were divided into two parts based on the date of delivery: the first part was used for model training and validation, while real world viability was evaluated using the second part. Four machine learning algorithms (logistic regression, random forest, support vector machine, and transformer) were employed to predict preterm birth. Receiver operating characteristic curves were plotted, and the area under the curve (AUC), sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and accuracy were calculated.ResultsThis research included data on 30,965 births, where 24,770 comprised the first part, and included 3164 (12.77%) in the preterm birth group, with 6195 in the second part, including 795 (12.83%) in the preterm birth group. Significant differences in various factors were observed between the preterm and full-term birth groups. The transformer model (AUC = 79.20%, sensitivity = 73.67%, specificity = 72.48%, PPV = 28.21%, NPV = 94.95%, and accuracy = 72.61% in the test dataset) demonstrated superior performance relative to logistic regression (AUC = 77.96% in the test dataset), support vector machine (AUC = 71.70% in the test dataset), and random forest (AUC = 75.09% in the test dataset) approaches.ConclusionThis study highlights the promise of deep learning algorithms, specifically the transformer algorithm, for predicting preterm birth.","2024-07","2025-02-26 20:41:56","2025-02-26 20:41:56","","141-146","","3","6","","","","","","","","","","English","","","","WOS:001276556800004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","Artificial intelligence; Machine learning; Preterm birth; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"45JQJ9EJ","journalArticle","2025","Guo, YQ; Mokany, K; Levick, SR; Yang, JY; Moghadam, P","Spatioformer: A Geo-Encoded Transformer for Large-Scale Plant Species Richness Prediction","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2025.3534654","","Earth observation (EO) data have shown promise in predicting species richness of vascular plants (alpha-diversity), but extending this approach to large spatial scales is challenging because geographically distant regions may exhibit different compositions of plant species (beta-diversity), resulting in a location-dependent relationship between richness and spectral measurements. In order to handle such geolocation dependence, we propose Spatioformer, where a novel geolocation encoder is coupled with the transformer model to encode geolocation context into remote sensing imagery. The Spatioformer model compares favorably to state-of-the-art models in richness predictions on a large-scale ground-truth richness dataset harmonized Australian vegetation plot (HAVPlot) that consists of 68170 in situ richness samples covering diverse landscapes across Australia. The results demonstrate that geolocational information is advantageous in predicting species richness from satellite observations over large spatial scales. With Spatioformer, plant species richness maps over Australia are compiled from the Landsat archive for the years from 2015 to 2023. The richness maps produced in this study reveal the spatiotemporal dynamics of plant species richness in Australia, providing supporting evidence to inform effective planning and policy development for plant diversity conservation. Regions of high richness prediction uncertainties are identified, highlighting the need for future in situ surveys to be conducted in these areas to enhance the prediction accuracy.","2025","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","","63","","","","","","","","","","English","","","","WOS:001420475600003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","Australia; Biodiversity; Context modeling; Data models; DIVERSITY; geolocation encoder; Geology; mapping; Predictive models; Remote sensing; Satellites; species richness; Surveys; transformer; Transformers; vascular plant; Vegetation mapping","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MBQFDDYZ","journalArticle","2024","Fang, Z; Zhan, XF; Ye, BC","X-ray absorption spectroscopy combined with deep learning for auto and rapid illicit drug detection","AMERICAN JOURNAL OF DRUG AND ALCOHOL ABUSE","","0095-2990","10.1080/00952990.2024.2377262","","Background: X-ray absorption spectroscopy (XAS) is a widely used substance analysis technique. It bases on the different absorption coefficients at different energy level to achieve material identification. Additionally, the combination of spectral technology and deep learning can achieve auto detection and high accuracy in material identification.Objectives: Current methods are difficult to identify drugs quickly and nondestructively. Therefore, we explore a novel approach utilizing XAS for the detection of prohibited drugs with common X-ray tube source and photon-counting (PC) detector.Method: To achieve automatic, rapid, and accurate detection of drugs. A CdTe detector and a common X-ray source were used to collect data, then dividing the data into training and testing sets. Finally, the improved transformer encoder model was used for classification. LSTM and ResU-net models are selected for comparation.Result: Fifty substances, which are isomers or compounds with similar molecular formulas of drugs, were selected for experiment substances. The results showed that the improved transformer model achieving 1.4 hours for training time and 96.73% for accuracy, which is better than the LSTM (2.6 hours and 65%) and ResU-net (1.5 hours and 92.7%).Conclusion: It can be concluded that the attention mechanism is more accurate for spectral material identification. XAS combined with deep learning can achieve efficient and accurate drug identification, offering promising application in clinical drug testing and drug enforcement.","2024-07-03","2025-02-26 20:41:56","2025-02-26 20:41:56","","471-480","","4","50","","","","","","","","","","English","","","","WOS:001293955000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","deep learning; Illicit drug testing; METHAMPHETAMINE; X-ray absorption spectroscopy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"46HS9WCB","journalArticle","2024","Moturu, S; Gummadi, SR; Valavala, M; Battula, VVR; Kantamaneni, S","A Novel Transformer Approach for the Recompensed Measurement Generation and Accurate Topology Identification","ENGINEERING LETTERS","","1816-093X","","","Accurate topology identification (TI) is essential for various applications, including fault location, load flow analysis, state estimation and system planning in the distribution networks. However, TI is vulnerable to missing measurements that may arise due to meter malfunctions and communication failure due to denial of service (DoS) attacks. Thus, a robust and novel methodology for accurate TI is proposed in this study. The proposed methodology is divided into two steps: 1) generating the recompensed measurement data by attention mechanismbased transformer model and 2) topology identification from the recompensed measurement data. For evaluating the efficacy of the proposed methodology, a comprehensive study is conducted to assess the influence of renewable energy sources (RES) on the prediction performance. This investigation aims to quantify the degree to which the integration of RES influenced the proposed approach's efficacy and robustness. The proposed approach has been tested and evaluated with varying percentages of missing data such as 10%, 30% and 50%, for the modified IEEE 37 and 69 node system. In addition, a comparative study with various reference models for the missing measurements forecasting is also conducted. The case study results indicate that the proposed approach outperforms other approaches in missing measurement forecasting and TI, while also demonstrating resilience in the context of missing measurements. The proposed approach improved the performance of the system by more than 35% for the 10%, 30%, and 50% missing percentages in the test systems.","2024-03-01","2025-02-26 20:41:56","2025-02-26 20:41:56","","601-613","","3","32","","","","","","","","","","English","","","","WOS:001180520900016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","deep learning; forecasting; measure- ments; missing; SYSTEMS; topology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EA8FE7NZ","journalArticle","2024","Wang, D; Lian, J; Jiao, WZ","Multi-label classification of retinal disease via a novel vision transformer model","FRONTIERS IN NEUROSCIENCE","","1662-453X","10.3389/fnins.2023.1290803","","Introduction The precise identification of retinal disorders is of utmost importance in the prevention of both temporary and permanent visual impairment. Prior research has yielded encouraging results in the classification of retinal images pertaining to a specific retinal condition. In clinical practice, it is not uncommon for a single patient to present with multiple retinal disorders concurrently. Hence, the task of classifying retinal images into multiple labels remains a significant obstacle for existing methodologies, but its successful accomplishment would yield valuable insights into a diverse array of situations simultaneously.Methods This study presents a novel vision transformer architecture called retinal ViT, which incorporates the self-attention mechanism into the field of medical image analysis. To note that this study supposed to prove that the transformer-based models can achieve competitive performance comparing with the CNN-based models, hence the convolutional modules have been eliminated from the proposed model. The suggested model concludes with a multi-label classifier that utilizes a feed-forward network architecture. This classifier consists of two layers and employs a sigmoid activation function.Results and discussion The experimental findings provide evidence of the improved performance exhibited by the suggested model when compared to state-of-the-art approaches such as ResNet, VGG, DenseNet, and MobileNet, on the publicly available dataset ODIR-2019, and the proposed approach has outperformed the state-of-the-art algorithms in terms of Kappa, F1 score, AUC, and AVG.","2024-01-08","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","","17","","","","","","","","","","English","","","","WOS:001153116600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","deep learning; machine vision; medical image analysis; multi-label classification; retinal image","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V2CFEAEF","journalArticle","2023","Kommrusch, S; Monperrus, M; Pouchet, LN","Self-Supervised Learning to Prove Equivalence Between Straight-Line Programs via Rewrite Rules","IEEE TRANSACTIONS ON SOFTWARE ENGINEERING","","0098-5589","10.1109/TSE.2023.3271065","","We target the problem of automatically synthesizing proofs of semantic equivalence between two programs made of sequences of statements. We represent programs using abstract syntax trees (AST), where a given set of semantics-preserving rewrite rules can be applied on a specific AST pattern to generate a transformed and semantically equivalent program. In our system, two programs are equivalent if there exists a sequence of application of these rewrite rules that leads to rewriting one program into the other. We propose a neural network architecture based on a transformer model to generate proofs of equivalence between program pairs. The system outputs a sequence of rewrites, and the validity of the sequence is simply checked by verifying it can be applied. If no valid sequence is produced by the neural network, the system reports the programs as non-equivalent, ensuring by design no programs may be incorrectly reported as equivalent. Our system is fully implemented for one single grammar which can represent straight-line programs with function calls and multiple types. To efficiently train the system to generate such sequences, we develop an original incremental training technique, named self-supervised sample selection. We extensively study the effectiveness of this novel training approach on proofs of increasing complexity and length. Our system,S4Eq, achieves 97% proof success on a curated dataset of 10,000 pairs of equivalent programs.","2023-07","2025-02-26 20:41:56","2025-02-26 20:41:56","","3771-3792","","7","49","","","","","","","","","","English","","","","WOS:001033501500007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;97</p>","","","Machine learning; program equivalence; self-supervised learning; symbolic reasoning; TRANSFORMATIONS; VERIFICATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2QYPDM2G","journalArticle","2022","Yang, F; Wang, WC; Wang, F; Fang, Y; Tang, DY; Huang, JZ; Lu, H; Yao, JH","scBERT as a large-scale pretrained deep language model for cell type annotation of single-cell RNA-seq data","NATURE MACHINE INTELLIGENCE","","2522-5839","10.1038/s42256-022-00534-z","","Annotating cell types on the basis of single-cell RNA-seq data is a prerequisite for research on disease progress and tumour microenvironments. Here we show that existing annotation methods typically suffer from a lack of curated marker gene lists, improper handling of batch effects and difficulty in leveraging the latent gene-gene interaction information, impairing their generalization and robustness. We developed a pretrained deep neural network-based model, single-cell bidirectional encoder representations from transformers (scBERT), to overcome the challenges. Following BERT's approach to pretraining and fine-tuning, scBERT attains a general understanding of gene-gene interactions by being pretrained on huge amounts of unlabelled scRNA-seq data; it is then transferred to the cell type annotation task of unseen and user-specific scRNA-seq data for supervised fine-tuning. Extensive and rigorous benchmark studies validated the superior performance of scBERT on cell type annotation, novel cell type discovery, robustness to batch effects and model interpretability. Cell type annotation is a core task for single cell RNA-sequencing, but current bioinformatic tools struggle with some of the underlying challenges, including high dimensionality, data sparsity, batch effects and a lack of labels. In a self-supervised approach, a transformer model called scBERT is pretrained on millions of unlabelled public single cell RNA-seq data and then fine-tuned with a small number of labelled samples for cell annotation tasks.","2022-10","2025-02-26 20:41:56","2025-02-26 20:41:56","","852-+","","10","4","","","","","","","","","","English","","","","WOS:000859605000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;151<br/>Total Times Cited:&nbsp;&nbsp;158<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CWPU382M","journalArticle","2024","Zhang, SH; Feng, Y; Ren, YH; Guo, ZF; Yu, RJ; Li, RB; Xing, PR","Multi-Modal Emotion Recognition Based on Wavelet Transform and BERT-RoBERTa: An Innovative Approach Combining Enhanced BiLSTM and Focus Loss Function","ELECTRONICS","","2079-9292","10.3390/electronics13163262","","Emotion recognition plays an increasingly important role in today's society and has a high social value. However, current emotion recognition technology faces the problems of insufficient feature extraction and imbalanced samples when processing speech and text information, which limits the performance of existing models. To overcome these challenges, this paper proposes a multi-modal emotion recognition method based on speech and text. The model is divided into two channels. In the first channel, the extended Geneva Minimalistic Acoustic Parameter Set (eGeMAPS) feature set is extracted from OpenSmile, and the original eGeMAPS feature set is merged with the wavelet transformed eGeMAPS feature set. Then, speech features are extracted through a sparse autoencoder. The second channel extracts text features through the BERT-RoBERTa model. Then, deeper text features are extracted through a gated recurrent unit (GRU), and the deeper text features are fused with the text features. Emotions are identified by the attention layer, the dual-layer Bidirectional Long Short-Term Memory (BiLSTM) model, and the loss function, combined with cross-entropy loss and focus loss. Experiments show that, compared with the existing model, the WA and UA of this model are 73.95% and 74.27%, respectively, on the imbalanced IEMOCAP dataset, which is superior to other models. This research result effectively solves the problem of feature insufficiency and sample imbalance in traditional sentiment recognition methods, and provides a new way of thinking for sentiment analysis application.","2024-08","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","16","13","","","","","","","","","","English","","","","WOS:001305041700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","attention layer; BERT-RoBERTa; cross-entropy loss; dual-layer BiLSTM; focus loss; GRU; multi-modal emotion recognition; sparse autoencoder; wavelet transform","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T6V2G3EB","journalArticle","2022","Zhang, SQ; Li, H","The Construction of an Action-Speech Feature-Based School Violence Recognition Algorithm and Occupational Therapy Education Model for Adolescents","OCCUPATIONAL THERAPY INTERNATIONAL","","0966-7903","10.1155/2022/1723736","","This paper constructs an algorithm for youth school violence recognition and an occupational therapy education model for victims through the extraction of action speech features. For the characteristics of violent actions and daily actions, action features in time and frequency domains are extracted and action categories are recognized by BP neural network; for complex actions, it is proposed to decompose complex actions into basic actions to improve the recognition rate; then, LDA dimensionality reduction algorithm is introduced for the problem of the high complexity of algorithm due to high dimensionality of features, and the feature dimensionality is reduced to 8 dimensions by LDA dimensionality reduction algorithm, which reduces the system running time by about 51% and improves the accuracy of violent action recognition by 3.3% while ensuring the overall performance of the system. The LDA dimensionality reduction algorithm reduces the number of features to 8 dimensions, which reduces the running time of the system by 51%, increases the accuracy rate of violent action recognition by 3.3%, and increases the recall rate of violent action recognition by 8.86% while ensuring the overall performance of the system. Based on the classical D-S theory, we proposed an improved D-S evidence fusion algorithm by modifying the original evidence model with a new probability distribution function and constructing new fusion rules, which can solve the fusion conflict problem well. The recall rate for violent actions is increased to 90.0%, thus reducing the missed alarm rate of the system.","2022-05-27","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","","2022","","","","","","","","","","English","","","","WOS:000807448400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","BP NEURAL-NETWORK; CHINA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VIG8UEQR","journalArticle","2023","Mounnan, O; Manad, O; El Mouatasim, A; Boubchir, L; Daachi, B","Deep Speech Recognition System Based on AutoEncoder-GAN for Biometric Access Control","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","Speech recognition-based biometric access control systems are promising solutions that have resolved many issues related to security and convenience. Speech recognition, as a biometric modality, offers unique advantages such as user-friendliness and non-intrusiveness, etc. However, developing robust and accurate speaker identification and authentication systems pose challenges due to variations in speech patterns and environmental factors. Integrating deep learning techniques, especially AutoEncoder and Generative Adversarial Network models, has shown promising results in addressing these challenges. This article presents a novel approach based on the combination of two deep learning models, namely, AE and GAN for speech recognition-based biometric access control. In the model architecture, the AutoEncoder takes the MFCC coefficients as input, and the encoder converts the latter to the latent space, whereas the decoder reconstructs the data. Then, speech features extracted from the latent space are used in the GAN generator to generate additional speech data. The discriminator network has a dual role, serving as both a feature extractor and a classifier. The first extracts relevant features from generated samples, while the latter distinguishes between generated and authentic samples that come from AutoEncoder. This strategy outperforms DNN and LSTM models on VoxCeleb 2, LibriSpeech, and Aishell-1 datasets. The models are trained to minimize Mean Squared Error (MSE) for both the generator and discriminator, aiming at achieving highly realistic datasets and a robust, interpretable model. This approach addresses challenges in feature extraction, data augmentation, realistic biometric samples generation, data variability handling, and data generalization enhancement, providing therefore, a comprehensive solution.","2023-11","2025-02-26 20:41:56","2025-02-26 20:41:56","","1302-1310","","11","14","","","","","","","","","","English","","","","WOS:001126560500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","authentication; biometric access control; Speaker identification; speech recognition; verification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8D6UR7AB","journalArticle","2023","Keelor, JL; Creaghead, NA; Silbert, NH; Breit, AD; Horowitz-Kraus, T","Impact of text-to-speech features on the reading comprehension of children with reading and language difficulties","ANNALS OF DYSLEXIA","","0736-9387","10.1007/s11881-023-00281-9","","This study investigated the reading comprehension scores of students with reading and language difficulties after reading a passage with and without text-to-speech (TTS). Students, ages 8 to 12 years, read five passages under the following conditions: (a) silent read, (b) read aloud, (c) listen only, (d) TTS with no highlighting, and (e) TTS with highlighting. Students answered multiple-choice comprehension questions following each condition. Mixed ANOVAs were performed to determine whether TTS improved reading comprehension. TTS significantly improved comprehension in comparison to no TTS, and specifically, TTS with no highlighting and TTS with highlighting resulted in significantly higher comprehension scores compared to silent read. No other significant differences were found across conditions including between the presentational features of TTS, specifically TTS with no highlighting and TTS with highlighting conditions. Students were grouped as dyslexia only or reading and language impairment based on their test results. Findings suggested that students with dyslexia only scored significantly higher on reading comprehension questions in all reading conditions and derived significantly more benefit in reading comprehension from TTS and the listen only condition compared to students with Reading and Language Impairment. Overall, TTS may be a helpful tool for supporting the reading comprehension of students with reading and language difficulties, particularly for students with dyslexia only; however, further studies are needed to explore the benefits of TTS' presentational features such as highlighting with students with reading and language difficulties.","2023-10","2025-02-26 20:41:56","2025-02-26 20:41:56","","469-486","","3","73","","","","","","","","","","English","","","","WOS:000978490200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","Assistive technology; ASSISTIVE TECHNOLOGY; COMPUTER; DISABILITIES; FLUENCY; INDIVIDUAL-DIFFERENCES; INTERVENTION; Language impairment; READERS; Reading comprehension; Reading difficulty; SIMPLE VIEW; SKILLS; STUDENTS; Text-to-speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZJZGANF7","journalArticle","2023","Zhou, JZ; Duan, YQ; Zou, YY; Chang, YC; Wang, YK; Lin, CT","Speech2EEG: Leveraging Pretrained Speech Model for EEG Signal Recognition","IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING","","1534-4320","10.1109/TNSRE.2023.3268751","","Identifying meaningful brain activities is critical in brain-computer interface (BCI) applications. Recently, an increasing number of neural network approaches have been proposed to recognize EEG signals. However, these approaches depend heavily on using complex network structures to improve the performance of EEG recognition and suffer from the deficit of training data. Inspired by the waveform characteristics and processing methods shared between EEG and speech signals, we propose Speech2EEG, a novel EEG recognition method that leverages pretrained speech features to improve the accuracy of EEG recognition. Specifically, a pretrained speech processing model is adapted to the EEG domain to extract multichannel temporal embeddings. Then, several aggregation methods, including the weighted average, channelwise aggregation, and channel-and-depthwise aggregation, are implemented to exploit and integrate the multichannel temporal embeddings. Finally, a classification network is used to predict EEG categories based on the integrated features. Our work is the first to explore the use of pretrained speech models for EEG signal analysis as well as the effective ways to integrate the multichannel temporal embeddings from the EEG signal. Extensive experimental results suggest that the proposed Speech2EEG method achieves state-of-the-art performance on two challenging motor imagery (MI) datasets, the BCI IV-2a and BCI IV-2b datasets, with accuracies of 89.5% and 84.07%, respectively. Visualization analysis of the multichannel temporal embeddings show that the Speech2EEG architecture can capture useful patterns related to MI categories, which can provide a novel solution for subsequent research under the constraints of a limited dataset scale.","2023","2025-02-26 20:41:56","2025-02-26 20:41:56","","2140-2153","","","31","","","","","","","","","","English","","","","WOS:000981895700002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;110</p>","","","BCI; BRAIN; CLASSIFICATION; DOMAIN; electroencephalogram; INTERFACES; motor imagery; NEURAL-NETWORK; NOISE; SEPARATION; Training; Transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"765R6E2U","journalArticle","2022","Wang, H; Sharma, A; Shabaz, M","Research on digital media animation control technology based on recurrent neural network using speech technology","INTERNATIONAL JOURNAL OF SYSTEM ASSURANCE ENGINEERING AND MANAGEMENT","","0975-6809","10.1007/s13198-021-01540-x","","A vivid and lifelike virtual speaker can attract the user's attention, and the construction of a lifelike virtual speaker not only requires a beautiful static appearance, but also has mouth movements, facial expressions and body movements that are truly synchronized with the voice. Virtual speaker refers to a technology in which a computer generates an animated facial image that can speak. In order to add special effects such as image editing and beautification in the broadcast screen. This paper proposes a voice-driven facial animation synthesis method based on deep BLSTM. A Neural Network BLSTM-RNN Using Audio-Visual Dual Modal Information Training of Speakers, uses the active appearance model to model the face image, and uses the AAM model parameters as Network output, to study the influence of network structure and input of different voice features on the effect of animation synthesis. The experimental results based on the LIPS2008 standard evaluation library show that the network effect with BLSTM layer is obviously better than that of forward network, and the three-layer model structure based on BLSTM-forward- BLSTM 256 node (BFB256) is the best. FBank, fundamental frequency and energy combination can further improve animation synthesis effect. The main aim of this paper is to study the method of speech-driven facial animation synthesis based on deep BLSTM-RNN, and tries the synthesis effect of different neural network structures and different speech features.","2022-03","2025-02-26 20:41:56","2025-02-26 20:41:56","","564-575","","SUPPL 1","13","","","","","","","","","","English","","","","WOS:000765666200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Active appearance model (AAM); BLSTM; Convolutional neural networks (CNNs); Facial animation; Hierarchical features; Language learning; Neural-mechanisms; PREDICTION; Recurrent neural network (RNN); Speech and language; TEXT; Virtual speaker","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UJU5RK8Y","journalArticle","2023","Morandini, JS; Beckman-Scott, D; Madill, C; Dar-Nimrod, I","BIDAR: Can Listeners Detect if a Man Is Bisexual from His Voice Alone?","JOURNAL OF SEX RESEARCH","","0022-4499","10.1080/00224499.2023.2182267","","Previous research has identified a range of perceptual voice and speech features that differ between gay and straight men, enabling listeners to determine if a man is gay or straight at a rate better than chance from his voice alone. To date, no published studies have examined if bisexual men's voices differ from gay and straight men's voices with regard to perceived masculinity-femininity - nor whether listeners can identify a bisexual man based only on his voice. In the present study, we examined if listeners could identify bisexual men's sexual identities from voice recordings. Seventy participants (N= 70) rated 60 voice recordings of a sample of 20 gay, 20 bisexual, and 20 straight Australian men on perceived sexual orientation and degree of masculinity-femininity. Participants could correctly categorize the sexual orientations of the gay and straight speakers at rates greater than chance, but bisexual men were only identified at chance. Bisexual voices were consistently misperceived as being the most exclusively female attracted, and, contrary to expectations, were perceived as the most masculine sounding of all the speakers. Together, these findings suggest that while the voices of bisexual men in our sample were perceived as more masculine and female attracted, listeners do not associate this impression with bisexuality, and thus cannot identify bisexual men from their voices. Consequently, while bisexual men appear to be at lower risk of facing voice-based identification and discrimination than gay men, they may be often misperceived as being straight.","2023-06-13","2025-02-26 20:41:56","2025-02-26 20:41:56","","611-623","","5","60","","","","","","","","","","English","","","","WOS:000946801100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","AROUSAL; ATTITUDES; BEHAVIOR; GAY; MASCULINITY; MENS SEXUAL ORIENTATION; PERSONALITY; PREFERENCES; SEEKING; STRAIGHT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NVSYTWMD","journalArticle","2023","Almadhor, A; Irfan, R; Gao, JC; Saleem, N; Rauf, HT; Kadry, S","E2E-DASR: End-to-end deep learning-based dysarthric automatic speech recognition","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2023.119797","","Dysarthria is a motor speech disability caused by weak muscles and organs involved in the articulation process, thereby affecting the speech intelligibility of individuals. Because this condition is linked to physical exhaustion disabilities, individuals not only have communication difficulties, but also have difficulty interacting with digital devices. Automatic speech recognition (ASR) makes an important difference for individuals with dysarthria since modern digital devices offer a better interaction medium that enables them to interact with their community and computers. Still, the performance of ASR technologies is poor in recognizing dysarthric speech, particularly for acute dysarthria. Multiple challenges, including dysarthric phoneme inaccuracy and labeling imperfection, are facing dysarthric ASR technologies. This paper proposes a spatio-temporal dysarthric ASR (DASR) system using Spatial Convolutional Neural Network (SCNN) and Multi-Head Attention Transformer (MHAT) to visually extract the speech features, and DASR learns the shapes of phonemes pronounced by dysarthric individuals. This visual DASR feature modeling eliminates phoneme-related challenges. The UA-Speech database is utilized in this paper, including different speakers with different speech intelligibility levels. However, because the proportion of us-able speech data to the number of distinctive classes in the UA-speech database was small, the proposed DASR system leverages transfer learning to generate synthetic leverage and visuals. In benchmarking with other DASRs examined in this study, the proposed DASR system outperformed and improved the recognition accuracy for 20.72% of the UA-Speech database. The largest improvements were achieved for very-low (25.75%) and low intelligibility (33.67%).","2023-07-15","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","","222","","","","","","","","","","English","","","","WOS:000952507500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;21<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","CNN; Dysarthria; Dysarthric ASR; FEATURES; Multi-head transformer; Speech intelligibility; SYSTEM; Words error","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LQU4YQR6","journalArticle","2022","Zong, Y; Lian, HL; Chang, HL; Lu, C; Tang, CA","Adapting Multiple Distributions for Bridging Emotions from Different Speech Corpora","ENTROPY","","1099-4300","10.3390/e24091250","","In this paper, we focus on a challenging, but interesting, task in speech emotion recognition (SER), i.e., cross-corpus SER. Unlike conventional SER, a feature distribution mismatch may exist between the labeled source (training) and target (testing) speech samples in cross-corpus SER because they come from different speech emotion corpora, which degrades the performance of most well-performing SER methods. To address this issue, we propose a novel transfer subspace learning method called multiple distribution-adapted regression (MDAR) to bridge the gap between speech samples from different corpora. Specifically, MDAR aims to learn a projection matrix to build the relationship between the source speech features and emotion labels. A novel regularization term called multiple distribution adaption (MDA), consisting of a marginal and two conditional distribution-adapted operations, is designed to collaboratively enable such a discriminative projection matrix to be applicable to the target speech samples, regardless of speech corpus variance. Consequently, by resorting to the learned projection matrix, we are able to predict the emotion labels of target speech samples when only the source label information is given. To evaluate the proposed MDAR method, extensive cross-corpus SER tasks based on three different speech emotion corpora, i.e., EmoDB, eNTERFACE, and CASIA, were designed. Experimental results showed that the proposed MDAR outperformed most recent state-of-the-art transfer subspace learning methods and even performed better than several well-performing deep transfer learning methods in dealing with cross-corpus SER tasks.","2022-09","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","9","24","","","","","","","","","","English","","","","WOS:000857621500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","ADAPTATION; cross-corpus speech emotion recognition; domain adaptation; FEATURES; speech emotion recognition; subspace learning; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UI23W3VT","journalArticle","2022","Daoudi, K; Das, B; Tykalova, T; Klempir, J; Rusz, J","Speech acoustic indices for differential diagnosis between Parkinson's disease, multiple system atrophy and progressive supranuclear palsy","NPJ PARKINSONS DISEASE","","2373-8057","10.1038/s41531-022-00389-6","","While speech disorder represents an early and prominent clinical feature of atypical parkinsonian syndromes such as multiple system atrophy (MSA) and progressive supranuclear palsy (PSP), little is known about the sensitivity of speech assessment as a potential diagnostic tool. Speech samples were acquired from 215 subjects, including 25 MSA, 20 PSP, 20 Parkinson's disease participants, and 150 healthy controls. The accurate differential diagnosis of dysarthria subtypes was based on the quantitative acoustic analysis of 26 speech dimensions related to phonation, articulation, prosody, and timing. A semi-supervised weighting-based approach was then applied to find the best feature combinations for separation between PSP and MSA. Dysarthria was perceptible in all PSP and MSA patients and consisted of a combination of hypokinetic, spastic, and ataxic components. Speech features related to respiratory dysfunction, imprecise consonants, monopitch, slow speaking rate, and subharmonics contributed to worse performance in PSP than MSA, whereas phonatory instability, timing abnormalities, and articulatory decay were more distinctive for MSA compared to PSP. The combination of distinct speech patterns via objective acoustic evaluation was able to discriminate between PSP and MSA with very high accuracy of up to 89% as well as between PSP/MSA and PD with up to 87%. Dysarthria severity in MSA/PSP was related to overall disease severity. Speech disorders reflect the differing underlying pathophysiology of tauopathy in PSP and alpha-synucleinopathy in MSA. Vocal assessment may provide a low-cost alternative screening method to existing subjective clinical assessment and imaging diagnostic approaches.","2022-10-27","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","1","8","","","","","","","","","","English","","","","WOS:000876098600002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","CEREBELLAR; DISORDERS; DYSARTHRIA; ORAL DIADOCHOKINESIS; PATTERNS; PREVALENCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LWE2VDKQ","journalArticle","2025","Jiang, W; Dang, XP; Zhang, R","Empowering Regional Rainfall-Runoff Modeling Through Encoder-Decoder Based on Convolutional Neural Networks","WATER","","2073-4441","10.3390/w17030339","","Regional rainfall-runoff modeling is a classic and significant research topic in hydrological sciences. Currently, the predominant modeling approach is developing data-driven models. This study proposes a rainfall-runoff model named ED-TimesNet (Encoder-Decoder-based TimesNet), which consists of convolutional neural networks. It transforms a one-dimensional time series into a two-dimensional matrix based on frequency-domain partitioning rules and subsequently employs a two-dimensional visual backbone to learn both local and global features of the hydrological time series. Compared to LSTM-based models and Transformer models, this model learns both intra-period and inter-period variations in hydrological series, simultaneously focusing on the relationships between adjacent and non-adjacent time points. It alleviates the temporal ambiguity problem inherent in attention mechanisms. This research validates the performance of the ED-TimesNet model in regional rainfall-runoff modeling tasks using the Catchment Attributes and Meteorology for Large-sample Studies (CAMELS) dataset. The model achieves a median and mean NSE of 0.8049 and 0.7808, respectively, across 448 basins, outperforming the benchmark LSTM, VIC, and mHM models, and achieving comparable performance to the Transformer model. This paper does not address the model's performance on ungauged basins. The method of predicting runoff based on the periodic features of hydrological data provides a novel perspective for hydrological sciences.","2025-02","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","3","17","","","","","","","","","","English","","","","WOS:001419223900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","convolutional neural networks; DATA SET; encoder-decoder structure; PART; regional rainfall-runoff modeling; two-dimensional variation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TAJCEXBX","journalArticle","2024","Zhang, YW; Wang, BY; Hong, Y; Zhang, S","Development of Women's Shirt Style Recognition Model (WSSRM) based on a ResNet and Transformer integrated method","TEXTILE RESEARCH JOURNAL","","0040-5175","10.1177/00405175241290521","","The rise of e-commerce has brought women's shirt images to the forefront, showcasing complex styles and diverse features. This presents a challenge for consumers in finding their preferred styles. Deep learning, known for its speed and superior retrieval performance, offers a solution by learning image features through multi-layer neural networks and extracting high-level semantic information, making it highly effective for recognizing and classifying clothing styles. The ResNet model excels in extracting detailed pixel information, but has limitations: (1) Jump connections in ResNet, which add input directly to the output in the residual block, can cause feature distortion, especially when input and output sizes do not match; (2) Despite many network layers, the effective receptive field of ResNet is smaller than theoretically expected. To address these limitations, this paper introduces the Transformer model into ResNet, proposing a new method for recognizing and classifying women's shirt styles based on local detail feature extraction. The Transformer's attention mechanism enhances the model's ability to focus on important features and suppress less relevant ones, improving the accuracy of local detail feature extraction. This study examines six typical women's shirt style features, applying the improved ResNet to their recognition and classification, resulting in a highly accurate and reliable model. This theoretical and practical advancement enhances the recognition of detailed features in women's shirts, significantly contributing to the development of intelligent clothing design.","2024-12-24","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","","","","","","","","","","","","English","","","","WOS:001382350400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","design intelligence; local features; ResNet. Transformer; Style recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LCZXJRN7","journalArticle","2024","Zhang, QY; Zuo, H; Cui, XQ; Yuan, XY; Hu, TZ","Automatic Compressive Sensing of Shack-Hartmann Sensors Based on the Vision Transformer","PHOTONICS","","2304-6732","10.3390/photonics11110998","","Shack-Hartmann wavefront sensors (SHWFSs) are crucial for detecting distortions in adaptive optics systems, but the accuracy of wavefront reconstruction is often hampered by low guide star brightness or strong atmospheric turbulence. This study introduces a new method of using the Vision Transformer model to process image information from SHWFSs. Compared with previous traditional methods, this model can assign a weight value to each subaperture by considering the position and image information of each subaperture of this sensor, and it can process to obtain wavefront reconstruction results. Comparative evaluations using simulated SHWFS light intensity images and corresponding deformable mirror command vectors demonstrate the robustness and accuracy of the Vision Transformer under various guide star magnitudes and atmospheric conditions, compared to convolutional neural networks (CNNs), represented in this study by Residual Neural Network (ResNet), which are widely used by other scholars. Notably, normalization preprocessing significantly improves the CNN performance (improving Strehl ratio by up to 0.2 under low turbulence) while having a varied impact on the Vision Transformer, improving its performance under a low turbulence intensity and high brightness (Strehl ratio up to 0.8) but deteriorating under a high turbulence intensity and low brightness (Strehl ratio reduced to about 0.05). Overall, the Vision Transformer consistently outperforms CNN models across all tested conditions, enhancing the Strehl ratio by an average of 0.2 more than CNNs.","2024-11","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","11","11","","","","","","","","","","English","","","","WOS:001365901500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","adaptive optics; compressive sensing; deep learning; RECONSTRUCTION; Shack-Hartmann sensor; WAVE-FRONT SENSOR","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4EUMIASR","journalArticle","2024","Liang, AB; Chai, XL; Sun, Y; Guizani, M","GTformer: Graph-Based Temporal-Order-Aware Transformer for Long-Term Series Forecasting","IEEE INTERNET OF THINGS JOURNAL","","2327-4662","10.1109/JIOT.2024.3419768","","In the production environment of the Internet of Things (IoT), sensors of various qualities generate a large amount of multivariate time series (MTS) data. The long-term prediction of time series data generated by various IoT devices provides longer foresight and helps execute necessary resource scheduling or fault alarms in advance, thus improving the efficiency of system operation and ensuring system security. In recent years, deep learning models like Transformers have achieved advanced performance in multivariate long-term time series forecasting (MLTSF) tasks. However, many previous research attempts either overlooked the interseries dependencies or ignored the need to model the strict temporal order of MTS data. In this article, we introduce GTformer, a graph-based temporal-order-aware transformer model. We propose an adaptive graph learning method specifically designed for MTS data to capture both uni-directional and bi-directional relations. In addition, we generate positional encoding in a sequential way to emphasize the strict temporal order of time series. By adopting these two components, our model can have a better understanding of the interseries and intraseries dependencies of MTS data. We conducted extensive experiments on eight real-world data sets, and the results show that our model achieves better predictions compared with state-of-the-art methods.","2024-10-01","2025-02-26 20:41:56","2025-02-26 20:41:56","","31467-31478","","19","11","","","","","","","","","","English","","","","WOS:001322588600053","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Data models; Forecasting; INTERNET; Internet of Things; Interseries dependencies; long-term time series forecasting; multivariate time series (MTS); NETWORK; Predictive models; strict temporal order; Task analysis; Time series analysis; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H76KYN98","journalArticle","2024","Li, JH; Wang, K; Hou, XW; Lan, DP; Wu, YW; Wang, HJ; Liu, L; Mumtaz, S","A Dual-Scale Transformer-Based Remaining Useful Life Prediction Model in Industrial Internet of Things","IEEE INTERNET OF THINGS JOURNAL","","2327-4662","10.1109/JIOT.2024.3376706","","With recent advances of Industrial Internet of Things (IIoT), the connectivity and data collection capabilities of industrial equipment have be significantly enhanced, yet bringing new challenges for the remaining useful life (RUL) prediction. To fulfill the RUL predicting demand in multivariate time series, this work proposes an encoder-decoder model termed as dual-scale transformer model (DSFormer), built upon the Transformer architecture. First, in the encoder part, a dual-attention module is designed for the weight feature extraction from both dimensions of the sensor and time series, aiming to compensate for the diverse impacts of different sensors on the prediction. Next, a temporal convolutional network (TCN) module is introduced to capture sequence features and alleviate the loss of positional information incurred by stacking blocks. Then, the feature decomposition module is integrated into the decoder for trend feature extraction from sequences, providing the model with additional sequence information. Finally, compared to existing models, the proposed method can obtain the superior performance in terms of the root mean square error (RMSE) and Score metrics on the FD001, FD002 and FD003 subsets of the C-MAPSS data set, with an average improvement of 3.2% and 2.5%, respectively. In particular, the ablation experiment further validates the effectiveness of proposed modules in handling multivariate time series and extracting features.","2024-08-15","2025-02-26 20:41:56","2025-02-26 20:41:56","","26656-26667","","16","11","","","","","","","","","","English","","","","WOS:001291138800039","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Attention mechanism; Data models; Feature extraction; HEALTH PROGNOSTICS; Industrial Internet of Things; Industrial Internet of Things (IIoT); multisensor data; Predictive models; remaining useful life (RUL); Sensors; Time series analysis; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G34LJSGK","journalArticle","2024","Wang, PJ; Long, QL; Zhang, H; Chen, X; Yu, R; Guo, FQ","Forecasting and Multilevel Early Warning of Wind Speed Using an Adaptive Kernel Estimator and Optimized Gated Recurrent Units","MATHEMATICS","","2227-7390","10.3390/math12162581","","Accurately predicting wind speeds is of great significance in various engineering applications, such as the operation of high-speed trains. Machine learning models are effective in this field. However, existing studies generally provide deterministic predictions and utilize decomposition techniques in advance to enhance predictive performance, which may encounter data leakage and fail to capture the stochastic nature of wind data. This work proposes an advanced framework for the prediction and early warning of wind speeds by combining the optimized gated recurrent unit (GRU) and adaptive kernel density estimator (AKDE). Firstly, 12 samples (26,280 points each) were collected from an extensive open database. Three representative metaheuristic algorithms were then employed to optimize the parameters of diverse models, including extreme learning machines, a transformer model, and recurrent networks. The results yielded an optimal selection using the GRU and the crested porcupine optimizer. Afterwards, by using the AKDE, the joint probability density and cumulative distribution function of wind predictions and related predicting errors could be obtained. It was then applicable to calculate the conditional probability that actual wind speed exceeds the critical value, thereby providing probabilistic-based predictions in a multilevel manner. A comparison of the predictive performance of various methods and accuracy of subsequent decisions validated the proposed framework.","2024-08","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","16","12","","","","","","","","","","English","","","","WOS:001305573200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","ALGORITHM; ARIMA; cumulative distribution function; EXTREME LEARNING-MACHINE; gated recurrent unit; kernel density estimation; machine learning; metaheuristic optimization; NETWORK; PREDICTION MODEL; VARIATIONAL MODE DECOMPOSITION; wind speed forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3NE3TGLX","journalArticle","2024","Tarchi, C; Zappoli, A; Ledesma, LC; Brante, EW","The Use of ChatGPT in Source-Based Writing Tasks","INTERNATIONAL JOURNAL OF ARTIFICIAL INTELLIGENCE IN EDUCATION","","1560-4292","10.1007/s40593-024-00413-1","","ChatGPT, a chatbot based on a Generative Pre-trained Transformer model, can be used as a teaching tool in the educational setting, providing text in an interactive way. However, concerns point out risks and disadvantages, as possible incorrect or irrelevant answers, privacy concerns, and copyright issues. This study aims to categorize the strategies used by undergraduate students completing a source-based writing task (SBW, i.e., written production based on texts previously read) with the help of ChatGPT and their relation to the quality and content of students' written products. ChatGPT can be educationally useful in SBW tasks, which require the synthesis of information from a text in response to a prompt. SBW requires mastering writing conventions and an accurate understanding of source material. We collected 27 non-expert users of ChatGPT and writers (Mage = 20.37; SD = 2.17). We administered a sociodemographic questionnaire, an academic writing motivation scale, and a measure of perceived prior knowledge. Participants were given a source-based writing task with access to ChatGPT as external aid. They performed a retrospective think-aloud interview on ChatGPT use. Data showed limited use of ChatGPT due to limited expertise and ethical concerns. The level of integration of conflicting information showed to not be associated with the interaction with ChatGPT. However, the use of ChatGPT showed a negative association with the amount of literal source-text information that students include in their written product.","2024-06-19","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","","","","","","","","","","","","English","","","","WOS:001250248300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Argumentative Writing; Artificial Intelligence; Higher Education; INTEGRATION; PERFORMANCE; Source-based Writing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AE3JWMMB","journalArticle","2024","Hemalakshmi, GR; Murugappan, M; Sikkandar, MY; Begum, SS; Prakash, NB","Automated retinal disease classification using hybrid transformer model (SViT) using optical coherence tomography images","NEURAL COMPUTING & APPLICATIONS","","0941-0643","10.1007/s00521-024-09564-7","","Optical coherence tomography (OCT) is a widely used imaging technique in ophthalmology for diagnosis and treatment. Recent advances in deep neural networks (DNNs) and vision transformers (ViTs) have paved the way for automated eye/retinal disease classifications and segmentations using OCT or spectral domain OCT (SD-OCT) images. Diabetic macular edema (DME), choroidal neovascularization (CNV), and Drusen are particularly challenging to accurately classify using OCT images because of their subtle differences and intricate features. Currently, the algorithms reported in the literature using DNNs or ViTs are computationally complex, consider fewer diseases, and are less accurate. This study proposes a hybrid SqueezeNet-vision transformer (SViT) model that combines the strengths of SqueezeNet and vision transformer (ViT), capturing local and global features of OCT images to achieve more accurate classification with less computational complexity. The proposed model uses the OCT2017 dataset for training, testing, and validation, and it performs both binary classification (normal vs disorders) as well as multiclass classification (DME, CNV, Drusen, and normal). As compared to state-of-the-art CNN-based and standalone Transformer models, the proposed SViT model achieves an overall classification accuracy of 99.90% for multiclass classification (CNV: 100%, DME: 99.9%, Drusen: 100%, and normal: 100%). With a good generalization ability, the model can be used to improve patient care and clinical decision-making across a broader range of applications.","2024-02-23","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","","","","","","","","","","","","English","","","","WOS:001167510900004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Classification; CNN; Eye disorders; Hybrid model; LEARNING APPROACH; OCT; Retinal diseases; SqueezeNet; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MNB5YVUB","journalArticle","2024","Gendy, G; Sabor, N; He, GH","Lightweight image super-resolution network based on extended convolution mixer","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2024.108069","","The single image super -resolution (SISR) is a computer vision task needed in many real -world applications. There are many methods developed to solve ill -posed SISR problem; however, these methods are based on attention mechanisms that need a large computing processing cost. So, these attention -based models cannot be used in real -world applications that need fast models. Thus, we propose an enhanced convolution mixer (EConvMixer) module to solve this SISR problem by using lower computing convolution layers. The EConvMixer is designed based on utilizing three convolution types, namely the dilated depthwise convolution for increasing the receptive field, the depthwise convolution for mixing spatial locations, and the pointwise convolution for mixing channel locations. Based on using this EConvMixer layer, we build a lightweight extended convolution mixer network (EConvMixN) for SR images. The EConvMixN has the spirit of the transformer model but with a low computational complexity using only convolution layers. It is clear that our model achieves appealing visual quality and reconstruction accuracy. Also, the EConvMixN model is faster than the state-of-the-art results at different SR scales. Moreover, the EConvMixN achieves state-of-the-art runtime in multiple SR scales. Finally, our model improves PSNR compared to CoMoNet-S by 0.12 dB and 0.08 dB for datasets of Set5 and Set14 at the scale of x 3.","2024-07","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","","133","","","","","","","","","","English","","","","WOS:001198514900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","Depthwise convolution; Extended convolution mixer layer; Image super-resolution; Lightweight super-resolution model; Pointwise convolution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V99WKBF4","journalArticle","2023","Moezzi, SAR; Ghaedi, A; Rahmanian, M; Mousavi, SZ; Sami, A","Application of Deep Learning in Generating Structured Radiology Reports: A Transformer-Based Technique","JOURNAL OF DIGITAL IMAGING","","0897-1889","10.1007/s10278-022-00692-x","","Since radiology reports needed for clinical practice and research are written and stored in free-text narrations, extraction of relative information for further analysis is difficult. In these circumstances, natural language processing (NLP) techniques can facilitate automatic information extraction and transformation of free-text formats to structured data. In recent years, deep learning (DL)-based models have been adapted for NLP experiments with promising results. Despite the significant potential of DL models based on artificial neural networks (ANN) and convolutional neural networks (CNN), the models face some limitations to implement in clinical practice. Transformers, another new DL architecture, have been increasingly applied to improve the process. Therefore, in this study, we propose a transformer-based fine-grained named entity recognition (NER) architecture for clinical information extraction. We collected 88 abdominopelvic sonography reports in free-text formats and annotated them based on our developed information schema. The text-to-text transfer transformer model (T5) and Scifive, a pre-trained domain-specific adaptation of the T5 model, were applied for fine-tuning to extract entities and relations and transform the input into a structured format. Our transformer-based model in this study outperformed previously applied approaches such as ANN and CNN models based on ROUGE-1, ROUGE-2, ROUGE-L, and BLEU scores of 0.816, 0.668, 0.528, and 0.743, respectively, while providing an interpretable structured report.","2023-02","2025-02-26 20:41:56","2025-02-26 20:41:56","","80-90","","1","36","","","","","","","","","","English","","","","WOS:000843983800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Deep learning; EXTRACTION; Named entity recognition; Natural language processing; Relation extraction; Structured reporting; TEXT; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HYWLDCJ5","journalArticle","2025","Kirubavathi, G; Sumathi, IR; Mahalakshmi, J; Srivastava, D","Detection and mitigation of TCP-based DDoS attacks in cloud environments using a self-attention and intersample attention transformer model","JOURNAL OF SUPERCOMPUTING","","0920-8542","10.1007/s11227-025-06940-5","","TCP-based Distributed Denial of Service (DDoS) attacks pose a significant danger to cloud infrastructures because they can imitate genuine traffic patterns, making them difficult to detect using standard approaches. This study introduces the Self-Attention and Intersample Attention Transformer (SAINT) model, a unique deep learning architecture that incorporates Sparse Logistic Regression to address these issues. The SAINT framework uses dual attention mechanisms-self-attention for capturing complicated intraflow dependencies and intersample attention for assessing interflow relationships-to provide enhanced detection of malicious traffic. SAINT, unlike existing methodologies, prioritizes scalability, interpretability, and computational efficiency, distinguishing it from traditional models such as CNNs, RNNs, and ensemble techniques. The model's efficacy was evaluated using the BCCC-cPacket-Cloud-DDoS-2024 dataset, which included 700,000 traffic flows across 17 advanced attack scenarios, with state-of-the-art metrics: 95% precision, 95% recall, 96% F1 score, and 97% accuracy. Furthermore, studies on the CICDDoS2019 dataset confirmed SAINT's resilience and flexibility to a variety of network conditions. SAINT addresses real-world issues in cloud-based DDoS detection, such as temporal and spatial traffic complexities, to provide a viable, high performance solution for protecting current cloud infrastructures. This work establishes the groundwork for scalable, adaptable, and efficient cloud-native security frameworks, paving the path for enhanced countermeasures to changing cyber threats.","2025-02","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","3","81","","","","","","","","","","English","","","","WOS:001418812100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","Anomaly detection; Cloud security; Cloud-native security; Deep learning; Network traffic analysis; TCP vulnerabilities; TCP-based DDoS attacks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9PSRPBBC","journalArticle","2024","Pehlivan, S; Laaksonen, J","Temporal teacher with masked transformers for semi-supervised action proposal generation","MACHINE VISION AND APPLICATIONS","","0932-8092","10.1007/s00138-024-01521-7","","By conditioning on unit-level predictions, anchor-free models for action proposal generation have displayed impressive capabilities, such as having a lightweight architecture. However, task performance depends significantly on the quality of data used in training, and most effective models have relied on human-annotated data. Semi-supervised learning, i.e., jointly training deep neural networks with a labeled dataset as well as an unlabeled dataset, has made significant progress recently. Existing works have either primarily focused on classification tasks, which may require less annotation effort, or considered anchor-based detection models. Inspired by recent advances in semi-supervised methods on anchor-free object detectors, we propose a teacher-student framework for a two-stage action detection pipeline, named Temporal Teacher with Masked Transformers (TTMT), to generate high-quality action proposals based on an anchor-free transformer model. Leveraging consistency learning as one self-training technique, the model jointly trains an anchor-free student model and a gradually progressing teacher counterpart in a mutually beneficial manner. As the core model, we design a Transformer-based anchor-free model to improve effectiveness for temporal evaluation. We integrate bi-directional masks and devise encoder-only Masked Transformers for sequences. Jointly training on boundary locations and various local snippet-based features, our model predicts via the proposed scoring function for generating proposal candidates. Experiments on the THUMOS14 and ActivityNet-1.3 benchmarks demonstrate the effectiveness of our model for temporal proposal generation task.","2024-05","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","3","35","","","","","","","","","","English","","","","WOS:001184315700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Anchor-free model; Semi-supervised learning; Temporal proposal generation; Transformer network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BP8UAUML","journalArticle","2024","Ma, ZC; Li, K","LASFormer: Light Transformer for Action Segmentation with Receptive Field-Guided Distillation and Action Relation Encoding","MATHEMATICS","","2227-7390","10.3390/math12010057","","Transformer-based models for action segmentation have achieved high frame-wise accuracy against challenging benchmarks. However, they rely on multiple decoders and self-attention blocks for informative representations, whose huge computing and memory costs remain an obstacle to handling long video sequences and practical deployment. To address these issues, we design a light transformer model for the action segmentation task, named LASFormer, with a novel encoder-decoder structure based on three key designs. First, we propose a receptive field-guided distillation to realize mode reduction, which can overcome more generally the gap in semantic feature structure between the intermediate features by aggregated temporal dilation convolution (ATDC). Second, we propose a simplified implicit attention to replace self-attention to avoid its quadratic complexity. Third, we design an efficient action relation encoding module embedded after the decoder, where the temporal graph reasoning introduces an inductive bias that adjacent frames are more likely to belong to the same class of model global temporal relations, and the cross-model fusion structure integrates frame-level and segment-level temporal clues, which can avoid over-segmentation independent of multiple decoders, thus reducing further computational complexity. Extensive experiments have verified the effectiveness and efficiency of the framework. Against the challenging 50Salads, GTEA, and Breakfast benchmarks, LASFormer significantly outperforms the current state-of-the-art methods in accuracy, edit score, and F1 score.","2024-01","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","1","12","","","","","","","","","","English","","","","WOS:001140708100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","action relation encoding; action segmentation; light transformer; model reduction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AWASIWBP","journalArticle","2023","Gharawi, A; Alahmadi, MD; Ramaswamy, L","Self-Supervised Skin Lesion Segmentation: An Annotation-Free Approach","MATHEMATICS","","2227-7390","10.3390/math11183805","","Skin cancer poses a significant health risk, affecting multiple layers of the skin, including the dermis, epidermis, and hypodermis. Melanoma, a severe type of skin cancer, originates from the abnormal proliferation of melanocytes in the epidermis. Current methods for skin lesion segmentation heavily rely on large annotated datasets, which are costly, time-consuming, and demand specialized expertise from dermatologists. To address these limitations and improve logistics in dermatology practices, we present a self-supervised strategy for accurate skin lesion segmentation in dermatologist images, eliminating the need for manual annotations. Unlike the traditional appraoch, our proposed approach integrates a hybrid CNN/Transformer model, harnessing the complementary strengths of both architectures. The Transformer module captures long-range contextual dependencies, enabling a comprehensive understanding of image content, while the CNN encoder extracts local semantic information. To dynamically recalibrate the representation space, we introduce a contextual attention module that effectively combines hierarchical features and pixel-level information. By incorporating local and global dependencies among image pixels, we perform a clustering process that organizes the image content into a meaningful space. Furthermore, as another contribution, we incorporate a spatial consistency loss to promote the gradual merging of clusters with similar representations, thereby improving the segmentation quality. Experimental evaluations conducted on two publicly available skin lesion segmentation datasets demonstrate the superiority of our proposed method, outperforming both unsupervised and self-supervised strategies, and achieving state-of-the-art performance in this challenging task.","2023-09","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","18","11","","","","","","","","","","English","","","","WOS:001071982200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","deep learning; Laplacian Transformer; texture segmentation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YN5ED97R","journalArticle","2023","Wu, Y; Che, YW; Wang, QF; Zhang, JQ; Li, XQ; Tang, XF","A Wide-Band Modeling Research of Voltage Transformer in EMU","ELECTRONICS","","2079-9292","10.3390/electronics12132844","","Considering that current voltage transformer models of electrical multiple units (EMUs) are narrow-band models or transformer models, this paper introduces a wide-band model of EMU voltage transformers based on the vector fitting method, circuit synthesis theory and black-box model theory. The admittances of voltage transformers from 30 kHz to 5 MHz are measured by the vector network analyzer, the branch admittances in the pi-type equivalent circuit are calculated according to the equation of a two-port network equivalent circuit. Based on the vector matching method, the rational function formulas of branch admittances are obtained, and the formulas are converted into the circuit models by circuit synthesis theory. The pi-type equivalent circuit model is constructed in the simulation software, and so is the voltage transformer model in the range of 30 kHz-5 MHz. The frequency sweeping method is used to measure the transmission characteristics from direct current (DC)to 30 kHz. The pi-type model is modified according to transmission characteristics, whereby the wide-band model in DC-5 MHz is obtained. Fast pulse experiments are carried out on the voltage transformer, and the actual injected fast pulse voltage is used as the excitation source in the simulation model. The measurement and simulation results on the secondary side of the voltage transformer show that the wide-band model has a high accuracy.","2023-07","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","13","12","","","","","","","","","","English","","","","WOS:001028369500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;14</p>","","","black-box model; vector fitting method; voltage transformer; wide-band model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CG8P7RY3","journalArticle","2023","Chen, ZH; He, C","Transformer-Based Unsupervised Cross-Sensor Domain Adaptation for Electromechanical Actuator Fault Diagnosis","MACHINES","","2075-1702","10.3390/machines11010102","","There have been some successful attempts to develop data-driven fault diagnostic methods in recent years. A common assumption in most studies is that the data of the source and target domains are obtained from the same sensor. Nevertheless, because electromechanical actuators may have complex motion trajectories and mechanical structures, it may not always be possible to acquire the data from a particular sensor position. When the sensor locations of electromechanical actuators are changed, the fault diagnosis problem becomes further complicated because the feature space is significantly distorted. The literature on this subject is relatively underdeveloped despite its critical importance. This paper introduces a Transformer-based end-to-end cross-sensor domain fault diagnosis method for electromechanical actuators to overcome these obstacles. An enhanced Transformer model is developed to obtain domain-stable features at various sensor locations. A convolutional embedding method is also proposed to improve the model's ability to integrate local contextual information. Further, the joint distribution discrepancy between two sensor domains is minimized by using Joint Maximum Mean Discrepancy. Finally, the proposed method is validated using an electromechanical actuator dataset. Twenty-four transfer tasks are designed to validate cross-sensor domain adaptation fault diagnosis problems, covering all combinations of three sensor locations under different operating conditions. According to the results, the proposed method significantly outperforms the comparative method in terms of varying sensor locations.","2023-01","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","1","11","","","","","","","","","","English","","","","WOS:000915198400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","cross-sensor; electro-mechanical actuators; fault diagnosis; NEURAL-NETWORK; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WR3DBHC4","journalArticle","2021","Trichtchenko, L","Frequency Considerations in GIC Applications","SPACE WEATHER-THE INTERNATIONAL JOURNAL OF RESEARCH AND APPLICATIONS","","1542-7390","10.1029/2020SW002694","","Geomagnetically induced currents (GIC) are a phenomenon well known for its negative effects on the operations of power systems. To efficiently mitigate them requires different types of power system modeling, from GIC to alternating current harmonic generation, to three-dimensional finite element models of transformers. GIC are initiated by variations of the geomagnetic field in the presence of the conductive Earth, that is, the geophysical variables characterized by continuous frequency spectra, making GIC also exhibit continuous spectra. In order to adequately estimate their variations and peak values for mitigation purposes, an analysis is required of how sampling rate and spectral frequency content impact the measured characteristics of GIC and harmonics. The study is based on the geomagnetic measurements and the power network data (i.e., GIC and harmonics) with high sampling rates recorded during two geomagnetic storms, March 31, 2001 and July 26-27, 2004. Availability of data covering both the source and the result of geomagnetic storm impacts on power grid allows (a) analysis of the influence of spectral content on adequate representation of both geomagnetic and geoelectric variations during the intervals with significant increases in GIC and harmonics and (b) identifying the sampling rate sufficient to usefully represent the network response presented as GIC and harmonics variations. In summary, the adequate sampling rate is suggested and the deficiencies associated with undersampling of the geoelectric and GIC variations are identified and discussed.","2021-08","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","8","19","","","","","","","","","","English","","","","WOS:000688191800005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","ENHANCED TRANSFORMER MODEL; FIELD VARIATIONS; geoelectric fields; geomagnetic storms; geomagnetically induced currents; GEOMAGNETICALLY INDUCED CURRENTS; harmonics; POWER TRANSFORMERS; SIMULATION; SURFACE; TRANSIENTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M4QG7I9J","journalArticle","2024","Ye, RC; Qian, YQ; Huang, XM","RT-CBAM: Refined Transformer Combined with Convolutional Block Attention Module for Underwater Image Restoration","SENSORS","","1424-8220","10.3390/s24185893","","Recently, transformers have demonstrated notable improvements in natural advanced visual tasks. In the field of computer vision, transformer networks are beginning to supplant conventional convolutional neural networks (CNNs) due to their global receptive field and adaptability. Although transformers excel in capturing global features, they lag behind CNNs in handling fine local features, especially when dealing with underwater images containing complex and delicate structures. In order to tackle this challenge, we propose a refined transformer model by improving the feature blocks (dilated transformer block) to more accurately compute attention weights, enhancing the capture of both local and global features. Subsequently, a self-supervised method (a local and global blind-patch network) is embedded in the bottleneck layer, which can aggregate local and global information to enhance detail recovery and improve texture restoration quality. Additionally, we introduce a multi-scale convolutional block attention module (MSCBAM) to connect encoder and decoder features; this module enhances the feature representation of color channels, aiding in the restoration of color information in images. We plan to deploy this deep learning model onto the sensors of underwater robots for real-world underwater image-processing and ocean exploration tasks. Our model is named the refined transformer combined with convolutional block attention module (RT-CBAM). This study compares two traditional methods and six deep learning methods, and our approach achieved the best results in terms of detail processing and color restoration.","2024-09","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","18","24","","","","","","","","","","English","","","","WOS:001323212000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","deep learning; ENHANCEMENT; image restoration; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9PM4IVGV","journalArticle","2024","Valdivielso, JU; Aizpurua, JI; Inarra, MB","Uncertainty Distribution Assessment of Jiles-Atherton Parameter Estimation for Inrush Current Studies","IEEE TRANSACTIONS ON POWER DELIVERY","","0885-8977","10.1109/TPWRD.2024.3398790","","Transformers are one of the key assets in AC distribution grids and renewable power integration. During transformer energization inrush currents appear, which lead to transformer degradation and can cause grid instability events. These inrush currents are a consequence of the transformer's magnetic core saturation during its connection to the grid. Transformer cores are normally modelled by the Jiles-Atherton (JA) model which contains five parameters. These parameters can be estimated by metaheuristic-based search algorithms. The parameter initialization of these algorithms plays an important role in the algorithm convergence. The most popular strategy used for JA parameter initialization is a random uniform distribution. However, techniques such as parameter initialization by Probability Density Functions (PDFs) have shown to improve accuracy over random methods. In this context, this research work presents a framework to assess the impact of different parameter initialization strategies on the performance of the JA parameter estimation for inrush current studies. Depending on available data and expert knowledge, uncertainty levels are modelled with different PDFs. Moreover, three different metaheuristic-search algorithms are employed on two different core materials and their accuracy and computational time are compared. Results show an improvement in the accuracy and computational time of the metaheuristic-based algorithms when PDF parameter initialization is used.","2024-08","2025-02-26 20:41:56","2025-02-26 20:41:56","","2275-2285","","4","39","","","","","","","","","","English","","","","WOS:001277988400047","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Circuit faults; Current transformers; ELIMINATION; HYSTERESIS; IDENTIFICATION; Inrush current; jiles-Atherton model; Magnetization; metaheuristic-based search; PART I; PREDICTIONS; probability density function; Probability density function; transformer; Transformer cores; TRANSFORMER MODEL; uncertainty; Uncertainty","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H5MS6QRQ","journalArticle","2024","Gu, Q; Zhang, H; Cai, R; Sui, SY; Wang, R","Segmentation of liver CT images based on weighted medical transformer model","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-60594-6","","Deep convolutional neural networks have made significant strides in the field of medical image segmentation. Although existing convolutional structures enhance performance by leveraging local image information, they often lose the interdependence information between contexts. Therefore, the article utilizes the multi-attention mechanism of the Transformer structure to more comprehensively express relationships between contexts and introduced the Transformer network architecture into the field of medical image segmentation. Most models based on this Transformer structure typically require large datasets for training. However, in the medical field, the limited size of datasets makes training models with the Transformer structure challenging. To address this, the article propose a Weighted Medical Transformer (WMT) model that imposes low requirements on dataset quantity. The weighting mechanism in the WMT model aims to improve the issue of inaccurate relative positional coding when dealing with small medical datasets. Additionally, a coarse-grained and fine-grained segmentation mechanism is introduced, focusing on both the detailed aspects within image blocks and the boundary information connecting blocks. Experimental results on a liver dataset demonstrate that the model achieves F1 and IoU scores of 88.48% and 79.41%, respectively. Results on the MoNuSeg dataset show comparable high F1 and IoU scores of 79.58% and 66.19%, respectively. The model's accuracy surpasses that of U-Net++ and U-Net models. Compared to other models, this approach is applicable to scenarios with limited datasets, exhibiting high execution efficiency and accuracy.","2024-04-30","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","1","14","","","","","","","","","","English","","","","WOS:001225890200057","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;85</p>","","","ANXIETY; BEHAVIORAL IMMUNE-SYSTEM; COVID-19; DEPRESSION; DISGUST; DISORDER; FEAR; INFORMATION; INSULAR CORTEX; RESPONSES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YF2WMHGH","journalArticle","2024","Kwak, IY; Kim, BC; Lee, J; Kang, T; Garry, DJ; Zhang, JY; Gong, WM","Proformer: a hybrid macaron transformer model predicts expression values from promoter sequences","BMC BIOINFORMATICS","","1471-2105","10.1186/s12859-024-05645-5","","The breakthrough high-throughput measurement of the cis-regulatory activity of millions of randomly generated promoters provides an unprecedented opportunity to systematically decode the cis-regulatory logic that determines the expression values. We developed an end-to-end transformer encoder architecture named Proformer to predict the expression values from DNA sequences. Proformer used a Macaron-like Transformer encoder architecture, where two half-step feed forward (FFN) layers were placed at the beginning and the end of each encoder block, and a separable 1D convolution layer was inserted after the first FFN layer and in front of the multi-head attention layer. The sliding k-mers from one-hot encoded sequences were mapped onto a continuous embedding, combined with the learned positional embedding and strand embedding (forward strand vs. reverse complemented strand) as the sequence input. Moreover, Proformer introduced multiple expression heads with mask filling to prevent the transformer models from collapsing when training on relatively small amount of data. We empirically determined that this design had significantly better performance than the conventional design such as using the global pooling layer as the output layer for the regression task. These analyses support the notion that Proformer provides a novel method of learning and enhances our understanding of how cis-regulatory sequences determine the expression values.","2024-02-20","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","1","25","","","","","","","","","","English","","","","WOS:001169097400004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","BINDING PROTEINS; Enhancer; ENHANCER ACTIVITY MAPS; Expression prediction; FUNCTIONAL DISSECTION; GENE-REGULATORY LOGIC; GENOME; Macaron Transformer; Passively Parallel Reporter Assay (MPRA); Sequence model; SYSTEMATIC DISSECTION; VARIANTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KEZM3RE8","journalArticle","2023","Dutta, P; Sathi, KA; Hossain, MA; Dewan, MAA","Conv-ViT: A Convolution and Vision Transformer-Based Hybrid Feature Extraction Method for Retinal Disease Detection","JOURNAL OF IMAGING","","2313-433X","10.3390/jimaging9070140","","The current advancement towards retinal disease detection mainly focused on distinct feature extraction using either a convolutional neural network (CNN) or a transformer-based end-to-end deep learning (DL) model. The individual end-to-end DL models are capable of only processing texture or shape-based information for performing detection tasks. However, extraction of only texture- or shape-based features does not provide the model robustness needed to classify different types of retinal diseases. Therefore, concerning these two features, this paper developed a fusion model called 'Conv-ViT' to detect retinal diseases from foveal cut optical coherence tomography (OCT) images. The transfer learning-based CNN models, such as Inception-V3 and ResNet-50, are utilized to process texture information by calculating the correlation of the nearby pixel. Additionally, the vision transformer model is fused to process shape-based features by determining the correlation between long-distance pixels. The hybridization of these three models results in shape-based texture feature learning during the classification of retinal diseases into its four classes, including choroidal neovascularization (CNV), diabetic macular edema (DME), DRUSEN, and NORMAL. The weighted average classification accuracy, precision, recall, and F1 score of the model are found to be approximately 94%. The results indicate that the fusion of both texture and shape features assisted the proposed Conv-ViT model to outperform the state-of-the-art retinal disease classification models.","2023-07","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","7","9","","","","","","","","","","English","","","","WOS:001036004100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;25<br/>Total Times Cited:&nbsp;&nbsp;25<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","classification; ENSEMBLE; hybrid feature; Inception-V3; MACULAR DEGENERATION; PREVALENCE; ResNet-50; retinal disease; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QBWF92SM","journalArticle","2023","Zhou, XJ; Yu, GX; Yin, QY; Yang, J; Sun, JY; Lv, SY; Shi, Q","Tooth Type Enhanced Transformer for Children Caries Diagnosis on Dental Panoramic Radiographs","DIAGNOSTICS","","2075-4418","10.3390/diagnostics13040689","","The objective of this study was to introduce a novel deep learning technique for more accurate children caries diagnosis on dental panoramic radiographs. Specifically, a swin transformer is introduced, which is compared with the state-of-the-art convolutional neural network (CNN) methods that are widely used for caries diagnosis. A tooth type enhanced swin transformer is further proposed by considering the differences among canine, molar and incisor. Modeling the above differences in swin transformer, the proposed method was expected to mine domain knowledge for more accurate caries diagnosis. To test the proposed method, a children panoramic radiograph database was built and labeled with a total of 6028 teeth. Swin transformer shows better diagnosis performance compared with typical CNN methods, which indicates the usefulness of this new technique for children caries diagnosis on panoramic radiographs. Furthermore, the proposed tooth type enhanced swin transformer outperforms the naive swin transformer with the accuracy, precision, recall, F1 and area-under-the-curve being 0.8557, 0.8832, 0.8317, 0.8567 and 0.9223, respectively. This indicates that the transformer model can be further improved with a consideration of domain knowledge instead of a copy of previous transformer models designed for natural images. Finally, we compare the proposed tooth type enhanced swin transformer with two attending doctors. The proposed method shows higher caries diagnosis accuracy for the first and second primary molars, which may assist dentists in caries diagnosis.","2023-02","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","4","13","","","","","","","","","","English","","","","WOS:000944971500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","artificial intelligence; caries diagnosis; children; dental panoramic radiographs; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HBWZZ4CD","journalArticle","2022","Lu, YD; Romero, A; Fenton, MJ; Whiteson, D; Baldi, P","Resolving extreme jet substructure","JOURNAL OF HIGH ENERGY PHYSICS","","1029-8479","10.1007/JHEP08(2022)046","","We study the effectiveness of theoretically-motivated high-level jet observables in the extreme context of jets with a large number of hard sub-jets (up to N = 8). Previous studies indicate that high-level observables are powerful, interpretable tools to probe jet substructure for N <= 3 hard sub-jets, but that deep neural networks trained on low-level jet constituents match or slightly exceed their performance. We extend this work for up to N = 8 hard sub-jets, using deep particle-flow networks (PFNs) and Transformer based networks to estimate a loose upper bound on the classification performance. A fully-connected neural network operating on a standard set of high-level jet observables, 135 N-subjetiness observables and jet mass, reach classification accuracy of 86.90%, but fall short of the PFN and Transformer models, which reach classification accuracies of 89.19% and 91.27% respectively, suggesting that the constituent networks utilize information not captured by the set of high-level observables. We then identify additional high-level observables which are able to narrow this gap, and utilize LASSO regularization for feature selection to identify and rank the most relevant observables and provide further insights into the learning strategies used by the constituent-based neural networks. The final model contains only 31 high-level observables and is able to match the performance of the PFN and approximate the performance of the Transformer model to within 2%.","2022-08-03","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","8","","","","","","","","","","","English","","","","WOS:000836240600006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","Hadron-Hadron Scattering; Jet Substructure and Boosted Jets; QCD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZMICLI23","journalArticle","2024","Durgam, LK; Jatoth, RK","Age Estimation from Speech Using Tuned CNN Model on Edge Devices","JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO TECHNOLOGY","","1939-8018","10.1007/s11265-024-01929-4","","The speaker's emotions, age, and gender have all been ascertained through imaginative investigation. This information can be applied to communications, common applications like biometric identification and human-machine interactions. The Edge Impulse framework employs a tiny model that has been trained to identify the speaker's age based on speech attributes. As a result, a speaker's age can be inferred from their voice. With the help of an external microphone connected to the Jetson Nano and the MP34DT05 digital microphone on the Arduino Nano BLE 33 device. It is possible to record and determine a person's age from their speech in real-time applications. Making an effective human-machine interface for practical applications is speech recognition's fundamental goal. The Arduino Nano BLE 33 has an integrated RGB LED that enables it to determine a speaker's age and determine if they are a child or an adult. A red led will be used to signify a child speaker, while a blue led will be used to identify an adult speaker. The proposed tuned deep convolution neural networks outperform the more commonly used convolutional neural networks in tests compared to training data.The proposed tuned 1D CNN with MFCC speech features are outperforming compared to existing traditional methods. The Nvidia Jetson Nano and Nano BLE 33 Microcontrollers are ideal for applications needing speaker age detection because of their low power consumption, ease of use, small size, and excellent computational performance.","2024-10","2025-02-26 20:41:56","2025-02-26 20:41:56","","569-585","","10","96","","","","","","","","","","English","","","","WOS:001345886900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Age identification; CLASSIFICATION; Convolutional neural networks; Edge impulse; EMOTION; SPEAKER; Speech recognition; Tiny ML","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AL5UNQKQ","journalArticle","2021","Athulya, MS; Sathidev, PS","Speaker Verification from Codec-Distorted Speech Through Combination of Affine Transform and Feature Switching","CIRCUITS SYSTEMS AND SIGNAL PROCESSING","","0278-081X","10.1007/s00034-021-01747-0","","A high-performance speaker verification system from codec-distorted speech is developed and implemented in this paper. Apriori knowledge of the type of the speech codec is utilized in this. Code excited linear prediction-based codec which is one of the most commonly used codecs in mobile communications is assumed here. A novel method is developed by applying the concepts of feature switching and affine transform for the design and implementation of the proposed speaker verification system. In this system, best feature set for each speaker is identified during training phase from affine transformed speech features to make feature selection more robust. Mel frequency cepstral coefficients and modified power normalized cepstral coefficients are identified as features for feature switching. Feature switching is done using direct method in feature level itself and an indirect method in the i-vector framework. During testing phase, best feature set of the claimed speaker is extracted from the codec-distorted speech and affine transform is applied to reflect the feature space during training. Speaker verification is performed using this affine transformed feature set. Classifiers based on Gaussian mixture model-universal background model and i-vector are used for verification. The performance of the proposed system is tested using two databases, namely TIMIT and VoxCeleb1. For both databases with the above two classifiers, we could achieve very low equal error rate when compared with the other competitive methods available in the literature. Hence, the proposed system is a very good candidate for critical applications like forensic speaker verification.","2021-12","2025-02-26 20:41:56","2025-02-26 20:41:56","","6016-6034","","12","40","","","","","","","","","","English","","","","WOS:000661396800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Affine transform; Codec distortion; Equal error rate; Feature switching; GMM-UBM; RECOGNITION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RYHRAI9Y","journalArticle","2024","Zhang, XL; Xie, HB; Zhou, YT; Jia, LJ","Local feature expansion Vision Transformer model for bearing fault diagnosis under noise environments","JOURNAL OF INSTRUMENTATION","","1748-0221","10.1088/1748-0221/19/03/P03018","","Vision Transformer (ViT) shows potential in bearing fault diagnosis due to its multi -head self -attention mechanism and parallel feature extraction network which are efficient to achieve the robust complete feature representation of the fault. However, its adaption to the noise interference relies on the sufficient huge amount of training samples to prepare the local features of the fault and may suffer performance degradation when only a limited number of samples are available for the model training. To combat this challenge, an improved ViT diagnosis model based on the local feature expansion, i.e., LFE-ViT, is proposed. An auxiliary feature extraction block is introduced using a local feature expansion network and works as a parallel module with the ViT encoder. Through the enlargement of the receptive field, the multi -scale local features on a high dimensional space are available upon the limited samples. Then, through a feature embedding channel, the extracted local features are transmitted to the ViT encoder. Finally, by virtue of the multi -head self -attention mechanism to capture the time sequence global information, a fault diagnosis model comprising comprehensively local and global feature information is derived. Experimental validation on the bearing fault dataset from Case Western Reserve University shows that LFE-ViT has provided a rather satisfactory diagnosis performance under limited samples and noise environment.","2024-03","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","3","19","","","","","","","","","","English","","","","WOS:001195425500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","Data processing methods; Detection of defects; Digital signal processing (DSP); Overall mechanics design (support structures and materials; vibration analysis etc)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L7EXTZER","journalArticle","2024","Rakhimova, D; Karibayeva, A; Turarbek, A","The Task of Post-Editing Machine Translation for the Low-Resource Language","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14020486","","In recent years, machine translation has made significant advancements; however, its effectiveness can vary widely depending on the language pair. Languages with limited resources, such as Kazakh, Uzbek, Kalmyk, Tatar, and others, often encounter challenges in achieving high-quality machine translations. Kazakh is an agglutinative language with complex morphology, making it a low-resource language. This article addresses the task of post-editing machine translation for the Kazakh language. The research begins by discussing the history and evolution of machine translation and how it has developed to meet the unique needs of languages with limited resources. The research resulted in the development of a machine translation post-editing system. The system utilizes modern machine learning methods, starting with neural machine translation using the BRNN model in the initial post-editing stage. Subsequently, the transformer model is applied to further edit the text. Complex structural and grammatical forms are processed, and abbreviations are replaced. Practical experiments were conducted on various texts: news publications, legislative documents, IT sphere, etc. This article serves as a valuable resource for researchers and practitioners in the field of machine translation, shedding light on effective post-editing strategies to enhance translation quality, particularly in scenarios involving languages with limited resources such as Kazakh and Uzbek. The obtained results were tested and evaluated using specialized metrics-BLEU, TER, and WER.","2024-01","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","2","14","","","","","","","","","","English","","","","WOS:001149063300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","BRNN; English; full post-editing; HANDLING UNKNOWN WORDS; Kazakh; light post-editing; machine translation; post-editing machine translation; PRODUCT; Russian; transformer; Uzbek","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3VS2XISN","journalArticle","2023","Ji, F; Ni, JS; Li, GN; Liu, LM; Wang, YY","Underwater Acoustic Target Recognition Based on Deep Residual Attention Convolutional Neural Network","JOURNAL OF MARINE SCIENCE AND ENGINEERING","","2077-1312","10.3390/jmse11081626","","Underwater acoustic target recognition methods based on time-frequency analysis have shortcomings, such as missing information on target characteristics and having a large computation volume, which leads to difficulties in improving the accuracy and immediacy of the target recognition system. In this paper, an underwater acoustic target recognition model based on a deep residual attention convolutional neural network called DRACNN is proposed, whose input is the time-domain signal of the underwater acoustic targets radiated noise. In this model, convolutional blocks with attention to the mechanisms are used to focus on and extract deep features of the target, and residual networks are used to improve the stability of the network training. On the full ShipsEar dataset, the recognition accuracy of the DRACNN model is 97.1%, which is 2.2% higher than the resnet-18 model with an approximately equal number of parameters as this model. With similar recognition accuracies, the DRACNN model parameters are 1/36th and 1/10th of the AResNet model and UTAR-Transformer model, respectively, and the floating-point operations are 1/292nd and 1/46th of the two models, respectively. Finally, the DRACNN model pre-trained on the ShipsEar dataset was migrated to the DeepShip dataset and achieved recognition accuracy of 89.2%. The experimental results illustrate that the DRACNN model has excellent generalization ability and is suitable for a micro-UATR system.","2023-08","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","8","11","","","","","","","","","","English","","","","WOS:001167112000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","channel attention mechanism; convolutional neural network; residual connections; time-domain signal; underwater acoustic target recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2DM9Q3F3","journalArticle","2024","Tida, VS; Hsu, S; Hei, XL","A Unified Training Process for Fake News Detection Based on Finetuned Bidirectional Encoder Representation from Transformers Model","BIG DATA","","2167-6461","10.1089/big.2022.0050","","An efficient fake news detector becomes essential as the accessibility of social media platforms increases rapidly. Previous studies mainly focused on designing the models solely based on individual data sets and might suffer from degradable performance. Therefore, developing a robust model for a combined data set with diverse knowledge becomes crucial. However, designing the model with a combined data set requires extensive training time and sequential workload to obtain optimal performance without having some prior knowledge about the model's parameters. The presented study here will help solve these issues by introducing the unified training strategy to have a base structure for the classifier and all hyperparameters from individual models using a pretrained transformer model. The performance of the proposed model is noted using three publicly available data sets, namely ISOT and others from the Kaggle website. The results indicate that the proposed unified training strategy surpassed the existing models such as Random Forests, convolutional neural networks, and long short-term memory, with 97% accuracy and achieved the F1 score of 0.97. Furthermore, there was a significant reduction in training time by almost 1.5 to 1.8 x by removing words lower than three letters from the input samples. We also did extensive performance analysis by varying the number of encoder blocks to build compact models and trained on the combined data set. We justify that reducing encoder blocks resulted in lower performance from the obtained results.","2024-08-01","2025-02-26 20:41:56","2025-02-26 20:41:56","","331-342","","4","12","","","","","","","","","","English","","","","WOS:000951070200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","BERT; fake news; finetuning; hyperparameters; pretrained model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QRR2AF3C","journalArticle","2023","Yuan, JY; Ding, XW; Liu, FY; Cai, X","Disaster cassification net: A disaster classification algorithm on remote sensing imagery","FRONTIERS IN ENVIRONMENTAL SCIENCE","","2296-665X","10.3389/fenvs.2022.1095986","","As we all know, natural disasters have a great impact on people's lives and properties, and it is very necessary to deal with disaster categories in a timely and effective manner. In light of this, we propose using tandem stitching to create a new Disaster Cassification network D-Net (Disaster Cassification Net) using the D-Conv, D-Linear, D-model, and D-Layer modules. During the experiment, we compared the proposed method with ""CNN "" and ""Transformer "", we found that disaster cassification net compared to CNN algorithm Params decreased by 26-608 times, FLOPs decreased by up to 21 times, Precision increased by 1.6%-43.5%; we found that disaster cassification net compared to Transformer algorithm Params decreased by 23-149 times, FLOPs decreased by 1.7-10 times, Precision increased by 3.9%-25.9%. Precision increased by 3.9%-25.9%. And found that disaster cassification net achieves the effect of SOTA(State-Of-The-Art) on the disaster dataset; After that, we compared the above-mentioned MobileNet_v2 with the best performance on the classification dataset and CCT network are compared with disaster cassification net on fashion_mnist and CIFAR_100 public datasets, respectively, and the results show that disaster cassification net can still achieve the state-of-the-art classification effect. Therefore, our proposed algorithm can be applied not only to disaster tasks, but also to other classification tasks.","2023-01-06","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","","10","","","","","","","","","","English","","","","WOS:000918765800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","convolutional neural networks and transformer model; disaster cassification net; natural disaster; portability; remote sensing image","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W2F9BZ67","journalArticle","2022","Jin, Z; Kim, J; Yeo, H; Choi, S","Transformer-based map-matching model with limited labeled data using transfer-learning approach","TRANSPORTATION RESEARCH PART C-EMERGING TECHNOLOGIES","","0968-090X","10.1016/j.trc.2022.103668","","In many spatial trajectory-based applications, it is necessary to map raw trajectory data points onto road networks in digital maps, which is commonly referred to as a map-matching process. While most previous map-matching methods have focused on using rule-based algorithms to deal with the map-matching problems, in this paper, we consider the map-matching task from the data-driven perspective, proposing a deep learning-based map-matching model. We build a Transformer-based map-matching model with a transfer learning approach. We generate trajectory data to pre-train the Transformer model and then fine-tune the model with a limited number of labeled data to minimize the model development cost and reduce the real-to-virtual gaps. Three metrics (Average Hamming Distance, F-score, and BLEU) at two levels (point and segment level) are used to evaluate the model performance. The model is tested with real world datasets, and the results show that the proposed map-matching model outperforms other existing map-matching models. We also analyze the matching mechanisms of the Transformer in the map-matching process, which helps to interpret the input data's internal correlation and the external relation between input data and matching results. In addition, the proposed model shows the possibility of using generated trajectories to solve the map-matching problems in the limited labeled data environment.","2022-07","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","","140","","","","","","","","","","English","","","","WOS:000797651100008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;22<br/>Total Times Cited:&nbsp;&nbsp;23<br/>Cited Reference Count:&nbsp;&nbsp;105</p>","","","ACCURACY; ALGORITHMS; AVERAGE HAMMING DISTANCE; FLOW PREDICTION; Limited labeled data; Map matching; NAVIGATION; NETWORKS; PERFORMANCE; Trajectory data; Transfer learning; Transformer; WEIGHT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GFCPIG8I","journalArticle","2021","Lan, M; Wu, YQ; Huang, ZQ; Liu, HH; Zhao, CX; Yu, YM; Kang, K","An Improved Six-Port Equivalent-Circuit Model for Millimeter-Wave On-Chip Transformers With Accurate Coupling Factor Modeling","IEEE TRANSACTIONS ON MICROWAVE THEORY AND TECHNIQUES","","0018-9480","10.1109/TMTT.2021.3092342","","This article presents an improved equivalent-circuit model for millimeter-wave six-port transformers on silicon with accurate coupling factor modeling. The lossy silicon substrate eddy current effects have a significant impact on the mutual resistive coupling factor (k(re)) of the primary and secondary coils, which in turn affects the maximum available gain (G(max)) of the transformer. To characterize eddy currents' loss in the silicon substrate, ""effective substrate current loops,"" which are magnetically coupled by the primary and secondary coils simultaneously, are presented. The mutual inductances and coupling capacitances are used to model coupling effects between all segments of the coils. The proposed model can accurately predict the frequency-dependent mutual reactive coupling factor (k(im)) and mutual resistive coupling factor (k(re)). A corresponding methodology to parameter extraction based on electromagnetic (EM) simulations is demonstrated. A two-way current-combining-based power amplifier (PA) is presented for fifth-generation (5G) communication in the 65-nm CMOS process. Using the developed transformer model, the baluns and inter-stage transformers in the PA are modeled and analyzed. The power gain of the PA is 22.8 dB, the saturated output power (P-sat) is 18.7 dBm, and the power-added efficiency (PAE) is 21.88%.","2021-09","2025-02-26 20:41:56","2025-02-26 20:41:56","","3989-4000","","9","69","","","","","","","","","","English","","","","WOS:000692231600008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","CMOS; integrated circuit modeling; INTERCONNECTS; maximum available gain; millimeter-wave (mm-wave); mutual resistive coupling factor; power amplifier (PA); POWER-AMPLIFIER; RECEIVER; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZKV3XQ3T","journalArticle","2025","Xing, X; Liu, CZ; Han, JY; Feng, Q; Qi, EF; Qu, YY; Ma, BX","Potato Plant Variety Identification Study Based on Improved Swin Transformer","AGRICULTURE-BASEL","","2077-0472","10.3390/agriculture15010087","","Potato is one of the most important food crops in the world and occupies a crucial position in China's agricultural development. Due to the large number of potato varieties and the phenomenon of variety mixing, the development of the potato industry is seriously affected. Therefore, accurate identification of potato varieties is a key link to promote the development of the potato industry. Deep learning technology is used to identify potato varieties with good accuracy, but there are relatively few related studies. Thus, this paper introduces an enhanced Swin Transformer classification model named MSR-SwinT (Multi-scale residual Swin Transformer). The model employs a multi-scale feature fusion module in place of patch partitioning and linear embedding. This approach effectively extracts features of various scales and enhances the model's feature extraction capability. Additionally, the residual learning strategy is integrated into the Swin Transformer block, effectively addressing the issue of gradient disappearance and enabling the model to capture complex features more effectively. The model can better capture complex features. The enhanced MSR-SwinT model is validated using the potato plant dataset, demonstrating strong performance in potato plant image recognition with an accuracy of 94.64%. This represents an improvement of 3.02 percentage points compared to the original Swin Transformer model. Experimental evidence shows that the improved model performs better and generalizes better, providing a more effective solution for potato variety identification.","2025-01","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","1","15","","","","","","","","","","English","","","","WOS:001393510200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","convolutional neural network; deep learning; potato; Swin Transformer; variety identification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JFVAEIBI","journalArticle","2024","Ahn, J; Kim, K; Kim, Y; Kim, H; Lee, Y","Detection of Floating Algae Blooms on Water Bodies Using PlanetScope Images and Shifted Windows Transformer Model","REMOTE SENSING","","2072-4292","10.3390/rs16203791","","The increasing water temperature due to climate change has led to more frequent algae blooms and deteriorating water quality in coastal areas and rivers worldwide. To address this, we developed a deep learning-based model for identifying floating algae blooms using PlanetScope optical images and the Shifted Windows (Swin) Transformer architecture. We created 1,998 datasets from 105 scenes of PlanetScope imagery collected between 2018 and 2023, covering 14 water bodies known for frequent algae blooms. The methodology included data pre-processing, dataset generation, deep learning modeling, and inference result generation. The input images contained six bands, including vegetation indices such as the Normalized Difference Vegetation Index (NDVI) and Enhanced Vegetation Index (EVI), enhancing the model's responsiveness to algae blooms. Evaluations were conducted using both single-period and multi-period datasets. The single-period model achieved a mean Intersection over Union (mIoU) between 72.18% and 76.47%, while the multi-period model significantly improved performance, with an mIoU of 91.72%. This demonstrates the potential of our model and highlights the importance of change detection in multi-temporal images for algae bloom monitoring. Additionally, the padding technique proposed in this study resolved the border issue that arises when mosaicking inference results from individual patches, providing a seamless view of the satellite scene.","2024-10","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","20","16","","","","","","","","","","English","","","","WOS:001341759300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","CHLOROPHYLL-A CONCENTRATION; deep learning; floating algae blooms; INDEX; MACROALGAE; PlanetScope; REMOTE ESTIMATION; shifted windows (Swin) Transformer; vegetation indices","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F9AGI3PV","journalArticle","2024","Choi, SH; Buu, SJ","Learning to Traverse Cryptocurrency Transaction Graphs Based on Transformer Network for Phishing Scam Detection","ELECTRONICS","","2079-9292","10.3390/electronics13071298","","Cryptocurrencies have experienced a surge in popularity, paralleled by an increase in phishing scams exploiting their transactional networks. Therefore, detecting anomalous transactions in the complex structure of cryptocurrency transaction data and the imbalance between legitimate and fraudulent data is considered a very important task. To this end, we introduce a model specifically designed for scam detection within the Ethereum network, focusing on its capability to process long and complex transaction graphs. Our method, Deep Graph traversal based on Transformer for Scam Detection (DGTSD), employs the DeepWalk algorithm to traverse extensive graph structures and a Transformer-based classifier to analyze intricate node relationships within these graphs. The necessity for such an approach arises from the inherent complexity and vastness of Ethereum transaction data, which traditional techniques struggle to process effectively. DGTSD applies subgraph sampling to manage this complexity, targeting significant portions of the network for detailed analysis. Then, it leverages the multi-head attention mechanism of the Transformer model to effectively learn and analyze complex patterns and relationships within the Ethereum transaction graph to identify fraudulent activity more accurately. Our experiments with other models demonstrate the superiority of this model over traditional methods in performance, with an F1 score of 0.9354. By focusing on the challenging aspects of Ethereum's transaction network, such as its size and intricate connections, DGTSD presents a robust solution for identifying fraudulent activities, significantly contributing to the enhancement of blockchain security.","2024-04","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","7","13","","","","","","","","","","English","","","","WOS:001201100300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","cryptocurrency security; DeepWalk; fraud detection; graph neural network; graph traversing; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9QCKGVM4","journalArticle","2024","Jaffari, ZH; Abbas, A; Kim, CM; Shin, J; Kwak, J; Son, C; Lee, YG; Kim, S; Chon, K; Cho, KH","Transformer-based deep learning models for adsorption capacity prediction of heavy metal ions toward biochar-based adsorbents","JOURNAL OF HAZARDOUS MATERIALS","","0304-3894","10.1016/j.jhazmat.2023.132773","","Biochar adsorbents synthesized from food and agricultural wastes are commonly applied to eliminate heavy metal (HM) ions from wastewater. However, biochar's diverse characteristics and varied experimental conditions make the accurate estimation of their adsorption capacity (qe) challenging. Herein, various machine-learning (ML) and three deep learning (DL) models were built using 1518 data points to predict the qe of HM on various biochars. The recursive feature elimination technique with 28 inputs suggested that 14 inputs were significant for model building. FT-transformer with the highest test R2 (0.98) and lowest root mean square error (RMSE) (0.296) and mean absolute error (MAE) (0.145) outperformed various ML and DL models. The SHAP feature importance analysis of the FT-transformer model predicted that the adsorption conditions (72.12%) were more important than the pyrolysis conditions (25.73%), elemental composition (1.39%), and biochar's physical properties (0.73%). The two-feature SHAP analysis proposed the optimized process conditions including adsorbent loading of 0.25 g, initial concentration of 12 mg/L, and solution pH of 9 using phosphoric-acid pre-treated biochar synthesized from banana-peel with a higher O/C ratio. The t-SNE technique was applied to transform the 14-input matrix of the FT-Transformer into two-dimensional data. Finally, we outlined the study's environmental implications.","2024-01-15","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","","462","","","","","","","","","","English","","","","WOS:001108627200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;31<br/>Total Times Cited:&nbsp;&nbsp;32<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","Adsorption capacity; Biochar-based adsorbents; Heavy metal ions; PHOTOCATALYTIC DEGRADATION; SORPTION MECHANISMS; Transformer -based deep learning models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JRA4Z69T","journalArticle","2023","Zhou, YA; Lian, J","Identification of emotions evoked by music via spatial-temporal transformer in multi-channel EEG signals","FRONTIERS IN NEUROSCIENCE","","1662-453X","10.3389/fnins.2023.1188696","","IntroductionEmotion plays a vital role in understanding activities and associations. Due to being non-invasive, many experts have employed EEG signals as a reliable technique for emotion recognition. Identifying emotions from multi-channel EEG signals is evolving into a crucial task for diagnosing emotional disorders in neuroscience. One challenge with automated emotion recognition in EEG signals is to extract and select the discriminating features to classify different emotions accurately. MethodsIn this study, we proposed a novel Transformer model for identifying emotions from multi-channel EEG signals. Note that we directly fed the raw EEG signal into the proposed Transformer, which aims at eliminating the issues caused by the local receptive fields in the convolutional neural networks. The presented deep learning model consists of two separate channels to address the spatial and temporal information in the EEG signals, respectively. ResultsIn the experiments, we first collected the EEG recordings from 20 subjects during listening to music. Experimental results of the proposed approach for binary emotion classification (positive and negative) and ternary emotion classification (positive, negative, and neutral) indicated the accuracy of 97.3 and 97.1%, respectively. We conducted comparison experiments on the same dataset using the proposed method and state-of-the-art techniques. Moreover, we achieved a promising outcome in comparison with these approaches. DiscussionDue to the performance of the proposed approach, it can be a potentially valuable instrument for human-computer interface system.","2023-07-06","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","","17","","","","","","","","","","English","","","","WOS:001032255300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","deep learning; electroencephalographic; emotion classification; human computer interface; machine learning; RECOGNITION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PW5SMXBR","journalArticle","2023","Yang, LJ; Jin, C; Yang, GH; Bing, ZT; Huang, L; Niu, YZ; Yang, L","Transformer-based deep learning method for optimizing ADMET properties of lead compounds","PHYSICAL CHEMISTRY CHEMICAL PHYSICS","","1463-9076","10.1039/d2cp05332b","","A successful drug needs to exhibit both effective pharmacodynamics (PD) and safe pharmacokinetics (PK). However, the coordinated optimization of PD and PK properties in molecule generation tasks remains a great challenge for most existing methods, especially when they focus on the pursuit of affinity and selectivity for the lead compound. Thus, molecular optimization for PK properties is a critical step in the drug discovery pipeline, in which absorption, distribution, metabolism, excretion and toxicity (ADMET) property predictive models play an increasingly important role by providing an effective method to assess multiple PK properties of compounds. Here, we proposed a Graph Bert-based ADMET prediction model that achieves state-of-the-art performance on the public dataset Therapeutics Data Commons (TDC) by combining molecular graph features and descriptor features, with 11 tasks ranked first and 20 tasks ranked in the top 3. Based on this prediction model, we trained a Transformer model with multiple properties as constraints for learning the structural transformations involved in MMP and the accompanying property changes. The experimental results show that the trained Constraints-Transformer can implement targeted modifications to the starting molecule, while preserving the core scaffold. Moreover, molecular docking and binding mode analysis demonstrate that the optimized molecules still retain the activity and selectivity for biological targets. Therefore, the proposed method accounts for biological activity and ADMET properties simultaneously. Finally, a webserver containing ADMET property prediction and molecular optimization functions is provided, enabling chemists to improve the properties of starting molecules individually.","2023-01-18","2025-02-26 20:41:56","2025-02-26 20:41:56","","2377-2385","","3","25","","","","","","","","","","English","","","","WOS:000907178700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","OPTIMIZATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8WB5PL8Y","journalArticle","2023","Zhang, SC; Zhang, JH; Wang, XP; Wang, JW; Wu, ZJ","ELS2T: Efficient Lightweight Spectral-Spatial Transformer for Hyperspectral Image Classification","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2023.3299442","","In recent years, convolutional neural networks (CNNs) have been extensively used in hyperspectral image (HSI) classification tasks and achieved desirable performance. However, CNNs expand the receptive field by stacking convolutional layers and pooling layers, but the actual receptive field is still insufficient, so it is hard to capture the global representations of HSIs. In addition, the existing CNN models used for HSI classification have low-computational efficiency, and cannot effectively fuse spectral and spatial information. To alleviate the above limitations, this article proposes a novel efficient lightweight spectral-spatial transformer (ELS2T) specially designed for HSI classification. The transformer model can model the long-distance feature dependencies in the HSI cube. First, we design a global multiscale attention module (GMAM) to effectively highlight the useful information and weaken the useless information. Second, considering the different importance of spectral and spatial information for classification tasks, an adaptive feature fusion module (AFFM) is proposed to adaptively fuse the acquired spectral and spatial information. Finally, to improve the computational efficiency, we design the lightweight separable spatial-spectral self-attention ( S(3)A ) module to replace the multihead self-attention (MHSA) module in the transformer encoder. Experimental results on the four well-known hyperspectral datasets show that our model is superior to the other state-of-the-art deep learning (DL) methods in both computational efficiency and classification performance.","2023","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","","61","","","","","","","","","","English","","","","WOS:001047542000009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;22<br/>Total Times Cited:&nbsp;&nbsp;23<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Adaptive feature fusion; deep learning (DL); efficient lightweight spectral-spatial transformer (ELS2T); global multiscale attention; hyperspectral image (HSI) classification; NETWORK; self-attention mechanism","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"28JWMCYD","journalArticle","2022","Jiang, XZ; Wang, S; Yu, XZ; Gong, YX","Double-Layer Positional Encoding Embedding Method for Cross-Platform Binary Function Similarity Detection","CHINESE JOURNAL OF ELECTRONICS","","1022-4653","10.1049/cje.2021.00.139","","The similarity detection between two cross-platform binary functions has been applied in many fields, such as vulnerability detection, software copyright protection or malware classification. Current advanced methods for binary function similarity detection usually use semantic features, but have certain limitations. For example, practical applications may encounter instructions that have not been seen in training, which may easily cause the out of vocabulary (OOV) problem. In addition, the generalization of the extracted binary semantic features may be poor, resulting in a lower accuracy of the trained model in practical applications. To overcome these limitations, we propose a double-layer positional encoding based transformer model (DP-Transformer). The DP-Transformer's encoder is used to extract the semantic features of the source instruction set architecture (ISA), which is called the source ISA encoder. Then, the source ISA encoder is fine-tuned by the triplet loss while the target ISA encoder is trained. This process is called DP-MIRROR. When facing the same semantic basic block, the embedding vectors of the source and target ISA encoders are similar. Different from the traditional transformer which uses single-layer positional encoding, the double-layer positional encoding embedding can solve the OOV problem while ensuring the separation between instructions, so it is more suitable for the embedding of assembly instructions. Our comparative experiment results show that DP-MIRROR outperforms the state-of-the-art approach, MIRROR, by about 35% in terms of precision at 1.","2022-07","2025-02-26 20:41:56","2025-02-26 20:41:56","","604-611","","4","31","","","","","","","","","","English","","","","WOS:000829360000003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","Binary similarity; Cross-platform and semantic features","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NUKQC8DE","journalArticle","2022","Chen, SK; Li, WX; Cao, YC; Lu, XB","Combining the Convolution and Transformer for Classification of Smoke-Like Scenes in Remote Sensing Images","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2022.3208120","","Remote sensing (RS) images are used in a wide range of tasks. In the fire detection field, smoke in RS images is considered as an indicator of wildfires. However, smoke-like scenes, e.g., cloud, in RS images increase the difficulty of smoke recognition. Convolutional neural networks (CNNs) have greatly promoted the development of image processing. CNNs are good at capturing local features; however, their ability to capture global features is relatively weak. Recently, the transformer deep learning model has shown strong potential in vision tasks. The transformer model utilizes self-attention modules to extract global features but may lose local details. Recognition of smoke in RS images depends strongly on the combination of both local and global features. Thus, this article proposes the transformer enhanced convolutional network (TECN) to classify RS smoke-like scenes. The proposed hybrid TECN model exploits the advantages of the CNN and transformer techniques at the same time. In TECN, the feature merge and intelligent aggregation modules are used to promote conversion and aggregation between CNN feature maps and transformer patch embeddings. Experiments are conducted on the USTC_SmokeRS dataset, which is developed for the classification of RS smoke-like scenes. The experimental results demonstrate that the proposed TECN achieves a competitive accuracy of 98.39% on this dataset.","2022","2025-02-26 20:41:56","2025-02-26 20:41:56","","","","","60","","","","","","","","","","English","","","","WOS:000864196200007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","ALGORITHM; Convolution; Convolutional neural network (CNN); Convolutional neural networks; FEATURE AGGREGATION; Feature extraction; FEATURES; Image analysis; Image recognition; NEURAL-NETWORK; scene classification; smoke-like scenes; Task analysis; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""