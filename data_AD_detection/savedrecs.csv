"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"J78H8IZ7","journalArticle","2024","Chou, CJ; Chang, CT; Chang, YN; Lee, CY; Chuang, YF; Chiu, YL; Liang, WL; Fan, YM; Liu, YC","Screening for early Alzheimer's disease: enhancing diagnosis with linguistic features and biomarkers","FRONTIERS IN AGING NEUROSCIENCE","","1663-4365","10.3389/fnagi.2024.1451326","","Introduction Research has shown that speech analysis demonstrates sensitivity in detecting early Alzheimer's disease (AD), but the relation between linguistic features and cognitive tests or biomarkers remains unclear. This study aimed to investigate how linguistic features help identify cognitive impairments in patients in the early stages of AD. Method This study analyzed connected speech from 80 participants and categorized the participants into early-AD and normal control (NC) groups. The participants underwent amyloid-beta positron emission tomography scans, brain magnetic resonance imaging, and comprehensive neuropsychological testing. Participants' speech data from a picture description task were examined. A total of 15 linguistic features were analyzed to classify groups and predict cognitive performance. Results We found notable linguistic differences between the early-AD and NC groups in lexical diversity, syntactic complexity, and language disfluency. Using machine learning classifiers (SVM, KNN, and RF), we achieved up to 88% accuracy in distinguishing early-AD patients from normal controls, with mean length of utterance (MLU) and long pauses ratio (LPR) serving as core linguistic indicators. Moreover, the integration of linguistic indicators with biomarkers significantly improved predictive accuracy for AD. Regression analysis also highlighted crucial linguistic features, such as MLU, LPR, Type-to-Token ratio (TTR), and passive construction ratio (PCR), which were sensitive to changes in cognitive function. Conclusion Findings support the efficacy of linguistic analysis as a screening tool for the early detection of AD and the assessment of subtle cognitive decline. Integrating linguistic features with biomarkers significantly improved diagnostic accuracy.","2024-09-23","2025-02-26 20:36:58","2025-02-26 20:36:58","","","","","16","","","","","","","","","","English","","","","WOS:001329347800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Alzheimer's disease; amyloid-beta; cognitive impairment; CONNECTED LANGUAGE; DECLINE; DEMENTIA; DISCOURSE; hippocampal volume; linguistic features; MARKER; MILD COGNITIVE IMPAIRMENT; SPEECH; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DJRN3JDI","journalArticle","2022","Kumar, MR; Vekkot, S; Lalitha, S; Gupta, D; Govindraj, VJ; Shaukat, K; Alotaibi, YA; Zakariah, M","Dementia Detection from Speech Using Machine Learning and Deep Learning Architectures","SENSORS","","1424-8220","10.3390/s22239311","","Dementia affects the patient's memory and leads to language impairment. Research has demonstrated that speech and language deterioration is often a clear indication of dementia and plays a crucial role in the recognition process. Even though earlier studies have used speech features to recognize subjects suffering from dementia, they are often used along with other linguistic features obtained from transcriptions. This study explores significant standalone speech features to recognize dementia. The primary contribution of this work is to identify a compact set of speech features that aid in the dementia recognition process. The secondary contribution is to leverage machine learning (ML) and deep learning (DL) models for the recognition task. Speech samples from the Pitt corpus in Dementia Bank are utilized for the present study. The critical speech feature set of prosodic, voice quality and cepstral features has been proposed for the task. The experimental results demonstrate the superiority of machine learning (87.6 percent) over deep learning (85 percent) models for recognizing Dementia using the compact speech feature combination, along with lower time and memory consumption. The results obtained using the proposed approach are promising compared with the existing works on dementia recognition using speech.","2022-12","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","23","22","","","","","","","","","","English","","","","WOS:000896357600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;27<br/>Total Times Cited:&nbsp;&nbsp;28<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Alzheimer's disease; ALZHEIMERS-DISEASE; CEPSTRUM; deep learning; machine learning; speech signal processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TWGWR6T7","journalArticle","2024","Tripathi, T; Kumar, R","Speech-based detection of multi-class Alzheimer's disease classification using machine learning","INTERNATIONAL JOURNAL OF DATA SCIENCE AND ANALYTICS","","2364-415X","10.1007/s41060-023-00475-9","","Alzheimer's disease, a significant global health concern, necessitates early detection for effective treatment and management. This research introduces an innovative method for classifying six types of cognitive impairment via speech-based analysis: probable AD, possible AD, MCI, memory impairments, vascular dementia, and control. Leveraging speech data from DementiaBank's Pitt Corpus, we preprocess the data to extract relevant acoustic features. These features are then employed to train five machine learning algorithms: KNN, DT, SVM, XGBoost, and RF. The study's results indicate an overall accuracy of 75.59% in the six-class classification challenge. Furthermore, statistical tests establish the statistical significance of the differences in accuracy between XGBoost and the other algorithms, except for random forest. This approach has the potential to evolve into a non-invasive, cost-effective, and readily accessible diagnostic tool for early cognitive impairment detection and management.","2024-06","2025-02-26 20:36:59","2025-02-26 20:36:59","","83-96","","1","18","","","","","","","","","","English","","","","WOS:001126739700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Alzheimer's disease; Classification; Machine learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V6QPZ7VE","journalArticle","2022","Yamada, Y; Shinkawa, K; Nemoto, M; Ota, M; Nemoto, K; Arai, T","Speech and language characteristics differentiate Alzheimer's disease and dementia with Lewy bodies","ALZHEIMER'S & DEMENTIA: DIAGNOSIS, ASSESSMENT & DISEASE MONITORING","","2352-8729","10.1002/dad2.12364","","IntroductionEarly differential diagnosis of Alzheimer's disease (AD) and dementia with Lewy bodies (DLB) is important, but it remains challenging. Different profiles of speech and language impairments between AD and DLB have been suggested, but direct comparisons have not been investigated. MethodsWe collected speech responses from 121 older adults comprising AD, DLB, and cognitively normal (CN) groups and investigated their acoustic, prosodic, and linguistic features. ResultsThe AD group showed larger differences from the CN group than the DLB group in linguistic features, while the DLB group showed larger differences in prosodic and acoustic features. Machine-learning classifiers using these speech features achieved 87.0% accuracy for AD versus CN, 93.2% for DLB versus CN, and 87.4% for AD versus DLB. DiscussionOur findings indicate the discriminative differences in speech features in AD and DLB and the feasibility of using these features in combination as a screening tool for identifying/differentiating AD and DLB.","2022","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","1","14","","","","","","","","","","English","","","","WOS:000914865700095","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;16<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","acoustic; ASSOCIATION WORKGROUPS; CRITERIA; DIAGNOSTIC GUIDELINES; digital health; IMPAIRMENT; language impairment; linguistic; machine learning; MANAGEMENT; NATIONAL INSTITUTE; natural language processing; PARKINSONS-DISEASE; prosodic; RECOMMENDATIONS; spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZG9UBQ7E","journalArticle","2021","Clarke, N; Barrick, TR; Garrard, P","A Comparison of Connected Speech Tasks for Detecting Early Alzheimer's Disease and Mild Cognitive Impairment Using Natural Language Processing and Machine Learning","FRONTIERS IN COMPUTER SCIENCE","","2624-9898","10.3389/fcomp.2021.634360","","Alzheimer's disease (AD) has a long pre-clinical period, and so there is a crucial need for early detection, including of Mild Cognitive Impairment (MCI). Computational analysis of connected speech using Natural Language Processing and machine learning has been found to indicate disease and could be utilized as a rapid, scalable test for early diagnosis. However, there has been a focus on the Cookie Theft picture description task, which has been criticized. Fifty participants were recruited - 25 healthy controls (HC), 25 mild AD or MCI (AD+MCI) - and these completed five connected speech tasks: picture description, a conversational map reading task, recall of an overlearned narrative, procedural recall and narration of a wordless picture book. A high-dimensional set of linguistic features were automatically extracted from each transcript and used to train Support Vector Machines to classify groups. Performance varied, with accuracy for HC vs. AD+MCI classification ranging from 62% using picture book narration to 78% using overlearned narrative features. This study shows that, importantly, the conditions of the speech task have an impact on the discourse produced, which influences accuracy in detection of AD beyond the length of the sample. Further, we report the features important for classification using different tasks, showing that a focus on the Cookie Theft picture description task may narrow the understanding of how early AD pathology impacts speech.","2021-05-31","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","3","","","","","","","","","","English","","","","WOS:000663557300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;29<br/>Total Times Cited:&nbsp;&nbsp;30<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","alzheimer's disease; ASSOCIATION WORKGROUPS; connected speech; dementia; DEMENTIA; DEPRESSION; DIAGNOSTIC GUIDELINES; discourse; DISCOURSE; EXAMINATION III; machine learning; mild cognitive impairment; MINI-MENTAL-STATE; NATIONAL INSTITUTE; natural language processing; PROGRESSIVE APHASIA; RECOMMENDATIONS; spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WEAKGLVG","journalArticle","2024","Noto, S; Sekiyama, Y; Nagata, R; Yamamoto, G; Tamura, T","Analysis of Speech Features in Alzheimer's Disease with Machine Learning: A Case-Control Study","HEALTHCARE","","2227-9032","10.3390/healthcare12212194","","Background: Changes in the speech and language of patients with Alzheimer's disease (AD) have been reported. Using machine learning to characterize these irregularities may contribute to the early, non-invasive diagnosis of AD. Methods: We conducted cognitive function assessments, including the Mini-Mental State Examination, with 83 patients with AD and 75 healthy elderly participants, and recorded pre- and post-assessment conversations to evaluate participants' speech. We analyzed the characteristics of the spectrum, intensity, fundamental frequency, and minute temporal variation (triangle) of the intensity and fundamental frequency of the speech and compared them between patients with AD and healthy participants. Additionally, we evaluated the performance of the speech features that differed between the two groups as single explanatory variables. Results: We found significant differences in almost all elements of the speech spectrum between the two groups. Regarding the intensity, we found significant differences in all the factors except for the standard deviation between the two groups. In the performance evaluation, the areas under the curve revealed by logistic regression analysis were higher for the center of gravity (0.908 +/- 0.036), mean skewness (0.904 +/- 0.023), kurtosis (0.932 +/- 0.023), and standard deviation (0.977 +/- 0.012) of the spectra. Conclusions: This study used machine learning to reveal speech features of patients diagnosed with AD in comparison with healthy elderly people. Significant differences were found between the two groups in all components of the spectrum, paving the way for early non-invasive diagnosis of AD in the future.","2024-11","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","21","12","","","","","","","","","","English","","","","WOS:001351451900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Alzheimer's disease; artificial intelligence (AI); DEMENTIA; machine learning; MILD COGNITIVE IMPAIRMENT; spectrum; voice","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ERX4YMNC","journalArticle","2021","Lindsay, H; Tröger, J; König, A","Language Impairment in Alzheimer's Disease-Robust and Explainable Evidence for AD-Related Deterioration of Spontaneous Speech Through Multilingual Machine Learning","FRONTIERS IN AGING NEUROSCIENCE","","1663-4365","10.3389/fnagi.2021.642033","","Alzheimer's disease (AD) is a pervasive neurodegenerative disease that affects millions worldwide and is most prominently associated with broad cognitive decline, including language impairment. Picture description tasks are routinely used to monitor language impairment in AD. Due to the high amount of manual resources needed for an in-depth analysis of thereby-produced spontaneous speech, advanced natural language processing (NLP) combined with machine learning (ML) represents a promising opportunity. In this applied research field though, NLP and ML methodology do not necessarily ensure robust clinically actionable insights into cognitive language impairment in AD and additional precautions must be taken to ensure clinical-validity and generalizability of results. In this study, we add generalizability through multilingual feature statistics to computational approaches for the detection of language impairment in AD. We include 154 participants (78 healthy subjects, 76 patients with AD) from two different languages (106 English speaking and 47 French speaking). Each participant completed a picture description task, in addition to a battery of neuropsychological tests. Each response was recorded and manually transcribed. From this, task-specific, semantic, syntactic and paralinguistic features are extracted using NLP resources. Using inferential statistics, we determined language features, excluding task specific features, that are significant in both languages and therefore represent ""generalizable"" signs for cognitive language impairment in AD. In a second step, we evaluated all features as well as the generalizable ones for English, French and both languages in a binary discrimination ML scenario (AD vs. healthy) using a variety of classifiers. The generalizable language feature set outperforms the all language feature set in English, French and the multilingual scenarios. Semantic features are the most generalizable while paralinguistic features show no overlap between languages. The multilingual model shows an equal distribution of error in both English and French. By leveraging multilingual statistics combined with a theory-driven approach, we identify AD-related language impairment that generalizes beyond a single corpus or language to model language impairment as a clinically-relevant cognitive symptom. We find a primary impairment in semantics in addition to mild syntactic impairment, possibly confounded by additional impaired cognitive functions.","2021-05-19","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","13","","","","","","","","","","English","","","","WOS:000656843700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;32<br/>Total Times Cited:&nbsp;&nbsp;34<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","Alzheimer's disease; COMPLEXITY; COMPREHENSION; dementia; DEMENTIA; explainability; language impairment; MILD COGNITIVE IMPAIRMENT; multilingual machine learning; natural language processing; picture description; PICTURE DESCRIPTION; spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TVNYCSYC","journalArticle","2021","Sadeghian, R; Schaffer, JD; Zahorian, SA","Towards an Automatic Speech-Based Diagnostic Test for Alzheimer's Disease","FRONTIERS IN COMPUTER SCIENCE","","2624-9898","10.3389/fcomp.2021.624594","","Automatic Speech Recognition (ASR) is widely used in many applications and tools. Smartphones, video games, and cars are a few examples where people use ASR routinely and often daily. A less commonly used, but potentially very important arena for using ASR, is the health domain. For some people, the impact on life could be enormous. The goal of this work is to develop an easy-to-use, non-invasive, inexpensive speech-based diagnostic test for dementia that can easily be applied in a clinician's office or even at home. While considerable work has been published along these lines, increasing dramatically recently, it is primarily of theoretical value and not yet practical to apply. A large gap exists between current scientific understanding, and the creation of a diagnostic test for dementia. The aim of this paper is to bridge this gap between theory and practice by engineering a practical test. Experimental evidence suggests that strong discrimination between subjects with a diagnosis of probable Alzheimer's vs. matched normal controls can be achieved with a combination of acoustic features from speech, linguistic features extracted from a transcription of the speech, and results of a mini mental state exam. A fully automatic speech recognition system tuned for the speech-to-text aspect of this application, including automatic punctuation, is also described.","2021-04-07","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","3","","","","","","","","","","English","","","","WOS:000705871800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","alzheimer's disease; dementia; DEMENTIA; machine learning; natural language processing; speech processing; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DT65YEQ9","journalArticle","2023","Bae, M; Seo, MG; Ko, HYW; Ham, H; Kim, KY; Lee, JY","The efficacy of memory load on speech-based detection of Alzheimer's disease","FRONTIERS IN AGING NEUROSCIENCE","","1663-4365","10.3389/fnagi.2023.1186786","","IntroductionThe study aims to test whether an increase in memory load could improve the efficacy in detection of Alzheimer's disease and prediction of the Mini-Mental State Examination (MMSE) score. MethodsSpeech from 45 mild-to-moderate Alzheimer's disease patients and 44 healthy older adults were collected using three speech tasks with varying memory loads. We investigated and compared speech characteristics of Alzheimer's disease across speech tasks to examine the effect of memory load on speech characteristics. Finally, we built Alzheimer's disease classification models and MMSE prediction models to assess the diagnostic value of speech tasks. ResultsThe speech characteristics of Alzheimer's disease in pitch, loudness, and speech rate were observed and the high-memory-load task intensified such characteristics. The high-memory-load task outperformed in AD classification with an accuracy of 81.4% and MMSE prediction with a mean absolute error of 4.62. DiscussionThe high-memory-load recall task is an effective method for speech-based Alzheimer's disease detection.","2023-06-02","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","15","","","","","","","","","","English","","","","WOS:001006364200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","ADULTS; Alzheimer's disease; automatic speech analysis; DEMENTIA; FLUENCY; IMPAIRMENT; machine learning; Mini Mental State Examination; MOTOR-PERFORMANCE; PARAMETERS; speech acoustics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7BTYDXHQ","journalArticle","2023","Yamada, Y; Shinkawa, K; Nemoto, M; Nemoto, K; Arai, T","A mobile application using automatic speech analysis for classifying Alzheimer?s disease and mild cognitive impairment","COMPUTER SPEECH AND LANGUAGE","","0885-2308","10.1016/j.csl.2023.101514","","Speech and language disturbances have been observed from the early stages of Alzheimer's disease (AD), including mild cognitive impairment (MCI), and speech analysis has been expected to help as a screening tool for early detection of AD and MCI. However, the questions of whether and how automatic speech analysis, including speech recognition by a self-administered tool, can be used for such detection remain largely unexplored. In this study, we performed automatic analysis of speech data collected via a mobile application from 114 older participants during cognitive tasks. The goal was to classify AD, MCI, and cognitively normal (CN) groups by using speech features characterizing acoustic, prosodic, and linguistic aspects. First, we evaluated how accurately linguistic features could be automatically extracted from transcriptions generated by automatic speech recognition (ASR), and we found that the features were highly correlated (r = 0.92) with those extracted from manual transcriptions. Then, a machine-learning speech classifier using these features achieved 78.6% accuracy for classifying AD, MCI, and CN through nested cross-validation (AD versus CN: 91.2% accuracy; MCI versus CN: 87.6% accuracy). Our results suggest the utility and validity of using a mobile application with automatic speech analysis as a self-administered screening tool for early detection of AD and MCI.","2023-06","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","81","","","","","","","","","","English","","","","WOS:000959955900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;111</p>","","","ADULTS; Automatic speech recognition; CARE; CONNECTED SPEECH; DEMENTIA; DIAGNOSIS; FLUENCY; LANGUAGE; Machine learning; Natural language processing; PARAMETERS; RECOGNITION; Screening; Self-administered; VOICES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2XSLJKMN","journalArticle","2022","Sanz, C; Carrillo, F; Slachevsky, A; Forno, G; Tempini, MLG; Villagra, R; Ibáñez, A; Tagliazucchi, E; García, AM","Automated text-level semantic markers of Alzheimer's disease","ALZHEIMER'S & DEMENTIA: DIAGNOSIS, ASSESSMENT & DISEASE MONITORING","","2352-8729","10.1002/dad2.12276","","IntroductionAutomated speech analysis has emerged as a scalable, cost-effective tool to identify persons with Alzheimer's disease dementia (ADD). Yet, most research is undermined by low interpretability and specificity. MethodsCombining statistical and machine learning analyses of natural speech data, we aimed to discriminate ADD patients from healthy controls (HCs) based on automated measures of domains typically affected in ADD: semantic granularity (coarseness of concepts) and ongoing semantic variability (conceptual closeness of successive words). To test for specificity, we replicated the analyses on Parkinson's disease (PD) patients. ResultsRelative to controls, ADD (but not PD) patients exhibited significant differences in both measures. Also, these features robustly discriminated between ADD patients and HC, while yielding near-chance classification between PD patients and HCs. DiscussionAutomated discourse-level semantic analyses can reveal objective, interpretable, and specific markers of ADD, bridging well-established neuropsychological targets with digital assessment tools.","2022","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","1","14","","","","","","","","","","English","","","","WOS:000914865700021","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;21<br/>Total Times Cited:&nbsp;&nbsp;22<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Alzheimer's disease dementia; ATROPHY; automated speech analysis; CONNECTED SPEECH; DEFICITS; DEMENTIA; DISCOURSE; LANGUAGE; Parkinson's disease; PARKINSONS-DISEASE; semantic granularity; semantic variability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ILQMQ7DB","journalArticle","2024","Garcia-Gutiérrez, F; Alegret, M; Marquié, M; Muñoz, N; Ortega, G; Cano, A; De Rojas, I; García-González, P; Olivé, C; Puerta, R; García-Sanchez, A; Capdevila-Bayo, M; Montrreal, L; Pytel, V; Rosende-Roca, M; Zaldua, C; Gabirondo, P; Tárraga, L; Ruiz, A; Boada, M; Valero, S","Unveiling the sound of the cognitive status: Machine Learning-based speech analysis in the Alzheimer's disease spectrum","ALZHEIMERS RESEARCH & THERAPY","","1758-9193","10.1186/s13195-024-01394-y","","BackgroundAdvancement in screening tools accessible to the general population for the early detection of Alzheimer's disease (AD) and prediction of its progression is essential for achieving timely therapeutic interventions and conducting decentralized clinical trials. This study delves into the application of Machine Learning (ML) techniques by leveraging paralinguistic features extracted directly from a brief spontaneous speech (SS) protocol. We aimed to explore the capability of ML techniques to discriminate between different degrees of cognitive impairment based on SS. Furthermore, for the first time, this study investigates the relationship between paralinguistic features from SS and cognitive function within the AD spectrum.MethodsPhysical-acoustic features were extracted from voice recordings of patients evaluated in a memory unit who underwent a SS protocol. We implemented several ML models evaluated via cross-validation to identify individuals without cognitive impairment (subjective cognitive decline, SCD), with mild cognitive impairment (MCI), and with dementia due to AD (ADD). In addition, we established models capable of predicting cognitive domain performance based on a comprehensive neuropsychological battery from Fundacio Ace (NBACE) using SS-derived information.ResultsThe results of this study showed that, based on a paralinguistic analysis of sound, it is possible to identify individuals with ADD (F1 = 0.92) and MCI (F1 = 0.84). Furthermore, our models, based on physical acoustic information, exhibited correlations greater than 0.5 for predicting the cognitive domains of attention, memory, executive functions, language, and visuospatial ability.ConclusionsIn this study, we show the potential of a brief and cost-effective SS protocol in distinguishing between different degrees of cognitive impairment and forecasting performance in cognitive domains commonly affected within the AD spectrum. Our results demonstrate a high correspondence with protocols traditionally used to assess cognitive function. Overall, it opens up novel prospects for developing screening tools and remote disease monitoring.","2024-02-02","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","1","16","","","","","","","","","","English","","","","WOS:001155288600002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","Alzheimer's disease; ASSOCIATION WORKGROUPS; Automated pattern recognition; BATTERY; DECLINE; DEMENTIA; DIAGNOSTIC GUIDELINES; Early diagnosis; IMPAIRMENT; Machine Learning; Mild cognitive impairment; NATIONAL INSTITUTE; Neuropsychological tests; PARAMETERS; RECOMMENDATIONS; Speech acoustics; VERSION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"38L6IBV2","journalArticle","2023","Parsapoor, M; Alam, MR; Mihailidis, A","Performance of machine learning algorithms for dementia assessment: impacts of language tasks, recording media, and modalities","BMC MEDICAL INFORMATICS AND DECISION MAKING","","1472-6947","10.1186/s12911-023-02122-6","","ObjectivesAutomatic speech and language assessment methods (SLAMs) can help clinicians assess speech and language impairments associated with dementia in older adults. The basis of any automatic SLAMs is a machine learning (ML) classifier that is trained on participants' speech and language. However, language tasks, recording media, and modalities impact the performance of ML classifiers. Thus, this research has focused on evaluating the effects of the above-mentioned factors on the performance of ML classifiers that can be used for dementia assessment.MethodologyOur methodology includes the following steps: (1) Collecting speech and language datasets from patients and healthy controls; (2) Using feature engineering methods which include feature extraction methods to extract linguistic and acoustic features and feature selection methods to select most informative features; (3) Training different ML classifiers; and (4) Evaluating the performance of ML classifiers to investigate the impacts of language tasks, recording media, and modalities on dementia assessment.ResultsOur results show that (1) the ML classifiers trained with the picture description language task perform better than the classifiers trained with the story recall language task; (2) the data obtained from phone-based recordings improves the performance of ML classifiers compared to data obtained from web-based recordings; and (3) the ML classifiers trained with acoustic features perform better than the classifiers trained with linguistic features.ConclusionThis research demonstrates that we can improve the performance of automatic SLAMs as dementia assessment methods if we: (1) Use the picture description task to obtain participants' speech; (2) Collect participants' voices via phone-based recordings; and (3) Train ML classifiers using only acoustic features. Our proposed methodology will help future researchers to investigate the impacts of different factors on the performance of ML classifiers for assessing dementia.","2023-03-03","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","1","23","","","","","","","","","","English","","","","WOS:000943084100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;79</p>","","","Acoustic features; Alzheimer's disease; ALZHEIMERS-DISEASE; COGNITIVE ASSESSMENT; Dementia; Language assessment methods; Language impairments; Linguistic features; Machine learning; Mild cognitive impairment; SPEECH ANALYSIS; Speech assessment methods","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3Y2IRBNM","journalArticle","2025","El Hallani, A; Chakhtouna, A; Adib, A","Advanced speech biomarker integration for robust Alzheimer's disease diagnosis","ANNALS OF TELECOMMUNICATIONS","","0003-4347","10.1007/s12243-025-01073-5","","The healthcare sector has witnessed a transformative shift in recent years, driven by rapid advancements in digital technologies. Among the myriad of applications, the management of Alzheimer's disease (AD) has garnered significant attention. AD, the most common form of dementia, affects millions globally and presents a significant challenge due to its progressive and currently incurable nature. Early detection is crucial, yet existing diagnostic methods are invasive, expensive, and not readily accessible. This study proposes a hybrid approach combining traditional acoustic features (e.g., MFCC, pitch, jitter, shimmer) with deep learning-based embeddings (YAMNet, VGGish) to enhance the robustness and accuracy of AD detection through speech analysis. The methodology involves comprehensive feature extraction, dimensionality reduction via autoencoders, and classification using advanced machine learning (ML) and deep learning (DL) models. Evaluation on the ADReSS dataset demonstrates the proposed method's superior performance, achieving an accuracy of 89.9% with a deep neural network classifier. The results highlight the potential of integrating traditional and modern techniques to develop non-invasive, cost-effective, and accessible tools for early AD detection, paving the way for timely intervention and improved patient outcomes. Future work will focus on expanding datasets, incorporating diverse demographics, and refining models for better sensitivity and specificity in clinical applications.","2025-02-18","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","","","","","","","","","","","English","","","","WOS:001424206200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Acoustic features; Alzheimer's disease; CLASSIFICATION; Deep features; Deep learning; DIMENSIONALITY; FEATURES; Machine learning; SET; Speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"36IAVPGC","journalArticle","2025","Balabin, H; Tamm, B; Spruyt, L; Dusart, N; Kabouche, I; Eycken, E; Statz, K; De Meyer, S; Van Hamme, H; Dupont, P; Moens, MF; Vandenberghe, R","Natural language processing-based classification of early Alzheimer's disease from connected speech","ALZHEIMERS & DEMENTIA","","1552-5260","10.1002/alz.14530","","INTRODUCTIONThe automated analysis of connected speech using natural language processing (NLP) emerges as a possible biomarker for Alzheimer's disease (AD). However, it remains unclear which types of connected speech are most sensitive and specific for the detection of AD. METHODSWe applied a language model to automatically transcribed connected speech from 114 Flemish-speaking individuals to first distinguish early AD patients from amyloid negative cognitively unimpaired (CU) and then amyloid negative from amyloid positive CU individuals using five different types of connected speech. RESULTSThe language model was able to distinguish between amyloid negative CU subjects and AD patients with up to 81.9% sensitivity and 81.8% specificity. Discrimination between amyloid positive and negative CU individuals was less accurate, with up to 82.7% sensitivity and 74.0% specificity. Moreover, autobiographical interviews consistently outperformed scene descriptions. DISCUSSIONOur findings highlight the value of autobiographical interviews for the automated analysis of connecting speech. Highlights This study compared five types of connected speech for the detection of early Alzheimer's disease (AD). Autobiographical interviews yielded a higher specificity than scene descriptions. A preceding clinical AD classification task can refine the performance of amyloid status classification in cognitively healthy individuals.","2025-01-27","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","","","","","","","","","","","English","","","","WOS:001407399300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Alzheimer's disease; amyloid; AUTOBIOGRAPHICAL MEMORY; connected speech; DEMENTIA; natural language processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2Y88AJWR","journalArticle","2022","Hason, L; Krishnan, S","Spontaneous speech feature analysis for alzheimer's disease screening using a random forest classifier","FRONTIERS IN DIGITAL HEALTH","","2673-253X","10.3389/fdgth.2022.901419","","Detecting Alzheimer's disease (AD) and disease progression based on the patient's speech not the patient's speech data can aid non-invasive, cost-effective, real-time early diagnostic and repetitive monitoring in minimum time and effort using machine learning (ML) classification approaches. This paper aims to predict early AD diagnosis and evaluate stages of AD through exploratory analysis of acoustic features, non-stationarity, and non-linearity testing, and applying data augmentation techniques on spontaneous speech signals collected from AD and cognitively normal (CN) subjects. Evaluation of the proposed AD prediction and AD stages classification models using Random Forest classifier yielded accuracy rates of 82.2% and 71.5%. This will enrich the Alzheimer's research community with further understanding of methods to improve models for AD classification and addressing non-stationarity and non-linearity properties on audio features to determine the best-suited acoustic features for AD monitoring.","2022-11-17","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","4","","","","","","","","","","English","","","","WOS:001033197400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","acoustic features; Alzheimer's disease; classification; data augmentation; DEMENTIA; LANGUAGE; machine learning; non-linearity; non-stationarity; spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J9UFFNL4","journalArticle","2023","Zolnoori, M; Zolnour, A; Topaz, M","ADscreen: A speech processing-based screening system for automatic identification of patients with Alzheimer's disease and related dementia","ARTIFICIAL INTELLIGENCE IN MEDICINE","","0933-3657","10.1016/j.artmed.2023.102624","","Alzheimer's disease and related dementias (ADRD) present a looming public health crisis, affecting roughly 5 million people and 11 % of older adults in the United States. Despite nationwide efforts for timely diagnosis of patients with ADRD, >50 % of them are not diagnosed and unaware of their disease. To address this challenge, we developed ADscreen, an innovative speech-processing based ADRD screening algorithm for the protective identification of patients with ADRD. ADscreen consists of five major components: (i) noise reduction for reducing background noises from the audio-recorded patient speech, (ii) modeling the patient's ability in phonetic motor planning using acoustic parameters of the patient's voice, (iii) modeling the patient's ability in semantic and syntactic levels of language organization using linguistic parameters of the patient speech, (iv) extracting vocal and semantic psycholinguistic cues from the patient speech, and (v) building and evaluating the screening algorithm. To identify important speech parameters (features) associated with ADRD, we used the Joint Mutual Information Maximization (JMIM), an effective feature selection method for high dimensional, small sample size datasets. Modeling the relationship between speech parameters and the outcome variable (presence/absence of ADRD) was conducted using three different machine learning (ML) architectures with the capability of joining informative acoustic and linguistic with contextual word embedding vectors obtained from the DistilBERT (Bidirectional Encoder Representations from Transformers). We evaluated the performance of the ADscreen on an audio-recorded patients' speech (verbal description) for the Cookie-Theft picture description task, which is publicly available in the dementia databank. The joint fusion of acoustic and linguistic parameters with contextual word embedding vectors of DistilBERT achieved F1-score = 84.64 (standard deviation [std] = & PLUSMN;3.58) and AUC-ROC = 92.53 (std = & PLUSMN;3.34) for training dataset, and F1-score = 89.55 and AUC-ROC = 93.89 for the test dataset. In summary, ADscreen has a strong potential to be integrated with clinical workflow to address the need for an ADRD screening tool so that patients with cognitive impairment can receive appropriate and timely care.","2023-09","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","143","","","","","","","","","","English","","","","WOS:001045176200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;172</p>","","","Alzheimer's disease and related dementias; CARE; COMMUNICATION; DEPRESSION; DIAGNOSIS; EMOTION; EXPRESSION; INTERVENTIONS; Machine learning; MILD COGNITIVE IMPAIRMENT; Natural language processing; NEURAL-NETWORKS; PROFILES; Screening algorithm; Speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2GUN4NAD","journalArticle","2021","Jang, H; Soroski, T; Rizzo, M; Barral, O; Harisinghani, A; Newton-Mason, S; Granby, S; Vasco, TMSD; Lewis, C; Tutt, P; Carenini, G; Conati, C; Field, TS","Classification of Alzheimer's Disease Leveraging Multi-task Machine Learning Analysis of Speech and Eye-Movement Data","FRONTIERS IN HUMAN NEUROSCIENCE","","1662-5161","10.3389/fnhum.2021.716670","","Alzheimer's disease (AD) is a progressive neurodegenerative condition that results in impaired performance in multiple cognitive domains. Preclinical changes in eye movements and language can occur with the disease, and progress alongside worsening cognition. In this article, we present the results from a machine learning analysis of a novel multimodal dataset for AD classification. The cohort includes data from two novel tasks not previously assessed in classification models for AD (pupil fixation and description of a pleasant past experience), as well as two established tasks (picture description and paragraph reading). Our dataset includes language and eye movement data from 79 memory clinic patients with diagnoses of mild-moderate AD, mild cognitive impairment (MCI), or subjective memory complaints (SMC), and 83 older adult controls. The analysis of the individual novel tasks showed similar classification accuracy when compared to established tasks, demonstrating their discriminative ability for memory clinic patients. Fusing the multimodal data across tasks yielded the highest overall AUC of 0.83 +/- 0.01, indicating that the data from novel tasks are complementary to established tasks.","2021-09-20","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","15","","","","","","","","","","English","","","","WOS:000703082000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","ACCURACY; Alzheimer's disease; eye-tracking; language; machine learning; mild cognitive impairment; MILD COGNITIVE IMPAIRMENT; multimodal; PROGRESSION; speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z25FVYUN","journalArticle","2024","Tripathi, T; Kumar, R","ML-Based Quantitative Analysis of Linguistic and Speech Features Relevant in Predicting Alzheimer's Disease","ADCAIJ-ADVANCES IN DISTRIBUTED COMPUTING AND ARTIFICIAL INTELLIGENCE JOURNAL","","2255-2863","10.14201/adcaij.31625","","Alzheimer's disease (AD) is a severe neurological condition that affects numerous people globally with detrimental consequences. Detecting AD early is crucial for prompt treatment and effective management. This study presents a novel approach for detecting and classifying six types of cognitive impairment using speech-based analysis, including probable AD, possible AD, mild cognitive impairment (MCI), memory impairments, vascular dementia, and control. The method employs speech data from DementiaBank's Pitt Corpus, which is preprocessed and analyzed to extract pertinent acoustic features. The characteristics are subsequently used to educate five machine learning algorithms, namely k-nearest neighbors (KNN), decision tree (DT), support vector machine (SVM), XGBoost, and random forest (RF). The effectiveness of every algorithm is assessed through a 10-fold cross-validation. According to the research findings, the suggested method based on speech obtains a total accuracy of 75.59% concerning the six-class categorization issue. Among the five machine learning algorithms tested, the XGBoost classifier showed the highest accuracy of 75.59%. These findings indicate that speech-based approaches can potentially be valuable for detecting and classifying cognitive impairment, including AD. The paper also explores robustness testing, evaluating the algorithms' performance under various circumstances, such as noise variability, voice quality changes, and accent variations. The proposed approach can be developed into a noninvasive, cost-effective, and accessible diagnostic tool for the early detection and management of cognitive impairment.","2024","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","13","","","","","","","","","","English","","","","WOS:001270700000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Alzheimer's disease; Deep learning; Feature selection; Machine learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M83BWACY","journalArticle","2024","Ding, KW; Chetty, M; Hoshyar, AN; Bhattacharya, T; Klein, B","Speech based detection of Alzheimer's disease: a survey of AI techniques, datasets and challenges","ARTIFICIAL INTELLIGENCE REVIEW","","0269-2821","10.1007/s10462-024-10961-6","","Alzheimer's disease (AD) is a growing global concern, exacerbated by an aging population and the high costs associated with traditional detection methods. Recent research has identified speech data as valuable clinical information for AD detection, given its association with the progressive degeneration of brain cells and subsequent impacts on memory, cognition, and language abilities. The ongoing demographic shift toward an aging global population underscores the critical need for affordable and easily available methods for early AD detection and intervention. To address this major challenge, substantial research has recently focused on investigating speech data, aiming to develop efficient and affordable diagnostic tools that align with the demands of our aging society. This paper presents an in-depth review of studies from 2018-2023 utilizing speech for AD detection. Following the PRISMA protocol and a two-stage selection process, we identified 85 publications for analysis. In contrast to previous literature reviews, this paper places a strong emphasis on conducting a rigorous comparative analysis of various Artificial Intelligence (AI) based techniques, categorizing them meticulously based on underlying algorithms. We perform an exhaustive evaluation of research papers leveraging common benchmark datasets, specifically ADReSS and ADReSSo, to assess their performance. In contrast to previous literature reviews, this work makes a significant contribution by overcoming the limitations posed by the absence of standardized tasks and commonly accepted benchmark datasets for comparing different studies. The analysis reveals the dominance of deep learning models, particularly those leveraging pre-trained models like BERT, in AD detection. The integration of acoustic and linguistic features often achieves accuracies above 85%. Despite these advancements, challenges persist in data scarcity, standardization, privacy, and model interpretability. Future directions include improving multilingual recognition, exploring emerging multimodal approaches, and enhancing ASR systems for AD patients. By identifying these key challenges and suggesting future research directions, our review serves as a valuable resource for advancing AD detection techniques and their practical implementation.","2024-10-12","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","12","57","","","","","","","","","","English","","","","WOS:001336421600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;133</p>","","","Alzheimer's disease; Classification; CLASSIFICATION; Deep learning; Dementia; DEMENTIA; FEATURES; IDENTIFICATION; Machine learning; RECOGNITION; Regression; Speech data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YQ7WJJUI","journalArticle","2023","Burke, E; Gunstad, J; Hamrick, P","Comparing global and local semantic coherence of spontaneous speech in persons with Alzheimer's disease and healthy controls","APPLIED CORPUS LINGUISTICS","","2666-7991","10.1016/j.acorp.2023.100064","","There is growing evidence that corpus-based computational tools are useful in identifying changes in speech that appear to accompany cognitive decline in Alzheimer's disease (AD). It has long been known that semantic coherence of speech is altered in AD, but only recently have computational tools been developed that allow for cohesion indices to be computed in an automated fashion on larger data sets. To that end, this study examined semantic coherence in persons with AD and healthy controls. Speech transcripts from 81 individuals with probable AD (Mage = 72.7 years, SD = 8.80, 70.4% female) and 61 healthy controls (Mage = 63.9 years, SD = 8.52, 62.3% female) from DementiaBank were analyzed. Machine learning analyses of coherence were conducted, and models evaluated for classification accuracy (i.e., AD vs controls) as well as ROC-AUC. Relationships between coherence indices and MMSE performance were also quantified. Though no significant group differences emerged in local semantic coherence among adjacent words, persons with AD produced less globally coherent speech relative to healthy controls. Furthermore, global coherence indices predicted AD diagnoses with accuracy between 75% and 78% and were significantly associated with MMSE scores. These findings suggest that automated measures of global coherence can distinguish individuals with AD from healthy controls, which may point to eventual diagnostic utility in clinical settings.","2023-12","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","3","3","","","","","","","","","","English","","","","WOS:001403155600004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","Alzheimer's Disease (AD); COHORT; DECLINE; DEMENTIA; DISCOURSE ANALYSIS; FEATURES; LANGUAGE; Machine learning; MEMORY; MILD COGNITIVE IMPAIRMENT; PATTERNS; PERFORMANCE; Semantic coherence; Spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UHICPK9X","journalArticle","2023","Liu, JM; Fu, F; Li, L; Yu, JX; Zhong, DC; Zhu, SS; Zhou, YX; Liu, B; Li, JQ","Efficient Pause Extraction and Encode Strategy for Alzheimer's Disease Detection Using Only Acoustic Features from Spontaneous Speech","BRAIN SCIENCES","","2076-3425","10.3390/brainsci13030477","","Clinical studies have shown that speech pauses can reflect the cognitive function differences between Alzheimer's Disease (AD) and non-AD patients, while the value of pause information in AD detection has not been fully explored. Herein, we propose a speech pause feature extraction and encoding strategy for only acoustic-signal-based AD detection. First, a voice activity detection (VAD) method was constructed to detect pause/non-pause feature and encode it to binary pause sequences that are easier to calculate. Then, an ensemble machine-learning-based approach was proposed for the classification of AD from the participants' spontaneous speech, based on the VAD Pause feature sequence and common acoustic feature sets (ComParE and eGeMAPS). The proposed pause feature sequence was verified in five machine-learning models. The validation data included two public challenge datasets (ADReSS and ADReSSo, English voice) and a local dataset (10 audio recordings containing five patients and five controls, Chinese voice). Results showed that the VAD Pause feature was more effective than common feature sets (ComParE: 6373 features and eGeMAPS: 88 features) for AD classification, and that the ensemble method improved the accuracy by more than 5% compared to several baseline methods (8% on the ADReSS dataset; 5.9% on the ADReSSo dataset). Moreover, the pause-sequence-based AD detection method could achieve 80% accuracy on the local dataset. Our study further demonstrated the potential of pause information in speech-based AD detection, and also contributed to a more accessible and general pause feature extraction and encoding method for AD detection.","2023-03","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","3","13","","","","","","","","","","English","","","","WOS:000954179500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Alzheimer's disease detection; DIAGNOSIS; ensemble machine learning; machine learning; MEMORY; SELECTION; SILENT PAUSES; speech pause feature; statistical analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D5Q3J2BB","journalArticle","2022","Fristed, E; Skirrow, C; Meszaros, M; Lenain, R; Meepegama, U; Papp, K; Ropacki, M; Weston, J","Leveraging speech and artificial intelligence to screen for early Alzheimer's disease and amyloid beta positivity","BRAIN COMMUNICATIONS","","2632-1297","10.1093/braincomms/fcac231","","Early detection of Alzheimer's disease is required to identify patients suitable for disease-modifying medications and to improve access to non-pharmacological preventative interventions. Prior research shows detectable changes in speech in Alzheimer's dementia and its clinical precursors. The current study assesses whether a fully automated speech-based artificial intelligence system can detect cognitive impairment and amyloid beta positivity, which characterize early stages of Alzheimer's disease. Two hundred participants (age 54-85, mean 70.6; 114 female, 86 male) from sister studies in the UK (NCT04828122) and the USA (NCT04928976), completed the same assessments and were combined in the current analyses. Participants were recruited from prior clinical trials where amyloid beta status (97 amyloid positive, 103 amyloid. negative, as established via PET or CSF test) and clinical diagnostic status was known (94 cognitively unimpaired, 106 with mild cognitive impairment or mild Alzheimer's disease). The automatic story recall task was administered during supervised in-person or relemedicine assessments, where participants were asked to recall stories immediately and after a brief delay. An artificial intelligence text-pair evaluation model produced vector-based outputs from the original story text and recorded and transcribed participant recalls, quantifying differences between them. Vector-based representations were fed into logistic regression models, trained with tournament leave-pair-out cross-validation analysis to predict amyloid beta status (primary endpoint), mild cognitive impairment and amyloid beta status in diagnostic subgroups (secondary endpoints). Predictions were assessed by the are-a under the receiver operating characteristic curve for the test result in comparison with reference standards (diagnostic and amyloid status). Simulation analysis evaluated two potential benefits of speech-based screening: (i) mild cognitive impairment screening in primary care compared with the Mini-Mental State Exam, and (ii) pre-screening prior to PET scanning when identifying an amyloid positive sample. Speech-based screening predicted amyloid beta positivity (area under the curve =0.77) and mild cognitive impairment or mild Alzheimer's disease (area under the curve = 0.83) in the full sample, and predicted amyloid beta in subsamples (mild cognitive impairment or mild Alzheimer's disease: area under the curve = 0.82; cognitively unimpaired: area under the curve = 0.71). Simulation analyses indicated that in primary care, speech-based screening could modestly improve detection of mild cognitive impairment (+8.5%), while reducing false positives (-59.1%). Furthermore, speech-based amyloid pre-screening was estimated to reduce the number of PET scans required by 35.3% and 35.5% in individuals with mild cognitive impairment and cognitively unimpaired individuals, respectively. Speech-based assessment offers accessible and scalable screening for mild cognitive impairment and amyloid beta positivity.","2022-09-01","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","5","4","","","","","","","","","","English","","","","WOS:000868824500002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","ADULTS; Alzheimer's disease; artificial intelligence; DEMENTIA; IMPLEMENTATION; machine learning; MCI (mild cognitive impairment); MILD COGNITIVE IMPAIRMENT; MINI-MENTAL-STATE; PREVALENCE; speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9XSIMZYX","journalArticle","2023","Hajjar, I; Okafor, M; Choi, JD; Moore, E; Abrol, A; Calhoun, VD; Goldstein, FC","Development of digital voice biomarkers and associations with cognition, cerebrospinal biomarkers, and neural representation in early Alzheimer's disease","ALZHEIMER'S & DEMENTIA: DIAGNOSIS, ASSESSMENT & DISEASE MONITORING","","2352-8729","10.1002/dad2.12393","","IntroductionAdvances in natural language processing (NLP), speech recognition, and machine learning (ML) allow the exploration of linguistic and acoustic changes previously difficult to measure. We developed processes for deriving lexical-semantic and acoustic measures as Alzheimer's disease (AD) digital voice biomarkers. MethodsWe collected connected speech, neuropsychological, neuroimaging, and cerebrospinal fluid (CSF) AD biomarker data from 92 cognitively unimpaired (40 A beta+) and 114 impaired (63 A beta+) participants. Acoustic and lexical-semantic features were derived from audio recordings using ML approaches. ResultsLexical-semantic (area under the curve [AUC] = 0.80) and acoustic (AUC = 0.77) scores demonstrated higher diagnostic performance for detecting MCI compared to Boston Naming Test (AUC = 0.66). Only lexical-semantic scores detected amyloid-beta status (p = 0.0003). Acoustic scores associated with hippocampal volume (p = 0.017) while lexical-semantic scores associated with CSF amyloid-beta (p = 0.007). Both measures were significantly associated with 2-year disease progression. DiscussionThese preliminary findings suggest that derived digital biomarkers may identify cognitive impairment in preclinical and prodromal AD, and may predict disease progression. HighlightsThis study derived lexical-semantic and acoustics features as Alzheimer's disease (AD) digital biomarkers.These features were derived from audio recordings using machine learning approaches.Voice biomarkers detected cognitive impairment and amyloid-beta status in early stages of AD.Voice biomarkers may predict Alzheimer's disease progression.These markers significantly mapped to functional connectivity in AD-susceptible brain regions.","2023-01","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","1","15","","","","","","","","","","English","","","","WOS:000928809600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;18<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Alzheimer's disease; DEMENTIA; diagnosis; digital biomarkers; IMPAIRMENT; lexical semantic; MEMORY; mild cognitive impairment; NETWORK; RECOGNITION; speech; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HAUZCWL4","journalArticle","2021","Calzà, L; Gagliardi, G; Favretti, RR; Tamburini, F","Linguistic features and automatic classifiers for identifying mild cognitive impairment and dementia","COMPUTER SPEECH AND LANGUAGE","","0885-2308","10.1016/j.csl.2020.101113","","Almost 50 million people are living with dementia in 2018 worldwide, and the number will double every 20 years. The effectiveness of existing pharmacologic treatments for the disease is limited to symptoms control, and none of them are able to prevent, reverse or turn off the neurodegenerative process that leads to dementia; therefore, a prompt detection of the ""disease signature"" is a key problem, in order to develop and test new drugs and to support the management of clinical and domestic context. Recent studies showed that linguistic alterations may be one of the earliest signs of the pathology, years before other neurocognitive deficits become evident. Traditional tests fail to identify these slight but noticeable changes; whereas, the analysis of spoken language productions by Natural Language Processing (NLP) techniques can ecologically and inexpensively identify minor language modifications in potential patients. This interdisciplinary study aims at quantifying and describing alterations of linguistic features due to cognitive decline and build an automatic system for early diagnosis and screening purpose. To this aim, we enrolled 96 participants: 48 healthy controls and 48 impaired subjects. Of the latter, 32 was diagnosed with Mild Cognitive Impairment and 16 with early Dementia (eD). Each subject underwent a brief neuropsychological screening, and samples of semi-spontaneous speech productions was collected by means of three elicitation tasks. Recorded sessions were orthographically transcribed, PoS tagged and parsed building two different corpora: in the first we kept the automatic annotations, while in the second the transcripts were manually corrected in order to remove all mistakes. A multidimensional parameter computation was performed on the data, taking into consideration a set of 87 acoustical, rhythmical, morpho-syntactic and lexical feature as well as some readability indexes and demographic information. After these preparatory steps, some automatic classifiers were trained to distinguish healthy controls from MCI subjects employing two different algorithms, Support Vector (SVC) and Random Forest Classifiers (RFC). Our system was able to distinguish between controls and MCI subjects exhibiting high F1 scores, around 75%, thus it seems to be a promising approach for the identification of preclinical stages of dementia. (C) 2020 Elsevier Ltd. All rights reserved.","2021-01","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","65","","","","","","","","","","English","","","","WOS:000573827700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;49<br/>Total Times Cited:&nbsp;&nbsp;52<br/>Cited Reference Count:&nbsp;&nbsp;104</p>","","","APHASIA; COMMUNICATION; DECLINE; Dementia; DISCOURSE; Language and speech analyses; Linguistic bio-marker; Mild Cognitive Impairment; MINI-MENTAL-STATE; NARRATIVE SPEECH; NLP Techniques; OBJECTIVE TECHNIQUE; PRECLINICAL ALZHEIMERS-DISEASE; SELECTION; SPONTANEOUS SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UNLP7VTB","journalArticle","2022","Liu, N; Luo, KX; Yuan, ZM; Chen, Y","A Transfer Learning Method for Detecting Alzheimer's Disease Based on Speech and Natural Language Processing","FRONTIERS IN PUBLIC HEALTH","","2296-2565","10.3389/fpubh.2022.772592","","Alzheimer's disease (AD) is a neurodegenerative disease that is difficult to be detected using convenient and reliable methods. The language change in patients with AD is an important signal of their cognitive status, which potentially helps in early diagnosis. In this study, we developed a transfer learning model based on speech and natural language processing (NLP) technology for the early diagnosis of AD. The lack of large datasets limits the use of complex neural network models without feature engineering, while transfer learning can effectively solve this problem. The transfer learning model is firstly pre-trained on large text datasets to get the pre-trained language model, and then, based on such a model, an AD classification model is performed on small training sets. Concretely, a distilled bidirectional encoder representation (distilBert) embedding, combined with a logistic regression classifier, is used to distinguish AD from normal controls. The model experiment was evaluated on Alzheimer's dementia recognition through spontaneous speech datasets in 2020, including the balanced 78 healthy controls (HC) and 78 patients with AD. The accuracy of the proposed model is 0.88, which is almost equivalent to the champion score in the challenge and a considerable improvement over the baseline of 75% established by organizers of the challenge. As a result, the transfer learning method in this study improves AD prediction, which does not only reduces the need for feature engineering but also addresses the lack of sufficiently large datasets.","2022-04-13","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","10","","","","","","","","","","English","","","","WOS:000792866600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Alzheimer's disease; BERT; DEMENTIA; machine learning; natural language processing; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QR2KESDD","journalArticle","2024","Cho, SHY; Olm, CA; Ash, S; Shellikeri, S; Agmon, G; Cousins, KAQ; Irwin, DJ; Grossman, M; Liberman, M; Nevler, N","Automatic classification of AD pathology in FTD phenotypes using natural speech","ALZHEIMERS & DEMENTIA","","1552-5260","10.1002/alz.13748","","INTRODUCTIONScreening for Alzheimer's disease neuropathologic change (ADNC) in individuals with atypical presentations is challenging but essential for clinical management. We trained automatic speech-based classifiers to distinguish frontotemporal dementia (FTD) patients with ADNC from those with frontotemporal lobar degeneration (FTLD).METHODSWe trained automatic classifiers with 99 speech features from 1 minute speech samples of 179 participants (ADNC = 36, FTLD = 60, healthy controls [HC] = 89). Patients' pathology was assigned based on autopsy or cerebrospinal fluid analytes. Structural network-based magnetic resonance imaging analyses identified anatomical correlates of distinct speech features.RESULTSOur classifier showed 0.88 +/-$ \pm $ 0.03 area under the curve (AUC) for ADNC versus FTLD and 0.93 +/-$ \pm $ 0.04 AUC for patients versus HC. Noun frequency and pause rate correlated with gray matter volume loss in the limbic and salience networks, respectively.DISCUSSIONBrief naturalistic speech samples can be used for screening FTD patients for underlying ADNC in vivo. This work supports the future development of digital assessment tools for FTD.Highlights We trained machine learning classifiers for frontotemporal dementia patients using natural speech. We grouped participants by neuropathological diagnosis (autopsy) or cerebrospinal fluid biomarkers. Classifiers well distinguished underlying pathology (Alzheimer's disease vs. frontotemporal lobar degeneration) in patients. We identified important features through an explainable artificial intelligence approach. This work lays the groundwork for a speech-based neuropathology screening tool.","2024-05","2025-02-26 20:36:59","2025-02-26 20:36:59","","3416-3428","","5","20","","","","","","","","","","English","","","","WOS:001196450700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","Alzheimer's disease; ALZHEIMERS-DISEASE; automated speech analysis; BEHAVIORAL VARIANT; COGNITIVE FUNCTION; DEMENTIA; EARLY-LIFE; FEATURES; frontotemporal lobar degeneration; GUIDELINES; LINGUISTIC ABILITY; machine learning classification; NATIONAL INSTITUTE; natural speech; pathology; RETRIEVAL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EYV3X5JY","journalArticle","2022","Adhikari, S; Thapa, S; Naseem, U; Singh, P; Huo, H; Bharathy, G; Prasad, M","Exploiting linguistic information from Nepali transcripts for early detection of Alzheimer's disease using natural language processing and machine learning techniques","INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES","","1071-5819","10.1016/j.ijhcs.2021.102761","","Alzheimer's disease (AD) is considered as progressing brain disease, which can be slowed down with the early detection and proper treatment by identifying the early symptoms. Language change serves as an early sign that a patient's cognitive functions have been impacted, potentially leading to early detection. The effects of language changes are being studied thoroughly in the English language to analyze the linguistic patterns in AD patients using Natural Language Processing (NLP). However, it has not been much explored in local languages and lowresourced languages like Nepali. In this paper, we have created a novel dataset on low resources language, i.e., Nepali, consisting of transcripts of the AD patients and control normal subjects. We have also presented baselines by applying various machine learning (ML) and deep learning (DL) algorithms on a novel dataset for the early detection of AD. The proposed work incorporates the speech decline of AD patients in order to classify them as control subjects or AD patients. This study makes an effective conclusion that the difficulty in processing information of AD patients reflects in their speech narratives of patients while describing a picture. The dataset is made publicly available.","2022-04","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","160","","","","","","","","","","English","","","","WOS:000792954200004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;21<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","Alzheimer's disease; CLASSIFICATION; Deep learning; DEMENTIA; DIAGNOSIS; Low resourced language; Machine learning; Natural language processing; Nepali language; TASK-FORCE; TRANSLATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V27APN5C","journalArticle","2023","Chandler, C; Diaz-Asper, C; Turner, RS; Reynolds, B; Elvevag, B","An explainable machine learning model of cognitive decline derived from speech","ALZHEIMER'S & DEMENTIA: DIAGNOSIS, ASSESSMENT & DISEASE MONITORING","","2352-8729","10.1002/dad2.12516","","INTRODUCTION: Traditional Alzheimer's disease (AD) and mild cognitive impairment (MCI) screening lacks the sensitivity and timeliness required to detect subtle indicators of cognitive decline. Multimodal artificial intelligence technologies using only speech data promise improved detection of neurodegenerative disorders.METHODS: Speech collected over the telephone from 91 older participants who were cognitively healthy (n = 29) or had diagnoses of AD (n = 30) or amnestic MCI (aMCI; n = 32) was analyzed with multimodal natural language and speech processing methods. An explainable ensemble decision tree classifier for the multiclass prediction of cognitive decline was created.RESULTS: This approach was 75% accurate overall-an improvement over traditional speech-based screening tools and a unimodal language-based model. We include a dashboard for the examination of the results, allowing for novel ways of interpreting such data.DISCUSSION: This work provides a foundation for a meaningful change in medicine as clinical translation, scalability, and user friendliness were core to the methodologies.","2023-10","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","4","15","","","","","","","","","","English","","","","WOS:001133061400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Alzheimer's disease; ALZHEIMERS-DISEASE; cognitive screening; IMPAIRMENT; MCI; multimodal machine learning; NLP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QKBTDTE3","journalArticle","2022","Liu, ZM; Paek, EJ; Yoon, SO; Casenhiser, D; Zhou, WJ; Zhao, XP","Detecting Alzheimer's Disease Using Natural Language Processing of Referential Communication Task Transcripts","JOURNAL OF ALZHEIMERS DISEASE","","1387-2877","10.3233/JAD-215137","","Background: People with Alzheimer's disease (AD) often demonstrate difficulties in discourse production. Referential communication tasks (RCTs) are used to examine a speaker's capability to select and verbally code the characteristics of an object in interactive conversation. Objective: In this study, we used contextualized word representations from Natural language processing (NLP) to evaluate how well RCTs are able to distinguish between people with AD and cognitively healthy older adults. Methods: We adapted machine learning techniques to analyze manually transcribed speech transcripts in an RCT from 28 older adults, including 12 with AD and 16 cognitively healthy older adults. Two approaches were applied to classify these speech transcript samples: 1) using clinically relevant linguistic features, 2) using machine learned representations derived by a state-of-art pretrained NLP transfer learning model, Bidirectional Encoder Representation from Transformer (BERT) based classification model. Results: The results demonstrated the superior performance of AD detection using a designed transfer learning NLP algorithm. Moreover, the analysis showed that transcripts of a single image yielded high accuracies in AD detection. Conclusion: The results indicated that RCT may be useful as a diagnostic tool for AD, and that the task can be simplified to a subset of images without significant sacrifice to diagnostic accuracy, which can make RCT an easier and more practical tool for AD diagnosis. The results also demonstrate the potential of RCT as a tool to better understand cognitive deficits from the perspective of discourse production in people with AD.","2022","2025-02-26 20:36:59","2025-02-26 20:36:59","","1385-1398","","3","86","","","","","","","","","","English","","","","WOS:000778786700031","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","Alzheimer's disease; ASSOCIATION; AUTOMATIC DIAGNOSIS; COGNITIVE IMPAIRMENT; COMPREHENSION; CONCEPTUAL PACTS; DEMENTIA; DYSFUNCTION; early diagnosis; INDIVIDUALS; MEMORY; natural language processing; SPEECH; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KSR56T6W","journalArticle","2022","Nasrolahzadeh, M; Rahnamayan, S; Haddadnia, J","Alzheimer's disease diagnosis using genetic programming based on higher order spectra features","MACHINE LEARNING WITH APPLICATIONS","","2666-8270","10.1016/j.mlwa.2021.100225","","In Alzheimer's diagnosis field, Computer -Aided Diagnosis (CADx) technology can improve the work performance of medical researchers and practitioners since it gives early chances to patient's eligibility for clinical trials. The aim of this study is to develop a novel CADx system for the diagnosis of Alzheimer's disease (AD) by utilizing genetic programming (GP) as data -driven evolutionary computation based modeling. The proposed method invokes a majority voting based scheme to select a set of most discriminant features which leads to the highest diagnosis accuracy of the final classification. The effectiveness of GP in categorizing patients with Alzheimer's versus healthy group was revealed by developing models according to their performance in terms of higher -order spectra (HOS) features. The results show that the GP method achieved better performance compared to other the -state-of-the-art approaches. It is also found that the highest accuracy index was yielded by using the proposed data -driven modeling technique. The results of this study emphasize the practicality of GP -based method for developing CADx systems, on the basis of spontaneous speech analysis; can efficiently assist in the diagnosis of Alzheimer's disease.","2022-03-15","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","7","","","","","","","","","","English","","","","WOS:001222874100013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","Alzheimer's disease; BISPECTRAL ANALYSIS; Classification; CLASSIFICATION; DEMENTIA; Feature selection; FORM; Genetic programming; GUIDELINES; IDENTIFICATION; Machine learning; PATHOLOGICAL DIAGNOSIS; Spontaneous speech signal; SPONTANEOUS SPEECH SIGNALS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TSUQWVS2","journalArticle","2024","Jahan, Z; Khan, SB; Saraee, M","Early dementia detection with speech analysis and machine learning techniques","DISCOVER SUSTAINABILITY","","2662-9984","10.1007/s43621-024-00217-2","","This in-depth study journey explores the context of natural language processing and text analysis in dementia detection, revealing their importance in a variety of fields. Beginning with an examination of the widespread and influence of text data. The dataset utilised in this study is from TalkBank's DementiaBank, which is basically a vast database of multimedia interactions built with the goal of examining communication patterns in the context of dementia. The various communication styles dementia patients exhibit when communicating with others are seen from a unique perspective by this specific dataset. Thorough data preprocessing procedures, including cleansing, tokenization, and structuring, are undertaken, with a focus on improving prediction capabilities through the combination of textual and non-textual information in the field of feature engineering. In the subsequent phase, the precision, recall, and F1-score metrics of Support Vector Machines (SVM), K-Nearest Neighbours (KNN), Random Forest, and Artificial Neural Networks (ANN) are assessed. Empirical facts are synthesized using text analysis methods and models to formulate a coherent conclusion. The significance of text data analysis, the revolutionary potential of natural language processing, and the direction for future research are highlighted in this synthesis. Throughout this paper, readers are encouraged to leverage text data to embark on their own adventures in the evolving, data-centric world of dementia detection.","2024-04-11","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","1","5","","","","","","","","","","English","","","","WOS:001200442700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;11</p>","","","Classification; Dementia; Feature extraction; Machine learning; Speech transcript analysis; Text mining; Word embedding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7JSWL4SK","journalArticle","2022","Liu, N; Yuan, ZM; Tang, QF","Improving Alzheimer's Disease Detection for Speech Based on Feature Purification Network","FRONTIERS IN PUBLIC HEALTH","","2296-2565","10.3389/fpubh.2021.835960","","Alzheimer's disease (AD) is a neurodegenerative disease involving the decline of cognitive ability with illness progresses. At present, the diagnosis of AD mainly depends on the interviews between patients and doctors, which is slow, expensive, and subjective, so it is not a better solution to recognize AD using the currently available neuropsychological examinations and clinical diagnostic criteria. A recent study has indicated the potential of language analysis for AD diagnosis. In this study, we proposed a novel feature purification network that can improve the representation learning of transformer model further. Though transformer has made great progress in generating discriminative features because of its long-distance reasoning ability, there is still room for improvement. There exist many common features that are not indicative of any specific class, and we rule out the influence of common features from traditional features extracted by transformer encoder and can get more discriminative features for classification. We apply this method to improve transformer's performance on three public dementia datasets and get improved classification results markedly. Specifically, the method on Pitt datasets gets state-of-the-art (SOTA) result.","2022-03-03","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","9","","","","","","","","","","English","","","","WOS:000772107200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Alzheimer's disease; AUTOMATIC DIAGNOSIS; deep learning; DEMENTIA; machine learning; mild cognitive impairment; MILD COGNITIVE IMPAIRMENT; natural language processing; speech and language; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IL8T9KHU","journalArticle","2023","Priyadarshinee, P; Clarke, CJ; Melechovsky, J; Lin, CMY; Balamurali, BT; Chen, JM","Alzheimer's Dementia Speech (Audio vs. Text): Multi-Modal Machine Learning at High vs. Low Resolution","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13074244","","Automated techniques to detect Alzheimer's Dementia through the use of audio recordings of spontaneous speech are now available with varying degrees of reliability. Here, we present a systematic comparison across different modalities, granularities and machine learning models to guide in choosing the most effective tools. Specifically, we present a multi-modal approach (audio and text) for the automatic detection of Alzheimer's Dementia from recordings of spontaneous speech. Sixteen features, including four feature extraction methods (Energy-Time plots, Keg of Text Analytics, Keg of Text Analytics-Extended and Speech to Silence ratio) not previously applied in this context were tested to determine their relative performance. These features encompass two modalities (audio vs. text) at two resolution scales (frame-level vs. file-level). We compared the accuracy resulting from these features and found that text-based classification outperformed audio-based classification with the best performance attaining 88.7%, surpassing other reports to-date relying on the same dataset. For text-based classification in particular, the best file-level feature performed 9.8% better than the frame-level feature. However, when comparing audio-based classification, the best frame-level feature performed 1.4% better than the best file-level feature. This multi-modal multi-model comparison at high- and low-resolution offers insights into which approach is most efficacious, depending on the sampling context. Such a comparison of the accuracy of Alzheimer's Dementia classification using both frame-level and file-level granularities on audio and text modalities of different machine learning models on the same dataset has not been previously addressed. We also demonstrate that the subject's speech captured in short time frames and their dynamics may contain enough inherent information to indicate the presence of dementia. Overall, such a systematic analysis facilitates the identification of Alzheimer's Dementia quickly and non-invasively, potentially leading to more timely interventions and improved patient outcomes.","2023-04","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","7","13","","","","","","","","","","English","","","","WOS:000972106200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Alzheimer's Dementia; deep learning; DISEASE; RECOGNITION; spontaneous speech; text/acoustic analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CJY8T373","journalArticle","2024","Amini, S; Hao, BR; Yang, JM; Karjadi, C; Kolachalama, VB; Au, R; Paschalidis, IC","Prediction of Alzheimer's disease progression within 6 years using speech: A novel approach leveraging language models","ALZHEIMERS & DEMENTIA","","1552-5260","10.1002/alz.13886","","INTRODUCTIONIdentification of individuals with mild cognitive impairment (MCI) who are at risk of developing Alzheimer's disease (AD) is crucial for early intervention and selection of clinical trials. METHODSWe applied natural language processing techniques along with machine learning methods to develop a method for automated prediction of progression to AD within 6 years using speech. The study design was evaluated on the neuropsychological test interviews of n = 166 participants from the Framingham Heart Study, comprising 90 progressive MCI and 76 stable MCI cases. RESULTSOur best models, which used features generated from speech data, as well as age, sex, and education level, achieved an accuracy of 78.5% and a sensitivity of 81.1% to predict MCI-to-AD progression within 6 years. DISCUSSIONThe proposed method offers a fully automated procedure, providing an opportunity to develop an inexpensive, broadly accessible, and easy-to-administer screening tool for MCI-to-AD progression prediction, facilitating development of remote assessment. Highlights Voice recordings from neuropsychological exams coupled with basic demographics can lead to strong predictive models of progression to dementia from mild cognitive impairment. The study leveraged AI methods for speech recognition and processed the resulting text using language models. The developed AI-powered pipeline can lead to fully automated assessment that could enable remote and cost-effective screening and prognosis for Alzehimer's disease.","2024-08","2025-02-26 20:36:59","2025-02-26 20:36:59","","5262-5270","","8","20","","","","","","","","","","English","","","","WOS:001253890000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","AGE; Alzheimer's disease prognosis; APOLIPOPROTEIN-E; CONVERSION; CSF; DEMENTIA; Framingham Heart Study; MILD COGNITIVE IMPAIRMENT; natural language processing; neuropsychological test; NEUROPSYCHOLOGICAL TESTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZDHFEWWN","journalArticle","2021","Balagopalan, A; Eyre, B; Robin, J; Rudzicz, F; Novikova, J","Comparing Pre-trained and Feature-Based Models for Prediction of Alzheimer's Disease Based on Speech","FRONTIERS IN AGING NEUROSCIENCE","","1663-4365","10.3389/fnagi.2021.635945","","Introduction: Research related to the automatic detection of Alzheimer's disease (AD) is important, given the high prevalence of AD and the high cost of traditional diagnostic methods. Since AD significantly affects the content and acoustics of spontaneous speech, natural language processing, and machine learning provide promising techniques for reliably detecting AD. There has been a recent proliferation of classification models for AD, but these vary in the datasets used, model types and training and testing paradigms. In this study, we compare and contrast the performance of two common approaches for automatic AD detection from speech on the same, well-matched dataset, to determine the advantages of using domain knowledge vs. pre-trained transfer models. Methods: Audio recordings and corresponding manually-transcribed speech transcripts of a picture description task administered to 156 demographically matched older adults, 78 with Alzheimer's Disease (AD) and 78 cognitively intact (healthy) were classified using machine learning and natural language processing as ""AD"" or ""non-AD."" The audio was acoustically-enhanced, and post-processed to improve quality of the speech recording as well control for variation caused by recording conditions. Two approaches were used for classification of these speech samples: (1) using domain knowledge: extracting an extensive set of clinically relevant linguistic and acoustic features derived from speech and transcripts based on prior literature, and (2) using transfer-learning and leveraging large pre-trained machine learning models: using transcript-representations that are automatically derived from state-of-the-art pre-trained language models, by fine-tuning Bidirectional Encoder Representations from Transformer (BERT)-based sequence classification models. Results: We compared the utility of speech transcript representations obtained from recent natural language processing models (i.e., BERT) to more clinically-interpretable language feature-based methods. Both the feature-based approaches and fine-tuned BERT models significantly outperformed the baseline linguistic model using a small set of linguistic features, demonstrating the importance of extensive linguistic information for detecting cognitive impairments relating to AD. We observed that fine-tuned BERT models numerically outperformed feature-based approaches on the AD detection task, but the difference was not statistically significant. Our main contribution is the observation that when tested on the same, demographically balanced dataset and tested on independent, unseen data, both domain knowledge and pretrained linguistic models have good predictive performance for detecting AD based on speech. It is notable that linguistic information alone is capable of achieving comparable, and even numerically better, performance than models including both acoustic and linguistic features here. We also try to shed light on the inner workings of the more black-box natural language processing model by performing an interpretability analysis, and find that attention weights reveal interesting patterns such as higher attribution to more important information content units in the picture description task, as well as pauses and filler words. Conclusion: This approach supports the value of well-performing machine learning and linguistically-focussed processing techniques to detect AD from speech and highlights the need to compare model performance on carefully balanced datasets, using consistent same training parameters and independent test datasets in order to determine the best performing predictive model.","2021-04-27","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","13","","","","","","","","","","English","","","","WOS:000648882600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;43<br/>Total Times Cited:&nbsp;&nbsp;45<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Alzheimer&apos; BERT; COGNITIVE FUNCTION; dementia detection; EARLY-LIFE; feature engineering; LINGUISTIC ABILITY; MMSE regression; PICTURE DESCRIPTION; s disease; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6ZBWEPAR","journalArticle","2023","Köenig, A; Linz, N; Baykara, E; Tröger, J; Ritchie, C; Saunders, S; Teipel, S; Köhler, S; Sánchez-Benavides, G; Grau-Rivera, O; Gispert, JD; Palmqvist, S; Tideman, P; Hansson, O","Screening over Speech in Unselected Populations for Clinical Trials in AD (PROSPECT-AD): Study Design and Protocol","JPAD-JOURNAL OF PREVENTION OF ALZHEIMERS DISEASE","","2274-5807","10.14283/jpad.2023.11","","BackgroundSpeech impairments are an early feature of Alzheimer's disease (AD) and consequently, analysing speech performance is a promising new digital biomarker for AD screening. Future clinical AD trials on disease modifying drugs will require a shift to very early identification of individuals at risk of dementia. Hence, digital markers of language and speech may offer a method for screening of at-risk populations that are at the earliest stages of AD, eventually in combination with advanced machine learning. To this end, we developed a screening battery consisting of speech-based neurocognitive tests. The automated test performs a remote primary screening using a simple telephone.ObjectivesPROSPECT-AD aims to validate speech biomarkers for identification of individuals with early signs of AD and monitor their longitudinal course through access to well-phenotyped cohorts.DesignPROSPECT-AD leverages ongoing cohorts such as EPAD (UK), DESCRIBE and DELCODE (Germany), and BioFINDER Primary Care (Sweden) and Beta-AARC (Spain) by adding a collection of speech data over the telephone to existing longitudinal follow-ups. Participants at risk of dementia are recruited from existing parent cohorts across Europe to form an AD 'probability-spectrum', i.e., individuals with a low risk to high risk of developing AD dementia. The characterization of cognition, biomarker and risk factor (genetic and environmental) status of each research participants over time combined with audio recordings of speech samples will provide a well-phenotyped population for comparing novel speech markers with current gold standard biomarkers and cognitive scores.ParticipantsN= 1000 participants aged 50 or older will be included in total, with a clinical dementia rating scale (CDR) score of 0 or 0.5. The study protocol is planned to run according to sites between 12 and 18 months.MeasurementsThe speech protocol includes the following neurocognitive tests which will be administered remotely: Word List [Memory Function], Verbal Fluency [Executive Functions] and spontaneous free speech [Psychological and/ or behavioral symptoms]. Speech features on the linguistic and paralinguistic level will be extracted from the recordings and compared to data from CSF and blood biomarkers, neuroimaging, neuropsychological evaluations, genetic profiles, and family history. Primary candidate marker from speech will be a combination of most significant features in comparison to biomarkers as reference measure.Machine learning and computational techniques will be employed to identify the most significant speech biomarkers that could represent an early indicator of AD pathology. Furthermore, based on the analysis of speech performances, models will be trained to predict cognitive decline and disease progression across the AD continuum.ConclusionThe outcome of PROSPECT-AD may support AD drug development research as well as primary or tertiary prevention of dementia by providing a validated tool using a remote approach for identifying individuals at risk of dementia and monitoring individuals over time, either in a screening context or in clinical trials.","2023-04","2025-02-26 20:36:59","2025-02-26 20:36:59","","314-321","","2","10","","","","","","","","","","English","","","","WOS:000913811100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;14</p>","","","Alzheimer's disease; cognitive assessment; Dementia; DISEASE; machine learning; phone-based; screening; speech biomarker","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VWIXPYFM","journalArticle","2025","Dino, FR; Pressman, PS; Cohen, KB; Dubljevic, V; Jarrold, W; Foltz, PW; Decamp, M; Mahoor, MH; Hunter, LE","Ethics in digital phenotyping: considerations regarding Alzheimer's disease, speech and artificial intelligence","JOURNAL OF MEDICAL ETHICS","","0306-6800","10.1136/jme-2024-110252","","Artificial intelligence (AI)-based digital phenotyping, including computational speech analysis, increasingly allows for the collection of diagnostically relevant information from an ever-expanding number of sources. Such information usually assesses human behaviour, which is a consequence of the nervous system, and so digital phenotyping may be particularly helpful in diagnosing neurological illnesses such as Alzheimer's disease. As illustrated by the use of computational speech analysis of Alzheimer's disease, however, neurological illness also introduces ethical considerations beyond commonly recognised concerns regarding machine learning and data collection in everyday environments. Individuals' decision-making capacity cannot be assumed. Understanding of analytical results will likely be limited even as the personal significance of those results is both highly sensitive and personal. In a traditional clinical evaluation, there is an opportunity to ensure that information is relayed in a way that is highly customised to the individual's ability to understand results and make decisions, and privacy is closely protected. Can any such assurance be offered as digital phenotyping technology continues to advance? AI-supported digital phenotyping offers great promise in neurocognitive disorders such as Alzheimer's disease, but it also poses ethical challenges. We outline some of these risks as well as strategies for risk mitigation.","2025-01-31","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","","","","","","","","","","","English","","","","WOS:001413311500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","AUTONOMY; Dementia; DIAGNOSIS; DISPARITIES; Ethics; Ethics-Medical; Ethics-Research; FRAMEWORK; PRINCIPLES; RESPECT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VETV3WCI","journalArticle","2021","Guo, Y; Li, CY; Roan, C; Pakhomov, S; Cohen, T","Crossing the ""Cookie Theft "" Corpus Chasm: Applying What BERT Learns From Outside Data to the ADReSS Challenge Dementia Detection Task","FRONTIERS IN COMPUTER SCIENCE","","2624-9898","10.3389/fcomp.2021.642517","","Large amounts of labeled data are a prerequisite to training accurate and reliable machine learning models. However, in the medical domain in particular, this is also a stumbling block as accurately labeled data are hard to obtain. DementiaBank, a publicly available corpus of spontaneous speech samples from a picture description task widely used to study Alzheimer's disease (AD) patients' language characteristics and for training classification models to distinguish patients with AD from healthy controls, is relatively small-a limitation that is further exacerbated when restricting to the balanced subset used in the Alzheimer's Dementia Recognition through Spontaneous Speech (ADReSS) challenge. We build on previous work showing that the performance of traditional machine learning models on DementiaBank can be improved by the addition of normative data from other sources, evaluating the utility of such extrinsic data to further improve the performance of state-of-the-art deep learning based methods on the ADReSS challenge dementia detection task. To this end, we developed a new corpus of professionally transcribed recordings from the Wisconsin Longitudinal Study (WLS), resulting in 1366 additional Cookie Theft Task transcripts, increasing the available training data by an order of magnitude. Using these data in conjunction with DementiaBank is challenging because the WLS metadata corresponding to these transcripts do not contain dementia diagnoses. However, cognitive status of WLS participants can be inferred from results of several cognitive tests including semantic verbal fluency available in WLS data. In this work, we evaluate the utility of using the WLS 'controls' (participants without indications of abnormal cognitive status), and these data in conjunction with inferred 'cases' (participants with such indications) for training deep learning models to discriminate between language produced by patients with dementia and healthy controls. We find that incorporating WLS data during training a BERT model on ADReSS data improves its performance on the ADReSS dementia detection task, supporting the hypothesis that incorporating WLS data adds value in this context. We also demonstrate that weighted cost functions and additional prediction targets may be effective ways to address issues arising from class imbalance and confounding effects due to data provenance.","2021-04-16","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","3","","","","","","","","","","English","","","","WOS:000705938200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;20<br/>Total Times Cited:&nbsp;&nbsp;20<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","ALZHEIMER-DISEASE; Alzheimer's disease; BERT; CARE; COHORT; dementia diagnosis; DIAGNOSIS; machine learning; natural language processing; VERBAL FLUENCY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UXTJ57WF","journalArticle","2021","Yeung, A; Iaboni, A; Rochon, E; Lavoie, M; Santiago, C; Yancheva, M; Novikova, J; Xu, MD; Robin, J; Kaufman, LD; Mostafa, F","Correlating natural language processing and automated speech analysis with clinician assessment to quantify speech-language changes in mild cognitive impairment and Alzheimer's dementia","ALZHEIMERS RESEARCH & THERAPY","","1758-9193","10.1186/s13195-021-00848-x","","Background Language impairment is an important marker of neurodegenerative disorders. Despite this, there is no universal system of terminology used to describe these impairments and large inter-rater variability can exist between clinicians assessing language. The use of natural language processing (NLP) and automated speech analysis (ASA) is emerging as a novel and potentially more objective method to assess language in individuals with mild cognitive impairment (MCI) and Alzheimer's dementia (AD). No studies have analyzed how variables extracted through NLP and ASA might also be correlated to language impairments identified by a clinician. Methods Audio recordings (n=30) from participants with AD, MCI, and controls were rated by clinicians for word-finding difficulty, incoherence, perseveration, and errors in speech. Speech recordings were also transcribed, and linguistic and acoustic variables were extracted through NLP and ASA. Correlations between clinician-rated speech characteristics and the variables were compared using Spearman's correlation. Exploratory factor analysis was applied to find common factors between variables for each speech characteristic. Results Clinician agreement was high in three of the four speech characteristics: word-finding difficulty (ICC = 0.92, p<0.001), incoherence (ICC = 0.91, p<0.001), and perseveration (ICC = 0.88, p<0.001). Word-finding difficulty and incoherence were useful constructs at distinguishing MCI and AD from controls, while perseveration and speech errors were less relevant. Word-finding difficulty as a construct was explained by three factors, including number and duration of pauses, word duration, and syntactic complexity. Incoherence was explained by two factors, including increased average word duration, use of past tense, and changes in age of acquisition, and more negative valence. Conclusions Variables extracted through automated acoustic and linguistic analysis of MCI and AD speech were significantly correlated with clinician ratings of speech and language characteristics. Our results suggest that correlating NLP and ASA with clinician observations is an objective and novel approach to measuring speech and language changes in neurodegenerative disorders.","2021-06-04","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","1","13","","","","","","","","","","English","","","","WOS:000658167400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;47<br/>Total Times Cited:&nbsp;&nbsp;50<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Alzheimer's; Automated speech analysis; COHERENCE; DECLINE; Dementia; DISCOURSE PRODUCTION; DISEASE; EXPLORATORY FACTOR-ANALYSIS; FEATURES; Machine learning; Markers; Mild cognitive impairment; Natural language processing; PRIMARY PROGRESSIVE APHASIA; RELIABILITY; SAMPLE; SCALE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ULS5F7UN","journalArticle","2022","Fristed, E; Skirrow, C; Meszaros, M; Lenain, R; Meepegama, U; Cappa, S; Aarsland, D; Weston, J","A remote speech-based AI system to screen for early Alzheimer's disease via smartphones","ALZHEIMER'S & DEMENTIA: DIAGNOSIS, ASSESSMENT & DISEASE MONITORING","","2352-8729","10.1002/dad2.12366","","IntroductionArtificial intelligence (AI) systems leveraging speech and language changes could support timely detection of Alzheimer's disease (AD). MethodsThe AMYPRED study (NCT04828122) recruited 133 subjects with an established amyloid beta (A beta) biomarker (66 A beta+, 67 A beta-) and clinical status (71 cognitively unimpaired [CU], 62 mild cognitive impairment [MCI] or mild AD). Daily story recall tasks were administered via smartphones and analyzed with an AI system to predict MCI/mild AD and A beta positivity. ResultsEighty-six percent of participants (115/133) completed remote assessments. The AI system predicted MCI/mild AD (area under the curve [AUC] = 0.85, +/- 0.07) but not A beta (AUC = 0.62 +/- 0.11) in the full sample, and predicted A beta in clinical subsamples (MCI/mild AD: AUC = 0.78 +/- 0.14; CU: AUC = 0.74 +/- 0.13) on short story variants (immediate recall). Long stories and delayed retellings delivered broadly similar results. DiscussionSpeech-based testing offers simple and accessible screening for early-stage AD.","2022","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","1","14","","","","","","","","","","English","","","","WOS:000914865700103","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;16<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Alzheimer's disease; artificial intelligence; clinical assessment; clinical screening; deep learning; DEMENTIA; DIAGNOSIS; diagnostics; digital health; episodic memory; IMPLEMENTATION; language; machine learning; mild cognitive impairment; MILD COGNITIVE IMPAIRMENT; MINI-MENTAL-STATE; PREVALENCE; RECOMMENDATIONS; remote; speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LL4UXNIN","journalArticle","2021","Chang, CH; Lin, CH; Liu, CY; Huang, CS; Chen, SJ; Lin, WC; Yang, HT; Lane, HY","Plasma d-glutamate levels for detecting mild cognitive impairment and Alzheimer's disease: Machine learning approaches","JOURNAL OF PSYCHOPHARMACOLOGY","","0269-8811","10.1177/0269881120972331","","Background: d-glutamate, which is involved in N-methyl-d-aspartate receptor modulation, may be associated with cognitive ageing. Aims: This study aimed to use peripheral plasma d-glutamate levels to differentiate patients with mild cognitive impairment (MCI) and Alzheimer's disease (AD) from healthy individuals and to evaluate its prediction ability using machine learning. Methods: Overall, 31 healthy controls, 21 patients with MCI and 133 patients with AD were recruited. Serum d-glutamate levels were measured using high-performance liquid chromatography (HPLC). Cognitive deficit severity was assessed using the Clinical Dementia Rating scale and the Mini-Mental Status Examination (MMSE). We employed four machine learning algorithms (support vector machine, logistic regression, random forest and naive Bayes) to build an optimal predictive model to distinguish patients with MCI or AD from healthy controls. Results: The MCI and AD groups had lower plasma d-glutamate levels (1097.79 +/- 283.99 and 785.10 +/- 720.06 ng/mL, respectively) compared to healthy controls (1620.08 +/- 548.80 ng/mL). The naive Bayes model and random forest model appeared to be the best models for determining MCI and AD susceptibility, respectively (area under the receiver operating characteristic curve: 0.8207 and 0.7900; sensitivity: 0.8438 and 0.6997; and specificity: 0.8158 and 0.9188, respectively). The total MMSE score was positively correlated with d-glutamate levels (r = 0.368, p < 0.001). Multivariate regression analysis indicated that d-glutamate levels were significantly associated with the total MMSE score (B = 0.003, 95% confidence interval 0.002-0.005, p < 0.001). Conclusions: Peripheral plasma d-glutamate levels were associated with cognitive impairment and may therefore be a suitable peripheral biomarker for detecting MCI and AD. Rapid and cost-effective HPLC for biomarkers and machine learning algorithms may assist physicians in diagnosing MCI and AD in outpatient clinics.","2021-03","2025-02-26 20:36:59","2025-02-26 20:36:59","","265-272","","3","35","","","","","","","","","","English","","","","WOS:000624033800006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;27<br/>Total Times Cited:&nbsp;&nbsp;28<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Alzheimer’; d-glutamate; machine learning; mild cognitive impairment; s disease","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UXCBELBW","journalArticle","2024","Burke, E; Gunstad, J; Pavlenko, O; Hamrick, P","Distinguishable features of spontaneous speech in Alzheimer's clinical syndrome and healthy controls","AGING NEUROPSYCHOLOGY AND COGNITION","","1382-5585","10.1080/13825585.2023.2221020","","There is growing evidence that subtle changes in spontaneous speech may reflect early pathological changes in cognitive function. Recent work has found that lexical-semantic features of spontaneous speech predict cognitive dysfunction in individuals with mild cognitive impairment (MCI). The current study assessed whether Ostrand and Gunstad's (OG) lexical-semantic features extend to predicting cognitive status in a sample of individuals with Alzheimer's clinical syndrome (ACS) and healthy controls. Four additional (New) speech indices shown to be important in language processing research were also explored in this sample to extend prior work. Speech transcripts of the Cookie Theft Task from 81 individuals with ACS (M-age = 72.7 years, SD = 8.80, 70.4% female) and 61 healthy controls (HC) (M-age = 63.9 years, SD = 8.52, 62.3% female) from Dementia Bank were analyzed. Random forest and logistic machine learning techniques examined whether subject-level lexical-semantic features could be used to accurately discriminate those with ACS from HC. Results showed that logistic models with the New lexical-semantic features obtained good classification accuracy (78.4%), but the OG features had wider success across machine learning model types. In terms of sensitivity and specificity, the random forest model trained on the OG features was the most balanced. Findings from the current study suggest that features of spontaneous speech used to predict MCI may also distinguish between individuals with ACS and healthy controls. Future work should evaluate these lexical-semantic features in pre-clinical persons to further explore their potential to assist with early detection through speech analysis.","2024-05-03","2025-02-26 20:36:59","2025-02-26 20:36:59","","575-586","","3","31","","","","","","","","","","English","","","","WOS:001002819000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","Alzheimer's clinical syndrome; Alzheimer's disease (AD); BASES; CONNECTED SPEECH; DEMENTIA; DISEASE; DIVERSITY; FREQUENCY; LANGUAGE; machine learning; MILD COGNITIVE IMPAIRMENT; PERFORMANCE; SEMANTIC MEMORY; Spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WVR22CQQ","journalArticle","2022","Liang, XH; Batsis, JA; Zhu, YX; Driesse, TM; Roth, RM; Kotz, D; MacWhinney, B","Evaluating voice-assistant commands for dementia detection","COMPUTER SPEECH AND LANGUAGE","","0885-2308","10.1016/j.csl.2021.101297","","Early detection of cognitive decline involved in Alzheimer's Disease and Related Dementias (ADRD) in older adults living alone is essential for developing, planning, and initiating interventions and support systems to improve users' everyday function and quality of life. In this paper, we explore the voice commands using a Voice-Assistant System (VAS), i.e., Amazon Alexa, from 40 older adults who were either Healthy Control (HC) participants or Mild Cognitive Impairment (MCI) participants, age 65 or older. We evaluated the data collected from voice commands, cognitive assessments, and interviews and surveys using a structured protocol. We extracted 163 unique command-relevant features from each participant's use of the VAS. We then built machine-learning models including 1-layer/2-layer neural networks, support vector machines, decision tree, and random forest, for classification and comparison with standard cognitive assessment scores, e.g., Montreal Cognitive Assessment (MoCA). Our classification models using fusion features achieved an accuracy of 68%, and our regression model resulted in a Root-Mean-Square Error (RMSE) score of 3.53. Our Decision Tree (DT) and Random Forest (RF) models using selected features achieved higher classification accuracy 80%-90%. Finally, we analyzed the contribution of each feature set to the model output, thus revealing the commands and features most useful in inferring the participants' cognitive status. We found that features of overall performance, features of music-related commands, features of call-related commands, and features from Automatic Speech Recognition (ASR) were the top-four feature sets most impactful on inference accuracy. The results from this controlled study demonstrate the promise of future home-based cognitive assessments using Voice-Assistant Systems.","2022-03","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","72","","","","","","","","","","English","","","","WOS:000728821200012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Alzheimer's disease; ALZHEIMERS-DISEASE; Cognitive decline; COHORT; COMMUNICATION; CONNECTED SPEECH; DEFICITS; HISTORY; LANGUAGE COMPREHENSION; Machine learning; MEMORY; PERFORMANCE; PROFILES; Speech analysis; Voice assistant","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KMWYXHS4","journalArticle","2024","Kobayashi, M; Yamada, Y; Shinkawa, K; Nemoto, M; Ota, M; Nemoto, K; Arai, T","Vocal expression of emotions discriminates dementia with Lewy bodies from Alzheimer's disease","ALZHEIMER'S & DEMENTIA: DIAGNOSIS, ASSESSMENT & DISEASE MONITORING","","2352-8729","10.1002/dad2.12594","","Dementia with Lewy bodies (DLB) and Alzheimer's disease (AD), the two most common neurodegenerative dementias, both exhibit altered emotional processing. However, how vocal emotional expressions alter in and differ between DLB and AD remains uninvestigated. We collected voice data during story reading from 152 older adults comprising DLB, AD, and cognitively unimpaired (CU) groups and compared their emotional prosody in terms of valence and arousal dimensions. Compared with matched AD and CU participants, DLB patients showed reduced overall emotional expressiveness, as well as lower valence (more negative) and lower arousal (calmer), the extent of which was associated with cognitive impairment and insular atrophy. Classification models using vocal features discriminated DLB from AD and CU with an AUC of 0.83 and 0.78, respectively. Our findings may aid in discriminating DLB patients from AD and CU individuals, serving as a surrogate marker for clinical and neuropathological changes in DLB.Highlights DLB showed distinctive reduction in vocal expression of emotions. Cognitive impairment was associated with reduced vocal emotional expression in DLB. Insular atrophy was associated with reduced vocal emotional expression in DLB. Emotional expression measures successfully differentiated DLB from AD or controls.","2024-04","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","2","16","","","","","","","","","","English","","","","WOS:001215525800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","affective prosody; AFFECTIVE PROSODY; arousal; ASSOCIATION WORKGROUPS; BRAIN; DIAGNOSTIC GUIDELINES; digital health; emotional processing; IMPAIRMENT; Lewy body dementia; machine learning; NATIONAL INSTITUTE; RECOGNITION; RECOMMENDATIONS; SPEECH; valence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZZKBQ3NZ","journalArticle","2021","Shah, Z; Sawalha, J; Tasnim, M; Qi, SA; Stroulia, E; Greiner, R","Learning Language and Acoustic Models for Identifying Alzheimer's Dementia From Speech","FRONTIERS IN COMPUTER SCIENCE","","2624-9898","10.3389/fcomp.2021.624659","","Alzheimer's dementia (AD) is a chronic neurodegenerative illness that manifests in a gradual decline of cognitive function. Early identification of AD is essential for managing the ensuing cognitive deficits, which may lead to a better prognostic outcome. Speech data can serve as a window into cognitive functioning and can be used to screen for early signs of AD. This paper describes methods for learning models using speech samples from the DementiaBank database, for identifying which subjects have Alzheimer's dementia. We consider two machine learning tasks: 1) binary classification to distinguish patients from healthy controls, and 2) regression to estimate each subject's Mini-Mental State Examination (MMSE) score. To develop models that can use acoustic and/or language features, we explore a variety of dimension reduction techniques, training algorithms, and fusion strategies. Our best performing classification model, using language features with dimension reduction and regularized logistic regression, achieves an accuracy of 85.4% on a held-out test set. On the regression task, a linear regression model trained on a reduced set of language features achieves a root mean square error (RMSE) of 5.62 on the test set. These results demonstrate the promise of using machine learning for detecting cognitive decline from speech in AD patients.","2021-02-09","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","3","","","","","","","","","","English","","","","WOS:000705871400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;25<br/>Total Times Cited:&nbsp;&nbsp;27<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","automatic analysis of speaker states and traits; DISEASE; HISTORY; machine learning; MILD COGNITIVE IMPAIRMENT; natural language proceeding (NLP); pathological speech and language; speech and audio classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XGE5FYTK","journalArticle","2024","Runde, BS; Alapati, A; Bazan, NG","The Optimization of a Natural Language Processing Approach for the Automatic Detection of Alzheimer's Disease Using GPT Embeddings","BRAIN SCIENCES","","2076-3425","10.3390/brainsci14030211","","The development of noninvasive and cost-effective methods of detecting Alzheimer's disease (AD) is essential for its early prevention and mitigation. We optimize the detection of AD using natural language processing (NLP) of spontaneous speech through the use of audio enhancement techniques and novel transcription methodologies. Specifically, we utilized Boll Spectral Subtraction to improve audio fidelity and created transcriptions using state-of-the-art AI services-locally-based Wav2Vec and Whisper, alongside cloud-based IBM Cloud and Rev AI-evaluating their performance against traditional manual transcription methods. Support Vector Machine (SVM) classifiers were then trained and tested using GPT-based embeddings of transcriptions. Our findings revealed that AI-based transcriptions largely outperformed traditional manual ones, with Wav2Vec (enhanced audio) achieving the best accuracy and F-1 score (0.99 for both metrics) for locally-based systems and Rev AI (standard audio) performing the best for cloud-based systems (0.96 for both metrics). Furthermore, this study revealed the detrimental effects of interviewer speech on model performance in addition to the minimal effect of audio enhancement. Based on our findings, current AI transcription and NLP technologies are highly effective at accurately detecting AD with available data but struggle to classify probable AD and mild cognitive impairment (MCI), a prodromal stage of AD, due to a lack of training data, laying the groundwork for the future implementation of an automatic AD detection system.","2024-03","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","3","14","","","","","","","","","","English","","","","WOS:001191772300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","dementia; embeddings; GPT; NLP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EMD4MC3D","journalArticle","2024","Bouazizi, M; Zheng, CH; Yang, SY; Ohtsuki, T","Dementia Detection from Speech: What If Language Models Are Not the Answer?","INFORMATION","","2078-2489","10.3390/info15010002","","A growing focus among scientists has been on researching the techniques of automatic detection of dementia that can be applied to the speech samples of individuals with dementia. Leveraging the rapid advancements in Deep Learning (DL) and Natural Language Processing (NLP), these techniques have shown great potential in dementia detection. In this context, this paper proposes a method for dementia detection from the transcribed speech of subjects. Unlike conventional methods that rely on advanced language models to address the ability of the subject to make coherent and meaningful sentences, our approach relies on the center of focus of the subjects and how it changes over time as the subject describes the content of the cookie theft image, a commonly used image for evaluating one's cognitive abilities. To do so, we divide the cookie theft image into regions of interest, and identify, in each sentence spoken by the subject, which regions are being talked about. We employed a Long Short-Term Memory (LSTM) neural network to learn different patterns of dementia subjects and control ones and used it to perform a 10-fold cross validation-based classification. Our experimental results on the Pitt corpus from the DementiaBank resulted in a 82.9% accuracy at the subject level and 81.0% at the sample level. By employing data-augmentation techniques, the accuracy at both levels was increased to 83.6% and 82.1%, respectively. The performance of our proposed method outperforms most of the conventional methods, which reach, at best, an accuracy equal to 81.5% at the subject level.","2024-01","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","1","15","","","","","","","","","","English","","","","WOS:001151582900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","ALZHEIMERS-DISEASE; AUTOMATIC DIAGNOSIS; deep learning; dementia detection; LSTM; machine learning; PRIMARY-CARE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SIEYGMZD","journalArticle","2021","Chlasta, K; Wolk, K","Towards Computer-Based Automated Screening of Dementia Through Spontaneous Speech","FRONTIERS IN PSYCHOLOGY","","1664-1078","10.3389/fpsyg.2020.623237","","Dementia, a prevalent disorder of the brain, has negative effects on individuals and society. This paper concerns using Spontaneous Speech (ADReSS) Challenge of Interspeech 2020 to classify Alzheimer's dementia. We used (1) VGGish, a deep, pretrained, Tensorflow model as an audio feature extractor, and Scikit-learn classifiers to detect signs of dementia in speech. Three classifiers (LinearSVM, Perceptron, 1NN) were 59.1% accurate, which was 3% above the best-performing baseline models trained on the acoustic features used in the challenge. We also proposed (2) DemCNN, a new PyTorch raw waveform-based convolutional neural network model that was 63.6% accurate, 7% more accurate then the best-performing baseline linear discriminant analysis model. We discovered that audio transfer learning with a pretrained VGGish feature extractor performs better than the baseline approach using automatically extracted acoustic features. Our DepCNN exhibits good generalization capabilities. Both methods presented in this paper offer progress toward new, innovative, and more effective computer-based screening of dementia through spontaneous speech.","2021-02-12","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","11","","","","","","","","","","English","","","","WOS:000621776600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","affective computing; ALZHEIMERS-DISEASE; AUDIO; convolutional neural network; dementia detection; DEPRESSION; machine learning; mental health monitoring; prosodic analysis; speech technology; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y64QP8UR","journalArticle","2021","Yamada, Y; Shinkawa, K; Kobayashi, M; Caggiano, V; Nemoto, M; Nemoto, K; Arai, T; König, A","Combining Multimodal Behavioral Data of Gait, Speech, and Drawing for Classification of Alzheimer's Disease and Mild Cognitive Impairment","JOURNAL OF ALZHEIMERS DISEASE","","1387-2877","10.3233/JAD-210684","","Background: Gait, speech, and drawing behaviors have been shown to be sensitive to the diagnosis of Alzheimer's disease (AD) and mild cognitive impairment (MCI). However, previous studies focused on only analyzing individual behavioral modalities, although these studies suggested that each of these modalities may capture different profiles of cognitive impairments associated with AD. Objective: We aimed to investigate if combining behavioral data of gait, speech, and drawing can improve classification performance compared with the use of individual modality and if each of these behavioral data can be associated with different cognitive and clinical measures for the diagnosis of AD and MCI. Methods: Behavioral data of gait, speech, and drawing were acquired from 118 AD, MCI, and cognitively normal (CN) participants. Results: Combining all three behavioral modalities achieved 93.0% accuracy for classifying AD, MCI, and CN, and only 81.9% when using the best individual behavioral modality. Each of these behavioral modalities was statistically significantly associated with different cognitive and clinical measures for diagnosing AD and MCI. Conclusion: Our findings indicate that these behaviors provide different and complementary information about cognitive impairments such that classification of AD and MCI is superior to using either in isolation.","2021","2025-02-26 20:36:59","2025-02-26 20:36:59","","315-327","","1","84","","","","","","","","","","English","","","","WOS:000722639900026","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;29<br/>Total Times Cited:&nbsp;&nbsp;32<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","ASSOCIATION WORKGROUPS; CONNECTED SPEECH; DEMENTIA; DIAGNOSTIC GUIDELINES; Drawing; FACTS; gait analysis; handwriting; machine learning; NATIONAL INSTITUTE; PATTERNS; RECOMMENDATIONS; speech; VARIABILITY; voice; walking","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CCSAA5LA","journalArticle","2024","Huang, LH; Yang, H; Che, YR; Yang, JJ","Automatic speech analysis for detecting cognitive decline of older adults","FRONTIERS IN PUBLIC HEALTH","","2296-2565","10.3389/fpubh.2024.1417966","","Background Speech analysis has been expected to help as a screening tool for early detection of Alzheimer's disease (AD) and mild-cognitively impairment (MCI). Acoustic features and linguistic features are usually used in speech analysis. However, no studies have yet determined which type of features provides better screening effectiveness, especially in the large aging population of China.Objective Firstly, to compare the screening effectiveness of acoustic features, linguistic features, and their combination using the same dataset. Secondly, to develop Chinese automated diagnosis model using self-collected natural discourse data obtained from native Chinese speakers.Methods A total of 92 participants from communities in Shanghai, completed MoCA-B and a picture description task based on the Cookie Theft under the guidance of trained operators, and were divided into three groups including AD, MCI, and heathy control (HC) based on their MoCA-B score. Acoustic features (Pitches, Jitter, Shimmer, MFCCs, Formants) and linguistic features (part-of-speech, type-token ratio, information words, information units) are extracted. The machine algorithms used in this study included logistic regression, random forest (RF), support vector machines (SVM), Gaussian Naive Bayesian (GNB), and k-Nearest neighbor (kNN). The validation accuracies of the same ML model using acoustic features, linguistic features, and their combination were compared.Results The accuracy with linguistic features is generally higher than acoustic features in training. The highest accuracy to differentiate HC and AD is 80.77% achieved by SVM, based on all the features extracted from the speech data, while the highest accuracy to differentiate HC and AD or MCI is 80.43% achieved by RF, based only on linguistic features.Conclusion Our results suggest the utility and validity of linguistic features in the automated diagnosis of cognitive impairment, and validated the applicability of automated diagnosis for Chinese language data.","2024-08-08","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","12","","","","","","","","","","English","","","","WOS:001294996600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","ALZHEIMERS-DISEASE; automatic speech recognition; CLASSIFICATION; cognitive decline; DEMENTIA; DIAGNOSIS; IMPAIRMENT; LANGUAGE; language aging; machine learning; natural language processing; PARAMETERS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"77PHKBZJ","journalArticle","2024","Rangaraju, B; Chinnadurai, T; Natarajan, S; Raja, V","Dual Attention Aware Octave Convolution Network for Early-Stage Alzheimer's Disease Detection","INFORMATION TECHNOLOGY AND CONTROL","","1392-124X","10.5755/j01.itc.53.1.34536","","Some of the most fundamental human capabilities, including thought, speech, and movement, may be lost due to brain illnesses. The most prevalent form of dementia, Alzheimer's disease (AD), is caused by a steady decline in brain function and is now incurable. Despite the challenges associated with making a conclusive diagnosis of AD, the field has generally shifted toward making diagnoses justified by patient records and neurological analysis, such as MRI. Reports of studies utilizing machine learning for AD identification have increased in recent years. In this publication, we report the results of our most recent research. It details a deep learning-based, 3D brain MRI-based method for automated AD detection. As a result, deep learning models have become increasingly popular in recent years for analyzing medical images. To aid in detecting Alzheimer's disease at an initial phase, we suggest a novel dual attention-aware Octave convolution-based deep learning network (DACN). The three main parts of DACN are as follows: First, we use Patch Convolutional Neural Network (PCNN) to identify discriminative features within each MRI patch while simultaneously boosting the features of abnormally altered micro-structures in the brain; second, we use an Octave convolution to minimize the spatial redundancy and widen the field of perception of the brain's structure; and third, we use a dual attention aware convolution classifier to dissect the resulting depiction further. An outstanding test accuracy of 99.87% is reached for categorizing dementia phases by employing the suggested method in experiments on a publicly available ADNI (Alzheimer's Disease Neuroimaging Initiative) dataset. The proposed model was more effective, efficient, and reliable than the state-of-the-art models through our comparisons.","2024","2025-02-26 20:36:59","2025-02-26 20:36:59","","302-316","","1","53","","","","","","","","","","English","","","","WOS:001280512700019","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Alzheimer's disease; Brain disorder; CLASSIFICATION; deep learning; depth-wise separable convolution; spatial attention blocks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4PPUKXAI","journalArticle","2024","Luz, S; Haider, F; Fromm, D; Lazarou, I; Kompatsiaris, I; Macwhinney, B","An Overview of the ADReSS-M Signal Processing Grand Challenge on Multilingual Alzheimer's Dementia Recognition Through Spontaneous Speech","IEEE OPEN JOURNAL OF SIGNAL PROCESSING","","2644-1322","10.1109/OJSP.2024.3378595","","The ADReSS-M Signal Processing Grand Challenge was held at the 2023 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2023. The challenge targeted difficult automatic prediction problems of great societal and medical relevance, namely, the detection of Alzheimer's Dementia (AD) and the estimation of cognitive test scoress. Participants were invited to create models for the assessment of cognitive function based on spontaneous speech data. Most of these models employed signal processing and machine learning methods. The ADReSS-M challenge was designed to assess the extent to which predictive models built based on speech in one language generalise to another language. The language data compiled and made available for ADReSS-M comprised English, for model training, and Greek, for model testing and validation. To the best of our knowledge no previous shared research task investigated acoustic features of the speech signal or linguistic characteristics in the context of multilingual AD detection. This paper describes the context of the ADReSS-M challenge, its data sets, its predictive tasks, the evaluation methodology we employed, our baseline models and results, and the top five submissions. The paper concludes with a summary discussion of the ADReSS-M results, and our critical assessment of the future outlook in this field.","2024","2025-02-26 20:36:59","2025-02-26 20:36:59","","738-749","","","5","","","","","","","","","","English","","","","WOS:001256424400006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","Alzheimer's disease; Biomedical signal processing; COHORT; DISEASE; human disease biomarkers; LANGUAGE; medical conditions; multilingual Alzheimer's dementia detection; natural language processing; speech processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JHWME77W","journalArticle","2022","Zheng, CH; Bouazizi, M; Ohtsuki, T","An Evaluation on Information Composition in Dementia Detection Based on Speech","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3203068","","In recent years, scientists are paying much attention to the research on automatic dementia detection that could be applied to the speech samples of dementia patients. In a related context, recent research has seen the fast development of Deep Learning (DL) and Natural Language Processing (NLP). The techniques developed for text classification or sentiment analysis have been applied to the field of early dementia detection by many researchers. However, text classification and sentiment analysis are different tasks from dementia detection, which makes us believe that for dementia detection, some adjustments would help improve the performance of the machine learning models. In this work, we implemented experiments with various language models including traditional n-gram language models, Average stochastic gradient descent Weight-Dropped Long Short-Term Memory (AWD-LSTM) models, and attention-based models to evaluate the speech data of dementia patients. Unlike traditional works where the text is stripped from stop words, we propose the idea of exploiting the stop words themselves, since they offer non-context information which helps to identify dementia. As a result, 3 different language models are prepared in this work: a model processing only context words, a model processing stop words and Part-of-Speech (PoS) tag sequences, and a model processing both of them. By performing the aforementioned experiments, we show that both grammar and vocabulary contribute equally to classification: The 3 models achieve an accuracy equal to 70.00%, 76.16%, and 81.54%, respectively.","2022","2025-02-26 20:36:59","2025-02-26 20:36:59","","92294-92306","","","10","","","","","","","","","","English","","","","WOS:000852220200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","ALZHEIMERS-DISEASE; AUTOMATIC DIAGNOSIS; deep learning; Dementia detection; language models; natural language processing; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NFBJQ7UK","journalArticle","2025","Zhang, MW; Cui, QS; Li, WY; Yu, WH; Chen, LH; Li, WJ; Zhu, CZ; Lü, Y","Augmented dialectal speech recognition for AI-based neuropsychological scale assessment in Alzheimer's disease","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2024.106821","","Alzheimer's disease (AD) is a prevalent and widespread neurodegenerative disorder among the older adult population worldwide. Among the numerous cognitive screening methods, neuropsychological scale assessments (NSA) are the widely utilized screening tools in clinical practice. The NSA places significant emphasis on speech-related questions, and thus the role of Automatic Speech Recognition (ASR) technology in AI-based NSA evaluations becomes particularly critical. However, the majority of ASR research pays limited attention to the study of speech recognition for various dialects. One of the primary reasons and main challenges for the scarcity of research in dialectal speech recognition is the limited availability of annotated dialectal data. Furthermore, the older adults' unclear pronunciation leads to erroneous recognition of similar phonetic words by ASR. To overcome the challenges of limited annotated dialect data in various regions and the issues related to confusable pronunciation of older adults, we propose a dialectal collaborative encoder mechanism and a machine reading comprehension augmented model (MRCAM) that automatically corrects the texts in the NSA. The dialectal collaborative encoder mechanism utilizes layer frozenness to transfer recognition ability to the dialectal model. Meanwhile, the MRCAM model fills the gap by combining speech recognition algorithms with natural language processing (NLP) technology to recognize the dialects spoken by older adults. The experimental evaluation results indicate that the proposed augmented model achieves over 90% consistency with the physician's judgment, providing the premise of the proposed methods for the task of automated screening for AD based on ASR.","2025-01","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","99","","","","","","","","","","English","","","","WOS:001316674000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","Automatic speech recognition; Encoder; Neuropsychological scale assessment; Text correction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YE6FLCTQ","journalArticle","2022","Agbavor, F; Liang, HL","Predicting dementia from spontaneous speech using large language models","PLOS DIGITAL HEALTH","","2767-3170","10.1371/journal.pdig.0000168","","Language impairment is an important biomarker of neurodegenerative disorders such as Alzheimer's disease (AD). Artificial intelligence (AI), particularly natural language processing (NLP), has recently been increasingly used for early prediction of AD through speech. Yet, relatively few studies exist on using large language models, especially GPT-3, to aid in the early diagnosis of dementia. In this work, we show for the first time that GPT-3 can be utilized to predict dementia from spontaneous speech. Specifically, we leverage the vast semantic knowledge encoded in the GPT-3 model to generate text embedding, a vector representation of the transcribed text from speech, that captures the semantic meaning of the input. We demonstrate that the text embedding can be reliably used to (1) distinguish individuals with AD from healthy controls, and (2) infer the subject's cognitive testing score, both solely based on speech data. We further show that text embedding considerably outperforms the conventional acoustic feature-based approach and even performs competitively with prevailing fine-tuned models. Together, our results suggest that GPT-3 based text embedding is a viable approach for AD assessment directly from speech and has the potential to improve early diagnosis of dementia.","2022-12","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","12","1","","","","","","","","","","English","","","","WOS:001416948000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;47<br/>Total Times Cited:&nbsp;&nbsp;49<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","ALZHEIMERS-DISEASE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DZP27T2S","journalArticle","2023","Bushnell, J; Unverzagt, F; Wadley, VG; Kennedy, R; Del Gaizo, J; Clark, DG","Post-processing automatic transcriptions with machine learning for verbal fluency scoring","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2023.102990","","Objective: To compare verbal fluency scores derived from manual transcriptions to those obtained using automatic speech recognition enhanced with machine learning classifiers. Methods: Using Amazon Web Services, we automatically transcribed verbal fluency recordings from 1400 individuals who performed both animal and letter F verbal fluency tasks. We manually adjusted timings and contents of the automatic transcriptions to obtain ""gold standard"" transcriptions. To make automatic scoring possible, we trained machine learning classifiers to discern between valid and invalid utterances. We then calculated and compared verbal fluency scores from the manual and automatic transcriptions. Results: For both animal and letter fluency tasks, we achieved good separation of valid versus invalid utterances. Verbal fluency scores calculated based on automatic transcriptions showed high correlation with those calculated after manual correction. Conclusion: Many techniques for scoring verbal fluency word lists require accurate transcriptions with word timings. We show that machine learning methods can be applied to improve off-the-shelf ASR for this purpose. These automatically derived scores may be satisfactory for some applications. Low correlations among some of the scores indicate the need for improvement in automatic speech recognition before a fully automatic approach can be reliably implemented.","2023-11","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","155","","","","","","","","","","English","","","","WOS:001098741200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Automatic speech recognition; COGNITIVE IMPAIRMENT; Cognitive science; Dementia; DISEASE; Language; Machine learning; RACIAL-DIFFERENCES; REASONS; SPEECH; STROKE; Verbal fluency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6G2GYH7X","journalArticle","2024","da Cunha, PL; Ruiz, F; Ferrante, F; Sterpin, LF; Ibanez, A; Slachevsky, A; Matallana, D; Martinez, A; Hesse, E; Garcia, AM","Automated free speech analysis reveals distinct markers of Alzheimer's and frontotemporal dementia","PLOS ONE","","1932-6203","10.1371/journal.pone.0304272","","Dementia can disrupt how people experience and describe events as well as their own role in them. Alzheimer's disease (AD) compromises the processing of entities expressed by nouns, while behavioral variant frontotemporal dementia (bvFTD) entails a depersonalized perspective with increased third-person references. Yet, no study has examined whether these patterns can be captured in connected speech via natural language processing tools. To tackle such gaps, we asked 96 participants (32 AD patients, 32 bvFTD patients, 32 healthy controls) to narrate a typical day of their lives and calculated the proportion of nouns, verbs, and first- or third-person markers (via part-of-speech and morphological tagging). We also extracted objective properties (frequency, phonological neighborhood, length, semantic variability) from each content word. In our main study (with 21 AD patients, 21 bvFTD patients, and 21 healthy controls), we used inferential statistics and machine learning for group-level and subject-level discrimination. The above linguistic features were correlated with patients' scores in tests of general cognitive status and executive functions. We found that, compared with HCs, (i) AD (but not bvFTD) patients produced significantly fewer nouns, (ii) bvFTD (but not AD) patients used significantly more third-person markers, and (iii) both patient groups produced more frequent words. Machine learning analyses showed that these features identified individuals with AD and bvFTD (AUC = 0.71). A generalizability test, with a model trained on the entire main study sample and tested on hold-out samples (11 AD patients, 11 bvFTD patients, 11 healthy controls), showed even better performance, with AUCs of 0.76 and 0.83 for AD and bvFTD, respectively. No linguistic feature was significantly correlated with cognitive test scores in either patient group. These results suggest that specific cognitive traits of each disorder can be captured automatically in connected speech, favoring interpretability for enhanced syndrome characterization, diagnosis, and monitoring.","2024-06-06","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","6","19","","","","","","","","","","English","","","","WOS:001241954400047","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;78</p>","","","BEHAVIORAL-VARIANT; DECLINE; DISCOURSE; DISEASE; FRONTAL VARIANT; LANGUAGE; NOUNS; PRIMARY PROGRESSIVE APHASIA; SELF-AWARENESS; VERBS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BGETYMEF","journalArticle","2022","Ding, Y; Chu, YX; Liu, M; Ling, ZH; Wang, SJ; Li, X; Li, YX","Fully automated discrimination of Alzheimer's disease using resting-state electroencephalography signals","QUANTITATIVE IMAGING IN MEDICINE AND SURGERY","","2223-4292","10.21037/qims-21-430","","Background: The Alzheimer's disease (AD) population increases worldwide, placing a heavy burden on the economy and society. Presently, there is no cure for AD. Developing a convenient method of screening for AD and mild cognitive impairment (MCI) could enable early intervention, thus slowing down the progress of the disease and enabling better overall disease management. Methods: In the current study, resting-state electroencephalography (EEG) data were acquired from 113 normal cognition (NC) subjects, 116 amnestic MCI patients, and 72 probable AD patients. After preprocessing by an automatic algorithm, features including spectral power, complexity, and functional connectivity were extracted, and machine-learning classifiers were built to differentiate among the 3 groups. The classification performance was evaluated from multiple perspectives, including accuracy, specificity, sensitivity, area under the curve (AUC) with 95% confidence intervals, and compared to the empirical chance level by permutation tests. Results: The analysis of variance results (P<0.05 with false discovery rate correction) confirmed the tendency to slow brain activity, reduced complexity, and connectivity with AD progress. By combining the features, the ability of the machine-learning classifiers, especially the ensemble trees, to differentiate among the 3 groups, was significantly better than that of the empirical chance level of the permutation test. The AUC of the classifier with the best performance was 80.08% for AD vs. NC, 70.82% for AD vs. MCI, and 63.95% for MCI vs. NC. Conclusions: The current study presented a fully automatic procedure that could significantly distinguish NC, MCI, and AD subjects via resting-state EEG signals. The study was based on a large data set with evidence-based medical diagnosis and provided further evidence that resting-state EEG data could assist in the discrimination of AD patients.","2022-02","2025-02-26 20:36:59","2025-02-26 20:36:59","","1063-1078","","2","12","","","","","","","","","","English","","","","WOS:000707548600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;24<br/>Total Times Cited:&nbsp;&nbsp;26<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","Alzheimer's disease (AD); automated discrimination; CLASSIFICATION; COHERENCE; DIAGNOSIS; EEG BACKGROUND ACTIVITY; ENTROPY ANALYSIS; machine learning; MILD COGNITIVE IMPAIRMENT; mild cognitive impairment (MCI); POPULATION; PREVALENCE; RECOGNITION; resting-state EEG; SYNCHRONIZATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YKGZ32XR","journalArticle","2024","Saunders, S; Haider, F; Ritchie, CW; Terrera, GM; Luz, S","Longitudinal observational cohort study: Speech for Intelligent cognition change tracking and DEtection of Alzheimer's Disease (SIDE-AD)","BMJ OPEN","","2044-6055","10.1136/bmjopen-2023-082388","","Introduction There is emerging evidence that speech may be a potential indicator and manifestation of early Alzheimer's disease (AD) pathology. Therefore, the University of Edinburgh and Sony Research have partnered to create the Speech for Intelligent cognition change tracking and DEtection of Alzheimer's Disease (SIDE-AD) study, which aims to develop digital speech-based biomarkers for use in neurodegenerative disease.Methods and analysis SIDE-AD is an observational longitudinal study, collecting samples of spontaneous speech. Participants are recruited from existing cohort studies as well as from the National Health Service (NHS)memory clinics in Scotland. Using an online platform, participants record a voice sample talking about their brain health and rate their mood, anxiety and apathy. The speech biomarkers will be analysed longitudinally, and we will use machine learning and natural language processing technology to automate the assessment of the respondents' speech patterns.Ethics and dissemination The SIDE-AD study has been approved by the NHS Research Ethics Committee (REC reference: 23/WM/0153, protocol number AC23046, IRAS Project ID 323311) and received NHS management approvals from Lothian, Fife and Forth Valley NHS boards. Our main ethical considerations pertain to the remote administration of the study, such as taking remote consent. To address this, we implemented a consent process, whereby the first step of the consent is done entirely remotely but a member of the research team contacts the participant over the phone to consent participants to the optional, most sensitive, elements of the study. Results will be presented at conferences, published in peer-reviewed journals and communicated to study participants.","2024-03","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","3","14","","","","","","","","","","English","","","","WOS:001195962600024","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Clinical Trial; NEUROLOGY; PUBLIC HEALTH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CNEXYSFH","journalArticle","2024","Takeshige-Amano, H; Oyama, G; Ogawa, M; Fusegi, K; Kambe, T; Shiina, K; Ueno, SI; Okuzumi, A; Hatano, T; Motoi, Y; Kawakami, I; Ando, M; Nakayama, S; Ishida, Y; Maei, S; Lu, XX; Kobayashi, T; Wooden, R; Ota, S; Morito, K; Ito, Y; Nakajima, Y; Yoritaka, A; Kato, T; Hattori, N","Digital detection of Alzheimer's disease using smiles and conversations with a chatbot","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-77220-0","","In super-aged societies, dementia has become a critical issue, underscoring the urgent need for tools to assess cognitive status effectively in various sectors, including financial and business settings. Facial and speech features have been tried as cost-effective biomarkers of dementia including Alzheimer's disease (AD). We aimed to establish an easy, automatic, and extensive screening tool for AD using a chatbot and artificial intelligence. Smile images and visual and auditory data of natural conversations with a chatbot from 99 healthy controls (HCs) and 93 individuals with AD or mild cognitive impairment due to AD (PwA) were analyzed using machine learning. A subset of 8 facial and 21 sound features successfully distinguished PwA from HCs, with a high area under the receiver operating characteristic curve of 0.94 +/- 0.05. Another subset of 8 facial and 20 sound features predicted the cognitive test scores, with a mean absolute error as low as 5.78 +/- 0.08. These results were superior to those obtained from face or auditory data alone or from conventional image depiction tasks. Thus, by combining spontaneous sound and facial data obtained through conversations with a chatbot, the proposed model can be put to practical use in real-life scenarios.","2024-11-01","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","1","14","","","","","","","","","","English","","","","WOS:001346703300074","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","COGNITIVE IMPAIRMENT; DEMENTIA; DIAGNOSIS; PARAMETERS; PEOPLE; SELECTION; SPONTANEOUS SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KVYHZBVW","journalArticle","2023","ter Huurne, D; Ramakers, I; Possemis, N; Banning, L; Gruters, A; Van Asbroeck, S; König, A; Linz, N; Tröger, J; Langel, K; Verhey, F; de Vugt, M","The Accuracy of Speech and Linguistic Analysis in Early Diagnostics of Neurocognitive Disorders in a Memory Clinic Setting","ARCHIVES OF CLINICAL NEUROPSYCHOLOGY","","0887-6177","10.1093/arclin/acac105","","Objective To investigate whether automatic analysis of the Semantic Verbal Fluency test (SVF) is reliable and can extract additional information that is of value for identifying neurocognitive disorders. In addition, the associations between the automatically derived speech and linguistic features and other cognitive domains were explored. Method We included 135 participants from the memory clinic of the Maastricht University Medical Center+ (with Subjective Cognitive Decline [SCD; N = 69] and Mild Cognitive Impairment [MCI]/dementia [N = 66]). The SVF task (one minute, category animals) was recorded and processed via a mobile application, and speech and linguistic features were automatically extracted. The diagnostic performance of the automatically derived features was investigated by training machine learning classifiers to differentiate SCD and MCI/dementia participants. Results The intraclass correlation for interrater reliability between the clinical total score (golden standard) and automatically derived total word count was 0.84. The full model including the total word count and the automatically derived speech and linguistic features had an Area Under the Curve (AUC) of 0.85 for differentiating between people with SCD and MCI/dementia. The model with total word count only and the model with total word count corrected for age showed an AUC of 0.75 and 0.81, respectively. Semantic switching correlated moderately with memory as well as executive functioning. Conclusion The one-minute SVF task with automatically derived speech and linguistic features was as reliable as the manual scoring and differentiated well between SCD and MCI/dementia. This can be considered as a valuable addition in the screening of neurocognitive disorders and in clinical practice.","2023-07-25","2025-02-26 20:36:59","2025-02-26 20:36:59","","667-676","","5","38","","","","","","","","","","English","","","","WOS:000918555900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","AGE; Alzheimer disease; ALZHEIMERS-DISEASE; Cognitive dysfunction; EDUCATION; MILD COGNITIVE IMPAIRMENT; Neuropsychological tests; NORMATIVE DATA; PARKINSONS-DISEASE; PARTICIPANTS; PERFORMANCE; Speech; TESTS; VERBAL FLUENCY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6P8P34AF","journalArticle","2021","Martinc, M; Haider, F; Pollak, S; Luz, S","Temporal Integration of Text Transcripts and Acoustic Features for Alzheimer's Diagnosis Based on Spontaneous Speech","FRONTIERS IN AGING NEUROSCIENCE","","1663-4365","10.3389/fnagi.2021.642647","","Background: Advances in machine learning (ML) technology have opened new avenues for detection and monitoring of cognitive decline. In this study, a multimodal approach to Alzheimer's dementia detection based on the patient's spontaneous speech is presented. This approach was tested on a standard, publicly available Alzheimer's speech dataset for comparability. The data comprise voice samples from 156 participants (1:1 ratio of Alzheimer's to control), matched by age and gender. Materials and Methods: A recently developed Active Data Representation (ADR) technique for voice processing was employed as a framework for fusion of acoustic and textual features at sentence and word level. Temporal aspects of textual features were investigated in conjunction with acoustic features in order to shed light on the temporal interplay between paralinguistic (acoustic) and linguistic (textual) aspects of Alzheimer's speech. Combinations between several configurations of ADR features and more traditional bag-of-n-grams approaches were used in an ensemble of classifiers built and evaluated on a standardised dataset containing recorded speech of scene descriptions and textual transcripts. Results: Employing only semantic bag-of-n-grams features, an accuracy of 89.58% was achieved in distinguishing between Alzheimer's patients and healthy controls. Adding temporal and structural information by combining bag-of-n-grams features with ADR audio/textual features, the accuracy could be improved to 91.67% on the test set. An accuracy of 93.75% was achieved through late fusion of the three best feature configurations, which corresponds to a 4.7% improvement over the best result reported in the literature for this dataset. Conclusion: The proposed combination of ADR audio and textual features is capable of successfully modelling temporal aspects of the data. The machine learning approach toward dementia detection achieves best performance when ADR features are combined with strong semantic bag-of-n-grams features. This combination leads to state-of-the-art performance on the AD classification task.","2021-06-14","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","13","","","","","","","","","","English","","","","WOS:000667188400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;22<br/>Total Times Cited:&nbsp;&nbsp;24<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","acoustic features; Alzheimer's dementia detection; DEMENTIA RECOGNITION; DISEASE; IMPAIRMENT; language; LANGUAGE; lexical features; machine learning; natural language processing; speech; speech processing; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7Y86N7QL","journalArticle","2024","Kleiman, MJ; Galvin, JE","High frequency post-pause word choices and task-dependent speech behavior characterize connected speech in individuals with mild cognitive impairment","JOURNAL OF ALZHEIMERS DISEASE","","1387-2877","10.1177/13872877241291239","","Background Alzheimer's disease (AD) is characterized by progressive cognitive decline, including impairments in speech production and fluency. Mild cognitive impairment (MCI), a prodrome of AD, has also been linked with changes in speech behavior but to a more subtle degree. Objective This study aimed to investigate whether speech behavior immediately following both filled and unfilled pauses (post-pause speech behavior) differs between individuals with MCI and healthy controls (HCs), and how these differences are influenced by the cognitive demands of various speech tasks. Methods Transcribed speech samples were analyzed from both groups across different tasks, including immediate and delayed narrative recall, picture descriptions, and free responses. Key metrics including lexical and syntactic complexity, lexical frequency and diversity, and part of speech usage, both overall and post-pause, were examined. Results Significant differences in pause usage were observed between groups, with a higher incidence and longer latencies following these pauses in the MCI group. Lexical frequency following filled pauses was higher among MCI participants in the free response task but not in other tasks, potentially due to the relative cognitive load of the tasks. The immediate recall task was most useful at differentiating between groups. Predictive analyses utilizing random forest classifiers demonstrated high specificity in using speech behavior metrics to differentiate between MCI and HCs. Conclusions Speech behavior following pauses differs between MCI participants and healthy controls, with these differences being influenced by the cognitive demands of the speech tasks. These post-pause speech metrics can be easily integrated into existing speech analysis paradigms.","2024-12","2025-02-26 20:36:59","2025-02-26 20:36:59","","815-829","","3","102","","","","","","","","","","English","","","","WOS:001410818700004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","alzheimer's disease; ALZHEIMERS; DISEASE; LANGUAGE; machine learning; MEMORY; mild cognitive impairment; neuropsychological assessment; speech; verbal behavior; VERSION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JGHRPXNS","journalArticle","2022","Santander-Cruz, Y; Salazar-Colores, S; Paredes-García, WJ; Guendulain-Arenas, H; Tovar-Arriaga, S","Semantic Feature Extraction Using SBERT for Dementia Detection","BRAIN SCIENCES","","2076-3425","10.3390/brainsci12020270","","Dementia is a neurodegenerative disease that leads to the development of cognitive deficits, such as aphasia, apraxia, and agnosia. It is currently considered one of the most significant major medical problems worldwide, primarily affecting the elderly. This condition gradually impairs the patient's cognition, eventually leading to the inability to perform everyday tasks without assistance. Since dementia is an incurable disease, early detection plays an important role in delaying its progression. Because of this, tools and methods have been developed to help accurately diagnose patients in their early stages. State-of-the-art methods have shown that the use of syntactic-type linguistic features provides a sensitive and noninvasive tool for detecting dementia in its early stages. However, these methods lack relevant semantic information. In this work, we propose a novel methodology, based on the semantic features approach, by using sentence embeddings computed by Siamese BERT networks (SBERT), along with support vector machine (SVM), K-nearest neighbors (KNN), random forest, and an artificial neural network (ANN) as classifiers. Our methodology extracted 17 features that provide demographic, lexical, syntactic, and semantic information from 550 oral production samples of elderly controls and people with Alzheimer's disease, provided by the DementiaBank Pitt Corpus database. To quantify the relevance of the extracted features for the dementia classification task, we calculated the mutual information score, which demonstrates a dependence between our features and the MMSE score. The experimental classification performance metrics, such as the accuracy, precision, recall, and F1 score (77, 80, 80, and 80%, respectively), validate that our methodology performs better than syntax-based methods and the BERT approach when only the linguistic features are used.","2022-02","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","2","12","","","","","","","","","","English","","","","WOS:000767755600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;21<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","ALZHEIMERS-DISEASE; dementia; NLP feature extraction; SBERT; semantic analysis; syntax analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PLTYXDX3","journalArticle","2023","Schäfer, S; Mallick, E; Schwed, L; König, A; Zhao, J; Linz, N; Bodin, TH; Skoog, J; Possemis, N; Ter Huurne, D; Zettergren, A; Kern, S; Sacuiu, S; Ramakers, I; Skoog, I; Tröger, J","Screening for Mild Cognitive Impairment Using a Machine Learning Classifier and the Remote Speech Biomarker for Cognition: Evidence from Two Clinically Relevant Cohorts","JOURNAL OF ALZHEIMERS DISEASE","","1387-2877","10.3233/JAD-220762","","Background: Modern prodromal Alzheimer's disease (AD) clinical trials might extend outreach to a general population, causing high screen-out rates and thereby increasing study time and costs. Thus, screening tools that cost-effectively detect mild cognitive impairment (MCI) at scale are needed. Objective: Develop a screening algorithm that can differentiate between healthy and MCI participants in different clinically relevant populations. Methods: Two screening algorithms based on the remote ki:e speech biomarker for cognition (ki:e SB-C) were designed on a Dutch memory clinic cohort (N= 121) and a Swedish birth cohort (N= 404). MCI classification was each evaluated on the training cohort as well as on the unrelated validation cohort. Results: The algorithms achieved a performance of AUC similar to 0.73 and AUC similar to 0.77 in the respective training cohorts and AUC similar to 0.81 in the unseen validation cohorts. Conclusion: The results indicate that a ki:e SB-C based algorithm robustly detectsMCIacross different cohorts and languages, which has the potential to make current trials more efficient and improve future primary health care.","2023","2025-02-26 20:36:59","2025-02-26 20:36:59","","1165-1171","","3","91","","","","","","","","","","English","","","","WOS:000925066900023","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","Alzheimer's disease; biomarker; clinical trial; machine learning; mild cognitive impairment; screening","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8AVLJ5SX","journalArticle","2023","He, R; Chapin, K; Al-Tamimi, J; Bel, N; Marquié, M; Rosende-Roca, M; Pytel, V; Tartari, JP; Alegret, M; Sanabria, A; Ruiz, A; Boada, M; Valero, S; Hinzen, W","Automated Classification of Cognitive Decline and Probable Alzheimer's Dementia Across Multiple Speech and Language Domains","AMERICAN JOURNAL OF SPEECH-LANGUAGE PATHOLOGY","","1058-0360","10.1044/2023_AJSLP-22-00403","","Background: Decline in language has emerged as a new potential biomarker for the early detection of Alzheimer's disease (AD). It remains unclear how sensitive language measures are across different tasks, language domains, and languages, and to what extent changes can be reliably detected in early stages such as subjective cognitive decline (SCD) and mild cognitive impairment (MCI). Method: Using a scene construction task for speech elicitation in a new Spanish/Catalan speaking cohort (N = 119), we automatically extracted features across seven domains, three acoustic (spectral, cepstral, and voice quality), one prosodic, and three from text (morpholexical, semantic, and syntactic). They were forwarded to a random forest classifier to evaluate the discriminability of participants with probable AD dementia, amnestic and nonamnestic MCI, SCD, and cognitively healthy controls. Repeated-measures analyses of variance and paired-samples Wilcoxon signed-ranks test were used to assess whether and how performance differs significantly across groups and linguistic domains. Results: The performance scores of the machine learning classifier were generally satisfactorily high, with the highest scores over.9. Model performance was significantly different for linguistic domains (p < .001), and speech versus text (p = .043), with speech features outperforming textual features, and voice quality performing best. High diagnostic classification accuracies were seen even within both cognitively healthy (controls vs. SCD) and MCI (amnestic and nonamnestic) groups. Conclusion: Speech-based machine learning is powerful in detecting cognitive decline and probable AD dementia across a range of different feature domains, though important differences exist between these domains as well.","2023-09","2025-02-26 20:36:59","2025-02-26 20:36:59","","2075-2086","","5","32","","","","","","","","","","English","","","","WOS:001159383000007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","BIOMARKERS; COHORT; DISEASE; EPISODIC MEMORY; IMPAIRMENT; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AGTA8WAR","journalArticle","2024","Soleimani, R; Guo, SJ; Haley, KL; Jacks, A; Lobaton, E","The Impact of Pause and Filler Word Encoding on Dementia Detection with Contrastive Learning","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14198879","","Dementia is primarily caused by neurodegenerative diseases like Alzheimer's disease (AD). It affects millions worldwide, making detection and monitoring crucial. This study focuses on the detection of dementia from speech transcripts of controls and dementia groups. We propose encoding in-text pauses and filler words (e.g., ""uh"" and ""um"") in text-based language models and thoroughly evaluating their impact on performance (e.g., accuracy). Additionally, we suggest using contrastive learning to improve performance in a multi-task framework. Our results demonstrate the effectiveness of our approaches in enhancing the model's performance, achieving 87% accuracy and an 86% f1-score. Compared to the state of the art, our approach has similar performance despite having significantly fewer parameters. This highlights the importance of pause and filler word encoding on the detection of dementia.","2024-10","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","19","14","","","","","","","","","","English","","","","WOS:001332195800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","CLASSIFICATION; contrastive learning; deep learning; dementia; LLMs; MARKERS; NEURAL-NETWORK; NLP; text classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FKX6KE9T","journalArticle","2024","Chen, YT; Hartsuiker, RJ; Pistono, A","A comparison of different connected-speech tasks for detecting mild cognitive impairment using multivariate pattern analysis","APHASIOLOGY","","0268-7038","10.1080/02687038.2024.2358556","","BackgroundIt is common for the elderly population to have age-associated cognitive decline and/or develop neurodegenerative diseases such as dementia. Several studies have suggested that classification algorithms based on linguistic features may be useful for the early detection of mild cognitive impairment (MCI).AimsThe current study aimed to examine connected-speech performance in people with MCI and cognitively healthy controls (HC). It tests whether patterns of lexical-semantic features extracted from these tasks could distinguish participants with MCI from HC, using univariate and multivariate analyses.Methods & procedureWe selected 16 English-speaking participants with MCI and 16 matched HC from the Delaware corpus. Four connected-speech tasks (a picture description, a story narrative, a story recall, and a procedural narrative). Eight lexical-semantic features were selected for analyses.Outcomes & resultsUnivariate analyses showed inter-group differences in revision ratio, core lexicon, or open/closed class words ratio, depending on the task. Multivariate pattern analysis (MVPA) results demonstrated that the story recall task is the only task that can discriminate the two groups above chance.ConclusionTo conclude, results showed that connected-speech tasks have the potential to detect subtle language changes in people with MCI. In particular, the story recall task had the potential to predict the group of a participant (MCI or HC).","2024-05-31","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","","","","","","","","","","","English","","","","WOS:001235413700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;95</p>","","","ADULTS; alzheimer's disease; ALZHEIMERS ASSOCIATION WORKGROUPS; BOSTON NAMING TEST; connected speech; DIAGNOSTIC GUIDELINES; DISEASE; FMRI; LANGUAGE PERFORMANCE; machine learning; Mild cognitive impairment; multivariate pattern analysis; NATIONAL INSTITUTE; RISK; VERBAL FLUENCY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TK8MS4Q8","journalArticle","2022","Shivhare, N; Rathod, S; Khan, MR","Dementia Detection Using LSTM and GRU","JOURNAL OF ADVANCED APPLIED SCIENTIFIC RESEARCH","","2454-3225","","","Neuro-degenerative infections, like dementia, can affect discourse, language, and the ability of correspondence. A new report to work on the precision of dementia identification examined the utilization of conversation analysis (CA) of meetings between patients and nervous system specialists to recognize reformist neuro-degenerative (ND) memory issues patients and those with (non-reformist) FMD (Functional Memory Disorder). In any case, manual CA is expensive for routine clinical use and hard proportional. In this work, we present an early dementia discovery framework utilizing discourse acknowledgment and examination dependent on NLP method and acoustic component handling strategy apply on various element extraction and learning using LSTM (Long Short-Term Memory) and GRU which strikingly catches the transient provisions and long haul conditions from authentic information to demonstrate the abilities of grouping models over a feed-forward neural organization in estimating discourse investigation related issues. Dementia dataset is taken where the audio file is considered for speech recognition analysis on basis of that data is generated and it is predefined given in dementia data databank. That audio file is converted to text based on speech analysis. Using LSTM and GRU gives efficient results.","2022","2025-02-26 20:36:59","2025-02-26 20:36:59","","80-88","","1","4","","","","","","","","","","English","","","","WOS:000785514500009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;16</p>","","","ALZHEIMERS-DISEASE; Dementia Detection; DIAGNOSIS; features extraction; GRU; Long Short-Term Memory; Speech Analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SASWB7ES","journalArticle","2023","García-Gutiérrez, F; Marquié, M; Muñoz, N; Alegret, M; Cano, A; de Rojas, I; García-González, P; Olivé, C; Puerta, R; Orellana, A; Montrreal, L; Pytel, V; Ricciardi, M; Zaldua, C; Gabirondo, P; Hinzen, W; Lleonart, N; García-Sánchez, A; Tárraga, L; Ruiz, A; Boada, M; Valero, S","Harnessing acoustic speech parameters to decipher amyloid status in individuals with mild cognitive impairment","FRONTIERS IN NEUROSCIENCE","","1662-453X","10.3389/fnins.2023.1221401","","Alzheimer ' s disease (AD) is a neurodegenerative condition characterized by a gradual decline in cognitive functions. Currently, there are no e ective treatments for AD, underscoring the importance of identifying individuals in the preclinical stages of mild cognitive impairment (MCI) to enable early interventions. Among the neuropathological events associated with the onset of the disease is the accumulation of amyloid protein in the brain, which correlates with decreased levels of A ss 42 peptide in the cerebrospinal fluid (CSF). Consequently, the development of non-invasive, low-cost, and easy-to-administer proxies for detecting A ss 42 positivity in CSF becomes particularly valuable. A promising approach to achieve this is spontaneous speech analysis, which combined with machine learning (ML) techniques, has proven highly useful in AD. In this study, we examined the relationship between amyloid status in CSF and acoustic features derived from the description of the Cookie Theft picture in MCI patients from a memory clinic. The cohort consisted of fifty-two patients with MCI (mean age 73 years, 65% female, and 57% positive amyloid status). Eighty-eight acoustic parameters were extracted from voice recordings using the extended Geneva Minimalistic Acoustic Parameter Set (eGeMAPS), and several ML models were used to classify the amyloid status. Furthermore, interpretability techniques were employed to examine the influence of input variables on the determination of amyloid-positive status. The best model, based on acoustic variables, achieved an accuracy of 75% with an area under the curve (AUC) of 0.79 in the prediction of amyloid status evaluated by bootstrapping and Leave-One-Out Cross Validation (LOOCV), outperforming conventional neuropsychological tests (AUC = 0.66). Our results showed that the automated analysis of voice recordings derived from spontaneous speech tests o ers valuable insights into AD biomarkers during the preclinical stages. These findings introduce novel possibilities for the use of digital biomarkers to identify subjects at high risk of developing AD.","2023-09-07","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","17","","","","","","","","","","English","","","","WOS:001071444900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;83</p>","","","Alzheimer's disease; ALZHEIMERS ASSOCIATION WORKGROUPS; automated pattern recognition; BATTERY; biomarkers; BIOMARKERS; cerebrospinal fluid; DECLINE; DEMENTIA; DIAGNOSTIC GUIDELINES; DISEASE; early diagnosis; LANGUAGE; machine learning; mild cognitive impairment; NATIONAL INSTITUTE; RECOMMENDATIONS; speech acoustics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y6HX6PA3","journalArticle","2023","Momota, Y; Liang, KC; Horigome, T; Kitazawa, M; Eguchi, Y; Takamiya, A; Goto, A; Mimura, M; Kishimoto, T","Language patterns in Japanese patients with Alzheimer disease: A machine learning approach","PSYCHIATRY AND CLINICAL NEUROSCIENCES","","1323-1316","10.1111/pcn.13526","","Aim The authors applied natural language processing and machine learning to explore the disease-related language patterns that warrant objective measures for assessing language ability in Japanese patients with Alzheimer disease (AD), while most previous studies have used large publicly available data sets in Euro-American languages.Methods The authors obtained 276 speech samples from 42 patients with AD and 52 healthy controls, aged 50 years or older. A natural language processing library for Python was used, spaCy, with an add-on library, GiNZA, which is a Japanese parser based on Universal Dependencies designed to facilitate multilingual parser development. The authors used eXtreme Gradient Boosting for our classification algorithm. Each unit of part-of-speech and dependency was tagged and counted to create features such as tag-frequency and tag-to-tag transition-frequency. Each feature's importance was computed during the 100-fold repeated random subsampling validation and averaged.Results The model resulted in an accuracy of 0.84 (SD = 0.06), and an area under the curve of 0.90 (SD = 0.03). Among the features that were important for such predictions, seven of the top 10 features were related to part-of-speech, while the remaining three were related to dependency. A box plot analysis demonstrated that the appearance rates of content words-related features were lower among the patients, whereas those with stagnation-related features were higher.Conclusion The current study demonstrated a promising level of accuracy for predicting AD and found the language patterns corresponding to the type of lexical-semantic decline known as 'empty speech', which is regarded as a characteristic of AD.","2023-05","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","5","77","","","","","","","","","","English","","","","WOS:000931717600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;101</p>","","","Alzheimer disease; CEREBROSPINAL-FLUID; CLINICAL-DIAGNOSIS; COGNITIVE IMPAIRMENT; CONNECTED SPEECH; DEGENERATION; dementia; DEMENTIA; EARLY-STAGE; machine learning; NATIONAL INSTITUTE; natural language processing; NEUROPATHOLOGY; PICTURE DESCRIPTION TASK; speech-language pathology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EB647NZN","journalArticle","2023","Zhou, Y; Han, W; Yao, XY; Xue, JJ; Li, Z; Li, YX","Developing a machine learning model for detecting depression, anxiety, and apathy in older adults with mild cognitive impairment using speech and facial expressions: A cross-sectional observational study","INTERNATIONAL JOURNAL OF NURSING STUDIES","","0020-7489","10.1016/j.ijnurstu.2023.104562","","Background: Depression, anxiety, and apathy are highly prevalent in older people with preclinical dementia and mild cognitive impairment. These symptoms have also proven valuable in predicting the progression from mild cognitive impairment to dementia, enabling a timely diagnosis and treatment. However, objective and reliable indicators to detect and distinguish depression, anxiety, and apathy are relatively scarce. Objective: This study aimed to develop a machine learning model to detect and distinguish depression, anxiety, and apathy based on speech and facial expressions. Design: An observational, cross-sectional study design. Setting(s): The memory outpatient department of a tertiary hospital. Participants: 319 older adults diagnosed with mild cognitive impairment. Methods: Depression, anxiety, and apathy were evaluated by the Public Health Questionnaire, General Anxiety Disorder, and Apathy Evaluation Scale, respectively. Speech and facial expressions of older adults with mild cog-nitive impairment were digitally captured using audio and video recording software. Open-source data analysis toolkits were utilized to extract speech, facial, and text features. The multiclass classification was used to develop classification models, and shapely additive explanations were used to explain the contribution of each feature within the model. Results: The random forest method was used to develop a multiclass emotion classification model, which per-formed well in classifying emotions with a weighted-average F1 score of 96.6 %. The model also demonstrated high accuracy, precision, and recall, with 87.4 %, 86.6 %, and 87.6 %, respectively. Conclusions: The machine learning model developed in this study demonstrated strong classification perfor-mance in detecting and differentiating depression, anxiety, and apathy. This innovative approach combines text, audio, and video to provide objective methods for precise classification and remote monitoring of these symptoms in nursing practice. Registration: This study was registered at the Chinese Clinical Trial Registry (registration number: ChiCTR1900023892; registration date: June 19th, 2019). & COPY; 2023 Elsevier Ltd. All rights reserved.","2023-10","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","146","","","","","","","","","","English","","","","WOS:001051596100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","Anxiety; Apathy; Depression; Emotion recognition; Facial analysis; Machine learning; Mild cognitive impairment; NEUROPSYCHIATRIC SYMPTOMS; PEOPLE; Speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5V4TPDTF","journalArticle","2022","De Looze, C; Dehsarvi, A; Suleyman, N; Crosby, L; Hernández, B; Coen, RF; Lawlor, BA; Reilly, RB","Structural Correlates of Overt Sentence Reading in Mild Cognitive Impairment and Mild-to-Moderate Alzheimer's Disease","CURRENT ALZHEIMER RESEARCH","","1567-2050","10.2174/1567205019666220805110248","","Background: Overt sentence reading in mild cognitive impairment (MCI) and mild-to-moderate Alzheimer's disease (AD) has been associated with slowness of speech, characterized by a higher number of pauses, shorter speech units and slower speech rate and attributed to reduced working memory/ attention and language capacity. Objective: This preliminary case-control study investigates whether the temporal organization of speech is associated with the volume of brain regions involved in overt sentence reading and explores the discriminative ability of temporal speech parameters and standard volumetric MRI measures for the classification of MCI and AD. Methods: Individuals with MCI, mild-to-moderate AD, and healthy controls (HC) had a structural MRI scan and read aloud sentences varying in cognitive-linguistic demand (length). The association between speech features and regional brain volumes was examined by linear mixed-effect modeling. Genetic programming was used to explore the discriminative ability of temporal and MRI features. Results: Longer sentences, slower speech rate, and a higher number of pauses and shorter interpausal units were associated with reduced volumes of the reading network. Speech-based classifiers performed similarly to the MRI-based classifiers for MCI-HC (67% vs. 68%) and slightly better for AD-HC (80% vs. 64%) and AD-MCI (82% vs. 59%). Adding the speech features to the MRI features slightly improved the performance of MRI-based classification for AD-HC and MCI-HC but not HC-MCI. Conclusion: The temporal organization of speech in overt sentence reading reflects underlying volume reductions. It may represent a sensitive marker for early assessment of structural changes and cognitive-linguistic deficits associated with healthy aging, MCI, and AD.","2022","2025-02-26 20:36:59","2025-02-26 20:36:59","","606-617","","8","19","","","","","","","","","","English","","","","WOS:000894560700004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;96</p>","","","AGING BRAIN; Alzheimer disease; ASSOCIATION WORKGROUPS; cognitive aging; COMPREHENSION; DIAGNOSTIC GUIDELINES; functional neuroimaging; genetic programming; INDIVIDUAL-DIFFERENCES; LANGUAGE; machine learning; mild cognitive impairment; NATIONAL INSTITUTE; sentence reading; SPEECH; temporal speech features; WORD; WORKING-MEMORY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RY2VS6HT","journalArticle","2023","Wang, RM; Kuang, C; Guo, CY; Chen, Y; Li, CY; Matsumura, Y; Ishimaru, M; Van Pelt, AJ; Chen, F","Automatic Detection of Putative Mild Cognitive Impairment from Speech Acoustic Features in Mandarin-Speaking Elders","JOURNAL OF ALZHEIMERS DISEASE","","1387-2877","10.3233/JAD-230373","","Background: To date, the reliable detection of mild cognitive impairment (MCI) remains a significant challenge for clinicians. Very fewstudies investigated the sensitivity of acoustic features in detecting Mandarin-speaking elders at risk for MCI, defined as ""putative MCI"" (pMCI). Objective: This study sought to investigate the possibility of using automatically extracted speech acoustic features to detect elderly people with pMCI and reveal the potential acoustic markers of cognitive decline at an early stage. Methods: Forty-one older adults with pMCI and 41 healthy elderly controls completed four reading tasks (syllable utterance, tongue twister, diadochokinesis, and short sentence reading), from which acoustic features were extracted automatically to train machine learning classifiers. Correlation analysiswas employed to evaluate the relationship between classifier predictions and participants' cognitive ability measured by Mini-Mental State Examination 2. Results: Classification results revealed that some temporal features (e.g., speech rate, utterance duration, and the number of silent pauses), spectral features (e.g., variability of F1 and F2), and energy features (e.g., SD of peak intensity and SD of intensity range) were effective predictors of pMCI. The best classification result was achieved in the Random Forest classifier (accuracy = 0.81, AUC = 0.81). Correlation analysis uncovered a strong negative correlation between participants' cognitive test scores and the probability estimates of pMCI in the Random Forest classifier, and a modest negative correlation in the Support Vector Machine classifier. Conclusions: The automatic acoustic analysis of speech could provide a promising non-invasive way to assess and monitor the early cognitive decline in Mandarin-speaking elders.","2023","2025-02-26 20:36:59","2025-02-26 20:36:59","","901-914","","3","95","","","","","","","","","","English","","","","WOS:001079395900010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","Alzheimer's disease; ALZHEIMERS-DISEASE; DEFICITS; DISCOURSE; LANGUAGE PERFORMANCE; LEXICAL ACCESS; machine learning; Mandarin; mild cognitive impairment; speech; SYSTEMS; WORD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2PM7MMIC","journalArticle","2024","Gong, YS; Parllaku, F; Placek, K; Vilela, M; Harel, B; Simen, A; Subirana, B; Brodtmann, A; Vogel, A; Tracey, B","Exploring Emotion and Emotional Variability as Digital Biomarkers in Frontotemporal Dementia Speech","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3402999","","Frontotemporal Dementia (FTD) encompasses a diverse group of progressive neurodegenerative diseases that impact speech production and comprehension, higher-order cognition, behavior, and motor control. Traditional acoustic speech markers have been extensively studied in FTD, as have assessments capturing apathy and impairments in recognizing and expressing emotion. This work leverages machine learning to track changes in emotional content within the speech of individuals with FTD and healthy controls. The aim of the project is to develop tools for assessing and monitoring emotional changes in individuals with FTD, quantifying these subtle aspects of the disease and thus potentially providing insights for assessing future therapeutic interventions. A retrospective analysis was conducted on a dataset comprising standard elicited speech tasks performed by 78 individuals diagnosed with FTD and 55 healthy elderly controls. We employed an ensemble-based convolutional neural network (CNN) classifier trained on the Interactive Emotional Dyadic Motion Capture (IEMOCAP) dataset to extract emotion scores from processed speech samples. The classifier was applied with a sliding window to the FTD and healthy control narratives to facilitate a granular examination of emotional changes throughout longer speech samples. Analysis of variance (ANOVA) was used to test for group differences in average emotion scores as well as emotional variability over the duration of the speech samples. Compared to healthy controls, people with FTD demonstrated reduced emotional change in a monologue task describing a happy experience, as measured by the interquartile range (IQR) (p <inverted exclamation> 0.005) and slope of ""happy"" emotion scores vs. time (p <inverted exclamation> 0.005). During a picture description task, people with FTD displayed a slightly elevated average level of frustration (p <inverted exclamation> 0.005). Increased frustration levels in individuals with FTD could potentially indicate their difficulties in accomplishing the task. This study introduced the application of a pre-trained Speech Emotion Recognition (SER) model on overlapping short segments of extended speech samples, allowing for a detailed examination of emotional changes over time. Capturing the temporal evolution of emotional content offers a nuanced understanding of communication in individuals with FTD. Our findings lay the groundwork for further development of digital biomarkers to refine the assessment, monitoring, and understanding of the emotional and social communication impacts of FTD.","2024","2025-02-26 20:36:59","2025-02-26 20:36:59","","71419-71432","","","12","","","","","","","","","","English","","","","WOS:001230818200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","APATHY; Artificial intelligence; Audio recording; BEHAVIORAL VARIANT; biomarkers; Biomarkers; bvFTD; CLASSIFICATION; dementia; DIAGNOSTIC-CRITERIA; Diseases; DISORDERS; emotion; FTD; LOBAR DEGENERATION; Mel frequency cepstral coefficient; MOTOR SPEECH; Older adults; PROSODY; RELIABILITY; SELF; speech; Task analysis; Training; voice","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KWSHHNK4","journalArticle","2022","Davuluri, R; Rengaswamy, R","A Pre-trained Neural Network to Predict Alzheimer's Disease at an Early Stage","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","Alzheimer's disease (AD), which is a neuro associated disease, has become a common for past few years. In this competitive world, individual has to perform lot of multi tasking to prove their efficiency, in this process the neurons in the brain gets affected after a while i.e., ""Alzheimer's Disease"". Existing models to identify the disease at early stage has taken the individuals speech as input then they are converted into textual transcripts. These transcripts are analyzed using neural network approached by integrating them with NLP techniques. These techniques failed in designing the model which can process the long conversation text at faster rate and few models are unable to recognize the replacement of the unknown words during the translation process. The proposed system addresses these issues by converting the speech obtained into image format and then the output ""Mel-spectrum"" is passed as input to pre-trained VGG-16. This process has greatly reduced the pre-processing step and improved the efficiency of the system with less kernel size architecture. The speech to image translation mechanism has improved accuracy when compared to speech to text translators.","2022-05","2025-02-26 20:36:59","2025-02-26 20:36:59","","194-200","","5","13","","","","","","","","","","English","","","","WOS:000835105000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","ADAM optimizer; flatten layers; Mel-spectrum; ReLU; softmax; VGG-16","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PMI6T6HV","journalArticle","2021","Mahajan, P; Baths, V","Acoustic and Language Based Deep Learning Approaches for Alzheimer's Dementia Detection From Spontaneous Speech","FRONTIERS IN AGING NEUROSCIENCE","","1663-4365","10.3389/fnagi.2021.623607","","Current methods for early diagnosis of Alzheimer's Dementia include structured questionnaires, structured interviews, and various cognitive tests. Language difficulties are a major problem in dementia as linguistic skills break down. Current methods do not provide robust tools to capture the true nature of language deficits in spontaneous speech. Early detection of Alzheimer's Dementia (AD) from spontaneous speech overcomes the limitations of earlier approaches as it is less time consuming, can be done at home, and is relatively inexpensive. In this work, we re-implement the existing NLP methods, which used CNN-LSTM architectures and targeted features from conversational transcripts. Our work sheds light on why the accuracy of these models drops to 72.92% on the ADReSS dataset, whereas, they gave state of the art results on the DementiaBank dataset. Further, we build upon these language input-based recurrent neural networks by devising an end-to-end deep learning-based solution that performs a binary classification of Alzheimer's Dementia from the spontaneous speech of the patients. We utilize the ADReSS dataset for all our implementations and explore the deep learning-based methods of combining acoustic features into a common vector using recurrent units. Our approach of combining acoustic features using the Speech-GRU improves the accuracy by 2% in comparison to acoustic baselines. When further enriched by targeted features, the Speech-GRU performs better than acoustic baselines by 6.25%. We propose a bi-modal approach for AD classification and discuss the merits and opportunities of our approach.","2021-02-05","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","13","","","","","","","","","","English","","","","WOS:000619455100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;43<br/>Total Times Cited:&nbsp;&nbsp;47<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","affective computing; cognitive decline detection; computational paralinguistics; deep learning; natural language processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AYK2DZ28","journalArticle","2021","Roshanzamir, A; Aghajan, H; Baghshah, MS","Transformer-based deep neural network language models for Alzheimer's disease risk assessment from targeted speech","BMC MEDICAL INFORMATICS AND DECISION MAKING","","1472-6947","10.1186/s12911-021-01456-3","","Background We developed transformer-based deep learning models based on natural language processing for early risk assessment of Alzheimer's disease from the picture description test. Methods The lack of large datasets poses the most important limitation for using complex models that do not require feature engineering. Transformer-based pre-trained deep language models have recently made a large leap in NLP research and application. These models are pre-trained on available large datasets to understand natural language texts appropriately, and are shown to subsequently perform well on classification tasks with small training sets. The overall classification model is a simple classifier on top of the pre-trained deep language model. Results The models are evaluated on picture description test transcripts of the Pitt corpus, which contains data of 170 AD patients with 257 interviews and 99 healthy controls with 243 interviews. The large bidirectional encoder representations from transformers (BERTLarge) embedding with logistic regression classifier achieves classification accuracy of 88.08%, which improves the state-of-the-art by 2.48%. Conclusions Using pre-trained language models can improve AD prediction. This not only solves the problem of lack of sufficiently large datasets, but also reduces the need for expert-defined features.","2021-03-09","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","1","21","","","","","","","","","","English","","","","WOS:000627886700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;54<br/>Total Times Cited:&nbsp;&nbsp;58<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Alzheimer’; Deep learning; DEMENTIA; Early risk assessment; Language model; Natural language processing; Picture description test; s disease; Transfer learning; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M2K4F58N","journalArticle","2024","Lee, J; Kim, N; Ha, JW; Kang, K; Park, E; Yoon, J; Park, KS","Exploring Voice Acoustic Features Associated with Cognitive Status in Korean Speakers: A Preliminary Machine Learning Study","DIAGNOSTICS","","2075-4418","10.3390/diagnostics14242837","","Objective: To develop a non-invasive cognitive impairment detection system using speech data analysis, addressing the growing global dementia crisis and enabling accessible early screening through daily health monitoring. Methods: Speech data from 223 Korean patients were collected across eight tasks. Patients were classified based on Korean Mini-Mental State Examination scores. Four machine learning models were tested for three binary classification tasks. Voice acoustic features were extracted and analyzed. Results: The Deep Neural Network model performed best in two classification tasks, with Precision-Recall Area Under the Curve scores of 0.737 for severe vs. no impairment and 0.726 for mild vs. no impairment, while Random Forest achieved 0.715 for severe + mild vs. no impairment. Several acoustic features emerged as potentially important indicators, with DDA shimmer from the /i/ task and stdevF0 from the /puh-tuh-kuh/ task showing consistent patterns across classification tasks. Conclusions: This preliminary study suggests that certain acoustic features may be associated with cognitive status, though demographic factors significantly influence these relationships. Further research with demographically matched populations is needed to validate these findings.","2024-12","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","24","14","","","","","","","","","","English","","","","WOS:001384905200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","AGE; ALGORITHM; ALZHEIMERS-DISEASE; BIOMARKERS; CLASSIFICATION; cognitive impairment; deep learning; DEMENTIA; DIADOCHOKINESIS; IMPAIRMENT; JITTER; K-MMSE; pre-screening; SPEECH; speech features; speech tasks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BXC56K88","journalArticle","2024","Bayat, S; Sanati, M; Mohammad-Panahi, M; Khodadadi, A; Ghasimi, M; Rezaee, S; Besharat, S; Mahboubi-Fooladi, Z; Almasi-Dooghaee, M; Sanei-Taheri, M; Dickerson, BC; Rezaii, N","Language abnormalities in Alzheimer's disease indicate reduced informativeness","ANNALS OF CLINICAL AND TRANSLATIONAL NEUROLOGY","","2328-9503","10.1002/acn3.52205","","Objective: : This study aims to elucidate the cognitive underpinnings of language abnormalities in Alzheimer's Disease (AD) using a computational cross-linguistic approach and ultimately enhance the understanding and diagnostic accuracy of the disease. Methods: : Computational analyses were conducted on language samples of 156 English and 50 Persian speakers, comprising both AD patients and healthy controls, to extract language indicators of AD. Furthermore, we introduced a machine learning-based metric, Language Informativeness Index (LII), to quantify empty speech. Results: : Despite considerable disparities in surface structures between the two languages, we observed consistency across language indicators of AD in both English and Persian. Notably, indicators of AD in English resulted in a classification accuracy of 90% in classifying AD in Persian. The substantial degree of transferability suggests that the language abnormalities of AD do not tightly link to the surface structures specific to English. Subsequently, we posited that these abnormalities stem from impairments in a more universal aspect of language production: the ability to generate informative messages independent of the language spoken. Consistent with this hypothesis, we found significant correlations between language indicators of AD and empty speech in both English and Persian. Interpretation: : The findings of this study suggest that language impairments in AD arise from a deficit in a universal aspect of message formation rather than from the breakdown of language-specific morphosyntactic structures. Beyond enhancing our understanding of the psycholinguistic deficits of AD, our approach fosters the development of diagnostic tools across various languages, enhancing health equity and biocultural diversity.","2024-11","2025-02-26 20:36:59","2025-02-26 20:36:59","","2946-2957","","11","11","","","","","","","","","","English","","","","WOS:001315078200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","DISCOURSE; SPEECH; VALIDATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L5FTIYFH","journalArticle","2023","Liu, N; Yuan, ZM; Chen, Y; Liu, C; Wang, LX","Learning implicit sentiments in Alzheimer's disease recognition with contextual attention features","FRONTIERS IN AGING NEUROSCIENCE","","1663-4365","10.3389/fnagi.2023.1122799","","BackgroundAlzheimer's disease (AD) is difficult to diagnose on the basis of language because of the implicit emotion of transcripts, which is defined as a supervised fuzzy implicit emotion classification at the document level. Recent neural network-based approaches have not paid attention to the implicit sentiments entailed in AD transcripts. MethodA two-level attention mechanism is proposed to detect deep semantic information toward words and sentences, which enables it to attend to more words and fewer sentences differentially when constructing document representation. Specifically, a document vector was built by progressively aggregating important words into sentence vectors and important sentences into document vectors. ResultsExperimental results showed that our method achieved the best accuracy of 91.6% on annotated public Pitt corpora, which validates its effectiveness in learning implicit sentiment representation for our model. ConclusionThe proposed model can qualitatively select informative words and sentences using attention layers, and this method also provides good inspiration for AD diagnosis based on implicit sentiment transcripts.","2023-05-17","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","15","","","","","","","","","","English","","","","WOS:000998855700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Alzheimer's disease; attention; deep learning; feature extraction; LANGUAGE; machine learning; MILD COGNITIVE IMPAIRMENT; NEURAL-NETWORK; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IDBNLYW7","journalArticle","2024","Cay, G; Pfeifer, VA; Lee, M; Rouzi, MD; Nunes, AS; El-Refaei, N; Momin, AS; Atique, MMU; Mehl, MR; Vaziri, A; Najafi, B","Harnessing Speech-Derived Digital Biomarkers to Detect and Quantify Cognitive Decline Severity in Older Adults","GERONTOLOGY","","0304-324X","10.1159/000536250","","<bold>Introduction: </bold>Current cognitive assessments suffer from floor/ceiling and practice effects, poor psychometric performance in mild cases, and repeated assessment effects. This study explores the use of digital speech analysis as an alternative tool for determining cognitive impairment. The study specifically focuses on identifying the digital speech biomarkers associated with cognitive impairment and its severity. <bold>Methods: </bold>We recruited older adults with varying cognitive health. Their speech data, recorded via a wearable-microphone during the reading aloud of a standard passage, were processed to derive digital biomarkers such as timing, pitch, and loudness. Cohen's D effect size highlighted group differences, and correlations were drawn to the Montreal Cognitive Assessment (MoCA). A stepwise approach using a Random Forest model was implemented to distinguish cognitive states using speech data and predict MoCA scores based on highly correlated features. <bold>Results: </bold>The study comprised 59 participants, with 36 demonstrating cognitive impairment and 23 serving as cognitively intact controls. Among all assessed parameters, similarity, as determined by Dynamic Time Warping (DTW), exhibited the most substantial positive correlation (rho=0.529, p<0.001), while timing parameters, specifically the ratio of extra words, revealed the strongest negative correlation (rho=-0.441, p<0.001) with MoCA scores. Optimal discriminative performance was achieved with a combination of four speech parameters: total pause time, speech to pause ratio, similarity via DTW, and ratio of extra words. Precision and balanced accuracy scores were found to be 84.3 +/- 1.5% and 75.0 +/- 1.4%, respectively. <bold>Discussion: </bold>Our research proposes that reading-derived speech data facilitates the differentiation between cognitively impaired individuals and cognitively intact, age-matched older adults. Specifically, parameters based on timing and similarity within speech data provide an effective gauge of cognitive impairment severity. These results suggest speech analysis as a viable digital biomarker for early detection and monitoring of cognitive impairment, offering novel approaches in dementia care.","2024-04","2025-02-26 20:36:59","2025-02-26 20:36:59","","429-438","","4","70","","","","","","","","","","English","","","","WOS:001162746100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","ALZHEIMERS-DISEASE; Cognitive decline; Dementia; DEMENTIA; Digital health; IMPAIRMENT; Machine learning; MONITORING-SYSTEM; PREDICTION; RANDOM FOREST; Speech; TIME; VALIDATION; Wearables","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FJX2N8DG","journalArticle","2024","Kaser, AN; Lacritz, LH; Winiarski, HR; Gabirondo, P; Schaffert, J; Coca, AJ; Jiménez-Raboso, J; Rojo, T; Zaldua, C; Honorato, I; Gallego, D; Nieves, ER; Rosenstein, LD; Cullum, CM","A novel speech analysis algorithm to detect cognitive impairment in a Spanish population","FRONTIERS IN NEUROLOGY","","1664-2295","10.3389/fneur.2024.1342907","","Objective: Early detection of cognitive impairment in the elderly is crucial for diagnosis and appropriate care. Brief, cost-effective cognitive screening instruments are needed to help identify individuals who require further evaluation. This study presents preliminary data on a new screening technology using automated voice recording analysis software in a Spanish population. Method: Data were collected from 174 Spanish-speaking individuals clinically diagnosed as cognitively normal (CN, n = 87) or impaired (mild cognitive impairment [MCI], n = 63; all-cause dementia, n = 24). Participants were recorded performing four common language tasks (Animal fluency, alternating fluency [sports and fruits], phonemic ""F"" fluency, and Cookie Theft Description). Recordings were processed via text-transcription and digital-signal processing techniques to capture neuropsychological variables and audio characteristics. A training sample of 122 subjects with similar demographics across groups was used to develop an algorithm to detect cognitive impairment. Speech and task features were used to develop five independent machine learning (ML) models to compute scores between 0 and 1, and a final algorithm was constructed using repeated cross-validation. A socio-demographically balanced subset of 52 participants was used to test the algorithm. Analysis of covariance (ANCOVA), covarying for demographic characteristics, was used to predict logistically-transformed algorithm scores. Results: Mean logit algorithm scores were significantly different across groups in the testing sample (p < 0.01). Comparisons of CN with impaired (MCI + dementia) and MCI groups using the final algorithm resulted in an AUC of 0.93/0.90, with overall accuracy of 88.4%/87.5%, sensitivity of 87.5/83.3, and specificity of 89.2/89.2, respectively. Conclusion: Findings provide initial support for the utility of this automated speech analysis algorithm as a screening tool for cognitive impairment in Spanish speakers. Additional study is needed to validate this technology in larger and more diverse clinical populations.","2024-04-04","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","15","","","","","","","","","","English","","","","WOS:001204726800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;80</p>","","","ASSOCIATION; dementia; DEMENTIA; digital biomarkers; EARLY ALZHEIMERS-DISEASE; early detection; LANGUAGE; MCI; MEMORY; METAANALYSIS; mild cognitive impairment; MINI-MENTAL-STATE; PRIMARY-CARE; RECOGNITION; speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ADSPKZA9","journalArticle","2024","Asano, T; Yasuda, A; Kinoshita, S; Nomoto, J; Kato, T; Suzuki, C; Suzuki, H; Kinoshita, T; Shigeta, M; Homma, A","Actual Clinical Practice Assessment: A Rapid and Easy-to-Use Tool for Evaluating Cognitive Decline Equivalent to Dementia","CUREUS JOURNAL OF MEDICAL SCIENCE","","2168-8184","10.7759/cureus.58781","","Background Screening tests reveal the early signs of cognitive decline, enabling better self-care and preparation for the future. We developed and evaluated the accuracy of a rapid (20 s) and easy-to-use tool called ONSEI, assessing the cognitive decline equivalent to dementia in actual clinical practice by correlating clinical diagnoses with the ONSEI classification. Methods In this retrospective observational study, data were collected from individuals who visited three neurosurgical clinics in neighboring prefectures of Tokyo, Japan. ONSEI analysis was performed using a smartphone or tablet. The tool adopts a machine-learning algorithm using the speaker's age, timeorientation task score, and acoustic features of spoken responses to that task. Significant differences in accuracy, sensitivity, and specificity were evaluated by Fisher's exact test. Results The overall classification accuracy of ONSEI was 98.1% (p<0.001). The sensitivity and specificity were 97.3% (p<0.001) and 98.5% (p<0.001), respectively. The proportion of correct classifications was consistent across different age groups. Conclusion ONSEI showed high classification accuracy for dementia in cognitively normal individuals in actual clinical practice, regardless of the facility at which the tests were conducted or the age of the participants. Thus, ONSEI can be useful for dementia screening and self-care.","2024-04-22","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","4","16","","","","","","","","","","English","","","","WOS:001222972400030","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;14</p>","","","automated classification; dementia; digital cognitive assessment; machine learning; speech features","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GP8GVISZ","journalArticle","2021","König, A; Mallick, E; Tröger, J; Linz, N; Zeghari, R; Manera, V; Robert, P","Measuring neuropsychiatric symptoms in patients with early cognitive decline using speech analysis","EUROPEAN PSYCHIATRY","","0924-9338","10.1192/j.eurpsy.2021.2236","","Background Certain neuropsychiatric symptoms (NPS), namely apathy, depression, and anxiety demonstrated great value in predicting dementia progression, representing eventually an opportunity window for timely diagnosis and treatment. However, sensitive and objective markers of these symptoms are still missing. Therefore, the present study aims to investigate the association between automatically extracted speech features and NPS in patients with mild neurocognitive disorders. Methods Speech of 141 patients aged 65 or older with neurocognitive disorder was recorded while performing two short narrative speech tasks. NPS were assessed by the neuropsychiatric inventory. Paralinguistic markers relating to prosodic, formant, source, and temporal qualities of speech were automatically extracted, correlated with NPS. Machine learning experiments were carried out to validate the diagnostic power of extracted markers. Results Different speech variables are associated with specific NPS; apathy correlates with temporal aspects, and anxiety with voice quality-and this was mostly consistent between male and female after correction for cognitive impairment. Machine learning regressors are able to extract information from speech features and perform above baseline in predicting anxiety, apathy, and depression scores. Conclusions Different NPS seem to be characterized by distinct speech features, which are easily extractable automatically from short vocal tasks. These findings support the use of speech analysis for detecting subtypes of NPS in patients with cognitive impairment. This could have great implications for the design of future clinical trials as this cost-effective method could allow more continuous and even remote monitoring of symptoms.","2021-10-13","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","1","64","","","","","","","","","","English","","","","WOS:000721263200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;20<br/>Total Times Cited:&nbsp;&nbsp;20<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","apathy; APATHY; DEMENTIA; depression; DEPRESSION; DISORDERS; GENDER RECOGNITION; ILLNESS; IMPAIRMENT; INSIGHT; mild neurocognitive disorders; neuropsychiatric symptoms; PREVALENCE; RISK; speech analysis; vocal parameters","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RYYHK35N","journalArticle","2021","Ditthapron, A; Agu, EO; Lammert, AC","Privacy-Preserving Deep Speaker Separation for Smartphone-Based Passive Speech Assessment","IEEE OPEN JOURNAL OF ENGINEERING IN MEDICINE AND BIOLOGY","","2644-1276","10.1109/OJEMB.2021.3063994","","Goal: Smartphones can be used to passively assess and monitor patients' speech impairments caused by ailments such as Parkinson's disease, Traumatic Brain Injury (TBI), Post-Traumatic Stress Disorder (PTSD) and neurodegenerative diseases such as Alzheimer's disease and dementia. However, passive audio recordings in natural settings often capture the speech of non-target speakers (cross-talk). Consequently, speaker separation, which identifies the target speakers' speech in audio recordings with two or more speakers' voices, is a crucial pre-processing step in such scenarios. Prior speech separation methods analyzed raw audio. However, in order to preserve speaker privacy, passively recorded smartphone audio and machine learning-based speech assessment are often performed on derived speech features such as Mel-Frequency Cepstral Coefficients (MFCCs). In this paper, we propose a novel Deep MFCC bAsed SpeaKer Separation (Deep-MASKS). Methods: Deep-MASKS uses an autoencoder to reconstruct MFCC components of an individual's speech from an i-vector, x-vector or d-vector representation of their speech learned during the enrollment period. Deep-MASKS utilizes a Deep Neural Network (DNN) for MFCC signal reconstructions, which yields a more accurate, higher-order function compared to prior work that utilized a mask. Unlike prior work that operates on utterances, Deep-MASKS operates on continuous audio recordings. Results: Deep-MASKS outperforms baselines, reducing the Mean Squared Error (MSE) of MFCC reconstruction by up to 44% and the number of additional bits required to represent clean speech entropy by 36%.","2021","2025-02-26 20:36:59","2025-02-26 20:36:59","","304-313","","","2","","","","","","","","","","English","","","","WOS:000736737800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Diseases; Feature extraction; Impact Statement-The proposed Deep-MASKS mitigates cross-talk in speech encoded as MFCC features; Mel frequency cepstral coefficient; Mel-Frequency Cepstrum Coefficients (MFCCs); overlapped speech; Pipelines; Smart phones; speaker representation; speech separation; Task analysis; Voice activity detection; which are widely utilized to preserve voice privacy in passive health assessment and other speech applications on smartphones","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MKB8A9C9","journalArticle","2025","Sigona, F; Radicioni, DP; Fivela, BG; Colla, D; Delsanto, M; Mensa, E; Bolioli, A; Vigorelli, P","A computational analysis of transcribed speech of people living with dementia: The Anchise 2022 Corpus","COMPUTER SPEECH AND LANGUAGE","","0885-2308","10.1016/j.csl.2024.101691","","Introduction: Automatic linguistic analysis can provide cost-effective, valuable clues to the diagnosis of cognitive difficulties and to therapeutic practice, and hence impact positively on wellbeing. In this work, we analyzed transcribed conversations between elderly individuals living with dementia and healthcare professionals. The material came from the Anchise 2022 Corpus, a large collection of transcripts of conversations in Italian recorded in naturalistic conditions. The aim of the work was to test the effectiveness of a number of automatic analyzes in finding correlations with the progression of dementia in individuals with cognitive decline as measured by the Mini-Mental State Examination (MMSE) score, which is the only psychometric-clinical information available on the participants in the conversations. Healthy controls (HC) were not considered in this study, nor does the corpus itself include HCs. The main innovation and strength of the work consists in the high ecological validity of the language analyzed (most of the literature to date concerns controlled language experiments); in the use of Italian (there is little corpora for Italian); in the size of the analyzed data (more than 200 conversations were considered); in the adoption of a wide range of NLP methods, that span from traditional morphosyntactic investigation to deep linguistic models for conducting analyzes such as through perplexity, sentiment (polarity) and emotions. Methods: Analyzing real-world interactions not designed with computational analysis in mind, such as is the case of the Anchise Corpus, is particularly challenging. To achieve the research goals, a wide variety of tools were employed. These included traditional morphosyntactic analysis based on digital linguistic biomarkers (DLBs), transformer-based language models, sentiment and emotion analysis, and perplexity metrics. Analyzes were conducted both on the continuous range of MMSE values and on the severe/moderate/mild categorization suggested by AIFA (Italian Medicines Agency) guidelines, based on MMSE threshold values. Results and discussion: Correlations between MMSE and individual DLBs were weak, up to 0.19 for positive, and-0.21 for negative correlation values. Nevertheless, some correlations were statistically significant and consistent with the literature, suggesting that people with a greater degree of impairment tend to show a reduced vocabulary, to have anomia, to adopt a more informal linguist register, and to display a simplified use of verbs, with a decrease in the use of participles, gerunds, subjunctive moods, modal verbs, as well as a flattening in the use of the tenses towards the present to the detriment of the past. The-0.26 inverse correlation between perplexity and MMSE suggests that perplexity captures slightly more specific linguistic information, which can complement the MMSE scores. In the categorization tasks, the classifier based on DLBs achieved an F1 score of 0.79 for binary classification between SEVERE and MILD, and 0.61 for multi-label categorization. Sentiment and emotion analyzes showed inverse trends for joy while MMSE scores suggested that less impaired individuals were less joyful, or more ""negative"", than others. Considering the real-world context, this is consistent with the hypothesis of a gradual reduction in awareness in individuals affected by dementia. Finally, integrating various profiles of analysis has been proved to be effective in offering a wider picture of linguistic and communication deficits, as well as more precise data regarding the progression of dementia.","2025-01","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","89","","","","","","","","","","English","","","","WOS:001287823400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;113</p>","","","ACCURACY; ALZHEIMERS-DISEASE; APHASIA; Automatic speech and language analysis; AUTOMATIC-ANALYSIS; BIOMARKERS; DIAGNOSIS; Digital linguistic biomarkers; Emotion analysis; Enabling approach; MILD COGNITIVE IMPAIRMENT; MINI-MENTAL-STATE; MMSE; Naturalistic conversations; NLP; Perplexity; SCALE; SELECTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M2GCNNUV","journalArticle","2022","Vincze, V; Szabó, MK; Hoffmann, I; Tóth, L; Pákáski, M; Kálmán, J; Gosztolya, G","Linguistic Parameters of Spontaneous Speech for Identifying Mild Cognitive Impairment and Alzheimer Disease","COMPUTATIONAL LINGUISTICS","","0891-2017","10.1162/coli_a_00428","","In this article, we seek to automatically identify Hungarian patients suffering from mild cognitive impairment (MCI) or mild Alzheimer disease (mAD) based on their speech transcripts, focusing only on linguistic features. In addition to the features examined in our earlier study, we introduce syntactic, semantic, and pragmatic features of spontaneous speech that might affect the detection of dementia. In order to ascertain the most useful features for distinguishing healthy controls, MCI patients, and mAD patients, we carry out a statistical analysis of the data and investigate the significance level of the extracted features among various speaker group pairs and for various speaking tasks. In the second part of the article, we use this rich feature set as a basis for an effective discrimination among the three speaker groups. In our machine learning experiments, we analyze the efficacy of each feature group separately. Our model that uses all the features achieves competitive scores, either with or without demographic information (3-class accuracy values: 68%-70%, 2-class accuracy values: 77.3%-80%). We also analyze how different data recording scenarios affect linguistic features and how they can be productively used when distinguishing MCI patients from healthy controls.","2022-04","2025-02-26 20:36:59","2025-02-26 20:36:59","","43-75","","1","48","","","","","","","","","","English","","","","WOS:000993785100005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","DEMENTIA; DIAGNOSIS; PROGRESSION; RECOGNITION; SELECTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XVN77GPI","journalArticle","2021","Shimoda, A; Li, Y; Hayashi, H; Kondo, N","Dementia risks identified by vocal features via telephone conversations: A novel machine learning prediction model","PLOS ONE","","1932-6203","10.1371/journal.pone.0253988","","Due to difficulty in early diagnosis of Alzheimer's disease (AD) related to cost and differentiated capability, it is necessary to identify low-cost, accessible, and reliable tools for identifying AD risk in the preclinical stage. We hypothesized that cognitive ability, as expressed in the vocal features in daily conversation, is associated with AD progression. Thus, we have developed a novel machine learning prediction model to identify AD risk by using the rich voice data collected from daily conversations, and evaluated its predictive performance in comparison with a classification method based on the Japanese version of the Telephone Interview for Cognitive Status (TICS-J). We used 1,465 audio data files from 99 Healthy controls (HC) and 151 audio data files recorded from 24 AD patients derived from a dementia prevention program conducted by Hachioji City, Tokyo, between March and May 2020. After extracting vocal features from each audio file, we developed machine-learning models based on extreme gradient boosting (XGBoost), random forest (RF), and logistic regression (LR), using each audio file as one observation. We evaluated the predictive performance of the developed models by describing the receiver operating characteristic (ROC) curve, calculating the areas under the curve (AUCs), sensitivity, and specificity. Further, we conducted classifications by considering each participant as one observation, computing the average of their audio files' predictive value, and making comparisons with the predictive performance of the TICS-J based questionnaire. Of 1,616 audio files in total, 1,308 (81.0%) were randomly allocated to the training data and 308 (19.1%) to the validation data. For audio file-based prediction, the AUCs for XGboost, RF, and LR were 0.863 (95% confidence interval [CI]: 0.794-0.931), 0.882 (95% CI: 0.840-0.924), and 0.893 (95%CI: 0.832-0.954), respectively. For participant-based prediction, the AUC for XGboost, RF, LR, and TICS-J were 1.000 (95%CI: 1.000-1.000), 1.000 (95%CI: 1.000-1.000), 0.972 (95%CI: 0.918-1.000) and 0.917 (95%CI: 0.918-1.000), respectively. There was difference in predictive accuracy of XGBoost and TICS-J with almost approached significance (p = 0.065). Our novel prediction model using the vocal features of daily conversations demonstrated the potential to be useful for the AD risk assessment.","2021-07-14","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","7","16","","","","","","","","","","English","","","","WOS:000678119300028","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;25<br/>Total Times Cited:&nbsp;&nbsp;26<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","ALZHEIMERS-DISEASE; COGNITIVE STATUS TICS; DIAGNOSIS; IMPAIRMENT; INTERVIEW; LANGUAGE; NEURAL-NETWORKS; PERFORMANCES; REGRESSION; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ICAX8YNZ","journalArticle","2022","Matias-Guiu, JA; Suárez-Coalla, P; Yus, M; Pytel, V; Hernández-Lorenzo, L; Delgado-Alonso, C; Delgado-Alvarez, A; Gómez-Ruiz, N; Polidura, C; Cabrera-Martín, MN; Matías-Guiu, J; Cuetos, F","Identification of the main components of spontaneous speech in primary progressive aphasia and their neural underpinnings using multimodal MRI and FDG-PET imaging","CORTEX","","0010-9452","10.1016/j.cortex.2021.10.010","","Background: Primary progressive aphasia (PPA) is a clinical syndrome characterized by gradual loss of language skills. This study aimed to evaluate the diagnostic capacity of a connected speech task for the diagnosis of PPA and its variants, to determine the main components of spontaneous speech, and to examine their neural correlates. Methods: A total of 118 participants (31 patients with nfvPPA, 11 with svPPA, 45 with lvPPA, and 31 healthy controls) were evaluated with the Cookie Theft picture description task and a comprehensive language assessment protocol. Patients also underwent F-18-fluorodeoxyglucose positron emission tomography and magnetic resonance imaging studies. Principal component analysis and machine learning were used to evaluate the main components of connected speech and the accuracy of connected speech parameters for diagnosing PPA. Voxel-based analyses were conducted to evaluate the correlation between spontaneous speech components and brain metabolism, brain volumes, and white matter microstructure. Results: Discrimination between patients with PPA and controls was 91.67%, with 77.78% discrimination between PPA variants. Parameters related to speech rate and lexical variables were the most discriminative for classification. Three main components were identified: lexical features, fluency, and syntax. The lexical component was associated with ventrolateral frontal regions, while the fluency component was associated with the medial superior prefrontal cortex. Number of pauses was more related with the left parietotemporal region, while pauses duration with the bilateral frontal lobe. The lexical component was correlated with several tracts in the language network (left frontal aslant tract, left superior longitudinal fasciculus I, II, and III, left arcuate fasciculus, and left uncinate fasciculus), and fluency was linked to the frontal aslant tract. Conclusion: Spontaneous speech assessment is a useful, brief approach for the diagnosis of PPA and its variants. Neuroimaging correlates suggested a subspecialization within the left frontal lobe, with ventrolateral regions being more associated with lexical production and the medial superior prefrontal cortex with speech rate. (C) 2021 Elsevier Ltd. All rights reserved.","2022-01","2025-02-26 20:36:59","2025-02-26 20:36:59","","141-160","","","146","","","","","","","","","","English","","","","WOS:000829963900003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","Brain metabolism; CLASSIFICATION; CONNECTED SPEECH; DEFICITS; DEMENTIA; DISRUPTION; IMPAIRMENTS; LANGUAGE; Machine learning; MRI; NONFLUENT; Primary progressive aphasia; Speech; VARIANTS; WORD RETRIEVAL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M8UEHH9P","journalArticle","2024","Possemis, N; ter Huurne, D; Banning, L; Gruters, A; Van Asbroeck, S; König, A; Linz, N; Tröger, J; Langel, K; Blokland, A; Prickaerts, J; de Vugt, M; Verhey, F; Ramakers, I","The Reliability and Clinical Validation of Automatically-Derived Verbal Memory Features of the Verbal Learning Test in Early Diagnostics of Cognitive Impairment","JOURNAL OF ALZHEIMERS DISEASE","","1387-2877","10.3233/JAD-230608","","Background: Previous research has shown that verbal memory accurately measures cognitive decline in the early phases of neurocognitive impairment. Automatic speech recognition from the verbal learning task (VLT) can potentially be used to differentiate between people with and without cognitive impairment. Objective: Investigate whether automatic speech recognition (ASR) of the VLT is reliable and able to differentiate between subjective cognitive decline (SCD) and mild cognitive impairment (MCI). Methods: The VLT was recorded and processed via a mobile application. Following, verbal memory features were automatically extracted. The diagnostic performance of the automatically derived features was investigated by training machine learning classifiers to distinguish between participants with SCD versus MCI/dementia. Results: The ICC for inter-rater reliability between the clinical and automatically derived features was 0.87 for the total immediate recall and 0.94 for the delayed recall. The full model including the total immediate recall, delayed recall, recognition count, and the novel verbal memory features had an AUC of 0.79 for distinguishing between participants with SCD versus MCI/dementia. The ten best differentiating VLT features correlated low to moderate with other cognitive tests such as logical memory tasks, semantic verbal fluency, and executive functioning. Conclusions: TheVLT with automatically derived verbal memory features showed in general high agreement with the clinical scoring and distinguished well between SCD and MCI/dementia participants. This might be of added value in screening for cognitive impairment.","2024","2025-02-26 20:36:59","2025-02-26 20:36:59","","179-191","","1","97","","","","","","","","","","English","","","","WOS:001167619600011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","AGE; Alzheimer's disease; ALZHEIMERS-DISEASE; cognitive dysfunction; DEMENTIA; EDUCATION; FLUENCY; memory; NORMATIVE DATA; PARTICIPANTS; RECALL; speech; UTILITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B76IAZYJ","journalArticle","2022","Ferrario, A; Luo, MX; Polsinelli, AJ; Moseley, SA; Mehl, MR; Yordanova, K; Martin, M; Demiray, B","Predicting Working Memory in Healthy Older Adults Using Real-Life Language and Social Context Information: A Machine Learning Approach","JMIR AGING","","2561-7605","10.2196/28333","","Background: Language use and social interactions have demonstrated a close relationship with cognitive measures. It is important to improve the understanding of language use and behavioral indicators from social context to study the early prediction of cognitive decline among healthy populations of older adults. Objective: This study aimed at predicting an important cognitive ability, working memory, of 98 healthy older adults participating in a 4-day-long naturalistic observation study. We used linguistic measures, part-of-speech (POS) tags, and social context information extracted from 7450 real-life audio recordings of their everyday conversations. Methods: The methods in this study comprise (1) the generation of linguistic measures, representing idea density, vocabulary richness, and grammatical complexity, as well as POS tags with natural language processing (NLP) from the transcripts of real-life conversations and (2) the training of machine learning models to predict working memory using linguistic measures, POS tags, and social context information. We measured working memory using (1) the Keep Track test, (2) the Consonant Updating test, and (3) a composite score based on the Keep Track and Consonant Updating tests. We trained machine learning models using random forest, extreme gradient boosting, and light gradient boosting machine algorithms, implementing repeated cross-validation with different numbers of folds and repeats and recursive feature elimination to avoid overfitting. Results: For all three prediction routines, models comprising linguistic measures, POS tags, and social context information improved the baseline performance on the validation folds. The best model for the Keep Track prediction routine comprised linguistic measures, POS tags, and social context variables. The best models for prediction of the Consonant Updating score and the composite working memory score comprised POS tags only. Conclusions: The results suggest that machine learning and NLP may support the prediction of working memory using, in particular, linguistic measures and social context information extracted from the everyday conversations of healthy older adults. Our findings may support the design of an early warning system to be used in longitudinal studies that collects cognitive ability scores and records real-life conversations unobtrusively. This system may support the timely detection of early cognitive decline. In particular, the use of a privacy-sensitive passive monitoring technology would allow for the design of a program of interventions to enable strategies and treatments to decrease or avoid early cognitive decline.","2022-01","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","1","5","","","","","","","","","","English","","","","WOS:000798389400005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","ACTIVATED RECORDER EAR; ALZHEIMERS-DISEASE; behavioral indicators; cognitive aging; COMPLEXITY; CROSS-VALIDATION; DECLINE; DEMENTIA; Electronically Activated Recorder (EAR); EXECUTIVE FUNCTIONS; GUIDELINES; language complexity; machine learning; natural language processing; social context","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A5AUIVY3","journalArticle","2024","Ferrante, FJ; Migeot, J; Birba, A; Amoruso, L; Pérez, G; Hesse, E; Tagliazucchi, E; Estienne, C; Serrano, C; Slachevsky, A; Matallana, D; Reyes, P; Ibáñez, A; Fittipaldi, S; Campo, CG; García, AM","Multivariate word properties in fluency tasks reveal markers of Alzheimer's dementia","ALZHEIMERS & DEMENTIA","","1552-5260","10.1002/alz.13472","","INTRODUCTION: Verbal fluency tasks are common in Alzheimer's disease (AD) assessments. Yet, standard valid response counts fail to reveal disease-specific semanticmemory patterns. Here, we leveraged automatedword-property analysis to capture neurocognitive markers of AD vis-a-vis behavioral variant frontotemporal dementia (bvFTD). METHODS: Patients and healthy controls completed two fluency tasks. We counted valid responses and computed each word's frequency, granularity, neighborhood, length, familiarity, and imageability. These features were used for group-level discrimination, patient-level identification, and correlations with executive and neural (magnetic resonanance imaging [MRI], functionalMRI [fMRI], electroencephalography [EEG]) patterns. RESULTS: Valid responses revealed deficits in both disorders. Conversely, frequency, granularity, and neighborhood yielded robust group- and subject-level discrimination only in AD, also predicting executive outcomes. Disease-specific cortical thickness patterns were predicted by frequency in both disorders. Default-mode and salience network hypoconnectivity, and EEG beta hypoconnectivity, were predicted by frequency and granularity only in AD. DISCUSSION: Word-property analysis of fluency can boost AD characterization and diagnosis.","2024-02","2025-02-26 20:36:59","2025-02-26 20:36:59","","925-940","","2","20","","","","","","","","","","English","","","","WOS:001082121200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","ASSOCIATION; BEHAVIORAL VARIANT; CRITERIA; DIAGNOSIS; DISEASE; electroencephalography; FUNCTIONAL CONNECTIVITY; machine learning; neurodegeneration; neuroimaging; semantic memory; SPEECH; TOOL; VERBAL FLUENCY; word properties","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CP39UIRI","journalArticle","2024","Kim, H; Hillis, AE; Themistocleous, C","Machine Learning Classification of Patients with Amnestic Mild Cognitive Impairment and Non-Amnestic Mild Cognitive Impairment from Written Picture Description Tasks","BRAIN SCIENCES","","2076-3425","10.3390/brainsci14070652","","Individuals with Mild Cognitive Impairment (MCI), a transitional stage between cognitively healthy aging and dementia, are characterized by subtle neurocognitive changes. Clinically, they can be grouped into two main variants, namely patients with amnestic MCI (aMCI) and non-amnestic MCI (naMCI). The distinction of the two variants is known to be clinically significant as they exhibit different progression rates to dementia. However, it has been particularly challenging to classify the two variants robustly. Recent research indicates that linguistic changes may manifest as one of the early indicators of pathology. Therefore, we focused on MCI's discourse-level writing samples in this study. We hypothesized that a written picture description task can provide information that can be used as an ecological, cost-effective classification system between the two variants. We included one hundred sixty-nine individuals diagnosed with either aMCI or naMCI who received neurophysiological evaluations in addition to a short, written picture description task. Natural Language Processing (NLP) and a BERT pre-trained language model were utilized to analyze the writing samples. We showed that the written picture description task provided 90% overall classification accuracy for the best classification models, which performed better than cognitive measures. Written discourses analyzed by AI models can automatically assess individuals with aMCI and naMCI and facilitate diagnosis, prognosis, therapy planning, and evaluation.","2024-07","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","7","14","","","","","","","","","","English","","","","WOS:001276446500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","ALZHEIMERS-DISEASE; AUTOMATED CLASSIFICATION; BIOMARKERS; DECLINE; DEMENTIA; DIAGNOSIS; DISCOURSE; machine learning; mild cognitive impairment; NARRATIVE SPEECH; PROGRESSION; RISK; writing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7ND8886I","journalArticle","2022","Horigome, T; Hino, K; Toyoshiba, H; Shindo, N; Funaki, K; Eguchi, Y; Kitazawa, M; Fujita, T; Mimura, M; Kishimoto, T","Identifying neurocognitive disorder using vector representation of free conversation","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-022-16204-4","","In recent years, studies on the use of natural language processing (NLP) approaches to identify dementia have been reported. Most of these studies used picture description tasks or other similar tasks to encourage spontaneous speech, but the use of free conversation without requiring a task might be easier to perform in a clinical setting. Moreover, free conversation is unlikely to induce a learning effect. Therefore, the purpose of this study was to develop a machine learning model to discriminate subjects with and without dementia by extracting features from unstructured free conversation data using NLP. We recruited patients who visited a specialized outpatient clinic for dementia and healthy volunteers. Participants' conversation was transcribed and the text data was decomposed from natural sentences into morphemes by performing a morphological analysis using NLP, and then converted into real-valued vectors that were used as features for machine learning. A total of 432 datasets were used, and the resulting machine learning model classified the data for dementia and non-dementia subjects with an accuracy of 0.900, sensitivity of 0.881, and a specificity of 0.916. Using sentence vector information, it was possible to develop a machine-learning algorithm capable of discriminating dementia from non-dementia subjects with a high accuracy based on free conversation.","2022-08-03","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","1","12","","","","","","","","","","English","","","","WOS:000835830500033","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","ALZHEIMERS-DISEASE; APHASIA; COGNITIVE IMPAIRMENT; COST-EFFECTIVENESS; DEMENTIA; DIAGNOSIS; DONEPEZIL; LANGUAGE; MEMORY; MILD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9YM8GZUX","journalArticle","2021","Alkenani, AH; Li, YF; Xu, Y; Zhang, Q","Predicting Alzheimer's Disease from Spoken and Written Language Using Fusion-Based Stacked Generalization","JOURNAL OF BIOMEDICAL INFORMATICS","","1532-0464","10.1016/j.jbi.2021.103803","","The importance of automating the diagnosis of Alzheimer disease (AD) towards facilitating its early prediction has long been emphasized, hampered in part by lack of empirical support. Given the evident association of AD with age and the increasing aging population owing to the general well-being of individuals, there have been unprecedented estimated economic complications. Consequently, many recent studies have attempted to employ the language deficiency caused by cognitive decline in automating the diagnostic task via training machine learning (ML) algorithms with linguistic patterns and deficits. In this study, we aim to develop multiple heterogeneous stacked fusion models that harness the advantages of several base learning algorithms to improve the overall generalizability and robustness of AD diagnostic ML models, where we parallelly utilized two different written and spoken-based datasets to train our stacked fusion models. Further, we examined the effect of linking these two datasets to develop a hybrid stacked fusion model that can predict AD from written and spoken languages. Our feature spaces involved two widely used linguistic patterns: lexicosyntactics and character n-gram spaces. We firstly investigated lexicosyntactics of AD alongside healthy controls (HC), where we explored a few new lexicosyntactic features, then optimized the lexicosyntactic feature space by proposing a correlation feature selection technique that eliminates features based on their feature-feature inter-correlations and feature-target correlations according to a certain threshold. Our stacked fusion models establish benchmarks on both datasets with AUC of 98.1% and 99.47% for the spoken and written-based datasets, respectively, and corresponding accuracy and F1 score values around 95% on spoken-based dataset and around 97% on the written-based dataset. Likewise, the hybrid stacked fusion model on linked data presents an optimal performance with 99.2% AUC as well as accuracy and F1 score falling around 97%. In view of the achieved performance and enhanced generalizability of such fusion models over single classifiers, this study suggests replacing the initial traditional screening test with such models that can be embedded into an online format for a fully automated remote diagnosis.","2021-06","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","118","","","","","","","","","","English","","","","WOS:000658811000006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;80</p>","","","AUTOMATIC DETECTION; Clinical diagnosis; Cognitive decline; CORRELATION-COEFFICIENT; DEMENTIA; Ensemble classifier; Feature selection; FEATURE-SELECTION; Information fusion; Machine learning; MILD COGNITIVE IMPAIRMENT; MUTUAL INFORMATION; Neurolinguistics; PERFORMANCE; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NUGNX7WD","journalArticle","2024","Ambrosini, E; Giangregorio, C; Lomurno, E; Moccia, S; Milis, M; Loizou, C; Azzolino, D; Cesari, M; Gala, MC; de Isla, CG; Gomez-Raja, J; Borghese, NA; Matteucci, M; Ferrante, S","Automatic Spontaneous Speech Analysis for the Detection of Cognitive Functional Decline in Older Adults: Multilanguage Cross-Sectional Study","JMIR AGING","","2561-7605","10.2196/50537","","Background: The rise in life expectancy is associated with an increase in long-term and gradual cognitive decline. Treatment effectiveness is enhanced at the early stage of the disease. Therefore, there is a need to find low-cost and ecological solutions for mass screening of community-dwelling older adults. Objective: This work aims to exploit automatic analysis of free speech to identify signs of cognitive function decline. Methods: A sample of 266 participants older than 65 years were recruited in Italy and Spain and were divided into 3 groups according to their Mini-Mental Status Examination (MMSE) scores. People were asked to tell a story and describe a picture, and voice recordings were used to extract high-level features on different time scales automatically. Based on these features, machine learning algorithms were trained to solve binary and multiclass classification problems by using both mono- and cross-lingual approaches. The algorithms were enriched using Shapley Additive Explanations for model explainability. Results: In the Italian data set, healthy participants (MMSE score >= 27) were automatically discriminated from participants with mildly impaired cognitive function (20 <= MMSE score <= 26) and from those with moderate to severe impairment of cognitive function (11 <= MMSE score <= 19) with accuracy of 80% and 86%, respectively. Slightly lower performance was achieved in the Spanish and multilanguage data sets. Conclusions: This work proposes a transparent and unobtrusive assessment method, which might be included in a mobile app for large-scale monitoring of cognitive functionality in older adults. Voice is confirmed to be an important biomarker of cognitive decline due to its noninvasive and easily accessible nature.","2024","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","7","","","","","","","","","","English","","","","WOS:001240929400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","ALZHEIMERS-DISEASE; cognitive decline; DEMENTIA; IMPAIRMENT; machine learning; Mini -Mental Status Examination; MINI-MENTAL-STATE; multilanguage; speech processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5HE4JXJ4","journalArticle","2023","Scotton, WJ; Shand, C; Todd, E; Bocchetta, M; Cash, DM; VandeVrede, L; Heuer, H; Young, AL; Oxtoby, N; Alexander, DC; Rowe, JB; Morris, HR; Boxer, AL; Rohrer, JD; Wijeratne, PA; PROSPECT Consortium; 4RTNI Consortium","Uncovering spatiotemporal patterns of atrophy in progressive supranuclear palsy using unsupervised machine learning","BRAIN COMMUNICATIONS","","2632-1297","10.1093/braincomms/fcad048","","To better understand the pathological and phenotypic heterogeneity of progressive supranuclear palsy and the links between the two, we applied a novel unsupervised machine learning algorithm (Subtype and Stage Inference) to the largest MRI data set to date of people with clinically diagnosed progressive supranuclear palsy (including progressive supranuclear palsy-Richardson and variant progressive supranuclear palsy syndromes). Our cohort is comprised of 426 progressive supranuclear palsy cases, of which 367 had at least one follow-up scan, and 290 controls. Of the progressive supranuclear palsy cases, 357 were clinically diagnosed with progressive supranuclear palsy-Richardson, 52 with a progressive supranuclear palsy-cortical variant (progressive supranuclear palsy-frontal, progressive supranuclear palsy-speech/language, or progressive supranuclear palsy-corticobasal), and 17 with a progressive supranuclear palsy-subcortical variant (progressive supranuclear palsy-parkinsonism or progressive supranuclear palsy-progressive gait freezing). Subtype and Stage Inference was applied to volumetric MRI features extracted from baseline structural (T1-weighted) MRI scans and then used to subtype and stage follow-up scans. The subtypes and stages at follow-up were used to validate the longitudinal consistency of subtype and stage assignments. We further compared the clinical phenotypes of each subtype to gain insight into the relationship between progressive supranuclear palsy pathology, atrophy patterns, and clinical presentation. The data supported two subtypes, each with a distinct progression of atrophy: a 'subcortical' subtype, in which early atrophy was most prominent in the brainstem, ventral diencephalon, superior cerebellar peduncles, and the dentate nucleus, and a 'cortical' subtype, in which there was early atrophy in the frontal lobes and the insula alongside brainstem atrophy. There was a strong association between clinical diagnosis and the Subtype and Stage Inference subtype with 82% of progressive supranuclear palsy-subcortical cases and 81% of progressive supranuclear palsy-Richardson cases assigned to the subcortical subtype and 82% of progressive supranuclear palsy-cortical cases assigned to the cortical subtype. The increasing stage was associated with worsening clinical scores, whilst the 'subcortical' subtype was associated with worse clinical severity scores compared to the 'cortical subtype' (progressive supranuclear palsy rating scale and Unified Parkinson's Disease Rating Scale). Validation experiments showed that subtype assignment was longitudinally stable (95% of scans were assigned to the same subtype at follow-up) and individual staging was longitudinally consistent with 90% remaining at the same stage or progressing to a later stage at follow-up. In summary, we applied Subtype and Stage Inference to structural MRI data and empirically identified two distinct subtypes of spatiotemporal atrophy in progressive supranuclear palsy. These image-based subtypes were differentially enriched for progressive supranuclear palsy clinical syndromes and showed different clinical characteristics. Being able to accurately subtype and stage progressive supranuclear palsy patients at baseline has important implications for screening patients on entry to clinical trials, as well as tracking disease progression. Scotton et al. apply Subtype and Stage Inference, a machine learning algorithm, to a cross-sectional MRI data to identify two distinct and stable spatiotemporal subtypes of atrophy progression in progressive supranuclear palsy (PSP). These subtypes provide unique insights into disease progression in PSP.","2023-03-02","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","2","5","","","","","","","","","","English","","","","WOS:000958319400006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","biomarkers; CLINICAL PHENOTYPES; disease progression; EARLY-STAGE; ELDERLY BRAIN; FEATURES; machine learning; MENTAL-STATE-EXAMINATION; OUTCOMES; progressive supranuclear palsy; PSP; RICHARDSONS-SYNDROME; SEGMENTATION; Subtype and Stage Inference; SURVIVAL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NF2LPZIZ","journalArticle","2021","O'Malley, RPD; Mirheidari, B; Harkness, K; Reuber, M; Venneri, A; Walker, T; Christensen, H; Blackburn, D","Fully automated cognitive screening tool based on assessment of speech and language","JOURNAL OF NEUROLOGY NEUROSURGERY AND PSYCHIATRY","","0022-3050","10.1136/jnnp-2019-322517","","Introduction Recent years have seen an almost sevenfold rise in referrals to specialist memory clinics. This has been associated with an increased proportion of patients referred with functional cognitive disorder (FCD), that is, non-progressive cognitive complaints. These patients are likely to benefit from a range of interventions (eg, psychotherapy) distinct from the requirements of patients with neurodegenerative cognitive disorders. We have developed a fully automated system, 'CognoSpeak', which enables risk stratification at the primary-secondary care interface and ongoing monitoring of patients with memory concerns. Methods We recruited 15 participants to each of four groups: Alzheimer's disease (AD), mild cognitive impairment (MCI), FCD and healthy controls. Participants responded to 12 questions posed by a computer-presented talking head. Automatic analysis of the audio and speech data involved speaker segmentation, automatic speech recognition and machine learning classification. Results CognoSpeak could distinguish between participants in the AD or MCI groups and those in the FCD or healthy control groups with a sensitivity of 86.7%. Patients with MCI were identified with a sensitivity of 80%. Discussion Our fully automated system achieved levels of accuracy comparable to currently available, manually administered assessments. Greater accuracy should be achievable through further system training with a greater number of users, the inclusion of verbal fluency tasks and repeat assessments. The current data supports CognoSpeak's promise as a screening and monitoring tool for patients with MCI. Pending confirmation of these findings, it may allow clinicians to offer patients at low risk of dementia earlier reassurance and relieve pressures on specialist memory services.","2021-01","2025-02-26 20:36:59","2025-02-26 20:36:59","","12-15","","1","92","","","","","","","","","","English","","","","WOS:000608393800008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;20<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;16</p>","","","ALZHEIMERS-DISEASE; DEMENTIA; IMPAIRMENT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TZQ8NNQC","journalArticle","2021","Tsai, PF; Wang, CH; Zhou, Y; Ren, JX; Jones, A; Watts, SO; Chou, CH; Ku, WS","A classification algorithm to predict chronic pain using both regression and machine learning-A stepwise approach","APPLIED NURSING RESEARCH","","0897-1897","10.1016/j.apnr.2021.151504","","This secondary data analysis study aimed to (1) investigate the use of two sense-based parameters (movement and sleep hours) as predictors of chronic pain when controlling for patient demographics and depression, and (2) identify a classification model with accuracy in predicting chronic pain. Data collected by Oregon Health & Science University between March 2018 and December 2019 under the Collaborative Aging Research Using Technology Initiative were analyzed in two stages. Data were collected by sensor technologies and questionnaires from older adults living independently or with a partner in the community. In Stage 1, regression models were employed to determine unique sensor-based behavioral predictors of pain. These sensor-based parameters were used to create a classification model to predict the weekly recalled pain intensity and interference level using a deep neural network model, a machine learning approach, in Stage 2. Daily step count was a unique predictor for both pain intensity (75% Accuracy, F1 = 0.58) and pain interference (82% Accuracy, F1 = 0.59). The developed classification model performed well in this dataset with acceptable accuracy scores. This study demonstrated that machine learning technique can be used to identify the relationship between patients' pain and the risk factors.","2021-12","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","62","","","","","","","","","","English","","","","WOS:000721092900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","AVOIDANCE; DEMENTIA; Depression; DEPRESSION; DISABILITY; FEAR; Machine learning; MOVEMENT; NOCICEPTION LEVEL; OLDER-ADULTS; Pain; Physical activity; PREVALENCE; Sleep; UNITED-STATES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZBMRNLQ2","journalArticle","2023","Yang, TH; Chen, YF; Cheng, YF; Huang, JN; Wu, CS; Chu, YC","Optimizing age-related hearing risk predictions: an advanced machine learning integration with HHIE-S","BIODATA MINING","","1756-0381","10.1186/s13040-023-00351-z","","ObjectivesThe elderly are disproportionately affected by age-related hearing loss (ARHL). Despite being a well-known tool for ARHL evaluation, the Hearing Handicap Inventory for the Elderly Screening version (HHIE-S) has only traditionally been used for direct screening using self-reported outcomes. This work uses a novel integration of machine learning approaches to improve the predicted accuracy of the HHIE-S tool for ARHL in older adults.MethodsWe employed a dataset that was gathered between 2016 and 2018 and included 1,526 senior citizens from several Taipei City Hospital branches. 80% of the data were used for training (n = 1220) and 20% were used for testing (n = 356). XGBoost, Gradient Boosting, and LightGBM were among the machine learning models that were only used and assessed on the training set. In order to prevent data leakage and overfitting, the Light Gradient Boosting Machine (LGBM) model-which had the greatest AUC of 0.83 (95% CI 0.81-0.85)-was then only used on the holdout testing data.ResultsOn the testing set, the LGBM model showed a strong AUC of 0.82 (95% CI 0.79-0.86), far outperforming conventional techniques. Notably, several HHIE-S items and age were found to be significant characteristics. In contrast to traditional HHIE research, which concentrates on the psychological effects of hearing loss, this study combines cutting-edge machine learning techniques-specifically, the LGBM classifier-with the HHIE-S tool. The incorporation of SHAP values enhances the interpretability of the model's predictions and provides a more comprehensive comprehension of the significance of various aspects.ConclusionsOur methodology highlights the great potential that arises from combining machine learning with validated hearing evaluation instruments such as the HHIE-S. Healthcare practitioners can anticipate ARHL more accurately thanks to this integration, which makes it easier to intervene quickly and precisely.","2023-12-14","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","1","16","","","","","","","","","","English","","","","WOS:001126714300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;81</p>","","","Age-related; CLASSIFICATION; DEMENTIA; HEALTH; Hearing loss; HHIE-S; Innovation; LGBM; Machine learning; OLDER-ADULTS; PERFORMANCE; Predictive enhancement; PREVALENCE; SEX-DIFFERENCES; TESTS; VALIDATION; VERSION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QF3X848V","journalArticle","2023","Warule, P; Mishra, SP; Deb, S","Time-frequency analysis of speech signal using Chirplet transform for automatic diagnosis of Parkinson's disease","BIOMEDICAL ENGINEERING LETTERS","","2093-9868","10.1007/s13534-023-00283-x","","Parkinson's disease (PD) is the second most prevalent neurodegenerative disorder in the world after Alzheimer's disease. Early diagnosing PD is challenging as it evolved slowly, and its symptoms eventuate gradually. Recent studies have demonstrated that changes in speech may be utilized as an excellent biomarker for the early diagnosis of PD. In this study, we have proposed a Chirplet transform (CT) based novel approach for diagnosing PD using speech signals. We employed CT to get the time-frequency matrix (TFM) of each speech recording, and we extracted time-frequency based entropy (TFE) features from the TFM. The statistical analysis demonstrates that the TFE features reflect the changes in speech that occurs in the speech due to PD, hence can be used for classifying the PD and healthy control (HC) individuals. The effectiveness of the proposed framework is validated using the vowels and words from the PC-GITA database. The genetic algorithm is utilized to select the optimum features subset, while a support vector machine (SVM), decision tree (DT), K-Nearest Neighbor (KNN), and Naive Bayes (NB) classifiers are employed for classification. The TFE features outperform the breathiness and Mel frequency cepstral coefficients (MFCC) features. The SVM classifier is most effective compared to other machine-learning classifiers. The highest classification accuracy rates of 98% and 99% are achieved using the vowel /a/ and word /atleta/, respectively. The results reveal that the proposed CT-based entropy features effectively diagnose PD using the speech of a person.","2023-11","2025-02-26 20:36:59","2025-02-26 20:36:59","","613-623","","4","13","","","","","","","","","","English","","","","WOS:000983875000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","ACCURACY; ALGORITHMS; Chirplet transform; CLASSIFICATION; Genetic algorithm; Parkinson's disease (PD); PREDICTION; Speech Pathology; Support vector machine; SYSTEM; Time-frequency representation; VOICE DISORDERS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2USUMVXX","journalArticle","2024","Zolnoori, M; Zolnour, A; Vergez, S; Sridharan, S; Spens, I; Topaz, M; Noble, JM; Bakken, S; Hirschberg, J; Bowles, K; Onorato, N; Mcdonald, M","Beyond electronic health record data: leveraging natural language processing and machine learning to uncover cognitive insights from patient-nurse verbal communications","JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION","","1067-5027","10.1093/jamia/ocae300","","Background Mild cognitive impairment and early-stage dementia significantly impact healthcare utilization and costs, yet more than half of affected patients remain underdiagnosed. This study leverages audio-recorded patient-nurse verbal communication in home healthcare settings to develop an artificial intelligence-based screening tool for early detection of cognitive decline.Objective To develop a speech processing algorithm using routine patient-nurse verbal communication and evaluate its performance when combined with electronic health record (EHR) data in detecting early signs of cognitive decline.Method We analyzed 125 audio-recorded patient-nurse verbal communication for 47 patients from a major home healthcare agency in New York City. Out of 47 patients, 19 experienced symptoms associated with the onset of cognitive decline. A natural language processing algorithm was developed to extract domain-specific linguistic and interaction features from these recordings. The algorithm's performance was compared against EHR-based screening methods. Both standalone and combined data approaches were assessed using F1-score and area under the curve (AUC) metrics.Results The initial model using only patient-nurse verbal communication achieved an F1-score of 85 and an AUC of 86.47. The model based on EHR data achieved an F1-score of 75.56 and an AUC of 79. Combining patient-nurse verbal communication with EHR data yielded the highest performance, with an F1-score of 88.89 and an AUC of 90.23. Key linguistic indicators of cognitive decline included reduced linguistic diversity, grammatical challenges, repetition, and altered speech patterns. Incorporating audio data significantly enhanced the risk prediction models for hospitalization and emergency department visits.Discussion Routine verbal communication between patients and nurses contains critical linguistic and interactional indicators for identifying cognitive impairment. Integrating audio-recorded patient-nurse communication with EHR data provides a more comprehensive and accurate method for early detection of cognitive decline, potentially improving patient outcomes through timely interventions. This combined approach could revolutionize cognitive impairment screening in home healthcare settings.","2024-12-12","2025-02-26 20:36:59","2025-02-26 20:36:59","","328-340","","2","32","","","","","","","","","","English","","","","WOS:001375321400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","ALZHEIMERS-DISEASE; CARE; cognitive impairment; DEMENTIA; DISCOURSE; home healthcare; IMPAIRMENT; machine learning; natural language processing; patient-nurse verbal communication; screening algorithms; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VJ4CB4EE","journalArticle","2021","Yan, C; Gao, C; Zhang, ZQ; Chen, WC; Malin, BA; Ely, EW; Patel, MB; Chen, Y","Predicting brain function status changes in critically ill patients via Machine learning","JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION","","1067-5027","10.1093/jamia/ocab166","","Objective: In intensive care units (ICUs), a patient's brain function status can shift from a state of acute brain dysfunction (ABD) to one that is ABD-free and vice versa, which is challenging to forecast and, in turn, hampers the allocation of hospital resources. We aim to develop a machine learning model to predict next-day brain function status changes. Materials and Methods: Using multicenter prospective adult cohorts involving medical and surgical ICU patients from 2 civilian and 3 Veteran Affairs hospitals, we trained and externally validated a light gradient boosting machine to predict brain function status changes. We compared the performances of the boosting model against state-of-the-art models-an ABD predictive model and its variants. We applied Shapley additive explanations to identify influential factors to develop a compact model. Results: There were 1026 critically ill patients without evidence of prior major dementia, or structural brain diseases, from whom 12 295 daily transitions (ABD: 5847 days; ABD-free: 6448 days) were observed. The boosting model achieved an area under the receiver-operating characteristic curve (AUROC) of 0.824 (95% confidence interval [CI], 0.821-0.827), compared with the state-of-the-art models of 0.697 (95% CI, 0.693-0.701) with P< .001. Using 13 identified top influential factors, the compact model achieved 99.4% of the boosting model on AUROC. The boosting and the compact models demonstrated high generalizability in external validation by achieving an AUROC of 0.812 (95% CI, 0.812-0.813). Conclusion: The inputs of the compact model are based on several simple questions that clinicians can quickly answer in practice, which demonstrates the model has direct prospective deployment potential into clinical practice, aiding in critical hospital resource allocation.","2021-11","2025-02-26 20:36:59","2025-02-26 20:36:59","","2412-2422","","11","28","","","","","","","","","","English","","","","WOS:000711702400012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","acute brain dysfunction; brain function status change; CRITICAL ILLNESS; DELIRIUM; DYSFUNCTION; intensive care unit; INTENSIVE-CARE-UNIT; machine learning; MECHANICALLY VENTILATED PATIENTS; RELIABILITY; SEDATION; TERM COGNITIVE IMPAIRMENT; transition prediction; VALIDATION; VALIDITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SJZWEC7I","journalArticle","2023","Tracey, B; Volfson, D; Glass, J; Haulcy, R; Kostrzebski, M; Adams, J; Kangarloo, T; Brodtmann, A; Dorsey, ER; Vogel, A","Towards interpretable speech biomarkers: exploring MFCCs","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-023-49352-2","","While speech biomarkers of disease have attracted increased interest in recent years, a challenge is that features derived from signal processing or machine learning approaches may lack clinical interpretability. As an example, Mel frequency cepstral coefficients (MFCCs) have been identified in several studies as a useful marker of disease, but are regarded as uninterpretable. Here we explore correlations between MFCC coefficients and more interpretable speech biomarkers. In particular we quantify the MFCC2 endpoint, which can be interpreted as a weighted ratio of low- to high-frequency energy, a concept which has been previously linked to disease-induced voice changes. By exploring MFCC2 in several datasets, we show how its sensitivity to disease can be increased by adjusting computation parameters.","2023-12-21","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","1","13","","","","","","","","","","English","","","","WOS:001131701500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","APHASIA; CLASSIFICATION; DISEASE; FRONTOTEMPORAL DEMENTIA; MOTOR SPEECH; VOICE QUALITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YT48NK2N","journalArticle","2023","Huang, LH; Qu, HY; Zhou, DY","Older adults' refusal speech act in cognitive assessment: A multimodal pragmatic perspective","FRONTIERS IN PSYCHOLOGY","","1664-1078","10.3389/fpsyg.2023.1026638","","This paper explores how older adults with different cognitive abilities perform the refusal speech act in the cognitive assessment in the setting of memory clinics. The refusal speech act and its corresponding illocutionary force produced by nine Chinese older adults in the Montreal Cognitive Assessment-Basic was annotated and analyzed from a multimodal perspective. Overall, regardless of the older adults' cognitive ability, the most common discursive device to refuse is the demonstration of their inability to carry out or continue the cognitive task. Individuals with lower cognitive ability were found to perform the refusal illocutionary force (hereafter RIF) with higher frequency and degree. Additionally, under the pragmatic compensation mechanism, which is influenced by cognitive ability, multiple expression devices (including prosodic features and non-verbal acts) interact dynamically and synergistically to help older adults carry out the refusal behavior and to unfold older adults' intentional state and emotion as well. The findings indicate that both the degree and the frequency of performing the refusal speech act in the cognitive assessment are related to the cognitive ability of older adults.","2023-02-01","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","14","","","","","","","","","","English","","","","WOS:001040630600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","cognitive assessment; cognitive impairment; COMMUNICATION-SKILLS; DEMENTIA; examiner-patient interaction; LAUGHTER; pragmatic compensation; REACTANCE; refusal speech act; RESISTANCE; RISK","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5CQFMRQC","journalArticle","2024","Altham, C; Zhang, HZ; Pereira, E","Machine learning for the detection and diagnosis of cognitive impairment in Parkinson's Disease: A systematic review","PLOS ONE","","1932-6203","10.1371/journal.pone.0303644","","Background Parkinson's Disease is the second most common neurological disease in over 60s. Cognitive impairment is a major clinical symptom, with risk of severe dysfunction up to 20 years post-diagnosis. Processes for detection and diagnosis of cognitive impairments are not sufficient to predict decline at an early stage for significant impact. Ageing populations, neurologist shortages and subjective interpretations reduce the effectiveness of decisions and diagnoses. Researchers are now utilising machine learning for detection and diagnosis of cognitive impairment based on symptom presentation and clinical investigation. This work aims to provide an overview of published studies applying machine learning to detecting and diagnosing cognitive impairment, evaluate the feasibility of implemented methods, their impacts, and provide suitable recommendations for methods, modalities and outcomes.Methods To provide an overview of the machine learning techniques, data sources and modalities used for detection and diagnosis of cognitive impairment in Parkinson's Disease, we conducted a review of studies published on the PubMed, IEEE Xplore, Scopus and ScienceDirect databases. 70 studies were included in this review, with the most relevant information extracted from each. From each study, strategy, modalities, sources, methods and outcomes were extracted.Results Literatures demonstrate that machine learning techniques have potential to provide considerable insight into investigation of cognitive impairment in Parkinson's Disease. Our review demonstrates the versatility of machine learning in analysing a wide range of different modalities for the detection and diagnosis of cognitive impairment in Parkinson's Disease, including imaging, EEG, speech and more, yielding notable diagnostic accuracy.Conclusions Machine learning based interventions have the potential to glean meaningful insight from data, and may offer non-invasive means of enhancing cognitive impairment assessment, providing clear and formidable potential for implementation of machine learning into clinical practice.","2024-05-16","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","5","19","","","","","","","","","","English","","","","WOS:001227144600131","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;174</p>","","","CLASSIFICATION; DEMENTIA; DOPAMINE; IMPACT; INTELLIGENCE; MEMORY; PREDICTION; QUALITY-OF-LIFE; REGRESSION; TOOL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QCA4QB9Z","journalArticle","2024","Pacheco-Lorenzo, MR; Christensen, H; Anido-Rifón, LE; Fernández-Iglesias, MJ; Valladares-Rodríguez, SM","Analysis of Voice Biomarkers for the Detection of Cognitive Impairment","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3442431","","The objective of this work is to determine whether speech obtained from interactions with a smart speaker can be used to predict the level of cognitive impairment (CI). We use a voice assistant to administer a cognitive test in Spanish, and we record the conversations in order to extract features that could potentially be used as voice biomarkers. A total of 21 participants (14 patients and 7 healthy controls) between the ages of 68 and 86 are included in the study (15 were women). Using just speech we are able to perform a regression with machine learning models, in order to predict the Global Deterioration Scale (GDS) of cognitive functions. Then, we measure the performance of the estimations with standard metrics - an R-2 of 0.74 was obtained in the best case using Support Vector Machine (SVM) algorithms. Despite needing a bigger sample of participants in future studies, this is a positive and promising result for such a non-intrusive procedure, which could potentially be used as a screening tool for automatic cognitive impairment assessment.","2024","2025-02-26 20:36:59","2025-02-26 20:36:59","","122840-122851","","","12","","","","","","","","","","English","","","","WOS:001310768600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","Accuracy; Alzheimer's disease; ALZHEIMERS-DISEASE; Biomarkers; cognitive impairment; dementia; Dementia; ECOLOGICAL VALIDITY; Feature extraction; Oral communication; PERFORMANCE; PROSPECTIVE MEMORY; regression; Regression analysis; SPEECH; Speech recognition; Support vector machines; Task analysis; TOOL; VIRTUAL-REALITY; voice","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UFGJ9ZW8","journalArticle","2023","Balaji, C; Suresh, DS","Multi-class Recognition of Alzheimer's and Parkinson's diseases using Bag of Deep reduced Features (BoDrF) with Improved Chaotic Multi Verse Harris Hawks Optimization (CMVHHO) and Random Forest (RF) based classification for early diagnosis","COMPUTER METHODS IN BIOMECHANICS AND BIOMEDICAL ENGINEERING-IMAGING AND VISUALIZATION","","2168-1163","10.1080/21681163.2022.2111721","","This manuscript proposes a multi-class recognition system with improved classification accuracy using machine-learning techniques by considering electroencephalogram (EEG) and speech signal analysis to classify and detect patients affected by Alzheimer's disease (AD) and Parkinson's disease (PD) in its initial stages. Acquired raw EEG and speech signal are pre-processed utilising wavelet filters to eliminate noises, then the features impedivity, phase angle, higher frequency slope of phase angle, standard deviation, minimal pitch, maximal pitch, count of voice breaks are extracted from EEG and speech signal using bag of deep reduced features. Optimal features mean absolute values, enhanced wavelength, wavelength, zeros crossing are selected using an improved chaotic multi-verse Harris Hawks optimisation (CMVHHO) algorithm. Finally, Random Forest (RF) classifier is employed to classify patients suffered by AD with PD. Experimental results show 95.17%, 96.31% and 97.48% higher accuracy for AD compared with existing methods, like MCR-AD-PD-SPWVD-CNN, MCR-AD-PD-ICA-DSCHN and MCR-AD-DWT-KNN-RLDA, respectively.","2023-05-04","2025-02-26 20:36:59","2025-02-26 20:36:59","","774-785","","3","11","","","","","","","","","","English","","","","WOS:000844097800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","Alzheimer's disease; AUTISM; AUTOMATED DIAGNOSIS; Bag of Deep reduced Features; BIOMARKERS; BRAIN; Chaotic Multi-Verse Harris Hawks Optimisation; Electroencephalography; MACHINE; Parkinson's disease; Random forest classifier; wavelet filters","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3XYX4Q2E","journalArticle","2024","Wang, YB; Wang, HY; Li, ZX; Zhang, HR; Yang, LW; Li, JR; Tang, ZX; Hou, SJ; Wang, Q","Sound as a bell: a deep learning approach for health status classification through speech acoustic biomarkers","CHINESE MEDICINE","","1749-8546","10.1186/s13020-024-00973-3","","BackgroundHuman health is a complex, dynamic concept encompassing a spectrum of states influenced by genetic, environmental, physiological, and psychological factors. Traditional Chinese Medicine categorizes health into nine body constitutional types, each reflecting unique balances or imbalances in vital energies, influencing physical, mental, and emotional states. Advances in machine learning models offer promising avenues for diagnosing conditions like Alzheimer's, dementia, and respiratory diseases by analyzing speech patterns, enabling complementary non-invasive disease diagnosis. The study aims to use speech audio to identify subhealth populations characterized by unbalanced constitution types.MethodsParticipants, aged 18-45, were selected from the Acoustic Study of Health. Audio recordings were collected using ATR2500X-USB microphones and Praat software. Exclusion criteria included recent illness, dental issues, and specific medical histories. The audio data were preprocessed to Mel-frequency cepstral coefficients (MFCCs) for model training. Three deep learning models-1-Dimensional Convolution Network (Conv1D), 2-Dimensional Convolution Network (Conv2D), and Long Short-Term Memory (LSTM)-were implemented using Python to classify health status. Saliency maps were generated to provide model explainability.ResultsThe study used 1,378 recordings from balanced (healthy) and 1,413 from unbalanced (subhealth) types. The Conv1D model achieved a training accuracy of 91.91% and validation accuracy of 84.19%. The Conv2D model had 96.19% training accuracy and 84.93% validation accuracy. The LSTM model showed 92.79% training accuracy and 87.13% validation accuracy, with early signs of overfitting. AUC scores were 0.92 and 0.94 (Conv1D), 0.99 (Conv2D), and 0.97 (LSTM). All models demonstrated robust performance, with Conv2D excelling in discrimination accuracy.ConclusionsThe deep learning classification of human speech audio for health status using body constitution types showed promising results with Conv1D, Conv2D, and LSTM models. Analysis of ROC curves, training accuracy, and validation accuracy showed all models robustly distinguished between balanced and unbalanced constitution types. Conv2D excelled with good accuracy, while Conv1D and LSTM also performed well, affirming their reliability. The study integrates constitution theory and deep learning technologies to classify subhealth populations using noninvasive approach, thereby promoting personalized medicine and early intervention strategies.","2024-07-24","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","1","19","","","","","","","","","","English","","","","WOS:001276260100003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Acoustic parameters; Body constitution; CHINESE MEDICINE; CONSTITUTION; Deep learning; Speech analysis; Subhealth; Traditional Chinese Medicine","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HCJ8EI45","journalArticle","2021","Gagliardi, G; Tamburini, F","LINGUISTIC BIOMARKERS FOR THE DETECTION OF MILD COGNITIVE IMPAIRMENT","LINGUE E LINGUAGGIO","","1720-9331","10.1418/101111","","A timely diagnosis of the prodromal stages of dementia remains a big challenge for healthcare systems: many assessment tools have been proposed over recent years, but the commonest screening instruments are largely unreliable for detecting subtle changes in cognition. The scientific literature contains a rising number of reports about language disturbances at the earliest stages of dementia, a clinical syndrome known as ""Mild Cognitive Impairment"" (MCI). Here we take advantage of these findings to develop a novel NLP method capable of identifying cognitive frailty at a very early stage by processing Italian spoken productions. This study constitutes a first step in the creation of an automatic tool for non-intrusive, low-cost dementia screening exploiting linguistic biomarkers. Our findings show that acoustic features (i.e., fluency indexes and spectral properties of the voice) are the most reliable parameters for MCI early identification. Moreover, lexical and syntactic features, grabbing the erosion of verbal abilities caused by the pathology, emerge as statistically significant and can support speech traits in the classification process.","2021-01","2025-02-26 20:36:59","2025-02-26 20:36:59","","3-31","","1","20","","","","","","","","","","English","","","","WOS:000682528400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;94</p>","","","COMMUNICATION; DEMENTIA; Dementia screening; linguistic biomarkers; Mild Cognitive Impairment; NARRATIVE DISCOURSE; Natural Language Processing; OBJECTIVE TECHNIQUE; PRECLINICAL ALZHEIMERS-DISEASE; PRESERVATION; PROGRESSION; SCREENING TOOL; SELECTION; SPONTANEOUS SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3D5X33XG","journalArticle","2023","Georgiou, EZ; Skondra, M; Charalampopoulou, M; Felemegkas, P; Pachi, A; Stafylidou, G; Papazachariou, D; Perneczky, R; Thomopoulos, V; Politis, A; Leroi, I; Economou, P; Alexopoulos, P","Validation of the test for finding word retrieval deficits (WoFi) in detecting Alzheimer's disease in a naturalistic clinical setting","EUROPEAN JOURNAL OF AGEING","","1613-9372","10.1007/s10433-023-00772-z","","BackgroundDetecting impaired naming capacity contributes to the detection of mild (MildND) and major (MajorND) neurocognitive disorder due to Alzheimer's disease (AD). The Test for Finding Word retrieval deficits (WoFi) is a new, 50-item, auditory stimuli-based instrument.ObjectiveThe study aimed to adapt WoFi to the Greek language, to develop a short version of WoFi (WoFi-brief), to compare the item frequency and the utility of both instruments with the naming subtest of the widely used Addenbrooke's cognitive examination III (ACEIIINaming) in detecting MildND and MajorND due to AD.MethodsThis cross-sectional, validation study included 99 individuals without neurocognitive disorder, as well as 114 and 49 patients with MildND and MajorND due to AD, respectively. The analyses included categorical principal components analysis using Cramer's V, assessment of the frequency of test items based on corpora of television subtitles, comparison analyses, Kernel Fisher discriminant analysis models, proportional odds logistic regression (POLR) models and stratified repeated random subsampling used to recursive partitioning to training and validation set (70/30 ratio).ResultsWoFi and WoFi-brief, which consists of 16 items, have comparable item frequency and utility and outperform ACEIIINaming. According to the results of the discriminant analysis, the misclassification error was 30.9%, 33.6% and 42.4% for WoFi, WoFi-brief and ACEIIINaming, respectively. In the validation regression model including WoFi the mean misclassification error was 33%, while in those including WoFi-brief and ACEIIINaming it was 31% and 34%, respectively.ConclusionsWoFi and WoFi-brief are more effective in detecting MildND and MajorND due to AD than ACEIIINaming.","2023-12","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","1","20","","","","","","","","","","English","","","","WOS:001020932700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","ASSOCIATION WORKGROUPS; Auditory stimuli-based naming test; DEMENTIA; DIAGNOSTIC GUIDELINES; Dysnomia; FREQUENCY; Mild and major neurocognitive disorder; MILD COGNITIVE IMPAIRMENT; NATIONAL INSTITUTE; RECOMMENDATIONS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SDZLMAAA","journalArticle","2024","Haraldsen, IH; Hatlestad-Hall, C; Marra, C; Renvall, H; Maestu, F; Acosta-Hernandez, J; Alfonsin, S; Andersson, V; Anand, A; Ayllon, V; Babic, A; Belhadi, A; Birck, C; Bruna, R; Caraglia, N; Carrarini, C; Christensen, E; Cicchetti, A; Daugbjerg, S; Di Bidino, R; Diaz-Ponce, A; Drews, A; Giuffre, GM; Georges, J; Gil-Gregorio, P; Gove, D; Govers, TM; Hallock, H; Hietanen, M; Holmen, L; Hotta, J; Kaski, S; Khadka, R; Kinnunen, AS; Koivisto, AM; Kulashekhar, S; Larsen, D; Liljestroem, M; Lind, PG; Dolado, AM; Marshall, S; Merz, S; Miraglia, F; Montonen, J; Maentynen, V; Oksengard, AR; Olazaran, J; Paajanen, T; Pena, JM; Pena, L; Peniche, DL; Perez, AS; Radwan, M; Ramirez-Torano, F; Rodriguez-Pedrero, A; Saarinen, T; Salas-Carrillo, M; Salmelin, R; Sousa, S; Suyuthi, A; Toft, M; Toharia, P; Tveitstol, T; Tveter, M; Upreti, R; Vermeulen, RJ; Vecchio, F; Yazidi, A; Rossini, PM","Intelligent digital tools for screening of brain connectivity and dementia risk estimation in people affected by mild cognitive impairment: the AI-Mind clinical study protocol","FRONTIERS IN NEUROROBOTICS","","1662-5218","10.3389/fnbot.2023.1289406","","More than 10 million Europeans show signs of mild cognitive impairment (MCI), a transitional stage between normal brain aging and dementia stage memory disorder. The path MCI takes can be divergent; while some maintain stability or even revert to cognitive norms, alarmingly, up to half of the cases progress to dementia within 5 years. Current diagnostic practice lacks the necessary screening tools to identify those at risk of progression. The European patient experience often involves a long journey from the initial signs of MCI to the eventual diagnosis of dementia. The trajectory is far from ideal. Here, we introduce the AI-Mind project, a pioneering initiative with an innovative approach to early risk assessment through the implementation of advanced artificial intelligence (AI) on multimodal data. The cutting-edge AI-based tools developed in the project aim not only to accelerate the diagnostic process but also to deliver highly accurate predictions regarding an individual's risk of developing dementia when prevention and intervention may still be possible. AI-Mind is a European Research and Innovation Action (RIA H2020-SC1-BHC-06-2020, No. 964220) financed between 2021 and 2026. First, the AI-Mind Connector identifies dysfunctional brain networks based on high-density magneto- and electroencephalography (M/EEG) recordings. Second, the AI-Mind Predictor predicts dementia risk using data from the Connector, enriched with computerized cognitive tests, genetic and protein biomarkers, as well as sociodemographic and clinical variables. AI-Mind is integrated within a network of major European initiatives, including The Virtual Brain, The Virtual Epileptic Patient, and EBRAINS AISBL service for sensitive data, HealthDataCloud, where big patient data are generated for advancing digital and virtual twin technology development. AI-Mind's innovation lies not only in its early prediction of dementia risk, but it also enables a virtual laboratory scenario for hypothesis-driven personalized intervention research. This article introduces the background of the AI-Mind project and its clinical study protocol, setting the stage for future scientific contributions.","2024-01-05","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","17","","","","","","","","","","English","","","","WOS:001144536600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","AI-Mind; ALZHEIMERS-DISEASE; artificial intelligence; CANTAB; clinical study protocol; CRITERIA; dementia; DIAGNOSIS; EEG; electroencephalography (EEG); machine learning; magnetoencephalography (MEG); mild cognitive impairment; MODELS; PROGRESSION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QAN7Z6KG","journalArticle","2024","Arrieta, E; Baz, P; García-Ribas, G","FORTCARE-MCI study protocol: evaluation of Fortasyn Connect in the management of mild cognitive impairment in primary care","FRONTIERS IN NEUROLOGY","","1664-2295","10.3389/fneur.2024.1434210","","Background: Neuropsychiatric symptoms are prevalent in patients with mild cognitive impairment (MCI) and are predictive of the conversion to dementia. Fortasyn Connect, a medical food, has shown efficacy in managing cognitive and behavioral symptoms associated with MCI. Early diagnosis and intervention in primary care are essential for managing MCI. However, real-world prospective studies assessing Fortasyn Connect in MCI are still limited. Methods: This observational, multicenter, prospective study will enroll 150 patients recently diagnosed with MCI by primary care physicians across several regions in Spain. Participants will be followed-up over a 12-month period, with assessments at baseline, 6 months, and 12 months, as per clinical practice. The study aims to evaluate the impact of Fortasyn Connect on neuropsychiatric symptoms, cognition, and health-related quality of life (HRQoL) using validated neuropsychological tests and machine learning (ML) techniques. The primary outcome measure will be changes in neuropsychiatric symptoms using the Neuropsychiatric Inventory Questionnaire (NPI-Q) at 6 months. Secondary outcome measures include further changes in the NPI-Q at 12 months, and changes in cognition (Fototest, and clock-drawing test) and HRQoL (EQ-5D-5L) at 6 and 12 months. Exploratory outcomes will assess speech using an artificial intelligence (AI)-enhanced ML tool, with a correlation analysis of these findings with traditional neuropsychological test results. Conclusion: This study will provide evidence of the effectiveness of Fortasyn Connect in a real-world setting, exploring its potential to stabilize or improve neuropsychiatric symptoms, cognition, and HRQoL in MCI patients. Results will also contribute to the understanding of AI and ML in identifying early biomarkers of cognitive decline, supporting the timely management of MCI.","2024-10-03","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","15","","","","","","","","","","English","","","","WOS:001342051800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;92</p>","","","Alzheimer's disease; CONVERSION; DEMENTIA; Fortasyn connect; METAANALYSIS; mild cognitive impairment; NEUROPSYCHIATRIC SYMPTOMS; PREVALENCE; primary care; PRODROMAL ALZHEIMERS-DISEASE; RISK; SYNAPSE LOSS; treatment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CVFEF766","journalArticle","2024","Shir, D; Corriveau-Lecavalier, N; Noguera, CB; Barnard, L; Pham, NTT; Botha, H; Duffy, JR; Clark, HM; Utianski, RL; Knopman, DS; Petersen, RC; Boeve, BF; Murray, ME; Nguyen, AT; Reichard, RR; Dickson, DW; Day, GS; Kremers, WK; Graff-Radford, NR; Jones, DT; Machulda, MM; Fields, JA; Whitwell, JL; Josephs, KA; Graff-Radford, J","Clinicoradiological and neuropathological evaluation of primary progressive aphasia","JOURNAL OF NEUROLOGY NEUROSURGERY AND PSYCHIATRY","","0022-3050","10.1136/jnnp-2023-332862","","Background Primary progressive aphasia (PPA) defines a group of neurodegenerative disorders characterised by language decline. Three PPA variants correlate with distinct underlying pathologies: semantic variant PPA (svPPA) with transactive response DNA-binding protein of 43 kD (TDP-43) proteinopathy, agrammatic variant PPA (agPPA) with tau deposition and logopenic variant PPA (lvPPA) with Alzheimer's disease (AD). Our objectives were to differentiate PPA variants using clinical and neuroimaging features, assess progression and evaluate structural MRI and a novel 18-F fluorodeoxyglucose positron emission tomography (FDG-PET) image decomposition machine learning algorithm for neuropathology prediction.Methods We analysed 82 autopsied patients diagnosed with PPA from 1998 to 2022. Clinical histories, language characteristics, neuropsychological results and brain imaging were reviewed. A machine learning framework using a k-nearest neighbours classifier assessed FDG-PET scans from 45 patients compared with a large reference database.Results PPA variant distribution: 35 lvPPA (80% AD), 28 agPPA (89% tauopathy) and 18 svPPA (72% frontotemporal lobar degeneration-TAR DNA-binding protein (FTLD-TDP)). Apraxia of speech was associated with 4R-tauopathy in agPPA, while pure agrammatic PPA without apraxia was linked to 3R-tauopathy. Longitudinal data revealed language dysfunction remained the predominant deficit for patients with lvPPA, agPPA evolved to corticobasal or progressive supranuclear palsy syndrome (64%) and svPPA progressed to behavioural variant frontotemporal dementia (44%). agPPA-4R-tauopathy exhibited limited pre-supplementary motor area atrophy, lvPPA-AD displayed temporal atrophy extending to the superior temporal sulcus and svPPA-FTLD-TDP had severe temporal pole atrophy. The FDG-PET-based machine learning algorithm accurately predicted clinical diagnoses and underlying pathologies.Conclusions Distinguishing 3R-taupathy and 4R-tauopathy in agPPA may rely on apraxia of speech presence. Additional linguistic and clinical features can aid neuropathology prediction. Our data-driven brain metabolism decomposition approach effectively predicts underlying neuropathology.","2024-09","2025-02-26 20:36:59","2025-02-26 20:36:59","","812-821","","9","95","","","","","","","","","","English","","","","WOS:001188999200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","APHASIA; APRAXIA; CRITERIA; DEMENTIA; DIAGNOSIS; DISEASE; DISORDER; FEATURES; LANGUAGE; MRI; TAU; VARIANT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VADJ4R9B","journalArticle","2024","Zhao, Q; Xu, HR; Li, JQ; Rajput, FA; Qiao, LY","The Application of Artificial Intelligence in Alzheimer's Research","TSINGHUA SCIENCE AND TECHNOLOGY","","1007-0214","10.26599/TST.2023.9010037","","Alzheimer's disease (AD) is an irreversible and neurodegenerative disease that slowly impairs memory and neurocognitive function, but the etiology of AD is still unclear. With the explosive growth of electronic health data, the application of artificial intelligence (Al) in the healthcare setting provides excellent potential for exploring etiology and personalized treatment approaches, and improving the disease's diagnostic and prognostic outcome. This paper first briefly introduces Al technologies and applications in medicine, and then presents a comprehensive review of Al in AD. In simple, it includes etiology discovery based on genetic data, computer-aided diagnosis (CAD), computer-aided prognosis (CAP) of AD using multi-modality data (genetic, neuroimaging and linguistic data), and pharmacological or non-pharmacological approaches for treating AD. Later, some popular publicly available AD datasets are introduced, which are important for advancing Al technologies in AD analysis. Finally, core research challenges and future research directions are discussed.","2024-02","2025-02-26 20:36:59","2025-02-26 20:36:59","","13-33","","1","29","","","","","","","","","","English","","","","WOS:001074356700002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;148</p>","","","Alzheimer's disease; artificial intelligence; ASSOCIATION; CLASSIFICATION; COGNITIVE IMPAIRMENT; computer-aided diagnosis; computer-aided prognosis; DEMENTIA; DISEASE; EARLY-DIAGNOSIS; etiology discovery; GAME; Genetics; Linguistics; Machine learning; Medical services; NATIONAL INSTITUTE; Neuroimaging; Neurosurgery; PREDICTION; Solid modeling; SPEECH; treatment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7ZDM68GW","journalArticle","2025","Rahimi, M; Al Masry, Z; Templeton, JM; Schneider, S; Poellabauer, C","A Comprehensive Multifunctional Approach for Measuring Parkinson's Disease Severity","APPLIED CLINICAL INFORMATICS","","1869-0327","10.1055/a-2420-0413","","Objectives This research study aims to advance the staging of Parkinson's disease (PD) by incorporating machine learning to assess and include a broader multifunctional spectrum of neurocognitive symptoms in the staging schemes beyond motor-centric assessments. Specifically, we provide a novel framework to modernize and personalize PD staging more objectively by proposing a hybrid feature scoring approach. Methods We recruited 37 individuals diagnosed with PD, each of whom completed a series of tablet-based neurocognitive tests assessing motor, memory, speech, executive functions, and tasks ranging in complexity from single to multifunctional. Then, the collected data were used to develop a hybrid feature scoring system to calculate a weighted vector for each function. We evaluated the current PD staging schemes and developed a new approach based on the features selected and extracted using random forest and principal component analysis. Results Our findings indicate a substantial bias in current PD staging systems toward fine motor skills, that is, other neurological functions (memory, speech, executive function, etc.) do not map into current PD stages as well as fine motor skills do. The results demonstrate that a more accurate and personalized assessment of PD severity could be achieved by including a more exhaustive range of neurocognitive functions in the staging systems either by involving multiple functions in a unified staging score or by designing a function-specific staging system. Conclusion The proposed hybrid feature score approach provides a comprehensive understanding of PD by highlighting the need for a staging system that covers various neurocognitive functions. This approach could potentially lead to more effective, objective, and personalized treatment strategies. Further, this proposed methodology could be adapted to other neurodegenerative conditions such as Alzheimer's disease or amyotrophic lateral sclerosis.","2025-01","2025-02-26 20:36:59","2025-02-26 20:36:59","","11-23","","01","16","","","","","","","","","","English","","","","WOS:001386740000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","digital health; disease staging; HEALTH-CARE; machine learning; neurocognitive disorder; Parkinson's disease","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VNJPFPBL","journalArticle","2022","Pavlovic, T; Azevedo, F; De, K; Riaño-Moreno, JC; Maglic, M; Gkinopoulos, T; Donnelly-Kehoe, PA; Payán-Gómez, C; Huang, GX; Kantorowicz, J; Birtel, MD; Schönegger, P; Capraro, V; Santamaría-García, H; Yucel, M; Ibanez, A; Rathje, S; Wetter, E; Stanojevic, D; van Prooijen, JW; Hesse, E; Elbaek, CT; Franc, R; Pavlovic, Z; Mitkidis, P; Cichocka, A; Gelfand, M; Alfano, M; Ross, RM; Sjåstad, H; Nezlek, JB; Cislak, A; Lockwood, P; Abts, K; Agadullina, E; Amodio, DM; Apps, MAJ; Aruta, JJB; Besharati, S; Bor, A; Choma, B; Cunningham, W; Ejaz, W; Farmer, H; Findor, A; Gjoneska, B; Gualda, E; Huynh, TLD; Imran, MA; Israelashvili, J; Kantorowicz-Reznichenko, E; Krouwel, A; Kutiyski, Y; Laakasuo, M; Lamm, C; Levy, J; Leygue, C; Lin, MJ; Mansoor, MS; Marie, A; Mayiwar, L; Mazepus, H; McHugh, C; Olsson, A; Otterbring, T; Packer, D; Palomäki, J; Perry, A; Petersen, MB; Puthillam, A; Rothmund, T; Schmid, PC; Stadelmann, D; Stoica, A; Stoyanov, D; Stoyanova, K; Tewari, S; Todosijevic, B; Torgler, B; Tsakiris, M; Tung, HH; Umbres, RG; Vanags, E; Vlasceanu, M; Vonasch, AJ; Zhang, YC; Abad, M; Adler, E; Mdarhri, HA; Antazo, B; Ay, FC; Ba, ME; Barbosa, S; Bastian, B; Berg, A; Bialek, M; Bilancini, E; Bogatyreva, N; Boncinelli, L; Booth, JE; Borau, S; Buchel, O; de Carvalho, CF; Celadin, T; Cerami, C; Chalise, HN; Cheng, XJ; Cian, LC; Cockcroft, K; Conway, J; Córdoba-Delgado, MA; Crespi, C; Crouzevialle, M; Cutler, J; Cypryanska, M; Dabrowska, J; Davis, VH; Minda, JP; Dayley, PN; Delouvée, S; Denkovski, O; Dezecache, G; Dhaliwal, NA; Diato, A; Di Paolo, R; Dulleck, U; Ekmanis, J; Etienne, TW; Farhana, HH; Farkhari, F; Fidanovski, K; Flew, T; Fraser, S; Frempong, RB; Fugelsang, J; Gale, J; García-Navarro, EB; Garladinne, P; Gray, K; Griffin, SM; Gronfeldt, B; Gruber, J; Halperin, E; Herzon, V; Hruska, M; Hudecek, MFC; Isler, O; Jangard, S; Jorgensen, F; Keudel, O; Koppel, L; Koverola, M; Kunnari, A; Leota, J; Lermer, E; Li, CY; Longoni, C; McCashin, D; Miklousic, I; Molina-Paredes, J; Monroy-Fonseca, C; Morales-Marente, E; Moreau, D; Muda, R; Myer, A; Nash, K; Nitschke, JP; Nurse, MS; de Mello, VO; Palacios-Galvez, MS; Palomäki, J; Pan, YF; Papp, Z; Pärnamets, P; Paruzel-Czachura, M; Perander, S; Pitman, M; Raza, A; Rêgo, GG; Robertson, C; Rodríguez-Pascual, I; Saikkonen, T; Salvador-Ginez, O; Sampaio, WM; Santi, GC; Schultner, D; Schutte, E; Scott, A; Skali, A; Stefaniak, A; Sternisko, A; Strickland, B; Thomas, JP; Tinghög, G; Traast, IJ; Tucciarelli, R; Tyrala, M; Ungson, ND; Uysal, MS; Van Rooy, D; Västfjäll, D; Vieira, JB; von Sikorski, C; Walker, AC; Watermeyer, J; Willardt, R; Wohl, MJA; Wójcik, AD; Wu, KD; Yamada, Y; Yilmaz, O; Yogeeswaran, K; Ziemer, CT; Zwaan, RA; Boggio, PS; Whillans, A; Van Lange, PAM; Prasad, R; Onderco, M; O'Madagain, C; Nesh-Nash, T; Laguna, OM; Kubin, E; Gümren, M; Fenwick, A; Ertan, AS; Bernstein, MJ; Amara, H; Van Bavel, JJ","Predicting attitudinal and behavioral responses to COVID-19 pandemic using machine learning","PNAS NEXUS","","2752-6542","10.1093/pnasnexus/pgac093","","At the beginning of 2020, COVID-19 became a global problem. Despite all the efforts to emphasize the relevance of preventive measures, not everyone adhered to them. Thus, learning more about the characteristics determining attitudinal and behavioral responses to the pandemic is crucial to improving future interventions. In this study, we applied machine learning on the multinational data collected by the International Collaboration on the Social and Moral Psychology of COVID-19 (N = 51,404) to test the predictive efficacy of constructs from social, moral, cognitive, and personality psychology, as well as socio-demographic factors, in the attitudinal and behavioral responses to the pandemic. The results point to several valuable insights. Internalized moral identity provided the most consistent predictive contribution-individuals perceiving moral traits as central to their self-concept reported higher adherence to preventive measures. Similar results were found for morality as cooperation, symbolized moral identity, self-control, open-mindedness, and collective narcissism, while the inverse relationship was evident for the endorsement of conspiracy theories. However, we also found a non-neglible variability in the explained variance and predictive contributions with respect to macro-level factors such as the pandemic stage or cultural region. Overall, the results underscore the importance of morality-related and contextual factors in understanding adherence to public health recommendations during the pandemic.","2022-07","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","3","1","","","","","","","","","","English","","","","WOS:001063386400036","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;20<br/>Total Times Cited:&nbsp;&nbsp;22<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","COVID-19; ESTEEM; hygiene; MORALITY; OPEN-MINDEDNESS; policy support; public health measures; SELF-CONTROL; SINGLE-ITEM MEASURE; social distancing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZL4I2225","journalArticle","2023","Dorr, F; Schäfer, S; Öhman, F; Linz, N; Bodin, TH; Skoog, J; Zettergren, A; Kern, S; Skoog, I; Tröger, J","Dissociating memory and executive function impairment through temporal features in a word list verbal learning task","NEUROPSYCHOLOGIA","","0028-3932","10.1016/j.neuropsychologia.2023.108679","","The Rey Auditory Verbal Learning Test (RAVLT) is an established verbal learning test commonly used to quantify memory impairments due to Alzheimer's Disease (AD) both at a clinical dementia stage or prodromal stage of mild cognitive impairment (MCI). Focal memory impairment-as quantified e.g. by the RAVLT-at an MCI stage is referred to as amnestic MCI (aMCI) and is often regarded as the cognitive phenotype of prodromal AD. However, recent findings suggest that not only learning and memory but also other cognitive domains, especially executive functions (EF) and processing speed (PS), influence verbal learning performance. This research investigates whether additional temporal features extracted from audio recordings from a participant's RAVLT response can better dissociate memory and EF in such tasks and eventually help to better describe MCI subtypes. 675 age-matched participants from the H70 Swedish birth cohort were included in this analysis; 68 participants were classified as MCI (33 aMCI and 35 due to executive impairment). RAVLT performances were recorded and temporal features extracted. Novel temporal features were correlated with established neuropsychological tests measuring EF and PS. Lastly, the downstream diagnostic potential of temporal features was estimated using group differences and a machine learning (ML) classification scenario. Temporal features correlated moderately with measures of EF and PS. Performance of an ML classifier could be improved by adding temporal features to traditional counts. We conclude that RAVLT temporal features are in general related to EF and that they might be capable of dissociating memory and EF in a word list learning task.","2023-10-10","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","189","","","","","","","","","","English","","","","WOS:001078573900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","AGE; ALZHEIMERS-DISEASE; aMCI; Amnestic mild cognitive impairment; CONVERSION; CRITERIA; exMCI; MILD COGNITIVE IMPAIRMENT; NORMATIVE DATA; PROCESSING SPEED; RAVLT; REACTION-TIME; Speech analysis; Temporal analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N46W5HCL","journalArticle","2024","Ding, HT; Lister, A; Karjadi, C; Au, RD; Lin, HH; Bischoff, B; Hwang, PH","Detection of Mild Cognitive Impairment From Non-Semantic, Acoustic Voice Features: The Framingham Heart Study","JMIR AGING","","2561-7605","10.2196/55126","","Background: With the aging global population and the rising burden of Alzheimer disease and related dementias (ADRDs),there is a growing focus on identifying mild cognitive impairment (MCI) to enable timely interventions that could potentiallyslow down the onset of clinical dementia. The production of speech by an individual is a cognitively complex task that engagesvarious cognitive domains. The ease of audio data collection highlights the potential cost-effectiveness and noninvasive natureof using human speech as a tool for cognitive assessment.Objective: This study aimed to construct a machine learning pipeline that incorporates speaker diarization, feature extraction,feature selection, and classification to identify a set of acoustic features derived from voice recordings that exhibit strong MCIdetection capability.Methods: The study included 100 MCI cases and 100 cognitively normal controls matched for age, sex, and education fromthe Framingham Heart Study. Participants' spoken responses on neuropsychological tests were recorded, and the recorded audiowas processed to identify segments of each participant's voice from recordings that included voices of both testers and participants.A comprehensive set of 6385 acoustic features was then extracted from these voice segments using OpenSMILE and Praatsoftware. Subsequently, a random forest model was constructed to classify cognitive status using the features that exhibitedsignificant differences between the MCI and cognitively normal groups. The MCI detection performance of various audio lengthswas further examined.Results: An optimal subset of 29 features was identified that resulted in an area under the receiver operating characteristic curveof 0.87, with a 95% CI of 0.81-0.94. The most important acoustic feature for MCI classification was the number of filled pauses(importance score=0.09, P=3.10E-08). There was no substantial difference in the performance of the model trained on the acousticfeatures derived from different lengths of voice recordings.Conclusions: This study showcases the potential of monitoring changes to nonsemantic and acoustic features of speech as away of early ADRD detection and motivates future opportunities for using human speech as a measure of brain health","2024","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","7","","","","","","","","","","English","","","","WOS:001302127300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Alzheimer disease and related dementias; ALZHEIMERS ASSOCIATION WORKGROUPS; DIAGNOSTIC GUIDELINES; digital voice; DISEASE; early detection; machine learning; mild cognitive impairment; mobile phone; NATIONAL INSTITUTE; RECOMMENDATIONS; smartphone; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2EUV8FHI","journalArticle","2022","Lamba, R; Gulati, T; Jain, A","An Intelligent System for Parkinson's Diagnosis Using Hybrid Feature Selection Approach","INTERNATIONAL JOURNAL OF SOFTWARE INNOVATION","","2166-7160","10.4018/IJSI.292027","","Parkinson's is the second most common neurodegenerative disorder after Alzheimer's disease. During the nascent stage, the symptoms of Parkinson's disease are mild and sometimes go unnoticed, but as the disease progresses, the symptoms become severe. Recent research has shown that changes in speech or distortion in voice can be effectively used for early Parkinson's detection. In this work, the authors propose a system of Parkinson's disease detection using speech signals. As the feature selection plays an important role during classification, the authors have proposed a hybrid MIRFE feature selection approach. The result of the proposed feature selection approach is compared with the five standard feature selection methods by XGBoost classifier. The proposed MIRFE approach selects 40 features out of 754 features with a feature reduction ratio of 94.69%. An accuracy of 93.88% and area under curve (AUC) of 0.978 is obtained by the proposed system.","2022-01","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","1","10","","","","","","","","","","English","","","","WOS:000799921700054","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","CLASSIFICATION; Dimensionality Reduction; DISEASE; Feature Selection; Machine Learning; Parkinson's Disease; Recursive Feature Elimination; XGBoost Classifier","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JIVSR9WN","journalArticle","2021","Millington, T; Luz, S","Analysis and Classification of Word Co-Occurrence Networks From Alzheimer's Patients and Controls","FRONTIERS IN COMPUTER SCIENCE","","2624-9898","10.3389/fcomp.2021.649508","","In this paper we construct word co-occurrence networks from transcript data of controls and patients with potential Alzheimer's disease using the ADReSS challenge dataset of spontaneous speech. We examine measures of the structure of these networks for significant differences, finding that networks from Alzheimer's patients have a lower heterogeneity and centralization, but a higher edge density. We then use these measures, a network embedding method and some measures from the word frequency distribution to classify the transcripts into control or Alzheimer's, and to estimate the cognitive test score of a participant based on the transcript. We find it is possible to distinguish between the AD and control networks on structure alone, achieving 66.7% accuracy on the test set, and to predict cognitive scores with a root mean squared error of 5.675. Using the network measures is more successful than using the network embedding method. However, if the networks are shuffled we find relatively few of the measures are different, indicating that word frequency drives many of the network properties. This observation is borne out by the classification experiments, where word frequency measures perform similarly to the network measures.","2021-04-29","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","3","","","","","","","","","","English","","","","WOS:000647216800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Alzheimer’; DIAGNOSIS; DISEASE; graph measures; LANGUAGE; machine learning; natural language processing; network analysis; network embedding; s disease","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZN2RUFEM","journalArticle","2023","Igarashi, T; Umeda-Kameyama, Y; Kojima, T; Akishita, M; Nihei, M","Questionnaires for the Assessment of Cognitive Function Secondary to Intake Interviews in In-Hospital Work and Development and Evaluation of a Classification Model Using Acoustic Features","SENSORS","","1424-8220","10.3390/s23115346","","The number of people with dementia is increasing each year, and early detection allows for early intervention and treatment. Since conventional screening methods are time-consuming and expensive, a simple and inexpensive screening is expected. We created a standardized intake questionnaire with thirty questions in five categories and used machine learning to categorize older adults with moderate and mild dementia and mild cognitive impairment, based on speech patterns. To evaluate the feasibility of the developed interview items and the accuracy of the classification model based on acoustic features, 29 participants (7 males and 22 females) aged 72 to 91 years were recruited with the approval of the University of Tokyo Hospital. The MMSE results showed that 12 participants had moderate dementia with MMSE scores of 20 or less, 8 participants had mild dementia with MMSE scores between 21 and 23, and 9 participants had MCI with MMSE scores between 24 and 27. As a result, Mel-spectrogram generally outperformed MFCC in terms of accuracy, precision, recall, and F1-score in all classification tasks. The multi-classification using Mel-spectrogram achieved the highest accuracy of 0.932, while the binary classification of moderate dementia and MCI group using MFCC achieved the lowest accuracy of 0.502. The FDR was generally low for all classification tasks, indicating a low rate of false positives. However, the FNR was relatively high in some cases, indicating a higher rate of false negatives.","2023-06-05","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","11","23","","","","","","","","","","English","","","","WOS:001004864300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","ALZHEIMERS-DISEASE; audio processing; cognitive function; DEMENTIA; gerontology; intake interview; mel-spectrum; MFCC","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7CHMBQS4","journalArticle","2022","Lamba, R; Gulati, T; Jain, A","A Hybrid Feature Selection Approach for Parkinson's Detection Based on Mutual Information Gain and Recursive Feature Elimination","ARABIAN JOURNAL FOR SCIENCE AND ENGINEERING","","2193-567X","10.1007/s13369-021-06544-0","","Parkinson's disease, which affects the neurological system of patients, is the second most common neurodegenerative ailment after Alzheimer's disease. Parkinson's disease is most common in adults over sixty and advances slowly. Parkinson's disease symptoms are mild in the early stages and may go unnoticed, but as the disease advances, the symptoms get more severe, and its diagnosis at an early stage is not easy. Recent studies have revealed that alterations in speech or voice distortion can be used to diagnose Parkinson's disease, because it develops as an early symptom in Parkinson's disease patients. The authors propose a technique for detecting Parkinson's disease using speech signals in this paper. As feature selection plays a vital role during classification, the authors have proposed a hybrid MIRFE feature selection approach based on mutual information gain and recursive feature elimination methods. A Parkinson's disease classification dataset consisting of 756 voice measures of 252 individuals was used in this study. The proposed feature selection approach is compared with the five standard feature selection methods by random forest and XGBoost classifier. The proposed MIRFE approach selects 40 features out of 754 features, with a feature reduction ratio of 94.69%. An accuracy of 93.88% and an area under the curve (AUC) of 0.978 are obtained by the proposed system, which is higher than some recent work.","2022-08","2025-02-26 20:36:59","2025-02-26 20:36:59","","10263-10276","","8","47","","","","","","","","","","English","","","","WOS:000744967400004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;18<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","Acoustic Features; CLASSIFICATION; Dimensionality Reduction; DISEASE; Feature Selection; Machine Learning; Parkinson's Disease; Random Forest; Recursive Feature Elimination; XGBoost Classifier","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7LQNICFG","journalArticle","2024","Sha, MHM; Rahamathulla, MP","Quantum deep learning in Parkinson's disease prediction using hybrid quantum-classical convolution neural network","QUANTUM INFORMATION PROCESSING","","1570-0755","10.1007/s11128-024-04588-3","","Deep learning, also known as DL, holds great potential within the field of artificial intelligence. Fast problem-solving approaches are widely used in quantum computing. Large multidimensional space is utilized to categorize and address intricate problems. The different algorithms have the ability to interact in a space with multiple dimensions and find solutions to the problems. Quantum deep learning facilitates different mining procedures by incorporating precise advancements in quantum computing. Prompt and accurate identification during the early stages of progression is crucial for various severe and life-threatening illnesses like cancer, hepatotoxicity, cardio toxicity, nephrotoxicity, and others. Currently, there is a critical need to create rapid, precise, and highly effective approaches for predicting different diseases. These methods should also be feasible and nonintrusive. Dementia, a highly hazardous condition, has a significant impact on the human nervous system. Dementia often includes Parkinson's as one of its prominent symptoms. The patient's entire operational behavior will be impacted. The proposed system is utilizing machine learning and quantum computing to develop a method for predicting Parkinson's disease based on speech signals. Quantum computers can be used to assist in identifying cancer by using a hybrid quantum-classical convolution neural network (QCCNN). This network is inspired by convolution neural networks (CNNs) but has been modified for quantum computing in order to improve the process of mapping features. Dimensionality reduction algorithms, principal component analysis (PCA) are applied to the preprocessed dataset to make predictions about diseases. The standard dataset from UCI machine learning repository will be used to determine the performance of the model. Ensemble models exceed the precision of highly accurate techniques such as neural networks. To demonstrate the superior detection capability of our model, we have compared its performance with several advanced machine learning and deep learning-based methods for Parkinson's disease detection.","2024-11-25","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","12","23","","","","","","","","","","English","","","","WOS:001362563600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","CLASSIFICATION; Convolution neural network; Deep learning; DIAGNOSIS; Dimensionality reduction; Parkinson's disease; Quantum computing; RECOGNITION; SIGNAL-PROCESSING ALGORITHMS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4CMM4V3L","journalArticle","2022","Mian, TS","An Unsupervised Neural Network Feature Selection and 1D Convolution Neural Network Classification for Screening of Parkinsonism","DIAGNOSTICS","","2075-4418","10.3390/diagnostics12081796","","Parkinson's disease (PD) is the second most common neurodegenerative disorder after Alzheimer's disease. It has a slow progressing neurodegenerative disorder rate. PD patients have multiple motor and non-motor symptoms, including vocal impairment, which is one of the main symptoms. The identification of PD based on vocal disorders is at the forefront of research. In this paper, an experimental study is performed on an open source Kaggle PD speech dataset and novel comparative techniques were employed to identify PD. We proposed an unsupervised autoencoder feature selection technique, and passed the compressed features to supervised machine-learning (ML) algorithms. We also investigated the state-of-the-art deep learning 1D convolutional neural network (CNN-1D) for PD classification. In this study, the proposed algorithms are support vector machine, logistic regression, random forest, naive Bayes, and CNN-1D. The classifier performance is evaluated in terms of accuracy score, precision, recall, and F1 score measure. The proposed 1D-CNN model shows the highest result of 0.927%, and logistic regression shows 0.922% on the benchmark dataset in terms of F1 measure. The major contribution of the proposed approach is that unsupervised neural network feature selection has not previously been investigated in Parkinson's detection. Clinicians can use these techniques to analyze the symptoms presented by patients and, based on the results of the above algorithms, can diagnose the disease at an early stage, which will allow for improved future treatment and care.","2022-08","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","8","12","","","","","","","","","","English","","","","WOS:000847130600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","ACOUSTIC ANALYSIS; CRITERIA; DIAGNOSIS; dimensionality reduction; DISEASE; linear discriminate analysis; logistic regression; ML; neural network; Parkinson's disease; principal component analysis; random forest; RECOGNITION; support vector machine; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8GMYAUAZ","journalArticle","2025","Chowdary, MK; Gopatoti, A; Shahila, DFD; Chaturvedi, A; Talasila, V; Babu, AK","Entertainment robots for automatic detection and mitigation of cognitive impairment in elderly populations","ENTERTAINMENT COMPUTING","","1875-9521","10.1016/j.entcom.2024.100803","","This study showed that using collaborative entertainment robots for human-robot interaction can be a promising way to help manage the health of ageing populations by automatically detecting and mitigating cognitive impairment. The system enhanced spoken interaction with users by using cutting-edge technologies such as stateof-the-art speech recognition, natural language processing, and machine learning. The system was tested on senior participants and gathered, analyzed, and displayed individual interaction models to provide automated user engagement, daily interaction monitoring, and automatic early detection of deteriorating mental health. The findings were presented using bar charts and confusion matrices, incorporating important metrics such as mental workload and speech/non-speech interaction graphic. These visualizations aided individuals in managing their behavior to achieve an optimal cognitive workload, a challenging measure to determine due to cognitive decline. In order to make significant progress in the subject, future advancements need to focus on addressing the unpredictability in human speech sequences, using non-speech modalities such as gestures or facial expressions as supplementary inputs to complement speech and behavior, and effectively managing concerns related to human rights and data protection. In addition to technological constraints, future research should prioritize the examination of the enduring impacts of cognitive therapies facilitated by entertainment robots.","2025-01","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","52","","","","","","","","","","English","","","","WOS:001267619200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Assistive technology; Automatic detection; CARE; Cognitive decline; Cognitive impairment; DEMENTIA; Elderly care; Elderly populations; Entertainment robots; Human-robot interaction; Mitigation; Robotics in healthcare; SYSTEMS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XYVGJQ3M","journalArticle","2021","Mohammadi, SM; Enshaeifar, S; Hilton, A; Dijk, DJ; Wells, K","Transfer Learning for Clinical Sleep Pose Detection Using a Single 2D IR Camera","IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING","","1534-4320","10.1109/TNSRE.2020.3048121","","Sleep quality is an important determinant of human health and wellbeing. Novel technologies that can quantify sleep quality at scale are required to enable the diagnosis and epidemiology of poor sleep. One important indicator of sleep quality is body posture. In this paper, we present the design and implementation of a non-contact sleep monitoring system that analyses body posture and movement. Supervised machine learning strategies applied to noncontact vision-based infrared camera data using a transfer learning approach, successfully quantified sleep poses of participants covered by a blanket. This represents the first occasion that such a machine learning approach has been used to successfully detect four predefined poses and the empty bed state during 8-10 hour overnight sleep episodes representing a realistic domestic sleep situation. The methodology was evaluated against manually scored sleep poses and poses estimated using clinical polysomnography measurement technology. In a cohort of 12 healthy participants, we find that a ResNet-152 pre-trained network achieved the best performance compared with the standard de novo CNN network and other pre-trained networks. The performance of our approach was better than other video-based methods for sleep pose estimation and produced higher performance compared to the clinical standard for pose estimation using a polysomnography position sensor. It can be concluded that infrared video capture coupled with deep learning AI can be successfully used to quantify sleep poses as well as the transitions between poses in realistic nocturnal conditions, and that this non-contact approach provides superior pose estimation compared to currently accepted clinical methods.","2021","2025-02-26 20:36:59","2025-02-26 20:36:59","","290-299","","","29","","","","","","","","","","English","","","","WOS:000626331500009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;27<br/>Total Times Cited:&nbsp;&nbsp;28<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Cameras; convolutional neural networks (CNN); Feature extraction; Manuals; Monitoring; polysomnography (PSG); Pose detection; Pose estimation; sleep; Sleep; Standards; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4TFZEBCG","journalArticle","2021","Antonsson, M; Fors, KL; Eckerström, M; Kokkinakis, D","Using a Discourse Task to Explore Semantic Ability in Persons With Cognitive Impairment","FRONTIERS IN AGING NEUROSCIENCE","","1663-4365","10.3389/fnagi.2020.607449","","This paper uses a discourse task to explore aspects of semantic production in persons with various degree of cognitive impairment and healthy controls. The purpose of the study was to test if an in-depth semantic analysis of a cognitive-linguistic challenging discourse task could differentiate persons with a cognitive decline from those with a stable cognitive impairment. Both quantitative measures of semantic ability, using tests of oral lexical retrieval, and qualitative analysis of a narrative were used to detect semantic difficulties. Besides group comparisons a classification experiment was performed to investigate if the discourse features could be used to improve classification of the participants who had a stable cognitive impairment from those who had cognitively declined. In sum, both types of assessment methods captured difficulties between the groups, but tests of oral lexical retrieval most successfully differentiated between the cognitively stable and the cognitively declined group. Discourse features improved classification accuracy and the best combination of features discriminated between participants with a stable cognitive impairment and those who had cognitively declined with an area under the curve (AUC) of 0.93.","2021-01-18","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","12","","","","","","","","","","English","","","","WOS:000613277100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","ALZHEIMERS-DISEASE; CONNECTED SPEECH; CONVERSION; DEMENTIA; discourse; language and aging; LANGUAGE PERFORMANCE; LATE-LIFE; machine learning; mild cognitive impairment; PROGRESSION; RISK; semantic impairment; SPONTANEOUS SPEECH; VERBAL FLUENCY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y64MNLW9","journalArticle","2023","Rohanian, O; Kouchaki, S; Soltan, A; Yang, JY; Rohanian, M; Yang, Y; Clifton, D","Privacy-Aware Early Detection of COVID-19 Through Adversarial Training","IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS","","2168-2194","10.1109/JBHI.2022.3230663","","Early detection of COVID-19 is an ongoing area of research that can help with triage, monitoring and general health assessment of potential patients and may reduce operational strain on hospitals that cope with the coronavirus pandemic. Different machine learning techniques have been used in the literature to detect potential cases of coronavirus using routine clinical data (blood tests, and vital signs measurements). Data breaches and information leakage when using these models can bring reputational damage and cause legal issues for hospitals. In spite of this, protecting healthcare models against leakage of potentially sensitive information is an understudied research area. In this study, two machine learning techniques that aim to predict a patient's COVID-19 status are examined. Using adversarial training, robust deep learning architectures are explored with the aim to protect attributes related to demographic information about the patients. The two models examined in this work are intended to preserve sensitive information against adversarial attacks and information leakage. In a series of experiments using datasets from the Oxford University Hospitals (OUH), Bedfordshire Hospitals NHS Foundation Trust (BH), University Hospitals Birmingham NHS Foundation Trust (UHB), and Portsmouth Hospitals University NHS Trust (PUH), two neural networks are trained and evaluated. These networks predict PCR test results using information from basic laboratory blood tests, and vital signs collected from a patient upon arrival to the hospital. The level of privacy each one of the models can provide is assessed and the efficacy and robustness of the proposed architectures are compared with a relevant baseline. One of the main contributions in this work is the particular focus on the development of effective COVID-19 detection models with built-in mechanisms in order to selectively protect sensitive attributes against adversarial attacks. The results on hold-out test set and external validation confirmed that there was no impact on the generalisibility of the model using adversarial learning.","2023-03","2025-02-26 20:36:59","2025-02-26 20:36:59","","1249-1258","","3","27","","","","","","","","","","English","","","","WOS:000965233400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","Adversarial machine learning; artificial neural networks; Blood; COVID-19; Data models; data privacy; deep learning; electronic medical records; Hospitals; medical information systems; Privacy; ROUTINE; Task analysis; Training","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DLSQR9FL","journalArticle","2022","Lukic, S; Licata, AE; Weis, E; Bogley, R; Ratnasiri, B; Welch, AE; Hinkley, LBN; Miller, Z; Garcia, AM; Houde, JF; Nagarajan, SS; Gorno-Tempini, ML; Borghesani, V","Auditory Verb Generation Performance Patterns Dissociate Variants of Primary Progressive Aphasia","FRONTIERS IN PSYCHOLOGY","","1664-1078","10.3389/fpsyg.2022.887591","","Primary progressive aphasia (PPA) is a clinical syndrome in which patients progressively lose speech and language abilities. Three variants are recognized: logopenic (lvPPA), associated with phonology and/or short-term verbal memory deficits accompanied by left temporo-parietal atrophy; semantic (svPPA), associated with semantic deficits and anterior temporal lobe (ATL) atrophy; non-fluent (nfvPPA) associated with grammar and/or speech-motor deficits and inferior frontal gyrus (IFG) atrophy. Here, we set out to investigate whether the three variants of PPA can be dissociated based on error patterns in a single language task. We recruited 21 lvPPA, 28 svPPA, and 24 nfvPPA patients, together with 31 healthy controls, and analyzed their performance on an auditory noun-to-verb generation task, which requires auditory analysis of the input, access to and selection of relevant lexical and semantic knowledge, as well as preparation and execution of speech. Task accuracy differed across the three variants and controls, with lvPPA and nfvPPA having the lowest and highest accuracy, respectively. Critically, machine learning analysis of the different error types yielded above-chance classification of patients into their corresponding group. An analysis of the error types revealed clear variant-specific effects: lvPPA patients produced the highest percentage of ""not-a-verb"" responses and the highest number of semantically related nouns (production of baseball instead of throw to noun ball); in contrast, svPPA patients produced the highest percentage of ""unrelated verb"" responses and the highest number of light verbs (production of take instead of throw to noun ball). Taken together, our findings indicate that error patterns in an auditory verb generation task are associated with the breakdown of different neurocognitive mechanisms across PPA variants. Specifically, they corroborate the link between temporo-parietal regions with lexical processing, as well as ATL with semantic processes. These findings illustrate how the analysis of pattern of responses can help PPA phenotyping and heighten diagnostic sensitivity, while providing insights on the neural correlates of different components of language.","2022-06-24","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","13","","","","","","","","","","English","","","","WOS:000822670300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;95</p>","","","ALZHEIMERS-DISEASE; ATROPHY PROGRESSION; auditory verb generation; errors analysis; lexical processing; LOGOPENIC VARIANT; NAMING ERRORS; NEURODEGENERATIVE DISEASES; NON-FLUENT/AGRAMMATIC VARIANT; NONFLUENT APHASIA; primary progressive aphasia; RETRIEVAL; SEMANTIC DEMENTIA; semantic processing; SPEECH PRODUCTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZZ76TKAK","journalArticle","2021","Khare, SK; Bajaj, V; Acharya, UR","PDCNNet: An Automatic Framework for the Detection of Parkinson's Disease Using EEG Signals","IEEE SENSORS JOURNAL","","1530-437X","10.1109/JSEN.2021.3080135","","Parkinson's disease (PD) is a neurodegenerative ailment which causes changes in the neuronal, behavioral, and physiological structures. During the early stages of PD, these changes are very subtle and hence accurate diagnosis is challenging. Pathological and neurological experts assess the PD patients by examining their drawing, writing, walking, tremor, facial expressions, and speech. The manual analysis performed by specialists is time-consuming and prone to errors. Electroencephalogram (EEG) signals represent changes in the brain activities, but it is difficult to manually analyze these signals due to their non-linear, non-stationary, and complex nature. Traditional machine learning methods require several manual steps, such as decomposition, extraction of features, and classification. To overcome these limitations, automated PD detection using smoothed pseudo-Wigner Ville distribution (SPWVD) coupled with convolutional neural networks (CNN) called Parkinson's disease CNN (PDCNNet) is proposed. First the EEG signals are subjected to SPWVD to obtain time-frequency representation (TFR). Then these two-dimensional plots are fed to an CNN. The proposed model is developed using two public databases. We have obtained an accuracy of 100% and 99.97% for dataset 1 and 2, respectively in detecting PD automatically using our proposed PDCNNet model. Our developed prototype has outperformed all existing state-of-the-art techniques and ready to be validated with more diverse datasets.","2021-08-01","2025-02-26 20:36:59","2025-02-26 20:36:59","","17017-17024","","15","21","","","","","","","","","","English","","","","WOS:000679541000065","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;56<br/>Total Times Cited:&nbsp;&nbsp;57<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Brain modeling; classification; COHERENCE; convolutional neural network; DEMENTIA; DIAGNOSIS; Diseases; electroencephalography; Electroencephalography; Feature extraction; Medical diagnostic imaging; Parkinson's disease; Sensors; smoothed pseudo Wigner Ville distribution; Time-frequency analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"43E8CQ8I","journalArticle","2024","Dias, M; Dörr, F; Garthof, S; Schäfer, S; Elmers, J; Schwed, L; Linz, N; Overell, J; Hayward-Koennecke, H; Tröger, J; König, A; Dillenseger, A; Tackenberg, B; Ziemssen, T","Detecting fatigue in multiple sclerosis through automatic speech analysis","FRONTIERS IN HUMAN NEUROSCIENCE","","1662-5161","10.3389/fnhum.2024.1449388","","Multiple sclerosis (MS) is a chronic neuroinflammatory disease characterized by central nervous system demyelination and axonal degeneration. Fatigue affects a major portion of MS patients, significantly impairing their daily activities and quality of life. Despite its prevalence, the mechanisms underlying fatigue in MS are poorly understood, and measuring fatigue remains a challenging task. This study evaluates the efficacy of automated speech analysis in detecting fatigue in MS patients. MS patients underwent a detailed clinical assessment and performed a comprehensive speech protocol. Using features from three different free speech tasks and a proprietary cognition score, our support vector machine model achieved an AUC on the ROC of 0.74 in detecting fatigue. Using only free speech features evoked from a picture description task we obtained an AUC of 0.68. This indicates that specific free speech patterns can be useful in detecting fatigue. Moreover, cognitive fatigue was significantly associated with lower speech ratio in free speech (rho = -0.283, p = 0.001), suggesting that it may represent a specific marker of fatigue in MS patients. Together, our results show that automated speech analysis, of a single narrative free speech task, offers an objective, ecologically valid and low-burden method for fatigue assessment. Speech analysis tools offer promising potential applications in clinical practice for improving disease monitoring and management.","2024-09-13","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","18","","","","","","","","","","English","","","","WOS:001320296200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","automated speech analysis; COGNITION; DEPRESSION; fatigue; IMPACT; IMPAIRMENT; INSTRUMENT; machine learning; multiple sclerosis (MS); PERFORMANCE OUTCOME MEASURE; QUALITY-OF-LIFE; SCALE; speech; VALIDATION; VALIDITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4I9SNS2I","journalArticle","2024","Themistocleous, C","Open Brain AI and language assessment","FRONTIERS IN HUMAN NEUROSCIENCE","","1662-5161","10.3389/fnhum.2024.1421435","","Neurolinguistic assessments play a vital role in neurological examinations, revealing a wide range of language and communication impairments associated with developmental disorders and acquired neurological conditions. Yet, a thorough neurolinguistic assessment is time-consuming and laborious and takes valuable resources from other tasks. To empower clinicians, healthcare providers, and researchers, we have developed Open Brain AI (OBAI). The aim of this computational platform is twofold. First, it aims to provide advanced AI tools to facilitate spoken and written language analysis, automate the analysis process, and reduce the workload associated with time-consuming tasks. The platform currently incorporates multilingual tools for English, Danish, Dutch, Finnish, French, German, Greek, Italian, Norwegian, Polish, Portuguese, Romanian, Russian, Spanish, and Swedish. The tools involve models for (i) audio transcription, (ii) automatic translation, (iii) grammar error correction, (iv) transcription to the International Phonetic Alphabet, (v) readability scoring, (vi) phonology, morphology, syntax, semantic measures (e.g., counts and proportions), and lexical measures. Second, it aims to support clinicians in conducting their research and automating everyday tasks with ""OBAI Companion,"" an AI language assistant that facilitates language processing, such as structuring, summarizing, and editing texts. OBAI also provides tools for automating spelling and phonology scoring. This paper reviews OBAI's underlying architectures and applications and shows how OBAI can help professionals focus on higher-value activities, such as therapeutic interventions.","2024-08-06","2025-02-26 20:36:59","2025-02-26 20:36:59","","","","","18","","","","","","","","","","English","","","","WOS:001293259800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","clinical AI analysis; cognition; DEMENTIA; DIAGNOSIS; FORMULA; language; LIFE; natural language processing (NLP); Open Brain AI; READABILITY; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G7MA7KCL","journalArticle","2025","Nylander, A; Sisodia, N; Henderson, K; Wijangco, J; Koshal, K; Poole, S; Dias, M; Linz, N; Tröger, J; König, A; Hayward-Koennecke, H; Pedotti, R; Brown, E; Halabi, C; Staffaroni, A; Bove, R","From ""invisible"" to ""audible"": Features extracted during simple speech tasks classify patient-reported fatigue in multiple sclerosis","MULTIPLE SCLEROSIS JOURNAL","","1352-4585","10.1177/13524585241303855","","Background: Fatigue is a major ""invisible"" symptom in people with multiple sclerosis (PwMS), which may affect speech. Automated speech analysis is an objective, rapid tool to capture digital speech biomarkers linked to functional outcomes. Objective: To use automated speech analysis to assess multiple sclerosis (MS) fatigue metrics. Methods: Eighty-four PwMS completed scripted and spontaneous speech tasks; fatigue was assessed with Modified Fatigue Impact Scale (MFIS). Speech was processed using an automated speech analysis pipeline (ki elements: SIGMA speech processing library) to transcribe speech and extract features. Regression models assessed associations between speech features and fatigue and validated in a separate set of 30 participants. Results: Cohort characteristics were as follows: mean age 49.8 (standard deviation (SD) = 13.6), 71.4% female, 85% relapsing-onset, median Expanded Disability Status Scale (EDSS) 2.5 (range: 0-6.5), mean MFIS 27.6 (SD = 19.4), and 30% with MFIS > 38. MFIS moderately correlated with pitch (R = 0.32, p = 0.005), pause duration (R = 0.33, p = 0.007), and utterance duration (R = 0.31, p = 0.0111). A logistic model using speech features from multiple tasks accurately classified MFIS in training (area under the curve (AUC) = 0.95, R-2 = 0.59, p < 0.001) and test sets (AUC = 0.93, R-2 = 0.54, p = 0.0222). Adjusting for EDSS, processing speed, and depression in sensitivity analyses did not impact model accuracy. Conclusion: Fatigue may be assessed using simple, low-burden speech tasks that correlate with gold-standard subjective fatigue measures.","2025-02","2025-02-26 20:37:00","2025-02-26 20:37:00","","231-241","","2","31","","","","","","","","","","English","","","","WOS:001380647600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","AUTOMATED-ANALYSIS; DISEASE; DISORDERS; Fatigue; IMPACT SCALE; multiple sclerosis; outcome measurement; PARAMETERS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y6ZURSJL","journalArticle","2021","Donohue, C; Khalifa, Y; Mao, ST; Perera, S; Sejdic, E; Coyle, JL","Characterizing Swallows From People With Neurodegenerative Diseases Using High-Resolution Cervical Auscultation Signals and Temporal and Spatial Swallow Kinematic Measurements","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2021_JSLHR-21-00134","","Purpose: The prevalence of dysphagia in patients with neurodegenerative diseases (ND) is alarmingly high and frequently results in morbidity and accelerated mortality due to subsequent adverse events (e.g., aspiration pneumonia). Swallowing in patients with ND should be continuously monitored due to the progressive disease nature. Access to instrumental swallow evaluations can be challenging, and limited studies have quantified changes in temporal/spatial swallow kinematic measures in patients with ND. High resolution cervical auscultation (HRCA), a dysphagia screening method, has accurately differentiated between safe and unsafe swallows, identified swallow kinematic events (e.g., laryngeal vestibule closure [LVC]), and classified swallows between healthy adults and patients with ND. This study aimed to (a) compare temporal/spatial swallow kinematic measures between patients with ND and healthy adults and (b) investigate HRCA's ability to annotate swallow kinematic events in patients with ND. We hypothesized there would be significant differences in temporal/spatial swallow measurements between groups and that HRCA would accurately annotate swallow kinematic events in patients with ND. Method: Participants underwent videofluoroscopic swallowing studies with concurrent HRCA. We used linear mixed models to compare temporal/spatial swallow measurements (n = 170 ND patient swallows, n = 171 healthy adult swallows) and deep learning machine learning algorithms to annotate specific temporal and spatial kinematic events in swallows from patients with ND. Results: Differences (p < .05) were found between groups for several temporal and spatial swallow kinematic measures. HRCA signal features were used as input to machine-learning algorithms and annotated upper esophageal sphincter (UES) opening, UES closure, LVC, laryngeal vestibule reopening, and hyoid bone displacement with 66.25%, 85%, 68.18%, 70.45%, and 44.6% accuracy, respectively, compared to human judges' measurements. Conclusion: This study demonstrates HRCA's potential in characterizing swallow function in patients with ND and other patient populations.","2021-09","2025-02-26 20:37:00","2025-02-26 20:37:00","","3416-3431","","9","64","","","","","","","","","","English","","","","WOS:000696806600004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","AMYOTROPHIC-LATERAL-SCLEROSIS; ASPIRATION; DEMENTIA; OROPHARYNGEAL DYSPHAGIA; SEX","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E34BXKFI","journalArticle","2023","Chow, HM; Garnett, EO; Ratner, NB; Chang, SE","Brain activity during the preparation and production of spontaneous speech in children with persistent stuttering","NEUROIMAGE-CLINICAL","","2213-1582","10.1016/j.nicl.2023.103413","","Speech production forms the basis for human verbal communication. Though fluent speech production is effortless and automatic for most people, it is disrupted in speakers who stutter, who experience difficulties especially during spontaneous speech and at utterance onsets. Brain areas comprising the basal ganglia thalamocortical (BGTC) motor loop have been a focus of interest in the context of stuttering, given this circuit's critical role in initiating and sequencing connected speech. Despite the importance of better understanding the role of the BGTC motor loop in supporting overt, spontaneous speech production, capturing brain activity during speech has been challenging to date, due to fMRI artifacts associated with severe head motions during speech production. Here, using an advanced technique that removes speech-related artifacts from fMRI signals, we examined brain activity occurring immediately before, and during, overt spontaneous speech production in 22 children with persistent stuttering (CWS) and 18 children who do not stutter (controls) in the 5-to-12-year age range. Brain activity during speech production was compared in two conditions: spontaneous speech (i.e., requiring language formulation) and automatic speech (i.e., overlearned word sequences). Compared to controls, CWS exhibited significantly reduced left premotor activation during spontaneous speech production but not during automatic speech. Moreover, CWS showed an age-related reduction in left putamen and thalamus activation during speech preparation. These results provide further evidence that stuttering is associated with functional deficits in the BGTC motor loop, which are exacerbated during spontaneous speech production.","2023","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","38","","","","","","","","","","English","","","","WOS:001163401300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","ALE METAANALYSIS; AREA; Basal ganglia; BASAL GANGLIA; COMPREHENSION; FLUENCY; FMRI; fMRI de-noising; FUNCTIONAL CONNECTIVITY; NETWORK; PATHWAYS; Speech motor planning; Speech production","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E4LVXA9N","journalArticle","2023","Botezatu, MR; Miller, E; Kiselica, AM","Limited connectedness of spontaneous speech may be a marker of dementia due to Alzheimer's disease","FRONTIERS IN AGING NEUROSCIENCE","","1663-4365","10.3389/fnagi.2023.1252614","","The study evaluated the connectedness of spontaneous speech production in individuals with dementia as a potential predictor of dementia severity. Data were derived from the baseline sample of 143 individuals with dementia in the English Pitt corpus. Dementia severity was assessed via the Mini Mental Status Exam, the Mattis Dementia Rating Scale, and the Blessed Dementia Scale. Language abilities were evaluated using verbal fluency and picture description tasks. Graph analysis was carried out for the picture description task using the computational tool SpeechGraphs to calculate connectedness. Results demonstrated that higher educational attainment, higher verbal fluency and strongly-connected spontaneous speech were associated with better cognitive function. Results suggest that automated language processing approaches, such as graph structure analysis, may provide a faster and ecologically valid method of detecting dementia symptoms.","2023-09-19","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","15","","","","","","","","","","English","","","","WOS:001076744900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Alzheimer's dementia; cognitive function; DECLINE; DISCOURSE; EDUCATION; graph structure analysis; SEMANTIC FLUENCY; spontaneous speech production; verbal fluency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DYQHQSNZ","journalArticle","2024","Wilson, SC; Teghipco, A; Sayers, S; Newman-Norlund, R; Newman-Norlund, S; Fridriksson, J","Story Recall in Peer Conflict Resolution Discourse Task to Identify Older Adults Testing Within Range of Cognitive Impairment","AMERICAN JOURNAL OF SPEECH-LANGUAGE PATHOLOGY","","1058-0360","10.1044/2024_AJSLP-24-00005","","Purpose: The current study used behavioral measures of discourse complexity and story recall accuracy in an expository discourse task to distinguish older adults testing within range of cognitive impairment according to a standardized cognitive screening tool in a sample of self-reported healthy older adults. Method: Seventy-three older adults who self-identified as healthy completed an expository discourse task and neuropsychological screener. Discourse data were used to classify participants testing within range of cognitive impairment using multiple machine learning algorithms and stability analysis for identifying reliably predictive features in an effort to maximize prediction accuracy. We hypothesized that a higher rate of pronoun use and lower scores on story recall would best classify older adults testing within range of cognitive impairment. Results: The highest classification accuracy exploited a single variable in a remarkably intuitive way: using 66% story recall as a cutoff for cognitive impairment. Forcing this decision tree model to use more features or increasing its complexity did not improve accuracy. Permutation testing confirmed that the 77% accuracy and 0.18 Brier skill score achieved by the model were statistically significant (p < .00001). Conclusions: These results suggest that expository discourse tasks that place demands on executive functions, such as working memory, can be used to identify aging adults who test within range of cognitive impairment. Accurate representation of story elements in working memory is critical for coherent discourse. Our simple yet highly accurate predictive model of expository discourse provides a promising assessment for easy identification of cognitive impairment in older adults.","2024-09","2025-02-26 20:37:00","2025-02-26 20:37:00","","2582-2598","","5","33","","","","","","","","","","English","","","","WOS:001334864800031","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;87</p>","","","ADOLESCENTS; ALZHEIMERS-DISEASE; ATTENTION; DECLINE; DEMENTIA; EXPOSITORY DISCOURSE; LANGUAGE; MOCA; PERFORMANCE; WORKING-MEMORY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H9XD5WUH","journalArticle","2024","Anmella, G; De Prisco, M; Joyce, JB; Valenzuela-Pascual, C; Mas-Musons, A; Oliva, V; Fico, G; Chatzisofroniou, G; Mishra, S; Al-Soleiti, M; Corponi, F; Giménez-Palomo, A; Montejo, L; González-Campos, M; Popovic, D; Pacchiarotti, I; Valenti, M; Cavero, M; Colomer, L; Grande, I; Benabarre, A; Llach, CD; Radua, J; Mcinnis, M; Hidalgo-Mazzei, D; Frye, MA; Murru, A; Vieta, E","Automated Speech Analysis in Bipolar Disorder: The CALIBER Study Protocol and Preliminary Results","JOURNAL OF CLINICAL MEDICINE","","2077-0383","10.3390/jcm13174997","","Background: Bipolar disorder (BD) involves significant mood and energy shifts reflected in speech patterns. Detecting these patterns is crucial for diagnosis and monitoring, currently assessed subjectively. Advances in natural language processing offer opportunities to objectively analyze them. Aims: To (i) correlate speech features with manic-depressive symptom severity in BD, (ii) develop predictive models for diagnostic and treatment outcomes, and (iii) determine the most relevant speech features and tasks for these analyses. Methods: This naturalistic, observational study involved longitudinal audio recordings of BD patients at euthymia, during acute manic/depressive phases, and after-response. Patients participated in clinical evaluations, cognitive tasks, standard text readings, and storytelling. After automatic diarization and transcription, speech features, including acoustics, content, formal aspects, and emotionality, will be extracted. Statistical analyses will (i) correlate speech features with clinical scales, (ii) use lasso logistic regression to develop predictive models, and (iii) identify relevant speech features. Results: Audio recordings from 76 patients (24 manic, 21 depressed, 31 euthymic) were collected. The mean age was 46.0 +/- 14.4 years, with 63.2% female. The mean YMRS score for manic patients was 22.9 +/- 7.1, reducing to 5.3 +/- 5.3 post-response. Depressed patients had a mean HDRS-17 score of 17.1 +/- 4.4, decreasing to 3.3 +/- 2.8 post-response. Euthymic patients had mean YMRS and HDRS-17 scores of 0.97 +/- 1.4 and 3.9 +/- 2.9, respectively. Following data pre-processing, including noise reduction and feature extraction, comprehensive statistical analyses will be conducted to explore correlations and develop predictive models. Conclusions: Automated speech analysis in BD could provide objective markers for psychopathological alterations, improving diagnosis, monitoring, and response prediction. This technology could identify subtle alterations, signaling early signs of relapse. Establishing standardized protocols is crucial for creating a global speech cohort, fostering collaboration, and advancing BD understanding.","2024-09","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","17","13","","","","","","","","","","English","","","","WOS:001311145400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;78</p>","","","acoustic properties; ANALYTICS; bipolar disorder; CLASSIFICATION; DEPRESSION; diagnosis; emotional profiles; FEATURES; global speech cohort; language content; natural language processing; precision psychiatry; PREDICTION; predictive models; RATING-SCALE; RELIABILITY; SCHIZOPHRENIA; SEVERITY; SPECTRUM; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DNSAKXZT","journalArticle","2022","König, A; Tröger, J; Mallick, E; Mina, M; Linz, N; Wagnon, C; Karbach, J; Kuhn, C; Peter, J","Detecting subtle signs of depression with automated speech analysis in a non-clinical sample","BMC PSYCHIATRY","","1471-244X","10.1186/s12888-022-04475-0","","Background: Automated speech analysis has gained increasing attention to help diagnosing depression. Most previous studies, however, focused on comparing speech in patients with major depressive disorder to that in healthy volunteers. An alternative may be to associate speech with depressive symptoms in a non-clinical sample as this may help to find early and sensitive markers in those at risk of depression. Methods: We included n = 118 healthy young adults (mean age: 23.5 & PLUSMN; 3.7 years; 77% women) and asked them to talk about a positive and a negative event in their life. Then, we assessed the level of depressive symptoms with a self-report questionnaire, with scores ranging from 0-60. We transcribed speech data and extracted acoustic as well as linguistic features. Then, we tested whether individuals below or above the cut-off of clinically relevant depressive symptoms differed in speech features. Next, we predicted whether someone would be below or above that cut-off as well as the individual scores on the depression questionnaire. Since depression is associated with cognitive slowing or attentional deficits, we finally correlated depression scores with performance in the Trail Making Test. Results: In our sample, n = 93 individuals scored below and n = 25 scored above cut-off for clinically relevant depressive symptoms. Most speech features did not differ significantly between both groups, but individuals above cut-off spoke more than those below that cut-off in the positive and the negative story. In addition, higher depression scores in that group were associated with slower completion time of the Trail Making Test. We were able to predict with 93% accuracy who would be below or above cut-off. In addition, we were able to predict the individual depression scores with low mean absolute error (3.90), with best performance achieved by a support vector machine. Conclusions: Our results indicate that even in a sample without a clinical diagnosis of depression, changes in speech relate to higher depression scores. This should be investigated in more detail in the future. In a longitudinal study, it may be tested whether speech features found in our study represent early and sensitive markers for subsequent depression in individuals at risk.","2022-12-27","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","1","22","","","","","","","","","","English","","","","WOS:000905001700004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Acoustic features; Automated speech analysis; Depressive symptoms; Machine learning; Textual features","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BD27NWY7","journalArticle","2021","Brederoo, SG; Nadema, FG; Goedhart, FG; Voppel, AE; De Boer, JN; Wouts, J; Koops, S; Sommer, IEC","Implementation of automatic speech analysis for early detection of psychiatric symptoms: What do patients want?","JOURNAL OF PSYCHIATRIC RESEARCH","","0022-3956","10.1016/j.jpsychires.2021.08.019","","Psychiatry is in dire need of a method to aid early detection of symptoms. Recent developments in automatic speech analysis prove promising in this regard, and open avenues for implementation of speech-based applications to detect psychiatric symptoms. The current survey was conducted to assess positions with regard to speech recordings among a group (n = 675) of individuals who experience psychiatric symptoms. Overall, respondents are open to the idea of speech recordings in light of their mental welfare. Importantly, concerns with regard to privacy were raised. Given that speech recordings are privacy sensitive, this requires special attention upon implementation of automatic speech analysis techniques. Furthermore, respondents indicated a preference for speech recordings in the presence of a clinician, as opposed to a recording made at home without the clinician present. In developing a speech marker for psychiatry, close collaboration with the intended users is essential to arrive at a truly valid and implementable method.","2021-10","2025-02-26 20:37:00","2025-02-26 20:37:00","","299-301","","","142","","","","","","","","","","English","","","","WOS:000693457700008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;15</p>","","","App-based monitoring; Automatic speech analysis; Early detection; Patient involvement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3SMQ988A","journalArticle","2024","Tharmalingam, K; Asmawi, A; Wei, LJ","SELF-ASSESSMENT METACOGNITIVE STRATEGIES IN A SPONTANEOUS ESL SPEECH PRODUCTION CONTEXT","MALAYSIAN JOURNAL OF LEARNING & INSTRUCTION","","1675-8110","10.32890/mjli2024.21.2.10","","Purpose - Self-assessment is regarded as a complex metacognitive process by scholars. Nevertheless, in the context of English as a Second Language (ESL) speaking, self-assessment practices often rely on assessment criteria and teacher commentaries. However, speaking involves spontaneous expression with limited access to external standards. Therefore, this case study aims to explore the metacognitive strategies that proficient ESL students use during self- assessment in spontaneous speech production contexts. Methodology - Three participants, purposefully selected, participated in two spontaneous group discussions recorded on video. Instances of participants' dysfluency served as prompts in stimulated recall interviews, complemented by video recordings to validate participants' responses. The thematic analysis of interview data utilised a conceptual framework integrating O'Malley and Chamot's (1990) metacognitive strategies and Kormos' (2006) speech production model. Findings - The analysis revealed that participants employed three key metacognitive strategies - organisational planning, selective attention, and self-monitoring to self-assess their spontaneous speech. Feedback sources, such as their proficiency in the second language (L2) and contextual factors, influenced the application and effectiveness of these strategies during self-assessment (SA). Significance - This study offers insights into how proficient ESL students self-assess their spontaneous speech production, leveraging their available resources. In addition, this study identifies speech challenges the participants encountered and how they applied metacognitive strategies to address them.","2024-07","2025-02-26 20:37:00","2025-02-26 20:37:00","","301-327","","2","21","","","","","","","","","","English","","","","WOS:001314718900010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","dysfluency markers; English as a Second Language; metacognitive strategies; self-assessment; spontaneous speech context","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y9LSM6ZE","journalArticle","2023","Hamrick, P; Sanborn, V; Ostrand, R; Gunstad, J","Lexical Speech Features of Spontaneous Speech in Older Persons With and Without Cognitive Impairment: Reliability Analysis","JMIR AGING","","2561-7605","10.2196/46483","","Background: Speech analysis data are promising digital biomarkers for the early detection of Alzheimer disease. However, despite its importance, very few studies in this area have examined whether older adults produce spontaneous speech with characteristics that are sufficiently consistent to be used as proxy markers of cognitive status.Objective: This preliminary study seeks to investigate consistency across lexical characteristics of speech in older adults with and without cognitive impairment.Methods: A total of 39 older adults from a larger, ongoing study (age: mean 81.1, SD 5.9 years) were included. Participants completed neuropsychological testing and both picture description tasks and expository tasks to elicit speech. Participants with T-scores of <= 40 on >= 2 cognitive tests were categorized as having mild cognitive impairment (MCI). Speech features were computed automatically by using Python and the Natural Language Toolkit.Results: Reliability indices based on mean correlations for picture description tasks and expository tasks were similar in persons with and without MCI (with r ranging from 0.49 to 0.65 within tasks). Intraindividual variability was generally preserved across lexical speech features. Speech rate and filler rate were the most consistent indices for the cognitively intact group, and speech rate was the most consistent for the MCI group.Conclusions: Our findings suggest that automatically calculated lexical properties of speech are consistent in older adults with varying levels of cognitive impairment. These findings encourage further investigation of the utility of speech analysis and other digital biomarkers for monitoring cognitive status over time.","2023","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","6","","","","","","","","","","English","","","","WOS:001087169100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Alzheimer's disease; ALZHEIMERS; cognitive dysfunction; early diagnosis; LANGUAGE; psychometrics; speech; technology assessment; United States","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PXJ3Q8JH","journalArticle","2024","Hahn, W; Tsalouchidou, PE; Nagels, A; Straube, B","Neural activation during natural speech and rests in patients with schizophrenia and schizophrenia spectrum disorders-an fMRI pilot trial","FRONTIERS IN PSYCHIATRY","","1664-0640","10.3389/fpsyt.2024.1402818","","Background In schizophrenia patients, spontaneous speech production has been hypothesized as correlating with right hemispheric activation, including the inferior frontal and superior temporal gyri as speech-relevant areas. However, robust evidence for this association is still missing. The aim of the present fMRI study is to examine BOLD signal changes during natural, fluent speech production in patients with schizophrenia in the chronic phase of their disease.Methods Using a case-control design, the study included 15 right-handed patients with schizophrenia spectrum disorders as well as 15 healthy controls. The participants described eight pictures from the Thematic Apperception Test for 1 min each, while BOLD signal changes were measured with 3T fMRI. The occurrence of positive and negative formal thought disorders was determined using standardized psychopathological assessments.Results We found significant BOLD signal changes during spontaneous speech production in schizophrenia patients compared to healthy controls, particularly in the right hemispheric network. A post-hoc analysis showed that this right-hemispheric lateralization was mainly driven by activation during experimental rests. Furthermore, the TLI sum value in patients correlated negatively with BOLD signal changes in the right Rolandic operculum.Conclusions Possible underlying factors for this inverse right-hemispheric lateralization of speech-associated areas are structural changes and transmitter system alterations, as well as a lack of neural downregulation in schizophrenia patients during rest periods due to dysfunctional executive functions. When examining spontaneous speech as the most natural form of language, other influencing factors, such as social cognition or emotional processing, should be considered. Our results indicate that future studies should consider group differences during rest, which might provide additional information typically covered in differential contrasts.","2024-06-13","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","15","","","","","","","","","","English","","","","WOS:001255617700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","fMRI; FORMAL THOUGHT-DISORDER; LANGUAGE LATERALIZATION; psychopathology; rest; schizophrenia; spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"829X5N4J","journalArticle","2024","Chen, ACH","Pitch variability in spontaneous speech production and its connection to usage-based grammar","JOURNAL OF PHONETICS","","0095-4470","10.1016/j.wocn.2024.101342","","This study explores pitch variability in language production and its implication for processing advantages of holistic units, with a specific focus on the relationship between disyllabic word production and their distributional properties in language use. Using a 185-million-word native corpus as a proxy for the statistical properties of native usage, the study examines how pitch variability of disyllabic words in a spontaneous speech corpus of Taiwan Mandarin is influenced by lexical frequency, predictive contingencies, and retrodictive contingencies. Building upon the duration-based pairwise variability index (PVI), this study introduces two variants of pitch-related PVI (f0PVI) to quantify pitch variability within speech segments. We assess their effectiveness through three phonetic analyses. The first analysis shows that disyllabic words exhibit significantly lower f0PVI values than their non-holistic partword counterparts, indicating the metric's capability to distinguish holistic linguistic units. The second analysis uncovers a significant inverse correlation between the pitch variability metrics of disyllabic words and their frequency values, highlighting a strong link between reduced prosodic prominence and the frequency-based processing advantages in lexical production. Finally, the third analysis demonstrates moderated effects of retrodictive lexical contingency on pitch variability, contingent on the word's alignment with prosodic junctures. We discuss the implications of contextual predictability in lexical retrieval and its role in the dynamic planning process of speech production. Our findings underscore f0PVI as a robust prosodic measure for the automatized processing and entrenchment of linguistic units arising from repeated usage. (c) 2024 Elsevier Ltd. All rights are reserved, including those for text and data mining, AI training, and similar technologies.","2024-09","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","106","","","","","","","","","","English","","","","WOS:001274242600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;82</p>","","","ACQUISITION; DURATION; FREQUENCY; LANGUAGE; Lexical Contingency; MAXIMUM SPEED; Pitch; PROBABILITY; Processing Advantages; PROSODY; PVI; REDUNDANCY; REPETITION; Retrodiction; Spontaneous Speech Production; Usage-based Grammar; WORD SEQUENCES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VVWWTQNZ","journalArticle","2024","Menne, F; Dörr, F; Schräder, J; Tröger, J; Habel, U; König, A; Wagels, L","The voice of depression: speech features as biomarkers for major depressive disorder","BMC PSYCHIATRY","","1471-244X","10.1186/s12888-024-06253-6","","Background Psychiatry faces a challenge due to the lack of objective biomarkers, as current assessments are based on subjective evaluations. Automated speech analysis shows promise in detecting symptom severity in depressed patients. This project aimed to identify discriminating speech features between patients with major depressive disorder (MDD) and healthy controls (HCs) by examining associations with symptom severity measures. Methods Forty-four MDD patients from the Psychiatry Department, University Hospital Aachen, Germany and fifty-two HCs were recruited. Participants described positive and negative life events, which were recorded for analysis. The Beck Depression Inventory (BDI-II) and the Hamilton Rating Scale for Depression gauged depression severity. Transcribed audio recordings underwent feature extraction, including acoustics, speech rate, and content. Machine learning models including speech features and neuropsychological assessments, were used to differentiate between the MDD patients and HCs. Results Acoustic variables such as pitch and loudness differed significantly between the MDD patients and HCs (effect sizes eta 2 between 0.183 and 0.3, p < 0.001). Furthermore, variables pertaining to temporality, lexical richness, and speech sentiment displayed moderate to high effect sizes (eta 2 between 0.062 and 0.143, p < 0.02). A support vector machine (SVM) model based on 10 acoustic features showed a high performance (AUC = 0.93) in differentiating between HCs and patients with MDD, comparable to an SVM based on the BDI-II (AUC = 0.99, p = 0.01). Conclusions This study identified robust speech features associated with MDD. A machine learning model based on speech features yielded similar results to an established pen-and-paper depression assessment. In the future, these findings may shape voice-based biomarkers, enhancing clinical diagnosis and MDD monitoring.","2024-11-12","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","1","24","","","","","","","","","","English","","","","WOS:001353612200004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;81</p>","","","ACOUSTIC MEASURES; Depression; Machine learning; POSTTRAUMATIC-STRESS-DISORDER; Precision psychiatry; SEVERITY; Speech biomarkers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JCTT5LY8","journalArticle","2024","Collée, E; Vincent, AJPE; Jiskoot, LC; Bos, EM; Schouten, JW; Dirven, CMF; Satoer, D","Spontaneous speech: a robust measurement before, during and after awake brain surgery in patients with glioma","BRITISH JOURNAL OF NEUROSURGERY","","0268-8697","10.1080/02688697.2024.2413438","","BackgroundPatients with glioma often report language complaints with devastating effect on daily life. Analysing spontaneous speech can help to understand underlying language problems. Spontaneous speech monitoring is also of importance during awake brain surgery: it can guide tumour resection and contributes to maintaining language function. We aimed to investigate the spontaneous speech of patients with glioma in the perioperative period and the additional value of spontaneous speech analyses compared to standardised language testing.MethodsWe elicited and transcribed spontaneous speech of eight patients with glioma elected for awake brain surgery preoperatively, intraoperatively and 2.0-3.5 months postoperatively. Linguistic errors were coded. Type Token Ratio, Mean Length of Utterance of words, minimal utterances, and errors were extracted from the transcriptions. Patients were categorised based on total error patterns: stable, decrease or increase during surgery. Reliable Change Index scores were calculated for all spontaneous speech variables to objectify changes between time points. Language performance on language tests was compared to spontaneous speech variables.ResultsMost errors occurred in lexico-syntax, followed by phonology/articulation, syntax, and semantics. The predominant errors were Repetitions, Self-corrections, and Incomplete sentences. Most patients remained stable over time in almost all spontaneous speech variables, except in Incomplete sentences, which deteriorated in most patients postoperatively compared to intraoperatively. Some spontaneous speech variables (total errors, MLUw, TTR) gave more information on language change than a standard language test.ConclusionsWhile the course of spontaneous speech over time remained relatively stable in most patients, Incomplete sentences seems to be a robust marker of language difficulties patients with glioma. These errors can be prioritised in spontaneous speech analysis to save time, especially to determine intra- to postoperative deterioration. Importantly, spontaneous speech analyses can give more information on language change than standardised language testing and should therefore be used in addition to standardised language tests.","2024-10-16","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","","","","","","","","","","","English","","","","WOS:001332872200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","APHASIA; awake brain surgery; ELOQUENT AREAS; IMPACT; INSIGHTS; LANGUAGE; language errors; patients with glioma; RESECTION; Spontaneous speech analysis; TUMOR","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DGM4CEFP","journalArticle","2023","Li, XH; Xu, ZH; Fang, F; Fan, QL; Wang, XF; Leung, VCM","Task Offloading for Deep Learning Empowered Automatic Speech Analysis in Mobile Edge-Cloud Computing Networks","IEEE TRANSACTIONS ON CLOUD COMPUTING","","2168-7161","10.1109/TCC.2022.3177649","","With the explosive growth of mobile multimedia services and artificial intelligence applications involving automatic speech analysis (ASA), mobile devices are increasingly unable to handle these computation-intensive tasks generated by users due to the limited computing resource. Besides, the existing cloud computing paradigm is not capable of processing such real-time and delaysensitive ASA tasks. In this paper, by leveraging mobile edge computing and deep learning (DL), we investigate task offloading for DLempowered ASA in mobile edge-cloud computing networks to minimize the total time for processing ASA tasks, thereby providing an agile service response. Specifically, to accelerate the processing of ASA tasks, we decompose a convolutional neural network based encoder-decoder model and deploy the encoder at edge servers to extract the features of ASA tasks. Moreover, edge servers derive the user tolerance limit by using a linear regression model for further enhancing the quality of experience of users. Based on some certain network constraints (i.e., user association and edge servers' storage/computing capacity), we propose a low-complexity and distributed offloading framework to solve the formulated complex problem. Evaluation results demonstrate the effectiveness of the proposed framework on reducing the total time and improving the satisfaction rate of users.","2023-04","2025-02-26 20:37:00","2025-02-26 20:37:00","","1985-1998","","2","11","","","","","","","","","","English","","","","WOS:001004238600063","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Automatic speech analysis; CONVERGENCE; deep learning; edge-cloud computing; INTERNET; mobile edge computing; task offloading","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GAWYEU3V","journalArticle","2023","Che, WJ","An English translation syntax error recognition based on improved transformer model","INTERNATIONAL JOURNAL OF COMPUTER APPLICATIONS IN TECHNOLOGY","","0952-8091","10.1504/IJCAT.2023.138830","","In order to overcome the problems of low recognition rate, high-error rate and long processing time of traditional English translation syntax error recognition methods, an English translation syntax error recognition method based on improved transformer model is proposed. The Kneser-Ney method is used to smoothy process the English translation text, and the Hidden Markov model is used to label the smoothed English translation sequence to extract the character features, part of speech features and part of speech features of the English translation sequence. The transformer model is improved through the global location of entities, and the improved transformer model and syntax error feature tags are used to recognition syntax error in English translation. The experimental results show that the maximum recognition rate of method of this paper is 97.1%, the minimum error recognition rate is 3.2% and the average processing time is 0.72 s.","2023","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","4","73","","","","","","","","","","English","","","","WOS:001237489600005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;16</p>","","","English translation; feature tags; Hidden Markov model; improved transformer model; smooth processing; syntax error recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XI327VK9","journalArticle","2022","Glanz, O; Hader, M; Schulze-Bonhage, A; Auer, P; Ball, T","A Study of Word Complexity Under Conditions of Non-experimental, Natural Overt Speech Production Using ECoG","FRONTIERS IN HUMAN NEUROSCIENCE","","1662-5161","10.3389/fnhum.2021.711886","","The linguistic complexity of words has largely been studied on the behavioral level and in experimental settings. Only little is known about the neural processes underlying it in uninstructed, spontaneous conversations. We built up a multimodal neurolinguistic corpus composed of synchronized audio, video, and electrocorticographic (ECoG) recordings from the fronto-temporo-parietal cortex to address this phenomenon based on uninstructed, spontaneous speech production. We performed extensive linguistic annotations of the language material and calculated word complexity using several numeric parameters. We orthogonalized the parameters with the help of a linear regression model. Then, we correlated the spectral components of neural activity with the individual linguistic parameters and with the residuals of the linear regression model, and compared the results. The proportional relation between the number of consonants and vowels, which was the most informative parameter with regard to the neural representation of word complexity, showed effects in two areas: the frontal one was at the junction of the premotor cortex, the prefrontal cortex, and Brodmann area 44. The postcentral one lay directly above the lateral sulcus and comprised the ventral central sulcus, the parietal operculum and the adjacent inferior parietal cortex. Beyond the physiological findings summarized here, our methods may be useful for those interested in ways of studying neural effects related to natural language production and in surmounting the intrinsic problem of collinearity between multiple features of spontaneously spoken material.","2022-02-04","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","15","","","","","","","","","","English","","","","WOS:000759612900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","APHASIA; articulation; CONSONANTS; CORTEX; ECoG; ELECTROCORTICOGRAPHIC GAMMA ACTIVITY; FREQUENCY; MOTOR; natural behavior; REPRESENTATION; spontaneous speech production; TASK; word complexity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4MT5X9AY","journalArticle","2024","Bloom, PP; Fisher, CJ; Tedesco, N; Kamdar, N; Garrido-Trevino, L; Robin, J; Asrani, SK; Lok, AS","HEAR-MHE study: Automated speech analysis identifies minimal hepatic encephalopathy and may predict future overt hepatic encephalopathy","HEPATOLOGY","","0270-9139","10.1097/HEP.0000000000001086","","Background and Aims: HE is a major cause of poor quality of life in patients with cirrhosis. A simple diagnostic test to identify minimal hepatic encephalopathy (MHE) and predict future overt HE (OHE) is lacking. We aimed to evaluate if analysis of speech patterns using a modern speech platform (1) correlates with validated HE tests, (2) correlates with MHE, and (3) predicts future OHE. Approach and Results: In a two-center prospective cohort study of 200 outpatients with cirrhosis and 50 controls, patients underwent baseline speech recording and validated HE diagnostic testing with psychometric HE score. Patients were followed for 6 months to identify episodes of OHE. Seven hundred fifty-two speech variables were extracted using an automated speech analysis platform, reflecting the acoustic, lexical, and semantic aspects of speech. Patients with cirrhosis were median 63 years old (IQR 54, 68), 49.5% (99) were female. Over 100 speech variables were significantly associated with psychometric HE score (p <0.05 with false discovery rate adjustment). A three-variable speech model (2 acoustic, 1 speech tempo variable) was similar to animal naming test in predicting MHE (AUC 0.76 vs. 0.69; p=0.11). Adding age and MELD-Na improved the accuracy of the speech model (AUC: 0.82). A combined clinical-speech model (""HEAR-MHE model"") predicted time to OHE with a concordance of 0.74 (p=0.06). Conclusions: Automated speech analysis is highly correlated with validated HE tests, associated with MHE, and may predict future OHE. Future research is needed to validate this tool and to understand how it can be implemented in clinical practice.","2024-09-12","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","","","","","","","","","","","English","","","","WOS:001335158800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","animal naming test; CIRRHOSIS; DIAGNOSIS; digital technology; home monitoring; MELD score; point-of-care test; psychometric HE score; voice recording","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BN5C94NT","journalArticle","2022","Bogavac, I; Jelicic, L; Nenadovic, V; Subotic, M; Janjic, V","The speech and language profile of a child with Turner Syndrome- a case study","CLINICAL LINGUISTICS & PHONETICS","","0269-9206","10.1080/02699206.2021.1953610","","Background Turner syndrome is a genetic disorder that affects only females. It has specific cognitive characteristics, but speech and language data are scarce. Methods and procedures Prospective case report; we report a girl aged seven's cognitive and speech and language profile. Results Cognitive assessment shows higher performance IQ (PIQ), and atypical cognitive profile for Turner syndrome. Speech and language assessment show a significant difference between receptive and expressive language levels. Although the girl did comprehend most of the language structure, there was a lack of it in spontaneous speech. She demonstrated inconsistency in the use of language morphology and complex linguistic structures, primarily because of significant inconsistency in her sound production. Although she produced the majority of phonemes correctly in isolation, her spontaneous speech production was incomprehensible. Conclusion Case studies of speech and language development may reveal a specific characteristic in the cases with Turner syndrome to delineate genetic factors from individual developmental variabilities.","2022-06-03","2025-02-26 20:37:00","2025-02-26 20:37:00","","565-578","","6","36","","","","","","","","","","English","","","","WOS:000678955400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","ABNORMALITIES; ANOMALIES; cognition; DEFICITS; DYSFUNCTION; FEATURES; IMPAIRMENT; MORPHOLOGY; NEUROPSYCHOLOGICAL ASPECTS; SKILLS; speech and language; Turner syndrome; X-CHROMOSOME","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VBSYNFUF","journalArticle","2024","Fullana, N; Mora-Plaza, I; Mora, JC; Adrian, M; Sosa-López, G","Task complexity effects on L2 speech rhythm in spontaneous speech production","SECOND LANGUAGE RESEARCH","","0267-6583","10.1177/02676583241281676","","Task-based pronunciation teaching studies have shown that the cognitive complexity of a task affects different aspects of second language (L2) speech, such as vowel accuracy and comprehensibility. However, its impact on L2 speech rhythm is still under-researched, especially in spontaneous pronunciation-unfocused tasks. In this study, we first investigated how task complexity influences L2 speech rhythm, and we then explored how L2 speech rhythm metrics might predict global pronunciation proficiency (comprehensibility and accentedness). Eighty-two Spanish/Catalan bilingual learners of English and a control group of eight native speakers (NSs) completed a simple and a complex version of an adapted monologic decision-making task. Oral production data were analysed using well-established rhythm metrics (%V, VarcoV, nPVI-V, and VarcoC), novel distance measures (Euclidean and Mahalanobis distance scores) and ratings from 13 English NSs. Results showed differential task complexity effects on L2 speech rhythm depending on the rhythm metrics and distance measures considered. Additionally, the %V rhythm metric and the Mahalanobis distance measure accounted for a modest amount of variance in both comprehensibility and accentedness scores, with Mahalanobis distances having a more reliable predicting power. The outcomes of this study point to the importance of further examining the role of task complexity in L2 speech rhythm in spontaneous speech and to what extent L2 speech rhythm is related to global measures of L2 pronunciation proficiency. These findings also highlight the need for identifying which rhythm metrics are more suitable to depict L2 speech elicited through different methods, particularly spontaneous speech.","2024-09-30","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","","","","","","","","","","","English","","","","WOS:001324284800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","2ND-LANGUAGE; accentedness; CATALAN; comprehensibility; COMPREHENSIBILITY; EFL CLASSROOM; ENGLISH; EXPERIENCE; FOREIGN ACCENT; L2 speech rhythm; LANGUAGE; PERCEPTION; PRONUNCIATION; spontaneous speech; task complexity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G3XA7TMJ","journalArticle","2022","de Almeida, IJ; Silagi, ML; Carthery-Goulart, MT; Parmera, JB; Cecchini, MA; Coutinho, AM; Brucki, SMD; Nitrini, R; Schochat, E","The Discourse Profile in Corticobasal Syndrome: A Comprehensive Clinical and Biomarker Approach","BRAIN SCIENCES","","2076-3425","10.3390/brainsci12121705","","The aim of this study was to characterize the oral discourse of CBS patients and to verify whether measures obtained during a semi-spontaneous speech production could differentiate CBS patients from controls. A second goal was to compare the performance of patients with CBS probably due to Alzheimer's disease (CBS-AD) pathology and CBS not related to AD (CBS-non-AD) in the same measures, based on the brain metabolic status (FDG-PET) and in the presence of amyloid deposition (amyloid-PET). Results showed that CBS patients were significantly different from controls in speech rate, lexical level, informativeness, and syntactic complexity. Discursive measures did not differentiate CBS-AD from CBS-non-AD. However, CBS-AD displayed more lexical-semantic impairments than controls, a profile that is frequently reported in patients with clinical AD and the logopenic variant of primary progressive aphasia (lvPPA). CBS-non-AD presented mainly with impairments related to motor speech disorders and syntactic complexity, as seen in the non-fluent variant of PPA.","2022-12","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","12","12","","","","","","","","","","English","","","","WOS:000900399900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","ALZHEIMERS-DISEASE; amyloid-PET; APHASIA; APRAXIA; BRAZILIAN PORTUGUESE; connected speech; CONNECTED SPEECH; corticobasal degeneration; corticobasal syndrome; DEGENERATION; discourse; language; NAMING ERRORS; positron emission tomography; PROGRESSIVE SUPRANUCLEAR PALSY; SCALE; spontaneous speech; VARIANTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8XCJ3LMI","journalArticle","2023","Krishnan, GG; Raghunathan, A; Sarma, VM","Mapping Commission Errors to Grammatical Development: A Case Study of Malayalam","LANGUAGES","","2226-471X","10.3390/languages8010029","","Young children learning Malayalam use morphological categories and inflections quite productively and accurately in general. However, their utterances sometimes show the use of extra morphological material (or commission errors), revealing mismatches between adult and child grammars. In this paper, we present a survey of such errors that are observed in longitudinally collected, spontaneous speech production data of monolingual Malayalam and bilingual Malayalam-English acquiring children in order to identify both the range of commission errors and the underlying grammatical features that may have triggered them. A close analysis of the data shows us that such errors are restricted to a few grammatical loci and shed light on the specific challenges that some grammatical constraints pose for developing grammars.","2023-03","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","1","8","","","","","","","","","","English","","","","WOS:000958085000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","ACQUISITION; bilingual acquisition; commission errors; early language acquisition; Malayalam; MORPHOLOGY; OVERREGULARIZATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JASYM635","journalArticle","2022","Amir, O; Abraham, WT; Azzam, ZS; Berger, G; Anker, SD; Pinney, SP; Burkhoff, D; Shallom, ID; Lotan, C; Edelman, ER","Remote Speech Analysis in the Evaluation of Hospitalized Patients With Acute Decompensated Heart Failure","JACC-HEART FAILURE","","2213-1779","10.1016/j.jchf.2021.08.008","","OBJECTIVES This study assessed the performance of an automated speech analysis technology in detecting pulmonary fluid overload in patients with acute decompensated heart failure (ADHF). BACKGROUND Pulmonary edema is the main cause of heart failure (HF)-related hospitalizations and a key predictor of poor postdischarge prognosis. Frequent monitoring is often recommended, but signs of decompensation are often missed. Voice and sound analysis technologies have been shown to successfully identify clinical conditions that affect vocal cord vibration mechanics. METHODS Adult patients with ADHF (n = 40) recorded 5 sentences, in 1 of 3 languages, using HearO, a proprietary speech processing and analysis application, upon admission (wet) to and discharge (dry) from the hospital. Recordings were analyzed for 5 distinct speech measures (SMs), each a distinct time, frequency resolution, and linear versus perceptual (ear) model; mean change from baseline SMs was calculated. RESULTS In total, 1,484 recordings were analyzed. Discharge recordings were successfully tagged as distinctly different from baseline (wet) in 94% of cases, with distinct differences shown for all 5 SMs in 87.5% of cases. The largest change from baseline was documented for SMs (218%). Unsupervised, blinded clustering of untagged admission and discharge recordings of 9 patients was further demonstrated for all 5 SMs. CONCLUSIONS Automated speech analysis technology can identify voice alterations reflective of HF status. This platform is expected to provide a valuable contribution to in-person and remote follow-up of patients with HF, by alerting to imminent deterioration, thereby reducing hospitalization rates. (C) 2022 The Authors. Published by Elsevier on behalf of the American College of Cardiology Foundation.","2022-01","2025-02-26 20:37:00","2025-02-26 20:37:00","","41-49","","1","10","","","","","","","","","","English","","","","WOS:000739034300007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;31<br/>Total Times Cited:&nbsp;&nbsp;32<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","acute decompensated heart failure (ADHF); HYDRATION; MECHANISMS; PRESSURE; remote speech analysis; speech measure (SM); VOICE CHANGES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MM6MGSYL","journalArticle","2023","Xie, DY; Chen, H; Li, B","Chunks, pauses, and holistic processing in Mandarin spontaneous speech","FRONTIERS IN PSYCHOLOGY","","1664-1078","10.3389/fpsyg.2023.1071729","","Chunks are multiword sequences with independent meaning and function, or formulaic based on the intuition of native speakers, hypothesized to be holistically restored and retrieved in the mental lexicon. Previous studies suggest that pauses and intonational boundaries tend to occur at the boundaries of chunks, but less discussion was made on the influence of chunk categories over mental processing and on pause placement associated with intonational continuity. This study adopted spontaneous monologs of Mandarin natives in formal and informal settings. It examined the co-occurrence of chunks and pause-defined processing units and pause placement around chunks to explore to what extent chunks are holistically processed. The results showed that Mandarin chunks were likely to be situated within a single processing unit, indicating chunks as smaller units than processing units in spontaneous speech. Major chunk categories exhibited significantly different patterns in co-occurring with processing units, indicating the influence of chunk properties on the mental processing of chunks. In addition, chunks tended to be fluently processed in spontaneous speech production as fewer hesitations occurred before and during chunk production. Major chunk categories shared a similar threshold in encountering hesitations before chunk production and differed significantly in hesitation distribution during chunk production. Hesitations in the middle of chunks were more likely to be situated within intonation units compared to those before chunk production. Speakers' effort to maintain the intonational continuity of chunks when they encounter processing difficulties reveals the mental reality of the holistic nature of chunks. Furthermore, the co-occurrence of chunks and processing units differed significantly between the formal and informal speech genres, indicating genre influence on the mental processing of chunks. Altogether, the findings of this study have provided implications for theories on chunks and the syntactic-prosody interface and contributed to implications for the design of Mandarin instructions and teaching.","2023-02-16","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","14","","","","","","","","","","English","","","","WOS:000953435000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","chunk; FORMULAIC SEQUENCES; FREQUENCY; HESITATION; holistic processing; LANGUAGE; pause; phonological coherence; spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BAUB5VI5","journalArticle","2023","Wasserzug, Y; Degani, Y; Bar-Shaked, M; Binyamin, M; Klein, A; Hershko, S; Levkovitch, Y","Development and validation of a machine learning-based vocal predictive model for major depressive disorder","JOURNAL OF AFFECTIVE DISORDERS","","0165-0327","10.1016/j.jad.2022.12.117","","Background: Variations in speech intonation are known to be associated with changes in mental state over time. Behavioral vocal analysis is an algorithmic method of determining individuals' behavioral and emotional characteristics from their vocal patterns. It can provide biomarkers for use in psychiatric assessment and monitoring, especially when remote assessment is needed, such as in the COVID-19 pandemic. The objective of this study was to design and validate an effective prototype of automatic speech analysis based on algorithms for classifying the speech features related to MDD using a remote assessment system combining a mobile app for speech recording and central cloud processing for the prosodic vocal patterns. Methods: Machine learning compared the vocal patterns of 40 patients diagnosed with MDD to the patterns of 104 non-clinical participants. The vocal patterns of 40 patients in the acute phase were also compared to 14 of these patients in the remission phase of MDD. Results: A vocal depression predictive model was successfully generated. The vocal depression scores of MDD patients were significantly higher than the scores of the non-patient participants (p < 0.0001). The vocal depression scores of the MDD patients in the acute phase were significantly higher than in remission (p < 0.02). Limitations: The main limitation of this study is its relatively small sample size, since machine learning validity improves with big data. Conclusions: The computerized analysis of prosodic changes may be used to generate biomarkers for the early detection of MDD, remote monitoring, and the evaluation of responses to treatment.","2023-03-15","2025-02-26 20:37:00","2025-02-26 20:37:00","","627-632","","","325","","","","","","","","","","English","","","","WOS:000923592300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Depression screening; Machine learning; OBJECTIVE-MEASURE; PAUSE-TIME; Predictive analytics; PSYCHIATRY; Remote patient monitoring; RETARDATION; SPEECH ANALYSIS; Speech prosody; Voice analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QVPTUH3D","journalArticle","2022","Gregory, S; Linz, N; König, A; Langel, K; Pullen, H; Luz, S; Harrison, J; Ritchie, CW","Remote data collection speech analysis and prediction of the identification of Alzheimer's disease biomarkers in people at risk for Alzheimer's disease dementia: the Speech on the Phone Assessment (SPeAk) prospective observational study protocol","BMJ OPEN","","2044-6055","10.1136/bmjopen-2021-052250","","Introduction Identifying cost-effective, non-invasive biomarkers of Alzheimer's disease (AD) is a clinical and research priority. Speech data are easy to collect, and studies suggest it can identify those with AD. We do not know if speech features can predict AD biomarkers in a preclinical population. Methods and analysis The Speech on the Phone Assessment (SPeAk) study is a prospective observational study. SPeAk recruits participants aged 50 years and over who have previously completed studies with AD biomarker collection. Participants complete a baseline telephone assessment, including spontaneous speech and cognitive tests. A 3-month visit will repeat the cognitive tests with a conversational artificial intelligence bot. Participants complete acceptability questionnaires after each visit. Participants are randomised to receive their cognitive test results either after each visit or only after they have completed the study. We will combine SPeAK data with AD biomarker data collected in a previous study and analyse for correlations between extracted speech features and AD biomarkers. The outcome of this analysis will inform the development of an algorithm for prediction of AD risk based on speech features. Ethics and dissemination This study has been approved by the Edinburgh Medical School Research Ethics Committee (REC reference 20-EMREC-007). All participants will provide informed consent before completing any study-related procedures, participants must have capacity to consent to participate in this study. Participants may find the tests, or receiving their scores, causes anxiety or stress. Previous exposure to similar tests may make this more familiar and reduce this anxiety. The study information will include signposting in case of distress. Study results will be disseminated to study participants, presented at conferences and published in a peer reviewed journal. No study participants will be identifiable in the study results.","2022-03","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","3","12","","","","","","","","","","English","","","","WOS:000770320300026","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","COGNITIVE IMPAIRMENT; delirium & cognitive disorders; dementia; EUROPEAN PREVENTION; old age psychiatry","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LP32W57B","journalArticle","2022","Rusz, J; Tykalova, T; Novotny, M; Zogala, D; Ruzicka, E; Dusek, P","Automated speech analysis in early untreated Parkinson's disease: Relation to gender and dopaminergic transporter imaging","EUROPEAN JOURNAL OF NEUROLOGY","","1351-5101","10.1111/ene.15099","","Background The mechanisms underlying speech abnormalities in Parkinson's disease (PD) remain poorly understood, with most of the available evidence based on male patients. This study aimed to estimate the occurrence and characteristics of speech disorder in early, drug-naive PD patients with relation to gender and dopamine transporter imaging. Methods Speech samples from 60 male and 40 female de novo PD patients as well as 60 male and 40 female age-matched healthy controls were analyzed. Quantitative acoustic vocal assessment of 10 distinct speech dimensions related to phonation, articulation, prosody, and speech timing was performed. All patients were evaluated using [123]I-2b-carbomethoxy-3b-(4-iodophenyl)-N-(3-fluoropropyl) nortropane single-photon emission computed tomography and Montreal Cognitive Assessment. Results The prevalence of speech abnormalities in the de novo PD cohort was 56% for male and 65% for female patients, mainly manifested with monopitch, monoloudness, and articulatory decay. Automated speech analysis enabled discrimination between PD and controls with an area under the curve of 0.86 in men and 0.93 in women. No gender-specific speech dysfunction in de novo PD was found. Regardless of disease status, females generally showed better performance in voice quality, consonant articulation, and pauses production than males, who were better only in loudness variability. The extent of monopitch was correlated to nigro-putaminal dopaminergic loss in men (r = 0.39, p = 0.003) and the severity of imprecise consonants was related to cognitive deficits in women (r = -0.44, p = 0.005). Conclusions Speech abnormalities represent a frequent and early marker of motor abnormalities in PD. Despite some gender differences, our findings demonstrate that speech difficulties are associated with nigro-putaminal dopaminergic deficits.","2022-01","2025-02-26 20:37:00","2025-02-26 20:37:00","","81-90","","1","29","","","","","","","","","","English","","","","WOS:000696723700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;41<br/>Total Times Cited:&nbsp;&nbsp;41<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","acoustic analysis; classification; DISORDERS; dysarthria; DYSARTHRIA; DYSFUNCTIONS; IMPAIRMENT; LARGE-SAMPLE; MOTOR; prevalence; sex; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MRBAZEL3","journalArticle","2022","Protserov, SD; Shishkin, AG","Segmentation of Noisy Speech Signals","SCIENTIFIC AND TECHNICAL INFORMATION PROCESSING","","0147-6882","10.3103/S0147688222050100","","One of the most important problems in digital speech-signal processing is distinguishing segments of active speech and of background noise or silence in an input acoustic signal. This problem arises in many important practical applications, such as speech analysis in voice command systems, transmission of speech over a network, automated speech recognition, etc. However, most available systems designed for automated speech analysis cannot efficiently solve this problem if the signal-to-noise ratio is small. In addition, their parameters must be tuned separately for different noise levels. This prevents fully automated segmentation of noisy speech signals. In this work, we design a system for the automated segmentation of speech signals distorted by additive noise of different types and intensities. The developed system is based on three various deep convolutional neural network models and can efficiently detect speech and silence segments in noisy signals over a wide range of the signal-to-noise ratios and different noise types.","2022-12","2025-02-26 20:37:00","2025-02-26 20:37:00","","356-363","","5","49","","","","","","","","","","English","","","","WOS:000946813100010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","convolutional neural networks; digital signal processing; segmentation; speech signals","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YKBI2NZP","journalArticle","2024","Zondag, A","Student teachers' experience with improvisation activities for spontaneous speech practice in English","LANGUAGE TEACHING RESEARCH","","1362-1688","10.1177/13621688211044725","","Because most real-life foreign language speech is naturally unpredictable, spontaneous speech should be practiced in the foreign language classroom. Student teachers of English as a foreign language (EFL) may benefit from practising methodology for spontaneous speech practice. This article reports the findings for a study into EFL student teachers' experiences with using improvisation activities, exploring the relevance of improvisation activities for spontaneous speech practice. The data include semi-guided texts and reluctant speakers' interviews. The findings showed that improvisation activities facilitated spontaneous speech practice and strengthened speaking confidence through enjoyment. The 'spontaneous speech mindset' enabled participants to explore linguistic and creative boundaries. The study showed that application of improvisation activities is an excellent method for spontaneous speech practice in EFL teacher education.","2024-11","2025-02-26 20:37:00","2025-02-26 20:37:00","","2190-2213","","6","28","","","","","","","","","","English","","","","WOS:000703236200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","drama; DRAMA; EDUCATION; EFL; English as a foreign language; English language teaching; ENJOYMENT; FOREIGN; improvisation; LANGUAGE CLASSROOM ANXIETY; oral language pedagogy; reluctant speaker; speaking confidence; spontaneous speech mindset; spontaneous speech practice; teacher education","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4EQQ4I8D","journalArticle","2025","Mohammadpoory, Z; Nasrolahzadeh, M; Amiri, SA; Haddadnia, J","A Non-invasive Approach for Early Alzheimer's Detection Through Spontaneous Speech Analysis Using Deep Visibility Graphs","COGNITIVE COMPUTATION","","1866-9956","10.1007/s12559-024-10398-7","","Identifying Alzheimer's disease (AD) in its early stages is a challenging task for physicians and clinicians. This paper proposes a new algorithm for diagnosing AD, which is based on analyzing spontaneous speech signals. The proposed method uses two visibility graph methods, Natural Visibility Graph (NVG) and Horizontal Visibility Graph (HVG), to derive features from speech windows. These features are then given to a deep BiLSTM-based classifier to decide about segments of the signal. The proposed approach could obtain a sensitivity of 98.33%, specificity of 99.44%, and accuracy of 99.17%. The advantage of converting speech signals into graphs using NVG and HVG is that it allows for the extraction of complex structural features that are not easily captured by traditional methods. This method is highly beneficial due to its non-invasive nature, low cost, and lack of side effects. Patients can undergo the procedure without experiencing any discomfort, while also benefiting from its affordability and accessibility. The method's safety and practicality make it an ideal choice for those seeking a reliable and effective solution. Moreover, the proposed algorithm has a high accuracy in detecting the early stage of AD, which makes it a promising tool to evaluate Alzheimer's disease diagnosis in its pre-clinical stage.","2025-02","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","1","17","","","","","","","","","","English","","","","WOS:001396264900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","ALGORITHM; Alzheimer's disease; BiLSTM method; DIAGNOSIS; DISEASE; NETWORK; PACKET-BASED FEATURES; SELECTION; SIGNALS; Spontaneous speech signal; Visibility graph","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QTYL7UZI","journalArticle","2023","Kouba, T; Frank, W; Tykalova, T; Muehlbaeck, A; Klempir, J; Lindenberg, KS; Landwehrmeyer, GB; Rusz, J","Speech biomarkers in Huntington's disease: A cross-sectional study in pre-symptomatic, prodromal and early manifest stages","EUROPEAN JOURNAL OF NEUROLOGY","","1351-5101","10.1111/ene.15726","","Background and purpose: Motor speech alterations are a prominent feature of clinically manifest Huntington's disease (HD). Objective acoustic analysis of speech can quantify speech alterations. It is currently unknown, however, at what stage of HD speech alterations can be reliably detected. We aimed to explore the patterns and extent of speech alterations using objective acoustic analysis in HD and to assess correlations with both rater-assessed phenotypical features and biological determinants of HD.Methods: Speech samples were acquired from 44 premanifest (29 pre-symptomatic and 15 prodromal) and 25 manifest HD gene expansion carriers, and 25 matched healthy controls. A quantitative automated acoustic analysis of 10 speech dimensions was performed.Results: Automated speech analysis allowed us to differentiate between participants with HD and controls, with areas under the curve of 0.74 for pre-symptomatic, 0.92 for prodromal, and 0.97 for manifest stages. In addition to irregular alternating motion rates and prolonged pauses seen only in manifest HD, both prodromal and manifest HD displayed slowed articulation rate, slowed alternating motion rates, increased loudness variability, and unstable steady state position of articulators. In participants with pre manifest HD, speech alteration severity was associated with cognitive slowing (r = -0.52, p < 0.001) and the extent of bradykinesia (r = 0.43, p = 0.004). Speech alterations correlated with a measure of exposure to mutant gene products (CAG- age-product score; r = 0.60, p < 0.001).Conclusion: Speech abnormalities in HD are associated with other motor and cognitive deficits and are measurable already in premanifest stages of HD. Therefore, automated speech analysis might represent a quantitative HD biomarker with potential for assessing disease progression.","2023-05","2025-02-26 20:37:00","2025-02-26 20:37:00","","1262-1271","","5","30","","","","","","","","","","English","","","","WOS:000936979900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","acoustic analysis; ACOUSTIC ANALYSIS; DYSFUNCTION; GENE CARRIERS; HD; Huntington's disease; hyperkinetic dysarthria; ONSET; PATTERNS; PERFORMANCE; PREMANIFEST; prodromal biomarker; REPEAT; speech; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WSJM6BK7","journalArticle","2021","König, A; Riviere, K; Linz, N; Lindsay, H; Elbaum, J; Fabre, R; Derreumaux, A; Robert, P","Measuring Stress in Health Professionals Over the Phone Using Automatic Speech Analysis During the COVID-19 Pandemic: Observational Pilot Study","JOURNAL OF MEDICAL INTERNET RESEARCH","","1438-8871","10.2196/24191","","Background: During the COVID-19 pandemic, health professionals have been directly confronted with the suffering of patients and their families. By making them main actors in the management of this health crisis, they have been exposed to various psychosocial risks (stress, trauma, fatigue, etc). Paradoxically, stress-related symptoms are often underreported in this vulnerable population but are potentially detectable through passive monitoring of changes in speech behavior. Objective: This study aims to investigate the use of rapid and remote measures of stress levels in health professionals working during the COVID-19 outbreak. This was done through the analysis of participants' speech behavior during a short phone call conversation and, in particular, via positive, negative, and neutral storytelling tasks. Methods: Speech samples from 89 health care professionals were collected over the phone during positive, negative, and neutral storytelling tasks; various voice features were extracted and compared with classical stress measures via standard questionnaires. Additionally, a regression analysis was performed. Results: Certain speech characteristics correlated with stress levels in both genders; mainly, spectral (ie, formant) features, such as the mel-frequency cepstral coefficient, and prosodic characteristics, such as the fundamental frequency, appeared to be sensitive to stress. Overall, for both male and female participants, using vocal features from the positive tasks for regression yielded the most accurate prediction results of stress scores (mean absolute error 5.31). Conclusions: Automatic speech analysis could help with early detection of subtle signs of stress in vulnerable populations over the phone. By combining the use of this technology with timely intervention strategies, it could contribute to the prevention of burnout and the development of comorbidities, such as depression or anxiety.","2021-04-19","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","4","23","","","","","","","","","","English","","","","WOS:000642263600002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","APATHY; computer linguistics; COVID-19; DEPRESSION; DISORDERS; EMOTIONS; EXPOSURE; GENDER RECOGNITION; INDICATORS; PERCEPTION; phone monitoring; PSYCHOMOTOR SYMPTOMS; speech; stress detection; voice analysis; VOICE PITCH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E4442WGZ","journalArticle","2024","Lei, XY","Real-time translation of English speech through speech feature extraction","ARTIFICIAL LIFE AND ROBOTICS","","1433-5298","10.1007/s10015-024-00951-w","","Real-time English speech translation is useful in numerous situations, including business and travel. The goal of this research is to improve real-time English speech translation efficacy. Initially, filter bank (FBank) features were extracted from English speech. Subsequently, an enhanced Transformer model was introduced, incorporating a causal convolution module in the front end of the encoder to capture English speech features with location information. The performance of the optimized model in translating English speech to different target languages was tested using the MuST-C dataset. The results revealed differences in translation results for different target languages using the improved Transformer. The highest bilingual evaluation understudy (BLEU) score was observed for Spanish text at 20.84, while Russian text obtained the lowest score of 10.56. The average BLEU score was 18.51, with an average lag time delay of 1202.33 ms. Compared to the conventional Transformer model, the improved model exhibited higher BLEU scores, lower time delay, and optimal performance when utilizing a convolutional kernel size of 3 x 3. The results demonstrate the dependability of the improved Transformer model in real-time English speech translation, highlighting its practical usefulness.","2024-08","2025-02-26 20:37:00","2025-02-26 20:37:00","","410-415","","3","29","","","","","","","","","","English","","","","WOS:001232189800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;16</p>","","","English speech; Real-time translation; Speech feature; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LWKJYLT2","journalArticle","2023","Vallejos-Yopán, R","From demonstrative to filler: este in Amazonian Spanish and beyond","LINGUISTICS","","0024-3949","10.1515/ling-2021-0137","","In Amazonian Spanish, este has two main functions: demonstrative and filler. Filler-este, which originally evolved from demonstrative-este, serves to deal with word-formulation delays during spontaneous speech production. Analyses of conversations reveal that este primarily functions as a filler: 70% of the tokens of este are either fillers serving as placeholders, which replace lexical items in specific syntactic slots, or fillers serving as hesitators, which are non-referential and distributionally free. Further, phonetic analyses show that demonstrative-este and filler-este exhibit different phonetic shapes. Demonstrative-este patterns with disyllabic words with penultimate stress - the first vowel is longer than the second vowel. Filler-este shows the opposite configuration - the second vowel is significantly longer than the first vowel. The evolution of este from demonstrative to filler may have been facilitated by two conspiring forces: its use as cataphor whose referent comes later in the discourse, and its use for recognitional purposes, in which establishing a referent relies on shared knowledge. This use is often accompanied by signs of hesitation. The diachronic proposal outlined here can account for the emergence of the filler-este in several varieties of Spanish spoken in Latin America. Overall, this study contributes to our understanding of the syntax of real-time interaction.","2023-05-25","2025-02-26 20:37:00","2025-02-26 20:37:00","","651-678","","3","61","","","","","","","","","","English","","","","WOS:000967528500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","demonstrative; filler; hesitator; placeholder; Spanish","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4KDAMTI3","journalArticle","2023","Feng, FF; Zhang, ZL; Tang, LJ; Qian, HS; Yang, LZ; Jiang, HH; Li, H","Test-retest reliability of acoustic and linguistic measures of speech tasks","COMPUTER SPEECH AND LANGUAGE","","0885-2308","10.1016/j.csl.2023.101547","","Recent studies suggest that automatic speech analysis is promising for diagnosing movement and cognitive disorders. However, the reliability of acoustic and linguistic measures receives insuf-ficient research efforts. The present study examines the test-retest reliability of commonly used acoustic and linguistic features in a healthy Chinese adult sample. Forty healthy young adults participated in the study and received seven frequently used speech tests twice, separated by 2-3 days. Fifty-six acoustic and linguistic features were extracted for each participant. The test-retest reliabilities of those features were then estimated using the intra-class correlation (ICC) method. The frequency-related, spectral, diadochokinetic (diadochokinetic rate, voice onset time), and content length features showed acceptable absolute agreement between the two test sessions. Articulation tasks (sustained vowel pronunciation, diadochokinetic rate) provided more reliable features than cognitive tasks such as picture descriptions. However, approximately half of those features failed to reach a moderate reliability requirement. There were no gender differences in the reliability estimates. We suggest increasing trial numbers or using multiple tests to increase the reliability of automated speech tests.","2023-10","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","83","","","","","","","","","","English","","","","WOS:001043846000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Acoustic and linguistic features; ALZHEIMERS-DISEASE; IMPAIRMENT; Movement and cognitive dysfunctions; Speech analysis; Test-retest reliability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SRTBCLIF","journalArticle","2024","Imaezue, GC","Recursive self-feedback improves spontaneous speech in chronic aphasia within real-world settings","APHASIOLOGY","","0268-7038","10.1080/02687038.2024.2432024","","BackgroundSpontaneous speech generation, often impaired in chronic nonfluent aphasia, is essential for natural communication. Treatments aiming to optimize spontaneous speech in real-world settings are critical for improving the quality of life for persons with nonfluent aphasia (PWNA). Traditional treatments frequently rely on models and feedback from external agents, which may not be sustainable in the long-term. Preliminary evidence suggests that PWNA can use self-feedback alone, through recursive self-feedback, to improve their production of scripted sentences. This study developed and examined the impact of spontaneous speech with recursive self-feedback on enabling PWNA to self-improve their spontaneous speech in real-world settings.MethodUsing a cross-over design, 3 participants received 2 treatments at their homes: spontaneous speech with recursive self-feedback and spontaneous speech with speech model. Recursive self-feedback treatment involved iterative self-monitoring and minimization/correction of errors during spontaneous speech response to narrative prompts. The speech model treatment provided corrective model responses to prompts from an external source which served as reference frames to help improve the participants' responses. Participants utilized a mobile app to practice the treatments intensively at home for 2 hours each day over a period of 12 to 14 days, spanning 2 to 3 weeks. Direct and generalized treatment effects on microlinguistic measures of spontaneous speech were determined using general linear mixed effects model and standardized mean difference.ResultsBoth treatments led to significant improvements in microlinguistic measures of spontaneous speech, with recursive self-feedback treatment showing broader post-treatment effects on treated prompts and generalization effects. to untreated prompts.ConclusionRecursive self-feedback is a promising procedure for enhancing spontaneous speech in PWNA, providing a simple and flexible self-directed treatment option. This procedure relies primarily on speech-auditory stimulations and self-feedback loops to improve spontaneous speech, suggesting its potential applicability across various spoken language cultures. To validate these findings and assess their broader relevance, further research is recommended.","2024-11-22","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","","","","","","","","","","","English","","","","WOS:001359424700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","ACQUIRED APRAXIA; Aphasia; DECISION; DISCOURSE; QUANTITATIVE-ANALYSIS; recursive self-feedback; REHABILITATION; spontaneous speech; telehealth","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A96HZJZL","journalArticle","2022","Iizuka, T; Mori, H","Comparison of machine learning algorithms and acoustic features in emotion recognition from spontaneous speech","ACOUSTICAL SCIENCE AND TECHNOLOGY","","1346-3969","10.1250/ast.43.228","","","2022","2025-02-26 20:37:00","2025-02-26 20:37:00","","228-231","","4","43","","","","","","","","","","English","","","","WOS:000811050700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","Emotion recognition; Emotional speech corpus; Machine learning; Spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LCWHAXS3","journalArticle","2022","Ivanova, O; Meilán, JJG; Martínez-Sánchez, F; Martínez-Nicolás, I; Llorente, TE; González, NC","Discriminating speech traits of Alzheimer's disease assessed through a corpus of reading task for Spanish language","COMPUTER SPEECH AND LANGUAGE","","0885-2308","10.1016/j.csl.2021.101341","","It is estimated that between 50% and 75% of all cases of dementia are due to Alzheimer's disease (AD), the most common neurodegenerative disease among World population. However, a long preclinical period of AD makes it difficult to differentiate between people with Mild Cognitive Impairment (MCI) that would progress to dementia from people with MCI that would not. One of the most promising solutions to detect MCI which will evolve to dementia (preAD) comes from the field of automatic speech analysis. Speech is a complex physiological and neurocognitive language-mediated process, which can be significantly altered in pathological aging and exhibit high levels of sensitivity for the diagnosis of neurological diseases. The purpose of this research is to offer a detailed perspective on the speech changes in MCI and mild AD when compared to healthy aging (HA), that would allow to detect pathological processes prior to the clinical expression of AD. Based on our previous research record on speech in HA, MCI and AD, we provide a global review of dementia-related speech traits and propose a reading-based protocol for assessing ongoing neurodegenerative processes in the elderly. We report the results of speech analysis in elderly people with different cognitive profiles, who performed a standardized reading task and were further analyzed for correlations between neurocognitive assessment indicative of cognitive impairment stage (HA, MCI or AD) and acoustic, temporal and prosodic traits in speech. We show that evolution from HA to AD exhibits a steady pattern of speech changes in parallel to the cognitive decline, which consists in significant increase in duration and phonation time, extension of pauses and voice breaks, intensification of variation in syllabic production, and decrease in speech energy and intensity leading to dysphony. In doing so, we prove that a standardized reading task is a very useful type of stimuli for detecting dementia-related speech traits and, in view of this, we discuss the relevance of reading for preclinical automated diagnosis of AD. The main contribution of this paper is a corpus of recordings of the standardized reading task performed by healthy elderly people and people with MCI and AD in Spanish language, and which can be used for further research purposes. In this respect, our work fills an important gap existing in corpora-based studies of speech and language impairments related to progression to dementia.","2022-05","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","73","","","","","","","","","","English","","","","WOS:000744097300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;115</p>","","","AGE; Alzheimer's disease; AMNESIC MCI; Automatic speech analysis; CLASSIFICATION; CONNECTED SPEECH; Corpus; DECLINE; DEMENTIA; DIAGNOSIS; MEMORY LOSS; Mild Cognitive Impairment; MILD COGNITIVE IMPAIRMENT; PERFORMANCE; Reading task","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FGQ96ZBQ","journalArticle","2021","Wolk, C; Götz, S; Jäschke, K","Possibilities and Drawbacks of Using an Online Application for Semi-automatic Corpus Analysis to Investigate Discourse Markers and Alternative Fluency Variables","CORPUS PRAGMATICS","","2509-9507","10.1007/s41701-019-00072-x","","To overcome planning phases in spontaneous speech production, learners and native speakers use strategies such as (un)filled pauses, smallwords or discourse markers. Small scale studies in this vein have demonstrated that learners differ from native speakers in that they underuse smallwords and discourse markers, and rely on other fluency-enhancing strategies instead. In the present paper, we present a corpus-based study, which investigates fluency-enhancing strategies in four components of the Louvain International Database of Spoken English Interlanguage (LINDSEI; Gilquin et al. 2010), covering four learner English varieties, namely Spanish, German, Bulgarian and Japanese. We investigate 216 different fluencemes (i.e. fluency-enhancing features; Gotz in Fluency in native and nonnative English speech, John Benjamins, Amsterdam, 2013) in 200 transcribed interviews with advanced learners of English. An online coding application, which was specially designed and programmed for this project, enables us to cover such a large amount of data. We report on the design, functionality and (dis-)advantages of the online application, the multilevel-coding system we implemented, and the methodological challenges we face in detail. We will also present the findings of one first pilot study where we exhibit considerable variation between and within learners of particular native languages concerning fluenceme frequencies, while distributional patterns of fluencemes are rather similar across varieties.","2021-03","2025-02-26 20:37:00","2025-02-26 20:37:00","","7-36","","1","5","","","","","","","","","","English","","","","WOS:000670619600002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Advanced spoken learner language; Discourse markers; Fluency; Online coding application","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VIDKBC93","journalArticle","2024","Sonkaya, ZZ; Özturk, B; Sonkaya, R; Taskiran, E; Karadas, Ö","Using Objective Speech Analysis Techniques for the Clinical Diagnosis and Assessment of Speech Disorders in Patients with Multiple Sclerosis","BRAIN SCIENCES","","2076-3425","10.3390/brainsci14040384","","Multiple sclerosis (MS) is one of the chronic and neurodegenerative diseases of the central nervous system (CNS). It generally affects motor, sensory, cerebellar, cognitive, and language functions. It is thought that identifying MS speech disorders using quantitative methods will make a significant contribution to physicians in the diagnosis and follow-up of MS patients. In this study, it was aimed to investigate the speech disorders of MS via objective speech analysis techniques. The study was conducted on 20 patients diagnosed with MS according to McDonald's 2017 criteria and 20 healthy volunteers without any speech or voice pathology. Speech data obtained from patients and healthy individuals were analyzed with the PRAAT speech analysis program, and classification algorithms were tested to determine the most effective classifier in separating specific speech features of MS disease. As a result of the study, the K-nearest neighbor algorithm (K-NN) was found to be the most successful classifier (95%) in distinguishing pathological sounds which were seen in MS patients from those in healthy individuals. The findings obtained in our study can be considered as preliminary data to determine the voice characteristics of MS patients.","2024-04","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","4","14","","","","","","","","","","English","","","","WOS:001210693300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","DYSARTHRIA; MS; quantitative speech analysis; speech disorders; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HJPL3JFT","journalArticle","2022","Iizuka, T; Mori, H","How Does a Spontaneously Speaking Conversational Agent Affect User Behavior?","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3214977","","People treat conversational agents as mere tools and not as human-like social actors. While there has been much research on human-like agents, few studies have approached the realization of a conversational agent as a social actor from the viewpoint of speech synthesis. This study investigated the effect of synthetic voice of conversational agent trained with spontaneous speech on human interactants. Specifically, we hypothesized that humans will exhibit more social responses when interacting with conversational agent that has a synthetic voice built on spontaneous speech. Typically, speech synthesizers are built on a speech corpus where voice professionals read a set of written sentences. The synthesized speech is clear as if a newscaster were reading the news or a voice actor were playing an anime character. However, this is quite different from spontaneous speech we speak in everyday conversation. Recent advances in speech synthesis enabled us to build a speech synthesizer on a spontaneous speech corpus, and to obtain a near-conversational synthesized speech with reasonable quality. By making use of these technologies, we examined whether humans produce more social responses to a spontaneously speaking conversational agent. We conducted a large-scale conversation experiment with a conversational agent whose utterances were synthesized with the model trained either with spontaneous speech or read speech. The result showed that the subjects who interacted with the agent whose utterances were synthesized from spontaneous speech tended to show shorter response time and a larger number of backchannels. The result of a questionnaire showed that subjects who interacted with the agent whose utterances were synthesized from spontaneous speech tended to rate their conversation with the agent as closer to a human conversation. These results suggest that speech synthesis built on spontaneous speech is essential to realize a conversational agent as a social actor.","2022","2025-02-26 20:37:00","2025-02-26 20:37:00","","111042-111051","","","10","","","","","","","","","","English","","","","WOS:000873899000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Behavioral sciences; Conversational agents; Human computer interaction; human-computer interaction; Spectrogram; Speech recognition; Speech synthesis; spontaneous speech synthesis; Synthesizers; Vocoders","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JIS54P7G","journalArticle","2024","Bauer, JF; Gerczuk, M; Schindler-Gmelch, L; Amiriparian, S; Ebert, DD; Krajewski, J; Schuller, B; Berking, M","Validation of Machine Learning-Based Assessment of Major Depressive Disorder from Paralinguistic Speech Characteristics in Routine Care","DEPRESSION AND ANXIETY","","1091-4269","10.1155/2024/9667377","","New developments in machine learning-based analysis of speech can be hypothesized to facilitate the long-term monitoring of major depressive disorder (MDD) during and after treatment. To test this hypothesis, we collected 550 speech samples from telephone-based clinical interviews with 267 individuals in routine care. With this data, we trained and evaluated a machine learning system to identify the absence/presence of a MDD diagnosis (as assessed with the Structured Clinical Interview for DSM-IV) from paralinguistic speech characteristics. Our system classified diagnostic status of MDD with an accuracy of 66% (sensitivity: 70%, specificity: 62%). Permutation tests indicated that the machine learning system classified MDD significantly better than chance. However, deriving diagnoses from cut-off scores of common depression scales was superior to the machine learning system with an accuracy of 73% for the Hamilton Rating Scale for Depression (HRSD), 74% for the Quick Inventory of Depressive Symptomatology-Clinician version (QIDS-C), and 73% for the depression module of the Patient Health Questionnaire (PHQ-9). Moreover, training a machine learning system that incorporated both speech analysis and depression scales resulted in accuracies between 73 and 76%. Thus, while findings of the present study demonstrate that automated speech analysis shows the potential of identifying patterns of depressed speech, it does not substantially improve the validity of classifications from common depression scales. In conclusion, speech analysis may not yet be able to replace common depression scales in clinical practice, since it cannot yet provide the necessary accuracy in depression detection. This trial is registered with DRKS00023670.","2024-04-09","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","2024","","","","","","","","","","English","","","","WOS:001205909600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;88</p>","","","CLASSIFICATION; EXPERIENCE; EXPRESSION; INTERVIEW; METAANALYSIS; PREVALENCE; RATING-SCALE; SELF-REPORT; SEVERITY; VALIDITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KRCEXDDH","journalArticle","2021","Zhu, YX; Liang, XH; Batsis, JA; Roth, RM","Exploring Deep Transfer Learning Techniques for Alzheimer's Dementia Detection","FRONTIERS IN COMPUTER SCIENCE","","2624-9898","10.3389/fcomp.2021.624683","","Examination of speech datasets for detecting dementia, collected via various speech tasks, has revealed links between speech and cognitive abilities. However, the speech dataset available for this research is extremely limited because the collection process of speech and baseline data from patients with dementia in clinical settings is expensive. In this paper, we study the spontaneous speech dataset from a recent ADReSS challenge, a Cookie Theft Picture (CTP) dataset with balanced groups of participants in age, gender, and cognitive status. We explore state-of-the-art deep transfer learning techniques from image, audio, speech, and language domains. We envision that one advantage of transfer learning is to eliminate the design of handcrafted features based on the tasks and datasets. Transfer learning further mitigates the limited dementia-relevant speech data problem by inheriting knowledge from similar but much larger datasets. Specifically, we built a variety of transfer learning models using commonly employed MobileNet (image), YAMNet (audio), Mockingjay (speech), and BERT (text) models. Results indicated that the transfer learning models of text data showed significantly better performance than those of audio data. Performance gains of the text models may be due to the high similarity between the pre-training text dataset and the CTP text dataset. Our multi-modal transfer learning introduced a slight improvement in accuracy, demonstrating that audio and text data provide limited complementary information. Multi-task transfer learning resulted in limited improvements in classification and a negative impact in regression. By analyzing the meaning behind the Alzheimer's disease (AD)/non-AD labels and Mini-Mental State Examination (MMSE) scores, we observed that the inconsistency between labels and scores could limit the performance of the multi-task learning, especially when the outputs of the single-task models are highly consistent with the corresponding labels/scores. In sum, we conducted a large comparative analysis of varying transfer learning models focusing less on model customization but more on pre-trained models and pre-training datasets. We revealed insightful relations among models, data types, and data labels in this research area.","2021-05-12","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","3","","","","","","","","","","English","","","","WOS:000656517800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;26<br/>Total Times Cited:&nbsp;&nbsp;27<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","Alzheimer&apos; COHORT; deep learning; DISEASE; early detection; FEATURES; LANGUAGE; MILD COGNITIVE IMPAIRMENT; PROGRESSION; RECOGNITION; s disease; spontaneous speech; SPONTANEOUS SPEECH; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ESUWK3Z5","journalArticle","2024","Bang, JU; Han, SH; Kang, BO","Alzheimer's disease recognition from spontaneous speech using large language models","ETRI JOURNAL","","1225-6463","10.4218/etrij.2023-0356","","We propose a method to automatically predict Alzheimer's disease from speech data using the ChatGPT large language model. Alzheimer's disease patients often exhibit distinctive characteristics when describing images, such as difficulties in recalling words, grammar errors, repetitive language, and incoherent narratives. For prediction, we initially employ a speech recognition system to transcribe participants' speech into text. We then gather opinions by inputting the transcribed text into ChatGPT as well as a prompt designed to solicit fluency evaluations. Subsequently, we extract embeddings from the speech, text, and opinions by the pretrained models. Finally, we use a classifier consisting of transformer blocks and linear layers to identify participants with this type of dementia. Experiments are conducted using the extensively used ADReSSo dataset. The results yield a maximum accuracy of 87.3% when speech, text, and opinions are used in conjunction. This finding suggests the potential of leveraging evaluation feedback from language models to address challenges in Alzheimer's disease recognition.","2024-02","2025-02-26 20:37:00","2025-02-26 20:37:00","","96-105","","1","46","","","","","","","","","","English","","","","WOS:001153525400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Alzheimer's disease; dementia; dementia detection; large language model; pretrained model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RRUS39WY","journalArticle","2021","Gosztolya, G; Balogh, R; Imre, N; Egas-López, JV; Hoffmann, I; Vincze, V; Tóth, L; Devanand, DP; Pákáski, M; Kálmán, J","Cross-lingual detection of mild cognitive impairment based on temporal parameters of spontaneous speech","COMPUTER SPEECH AND LANGUAGE","","0885-2308","10.1016/j.csl.2021.101215","","Mild Cognitive Impairment (MCI) is a heterogeneous clinical syndrome, often considered as the prodromal stage of dementia. It is characterized by the subtle deterioration of cognitive functions, including memory, executive functions and language. Mainly due to the tenuous nature of these impairments, a high percentage of MCI cases remain undetected. There is evidence that language changes in MCI are present even before the manifestation of other distinctive cognitive symptoms, which offers a chance for early recognition. A cheap noninvasive way of early screening could be the use of automatic speech analysis. Earlier, our research team developed a set of speech temporal parameters, and demonstrated its applicability for MCI detection. For the automatic extraction of these attributes, a Hungarian -language ASR system was employed to match the native language of the MCI and healthy control (HC) subjects. In practical applications, however, it would be convenient to use exactly the same tool, regardless of the language spoken by the subjects. In this study we show that our temporal parameter set, consisting of articulation rate, speech tempo and various other attributes describing the hesitation of the subject, can indeed be reliably extracted regardless of the language of the ASR system used. For this purpose, we performed experiments both on English-speaking and on Hungarian-speaking MCI patients and healthy control subjects, using English and Hungarian ASR systems in both cases. Our experimental results indicate that the language on which the ASR system was trained only slightly affects the MCI classification performance, because we got quite similar scores (67-92%) as we did in the monolingual cases (67-92% as well). As our last investigation, we compared the proposed attribute values for the same utterances, utilizing both the English and the Hungarian ASR models. We found that the articulation rate and speech tempo values calculated based on the two ASR models were highly correlated, and so were the attributes corresponding to silent pauses; however, noticeable differences were found regarding the filled pauses (still, these attributes remained indicative for both languages). Our further analysis revealed that this is probably due to a difference regarding the annotation of the English and the Hungarian ASR training utterances. (c) 2021 Published by Elsevier Ltd.","2021-09","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","69","","","","","","","","","","English","","","","WOS:000646337600006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Automatic speech recognition; CLASSIFICATION; Cross-linguality; Dementia; Mild cognitive impairment; PAUSES; SPEAKER; SUPPORT; Temporal speech parameters","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B253WPMC","journalArticle","2023","da Silva, SL; Alves, LM; Britto, DBDE","Profile of fluency in spontaneous speech, reading, and retelling of texts by adults who stutter","CODAS","","2317-1782","10.1590/2317-1782/20232022009en","","Purpose: to describe the profile of fluency concerning the typology of disfluencies, speed, and frequency of disruptions in spontaneous speech, reading, and retelling; to compare the fluency profile in adults who stutter in spontaneous speech, reading, and retelling of text. Methods: The present work is a cross-sectional comparative study with a sample composed of 15 adults who stutter of both sexes, with higher education or equivalent to complete elementary school II. Samples were collected in the tasks of spontaneous speech, reading, and text retelling through video calls made individually with the participants. The first 200 syllables expressed in each task were transcribed and analyzed according to the Fluency Profile Assessment Protocol (FPAP). The study compared the frequency of common and stuttering disfluencies and the speed in the different tasks surveyed. The Kruskal & Wallis test was used together with Duncan's multiple comparisons test to compare the medians and verify possible differences between the tasks researched with a significance level of 5%. Results: The reading task presented a lower number of common disfluencies and a percentage of speech discontinuity about spontaneous speech and retelling tasks. No statistically significant differences were found between stuttering disfluencies in the three tasks surveyed. Conclusion: This study showed that there are differences in the occurrence of common disfluencies - hesitations, interjections, and revisions - and in the percentage of speech discontinuity during an oral reading of adults who stutter concerning spontaneous speech and text retelling.","2023","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","5","35","","","","","","","","","","English","","","","WOS:001222906200011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;10</p>","","","Adulto; cio na Inf & acirc; Fala; Fonoaudiologia; Gagueirax; Leitura; ncia; ncia com In & iacute; Transtorno da Flu & ecirc","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4PBGBBHW","journalArticle","2024","Kleih, SC; Botrel, L","Post-stroke aphasia rehabilitation using an adapted visual P300 brain-computer interface training: improvement over time, but specificity remains undetermined","FRONTIERS IN HUMAN NEUROSCIENCE","","1662-5161","10.3389/fnhum.2024.1400336","","Introduction This study aimed to evaluate the efficacy of visual P300 brain-computer interface use to support rehabilitation of chronic language production deficits commonly experienced by individuals with a left-sided stroke resulting in post-stroke aphasia.Methods The study involved twelve participants, but five dropped out. Additionally, data points were missing for three participants in the remaining sample of seven participants. The participants underwent four assessments-a baseline, pre-assessment, post-assessment, and follow-up assessment. Between the pre-and post-assessment, the participants underwent at least 14 sessions of visual spelling using a brain-computer interface. The study aimed to investigate the impact of this intervention on attention, language production, and language comprehension and to determine whether there were any potential effects on quality of life and well-being.Results None of the participants showed a consistent improvement in attention. All participants showed an improvement in spontaneous speech production, and three participants experienced a reduction in aphasia severity. We found an improvement in subjective quality of life and daily functioning. However, we cannot rule out the possibility of unspecific effects causing or at least contributing to these results.Conclusion Due to challenges in assessing the patient population, resulting in a small sample size and missing data points, the results of using visual P300 brain-computer interfaces for chronic post-stroke aphasia rehabilitation are preliminary. Thus, we cannot decisively judge the potential of this approach.","2024-05-30","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","18","","","","","","","","","","English","","","","WOS:001244471100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","aphasia; ATTENTION; brain-computer interface (BCI); LANGUAGE THERAPY; P300-event related potential; PERFORMANCE; POWER; PSYCHOPHYSIOLOGY; quality of life; RECOVERY; rehabilitation; SPEECH; stroke","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HXFCJJ3I","journalArticle","2023","Weintraub, MJ; Posta, F; Ichinose, MC; Arevian, AC; Miklowitz, DJ","Word usage in spontaneous speech as a predictor of depressive symptoms among youth at high risk for mood disorders","JOURNAL OF AFFECTIVE DISORDERS","","0165-0327","10.1016/j.jad.2022.12.047","","Background: We examined whether digital phenotyping of spontaneous speech, such as the use of specific word categories during speech samples, was associated with depressive symptoms in youth who were at familial and clinical risk for mood disorders. Methods: Participants (ages 13-19) had active mood symptoms, mood instability, and at least one parent with bipolar or major depressive disorder. During a randomized trial of family-focused therapy, participants were instructed to make weekly calls to a central voice server and leave speech samples in response to automated prompts. We coded youths' speech samples with the Linguistic Inquiry and Word Count system and used machine learning to identify the combination of speech features that were most closely associated with the course of depressive symptoms over 18 weeks. Results: A total of 253 speech samples were collected from 44 adolescents (mean age = 15.8 years; SD = 1.6) over 18 weeks. Speech containing affective processes, social processes, drives toward risk or reward, nonfluencies, and time orientation words were correlated with depressive symptoms at concurrent time periods (ps < 0.01). Ma-chine learning analyses revealed that affective processes, nonfluencies, drives and risk words combined to most strongly predict changes in depressive symptoms over 18 weeks of treatment. Limitations: Study results were limited by the small sample and the exclusion of paralinguistic or contextual variables in analyzing speech samples. Conclusions: In youth at high risk for mood disorders, knowledge of speech patterns may inform prognoses during outpatient psychosocial treatment.","2023-02-15","2025-02-26 20:37:00","2025-02-26 20:37:00","","675-678","","","323","","","","","","","","","","English","","","","WOS:000906356300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","Adolescents; ADOLESCENTS; Bipolar; CHILDREN; Depression; Family -focused therapy; Linguistic; LIWC; Machine learning; MANIA; RELIABILITY; SCALE; VALIDITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HT5RAWCB","journalArticle","2023","Ní Chéileachair, F; Chondrogianni, V; Sorace, A; Paradis, J; De Aguiar, V","Developmental language disorder in sequential bilinguals: Characterising word properties in spontaneous speech","JOURNAL OF CHILD LANGUAGE","","0305-0009","10.1017/S0305000922000241","","The current study sought to investigate whether word properties can facilitate the identification of developmental language disorder (DLD) in sequential bilinguals by analyzing properties in nouns and verbs in L2 spontaneous speech as potential DLD markers. Measures of semantic (imageability, concreteness), lexical (frequency, age of acquisition) and phonological (phonological neighbourhood, word length) properties were computed for nouns and verbs produced by 15 sequential bilinguals (5;7) with DLD and 15 age-matched controls with diverse L1 backgrounds. Linear mixed modelling revealed a significant interaction of group and word category on phonological neighbourhood values but no differences across imageability, concreteness, frequency, age of acquisition, and word length measures in spontaneous speech. Outcomes suggest that group-level differences may not be apparent at the word-level, due to the heterogeneous nature of DLD and potential similarities in production during early L2 acquisition.","2023-07","2025-02-26 20:37:00","2025-02-26 20:37:00","","954-980","","4","50","","","","","","","","","","English","","","","WOS:000792175300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","ACQUISITION; AGE; CHILDREN; developmental language disorder; FREQUENCY; IMAGEABILITY; IMPAIRMENT; MORPHOLOGY; PHONOLOGICAL SIMILARITY; SEMANTIC DEFICITS; sequential bilingualism; spontaneous speech; VOCABULARY; word properties","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GBXUDRME","journalArticle","2023","Sotome, T; Kanazawa, T; Konomi, U; Maeara, N; Misawa, K; Takahashi, S; Fukaura, J; Watanabe, Y","Analysis of Speech Fundamental Frequencies for Different Tasks in Japanese","JOURNAL OF VOICE","","0892-1997","10.1016/j.jvoice.2020.12.021","","Purpose. Speech fundamental frequency (SFF) assessment is essential for all dysphonia patients to effectively evaluate the therapeutic effects of voice therapy, especially in patients with disturbances in their voice pitch due to mutational dysphonia, Reinke's edema, or as side effects of hormone therapy. A standard method of SFF measurement remains unknown. Speech tasks such as sustained vowel phonation, counting, reading passage, and spontaneous speech have generally been used for SFF measurements. Ideally, spontaneous speech best reflects SFF; however, this task has not yet been clearly defined and is limited with regard to its adaptation to a clinical setting. A reliable task for SFF measurement in Japanese, which corresponds to a speech task that most closely reflects the value that would be observed with typical spontaneous speech, has not been investigated. This study aimed to identify a reliable speech task by measuring the SFF values elicited by different widely used speech tasks in Japanese, and assess its reliability and coefficient of determination (R-2).Methods. Sixty healthy volunteers (30 men and 30 women; aged 19-30 years; mean age 22.5 years) were enrolled. All experimental procedures were performed in Japanese. The SFF values for the speech tasks were determined through the voice samples recorded using a Pulse Code Modulation (PCM) recorder. Each task, except spontaneous speech, was repeated five times, and the average fundamental frequency in each task was determined as the SFF. To assess the reliability of the SFF values across daily variations within individual speakers, the SFF measurements were repeated on two different days, separated by at least 1 week.Results. The SFF values of sustained /a/ phonation, sustained vowel-average, counting, reading passage, and spontaneous speech had excellent reliability, in terms of their reproduction based on intraclass correlation. Significantly high SFF values were observed, in decreasing order, for sustained vowels-average, counting, reading pas -sage, and spontaneous speech in both males and females. The highest R-2 for spontaneous speech was that of reading passage in both males (R-2 = 0.771) and females (R-2 = 0.806) (P < 0.01).Conclusion. When spontaneous speech was presented as a task most reflective of daily conversation, reading passage was determined to be the reliable task to assess the therapeutic effect of voice therapy in Japanese.","2023-03","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","2","37","","","","","","","","","","English","","","","WOS:000972469300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","Acoustic analysis; Coeffi- cient of determination; DURATION; Dysphonia; Intraclass correlation; SPEAKING; Speech fundamental frequency; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"72N2QTUP","journalArticle","2024","Lu, AL; Su, DJ","Shadowing textbook and authentic materials in beginning L2 learners' acquisition of Mandarin Chinese tones in spontaneous speech","JOURNAL OF SECOND LANGUAGE PRONUNCIATION","","2215-1931","10.1075/jslp.22033.lu","","Addressing the lack of research examining the use of discourse-level speech input in beginning L2 learners' Mandarin tone production in spontaneous speech, this study compares the effects of authentic videos and textbook audios as shadowing materials on beginners' multisyllabic tone production in spontaneous speech and learner attitudes. Fourteen college students, randomly divided into the ""authentic"" and ""textbook"" groups, shadowed for four weeks. From the pretest to the posttest, both groups significantly improved tone accuracy in sentence-level spontaneous speech with no significant differences between groups. Quantitative and qualitative analyses of learners' responses show that (1) both groups had positive attitudes toward the materials, (2) authentic materials generated greater interest, and learners appreciated shadowing authentic conversations or conversations that mimic natural discourse, and (3) the learners primarily cared about whether the materials were comprehensible, interesting, and accessible. The findings shed light on using authentic materials to teach L2 pronunciation.","2024-07-01","2025-02-26 20:37:00","2025-02-26 20:37:00","","59-84","","1","10","","","","","","","","","","English","","","","WOS:001260416200005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","ABILITY; authentic materials; beginning L2 learners; EXPERIENCE; IDENTIFICATION; learner attitudes; Mandarin tones; PERCEPTION; pronunciation; shadowing; SPOKEN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WMJSCTXD","journalArticle","2022","Andayani, F; Theng, LB; Tsun, MT; Chua, C","Hybrid LSTM-Transformer Model for Emotion Recognition From Speech Audio Files","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3163856","","Emotion is a vital component in daily human communication and it helps people understand each other. Emotion recognition plays a crucial role in developing human-computer interaction and computer-based speech emotion recognition. In a nutshell, Speech Emotion Recognition (SER) recognizes emotion signals transmitted through human speech or daily conversation where the emotions in a speech strongly depend on temporal information. Despite the fact that much existing research showed that a hybrid system performs better than traditional single classifiers used in SER, there are some limitations in each of them. As a result, this paper discussed a proposed hybrid Long Short-Term Memory (LSTM) Network and Transformer Encoder to learn the long-term dependencies in speech signals and classify emotions. Speech features are extracted with Mel Frequency Cepstral Coefficient (MFCC) and fed into the proposed hybrid LSTM-Transformer classifier. A range of performance evaluations was conducted on the proposed LSTM-Transformer model. The results indicate that it achieves a significant recognition improvement compared with existing models offered by other published works. The proposed hybrid model reached 75.62%, 85.55%, and 72.49% recognition success with the RAVDESS, Emo-DB, and language-independent datasets.","2022","2025-02-26 20:37:00","2025-02-26 20:37:00","","36018-36027","","","10","","","","","","","","","","English","","","","WOS:000779604400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;46<br/>Total Times Cited:&nbsp;&nbsp;51<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Attention mechanism; Convolutional neural networks; Emotion recognition; Feature extraction; long short-term memory network; Spectrogram; speech emotion recognition; Speech recognition; Task analysis; transformer encoder; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AS32EPY7","journalArticle","2021","Albuquerque, L; Valente, ARS; Teixeira, A; Oliveira, C; Figueiredo, D","Age and gender effects in European Portuguese spontaneous speech","LOQUENS","","2386-2637","10.3989/loquens.2021.077","","Aging is part of the normal evolution of human beings. However, the knowledge about speech in the older ages is still dispersed and incomplete. Considering conflicting findings reported in prior research, this study aims to contribute to increase our knowledge about age effects on the spontaneous speech of Portuguese adults. In order to analyze the effects of age on rhythmic, intonation and voice quality domains, several parameters were extracted from spontaneous speech produced by 112 adults, aged between 35 and 97. Data were obtained through a picture description task. The results showed that the most consistent age-related effects are an increase in speech pauses, mainly in men, and a Harmonics-to-Noise Ratio (HNR) decrease in women. Speaking fundamental frequency (f(0)) tends to decrease in women and to slightly increase in men with age. These findings for Portuguese are in line with previous research suggesting that suprasegmental characteristics of speech change with age, with some gender differences.","2021-12","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","1-2","8","","","","","","","","","","English","","","","WOS:000791548700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","aging; DIALECT; FUNDAMENTAL-FREQUENCY; IMPACT; rhythm; SPEAKERS; speaking fundamental frequency; spontaneous speech; VOICE DATA; YOUNG","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E3RE6PXT","journalArticle","2022","Eren, Ö; Kilic, M; Bada, E","Fluency in L2: Read and Spontaneous Speech Pausing Patterns of Turkish, Swahili, Hausa and Arabic Speakers of English","JOURNAL OF PSYCHOLINGUISTIC RESEARCH","","0090-6905","10.1007/s10936-021-09822-y","","Language learners' actual speech performances constitute an essential aspect of studies on second language learning and teaching. Although there is ample research on fluency and pauses in English, current literature does not touch on this issue from a multilingual perspective by comparing both read and spontaneous speech performances. In this descriptive study, the researchers investigated pausing patterns with 40 Turkish, Swahili, Hausa, and Arabic speakers of English. For the read speech fragments' elicitation, the participants read out a short story, and for spontaneous speech, the data was gathered through structured interviews. In total, 4007 pauses were measured through Praat, and the findings obtained from the data were analyzed using multiple regression and several multivariate analyses of variance. The findings revealed crucial insights into the nature of fluency research in terms of (a) speech registers, (b) positions, (c) conjunctions, and (d) mother tongues.","2022-04","2025-02-26 20:37:00","2025-02-26 20:37:00","","237-253","","2","51","","","","","","","","","","English","","","","WOS:000722968000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Conjunctions; Fluency; LEARNERS; Pause; PAUSES; PERCEPTIONS; Read speech; Spontaneous speech; THOUGHT; UTTERANCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MKW5LRGM","journalArticle","2021","Yamada, Y; Shinkawa, K; Nemoto, M; Arai, T","Automatic Assessment of Loneliness in Older Adults Using Speech Analysis on Responses to Daily Life Questions","FRONTIERS IN PSYCHIATRY","","1664-0640","10.3389/fpsyt.2021.712251","","Loneliness is a perceived state of social and emotional isolation that has been associated with a wide range of adverse health effects in older adults. Automatically assessing loneliness by passively monitoring daily behaviors could potentially contribute to early detection and intervention for mitigating loneliness. Speech data has been successfully used for inferring changes in emotional states and mental health conditions, but its association with loneliness in older adults remains unexplored. In this study, we developed a tablet-based application and collected speech responses of 57 older adults to daily life questions regarding, for example, one's feelings and future travel plans. From audio data of these speech responses, we automatically extracted speech features characterizing acoustic, prosodic, and linguistic aspects, and investigated their associations with self-rated scores of the UCLA Loneliness Scale. Consequently, we found that with increasing loneliness scores, speech responses tended to have less inflections, longer pauses, reduced second formant frequencies, reduced variances of the speech spectrum, more filler words, and fewer positive words. The cross-validation results showed that regression and binary-classification models using speech features could estimate loneliness scores with an R-2 of 0.57 and detect individuals with high loneliness scores with 95.6% accuracy, respectively. Our study provides the first empirical results suggesting the possibility of using speech data that can be collected in everyday life for the automatic assessments of loneliness in older adults, which could help develop monitoring technologies for early detection and intervention for mitigating loneliness.","2021-12-13","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","12","","","","","","","","","","English","","","","WOS:000735585300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;98</p>","","","ACOUSTIC MEASURES; ALZHEIMERS-DISEASE; CLASSIFICATION; COGNITIVE IMPAIRMENT; DEPRESSION SEVERITY; EMOTION; HEALTH; health-monitoring; mental health; MORTALITY; RISK; social connectedness; SOCIAL-ISOLATION; speech analysis and processing; voice","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TNBL5IYC","journalArticle","2024","Agbavor, F; Liang, HL","Multilingual Prediction of Cognitive Impairment with Large Language Models and Speech Analysis","BRAIN SCIENCES","","2076-3425","10.3390/brainsci14121292","","Background: Cognitive impairment poses a significant global health challenge, emphasizing the critical need for early detection and intervention. Traditional diagnostics like neuroimaging and clinical evaluations are often subjective, costly, and inaccessible, especially in resource-poor settings. Previous research has focused on speech analysis primarily conducted using English data, leaving multilingual settings unexplored. Methods: In this study, we present our results from the INTERSPEECH 2024 TAUKADIAL Challenge, where we aimed to automatically detect mild cognitive impairment (MCI) and predict cognitive scores for English and Chinese speakers (169 in total). Our approach leverages Whisper, a speech foundation model, to extract language-agnostic speech embeddings. We then utilize ensemble models to incorporate task-specific information. Results: Our model achieved unweighted average recall of 81.83% in an MCI classification task, and root mean squared error of 1.196 in cognitive score prediction task, which placed the model at the second and the first position, respectively, in the ranking for each task. Comparison between language-agnostic and language-specific models reveals the importance of capturing language-specific nuances for accurate cognitive impairment prediction. Conclusions: This study demonstrates the effectiveness of language-specific ensemble modeling with Whisper embeddings in enabling scalable, non-invasive cognitive health assessments of Alzheimer's disease, achieving state-of-the-art results in multilingual settings.","2024-12","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","12","14","","","","","","","","","","English","","","","WOS:001387743800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","ALZHEIMERS-DISEASE; dementia detection; DIAGNOSIS; large language model; mild cognitive impairment; MINI-MENTAL-STATE; multilingual processing; speech analysis; whisper","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ALNHMP8G","journalArticle","2023","Feng, KX; Chaspari, T","Few-Shot Learning in Emotion Recognition of Spontaneous Speech Using a Siamese Neural Network With Adaptive Sample Pair Formation","IEEE TRANSACTIONS ON AFFECTIVE COMPUTING","","1949-3045","10.1109/TAFFC.2021.3109485","","Speech-based machine learning (ML) has been heralded as a promising solution for tracking prosodic and spectrotemporal patterns in real-life that are indicative of emotional changes, providing a valuable window into one's cognitive and mental state. Yet, the scarcity of labelled data in ambulatory studies prevents the reliable training of ML models, which usually rely on ""data-hungry"" distribution-based learning. Leveraging the abundance of labelled speech data from acted emotions, this paper proposes a few-shot learning approach for automatically recognizing emotion in spontaneous speech from a small number of labelled samples. Few-shot learning is implemented via a metric learning approach through a siamese neural network, which models the relative distance between samples rather than relying on learning absolute patterns of the corresponding distributions of each emotion. Results indicate the feasibility of the proposed metric learning in recognizing emotions from spontaneous speech in four datasets, even with a small amount of labelled samples. They further demonstrate superior performance of the proposed metric learning compared to commonly used adaptation methods, including network fine-tuning and adversarial learning. Findings from this work provide a foundation for the ambulatory tracking of human emotion in spontaneous speech contributing to the real-life assessment of mental health degradation.","2023-04","2025-02-26 20:37:00","2025-02-26 20:37:00","","1627-1633","","2","14","","","","","","","","","","English","","","","WOS:001000299100057","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","ADVERSARIAL; Emotion recognition; few-shot learning; metric learning; scripted/spontaneous speech; siamese neural network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZJINKT69","journalArticle","2023","Bruno, E; Martz, E; Weiner, L; Greco, A; Vanello, N","Speech signal analysis as an aid to clinical diagnosis and assessment of mental health disorders","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2023.104854","","Objective: In this study, we estimate speech features from different Verbal Fluency Tests (VFT) conditions to distinguish comorbid Bipolar Disorder (BD) in adults suffering from Attention Deficit Hyperactivity Disorder (ADHD) and to identify ADHD subtypes such as the inattentive (ADHD-I) from the combined one (ADHD-C). Methods: Prosodic and spectral features in five conditions of VFTs were extracted and selected for the classification performed with machine learning methods. Specifically, a Support Vector Machine exploiting Recursive Features Elimination (SVM-RFE) has been trained with clinical scores and exploiting the within subject variability of speech features across VFT conditions. The final classification was optimized by combining the marginal classification outcomes obtained from the different VFTs using a voting scheme. Results: Our results show that we successfully classify the ADHD+BD comorbidity and the ADHD subtypes according to clinician diagnosis. The results are discussed in the light of possible benefits of developing such approach within clinical research. Conclusion: Significant information is carried out by speech audio features acquired with VFTs, allowing to classify ADHD subtypes and comorbid patterns. This work clearly shows that the audio analysis of speech, along with properly designed speech tasks, is a candidate for the development of clinical decision support systems in psychiatry. Significance: This work represents a major contribution to the applications of speech analysis in ADHD subjects and could support clinicians by identifying objective biomarkers.","2023-08","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","85","","","","","","","","","","English","","","","WOS:000989697700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Acoustic analysis; ADULT ADHD; Attention Deficit Hyperactivity Disorder; ATTENTION-DEFICIT/HYPERACTIVITY DISORDER; Bipolar Disorder; DEFICIT HYPERACTIVITY DISORDER; DEPRESSION; EMOTION; FEATURES; PERFORMANCE; PREVALENCE; Speech features; SVM-RFE; Verbal fluency tests","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2P7P2NZG","journalArticle","2022","Haas, M; Mehl, MR; Ballhausen, N; Zuber, S; Kliegel, M; Hering, A","The Sounds of Memory: Extending the Age-Prospective Memory Paradox to Everyday Behavior and Conversations","JOURNALS OF GERONTOLOGY SERIES B-PSYCHOLOGICAL SCIENCES AND SOCIAL SCIENCES","","1079-5014","10.1093/geronb/gbac012","","Objectives Around the turn of the millennium, the ""age-prospective memory (PM) paradox"" challenged the classical assumption that older adults necessarily evidence a marked decline in PM functioning. As previous investigations highlighted ecological validity to be a potential explanation, the present study sought to extend established approaches by using novel real-world assessment technologies to examine PM unobtrusively in everyday-life conversations. Method Next to laboratory PM tasks, real-life PM performance of 53 younger adults (19-32 years) and 38 older adults (60-81 years) was assessed from three sources: Over 9 days, participants completed an experimenter-given naturalistic task, a diary-based approach assessing self-assigned intentions, as well as an ambulatory assessment with the Electronically Activated Recorder (EAR), a device that unobtrusively samples ambient sounds to detect spontaneous speech production related to (lapses in) everyday PM. Results Older adults showed lower performance in laboratory PM only for the time-based task and performed either equally well as or even better than younger adults in everyday PM. With regard to PM performance as captured in real-life ambient audio data, younger adults talked more frequently about PM than older adults, but no significant difference between younger and older adults was found for speech related to PM errors. Discussion Findings confirmed older adults' preserved PM performance in everyday life across different indicators with increasing ecological validity. Furthermore, as a novel method to assess conversational PM in everyday life, the EAR opens new insights about the awareness of PM lapses and the communication of intentions in real life.","2022-04-01","2025-02-26 20:37:00","2025-02-26 20:37:00","","695-703","","4","77","","","","","","","","","","English","","","","WOS:000767420600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","ADULTHOOD; Ambulatory assessment; Ecological validity; Electronically activated recorder; Everyday cognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HAGL7Z9S","journalArticle","2022","Guo, CY; Chen, F; Yan, JT; Gao, XT; Zhu, M","Atypical prosodic realization by Mandarin-speaking autistic children: Evidence from tone sandhi and neutral tone","JOURNAL OF COMMUNICATION DISORDERS","","0021-9924","10.1016/j.jcomdis.2022.106280","","Introduction Atypical prosodic features have been widely reported in autism spectrum disorder (ASD), primarily in non-tonal language speakers. Nevertheless, the prosodic realizations in autistic people who speak tonal languages were relatively understudied. This study aimed to investigate the acoustic and phonetic patterns at the word-level speech in Mandarin-speaking autistic and typically developing (TD) children at different age ranges. Methods Thirty Mandarin-speaking autistic children (15 three- to five-year-olds and 15 six- to eight-year-olds) were recruited into the ASD group. The TD group consisted of 30 age- and gender-matched children. We employed a picture-naming task to elicit the spontaneous speech production of Mandarin disyllabic words in which tone change processes occur, namely Tone 3 (T3) sandhi and neutral tone (T0). Results The phonetic analysis showed that the ASD group generally could produce typical-like T3 sandhi and T0 in terms of pitch height. However, relative to the TD group, they exhibited flatter pitch contours during T3 sandhi production. Moreover, the acoustic pitch mean of citation tones in the ASD group was also significantly higher, accompanied by more rigid pitch curves in contour tones. In addition, the atypical temporal realization in the ASD group was manifested by the longer duration of T0 and the earlier inflection position of T3. Conclusions Mandarin-speaking autistic children under eight had the phonological ability to produce context-dependent tones based on connected tonal information at the word level. Nevertheless, their phonetic prosodic realization of tone change processes was atypical. Our findings provide evidence of atypical prosody in autistic children who speak tone languages. Clinically, these findings may be attributable to underlying neural differences in autistic children.","2022-11","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","100","","","","","","","","","","English","","","","WOS:001035653300003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","ACQUISITION; Autism spectrum disorder; HIGH-FUNCTIONING AUTISM; Mandarin-speaking children; PATTERNS; Prosodic realization; SPEAKERS; SPEECH; STRESS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WTHJANS9","journalArticle","2024","Barker, MS; Knight, JL; Dean, RJ; Richards, LJ; Robinson, GA","Adynamic spoken language in corpus callosum dysgenesis","CORTEX","","0010-9452","10.1016/j.cortex.2024.07.021","","Corpus callosum dysgenesis (CCD) is a congenital brain malformation that occurs when the development of the corpus callosum is disrupted, either partially or completely. The cognitive outcomes in individuals with CCD vary greatly, but generally the neuropsychological profile is characterised by slow processing speed, poor transfer of interhemispheric sensory-motor information, and impaired complex problem solving. Core language skills are often preserved in CCD, but there is some evidence that complex language may be impaired. Thus, the current study sought to examine whether spontaneous speech output was reduced in a cohort of individuals with CCD compared to age-matched controls. We further explored a series of factors that may be contributing to poor spontaneous speech in CCD, such as difficulties generating, selecting, and sequencing ideas for expression, as well as apathy and slowed processing speed. A cohort of 25 individuals with CCD and 39 neurotypical controls were enrolled in this study. Participants completed a picture description task to measure spontaneous speech output, alongside a series of cognitive and language baseline tests. Verbal and nonverbal fluency tasks gauged idea generation and sequencing, and sentence-level selection tasks measured idea selection. We found that, despite having largely intact core language skills, individuals with CCD produced significantly less spontaneous speech on the picture description task than controls. This language profile may be described as ""adynamic"". Further, we found that poor spontaneous speech output in CCD was related to problems generating ideas for expression, as individuals with CCD performed below controls on the verbal and nonverbal fluency tasks. Exploratory analyses revealed that apathy and slowed processing speed may be contributing factors. Adynamia in CCD is a novel finding that may be an intervention target for improving communication skills in this population. (c) 2024 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).","2024-11","2025-02-26 20:37:00","2025-02-26 20:37:00","","42-54","","","180","","","","","","","","","","English","","","","WOS:001322513900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Adynamia; AGENESIS; Apathy; COMPREHENSION; Corpus callosum dysgenesis; DEFICITS; DYNAMIC APHASIA; FLUENCY; GENERATION; INDIVIDUALS; PROGRESSIVE SUPRANUCLEAR PALSY; SELECTION; SPEECH PRODUCTION; Spontaneous speech; Verbal fluency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AT5L9C6A","journalArticle","2024","Garcia, M","The Intonation of Peruvian Amazonian Spanish Declaratives: An Exploration of Spontaneous Speech","LANGUAGES","","2226-471X","10.3390/languages9020061","","The present study explores intonational patterns in spontaneous speech in Peruvian Amazonian Spanish (PAS). The data came from 12 monolingual Spanish speakers in the city of Pucallpa, where the Spanish language has historically been in contact with the Amazonian language Shipibo-Konibo. The speakers responded to an open-ended prompt that elicited broad focus declaratives. Acoustic information from 1524 pitch accents was extracted from 194 sentences and analyzed using Praat. The analysis focused on five features: F0 rises, F0 peak alignment, downstepping, final lowering, and cases of stress clash. The results not only supported previous research on this variety that came from read speech tasks (e.g., F0 peaks consistently aligned with the stressed syllable), but also highlighted the importance of using multiple methodologies to gain a more comprehensive understanding of PAS prosody. Specifically, the varied sentence lengths and structures common in spontaneous speech provided new insights into downstepping, final lowering, and stress clash in PAS intonation. Overall, these results contribute to the growing literature on Spanish prosody in shared linguistic spaces and lend support for trends (such as F0 peak alignment) that have been reported in other language contact varieties.","2024-02","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","2","9","","","","","","","","","","English","","","","WOS:001172282000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","intonation; Peruvian Amazonian Spanish; prosody; spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZIJ6C4T3","journalArticle","2021","Li, YW; Tao, JH; Erickson, D; Liu, B; Akagi, M","F0-Noise-Robust Glottal Source and Vocal Tract Analysis Based on ARX-LF Model","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2021.3120585","","This paper proposes a robust automatic speech analysis method based on a source-filter model constructed of an Auto-Regressive eXogenous (ARX) model and the Liljencrants-Fant (LF) model. The proposed method estimates glottal source waveform and vocal tract shape parameters using an analysis-by-synthesis approach. Structurally, the first step is to initialize the glottal source parameters using the inverse filter method, and the second step is to simultaneously estimate the glottal source waveform and the vocal tract shape parameters using an analysis-by-synthesis approach with an iterative algorithm. The proposed method was verified on synthetic voices with different glottal noise (signal to noise ratio) from 0 dB to 50 dB and different fundamental frequency (F-0) from 80 Hz to 320 Hz levels. The results show that the proposed method achieved a much higher estimation accuracy than that of the state-of-the-art inverse filtering methods on both different glottal noise and different F-0 levels.","2021","2025-02-26 20:37:00","2025-02-26 20:37:00","","3375-3383","","","29","","","","","","","","","","English","","","","WOS:000717754300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","ARX-LF model; Brain modeling; EPOCH EXTRACTION; Estimation; FLOW; Glottal source; Iterative methods; LINEAR PREDICTION; Low-frequency noise; Production; Shape; source-filter model; Speech recognition; vocal tract; WAVE-FORM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3LMMG7RI","journalArticle","2023","Gulyaeva, NI","Hesitation phenomena in spontaneous Komi speech","VESTNIK UGROVEDENIYA-BULLETIN OF UGRIC STUDIES","","2220-4156","10.30624/2220-4156-2023-13-3-416-424","","Introduction: the article analyzes the hesitation phenomena most often found in Komi spontaneous speech; it provides a general typology of hesitation markers used by a communicant in a hesitation situation. Objective: to identify and describe the most common markers of hesitation that occur in Komi spontaneous speech; to determine their main functions based on the analysis of their use in the structure of an utterance. Research materials: hezitation phenomena excerpted from the spontaneous speech of participants of Komi-language programs on television and radio, aired in 2017-2023; examples from Komi works of art. Results and novelty of the research: for the first time in the article the hesitation phenomena occurring in the Komi spontaneous speech are comprehensively analyzed; their pragmatic features are described. It is established that the main hesitation phenomena common in Komi speech are hesitation pauses (verbal and nonverbal), repetitions, and autocorrections. It can be stated that the hesitation phenomena used by communicants in the process of speech production, in most cases contribute to successful communication. The main function for these speech units is the speech organizing function. They ensure the coherence of the discourse and transmit information relating only to the way of organizing and presenting verbal information; in certain situations, they act as fillers for speech pauses, help a speaker to keep the listener's attention, and find right words to continue the conversation. The article presents the classification of hesitation phenomena, determines the specifics of their functioning.","2023","2025-02-26 20:37:00","2025-02-26 20:37:00","","416-424","","3","13","","","","","","","","","","English","","","","WOS:001105899600002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","auto-corrections; hesitation pauses; hesitation phenomena; Komi language; non-verbal hesitation pauses; repetitions; spontaneous speech; verbal hesitation pauses; verbal hesitations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BTS2KCSU","journalArticle","2022","Tonn, P; Seule, L; Degani, Y; Herzinger, S; Klein, A; Schulze, N","Digital Content-Free Speech Analysis Tool to Measure Affective Distress in Mental Health: Evaluation Study","JMIR FORMATIVE RESEARCH","","2561-326X","10.2196/37061","","Background: Mood disorders and depression are pervasive and significant problems worldwide. These represent severe health and emotional impairments for individuals and a considerable economic and social burden. Therefore, fast and reliable diagnosis and appropriate treatment are of great importance. Verbal communication can clarify the speaker's mental state-regardless of the content, via speech melody, intonation, and so on. In both everyday life and clinical conditions, a listener with appropriate previous knowledge or a trained specialist can grasp helpful knowledge about the speaker's psychological state. Using automated speech analysis for the assessment and tracking of patients with mental health issues opens up the possibility of remote, automatic, and ongoing evaluation when used with patients' smartphones, as part of the current trends toward the increasing use of digital and mobile health tools. Objective: The primary aim of this study is to evaluate the measurements of the presence or absence of depressive mood in participants by comparing the analysis of noncontentual speech parameters with the results of the Patient Health Questionnaire-9. Methods: This proof-of-concept study included participants in different affective phases (with and without depression). The inclusion criteria included a neurological or psychiatric diagnosis made by a specialist and fluent use of the German language. The measuring instrument was the VoiceSense digital voice analysis tool, which enables the analysis of 200 specific speech parameters based on machine learning and the assessment of the findings using Patient Health Questionnaire-9. Results: A total of 292 psychiatric and voice assessments were performed with 163 participants (males: n=47, 28.8%) aged 15 to 82 years. Of the 163 participants, 87 (53.3%) were not depressed at the time of assessment, and 88 (53.9%) participants had clinically mild to moderate depressive phases. Of the 163 participants, 98 (32.5%) showed subsyndromal symptoms, and 19 (11.7%) participants were severely depressed. In the speech analysis, a clear differentiation between the individual depressive levels, as seen in the Patient Health Questionnaire-9, was also shown, especially the clear differentiation between nondepressed and depressed participants. The study showed a Pearson correlation of 0.41 between clinical assessment and noncontentual speech analysis (P<.001). Conclusions: The use of speech analysis shows a high level of accuracy, not only in terms of the general recognition of a clinically relevant depressive state in the participants. Instead, there is a high degree of agreement regarding the extent of depressive impairment with the assessment of experienced clinical practitioners. From our point of view, the application of the noncontentual analysis system in everyday clinical practice makes sense, especially with the idea of a quick and unproblematic assessment of the state of mind, which can even be carried out without personal contact.","2022-08","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","8","6","","","","","","","","","","English","","","","WOS:000854086000065","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","ANXIETY; assessment; depression; DEPRESSION; diagnosis; distress; evaluation; measurement; mental health; mHealth; mobile health; mobile phone; mood; questionnaire; speech; speech analysis; tool; voice analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E7CS65YV","journalArticle","2024","He, R; Alonso-Sánchez, MF; Sepulcre, J; Palaniyappan, L; Hinzen, W","Changes in the structure of spontaneous speech predict the disruption of hierarchical brain organization in first-episode psychosis","HUMAN BRAIN MAPPING","","1065-9471","10.1002/hbm.70030","","Psychosis implicates changes across a broad range of cognitive functions. These functions are cortically organized in the form of a hierarchy ranging from primary sensorimotor (unimodal) to higher-order association cortices, which involve functions such as language (transmodal). Language has long been documented as undergoing structural changes in psychosis. We hypothesized that these changes as revealed in spontaneous speech patterns may act as readouts of alterations in the configuration of this unimodal-to-transmodal axis of cortical organization in psychosis. Results from 29 patients with first-episodic psychosis (FEP) and 29 controls scanned with 7 T resting-state fMRI confirmed a compression of the cortical hierarchy in FEP, which affected metrics of the hierarchical distance between the sensorimotor and default mode networks, and of the hierarchical organization within the semantic network. These organizational changes were predicted by graphs representing semantic and syntactic associations between meaningful units in speech produced during picture descriptions. These findings unite psychosis, language, and the cortical hierarchy in a single conceptual scheme, which helps to situate language within the neurocognition of psychosis and opens the clinical prospect for mental dysfunction to become computationally measurable in spontaneous speech. Psychosis involves alterations in the entire cognitive architecture, as organized hierarchically in the cortex from lower-order sensation to higher-order cognitive processes like language. Structural changes in spontaneous language have long been documented in psychosis, but have not been related to neurofunctional changes. This work documents alterations in the cortical hierarchy in the first-episodic psychosis and demonstrates their relation to altered language structures as manifested in spontaneous speech during picture descriptions. Neurofunctional changes affected both the hierarchical distances between sensorimotor and default mode networks, and the hierarchical organization of the semantic network. Moreover, these changes were predicted by graphs representing semantic and syntactic associations between meaningful units. Our findings show the potential of computational measurements of mental disorders via spontaneous speech. image","2024-10","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","14","45","","","","","","","","","","English","","","","WOS:001315962300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","CONNECTIVITY; functional gradient; natural language processing; PERCEPTION; psychosis; REVEALS; SCHIZOPHRENIA; semantic network; spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DFQP3D7E","journalArticle","2022","Almudhi, A","Evaluating adaptation effect in real versus virtual reality environments with people who stutter","EXPERT REVIEW OF MEDICAL DEVICES","","1743-4440","10.1080/17434440.2021.1894124","","Introduction: The adaptation effect refers to the gradual reduction of dysfluencies with repeated exposure to a substance. The concept of adaptation was originally defined in light of the reading task. Yet, limited studies have also confirmed the adaptation effect in spontaneous-speech. The reduction in the dysfluencies can be attributed to the reduction in the anxiety, or getting habituated to the content of reading material or due to motor learning. Methods This research aimed at measuring the adaptation effect in real and virtual reality (VR) environments for spontaneous-speech and reading. The objectives were divided into two categories. The first objective aimed at comparing the adaption effect for the real and VR environments on the reading task, while the second objective addressed the same objective, but for the spontaneous-speech task. The study involved 24 participants in the age range of 19-33 years. SSI-4 was administered on the participants. Conclusion The reduction in dysfluencies was seen for both real and VR testing environments. The reduction in the dysfluency was more marked for reading-task compared to spontaneous-speech task. The results shed light on the relationship between adaptation effect and the test environment.","2022-01-02","2025-02-26 20:37:00","2025-02-26 20:37:00","","75-81","","1","19","","","","","","","","","","English","","","","WOS:000626406000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","COMMUNICATION; dysfluency; FREQUENCY; Real Environment; REPEATED READINGS; SEVERITY; SIZE; stuttering; task Variability; virtual Environment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FDNLDJ6J","journalArticle","2024","Van der Donckt, J; Kappen, M; Degraeve, V; Demuynck, K; Vanderhasselt, MA; Van Hoecke, S","Ecologically valid speech collection in behavioral research: The Ghent Semi-spontaneous Speech Paradigm (GSSP)","BEHAVIOR RESEARCH METHODS","","1554-351X","10.3758/s13428-023-02300-4","","This paper introduces the Ghent Semi-spontaneous Speech Paradigm (GSSP), a new method for collecting unscripted speech data for affective-behavioral research in both experimental and real-world settings through the description of peer-rated pictures with a consistent affective load. The GSSP was designed to meet five criteria: (1) allow flexible speech recording durations, (2) provide a straightforward and non-interfering task, (3) allow for experimental control, (4) favor spontaneous speech for its prosodic richness, and (5) require minimal human interference to enable scalability. The validity of the GSSP was evaluated through an online task, in which this paradigm was implemented alongside a fixed-text read-aloud task. The results indicate that participants were able to describe images with an adequate duration, and acoustic analysis demonstrated a trend for most features in line with the targeted speech styles (i.e., unscripted spontaneous speech versus scripted read-aloud speech). A speech style classification model using acoustic features achieved a balanced accuracy of 83% on within-dataset validation, indicating separability between the GSSP and read-aloud speech task. Furthermore, when validating this model on an external dataset that contains interview and read-aloud speech, a balanced accuracy score of 70% is obtained, indicating an acoustic correspondence between the GSSP speech and spontaneous interviewee speech. The GSSP is of special interest for behavioral and speech researchers looking to capture spontaneous speech, both in longitudinal ambulatory behavioral studies and laboratory studies. To facilitate future research on speech styles, acoustics, and affective states, the task implementation code, the collected dataset, and analysis notebooks are available.","2024-09","2025-02-26 20:37:00","2025-02-26 20:37:00","","5693-5708","","6","56","","","","","","","","","","English","","","","WOS:001123723900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Acoustics; Behavioral research; Experimental research; FEATURES; Machine learning; Psycholinguistics; Speech; Speech collection; Speech styles; STIMULI; STRESS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CR3FYRCE","journalArticle","2024","Bose, A; Ahmed, S; Cheng, YS; Suárez-Gonzalez, A","Connected speech features in non-English speakers with Alzheimer's disease: protocol for scoping review","SYSTEMATIC REVIEWS","","2046-4053","10.1186/s13643-023-02379-y","","BackgroundA large body of literature indicates that connected speech profiles in patients with Alzheimer's disease (AD) can be utilized for diagnosis, disease monitoring, and for developing communication strategies for patients. Most connected speech research has been conducted in English, with little work in some European languages. Therefore, significant drawback remains with respect to the diversity of languages studied, and how the fragmentation of linguistic features differs across languages in AD. Accordingly, existing reviews on connected speech in AD have focused on findings from English-speaking patients; none have specifically focused on the linguistic diversity of AD populations. This scoping review is undertaken to provide the currently reported characteristics of connected speech in AD in languages other than English. It also seeks to identify the type of assessments, methods to elicit speech samples, type of analysis and linguistic frameworks used, and micro- and macro-linguistic features of speech reported in non-English speakers with AD.MethodWe will conduct a scoping review of published studies that have quantitively assessed connected speech in AD in languages other than English. The inclusion criteria for the studies would be subject/s with a clinical diagnosis of AD. The search will include the electronic databases PubMed, Ovid-Embase, PsycINFO, Linguistic and Language Behaviour Abstracts (LLBA), and Web of Science up until March 2023. Findings will be mapped and described according to the languages studied, the methodology employed (e.g., patient characteristics, tasks used, linguistic analysis framework utilized), and connected speech profiles derived (e.g., micro- and macro-linguistic reported).DiscussionThe scoping review will provide an overview of languages studied in connected speech research in AD with variation in linguistic features across languages, thus allowing comparison with the established key features that distinguish AD patients from healthy controls. The findings will inform future research in connected speech in different languages to facilitate robust connected speech research in linguistically and ethnically diverse populations.","2024-01-25","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","1","13","","","","","","","","","","English","","","","WOS:001150665000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","Alzheimer's disease; APHASIA; Connected speech analysis; DECLINE; Dementia; Grammar; Lexicon; MORPHOLOGY; Narrative; Naturalistic speech; Spontaneous speech; Syntax","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZMSUWEBZ","journalArticle","2024","Lange, R; Sell, B; Terada, M; Belz, M; Mooshammer, C; Lüdeling, A","Schwa realisation in verbal inflection in two dialogue registers of German spontaneous speech","ZEITSCHRIFT FUR SPRACHWISSENSCHAFT","","0721-9067","10.1515/zfs-2024-2011","","Word-final schwa in German inflectional suffixes shows varying realisations in spontaneous speech - from full realisations with varying duration to no realisation. While previous research has identified numerous social, distributional, and grammatical factors influencing the variation of phonetic variables in general, it remains unclear how fine-grained functional differences in different registers specifically affect schwa realisation. In this corpus-based study, we compare schwa realisation in two dialogue registers of German spontaneous speech - free conversation and task-based dialogues - which differ only in their communicative goal and therefore have different functional requirements. We find that schwa is rarely realised, though slightly but significantly more often in free conversation than in task-based dialogue. Other factors also promoting schwa realisation across both situations are less frequent verbs and sequences, and IP-final position.","2024-11-26","2025-02-26 20:37:00","2025-02-26 20:37:00","","237-266","","2","43","","","","","","","","","","English","","","","WOS:001290652800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;88</p>","","","ACOUSTIC REDUCTION; CORPUS; DELETION; DUTCH VOWELS; FORM; FREQUENCY; German; phonetic variation; PREDICTABILITY; READ; register; schwa realisation; situational-functional differences; STYLE; TEXT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FCEMHMG9","journalArticle","2022","Wang, YF; Zhang, J; Zhang, B; Jin, Q","Research and Implementation of Chinese Couplet Generation System With Attention Based Transformer Mechanism","IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS","","2329-924X","10.1109/TCSS.2021.3072153","","Couplet is a unique art form in Chinese traditional culture. The development of deep neural network (DNN) technology makes it possible for computers to automatically generate couplets. Especially, Transformer is a DNN-based ``Encoder-Decoder'' framework, and widely used in natural language processing (NLP). However, the existed Transformer mechanism cannot fully exploit the essential linguistic knowledge in Chinese, including the special format and requirements of Chinese couplets. Therefore, this article adapts the Transformer mechanism to generate meaningful Chinese couplets. Specifically, the contributions of our work are threefold. First, considering the fact that the words in the corresponding positions of the antecedent clause and the subsequent clause in a Chinese couplet always have same part-of-speech (pos, i.e., word class), pos information is intentionally added into the Transformer to improve the accuracy of the conceived couplet. Second, to deal with the large number of unregistered and low-frequency words in Chinese couplet, a specific unregistered/low-frequency word processing mechanism (UWP) is designed and combined with the Transformer model. Third, to further improve the coherence of couplets, we incorporate the polish mechanisms (PMs) into Transformer model. In terms of three evaluation criteria including bilingual evaluation understudy (BLEU), perplexity, and human evaluation, the experimental results demonstrate the effectiveness of our designed Chinese couplet generation system.","2022-08","2025-02-26 20:37:00","2025-02-26 20:37:00","","1020-1028","","4","9","","","","","","","","","","English","","","","WOS:000732879000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","Computational modeling; Computers; Decoding; Deep neural network (DNN) based Transformer mechanism; Dictionaries; part-of-speech features; polish-up mechanism; Recurrent neural networks; Semantics; Telecommunications; unregistered and low-frequency words","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9ZMZ2JS4","journalArticle","2022","Kálmán, J; Devanand, DP; Gosztolya, G; Balogh, R; Imre, N; Tóth, L; Hoffmann, I; Kovács, I; Vincze, V; Pákáski, M","Temporal Speech Parameters Detect Mild Cognitive Impairment in Different Languages: Validation and Comparison of the Speech-GAP Test® in English and Hungarian","CURRENT ALZHEIMER RESEARCH","","1567-2050","10.2174/1567205019666220418155130","","Background: The development of automatic speech recognition (ASR) technology allows the analysis of temporal (time-based) speech parameters characteristic of mild cognitive impairment (MCI). However, no information has been available on whether the analysis of spontaneous speech can be used with the same efficiency in different language environments. Objective: The main goal of this international pilot study is to address the question of whether the Speech-Gap Test (R) (S-GAP Test (R)), previously tested in the Hungarian language, is appropriate for and applicable to the recognition of MCI in other languages such as English. Methods: After an initial screening of 88 individuals, English-speaking (n = 33) and Hungarian-speaking (n = 33) participants were classified as having MCI or as healthy controls (HC) based on Petersen's criteria. The speech of each participant was recorded via a spontaneous speech task. Fifteen temporal parameters were determined and calculated through ASR. Results: Seven temporal parameters in the English-speaking sample and 5 in the Hungarian-speaking sample showed significant differences between the MCI and the HC groups. Receiver operating characteristics (ROC) analysis clearly distinguished the English-speaking MCI cases from the HC group based on speech tempo and articulation tempo with 100% sensitivity, and on three more temporal parameters with high sensitivity (85.7%). In the Hungarian-speaking sample, the ROC analysis showed similar sensitivity rates (92.3%). Conclusion: The results of this study in different native-speaking populations suggest that changes in acoustic parameters detected by the S-GAP Test (R) might be present across different languages.","2022","2025-02-26 20:37:00","2025-02-26 20:37:00","","373-386","","5","19","","","","","","","","","","English","","","","WOS:000854465700004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","ALZHEIMERS-DISEASE; CONNECTED SPEECH; early recognition; language; Mild cognitive impairment; neurocognitive disorder; PERFORMANCE; SELECTION; speech analysis; temporal parameters","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DDQ7T64K","journalArticle","2022","Li, HX; Tuo, X","Research on an English translation method based on an improved transformer model","JOURNAL OF INTELLIGENT SYSTEMS","","0334-1860","10.1515/jisys-2022-0038","","With the expansion of people's needs, the translation performance of traditional models is increasingly unable to meet current demands. This article mainly studied the Transformer model. First, the structure and principle of the Transformer model were briefly introduced. Then, the model was improved by a generative adversarial network (GAN) to improve the translation effect of the model. Finally, experiments were carried out on the linguistic data consortium (LDC) dataset. It was found that the average Bilingual Evaluation Understudy (BLEU) value of the improved Transformer model improved by 0.49, and the average perplexity value reduced by 10.06 compared with the Transformer model, but the computation speed was not greatly affected. The translation results of the two example sentences showed that the translation of the improved Transformer model was closer to the results of human translation. The experimental results verify that the improved Transformer model can improve the translation quality and be further promoted and applied in practice to further improve the English translation and meet application needs in real life.","2022-04-29","2025-02-26 20:37:00","2025-02-26 20:37:00","","532-540","","1","31","","","","","","","","","","English","","","","WOS:000788846500002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","English translation; generative adversarial network; GENERATIVE ADVERSARIAL NETWORKS; MACHINE; perplexity value; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D5FCX5QW","journalArticle","2023","Liu, JJ; Wumaier, A; Fan, C; Guo, S","Automatic Fluency Assessment Method for Spontaneous Speech without Reference Text","ELECTRONICS","","2079-9292","10.3390/electronics12081775","","The automatic fluency assessment of spontaneous speech without reference text is a challenging task that heavily depends on the accuracy of automatic speech recognition (ASR). Considering this scenario, it is necessary to explore an assessment method that combines ASR. This is mainly due to the fact that in addition to acoustic features being essential for assessment, the text features output by ASR may also contain potentially fluency information. However, most existing studies on automatic fluency assessment of spontaneous speech are based solely on audio features, without utilizing textual information, which may lead to a limited understanding of fluency features. To address this, we propose a multimodal automatic speech fluency assessment method that combines ASR output. Specifically, we first explore the relevance of the fluency assessment task to the ASR task and fine-tune the Wav2Vec2.0 model using multi-task learning to jointly optimize the ASR task and fluency assessment task, resulting in both the fluency assessment results and the ASR output. Then, the text features and audio features obtained from the fine-tuned model are fed into the multimodal fluency assessment model, using attention mechanisms to obtain more reliable assessment results. Finally, experiments on the PSCPSF and Speechocean762 dataset suggest that our proposed method performs well in different assessment scenarios.","2023-04","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","8","12","","","","","","","","","","English","","","","WOS:000976862400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","automatic fluency assessment; automatic speech recognition; multi-task learning; multimodal; RECOGNITION; spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8YVE3AEG","journalArticle","2023","Robin, J; Xu, MD; Balagopalan, A; Novikova, J; Kahn, L; Oday, A; Hejrati, M; Hashemifar, S; Negahdar, M; Simpson, W; Teng, E","Automated detection of progressive speech changes in early Alzheimer's disease","ALZHEIMER'S & DEMENTIA: DIAGNOSIS, ASSESSMENT & DISEASE MONITORING","","2352-8729","10.1002/dad2.12445","","Speech and language changes occur in Alzheimer's disease (AD), but few studies have characterized their longitudinal course. We analyzed open-ended speech samples from a prodromal-to-mild AD cohort to develop a novel composite score to characterize progressive speech changes. Participant speech from the Clinical Dementia Rating (CDR) interview was analyzed to compute metrics reflecting speech and language characteristics. We determined the aspects of speech and language that exhibited significant longitudinal change over 18 months. Nine acoustic and linguistic measures were combined to create a novel composite score. The speech composite exhibited significant correlations with primary and secondary clinical endpoints and a similar effect size for detecting longitudinal change. Our results demonstrate the feasibility of using automated speech processing to characterize longitudinal change in early AD. Speech-based composite scores could be used to monitor change and detect response to treatment in future research. HIGHLIGHTSLongitudinal speech samples were analyzed to characterize speech changes in early AD.Acoustic and linguistic measures showed significant change over 18 months.A novel speech composite score was computed to characterize longitudinal change.The speech composite correlated with primary and secondary trial endpoints.Automated speech analysis could facilitate remote, high frequency monitoring in AD.","2023-04","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","2","15","","","","","","","","","","English","","","","WOS:001010301100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Alzheimer's disease; CLINICAL-TRIALS; CONNECTED SPEECH; digital biomarkers; language; mild cognitive impairment; natural language processing; speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XIIVJ9BK","journalArticle","2024","Zhou, N; Shang, BW; Zhang, JS; Xu, MM","Research on prediction method of photovoltaic power generation based on transformer model","FRONTIERS IN ENERGY RESEARCH","","2296-598X","10.3389/fenrg.2024.1452173","","Accurate prediction of photovoltaic power generation is of great significance to stable operation of power system. To improve the prediction accuracy of photovoltaic power, a photovoltaic power generation prediction machine learning model based on Transformer model is proposed in this paper. In this paper, the basic principle of Transformer model is introduced. Correlation analysis tools such as Pearson correlation coefficient and Spearman correlation coefficient are introduced to analyze the correlation between various factors and power generation in the photovoltaic power generation process. Then, the prediction results of traditional machine learning models and the Transformer model proposed in this paper were compared and analyzed for errors. The results show that: for long-term prediction tasks such as photovoltaic power generation prediction, Transformer model has higher prediction accuracy than traditional machine learning models. Moreover, compared with BP, LSTM and Bi-LSTM models, the Mean Square Error (MSE) of Transformer model decreases by 70.16%, 69.32% and 62.88% respectively in short-term prediction, and the Mean Square Error (MSE) of Transformer model decreases by 63.58%, 51.02% and 38.3% respectively in long-term prediction, which has good prediction effect. In addition, compared with the long-term prediction effect of Informer model, Transformer model has higher prediction accuracy.","2024-08-05","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","12","","","","","","","","","","English","","","","WOS:001293147300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;17</p>","","","correlation analysis; long-term prediction; machine learning; photovoltaic power generation; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"APRZUZ6T","journalArticle","2024","Sun, J; Zhu, JX; Shao, J","Long-Time Speech Emotion Recognition Using Feature Compensation and Accentuation-Based Fusion","CIRCUITS SYSTEMS AND SIGNAL PROCESSING","","0278-081X","10.1007/s00034-023-02480-6","","In this paper, we study the speech emotion feature optimization using stochastic optimization algorithms, and feature compensation using deep neural networks. We also proposed to use accentuation-based fusion for long-time speech emotion recognition. Firstly, the extraction method of emotional features is studied, and a series of speech features are constructed for the recognition of emotion. Secondly, we propose a method of sample adaptation through denoising autoencoder to enhance the versatility of features through the mapping of sample features to improve adaptive ability. Thirdly, GA and SFLA are used to optimize the combination of features to improve the emotion recognition results at the utterance level. Finally, we use transformer model to implement accentuation-based emotion fusion in long-time speech. The continuous long-time speech corpus, as well as the public available EMO-DB, are used for experiments. Results show that the proposed method can effectively improve the performance of long-time speech emotion recognition.","2024-02","2025-02-26 20:37:00","2025-02-26 20:37:00","","916-940","","2","43","","","","","","","","","","English","","","","WOS:001065086500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Accentuation-based fusion; Feature compensation; Long-time emotion recognition; Speech emotion recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HEV83Y6C","journalArticle","2023","Cao, YF; Font-Rotchés, D; Rius-Escudé, A","Front vowels of Spanish: A challenge for Chinese speakers","OPEN LINGUISTICS","","2300-9969","10.1515/opli-2022-0230","","This research proposes to define the timbre of front vowels [e] and in the spontaneous speech of the Spanish interlanguage spoken by Chinese people and to determine the convergent and divergent features of Peninsular Spanish. Variables such as gender, level of Spanish proficiency and the (a)tonicity of the vowels will also be assessed to see the extent to which these factors influence the pronunciation of the learners. A corpus of 1,489 front vowels produced by 36 Chinese speakers and a corpus of 420 vowels produced by 79 Spanish speakers were used for this study. The mean F-1 and F-2 values were calculated for each vowel. According to the statistical analysis of spontaneous speech, the interlanguage and the target language are similar in that the sounds and [e] are significantly different, the atonic and tonic show no significant differences and the tonic [e] is more open than the atonic [e] in both genders. However, the interlanguage diverges more from the target language because the timbre of the front vowels is more dispersed, that of is more closed and fronted and that of [e] is more open and fronted, in both males and females, tonic and atonic. Finally, the study reveals that the level of language proficiency and tonicity are factors that influence the acquisition of pronunciation.","2023-02-17","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","1","9","","","","","","","","","","English","","","","WOS:000934814300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","acoustic analysis; Chinese speakers; front vowels; L2 Spanish; spontaneous speech; SPONTANEOUS SPEECH; VARIABILITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4VGCV8D6","journalArticle","2021","Mereu, D; Vietti, A","Dialogic ItAlian: the creation of a corpus of Italian spontaneous speech","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2021.03.002","","In recent decades, the interest in speech sciences for casual conversations has increased, and researchers have begun to investigate the characteristics of spontaneous and casual speech in different languages, such as German, Dutch, English, French, Spanish and Czech. These types of investigations are based on novel spontaneous speech corpora that allow the systematic research on large amounts of data and contribute to understand the empirical dimension of phonological competence. In this paper we present a new speech corpus of spontaneous Italian based on dialogic interactions (DIA - Dialogic ItAlian), representing the language variety spoken by both native and non-native speakers in a bilingual community. After discussing some of the methodological and theoretical issues concerning the role of speech corpora in the study of language variation, we illustrate how the corpus was created, from data collection to the construction of a database. We then offer an exploratory investigation on some indicators of spontaneity.","2021-06","2025-02-26 20:37:00","2025-02-26 20:37:00","","1-14","","","130","","","","","","","","","","English","","","","WOS:000647676900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;94</p>","","","corpus linguistics; ENGLISH; Italian; LAUGHTER; NIJMEGEN CORPUS; ORGANIZATION; spontaneous speech; WORDS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CG3YFZLW","journalArticle","2023","Shibata, Y; Victorino, JN; Natsuyama, T; Okamoto, N; Yoshimura, R; Shibata, T","Estimation of subjective quality of life in schizophrenic patients using speech features","FRONTIERS IN REHABILITATION SCIENCES","","2673-6861","10.3389/fresc.2023.1121034","","IntroductionPatients with schizophrenia experience the most prolonged hospital stay in Japan. Also, the high re-hospitalization rate affects their quality of life (QoL). Despite being an effective predictor of treatment, QoL has not been widely utilized due to time constraints and lack of interest. As such, this study aimed to estimate the schizophrenic patients' subjective quality of life using speech features. Specifically, this study uses speech from patients with schizophrenia to estimate the subscale scores, which measure the subjective QoL of the patients. The objectives were to (1) estimate the subscale scores from different patients or cross-sectional measurements, and 2) estimate the subscale scores from the same patient in different periods or longitudinal measurements.MethodsA conversational agent was built to record the responses of 18 schizophrenic patients on the Japanese Schizophrenia Quality of Life Scale (JSQLS) with three subscales: ""Psychosocial,"" ""Motivation and Energy,"" and ""Symptoms and Side-effects."" These three subscales were used as objective variables. On the other hand, the speech features during measurement (Chromagram, Mel spectrogram, Mel-Frequency Cepstrum Coefficient) were used as explanatory variables. For the first objective, a trained model estimated the subscale scores for the 18 subjects using the Nested Cross-validation (CV) method. For the second objective, six of the 18 subjects were measured twice. Then, another trained model estimated the subscale scores for the second time using the 18 subjects' data as training data. Ten different machine learning algorithms were used in this study, and the errors of the learned models were compared.Results and DiscussionThe results showed that the mean RMSE of the cross-sectional measurement was 13.433, with k-Nearest Neighbors as the best model. Meanwhile, the mean RMSE of the longitudinal measurement was 13.301, using Random Forest as the best. RMSE of less than 10 suggests that the estimated subscale scores using speech features were close to the actual JSQLS subscale scores. Ten out of 18 subjects were estimated with an RMSE of less than 10 for cross-sectional measurement. Meanwhile, five out of six had the same observation for longitudinal measurement. Future studies using a larger number of subjects and the development of more personalized models based on longitudinal measurements are needed to apply the results to telemedicine for continuous monitoring of QoL.","2023-03-10","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","4","","","","","","","","","","English","","","","WOS:001019507800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","machine learning; model development; OUTCOMES; quality of life; schizophrenia; SELECTION; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"447Z49KL","journalArticle","2022","Qin, MY","A study on automatic correction of English grammar errors based on deep learning","JOURNAL OF INTELLIGENT SYSTEMS","","0334-1860","10.1515/jisys-2022-0052","","Grammatical error correction (GEC) is an important element in language learning. In this article, based on deep learning, the application of the Transformer model in GEC was briefly introduced. Then, in order to improve the performance of the model on GEC, it was optimized by a generative adversarial network (GAN). Experiments were conducted on two data sets. It was found that the performance of the GAN-combined Transformer model was significantly improved compared to the Transformer model. The F-0(.5) value of the optimized model was 53.87 on CoNIL-2014, which was 2.69 larger than the Transformer model; the generalized language evaluation understanding (GLEU) value of the optimized model was 61.77 on JFLEG, which was 8.81 larger than that of the Transformer model. The optimized model also had a favorable correction performance in an actual English essay. The experimental results verify the reliability of the GAN-combined Transformer model on automatic English GEC, suggesting that the model can be further promoted and applied in practice.","2022-06-02","2025-02-26 20:37:00","2025-02-26 20:37:00","","672-680","","1","31","","","","","","","","","","English","","","","WOS:000810146100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","deep learning; English essay; grammatical error correction; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XHPA3NUP","journalArticle","2023","Schneider, K; Leinweber, K; Jamalabadi, H; Teutenberg, L; Brosch, K; Pfarr, JK; Thomas-Odenthal, F; Usemann, P; Wroblewski, A; Straube, B; Alexander, N; Nenadic, I; Jansen, A; Krug, A; Dannlowski, U; Kircher, T; Nagels, A; Stein, F","Syntactic complexity and diversity of spontaneous speech production in schizophrenia spectrum and major depressive disorders","SCHIZOPHRENIA","","2754-6993","10.1038/s41537-023-00359-8","","Syntax, the grammatical structure of sentences, is a fundamental aspect of language. It remains debated whether reduced syntactic complexity is unique to schizophrenia spectrum disorder (SSD) or whether it is also present in major depressive disorder (MDD). Furthermore, the association of syntax (including syntactic complexity and diversity) with language-related neuropsychology and psychopathological symptoms across disorders remains unclear. Thirty-four SSD patients and thirty-eight MDD patients diagnosed according to DSM-IV-TR as well as forty healthy controls (HC) were included and tasked with describing four pictures from the Thematic Apperception Test. We analyzed the produced speech regarding its syntax delineating measures for syntactic complexity (the total number of main clauses embedding subordinate clauses) and diversity (number of different types of complex sentences). We performed cluster analysis to identify clusters based on syntax and investigated associations of syntactic, to language-related neuropsychological (verbal fluency and verbal episodic memory), and psychopathological measures (positive and negative formal thought disorder) using network analyses. Syntax in SSD was significantly reduced in comparison to MDD and HC, whereas the comparison of HC and MDD revealed no significant differences. No associations were present between speech measures and current medication, duration and severity of illness, age or sex; the single association accounted for was education. A cluster analysis resulted in four clusters with different degrees of syntax across diagnoses. Subjects with less syntax exhibited pronounced positive and negative symptoms and displayed poorer performance in executive functioning, global functioning, and verbal episodic memory. All cluster-based networks indicated varying degrees of domain-specific and cross-domain connections. Measures of syntactic complexity were closely related while syntactic diversity appeared to be a separate node outside of the syntactic network. Cross-domain associations were more salient in more complex syntactic production.","2023-05-29","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","1","9","","","","","","","","","","English","","","","WOS:000996770500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;91</p>","","","BIOMARKERS; BIPOLAR DISORDER; CHILDHOOD-ONSET SCHIZOPHRENIA; EPISODIC MEMORY; FORMAL THOUGHT-DISORDER; LANGUAGE; NEGATIVE SYMPTOMS; PATTERN-CLASSIFICATION; RATING-SCALE; VERBAL FLUENCY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DUVH9BQR","journalArticle","2021","Lv, XZ; Zhao, M; Li, T; Yuan, CZ; Zhang, HF; Pu, CC; Li, ZY; Zhang, N; Yu, X; Wang, HL","Effects of an Enhanced Training on Primary Care Providers Knowledge, Attitudes, Service and Skills of Dementia Detection: A Cluster Randomized Trial","FRONTIERS IN NEUROLOGY","","1664-2295","10.3389/fneur.2021.651826","","Background: Effective training programs for primary care providers (PCPs) to support dementia detection are needed, especially in developing countries. This study aimed to investigate the effect of an enhanced training on the competency and service of PCPs for dementia detection. Methods: We conducted a cluster randomized trial in Beijing, China. Community healthcare centers (CHCs) located in Fengtai or Fangshan District were eligible. The enrolled CHCs in each district were randomly assigned to the standard or the enhanced training group at a 1:1 ratio. PCPs serving older adults in enrolled CHCs were eligible to participate. The standard training group received three-hour didactic lectures, three monthly supervisions, 3 months of online support and dementia screening packages. The enhanced training group additionally received three monthly face-to-face supervisions and 3 months of online support. The participants became aware of their group membership at the end of the standard training. The knowledge, attitudes, service, and skills regarding dementia detection were assessed using questionnaires and submitted dementia detection records, respectively. Results: A total of 23 and 21 CHCs were randomly assigned to the standard and the enhanced training group, respectively, and 58 participants from 20 CHCs assigned to the standard training group and 48 from 16 CHCs assigned to the enhanced training group were included in the final analysis (mean age 37.5 years, and 67.0% women). A significant increase in the knowledge score was found in both groups, but the increase was similar in the two groups (P = 0.262). The attitude score remained stable in both groups, and no between-group difference was found. Compared with the baseline, both groups reported an increase in dementia detection service, especially the enhanced training group (24.1% to 31.0% in the standard training group and 14.6% to 45.8% in the enhanced training group). The completion rate and accuracy of submitted dementia detection records in the enhanced training group were both significantly higher than those in the standard training group (both P < 0.001). Conclusion: The enhanced training had similar effect on the knowledge of PCPs comparing with the standard training, but was better on continuous service and skills of PCPs related to dementia detection.","2021-07-23","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","12","","","","","","","","","","English","","","","WOS:000708394900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","attitudes; cluster randomized trial; COMMUNITY; dementia detection; DIAGNOSIS; EDUCATIONAL INTERVENTIONS; FACING DEMENTIA; HEALTH; knowledge; MANAGEMENT; primary care providers; PROGRAM; service; training","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GVVLSVZB","journalArticle","2023","Boonen, N; Kloots, H; Nurzia, P; Gillis, S","Spontaneous speech intelligibility: early cochlear implanted children versus their normally hearing peers at seven years of age","JOURNAL OF CHILD LANGUAGE","","0305-0009","10.1017/S0305000921000714","","Speaking intelligibly is an important achievement in children's language development. How far do congenitally severe-to-profound hearing-impaired children who received a cochlear implant (CI) in the first two years of their life advance on the path to intelligibility in comparison to children with typical hearing (NH)? Spontaneous speech samples of children with CI and children with NH were orthographically transcribed by naive transcribers. The entropy of the transcriptions was computed to analyze their degree of uniformity. The same samples were also rated on a continuous rating scale by another group of adult listeners. The transcriptions of the NH children's speech were more uniform, i.e., had significantly lower entropy, than those of the CI children, suggesting that the latter group displayed lower intelligibility. This was confirmed by the ratings on the continuous scale. Despite the relatively restricted age ranges, older children reached better intelligibility scores in both groups.","2023-01","2025-02-26 20:37:00","2025-02-26 20:37:00","","78-103","","1","50","","","","","","","","","","English","","","","WOS:000771568200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","ARTICULATION; children with a cochlear implant; CONVERSATIONAL SPEECH; DEAF-CHILDREN; EXPERIENCE; intelligibility; OUTCOMES; PERCEPTION; PREDICTION; SINGLE-WORD; SPOKEN LANGUAGE-DEVELOPMENT; spontaneous speech; YOUNGER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GHIZYXGM","journalArticle","2021","Thorson, JC; Morgan, JL","Prosodic realizations of new, given, and corrective referents in the spontaneous speech of toddlers","JOURNAL OF CHILD LANGUAGE","","0305-0009","10.1017/S0305000920000434","","Our motivation was to examine how toddler (2;6) and adult speakers of American English prosodically realize information status categories. The aims were three-fold: 1) to analyze how adults phonologically make information status distinctions; 2) to examine how these same categories are signaled in toddlers' spontaneous speech; and 3) to analyze the three primary acoustic correlates of prosody (F-0, intensity, and duration). During a spontaneous speech task designed as an interactive game, a set of target nouns was elicited as one of three types (new, given, corrective). Results show that toddlers primarily used H* across information status categories, with secondary preferences for deaccenting given information and for using L+H* for corrective information. Only duration distinguished information status, and duration, average pitch, and intensity differentiated pitch accent types for both adults and children. Discussion includes how pitch accent selection and input play a role in guiding prosodic realizations of information status.","2021-05","2025-02-26 20:37:00","2025-02-26 20:37:00","","541-568","","3","48","","","","","","","","","","English","","","","WOS:000639314500006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;81</p>","","","ACCENT; acoustic-phonetics; CHILDREN; CONTRASTIVE STRESS; EMPHASIS; ENGLISH; first language acquisition; FOCUS; information status; INFORMATION STATUS; INTONATION; MARKING; PROMINENCE; prosody","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H6FT7BS9","journalArticle","2025","Nasrolahzadeh, M; Mohammadpoory, Z; Haddadnia, J","Small-world networks propensity in spontaneous speech signals of Alzheimer's disease: visibility graph analysis","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-025-88947-9","","Exploiting complex network methods to describe dynamical behavior based on speech time series can provide fundamental insights into the function of underlying dynamical processes in Alzheimer's disease (AD). This study scrutinizes the dynamic alterations in Alzheimer's speech through abstract concepts of small-world networks. The visibility graph (VG) of the time series of spontaneous speech is introduced as a quantitative method to differentiate between healthy individuals and those with Alzheimer's. The dynamic speech patterns across three AD and healthy subjects stages are analyzed by examining the small-world feature structure, characterized by a high clustering coefficient (C) and short average path length (L) in the VG. These characteristics are calculated based on degree K. The results demonstrate the practical utility of C and L in identifying the underlying pathological mechanisms of AD. Furthermore, all speech series exhibit small-world topology based on VG, with changes reflecting the brain system's pathology that impacts individuals' language skills.","2025-02-10","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","1","15","","","","","","","","","","English","","","","WOS:001417012000006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","Alzheimer's disease; BRAIN FUNCTIONAL NETWORKS; CHILDREN; CONNECTIVITY; DIAGNOSIS; PACKET-BASED FEATURES; SELECTION; Small-worldness; Spontaneous Speech Signal; THEORETICAL ANALYSIS; Visibility graph","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BKNXQPV4","journalArticle","2025","Guo, X; Kim, Y; Ning, XL; Min, SD","Enhancing the Transformer Model with a Convolutional Feature Extractor Block and Vector-Based Relative Position Embedding for Human Activity Recognition","SENSORS","","1424-8220","10.3390/s25020301","","The Transformer model has received significant attention in Human Activity Recognition (HAR) due to its self-attention mechanism that captures long dependencies in time series. However, for Inertial Measurement Unit (IMU) sensor time-series signals, the Transformer model does not effectively utilize the a priori information of strong complex temporal correlations. Therefore, we proposed using multi-layer convolutional layers as a Convolutional Feature Extractor Block (CFEB). CFEB enables the Transformer model to leverage both local and global time series features for activity classification. Meanwhile, the absolute position embedding (APE) in existing Transformer models cannot accurately represent the distance relationship between individuals at different time points. To further explore positional correlations in temporal signals, this paper introduces the Vector-based Relative Position Embedding (vRPE), aiming to provide more relative temporal position information within sensor signals for the Transformer model. Combining these innovations, we conduct extensive experiments on three HAR benchmark datasets: KU-HAR, UniMiB SHAR, and USC-HAD. Experimental results demonstrate that our proposed enhancement scheme substantially elevates the performance of the Transformer model in HAR.","2025-01","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","2","25","","","","","","","","","","English","","","","WOS:001405399400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","ACCELEROMETER; convolutional neural networks (CNNs); human activity recognition; inertial measurement units (IMUs); NETWORKS; relative position embedding; time series signal; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"75Z628YL","journalArticle","2021","Zhang, Y; Shi, XY; Mi, SY; Yang, X","Image captioning with transformer and knowledge graph","PATTERN RECOGNITION LETTERS","","0167-8655","10.1016/j.patrec.2020.12.020","","The Transformer model has achieved very good results in machine translation tasks. In this paper, we adopt the Transformer model for the image captioning task. To promote the performance of image captioning, we improve the Transformer model from two aspects. First, we augment the maximum likelihood estimation (MLE) with an extra Kullback-Leibler (KL) divergence term to distinguish the difference between incorrect predictions. Second, we introduce a method to help the Transformer model generate captions by leveraging the knowledge graph. Experiments on benchmark datasets demonstrate the effectiveness of our method. (c) 2021 Elsevier B.V. All rights reserved.","2021-03","2025-02-26 20:37:00","2025-02-26 20:37:00","","43-49","","","143","","","","","","","","","","English","","","","WOS:000615785700007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;57<br/>Total Times Cited:&nbsp;&nbsp;57<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Image captioning; Knowledge graph; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G7TRJ7VN","journalArticle","2023","Kieling, MLM; Finkelsztejn, A; Konzen, VR; dos Santos, VB; Ayres, A; Klein, I; Rothe-Neves, R; Olchik, MR","Articulatory speech measures can be related to the severity of multiple sclerosis","FRONTIERS IN NEUROLOGY","","1664-2295","10.3389/fneur.2023.1075736","","BackgroundDysarthria is one of the most frequent communication disorders in patients with Multiple Sclerosis (MS), with an estimated prevalence of around 50%. However, it is unclear if there is a relationship between dysarthria and the severity or duration of the disease. ObjectiveDescribe the speech pattern in MS, correlate with clinical data, and compare with controls. MethodsA group of MS patients (n = 73) matched to healthy controls (n = 37) by sex and age. Individuals with neurological and/or systemic conditions that could interfere with speech were excluded. MS group clinical data were obtained through the analysis of medical records. The speech assessment consisted of auditory-perceptual and speech acoustic analysis, from recording the following speech tasks: phonation and breathing (sustained vowel/a/); prosody (sentences with different intonation patterns) and articulation (diadochokinesis; spontaneous speech; diphthong/iu/repeatedly). ResultsIn MS, 72.6% of the individuals presented mild dysarthria, with alterations in speech subsystems: phonation, breathing, resonance, and articulation. In the acoustic analysis, individuals with MS were significantly worse than the control group (CG) in the variables: standard deviation of the fundamental frequency (p = 0.001) and maximum phonation time (p = 0.041). In diadochokinesis, individuals with MS had a lower number of syllables, duration, and phonation time, but larger pauses per seconds, and in spontaneous speech, a high number of pauses were evidenced as compared to CG. Correlations were found between phonation time in spontaneous speech and the Expanded Disability Status Scale (EDSS) (r = - 0.238, p = 0.043) and phonation ratio in spontaneous speech and EDSS (r = -0.265, p = 0.023), which indicates a correlation between the number of pauses during spontaneous speech and the severity of the disease. ConclusionThe speech profile in MS patients was mild dysarthria, with a decline in the phonatory, respiratory, resonant, and articulatory subsystems of speech, respectively, in order of prevalence. The increased number of pauses during speech and lower rates of phonation ratio can reflect the severity of MS.","2023-06-13","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","14","","","","","","","","","","English","","","","WOS:001016968300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","DIAGNOSIS; dysarthria; DYSARTHRIA; multiple sclerosis; speech acoustics; speech disorder; speech therapy assessment; VOICE QUALITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X8SD8XXM","journalArticle","2024","Kuhlmann, LL; Iwarsson, J","Effects of Speaking Rate on Breathing and Voice Behavior","JOURNAL OF VOICE","","0892-1997","10.1016/j.jvoice.2021.09.005","","Objectives. The objective of this study was to investigate the effects of speaking rate (habitual and fast) and speech task (reading and spontaneous speech) on seven dependent variables: Breath group size (in syllables), Breath group duration (in seconds), Lung volume at breath group initiation, Lung volume at breath group termination, Lung volume excursion for each breath group (in % vital capacity), Lung volume excursion per syllable (in % vital capacity) and mean speaking Fundamental frequency (fO). Methods. Ten women and seven men were included as subjects. Lung volume and breathing behaviors were measured by respiratory inductance plethysmography and fO was measured from audio recordings by the Praat software. Statistical significance was tested by analysis of variance. Results. For both reading and spontaneous speech, the group increased mean breath group size and breath group duration significantly in the fast speaking rate condition. The group significantly decreased lung volume excursion per syllable in fast speech. Females also showed a significant increase of fO in fast speech. The lung volume levels for initiation and termination of breath groups, as well as lung volume excursions in % vital capacity, showed great individual variations and no significant effects of rate. Significant effects of speech task were found for breath group size and lung volume excursion per syllable, where reading induced more syllables produced per breath group and less % VC spend per syllable as compared to spontaneous speech. Interaction effects showed that the increases in breath group size and breath group duration associated with fast rate were significantly larger in reading than in spontaneous speech. Conclusion. Our data from 17 vocally untrained, healthy subjects showed great individual variations but still significant group effects regarding increased speaking rate, where the subjects seemed to spend less air per syllable and inhaled less often as a consequence of greater breath group sizes in fast speech. Subjects showed greater changes in breath group patterns as a consequence of fast speech in reading than in spontaneous speech, indicating that effects of speaking rate are dependent on the speech task.","2024-03","2025-02-26 20:37:00","2025-02-26 20:37:00","","346-356","","2","38","","","","","","","","","","English","","","","WOS:001218809800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","FUNDAMENTAL-FREQUENCY; IMPACT; INTENSITY; LOUDNESS; Lung volume; LUNG-VOLUME INITIATION; Respiratory Inductance Plethysmography; Speaking rate; SPEECH; Speech breathing; Speech tempo; Voice therapy; YOUNG-ADULT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P9UIXUBA","journalArticle","2023","Hayes, EN","Meeting in the Middle: Sociophonetic Convergence of Bad Bunny and J Balvin's Coda /s/ in Their Artistic Performance Speech","LANGUAGES","","2226-471X","10.3390/languages8040287","","The artistic performance of identity by top Latin music artists can be heard on many Top-40 US radio stations, since, as of July 2023, 20% of the Billboard Hot 100 is (Spanish language) Latin music. This study aims to determine the variants found in the pronunciation of coda /s/, a robust phonetic differentiator of regional and social dialects, in the top songs versus in the spontaneous speech of the two top Latin music artists in the global market. Are Bad Bunny and J Balvin holding to the pronunciation of their respective regional variety in their artistic performance speech (APS, my term) or are they shifting to a different pronunciation? What motivations might cause a difference in the pronunciation of their APS and spontaneous speech? Bad Bunny and J Balvin's pronunciation of coda /s/ is analyzed in depth as sociophonetic data: their performances of songs from 2018 to 2020 that charted at the top of the Hot Latin Songs Billboard chart as well as on The Billboard Hot 100 chart, and their spontaneous speech from their most-viewed Spanish-language interviews and Instagram Live recordings on YouTube recorded between 2018 and 2020. Bad Bunny overwhelmingly used deletions ( null ) in his spontaneous speech-which is typical of an island Puerto Rican-but used a statistically significant amount of maintenance of the sibilant [s] and its aspirated variant [h] in his APS (p < 0.0001). J Balvin primarily used [s] in his spontaneous speech-which is typical of Medellin, Colombia-but used about 50/50 [s] and ( null ) in his APS. They are both shifting to a different pronunciation in their APS and converging towards each other, and the difference is statistically significant (p < 0.0001). This dialect convergence could be the beginning of an identity-based pan-Latinx dialect leveling that is, on the one hand, the ""in-crowd"" pronunciation with covert prestige but, on the other hand, is part of the formation of an evolving multi-regional connector variant diffused through popular music and pop culture.","2023-12","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","4","8","","","","","","","","","","English","","","","WOS:001132780100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","ASPIRATION; identity; language attitudes; Latin music; sociolinguistics; sociophonetics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U59DIL4J","journalArticle","2023","Gilman, M; Shelly, S; Gillespie, AI","Vocal Acoustics and Aerodynamics During Scripted Reading Compared to Spontaneous Speech","JOURNAL OF VOICE","","0892-1997","10.1016/j.jvoice.2021.03.022","","Background. Examination of vocal acoustics and phonatory aerodynamics during connected speech provide a more ecologically valid approach to voice assessment than single phoneme measures. The purpose of the current investigation was to determine if differences exist in vocal acoustics and aerodynamics between read-ing and spontaneous speech tasks in patients with common voice disorders. Methods. The Emory University Institutional Review Board approved this retrospective study. The voice records of 100 patients (74 females and 26 males) diagnosed with benign voice disorders and referred for voice evaluation at the Emory Voice Center between November 2018 and March 2019 were analyzed. These consisted of reading a scripted passage (the Rainbow Passage) and spontaneous speech (describing how to make a peanut butter and jelly sandwich). Data collected included gender, voice diagnosis, mean fundamental frequency (F0), mean airflow during voicing, and mean inspiratory airflow (MIA). Results. Univariate analysis assessed normality of the data. Variables with normal distribution utilized paired t test. Non-normal data were log transformed. Mean F0 was not significant for complete case analysis (P = 0.053) but gender based stratified analysis, for females (mean difference = 4.68 Hz; 95% CI = 0.359, 9.0012; P = 0.03). Gender-related statistical differences were also found in MIA in women (P = 0.0001), and P = 0.0003 for MIA in men. The direction and range of change between scripted reading and the spontaneous speech tasks in all metrics varied widely. No consistent patterns were noted in gender, age and diagnosis across the parameters studied. However, clinically salient findings in the range of MIA were noted in a small subgroup of participants. Conclusions. This study suggests that multiple testing stimuli for phonatory aerodynamic and acoustic out-comes measurement may be appropriate for use depending on the need and vocal challenges of the individual patient. Clinically, both structured reading and spontaneous speech provide valuable insight into the vocal capa-bilities of the patient.","2023-07","2025-02-26 20:37:00","2025-02-26 20:37:00","","539-545","","4","37","","","","","","","","","","English","","","","WOS:001040238800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Acoustics; AIR-FLOW; Connected speech; MAXIMUM DURATION; PATTERNS; Phonatory aerodynamics; S/Z RATIO; SUSTAINED S; Voice; WOMEN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LBRHEIH6","journalArticle","2024","Lim, YD; Zhao, P; Guidoni, L; Likforman, JP; Tan, CS","Next-Value Prediction of Beam Waists From Mixed Pitch Grating Using Simplified Transformer Model","IEEE PHOTONICS JOURNAL","","1943-0655","10.1109/JPHOT.2024.3442169","","In this study, a simplified transformer model is used to predict the beam waist of 1,092 nm light coupled out from SiN-based mixed pitch gratings at various heights. The beam waists data at various heights above the grating is first compiled. Then, we used a sequence of the current beam waist values, z-positions, and the computed mathematical indicators (features) to predict the next beam waist value (labels). Optimized transformer model yields average percentage error (APE) of 6.6% between the predicted and actual beam waists, which corresponds to 93.4% prediction accuracy. This study provides a pioneering approach to using natural language processing model to perform predictive modelling on photonics data, and possible extrapolation of photonics data using transformer model.","2024-10","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","5","16","","","","","","","","","","English","","","","WOS:001294287500002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Attention; Computational modeling; Data models; gratings; Gratings; Laser beams; Mathematical models; multi-head attention; photonics integrated circuits; Predictive models; quantum computing; self-attention; silicon photonics; transformer model; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YTEG898X","journalArticle","2024","Antonsson, M; Fors, KL; Hartelius, L","Disfluencies in spontaneous speech in persons with low-grade glioma before and after surgery","CLINICAL LINGUISTICS & PHONETICS","","0269-9206","10.1080/02699206.2023.2226305","","Impaired lexical retrieval is common in persons with low-grade glioma (LGG). Several studies have reported a discrepancy between subjective word-finding difficulties and results on formal tests. Analysis of spontaneous speech might be more sensitive to signs of word-finding difficulties, hence we aimed to explore disfluencies in a spontaneous-speech task performed by participants with presumed LGG before and after surgery. Further, we wanted to explore how the presence of disfluencies in spontaneous speech differed in the participants with and without objectively established lexical-retrieval impairment and with and without self-reported subjective experience of impaired language, speech and communication. Speech samples of 26 persons with presumed low-grade glioma were analysed with regard to disfluency features. The post-operative speech samples had a higher occurrence of fillers, implying more disfluent language production. The participants performed worse on two of the word fluency tests, and after surgery the number of participants who were assessed as having an impaired lexical retrieval had increased from 6 to 12. The number of participants who experienced a change in their language, speech or communication had increased from 9 to 12. Additional comparisons showed that those with impaired lexical retrieval had a higher proportion of false starts after surgery than those with normal lexical retrieval, and differences in articulation rate and speech rate, favouring those not having experienced any change in language, speech or communication. Taken together, the findings from this study strengthen the existing claim that temporal aspects of language and speech are important when assessing persons with gliomas.","2024-04-02","2025-02-26 20:37:00","2025-02-26 20:37:00","","359-380","","4","38","","","","","","","","","","English","","","","WOS:001016471900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","AWAKE SURGERY; COMMUNICATION; DEFICITS; disfluency; ELOQUENT AREAS; EVALUATE; FILLED PAUSES; GAPS; LANGUAGE; lexical impairment; Low-grade glioma; pauses; RESECTION; subjective language complaints; SWEDISH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LSP662EI","journalArticle","2021","Feenaughty, L; Basilakos, A; Bonilha, L; Fridriksson, J","Speech timing changes accompany speech entrainment in aphasia","JOURNAL OF COMMUNICATION DISORDERS","","0021-9924","10.1016/j.jcomdis.2021.106090","","Background: Prior speech entrainment studies, where individuals with non-fluent aphasia mimic an audio-visual model, suggest speech entrainment improves speech fluency, as indexed by various linguistic measures (e.g., the total number of different words produced per minute). Here, more precise speech timing adjustments accompanying entrained speech were studied and compared to spontaneous speech to determine how these temporal variables relate to the fluency inducing effects of speech entrainment in aphasia. Methods: Thirty-one left hemisphere stroke survivors classified with fluent or non-fluent speech were audio-video recorded as they described a picture and during speech entrainment. Speech fluency was documented using the Western Aphasia Battery-Revised. Acoustic measures of speech timing included total number of syllables, speech rate, articulatory rate, silent pause frequency and duration. Standard descriptive statistics and a two-factor mixed model analysis of variance were used to investigate group, task, and 'group x task' interaction effects. Findings: All acoustic measures of speech timing differentiated the fluent and nonfluent groups except for silent pause frequency. Differences between speech entrainment and spontaneous speech were found for most acoustic measures of speech timing and speaker groups, yet the direction of the effect varied. Stroke survivors classified with non-fluent aphasia improved speech fluency such that speech entrainment elicited pause adjustments facilitating more typical speech timing in comparison to spontaneous speech. Conclusion: Overall, findings provide further evidence of the impact of speech entrainment on measures of speech timing to help individuals with non-fluent aphasia to practice speaking more fluently. Practicing speaking more fluently may ultimately impact perceptual judgments of speech naturalness and social acceptance for persons with aphasia.","2021-03","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","90","","","","","","","","","","English","","","","WOS:000633373400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","Aphasia; APRAXIA; BROCAS AREA; CONNECTED SPEECH; DISCOURSE; FLUENCY; ISCHEMIC-STROKE; LANGUAGE; MELODIC INTONATION THERAPY; Non-fluent speech; PEOPLE; Speech entrainment; Speech timing; Spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QP3S2HF3","journalArticle","2022","Fahad, MS; Singh, S; Abhinav; Ranjan, A; Deepak, A","Emotion recognition from spontaneous speech using emotional vowel-like regions","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-022-12453-7","","Spontaneous speech varies in terms of characteristics such as emotion, volume, and pitch. Emotion, itself, is not uniformly distributed across an utterance. The extraction of relevant portions from an utterance that contain meaningful information in terms of emotion is always challenging. The vowel like regions (VLRs) are known to contain emotion-specific information. However, for spontaneous speech, all the VLRs in an utterance do not contain emotion. This paper proposes a method for extracting the emotional VLRs from a set of vowels in an utterance based on the fundamental frequency of a VLR. Further, the recently proposed epoch synchronous single frequency cepstral coefficients (SFCCs) features are combined with the epoch-based features producing 1.33% better result than state-of-the-art technique. In general, the accuracy value reduces for long utterances because all the VLRs in a long utterance are not consistent with the ground truth label. However, the proposed approach produced an improvement in accuracy by 8.22% for the long utterances when emotional VLRs were used in place of all VLRs.","2022-04","2025-02-26 20:37:00","2025-02-26 20:37:00","","14025-14043","","10","81","","","","","","","","","","English","","","","WOS:000761886300013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Emotional vowel; EPOCH EXTRACTION; FREQUENCY; Fundamental-frequency; Long-utterance; Single frequency cepstral coefficients (SFCC); SPEAKER VERIFICATION; Speech emotion recognition (SER); Vowel-like-regions(VLRs)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9ET57PQR","journalArticle","2023","Loo, K; Tomaschek, F; Lippus, P; Tucker, B","Paradigmatic and Syntagmatic Effects in Estonian Spontaneous Speech","LANGUAGE AND SPEECH","","0023-8309","10.1177/00238309221107000","","Recent evidence indicates that a word's paradigmatic neighbors affect production. However, these findings have mostly been obtained in careful laboratory settings using words in isolation, and thus ignoring potential effects that may arise from the syntagmatic context, which is typically present in spontaneous speech. The current corpus analysis investigates paradigmatic and syntagmatic effects in Estonian spontaneous speech. Following work on English, we focus on the duration of inflected and uninflected word-final /-s/ in content words, while simultaneously investigating whole words. Our analyses reveal three points. First, we find an effect of realized inflectional paradigm size, such that smaller paradigms actively used by the speakers lead to longer durations. Second, higher conditional probability is associated with shorter word forms and shorter segments. Finally, we do not directly replicate previous work on effects of inflectional status as in English word-final /-s/. Instead, we find that inflectional status interacts with conditional probability. We discuss the results in light of models of speech production and how they account for morphologically complex words and their paradigmatic neighbors.","2023-06","2025-02-26 20:37:00","2025-02-26 20:37:00","","474-499","","2","66","","","","","","","","","","English","","","","WOS:000840963500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;106</p>","","","ACOUSTIC DURATION; acoustic durations; COARTICULATION; conditional probability; CONTEXTUAL PREDICTABILITY; ENGLISH; inflection; MODEL; Morphological complexity; paradigm size; PATTERNS; PHONETIC DETAIL; REDUNDANCY; WHOLE-WORD FREQUENCY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NCNRXP6Z","journalArticle","2023","Warner, HJ; Shroff, R; Zuanazzi, A; Arenas, RM; Jackson, ES","Linguistic features of stuttering during spontaneous speech","JOURNAL OF FLUENCY DISORDERS","","0094-730X","10.1016/j.jfludis.2023.106016","","Purpose: Previous work shows that linguistic features (e.g., word length, word frequency) impact the predictability of stuttering events. Most of this work has been conducted using reading tasks. Our study examined how linguistic features impact the predictability of stuttering events during spontaneous speech. Methods: The data were sourced from the FluencyBank database and consisted of interviews with 35 adult stutterers (27,009 words). Three logistic regression mixed models were fit as the primary analyses: one model with four features (i.e., initial phoneme, grammatical function, word length, and word position within a sentence), a second model with six features (i.e., the features from the previous model plus word frequency and neighborhood density), and a third model with nine features (i.e., the features from the previous model plus bigram frequency, word concreteness, and typical age of word acquisition). We compared our models using the Area Under the Curve statistic. Results: The four-feature model revealed that initial phoneme, grammatical function, and word length were predictive of stuttering events. The six-feature model revealed that initial phoneme, word length, word frequency, and neighborhood density were predictive of stuttering events. The nine-feature model was not more predictive than the six-feature model. Conclusion: Linguistic features that were previously found to be predictive of stuttering during reading were predictive of stuttering during spontaneous speech. The results indicate the influence of linguistic processes on the predictability of stuttering events such that words associated with increased planning demands (e.g., longer words, low frequency words) were more likely to be stuttered.","2023-12","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","78","","","","","","","","","","English","","","","WOS:001105765600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;87</p>","","","ADULTS; CHILDREN; COMPLEXITY; DISFLUENCIES; EXCHANGE; FREQUENCY; Linguistics; PHONOLOGICAL NEIGHBORHOOD; RETRIEVAL; SEVERITY; Spontaneous speech; Stuttering; WORD-LENGTH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B5LHPTMC","journalArticle","2024","Yu, CH; Yao, Y; Yang, HQ; Wang, X","An Improved Transformer Model for Sap Flow Prediction that Efficiently Utilizes Environmental Information","AGRICULTURAL RESEARCH","","2249-720X","10.1007/s40003-024-00807-6","","As an important reference for assessing plant water consumption and estimating plant transpiration, it is of great significance to achieve accurate prediction of plant sap flow. A number of deep learning models were established and compared using approximately 3 years of continuous eucalyptus flow time series data collected from the SAPFLUXNET open dataset and 6 environmental factors, including shortwave solar incident radiation, air temperature, air relative humidity, net radiation, vapor pressure deficit, and photosynthetic photon flux density. The experimental results show that the improved Transformer model, with the introduction of a two-step self-attention mechanism and simplified design, maintains significant predictive performance advantages compared to the original Transformer model, long short-term memory, gated recurrent unit, and temporal convolutional neural network models. In the shorter 1-h forecast, the mean squared error and coefficient of determination (R2) of the improved Transformer model are 0.0191 and 0.965, respectively. Compared to the suboptimal typical Transformer model, the MSE is reduced by 22.9%, and R2 is increased by 1.0%. Additionally, the improved model maintains stable predictive performance advantages in long-term plant flow prediction. In the longest 8-h advance prediction, the MSE is reduced by 14.9% compared to the suboptimal Transformer model, and R2 increases by 3.0% compared to the Transformer model. The comprehensive experimental results show that the improved Transformer model makes more effective use of environmental information to achieve more accurate and long-term plant flow prediction. This study emphasizes the basic principle and validity of the two-step self-attention network structure and provides a valuable basis for developing more effective methods for predicting plant sap flow.","2024-11-12","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","","","","","","","","","","","English","","","","WOS:001352794600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Deep learning; DYNAMICS; Environmental factor; EVERGREEN; Improved transformer; Sap flow prediction; SAPFLUXNET; TRANSPIRATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VS6X2KJ6","journalArticle","2021","Nguyen, T; Nguyen, L; Tran, P; Nguyen, H","Improving Transformer-Based Neural Machine Translation with Prior Alignments","COMPLEXITY","","1076-2787","10.1155/2021/5515407","","Transformer is a neural machine translation model which revolutionizes machine translation. Compared with traditional statistical machine translation models and other neural machine translation models, the recently proposed transformer model radically and fundamentally changes machine translation with its self-attention and cross-attention mechanisms. These mechanisms effectively model token alignments between source and target sentences. It has been reported that the transformer model provides accurate posterior alignments. In this work, we empirically prove the reverse effect, showing that prior alignments help transformer models produce better translations. Experiment results on Vietnamese-English news translation task show not only the positive effect of manually annotated alignments on transformer models but also the surprising outperformance of statistically constructed alignments reinforced with the flexibility of token-type selection over manual alignments in improving transformer models. Statistically constructed word-to-lemma alignments are used to train a word-to-word transformer model. The novel hybrid transformer model improves the baseline transformer model and transformer model trained with manual alignments by 2.53 and 0.79 BLEU, respectively. In addition to BLEU score, we make limited human judgment on translation results. Strong correlation between human and machine judgment confirms our findings.","2021-05-08","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","2021","","","","","","","","","","English","","","","WOS:000665084500002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M9RAVI7R","journalArticle","2024","Ke, XQ; Mak, MW; Meng, HM","Automatic selection of spoken language biomarkers for dementia detection","NEURAL NETWORKS","","0893-6080","10.1016/j.neunet.2023.10.018","","This paper analyzes diverse features extracted from spoken language to select the most discriminative ones for dementia detection. We present a two-step feature selection (FS) approach: Step 1 utilizes filter methods to pre-screen features, and Step 2 uses a novel feature ranking (FR) method, referred to as dual dropout ranking (DDR), to rank the screened features and select spoken language biomarkers. The proposed DDR is based on a dual-net architecture that separates FS and dementia detection into two neural networks (namely, the operator and selector). The operator is trained on features obtained from the selector to reduce classification or regression loss. The selector is optimized to predict the operator's performance based on automatic regularization. Results show that the approach significantly reduces feature dimensionality while identifying small feature subsets that achieve comparable or superior performance compared with the full, default feature set. The Python codes are available at https://github.com/kexquan/dual-dropout-ranking.","2024-01","2025-02-26 20:37:00","2025-02-26 20:37:00","","191-204","","","169","","","","","","","","","","English","","","","WOS:001104047000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","ALZHEIMERS; Dementia detection; Feature ranking; Feature selection; SPEECH; Spoken language biomarkers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CQWCV7VS","journalArticle","2022","Hernández-Sarmiento, JG; Moreno, P; Loo-Yau, JR","Transformer model with hysteresis for electromagnetic transients computation in the frequency domain","ELECTRICAL ENGINEERING","","0948-7921","10.1007/s00202-022-01512-9","","In this work, saturation and hysteresis loops are included in a four-port transformer model for electromagnetic transients computation in the frequency domain. Approximations with linear segments of the hysteresis characteristic and saturation curve are used. To obtain time domain results, the numerical Laplace transform is employed and the results are compared with those obtained from ATP.","2022-10","2025-02-26 20:37:00","2025-02-26 20:37:00","","2827-2834","","5","104","","","","","","","","","","English","","","","WOS:000761143900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","Electromagnetic transients; Four-port transformer model; Hysteresis loop; Numerical Laplace transform; Saturation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9CCZPGRL","journalArticle","2024","Pan, YL; Lu, MY; Shi, YP; Zhang, HY","A Path Signature Approach for Speech-Based Dementia Detection","IEEE SIGNAL PROCESSING LETTERS","","1070-9908","10.1109/LSP.2023.3291651","","People who have dementia show a decline in their speech abilities. In speech-based dementia detection, the difficulty has remained the representation of an individual's sequential temporal variation of speech is related to dementia symptoms with fix-length features. In this letter, a novel feature extraction method is proposed for extracting fix-length features from unfixed-length audio recordings for dementia detection. When diagnosing dementia, an automatic speech recognition (ASR) system is necessary for extracting linguistic information when constructing an automatic dementia detection system. This letter uses wav2vec2.0, a self-supervised end-to-end ASR system, to achieve such a goal. Similar to the pipeline ASR system, which has been used for extracting the sequential speak-and-pause patterns related to dementia using estimated time alignment information, we propose using character-level transcripts to extract speak-and-pause patterns. Path signature technology, which can represent a sequential feature with a trajectory in the un-parameterised path space, is proposed to describe speak-and-pause patterns embedded in character-level transcripts into character path signatures. Similarly, the variable-length embedding matrices extracted from wav2vec2.0's contextual layers are also represented with their acoustic path signatures. The experiments are designed based on three publicly available datasets: DementiaBank, ADReSS and ADReSSo. The results show that: (1). The distinguished information embedded in the character path signature is visualised for dementia detection; (2). The acoustic path signature and character path signature individually can show superior performance on all three publicly available datasets. (3). Combining the character path signature with the acoustic path signature can considerably increase performance over the ADReSSo dataset.","2024","2025-02-26 20:37:00","2025-02-26 20:37:00","","2880-2884","","","31","","","","","","","","","","English","","","","WOS:001342549800005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Acoustics; ALZHEIMERS-DISEASE; Audio recording; Character-level transcript; Data mining; Dementia; dementia detection; Feature extraction; path signature; Rhythm; speak-pause pattern feature; Trajectory; wav2vec2.0","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CWGWDVH8","journalArticle","2023","Zou, W; Zhang, WB; Tian, ZF; Wu, WH","A hybrid model for text classification using part-of-speech features","JOURNAL OF INTELLIGENT & FUZZY SYSTEMS","","1064-1246","10.3233/JIFS-231699","","In the field of text classification, current research ignores the role of part-of-speech features, and the multi-channel model that can learn richer text information compared to a single model. Moreover, the method based on neural network models to achieve final classification, using fully connected layer and Softmax layer can be further improved and optimized. This paper proposes a hybrid model for text classification using part-of-speech features, namely PAGNN-Stacking1. In the text representation stage of the model, introducing part-of-speech features facilitates a more accurate representation of text information. In the feature extraction stage of the model, using the multi-channel attention gated neural network model can fully learn the text information. In the text final classification stage of the model, this paper innovatively adopts Stacking algorithm to improve the fully connected layer and Softmax layer, which fuses five machine learning algorithms as base classifier and uses fully connected layer Softmax layer as meta classifier. The experiments on the IMDB, SST-2, andAG News datasets show that the accuracy of the PAGNN-Stacking model is significantly improved compared to the benchmark models.","2023","2025-02-26 20:37:00","2025-02-26 20:37:00","","1235-1249","","1","45","","","","","","","","","","English","","","","WOS:001028560600085","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","BIDIRECTIONAL LSTM; multi-channel; NEURAL-NETWORK; part-of-speech features; stacking algorithm; Text classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FUKB9IFG","journalArticle","2022","Capelli, E; Silibello, G; Ajmone, PF; Altamore, E; Lalatta, F; Vizziello, PG; Costantino, MA; Zampini, L","Language Development in Sex Chromosome Trisomies: Developmental Profiles at 2 and 4 Years of Age, and Predictive Measures","DEVELOPMENTAL NEUROREHABILITATION","","1751-8423","10.1080/17518423.2021.2020925","","Purpose Describing language development in children with sex chromosome trisomies (SCT) and testing the predictive value of early language measures on later outcomes. Method Thirteen children with SCT were followed longitudinally. Their developmental profile was assessed, with particular attention to language, at 2 and 4 years. The predictive value of direct (spontaneous speech analysis) and indirect (communicative development inventory) language measures at 2 on performances at 4 was tested. Results Language performances at both ages were lower than non-verbal development. At 2, more than 50% of the group produced less than 50 words. At 4, impaired performances were observed in speech sound development and expressive morpho-syntax. Direct measures of Pre-syntactic development predicted later global language outcomes and Sentence Repetition. The number of consonants used at 2 was significantly related to Nonword Repetition at 4. Conclusions The study highlights the importance of early detection and careful follow-up for children with SCT.","2022-07-04","2025-02-26 20:37:00","2025-02-26 20:37:00","","337-348","","5","25","","","","","","","","","","English","","","","WOS:000739120200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;111</p>","","","CHILDREN; EXPRESSIVE-LANGUAGE; FINE MOTOR DEVELOPMENT; IMPAIRMENT; KLINEFELTER-SYNDROME; language development; LATE-TALKING; longitudinal study; PHONOLOGICAL DEVELOPMENT; predictive measures; Sex chromosome trisomies; SOCIAL DIFFICULTIES; TRIPLE X SYNDROME; VOCABULARY DEVELOPMENT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GX8YP6B4","journalArticle","2024","Alonso-Hernández, JB; Barragán-Pulido, ML; Santana-Luis, A; Ferrer-Ballester, MA","Emotional Temperature for the Evaluation of Speech in Patients with Alzheimer's Disease through an Automatic Interviewer","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14135588","","In the context of the detection and evolutionary control of Alzheimer's disease from voice recordings and their automatic processing, this work aims to objectively determine the discriminatory capacity of a set of voice features linked to the emotional load of speech. We use descriptive statistics derived from the concept of emotional temperature as quantifiable characteristics of the voice. We apply a series of parametric and nonparametric analyses to the set of features, both individually and collectively, and explore their potential in relation to the use of different methods of unsupervised classification. With the aim of comparing how the type of interviewer used in the sample collection (i.e., voice recordings) influences the discrimination of AD through emotional speech analysis, we used the CSAP-19 database, which includes voice samples obtained through human interviewer (spontaneous speech samples) and automatic interviewer (induced speech samples) for the three defined populations (HC, mild AD, and moderate AD). In this regard, a comparative analysis is also conducted on the potential of emotional temperature features defined according to the sample collection process (manual or automatic interview process).","2024-07","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","13","14","","","","","","","","","","English","","","","WOS:001270015300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Alzheimer's disease (AD); DIAGNOSIS; FEATURES; SELECTION; automatic interviewer; emotional temperature; telecare; telemedicine","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WYE82JGW","journalArticle","2023","Zheng, CH; Bouazizi, M; Ohtsuki, T; Kitazawa, M; Horigome, T; Kishimoto, T","Detecting Dementia from Face-Related Features with Automated Computational Methods","BIOENGINEERING-BASEL","","2306-5354","10.3390/bioengineering10070862","","Alzheimer's disease (AD) is a type of dementia that is more likely to occur as people age. It currently has no known cure. As the world's population is aging quickly, early screening for AD has become increasingly important. Traditional screening methods such as brain scans or psychiatric tests are stressful and costly. The patients are likely to feel reluctant to such screenings and fail to receive timely intervention. While researchers have been exploring the use of language in dementia detection, less attention has been given to face-related features. The paper focuses on investigating how face-related features can aid in detecting dementia by exploring the PROMPT dataset that contains video data collected from patients with dementia during interviews. In this work, we extracted three types of features from the videos, including face mesh, Histogram of Oriented Gradients (HOG) features, and Action Units (AU). We trained traditional machine learning models and deep learning models on the extracted features and investigated their effectiveness in dementia detection. Our experiments show that the use of HOG features achieved the highest accuracy of 79% in dementia detection, followed by AU features with 71% accuracy, and face mesh features with 66% accuracy. Our results show that face-related features have the potential to be a crucial indicator in automated computational dementia detection.","2023-07","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","7","10","","","","","","","","","","English","","","","WOS:001034982000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","action unit; dementia detection; face mesh; HOG; machine learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E7XUF3GF","journalArticle","2023","Kwon, G; Lee, HYJ","Time series KSTAR PF superconducting coil temperature forecasting using recurrent transformer model","FUSION ENGINEERING AND DESIGN","","0920-3796","10.1016/j.fusengdes.2023.113693","","In this paper, we propose a KSTAR PF superconducting coil temperature forecasting model using a recurrent transformer model to protect the PF coil during operation. We developed a Recurrent Transformer model (RTransformer) that recurrently forecasts future time points using current time input data and latent variables from previous time steps based on the perceiver autoregressive model. The RTransformer model is compu-tationally and memory efficient, requiring lower overhead than the Transformer model as it only computes forecasting points using a subset of input sequence data instead of the entire sequence of time windows. The RTransformer model was trained using the KSTAR PF coil temperature dataset obtained from the PF coil monitoring system. We compared the performance of the proposed model with Long-Short-Term memory (LSTM), Transformer model, and TransformerXL, based on R2 score, Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and Mean Absolute Percentage Error (MAPE). We also compared the inference time for each model. The experimental results showed that the proposed model outperformed other deep learning models, with lower error rates and similar inference times to the Transformer model. For most performance metrics, our proposed model scored among the top 1 and top 2 scoring models.","2023-08","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","193","","","","","","","","","","English","","","","WOS:000967099500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;13</p>","","","Autoregression model; Deep learning; Superconducting coil temperature; Time series forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4F8SRJP3","journalArticle","2025","Shi, YS; Wang, LC; Liao, N; Xu, ZQ","Lithium-Ion Battery Degradation Based on the CNN-Transformer Model","ENERGIES","","1996-1073","10.3390/en18020248","","Due to its innovative structure and superior handling of long time series data with parallel input, the Transformer model has demonstrated a remarkable effectiveness. However, its application in lithium-ion battery degradation research requires a massive amount of data, which is disadvantageous for the online monitoring of batteries. This paper proposes a lithium-ion battery degradation research method based on the CNN-Transformer model. By leveraging the efficiency of the CNN model in feature extraction, it reduces the dependency of the Transformer model on data volume, thereby ensuring faster overall model training without a significant loss in model accuracy. This facilitates the online monitoring of battery degradation. The dataset used for training and validation consists of charge-discharge data from 124 lithium iron phosphate batteries. The experimental results include an analysis of the model training results for both single-battery and multiple-battery data, compared with commonly used models such as LSTM and Transformer. Regarding the instability of single-battery data in the CNN-Transformer model, statistical analysis is conducted to analyze the experimental results. The final model results indicate that the root mean square error (RMSE) of capacity predictions for the majority of batteries among the 124 batteries is within 3% of the actual values.","2025-01","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","2","18","","","","","","","","","","English","","","","WOS:001405221400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","CNN-Transformer model; HEALTH ESTIMATION; lithium-ion battery; parallelized data input; SOC prediction; STATE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9MK3NGG5","journalArticle","2022","Tian, FY; Fan, XX; Wang, RT; Qin, HC; Fan, YX","A Power Forecasting Method for Ultra-Short-Term Photovoltaic Power Generation Using Transformer Model","MATHEMATICAL PROBLEMS IN ENGINEERING","","1024-123X","10.1155/2022/9421400","","The volatility of solar energy, geographic location, and weather factors continues to affect the stability of photovoltaic power generation, reliable and accurate photovoltaic power prediction methods not only effectively reduce the operating cost of the photovoltaic system but also provide reliable data support for the energy scheduling of the light storage microgrid, improve the stability of the photovoltaic system, and provide important help for the optimization operation of the photovoltaic system. Therefore, it is an important study to find reliable photovoltaic power prediction methods. In recent years, researchers have improved the accuracy of photovoltaic power generation forecasting by using deep learning models. Compared with the traditional neural network, the Transformer model can better learn the relationship between weather features and has good stability and applicability. Therefore, in this paper, the transformer model is used for predicting ultra-short-term photovoltaic power generation, and the photovoltaic power generation data and weather data in Hebei are selected. In the experiment, the prediction result of the transformer model was compared to the GRU and DNN models to show that the transformer model has better predictive ability and stability. Experimental results demonstrated that the proposed Transformer model outperforms the GRU model and DNN model by a difference of about 0.04 kW and 0.047 kW in the MSE value, and 22.0% and 29.1% of the MAPE error. In addition, the public DC competition dataset is selected for control experiments to demonstrate the general applicability of the transformer model for PV power prediction in different regions.","2022-10-28","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","2022","","","","","","","","","","English","","","","WOS:000880430800005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","PREDICTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EY3R3CMK","journalArticle","2024","Favaro, A; Butala, A; Thebaud, T; Villalba, J; Dehak, N; Moro-Velazquez, L","Unveiling early signs of Parkinson's disease via a longitudinal analysis of celebrity speech recordings","NPJ PARKINSONS DISEASE","","2373-8057","10.1038/s41531-024-00817-9","","Numerous studies proposed methods to detect Parkinson's disease (PD) via speech analysis. However, existing corpora often lack prodromal recordings, have small sample sizes, and lack longitudinal data. Speech samples from celebrities who publicly disclosed their PD diagnosis provide longitudinal data, allowing the creation of a new corpus, ParkCeleb. We collected videos from 40 subjects with PD and 40 controls and analyzed evolving speech features from 10 years before to 20 years after diagnosis. Our longitudinal analysis, focused on 15 subjects with PD and 15 controls, revealed features like pitch variability, pause duration, speech rate, and syllable duration, indicating PD progression. Early dysarthria patterns were detectable in the prodromal phase, with the best classifiers achieving AUCs of 0.72 and 0.75 for data collected ten and five years before diagnosis, respectively, and 0.93 post-diagnosis. This study highlights the potential for early detection methods, aiding treatment response identification and screening in clinical trials.","2024-10-27","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","1","10","","","","","","","","","","English","","","","WOS:001343198900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;88</p>","","","BODY-SIZE; FREQUENCY; INDIVIDUALS; LEVODOPA; PEOPLE; PROGRESSION; VARIABILITY; VOCAL-TRACT LENGTH; VOICE DISORDERS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DQCFZSSB","journalArticle","2022","Meng, W; Zhang, QH; Ma, SM; Cai, MC; Liu, DJ; Liu, ZC; Yang, J","A lightweight CNN and Transformer hybrid model for mental retardation screening among children from spontaneous speech","COMPUTERS IN BIOLOGY AND MEDICINE","","0010-4825","10.1016/j.compbiomed.2022.106281","","Mental retardation (MR) is a group of mental disorders characterized by low intelligence and social adjustment difficulties. Early diagnosis is beneficial for the timely intervention of children with MR to ease the degree of disability. Children with MR always have impaired speech functions compared to normal children, which is significant for clinical diagnosis. On the basis of this, our study proposes a spontaneous speech -based framework (MT-Net) for screening MR, which merges mobile inverted bottleneck convolutional blocks (MBConv) and visual Transformer blocks. MT-Net takes log-mel spectrograms converted from raw interview speech as data source, and utilizes MBConv and visual Transformer to learn low-level and high-level features well. In addition, SpecAugment, a data augmentation strategy, has been used to expand our audio dataset to further enhance the performance of MT-Net. The experimental results show that our proposed MT -Net outperforms Transformer networks (ViT) and convolutional neural networks (ResNet18, MobileNetV2, EfficientNetV2), achieving accuracy of 91.60% after using SpecAugment. Our proposed MT-Net has fewer parameters, low computing consumption and high prediction accuracy, which is expected to be an auxiliary screening tool for MR.","2022-12","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","151","","","","","","","","","","English","","","","WOS:000900240200002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","blocks; DISORDERS; DOWN-SYNDROME; FRAGILE-X; IMPAIRMENT; Mental retardation; Mobile inverted bottleneck convolutional; Spontaneous speech; Visual Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZRGELY5F","journalArticle","2024","Fang, JJ; Yang, LS; Wen, XH; Yu, HJ; Li, WD; Adamowski, JF; Barzegar, R","Ensemble learning using multivariate variational mode decomposition based on the Transformer for multi-step-ahead streamflow forecasting","JOURNAL OF HYDROLOGY","","0022-1694","10.1016/j.jhydrol.2024.131275","","Accurate streamflow forecasting is critical in the domain of water resources management. However, the inherently non -stationary and stochastic nature of streamflow poses a significant challenge to achieving accuracy in streamflow forecasting. In this study, we introduce an MVMD-ensembled Transformer model (MVMD-Transformer), which incorporates the MVMD for concurrent time -frequency analysis of streamflow and related potential influencing variables. The model aligns common modes in the decomposition results, ensuring that the different variables corresponding to each mode have the same center frequency. This alignment overcomes frequency mismatches and helps uncover the intrinsic patterns and essential features between streamflow and associated variables. During the forecasting phase, the Transformer component of the MVMD-Transformer model establishes connections among streamflow and other influencing variables across pairs of nodes in each mode. We tested the performance of the MVMD-Transformer model in forecasting streamflow across 1-, 3-, 5-, and 7day horizons within the Shiyang River, Heihe River, and Shule River basins situated in the Hexi Corridor of Northwest China. The MVMD-Transformer model harnesses MVMD to concurrently decompose both predictor variables (precipitation, air temperature, air pressure, soil moisture) and the response variable (streamflow). Subsequently, the modes drived from the MVMD were fed into the Transformer, serving as the predictive analytics engine, to forecast streamflow. Furthermore, we conducted a comprehensive performance evaluation by comparing the MVMD-Transformer model against four alternatives: the VMD-ensembled Transformer model (VMD-Transformer), CEEMDAN-ensembled Transformer model (CEEMDAN-Transformer), stand-alone Transformer model, and LSTM model. The results indicate that MVMD-Transformer outperformed all other models, achieving Nash -Sutcliffe coefficient (NSE) values exceeding 0.85 in the majority of the forecasting scenarios. This superior performance highlights the proficiency of the MVMD approach in more accurately unraveling the intricate interdependencies between streamflow and its various potential influencing variables, thus significantly improving the precision of streamflow forecasting.","2024-06","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","636","","","","","","","","","","English","","","","WOS:001240438200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;122</p>","","","ARTIFICIAL NEURAL-NETWORK; Ensemble learning; FLOW; HYBRID MODEL; Multivariate variational mode decomposition; PREDICTION; Streamflow forecasting; SUPPORT-VECTOR-MACHINE; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6SVARAN7","journalArticle","2023","Yokoi, K; Iribe, Y; Kitaoka, N; Tsuboi, T; Hiraga, K; Satake, Y; Hattori, M; Tanaka, Y; Sato, M; Hori, A; Katsuno, M","Analysis of spontaneous speech in Parkinson's disease by natural language processing","PARKINSONISM & RELATED DISORDERS","","1353-8020","10.1016/j.parkreldis.2023.105411","","Introduction: Patients with Parkinson's disease (PD) encounter a variety of speech-related problems, including dysarthria and language disorders. To elucidate the pathophysiological mechanisms for linguistic alteration in PD, we compared the utterance of patients and that of healthy controls (HC) using automated morphological analysis tools.Methods: We enrolled 53 PD patients with normal cognitive function and 53 HC, and assessed their spontaneous speech using natural language processing. Machine learning algorithms were used to identify the characteristics of spontaneous conversation in each group. Thirty-seven features focused on part-of-speech and syntactic complexity were used in this analysis. A support-vector machine (SVM) model was trained with ten-fold cross -validation.Results: PD patients were found to speak less morphemes on one sentence than the HC group. Compared to HC, the speech of PD patients had a higher rate of verbs, case particles (dispersion), and verb utterances, and a lower rate of common noun utterances, proper noun utterances, and filler utterances. Using these conversational changes, the respective discrimination rates for PD or HC were more than 80%.Conclusions: Our results demonstrate the potential of natural language processing for linguistic analysis and diagnosis of PD.","2023-08","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","113","","","","","","","","","","English","","","","WOS:001053036200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","DIAGNOSIS; Linguistic analysis; Natural language processing; Parkinson's disease; Part-of-speech; Spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AVDR2Y83","journalArticle","2023","Choi, HW; Ko, GH","Orthographic influence on resyllabification errors by Vietnamese learners of Korean: A speech corpus study","LINGUISTIC RESEARCH","","1229-1374","10.17250/khisli.40..202309.002","","Choi, Hye-Won and Gunhee Ko. 2023. Orthographic influence on resyllabification errors by Vietnamese learners of Korean: A speech corpus study. Linguistic Research 40(Special Edition): 33-59. This study investigates resyllabification errors made by Vietnamese learners of Korean, utilizing an L2 speech corpus known as ""A Collection of Foreigners' Korean Speech Data for AI Training."" By analyzing the read-aloud and spontaneous speech data from 40 Vietnamese L1 speakers in the corpus, we discovered that the error rate was higher in script reading than in spontaneous speech. We propose the rigid syllable boundary in Vietnamese L1 phonology, contrasting with the fluid syllable boundary in Korean L2 phonology, results in a negative transfer, causing Vietnamese learners' difficulty in resyllabification when speaking Korean. Furthermore, the orthographic rigidity of syllable boundary of the Korean writing system presents negative orthographic input for Vietnamese learners, whose orthography (Roman alphabet) allows for syllabic ambiguity. Consequently, speakers tend to produce more errors in script reading with such orthographic input than in spontaneous speech. We conclude the disparity between the phonological fluidity and the orthographic rigidity of Korean syllables contributes to failure of resyllabification among Vietnamese speakers. (Ewha Womans University)","2023","2025-02-26 20:37:00","2025-02-26 20:37:00","","33-59","","","40","","","","","","","","","","English","","","","WOS:001082472700002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","CHINESE; INPUT; Korean as a foreign language (KFL); orthography; resyllabification; second language pronunciation errors; speech corpus; syllable boundary; Vietnamese learners","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4ZUUAYUG","journalArticle","2022","Puggaard-Rode, R; Horslund, CS; Jorgensen, H","The rarity of intervocalic voicing of stops in Danish spontaneous speech","LABORATORY PHONOLOGY","","1868-6346","10.16995/labphon.6449","","Previous studies of the phonetics of Danish stops have neglected closure voicing. Danish is an aspiration language, but the aspirated stops /p t k/ are produced with shorter closure duration and less articulatory effort than the unaspirated stops /b d g/. Furthermore, all Danish stops are characterized by some degree of glottal spreading during the closure. In this study, we use a corpus of Danish spontaneous speech (DanPASS) to investigate the intervocalic voicing-its distribution across the two laryngeal categories, whether it patterns as a lenition phenomenon, and whether the aerodynamic environment predicts its distribution. We find that intervocalic voicing is not the norm for either set of stops and is particularly rare in /p t k/. Voiced tokens are mostly found in environments associated with lenition. We suggest that the glottal spreading gesture found in all Danish stops is a phonological mechanism blocking voicing, which is probabilistically lost in spontaneous speech. This predicts our results better than relying on laryngeal features like [voice] or [spread glottis]. The study fills a gap in our knowledge of Danish phonetics and phonology, and is also one of the most extensive corpus studies of intervocalic stop voicing in an 'aspiration language.'","2022-05-23","2025-02-26 20:37:00","2025-02-26 20:37:00","","1-47","","1","13","","","","","","","","","","English","","","","WOS:000802825200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;141</p>","","","GENDER; LARYNGEAL FEATURES; LENITION; LEXICAL FREQUENCY; ONSET; PHONOLOGY; REPRESENTATION; VARIABILITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3JY7GF26","journalArticle","2024","Johnson, KA; Babel, M","Language Contact Within the Speaker: Phonetic Variation and Crosslinguistic Influence","LANGUAGE AND SPEECH","","0023-8309","10.1177/00238309231182592","","A recent model of sound change posits that the direction of change is determined, at least in part, by the distribution of variation within speech communities. We explore this model in the context of bilingual speech, asking whether the less variable language constrains phonetic variation in the more variable language, using a corpus of spontaneous speech from early Cantonese-English bilinguals. As predicted, given the phonetic distributions of stop obstruents in Cantonese compared with English, intervocalic English /b d g/ were produced with less voicing for Cantonese-English bilinguals and word-final English /t k/ were more likely to be unreleased compared with spontaneous speech from two monolingual English control corpora. Whereas voicing initial obstruents can be gradient in Cantonese, the release of final obstruents is prohibited. Neither Cantonese-English bilingual initial voicing nor word-final stop release patterns were significantly impacted by language mode. These results provide evidence that the phonetic variation in crosslinguistically linked categories in bilingual speech is shaped by the distribution of phonetic variation within each language, thus suggesting a mechanistic account for why some segments are more susceptible to cross-language influence than others.","2024-06","2025-02-26 20:37:00","2025-02-26 20:37:00","","401-437","","2","67","","","","","","","","","","English","","","","WOS:001037759700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;110</p>","","","1ST-LANGUAGE; ASPIRATION; BILINGUAL SPEECH; bilingualism; CORONAL STOP DELETION; crosslinguistic influence; ENGLISH; INITIAL STOPS; PERCEPTION; pronunciation variation; SOUND CHANGE; Speech production; spontaneous speech corpus; VARIABILITY; VOICE ONSET TIME","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8H9HYK2X","journalArticle","2024","Lai, HY; Hu, CC; Wen, CH; Wu, JX; Pai, NS; Yeh, CY; Lin, CH","Mel-Scale Frequency Extraction and Classification of Dialect-Speech Signals With 1D CNN Based Classifier for Gender and Region Recognition","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3430296","","Humans communicate and interact through natural languages, such as American English (AE), Taiwanese, Italian, and numerous variants of Spanish. Through automatic speech analysis and recognition technologies, human-machine interaction systems (HMISs) can be used for language learning in query systems, smart devices, and healthcare applications, emphasizing the need to enhance user interaction across different sectors. Because people differ in their basic attributes (e.g., gender, age group, and spoken dialect), an HMIS must be able to identify the speaker's gender, age group, and regional dialect on the basis of their speech signals. To achieve automatic speech recognition, we analyzed and distinguished feature patterns using a feature extraction method and identified gender and region using a convolutional neural network (CNN)-based classifier. Mel-frequency cepstral coefficients were used to extract Mel-scale frequencies (MSF) from dialect-sentence speech signals for conversion into specific feature patterns. Subsequently, a one-dimensional CNN-based classifier was used to identify these features patterns by gender and regional dialect. The proposed speech classifier was rigorously trained, tested, and validated using dialect-sentence speech corpora from AE, Italian (IT), and Spanish (SP) acoustic-phonetic continuous speech database. The experimental results indicate that the proposed model with MSF features can perform accurate gender and region recognition. The classifier was evaluated in metrics of precision (%), recall (%), F1 score, and accuracy (%).","2024","2025-02-26 20:37:00","2025-02-26 20:37:00","","102962-102976","","","12","","","","","","","","","","English","","","","WOS:001283762000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","acoustic-phonetic continuous speech; Automatic speech recognition (ASR); dialect-sentence speech signal; Mel-scale frequency; one-dimensional convolutional neural network (CNN)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z5FW9A2I","journalArticle","2022","Li, LH; Cheng, S; Mei, NS; Zhang, ZF","A Well-matched and Balanced Impedance Matching Method Utilizing a Full-Scalable Magnetic-Electric Coupled Transformer Model","JOURNAL OF INFRARED MILLIMETER AND TERAHERTZ WAVES","","1866-6892","10.1007/s10762-021-00836-0","","This article presents a new method to achieve a well-matched and balanced impedance matching using a magnetic-electric coupled (MEC) transformer model. Both the MEC transformer model and its matching method are analyzed comprehensively. The MEC model takes the common-mode effects into consideration and improves accuracy FoM value (AFV) in the 1 similar to 100 GHz frequency band compared to the magnetically coupled transformer model in a 1:2 transformer example, which can provide higher accuracy for designing a better transformer. The proposed matching approach in this article can determine a well-matched and balanced MEC transformer matching network according to the target impedance. Mapping relationships between the parameters of the MEC transformer model and the geometric parameters of the transformer are further discussed to achieve a practical and optimal transformer simulation prototype. The methods to control the common-mode effects of the transformer are discussed both at the physical and circuit levels. The full-scalable parameters extraction methodology is verified over broadband by full-wave electromagnetic (EM) simulations and measurements. The proposed well-matched and balanced impedance matching approach is proven by the HFSS (3D High Frequency Simulation Software) simulation and structure measurements.","2022-01","2025-02-26 20:37:00","2025-02-26 20:37:00","","71-93","","1-2","43","","","","","","","","","","English","","","","WOS:000749037100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","CIRCUIT MODEL; DESIGN; GAIN; Magnetic-electric coupling; Matching method; Millimeter wave; ON-CHIP TRANSFORMERS; PAE; Parameter extraction; POWER-AMPLIFIER; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XIGIDI3J","journalArticle","2024","Gwak, M; Cha, J; Yoon, H; Kang, D; An, D","Lightweight Transformer Model for Mobile Application Classification","SENSORS","","1424-8220","10.3390/s24020564","","Recently, realistic services like virtual reality and augmented reality have gained popularity. These realistic services require deterministic transmission with end-to-end low latency and high reliability for practical applications. However, for these real-time services to be deterministic, the network core should provide the requisite level of network. To deliver differentiated services to each real-time service, network service providers can classify applications based on traffic. However, due to the presence of personal information in headers, application classification based on encrypted application data is necessary. Initially, we collected application traffic from four well-known applications and preprocessed this data to extract encrypted application data and convert it into model input. We proposed a lightweight transformer model consisting of an encoder, a global average pooling layer, and a dense layer to categorize applications based on the encrypted payload in a packet. To enhance the performance of the proposed model, we determined hyperparameters using several performance evaluations. We evaluated performance with 1D-CNN and ET-BERT. The proposed transformer model demonstrated good performance in the performance evaluation, with a classification accuracy and F1 score of 96% and 95%, respectively. The time complexity of the proposed transformer model was higher than that of 1D-CNN but performed better in application classification. The proposed transformer model had lower time complexity and higher classification performance than ET-BERT.","2024-01","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","2","24","","","","","","","","","","English","","","","WOS:001151432300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","application classification; deep learning; transformer model; wireless LAN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3DUNEZ65","journalArticle","2022","Amjad, A; Khan, L; Ashraf, N; Mahmood, MB; Chang, HT","Recognizing Semi-Natural and Spontaneous Speech Emotions Using Deep Neural Networks","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3163712","","We needed to find deep emotional features to identify emotions from audio signals. Identifying emotions in spontaneous speech is a novel and challenging subject of research. Several convolutional neural network (CNN) models were used to learn deep segment-level auditory representations of augmented Mel spectrograms. The proposed study introduces a novel technique for recognizing semi-natural and spontaneous speech emotions based on 1D (Model A) and 2D (Model B) deep convolutional neural networks (DCNNs) with two layers of long-short-term memory (LSTM). Both models used raw speech data and augmented (mid, left, right, and side) segment level Mel spectrograms to learn local and global features. The architecture of both models consists of five local feature learning blocks (LFLBs), two LSTM layers, and a fully connected layer (FCL). In addition to learning local correlations and extracting hierarchical correlations, LFLB comprises two convolutional layers and a max-pooling layer. The LSTM layer learns long-term correlations from local features. The experiments illustrated that the proposed systems perform better than conventional methods. Model A achieved an average identification accuracy of 94.78% for speaker-dependent (SD) with a raw SAVEE dataset. With the IEMOCAP database, Model A achieved an average accuracy of an SD experiment with raw audio of 73.15%. In addition, Model A obtained identification accuracies of 97.19%, 94.09%, and 53.98% on SAVEE, IEMOCAP, and BAUM-1s, the databases for speaker-dependent (SD) experiments with an augmented Mel spectrogram, respectively. In contrast, Model B achieved identification accuracy of 96.85%, 88.80%, and 48.67% on SAVEE, IEMOCAP, and the BAUM-1s database for SI experiments with augmented reality Mel spectrogram, respectively.","2022","2025-02-26 20:37:00","2025-02-26 20:37:00","","37149-37163","","","10","","","","","","","","","","English","","","","WOS:000782403300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;95</p>","","","CLASSIFICATION; convolutional neural network; Convolutional neural networks; data augmentation; Data models; Databases; Emotion recognition; Feature extraction; long-short-term memory; RECOGNITION FEATURES; SENTIMENT ANALYSIS; Spectrogram; Speech emotion recognition; Speech recognition; spontaneous speech database","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E69BJLEV","journalArticle","2023","Sánchez-Mompeán, S","The melody of Spanish dubbed dialogue","TRANSLATION SPACES","","2211-3711","10.1075/ts.23007.san","","Dubbed speech has often been accused of sounding artificial and somewhat exaggerated, mainly because it features a type of melody that substantially differs from both spontaneous speech and domestic fictional dialogue. This paper explores the most significant vocal patterns that shape a recognisable melody in Castilian-Spanish dubbed dialogue in order to ascertain whether they really contribute to the artificiality of the target version or, on the contrary, help preserve the credibility of the film production and viewers' cinematic illusion. The discussion reveals that dubbed speech is characterised by certain vocal features specific to this genre that, despite differing from the ones used in spontaneous speech and screen acting, appear to work effectively in dubbing and are generally tolerated by audiences. There seems to be room, however, for naturalising some of these patterns in an effort to achieve an acceptable balance between what conveys the impression of spontaneity and what sounds natural within the context of dubbing.Dubbed speech has often been accused of sounding artificial and somewhat exaggerated, mainly because it features a type of melody that substantially differs from both spontaneous speech and domestic fictional dialogue. This paper explores the most significant vocal patterns that shape a recognisable melody in Castilian-Spanish dubbed dialogue in order to ascertain whether they really contribute to the artificiality of the target version or, on the contrary, help preserve the credibility of the film production and viewers' cinematic illusion. The discussion reveals that dubbed speech is characterised by certain vocal features specific to this genre that, despite differing from the ones used in spontaneous speech and screen acting, appear to work effectively in dubbing and are generally tolerated by audiences. There seems to be room, however, for naturalising some of these patterns in an effort to achieve an acceptable balance between what conveys the impression of spontaneity and what sounds natural within the context of dubbing.","2023-12-15","2025-02-26 20:37:00","2025-02-26 20:37:00","","326-347","","2","12","","","","","","","","","","English","","","","WOS:001125909700008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","artificiality; credibility; dubbing; dubbitis; ENGLISH; LANGUAGE; MARKERS; melody; naturalness; NATURALNESS; prosodic features","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8PEUHYQ3","journalArticle","2022","Sara, M; Daniela, C; Sonia, D; Savina, R; Caterina, SM","Linguistic characteristics of different types of aphasia: A computer-assisted qualitative analysis using T-LAB","JOURNAL OF NEUROLINGUISTICS","","0911-6044","10.1016/j.jneuroling.2021.101056","","Background: Aphasic disorders are observed in patients with both vascular and neurodegenerative pathology. Although spontaneous speech in the various forms of aphasia has some features that are identifiable on a purely linguistic level, diagnosing the type of aphasia critically relies on the support of clinical and neuroimaging data.Objective: To identify some core characteristics of different types of fluent aphasias (i.e., disorders of speech production due to lesions in the posterior regions of the left perisylvian areas not associated with articulatory deficits or apraxia of speech) in spontaneous speech using T-LAB computer-assisted qualitative analyses. This is a mixed-method software that allows exploring narratives by highlighting their key features using linguistic, statistical and graphical tools. Methods: We collected samples of spontaneous speech (narratives) from 34 fluent aphasic Italian speakers (i.e.,11 post-stroke aphasic patients, 17 with the logopenic variant of Primary Progressive Aphasia and 6 with the semantic variant) during the description of the Cookie Theft Picture of the Boston Diagnostic Aphasia Examination. Thirty-four healthy control subjects were asked to complete the same task. Analyses of the entire corpus (all of the narratives), specific metadata introduction and tagging were performed by two raters and any conflicts were resolved by a third rater.Results: T-LAB analysis revealed statistically significant differences between both aphasic patients and healthy controls and between vascular and degenerative patients. Although the main distinction emerged between post-stroke and neurodegenerative aphasias, important differences also emerged between the individuals with the logopenic variant and the semantic variant.Discussion: These findings underline the potential usefulness of a computer-assisted analysis of speech production to identify the core linguistic characteristics of different aphasic disorders, independently of any clinical support.","2022-05","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","62","","","","","","","","","","English","","","","WOS:000777286800008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Linguistic differences; Logopenic aphasia; Post stroke aphasia; Qualitative textual analysis; Semantic aphasia; SPONTANEOUS SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YHABVLTE","journalArticle","2023","Tang, SX; Hänsel, K; Cong, Y; Nikzad, AH; Mehta, A; Cho, S; Berretta, S; Behbehani, L; Pradhan, S; John, M; Liberman, MY","Latent Factors of Language Disturbance and Relationships to Quantitative Speech Features","SCHIZOPHRENIA BULLETIN","","0586-7614","10.1093/schbul/sbac145","","Background and Hypothesis Quantitative acoustic and textual measures derived from speech (""speech features"") may provide valuable biomarkers for psychiatric disorders, particularly schizophrenia spectrum disorders (SSD). We sought to identify cross-diagnostic latent factors for speech disturbance with relevance for SSD and computational modeling. Study Design Clinical ratings for speech disturbance were generated across 14 items for a cross-diagnostic sample (N = 334), including SSD (n = 90). Speech features were quantified using an automated pipeline for brief recorded samples of free speech. Factor models for the clinical ratings were generated using exploratory factor analysis, then tested with confirmatory factor analysis in the cross-diagnostic and SSD groups. The relationships between factor scores and computational speech features were examined for 202 of the participants. Study Results We found a 3-factor model with a good fit in the cross-diagnostic group and an acceptable fit for the SSD subsample. The model identifies an impaired expressivity factor and 2 interrelated disorganized factors for inefficient and incoherent speech. Incoherent speech was specific to psychosis groups, while inefficient speech and impaired expressivity showed intermediate effects in people with nonpsychotic disorders. Each of the 3 factors had significant and distinct relationships with speech features, which differed for the cross-diagnostic vs SSD groups. Conclusions We report a cross-diagnostic 3-factor model for speech disturbance which is supported by good statistical measures, intuitive, applicable to SSD, and relatable to linguistic theories. It provides a valuable framework for understanding speech disturbance and appropriate targets for modeling with quantitative speech features.","2023-03-22","2025-02-26 20:37:00","2025-02-26 20:37:00","","S93-S103","","SUPP2","49","","","","","","","","","","English","","","","WOS:000989362600003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","alogia; COMMUNICATION; disorganization; FORMAL THOUGHT; graph analysis; MARKERS; natural language processing; psychosis; PSYCHOSIS; SCALE; schizophrenia; SCHIZOPHRENIA; SYMPTOMS; thought disorder; THOUGHT-DISORDER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YHEEVQJS","journalArticle","2023","de Velasco, M; Justo, R; Zorrilla, AL; Torres, MI","Analysis of Deep Learning-Based Decision-Making in an Emotional Spontaneous Speech Task","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13020980","","In this work, we present an approach to understand the computational methods and decision-making involved in the identification of emotions in spontaneous speech. The selected task consists of Spanish TV debates, which entail a high level of complexity as well as additional subjectivity in the human perception-based annotation procedure. A simple convolutional neural model is proposed, and its behaviour is analysed to explain its decision-making. The proposed model slightly outperforms commonly used CNN architectures such as VGG16, while being much lighter. Internal layer-by-layer transformations of the input spectrogram are visualised and analysed. Finally, a class model visualisation is proposed as a simple interpretation approach whose usefulness is assessed in the work.","2023-01","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","2","13","","","","","","","","","","English","","","","WOS:000916886100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;83</p>","","","emotion detection; explainable artificial intelligence; machine learning; RECOGNITION; speech processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JGK8LQI9","journalArticle","2022","Lee, YJ; Kreiman, J","Acoustic voice variation in spontaneous speech","JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA","","0001-4966","10.1121/10.0011471","","This study replicates and extends the recent findings of Lee, Keating, and Kreiman [J. Acoust. Soc. Am. 146(3), 1568-1579 (2019)] on acoustic voice variation in read speech, which showed remarkably similar acoustic voice spaces for groups of female and male talkers and the individual talkers within these groups. Principal component analysis was applied to acoustic indices of voice quality measured from phone conversations for 99/100 of the same talkers studied previously. The acoustic voice spaces derived from spontaneous speech are highly similar to those based on read speech, except that unlike read speech, variability in fundamental frequency accounted for significant acoustic variability. Implications of these findings for prototype models of speaker recognition and discrimination are considered. (C) 2022 Acoustical Society of America.","2022-05","2025-02-26 20:37:00","2025-02-26 20:37:00","","3462-3472","","5","151","","","","","","","","","","English","","","","WOS:000806072200003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","BODY-SIZE; BREATHY; DISCRIMINATION; MEMORY; PERCEPTION; QUALITY; READ","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4F2NN3Z7","journalArticle","2021","Parjane, N; Cho, S; Ash, S; Cousins, KAQ; Shellikeri, S; Liberman, M; Shaw, LM; Irwin, DJ; Grossman, M; Nevler, N","Digital Speech Analysis in Progressive Supranuclear Palsy and Corticobasal Syndromes","JOURNAL OF ALZHEIMERS DISEASE","","1387-2877","10.3233/JAD-201132","","Background: Progressive supranuclear palsy syndrome (PSPS) and corticobasal syndrome (CBS) as well as non-fluent/agrammatic primary progressive aphasia (naPPA) are often associated with misfolded 4-repeat tau pathology, but the diversity of the associated speech features is poorly understood. Objective: Investigate the full range of acoustic and lexical properties of speech to test the hypothesis that PSPS-CBS show a subset of speech impairments found in naPPA. Methods: Acoustic and lexical measures, extracted from natural, digitized semi-structured speech samples using novel, automated methods, were compared in PSPS-CBS (n = 87), naPPA (n = 25), and healthy controls (HC, n = 41). We related these measures to grammatical performance and speech fluency, core features of naPPA, to neuropsychological measures of naming, executive, memory and visuoconstructional functioning, and to cerebrospinal fluid (CSF) phosphorylated tau (pTau) levels in patients with available biofluid analytes. Results: Both naPPA and PSPS-CBS speech produced shorter speech segments, longer pauses, higher pause rates, reduced fundamental frequency (f0) pitch ranges, and slower speech rate compared to HC. naPPA speech was distinct from PSPS-CBS with shorter speech segments, more frequent pauses, slower speech rate, reduced verb production, and higher partial word production. In both groups, acoustic duration measures generally correlated with speech fluency, measured as words per minute, and grammatical performance. Speech measures did not correlate with standard neuropsychological measures. CSF pTau levels correlated with f0 range in PSPS-CBS and naPPA. Conclusion: Lexical and acoustic speech features of PSPS-CBS overlaps those of naPPA and are related to CSF pTau levels.","2021","2025-02-26 20:37:00","2025-02-26 20:37:00","","33-45","","1","82","","","","","","","","","","English","","","","WOS:000670297900004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;16<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","APRAXIA; AUTOMATED-ANALYSIS; CLINICAL-DIAGNOSIS; COGNITION; Corticobasal syndrome; DEGENERATION; language; LANGUAGE; non-fluent primary progressive aphasia; NONFLUENT APHASIA; PATHOLOGY; progressive supranuclear palsy; RATING-SCALE; speech; SUBCORTICAL DEMENTIA; tauopathy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YL89I2N2","journalArticle","2021","Yamada, Y; Shinkawa, K; Kobayashi, M; Nishimura, M; Nemoto, M; Tsukada, E; Ota, M; Nemoto, K; Arai, T","Tablet-Based Automatic Assessment for Early Detection of Alzheimer's Disease Using Speech Responses to Daily Life Questions","FRONTIERS IN DIGITAL HEALTH","","2673-253X","10.3389/fdgth.2021.653904","","Health-monitoring technologies for automatically detecting the early signs of Alzheimer's disease (AD) have become increasingly important. Speech responses to neuropsychological tasks have been used for quantifying changes resulting from AD and differentiating AD and mild cognitive impairment (MCI) from cognitively normal (CN). However, whether and how other types of speech tasks with less burden on older adults could be used for detecting early signs of AD remains unexplored. In this study, we developed a tablet-based application and compared speech responses to daily life questions with those to neuropsychological tasks in terms of differentiating MCI from CN. We found that in daily life questions, around 80% of speech features showing significant differences between CN and MCI overlapped those showing significant differences in both our study and other studies using neuropsychological tasks, but the number of significantly different features as well as their effect sizes from life questions decreased compared with those from neuropsychological tasks. On the other hand, the results of classification models for detecting MCI by using the speech features showed that daily life questions could achieve high accuracy, i.e., 86.4%, comparable to neuropsychological tasks by using eight questions against all five neuropsychological tasks. Our results indicate that, while daily life questions may elicit weaker but statistically discernable differences in speech responses resulting from MCI than neuropsychological tasks, combining them could be useful for detecting MCI with comparable performance to using neuropsychological tasks, which could help develop health-monitoring technologies for early detection of AD in a less burdensome manner.","2021-03-17","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","3","","","","","","","","","","English","","","","WOS:001031875600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","Alzheimer's disease; APHASIA; CONNECTED SPEECH; DEMENTIA PREVENTION; early screening; health-monitoring; INTERVENTION; language dysfunction; mild cognitive impairment; MILD COGNITIVE IMPAIRMENT; OBJECTIVE TECHNIQUE; PARAMETERS; PERFORMANCE; speech analysis and processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y49NAX86","journalArticle","2024","Gumus, M; Koo, M; Studzinski, CM; Bhan, A; Robin, J; Black, SE","Linguistic changes in neurodegenerative diseases relate to clinical symptoms","FRONTIERS IN NEUROLOGY","","1664-2295","10.3389/fneur.2024.1373341","","Background: The detection and characterization of speech changes may help in the identification and monitoring of neurodegenerative diseases. However, there is limited research validating the relationship between speech changes and clinical symptoms across a wide range of neurodegenerative diseases. Method: We analyzed speech recordings from 109 patients who were diagnosed with various neurodegenerative diseases, including Alzheimer's disease, Frontotemporal Dementia, and Vascular Cognitive Impairment, in a cognitive neurology memory clinic. Speech recordings of an open-ended picture description task were processed using the Winterlight speech analysis platform which generates >500 speech features, including the acoustics of speech and linguistic properties of spoken language. We investigated the relationship between the speech features and clinical assessments including the Mini Mental State Examination (MMSE), Mattis Dementia Rating Scale (DRS), Western Aphasia Battery (WAB), and Boston Naming Task (BNT) in a heterogeneous patient population. Result: Linguistic features including lexical and syntactic features were significantly correlated with clinical assessments in patients, across diagnoses. Lower MMSE and DRS scores were associated with the use of shorter words and fewer prepositional phrases. Increased impairment on WAB and BNT was correlated with the use of fewer nouns but more pronouns. Patients also differed from healthy adults as their speech duration was significantly shorter with more pauses. Conclusion: Linguistic changes such as the use of simpler vocabularies and syntax were detectable in patients with different neurodegenerative diseases and correlated with cognitive decline. Speech has the potential to be a sensitive measure for detecting cognitive impairments across various neurodegenerative diseases.","2024-03-25","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","15","","","","","","","","","","English","","","","WOS:001198063600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","3 VARIANTS; ALZHEIMERS-DISEASE; clinical symptoms; DEFICITS; digital health; LANGUAGE DECLINE; linguistic; MILD COGNITIVE IMPAIRMENT; neurodegenerative diseases; NORMS; PRIMARY PROGRESSIVE APHASIA; SEMANTIC DEMENTIA; speech; SPEECH; WORD-FREQUENCY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8VULB7W5","journalArticle","2024","Huang, LY; Yang, XT; Lai, YZ; Zou, AK; Zhang, JL","Crude Oil Futures Price Forecasting Based on Variational and Empirical Mode Decompositions and Transformer Model","MATHEMATICS","","2227-7390","10.3390/math12244034","","Crude oil is a raw and natural, but nonrenewable, resource. It is one of the world's most important commodities, and its price can have ripple effects throughout the broader economy. Accurately predicting crude oil prices is vital for investment decisions but it remains challenging. Due to the deficiencies neglecting residual factors when forecasting using conventional combination models, such as the autoregressive moving average and the long short-term memory for prediction, the variational mode decomposition (VMD)-empirical mode decomposition (EMD)-Transformer model is proposed to predict crude oil prices in this study. This model integrates a second decomposition and Transformer model-based machine learning method. More specifically, we employ the VMD technique to decompose the original sequence into variational mode filtering (VMF) and a residual sequence, followed by using EMD to decompose the residual sequence. Ultimately, we apply the Transformer model to predict the decomposed modal components and superimpose the results to produce the final forecasted prices. Further empirical test results demonstrate that the proposed quadratic decomposition composite model can comprehensively identify the characteristics of WTI and Brent crude oil futures daily price series. The test results illustrate that the proposed VMD-EMD-Transformer model outperforms the other three models-long short-term memory (LSTM), Transformer, and VMD-Transformer in forecasting crude oil prices. Details are presented in the empirical study part.","2024-12","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","24","12","","","","","","","","","","English","","","","WOS:001384754200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","crude oil price; empirical mode decomposition; MACHINE; machine learning methods; NEURAL-NETWORK; Transformer model; variational mode decomposition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H2LLY9MZ","journalArticle","2024","Coulange, S; Kato, T; Rossato, S; Masperi, M","Enhancing Language Learners' Comprehensibility through Automated Analysis of Pause Positions and Syllable Prominence","LANGUAGES","","2226-471X","10.3390/languages9030078","","This research paper addresses the challenge of providing effective feedback on spontaneous speech produced by second language (L2) English learners. As the position of pauses and lexical stress is often considered a determinative factor for easy comprehension by listeners, an automated pipeline is introduced to analyze the position of pauses in speech, the lexical stress patterns of polysyllabic content words, and the degree of prosodic contrast between stressed and unstressed syllables, on the basis of F0, intensity, and duration measures. The pipeline is applied to 11 h of spontaneous speech from 176 French students with B1 and B2 proficiency levels. It appeared that B1 students make more pauses within phrases and less pauses between clauses than B2 speakers, with a large diversity among speakers at both proficiency levels. Overall, lexical stress is correctly placed in only 35.4% of instances, with B2 students achieving a significantly higher score (36%) than B1 students (29.6%). However, great variation among speakers is also observed, ranging from 0% to 68% in stress position accuracy. Stress typically falls on the last syllable regardless of the prosodic expectations, with the strong influence of syllable duration. Only proficient speakers show substantial F0 and intensity contrasts.","2024-03","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","3","9","","","","","","","","","","English","","","","WOS:001192659600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","comprehensibility; computer-assisted language learning (CAPT); ENGLISH; lexical stress; LEXICAL STRESS; pause positions; PITCH ACCENT; rhythm; spontaneous speech; STRESS DETECTION; syllable prominence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QQLFJFZA","journalArticle","2022","Wang, P","A study of an intelligent algorithm combining semantic environments for the translation of complex English sentences","JOURNAL OF INTELLIGENT SYSTEMS","","0334-1860","10.1515/jisys-2022-0048","","In order to improve the translation quality of complex English sentences, this paper investigated unknown words. First, two baseline models, the recurrent neural machine translation (RNMT) model and the transformer model, were briefly introduced. Then, the unknown words were identified and replaced based on WordNet and the semantic environment and input to the neural machine translation (NMT) model for translation. Finally, experiments were conducted on several National Institute of Standards and Technology (NIST) datasets. It was found that the transformer model significantly outperformed the RNMT model, its average bilingual evaluation understudy (BLEU) value was 42.14, which was 6.96 higher than the RNMT model, and its translation error rate (TER) was also smaller. After combining the intelligent algorithm, the BLEU values of both models improved, and the TER became smaller; the average BLEU value of the transformer model combined with the intelligent algorithm was 43.7, and the average TER was 57.68. The experiment verifies that the transformer model combined with the intelligent algorithm is reliable in translating complex sentences and can obtain higher-quality translation results.","2022-05-24","2025-02-26 20:37:00","2025-02-26 20:37:00","","623-631","","1","31","","","","","","","","","","English","","","","WOS:000799428200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","bilingual evaluation understudy; complex sentence; English translation; MACHINE TRANSLATION; SELECTION; semantic environment; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VJZJ5BVU","journalArticle","2021","Zhang, SQ; Tao, X; Chuang, YL; Zhao, XM","Learning deep multimodal affective features for spontaneous speech emotion recognition","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2020.12.009","","Recently, spontaneous speech emotion recognition has become an active and challenging research subject. This paper proposes a new method of spontaneous speech emotion recognition by using deep multimodal audio feature learning based on multiple deep convolutional neural networks (multi-CNNs). The proposed method initially generates three different audio inputs for multi-CNNs so as to learn deep multimodal segment-level features from the original 1D audio signal in three aspects: 1) a 1D CNN for 1D raw waveform modeling, 2) a 2D CNN for 2D time-frequency Mel-spectrogram modeling, and 3) a 3D CNN for temporal-spatial dynamic modeling. Then, an average-pooling is performed on the obtained segment-level classification results from 1D, 2D, and 3D CNN networks, to produce utterance-level classification results. Finally, a score-level fusion strategy is adopted as a multi-CNN fusion method to integrate different utterance-level classification results for final emotion classification. The learned deep multimodal audio features are shown to be complementary to each other so that they are combined in a multi-CNN fusion network to achieve significantly improved emotion classification performance. Experiments are conducted on two challenging spontaneous emotional speech datasets, i.e., the AFEW5.0 and BAUM-1 s databases, demonstrating the promising performance of our proposed method.","2021-03","2025-02-26 20:37:00","2025-02-26 20:37:00","","73-81","","","127","","","","","","","","","","English","","","","WOS:000698686300006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;46<br/>Total Times Cited:&nbsp;&nbsp;49<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Convolutional neural networks; Deep multimodal feature learning; NEURAL-NETWORK; Score-level fusion; Speech emotion recognition; Temporal-spatial","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CGH95GAY","journalArticle","2024","Takashima, R; Sawa, Y; Aihara, R; Takiguchi, T; Imai, Y","Dysarthric Speech Recognition Using Pseudo-Labeling, Self-Supervised Feature Learning, and a Joint Multi-Task Learning Approach","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3374874","","In this paper, we investigate the use of the spontaneous speech of dysarthric people for training an automatic speech recognition (ASR) model for them. Although the spontaneous speech of dysarthric people can be collected relatively easily compared to script-reading speech, which is obtained by having them read a prepared script, labeling the spontaneous speech of dysarthric people is very difficult and costly. For training an ASR model using unlabeled speech data, pseudo-labeling and self-supervised feature learning have been studied as effective approaches; however, the effectiveness of these approaches has not been clear when they are applied to the unlabeled dysarthric speech. In addition, pseudo-labeling may not be effective since the pseudo-labels of dysarthric speech include many errors and are not reliable. In this paper, we evaluate the above two approaches for the dysarthric speech recognition, and we propose a multi-task learning approach, which combines these approaches to train an ASR model that is robust against the errors in the pseudo-labels. Experimental results using Japanese and English datasets demonstrated that all approaches are effective, but among them, the proposed multi-task learning approach showed the best performance.","2024","2025-02-26 20:37:00","2025-02-26 20:37:00","","36990-36999","","","12","","","","","","","","","","English","","","","WOS:001185013600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","ADAPTATION; Automatic speech recognition; Data models; DATABASE; dysarthria; Multitasking; pseudo-labeling; Representation learning; self-supervised feature learning; Self-supervised learning; Speech recognition; Task analysis; Training","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FIY7PWGJ","journalArticle","2022","Miao, HR; Cheng, GF; Zhang, PY","Low-latency transformer model for streaming automatic speech recognition","ELECTRONICS LETTERS","","0013-5194","10.1049/ell2.12349","","Transformer models have made great progress in automatic speech recognition. However, it is challenging for streaming transformer models to make trade-off between output latency and recognition accuracy. In this letter, it is aimed to propose a low-latency transformer model with satisfactory recognition accuracy. First, a streaming transformer is designed and explain how it works streamingly. Second, the authors propose to use CTC during training to minimise the latency of transformer models. Finally, the authors also propose to utilise CTC as a backup during decoding to ensure that the low-latency characteristic is maintained. The authors fairly compare our streaming transformer model to existing streaming models, particularly the transducer model, which is a popular low-latency approach. The experiments show that, while having comparable output latency, the transformer model outperforms the transducer model by average relative character (or word) error rate reduction of 22.18%, 26.71% and 19.36% on HKUST, Switchboard and Call Home, respectively.","2022-01","2025-02-26 20:37:00","2025-02-26 20:37:00","","44-46","","1","58","","","","","","","","","","English","","","","WOS:000711330100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;16</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K29GHBJB","journalArticle","2021","Faes, J; Gillis, S","Consonant and vowel production in the spontaneous speech productions of children with auditory brainstem implants","CLINICAL LINGUISTICS & PHONETICS","","0269-9206","10.1080/02699206.2020.1869833","","Auditory brainstem implantation provides hearing sensations in children and adults with anomalies of the auditory nerves. In children, perceptual benefits have been established, and research already demonstrated (limited) effects on children's speech production. The current study extends the literature by scrutinizing the phonological development of three children with ABI. Spontaneous speech samples were used to establish their phonemic inventories of vowels, word-initial consonants and word-final consonants, both independently of the target phoneme and relative to the target phoneme. The three children produced all vowels with longer device use and larger vocabulary size. Word-initial and word-final consonants appeared in the three children's spontaneous productions. However, the segmental accuracy was only moderate in the children's productions.","2021-12-02","2025-02-26 20:37:00","2025-02-26 20:37:00","","1132-1160","","12","35","","","","","","","","","","English","","","","WOS:000606869800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","Auditory brainstem implantation; COCHLEAR IMPLANT; consonants; pediatric; phoneme inventory; PRODUCTION ACCURACY; vowels","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RFW36NBT","journalArticle","2023","Irfan, M; Shahrestani, S; Elkhodr, M","Enhancing Early Dementia Detection: A Machine Learning Approach Leveraging Cognitive and Neuroimaging Features for Optimal Predictive Performance","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app131810470","","Dementia, including Alzheimer's Disease (AD), is a complex condition, and early detection remains a formidable challenge due to limited patient records and uncertainty in identifying relevant features. This paper proposes a machine learning approach to address this issue, utilizing cognitive and neuroimaging features for training predictive models. This study highlighted the viability of cognitive test scores in dementia detection-a procedure that offers the advantage of simplicity. The AdaBoost Ensemble model, trained on cognitive features, displayed a robust performance with an accuracy rate of approximately 83%. Notably, this model surpassed benchmark models such as the Artificial Neural Network, Support Vector Machine, and Naive Bayes. This study underscores the potential of cognitive tests and machine learning for early dementia detection.","2023-09","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","18","13","","","","","","","","","","English","","","","WOS:001145098300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","alzheimer; cognitive features; dementia; machine learning; neighborhood component analysis (NCA); neuroimaging features","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CJX2WZXV","journalArticle","2024","Rozhanskiy, F","SYNTAX OF THE NUMERAL PHRASE IN SOIKKOLA INGRIAN","EESTI JA SOOME-UGRI KEELETEADUSE AJAKIRI-JOURNAL OF ESTONIAN AND FINNO-UGRIC LINGUISTICS","","1736-8987","10.12697/jeful.2024.15.1.06","","This article describes the numeral phrase in Soikkola Ingrian. It focuses on the external syntax of the numeral phrase (first of all, case marking of its components) and on the number agreement between the numeral phrase in the subject position and the predicate. The sources of data are (a) a collection of spontaneous speech samples recorded in 2006-2013, (b) samples of spontaneous speech published by previous researchers, (c) elicited material recorded in 2006-2023. Though the numeral phrase in Soikkola Ingrian preserves most of the common Finnic traits, it has some less common features, e.g. agreement in all numeral phrases with a numeral ending in 'one' or expressing approximate quantity through a reversed word order. Most likely these features arose due to the contact influence of Russian.","2024","2025-02-26 20:37:00","2025-02-26 20:37:00","","187-220","","1","15","","","","","","","","","","English","","","","WOS:001265581500006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","agreement; case marking; Ingrian; language contact; numeral phrase; syntax","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BCZ3YJ59","journalArticle","2023","Alderete, J; Baese-berk, M; Brasoveanu, A; Law, JHK","A New Corpus of Lexical Substitution and Word Blend Errors: Probing the Semantic Structure of Lemma Access Failures","JOURNAL OF COGNITION","","2514-4820","10.5334/joc.278","","Models of lemma access in language production predict occasional mis-selection of lemmas linked to highly similar concepts (synonyms) and concepts standing in a set-superset relation (subsumatives). It is unclear, however, if such errors occur in spontaneous speech, and if they do, whether humans can detect them given their minimal impact on sentence meaning. This data report examines a large corpus of English spontaneous speech errors and documents a low but non-negligible occurrence of these categories. The existence of synonym and subsumative errors is documented in a larger open access data set that supports a range of new investigations of the semantic structure of lexical substitution and word blend speech errors.","2023","2025-02-26 20:37:00","2025-02-26 20:37:00","","32-32","","1","6","","","","","","","","","","English","","","","WOS:001376165400020","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","lemma selection; lexical substitutions; RETRIEVAL; semantic processing; speech errors; SPEECH ERRORS; SPREADING-ACTIVATION THEORY; word blends","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CBFCW4QC","journalArticle","2024","Niu, B; Zhuang, XB; Lin, ZJ; Zhang, LJ","Navigation spoofing interference detection based on Transformer model","ADVANCES IN SPACE RESEARCH","","0273-1177","10.1016/j.asr.2024.07.016","","Spoofed signal interference poses a serious threat to the security of Global Navigation Satellite Systems (GNSS). In order to effectively detect spoofing signals, this paper proposes a spoofing signal detection method based on the Transformer model in the signal capture phase. When a spoofed signal is added, the capture matrix of the receiver changes. The method takes the capture matrix near the relevant peak as the data set for training the Transformer model to improve the model's ability to recognize the features of the capture matrix, and then uses the trained model to identify the capture results and get the discriminative result of whether there is deception joining. Subsequently, the trained model is embedded into the navigation receiver, and the receiver configuration is modified so that it continuously performs signal capture over the whole data and detects spoofing signals on the capture results. The experimental results show that the spoofing signal detection method based on the Transformer model has a higher detection accuracy compared to other deep learning models. For data with different search steps, its detection accuracy can reach more than 95%. When the chip delay of the spoofed signal is greater than half a chip, the detection accuracy tends to be close to 100%. For online open-source spoofing datasets, the detection algorithm can still obtain excellent detection results. The spoofing signal detection technique based on the Transformer model is of great significance to improve the security and robustness of the navigation system and has the prospect of wide application.","2024-11-15","2025-02-26 20:37:00","2025-02-26 20:37:00","","5156-5171","","10","74","","","","","","","","","","English","","","","WOS:001348825500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","AUTHENTICATION; GNSS; Navigation spoofing; Signal acquisition; Spoofing detection; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"92S3AVIK","journalArticle","2023","Tang, LJ; Zhang, ZL; Feng, FF; Yang, LZ; Li, H","Explainable Alzheimer's Disease Detection Using linguistic features From Automatic Speech Recognition","DEMENTIA AND GERIATRIC COGNITIVE DISORDERS","","1420-8008","10.1159/000531818","","Introduction: Alzheimer's disease (AD) is the most prevalent type of dementia and can cause abnormal cognitive function and pro-gressive loss of essential life skills. Early screening is thus necessary for the preven-tion and intervention of AD. Speech dysfunc-tion is an early-onset symptom of AD pa-tients. Recent studies have demonstrated the promise of automated acoustic assessment using acoustic or linguistic features extracted from speech. However, most previous stud-ies have relied on manual transcription of text to extract linguistic features, which weakens the efficiency of automated as-sessment. The present study thus investi-gates the effectiveness of automatic speech recognition (ASR) in building an end-to-end automated speech analysis model for AD detection. Methods: We implemented three publicly available ASR engines and compared the classification performance using the ADReSS-IS2020 dataset. Besides, the SHapley Additive exPlanations (SHAP) algorithm was then used to identify critical features that contributed most to model performance. Results: Three automatic transcription tools obtained mean word error rate (WER) texts of 32%, 43%, and 40%, respectively. These automated texts achieved similar or even better results than manual texts in model performance for detecting dementia, achiev-ing classification accuracies of 89.58%, 83.33%, and 81.25%, respectively. Conclusion: Our best model, using ensemble learning, is comparable to the state-of-art manual tran-scription-based methods, suggesting the possibility of an end-to-end medical assis-tance system for AD detection with ASR en-gines. Moreover, the critical linguistic fea-tures might provide insight into further stud-ies on the mechanism of AD.","2023-10","2025-02-26 20:37:00","2025-02-26 20:37:00","","240-248","","4","52","","","","","","","","","","English","","","","WOS:001026727400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","DEMENTIA; IDENTIFICATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZGGTEXCT","journalArticle","2024","Chang, JQ; Huang, HW; Thewes, M; Zhang, DM; Wu, HM","Data-Based postural prediction of shield tunneling via machine learning with physical information","COMPUTERS AND GEOTECHNICS","","0266-352X","10.1016/j.compgeo.2024.106584","","When applying machine learning algorithms to predict the posture of shield machines during tunneling, the generalization performance of these models might not be as good as expected when applied to different projects. In this study, the Transformer method was improved by incorporating physical information from finite element method (FEM) numerical simulation to enhance the generalization performance of the models, achieving accurate prediction of shield machine posture during the construction of new projects. A refined FEM numerical simulation of the shield machine construction process is established, and the FEM surrogate model is trained through the calculation of a large number of cases. Simultaneously, a data-driven machine learning model (Transformer) is developed based on historical shield machine construction data. The FEM surrogate model is then introduced into the data-driven Transformer model as physical information, resulting in the creation of a Transformer model with physical information. By comparing the prediction accuracy of the FEM surrogate model, the data-driven Transformer model and the Transformer model with physical information from a new project, the results show that the Transformer model with physical information significantly improves the prediction accuracy.","2024-10","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","174","","","","","","","","","","English","","","","WOS:001271559300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;77</p>","","","Finite element method; FINITE-ELEMENT; Machine learning with physical information; MODEL; MOMENT; RECTIFICATION; Shield machine posture; SIMULATION; Surrogate model; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GYQWCEQ5","journalArticle","2024","Iavarone, B; Morelli, MS; Brunato, D; Ghiasi, S; Scilingo, EP; Vanello, N; Dell'Orletta, F; Greco, A","The linguistic structure of an emotional text influences the sympathetic activity and the speech prosody of the reader","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2023.105776","","In this study, we present an analysis of the relationship between the linguistic profile of a text and the physiological and acoustic characteristics of the reader to improve the emotion recognition systems. To this aim, we recorded the speech and electrodermal activity (EDA) signals from 33 healthy volunteers reading neutral and affective texts aloud. We used the BioVoice toolbox and cvxEDA algorithm to estimate some of the main speech and EDA features, respectively. The selected texts were analyzed to quantify their lexical, morpho-syntactic, and syntactic properties. Correlation and Support Vector Regression analyses between linguistic and speech and EDA features have shown a significant bidirectional association between the morphosyntactic structure of the text and both sympathetic markers and voice acoustic properties. Specifically, significant relationships were observed between linguistic properties and certain EDA and speech features commonly used to evaluate human emotional state (e.g., edaSymp, mean tonic, F0). These findings suggest that lexical, morpho-syntactic, and syntactic properties may have a significant impact on an individual's emotional dynamics.","2024-03","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","89","","","","","","","","","","English","","","","WOS:001162327100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Electrodermal activity; ELECTRODERMAL ACTIVITY; Linguistic profile; Speech analysis; Support Vector Regressor","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L557AN3G","journalArticle","2024","Lim, YD; Tan, CS","Modelling and next-value prediction of beam propagation from grating structures using a simplified transformer model","OPTICS EXPRESS","","1094-4087","10.1364/OE.531050","","In this study, a simplified transformer model is used to perform next-value prediction on light coupled out from silicon photonics gratings to free space. Finite-difference time-domain (FDTD) simulation is performed to simulate the electric field (E-field) in laser light coupled from gratings with pitches of 0.6, 0.8, 1.0, 1.2, 1.4 and 1.6 mu m, to free-space. Only E-field distribution from 0.6 mu m is used in model training, and the trained transformer model is used to predict the E-field from the rest of the gratings. Prediction of accuracy up to 92.5% is obtained. The time taken for model training is 1908.4 seconds, which is significantly shorter than the conventional three-dimensional FDTD simulation that takes up to several hours. To further reduce the training time, transformer models can be trained with stepped datasets, but with compromised prediction accuracies. In summary, we demonstrated that the transformer model can be used to perform next-value E-field prediction using minimal training data. The developed and trained transformer model can be integrated to the state-of-the-art FDTD software to further expedite the existing FDTD simulation.","2024-08-26","2025-02-26 20:37:00","2025-02-26 20:37:00","","31533-31548","","18","32","","","","","","","","","","English","","","","WOS:001306695500009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","OPTICAL PHASED-ARRAY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UUUR2LKE","journalArticle","2023","Lu, YR; Wu, TH; Jeng, Y; Lee, WY; Hsu, WC; Yen, AMF; Pan, SL; Chen, YC; Chen, SLS; Chen, HH; Liou, HH","The impact of active community-based survey on dementia detection ratio in Taiwan: A cohort study with historical control","FRONTIERS IN PUBLIC HEALTH","","2296-2565","10.3389/fpubh.2022.1005252","","BackgroundAlthough early dementia detection is crucial to optimize the treatment outcomes and the management of associated symptoms, the published literature is scarce regarding the effectiveness of active screening protocols in enhancing dementia awareness and increasing the rate of early detection. The present study compared the detection ratio of an active community-based survey for dementia detection with the detection ratio of passive screening during routine clinical practice. Data for passive screening were obtained from the National Health Insurance (NHI) system, which was prospectively collected during the period from 2000 to 2003. DesignA population-based cohort study with historical control. SettingTaiwan. ParticipantsA total of 183 participants aged 65 years or older were involved in a community-based survey. Data from 1,921,308 subjects aged 65 years or older were retrieved from the NHI system. MeasurementsAn adjusted detection ratio, defined as a ratio of dementia prevalence to incidence was used. ResultsThe results showed that the dementia prevalence during the 2000-2003 period was 2.91% in the elderly population, compared with a prevalence of 6.59% when the active survey was conducted. The incidence of dementia in the active survey cohort was 1.83%. Overall, the dementia detection ratio was higher using active surveys [4.23, 95% confidence interval (CI): 2.68-6.69] than using passive detection (1.45, 95% CI: 1.43-1.47) for those aged 65-79 years. Similar findings were observed for those aged 80 years and older. ConclusionThe implementation of an active community-based survey led to a 3-fold increase in the detection rate of early dementia detection compared to passive screening during routine practice.","2023-01-06","2025-02-26 20:37:00","2025-02-26 20:37:00","","","","","10","","","","","","","","","","English","","","","WOS:000913828300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","ALZHEIMERS-DISEASE; awareness; dementia; early detection; incidence; POPULATION; prevalence; PREVALENCE; RISK; VASCULAR DEMENTIA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9A5QNAQF","journalArticle","2024","Chen, YC","Effects of technology-enhanced language learning on reducing EFL learners' public speaking anxiety","COMPUTER ASSISTED LANGUAGE LEARNING","","0958-8221","10.1080/09588221.2022.2055083","","Public speaking is considered the most anxiety-provoking speaking activity for English as a foreign language (EFL) learner. While traditional lecture-based classrooms hinder EFL learners' constant practice and frequent interaction due to large class sizes and limited time, recent developments in technology, including Artificial Intelligence (AI), Automatic Speech Analysis, and Virtual Reality (VR), may enhance language learning by offering accessible and personalized learning experiences. This study aimed to investigate the effects of technology-enhanced learning on reducing EFL learners' PSA. Thirty-three university students were divided into three groups and received either lecture-based, mobile-assisted, or VR-facilitated instruction for four weeks. The students' perceived PSA levels were reduced in all three groups after their respective instruction, but only the VR-facilitated group reached statistical significance, and there were no differences in the three groups' final oral performances. However, the two technology-enhanced language learning (TELL) groups achieved more convergent performances on the Personal Report of Public Speaking Anxiety scale compared with the non-TELL group, which indicated that the impact of individual differences may have been compensated by technology assistance. The findings suggested that the instructional feedback generated by AI decreased the participants' PSA, although the irreplaceable role of teachers as facilitators was also emphasized, while the potential of using VR in teaching public speaking was evident.","2024-05-03","2025-02-26 20:37:01","2025-02-26 20:37:01","","789-813","","4","37","","","","","","","","","","English","","","","WOS:000801132600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;22<br/>Total Times Cited:&nbsp;&nbsp;23<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","elaborative feedback; ENGLISH; explicit instruction; FEEDBACK; FOREIGN-LANGUAGE; mobile-assisted language learning; PROFICIENCY; Public speaking anxiety; STRATEGY USE; technology acceptance model; technology enhanced language learning; virtual reality exposure therapy; VIRTUAL-REALITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GTVVFL5H","journalArticle","2024","Parlak, C; Altun, Y","A Quest for Formant-Based Compact Nonuniform Trapezoidal Filter Banks for Speech Processing with VGG16","CIRCUITS SYSTEMS AND SIGNAL PROCESSING","","0278-081X","10.1007/s00034-024-02794-z","","In this text, we discuss the filter banks used for speech analysis and propose a novel filter bank for speech processing applications. Filter banks are building blocks of speech processing applications. Multiple filter strategies have been proposed, including Mel, PLP, Seneff, Lyon, and Gammatone filters. MFCC is a transformed version of Mel filters and is still a state-of-the-art method for speech recognition applications. However, 40 years after their debut, time is running out to launch new structures as novel speech features. The proposed acoustic filter banks (AFB) are innovative alternatives to dethrone Mel filters, PLP filters, and MFCC features. Foundations of AFB filters are based on the formant regions of vowels and consonants. In this study, we pioneer an acoustic filter bank comprising 11 frequency regions and conduct experiments using the VGG16 model on the TIMIT and Speech Command V2 datasets. The outcomes of the study concretely indicate that MFCC, Mel, and PLP filters can effectively be replaced with novel AFB filter bank features.","2024-11","2025-02-26 20:37:01","2025-02-26 20:37:01","","7309-7338","","11","43","","","","","","","","","","English","","","","WOS:001281629000005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;125</p>","","","Convolutional neural networks; DISCRIMINATION; Filter banks; FREQUENCY; LOUDNESS; Mel filters; MFCC; MODEL; PERCEPTION; PLP; RECOGNITION; Speech processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"98JD94RI","journalArticle","2024","Liu, YN; Zhou, D; Li, AJ; Dang, JW; Okada, S; Unoki, M","Investigation of Social Factor in Conversational Entrainments","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3491857","","Social aspects such as social roles and status play a crucial role in human-to-human conversations, where the interlocutors adapt to each other to achieve conversational entrainment and gain approval. Due to their complexity, these aspects are challenging to quantify in current dialogue systems and human-machine interaction systems. To simplify this problem, we assume that social aspects have a consistent effect on the same style of conversational scenarios. Therefore, we define the concept of ""social factor"" to measure the quantitative influence of social aspects on conversational entrainments, and propose a method to extract the social factor in different conversation styles. To do so, we designed a Chinese corpus with four conversation scenarios, arguing, comforting, convincing, and sharing happiness to investigate the importance of the social factor. We also employed an existing English corpus to predict the trajectory of conversational entrainment using the social factor. The importance of the social factors was evaluated by comparing the proposed method with a conventional method using speech features. The accuracy for classifying conversation scenarios in Chinese corpus was 52.9% by using the proposed social factor, and 51.7% by using the conventional speech features. For the English corpus, the accuracy of predicting the trajectory of conversational entrainment was 48.8% by using social factor, and 49.0% by conventional speech features. These results indicate that the social factor plays the same importance as that of the speech features. When combining speech features and social factor, the accuracy increases 6.1% in the Chinese corpus, and 2.0% in the English corpus. This suggests that social factor and speech features have distinguishable information that can compensate for each other. This study demonstrated that the social factor may be important in quantifying the pragmatic information involved in the conversations.","2024","2025-02-26 20:37:01","2025-02-26 20:37:01","","165507-165524","","","12","","","","","","","","","","English","","","","WOS:001354538100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Accuracy; Acoustics; ALIGNMENT; communication accommodation; Convergence; conversational entrainment; human-computer interaction; Linear programming; Modulation; Oral communication; Particle measurements; Principal component analysis; Social factor; Social factors; Trajectory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DB2BE5RH","journalArticle","2021","Byun, SW; Lee, SP","A Study on a Speech Emotion Recognition System with Effective Acoustic Features Using Deep Learning Algorithms","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app11041890","","The goal of the human interface is to recognize the user's emotional state precisely. In the speech emotion recognition study, the most important issue is the effective parallel use of the extraction of proper speech features and an appropriate classification engine. Well defined speech databases are also needed to accurately recognize and analyze emotions from speech signals. In this work, we constructed a Korean emotional speech database for speech emotion analysis and proposed a feature combination that can improve emotion recognition performance using a recurrent neural network model. To investigate the acoustic features, which can reflect distinct momentary changes in emotional expression, we extracted F0, Mel-frequency cepstrum coefficients, spectral features, harmonic features, and others. Statistical analysis was performed to select an optimal combination of acoustic features that affect the emotion from speech. We used a recurrent neural network model to classify emotions from speech. The results show the proposed system has more accurate performance than previous studies.","2021-02","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","4","11","","","","","","","","","","English","","","","WOS:000632103000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;18<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","FACIAL EXPRESSIONS; recurrent neural network; SET; speech analysis; speech emotion recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PYHHBQ5W","journalArticle","2021","Lagerberg, TB; Holm, K; McAllister, A; Strömbergsson, S","Measuring intelligibility in spontaneous speech using syllables perceived as understood","JOURNAL OF COMMUNICATION DISORDERS","","0021-9924","10.1016/j.jcomdis.2021.106108","","Purpose: Intelligibility, the ability to convey a message by speech, is one of the most important variables in speech-language pathology. The assessment of intelligibility is a challenge especially when it comes to spontaneous speech. The aim of the study was to investigate validity and reliability of a method for assessment of intelligibility, syllables perceived as understood (SPU); a method that is more time-efficient than previous methods based on transcription, as it does not require a master transcript for reference. Method: A group of 20 adult listeners transcribed stimuli consisting of spontaneous speech from 16 children (14 with speech sound disorder and two with typical speech and language development, age 4:4 to 8:1, M = 6:0). Intelligibility was calculated based on these orthographic transcripts, as a) proportion of syllables perceived as understood (SPU) and b) proportion of syllables correctly understood (SCU), with reference to a master transcript. Validity was checked through investigation of the correlation and difference between these two measures. Reliability was analysed with inter-listener reliability by intra-class correlation. Results: The correlation between SPU and SCU (the gold standard intelligibility score) was strong and statistically significant, with SPU being consistently higher than SCU. Inter-listener reliability for single measures of intra-class correlation of the assessment by syllables perceived as understood was moderate to low, whereas the inter-listener reliability for average measures of intraclass correlation was high. Conclusions: The method based on SPU might be used for assessment of intelligibility if the median from several listeners is used or when comparing results from the same listener over time. The SPU method might therefore be a valuable tool in a clinical and research context as a more valid option than rating scales and a more time-efficient method than the gold standard SCU method. However, it should be noted that the reliability of the SPU is not as high as for the SCU.","2021-07","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","92","","","","","","","","","","English","","","","WOS:000661168800006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","ACCURACY; Assessment; Children; CHILDREN; DYSARTHRIA; Intelligibility; LISTENER FAMILIARITY; RATINGS; RELIABILITY; SCORES; SEVERITY; SPEAKERS; Speech disorders; Spontaneous speech; VARIABILITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"83VZCWPU","journalArticle","2021","Haulcy, R; Glass, J","Classifying Alzheimer's Disease Using Audio and Text-Based Representations of Speech","FRONTIERS IN PSYCHOLOGY","","1664-1078","10.3389/fpsyg.2020.624137","","Alzheimer's Disease (AD) is a form of dementia that affects the memory, cognition, and motor skills of patients. Extensive research has been done to develop accessible, cost-effective, and non-invasive techniques for the automatic detection of AD. Previous research has shown that speech can be used to distinguish between healthy patients and afflicted patients. In this paper, the ADReSS dataset, a dataset balanced by gender and age, was used to automatically classify AD from spontaneous speech. The performance of five classifiers, as well as a convolutional neural network and long short-term memory network, was compared when trained on audio features (i-vectors and x-vectors) and text features (word vectors, BERT embeddings, LIWC features, and CLAN features). The same audio and text features were used to train five regression models to predict the Mini-Mental State Examination score for each patient, a score that has a maximum value of 30. The top-performing classification models were the support vector machine and random forest classifiers trained on BERT embeddings, which both achieved an accuracy of 85.4% on the test set. The best-performing regression model was the gradient boosting regression model trained on BERT embeddings and CLAN features, which had a root mean squared error of 4.56 on the test set. The performance on both tasks illustrates the feasibility of using speech to classify AD and predict neuropsychological scores.","2021-01-15","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","11","","","","","","","","","","English","","","","WOS:000612810800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;48<br/>Total Times Cited:&nbsp;&nbsp;51<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Alzheimer&apos; BERT; dementia detection; DEMENTIA RECOGNITION; FEATURES; i-vectors; MMSE prediction; PERFORMANCE; PICTURE DESCRIPTION TASK; PREDICTION; s disease; speech; SYSTEM; word vectors; x-vectors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q3YRLRZ6","journalArticle","2023","Inbar, M; Genzer, S; Perry, A; Grossman, E; Landau, AN","Intonation Units in Spontaneous Speech Evoke a Neural Response","JOURNAL OF NEUROSCIENCE","","0270-6474","10.1523/JNEUROSCI.0235-23.2023","","Spontaneous speech is produced in chunks called intonation units (IUs). IUs are defined by a set of prosodic cues and presumably occur in all human languages. Recent work has shown that across different grammatical and sociocultural conditions IUs form rhythms of similar to 1 unit per second. Linguistic theory suggests that IUs pace the flow of information in the discourse. As a result, IUs provide a promising and hitherto unexplored theoretical framework for studying the neural mechanisms of communication. In this article, we identify a neural response unique to the boundary defined by the IU. We measured the EEG of human participants (of either sex), who listened to different speakers recounting an emotional life event. We analyzed the speech stimuli linguistically and modeled the EEG response at word offset using a GLM approach. We find that the EEG response to IU-final words differs from the response to IU-nonfinal words even when equating acoustic boundary strength. Finally, we relate our findings to the body of research on rhythmic brain mechanisms in speech processing. We study the unique contribution of IUs and acoustic boundary strength in predicting delta-band EEG. This analysis suggests that IU-related neural activity, which is tightly linked to the classic Closure Positive Shift (CPS), could be a time-locked component that captures the previously characterized delta-band neural speech tracking.","2023-11-29","2025-02-26 20:37:01","2025-02-26 20:37:01","","8189-8200","","48","43","","","","","","","","","","English","","","","WOS:001148071000007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;86</p>","","","CLAUSE; COMPUTATIONAL PRINCIPLES; CUES; delta-band speech tracking; electroencephalography; general linear model; GRAMMAR; intonation units; LISTENERS; OSCILLATIONS; PERCEPTION; PROSODY; speech prosody; spontaneous speech processing; SYNTAX","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"77B6N6VJ","journalArticle","2023","Deng, YC; Liao, YF; Wang, YR; Chen, SH","Toward enriched decoding of mandarin spontaneous speech","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2023.102983","","A deep neural network (DNN)-based automatic speech recognition (ASR) method for enriched decoding of Mandarin spontaneous speech is proposed. It adopts an enhanced approach over the baseline model built with factored time delay neural networks (TDNN-f) and rescored with RNNLM to first building a baseline system composed of a TDNN-f acoustic model (AM), a trigram language model (LM), and a recurrent neural network language model (RNNLM) to generate a word lattice. It then sequentially incorporates a multi-task Part-ofSpeech-RNNLM (POS-RNNLM), a hierarchical prosodic model (HPM), and a reduplication-word LM (RLM) into the decoding process by expanding the word lattice and performing rescoring to improve recognition performance and enrich the decoding output with syntactic parameters of POS and punctuation (PM), prosodic tags of word-juncture break types and syllable prosodic states, and an edited recognition text with reduplication words being eliminated. Experimental results on the Mandarin conversational dialogue corpus (MCDC) showed that SER, CER, and WER of 13.2 %, 13.9 %, and 19.1 % were achieved when incorporating the POS-RNNLM and HPM into the baseline system. They represented relative SER, CER, and WER reductions of 7.7 %, 7.9 % and 5.0 % as comparing with those of the baseline system. Futhermore, the use of the RLM resulted in additional 3 %, 4.6 %, and 4.5 % relative SER, CER, and WER reductions through eliminating reduplication words.","2023-10","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","154","","","","","","","","","","English","","","","WOS:001084498700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Disfluencies and paralinguistic phenomena; Hierarchical prosodic model; Mandarin conversational dialogue corpus; Part -of -speech language model; Reduplication -word language model; Spontaneous speech recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"URDZRFAD","journalArticle","2024","Xu, XY; Deng, B; Wang, J; Yi, GS","Individual Prediction of Electric Field Induced by Deep-Brain Magnetic Stimulation With CNN-Transformer","IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING","","1534-4320","10.1109/TNSRE.2024.3408902","","Deep-brain Magnetic Stimulation (DMS) can improve the symptoms caused by Alzheimer's disease by inducing rhythmic electric field in the deep brain, and the induced electric field is rhythm-dependent. However, calculating the induced electric field requires building a voxel model of the brain for the stimulated object, which usually takes several hours. In order to obtain the rhythm-dependent electric field induced by DMS in real time, we adopt a CNN-Transformer model to predict it. A data set with a sample size of 7350 is established for the training and testing of the model. 10-fold cross validation is used to determine the optimal hyperparameters for training CNN-Transformer. The combination of 5-layer CNN and 6-layer Transformer is verified as the optimal combination of CNN-Transformer model. The experimental results show that the CNN-Transformer model can complete the prediction in 0.731s (CPU) or 0.042s (GPU), and the overall performance metrics of prediction can reach: MAE =0.0269, RMSE =0.0420, MAPE =4.61% and R-2=0.9627. The prediction performance of the CNN-Transformer model for the hippocampal electric field is better than that of the brain grey matter electric field, and the stimulation rhythm has less influence on the model performance than the coil configuration. Taking the same dataset to train and test the separate CNN model and Transformer model, it is found that CNN-Transformer has better prediction performance than the separate CNN model and Transformer model in the task of predicting electric field induced by DMS.","2024","2025-02-26 20:37:01","2025-02-26 20:37:01","","2143-2152","","","32","","","","","","","","","","English","","","","WOS:001246153200002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Brain modeling; CNN-transformer; Deep-brain magnetic stimulation; electric field; Electric fields; Magnetic heads; Mathematical models; Permittivity; Predictive models; rhythm-dependent; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PY4S9SSQ","journalArticle","2024","Niculescu, O","A PRELIMINARY ACCOUNT OF INBREATHS IN ROMANIAN SPONTANEOUS SPEECH","REVUE ROUMAINE DE LINGUISTIQUE-ROMANIAN REVIEW OF LINGUISTICS","","0035-3957","10.59277/RRL.2024.1-2.10","","Human speech is a blend between verbal and non-verbal vocalisations (NVVs). Based on previous studies pertaining to different research fields, this article focuses on breath intakes occurring in spontaneous speech. Classified as NVVs, alongside other phenomena such as vegetative sounds, affect bursts, onomatopoeia, filler particles and melodic utterances, inbreaths perform multiple and often cumulative roles in the discourse. Moreover, the interplay between speech planning and breathing control has been extensively researched in numerous studies. Analyses ofNVVs in human speech have the potential of bridging the gap between various research domains, ranging from psycholinguistics and clinical linguistics to discourse management and speech planning, forensic voice comparison, as well as language processing. While the topic remains relatively unexplored in Romanian linguistics, our current study aims to broaden our understanding of the distribution and acoustic correlatesof inbreaths in monologue speech","2024","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","1-2","69","","","","","","","","","","English","","","","WOS:001321979500010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","breath intakes; CLICKS; non-verbal vocalisations; RESPIRATORY RATE; Romanian connected speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2NEJNBIL","journalArticle","2024","Li, F; Liu, HL; Wang, W; Ma, JW","Swin Transformer for Seismic Denoising","IEEE GEOSCIENCE AND REMOTE SENSING LETTERS","","1545-598X","10.1109/LGRS.2024.3358234","","Seismic noise suppression is an important preprocessing stage for obtaining high-quality seismic signals, which are crucial for seismic exploration. Deep learning methods have achieved excellent results in the field of seismic signal processing. Currently, many researchers have used convolutional neural networks (CNNs) for seismic signal denoising, but few have used Transformer model for related research. We apply the swin transformer model, an improved version of transformer model based on the self-attention mechanism, to denoise 2-D seismic data. The swin transformer calculates self-attention within shifted windows, effectively improving information exchange within the different windows. It performs well in suppressing random seismic noise to improve the signal-to-noise ratio.","2024","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","21","","","","","","","","","","English","","","","WOS:001164283100008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","Seismic denoising; self-attention mechanism; shifted window; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YT5C25L9","journalArticle","2023","Liu, Y","Product Image Recommendation with Transformer Model Using Deep Reinforcement Learning","INTERNATIONAL JOURNAL OF IMAGE AND GRAPHICS","","0219-4678","10.1142/S0219467825500202","","A product image recommendation algorithm with transformer model using deep reinforcement learning is proposed. First, the product image recommendation architecture is designed to collect users' historical product image clicking behaviors through the log information layer. The recommendation strategy layer uses collaborative filtering algorithm to calculate users' long-term shopping interest and gated recurrent unit to calculate users' short-term shopping interest, and predicts users' long-term and short-term interest output based on users' positive and negative feedback sequences. Second, the prediction results are fed into the transformer model for content planning to make the data format more suitable for subsequent content recommendation. Finally, the planning results of the transformer model are input to Deep Q-Leaning Network to obtain product image recommendation sequences under the learning of this network, and the results are transmitted to the data result layer, and finally presented to users through the presentation layer. The results show that the recommendation results of the proposed algorithm are consistent with the user's browsing records. The average accuracy of product image recommendation is 97.1%, the maximum recommended time is 1.0s, the coverage and satisfaction are high, and the practical application effect is good. It can recommend more suitable products for users and promote the further development of e-commerce.","2023-11","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","06","23","","","","","","","","","","English","","","","WOS:001042500400006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","deep Q-learning network; deep reinforcement learning; gated recurrent unit; NETWORKS; Product image recommendation; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SNHT6DLF","journalArticle","2022","Li, C; Fan, MB; Cao, BH; Wang, Q","Accurate Thickness Measurement Using Eddy Current System Based on Novel Transformer Model","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2022.3218108","","Eddy current (EC) testing has been widely regarded as a popular tool for thickness measurement due to the advantages of noncontact, low cost, and efficiency. Phase signature is believed to change linearly as a function of specimen thickness using the conventional transformer model, which, however, does not take into account the effect of EC diffusion and reflection. In this work, a novel transformer model is developed, and an accurate method for thickness measurement is proposed subsequently. Firstly, true skin depth is formulated with a simple but accurate function, and an equivalent thickness is introduced to characterize ECs considering the difference between the standard and true skin depth. Secondly, the use of the thickness of equivalent ECs develops the novel transformer model, and a novel method is figured out to improve the accuracy of thickness measurement. Basically, the difference between the true and standard skin depth is closely related to excitation frequency, liftoff distance and the electromagnetic properties of a specimen. Therefore, a correction parameter is needed and it should be redetermined for different cases. Finally, an EC system was built, and the experiments were carried out to evaluate the novel method. The results show that it outputs more accurate specimen thickness, especially for low conductive materials.","2022","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","71","","","","","","","","","","English","","","","WOS:000880647100005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","Attenuation; Conductivity; CONDUCTIVITY; Detecting system; eddy current (EC); Eddy currents; exponential relationship; METALLIC LAYERS; novel transformer model; phase signature; PLATES; PROBE; Skin; Standards; Testing; thickness measurement; Thickness measurement; true skin depth","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3LZPS8MN","journalArticle","2024","Luo, Q; Di, YZ; Zhu, TS","Predictive modeling of neuroticism in depressed and non-depressed cohorts using voice features","JOURNAL OF AFFECTIVE DISORDERS","","0165-0327","10.1016/j.jad.2024.02.021","","Background: Neuroticism's impact on psychopathological and physical health issues has significant public health implications. Multiple studies confirm its predictive effect on suicide risk among depressed patients. However, previous research lacks a standardized criterion for assessing neuroticism through speech, often relying on simple features (such as pitch, loudness and MFCCs). This study aims to improve upon this by extracting features using advanced pre -trained speaker embedding models (i-vector and x -vector extractors). Additionally, unlike prior studies utilizing general population data, we explore neuroticism prediction in depressed and non -depressed subgroups. Methods: We collected edited discourse data from clinical interviews of 3580 depressed individuals and 4016 healthy individuals from the CONVERGE study. Instead of solely extracting Low -Level Acoustic Descriptors, we incorporated i-vector and x -vector features. We compared the performance of three different features in predicting neuroticism and explored their combination to enhance model accuracy. Results: The SVR model, combining three speech features with downscaled features to 300, exhibited the highest performance in predicting neuroticism scores. It achieved a coefficient of determination (R -squared) of 0.3 or higher and a correlation of 0.56 between predicted and actual values. The predictive classification accuracy of speech features for neuroticism in specific populations (healthy and depressed) exceeded 60 %. Limitations: This study included only women. Conclusion: Combining diverse speech features enhances the predictive capacity of models using speech features to assess neuroticism, particularly in specific populations. This study lays the foundation for future exploration of speech features in neuroticism prediction.","2024-05-01","2025-02-26 20:37:01","2025-02-26 20:37:01","","395-402","","","352","","","","","","","","","","English","","","","WOS:001202669200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Assessment/diagnosis; Clinical trials; Computer/internet technology; Depression; DISORDERS; Neuroticism; PERSONALITY; SPEECH; VALIDATION; VECTORS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2VB52RM8","journalArticle","2023","Cui, BW; Liu, MY; Li, SQ; Jin, ZF; Zeng, Y; Lin, XY","Deep learning methods for atmospheric PM2.5 prediction: A comparative study of transformer and CNN-LSTM-attention","ATMOSPHERIC POLLUTION RESEARCH","","1309-1042","10.1016/j.apr.2023.101833","","A transformer-based method was firstly developed to predict the hourly PM2.5 concentration at 12 monitoring stations in Beijing. Convolutional neural network-long short-term memory-attention mechanism (CNN-LSTM-Attention) model were introduced to compare with Transformer model. Experiments on historical long time series data and future prediction were conducted to evaluate the model performance and generalization ability over a long period of time. The four metrics, namely, the explained variance score (EVS), R2, mean absolute error (MAE), and mean square error (MSE), were selected to evaluate the models. The results revealed that the EVS, MAE, MSE, and R2 values of Transformer model were 12%, 9%, 6%, and 30% higher than those of the CNN-LSTM-Attention model, respectively. The forecast results revealed that the Transformer model outperformed the CNN-LSTM-Attention model in terms of the goodness-of-fit R2 (94.4% vs. 83.6%). Transformer model can capture short-term pollution changes affected by abruptly changing meteorological conditions and long-term trends with significant seasonal changes, especially in autumn and winter when the pollution situation is more complex. Transformer model has obvious advantages in overcoming the interdependence problem of the influencing factors in long sequences, providing a new method for the long-term prediction of air quality.","2023-09","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","9","14","","","","","","","","","","English","","","","WOS:001118662100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;29<br/>Total Times Cited:&nbsp;&nbsp;30<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Air pollution; Deep learning; EMISSION; MACHINE; MODEL; NETWORK; Predictive model; Regional transmission","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S9M6MA9J","journalArticle","2022","Yonezawa, R","Development of a reversible transformer model for the calculation of inrush currents energizing from higher and lower voltage windings","ELECTRICAL ENGINEERING IN JAPAN","","0424-7760","10.1002/eej.23365","","Transformers are normally energized from the higher voltage winding. In power system restoration, however, they may be energized from the lower voltage winding. Therefore, a reversible transformer model that is able to accurately calculate inrush currents and some other low-frequency transients is required regardless of which winding is energized. Although a reversible transformer model based on a topology-based model that considers magnetic couplings between phases has been proposed, it is difficult to determine the parameters of the model because iron-core and winding design information are not available in most cases. In addition, the approximation of the design information required when such information is not available does not always hold accurately. In this article, a reversible transformer model that can be composed only from available information such as nameplates and test reports, without using the design information (or the approximation), by using mutually coupled magnetic resistances has been developed. As a result of verification using a 500 VA single-phase three-winding transformer, it is indicated that the inrush currents calculated by the developed model are in good agreement with those obtained by the laboratory measurements using the test transformer regardless of which winding is energized.","2022-06","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","2","215","","","","","","","","","","English","","","","WOS:000765998000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;14</p>","","","air-core inductance; black start; electromagnetic transient analysis; energization from lower voltage winding; LOW-FREQUENCY; reversible transformer model; TRANSIENTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KE48MM3W","journalArticle","2024","Rusz, J; Krack, P; Tripoliti, E","From prodromal stages to clinical trials: The promise of digital speech biomarkers in Parkinson's disease","NEUROSCIENCE AND BIOBEHAVIORAL REVIEWS","","0149-7634","10.1016/j.neubiorev.2024.105922","","Speech impairment is a common and disabling symptom in Parkinson's disease (PD), affecting communication and quality of life. Advances in digital speech processing and artificial intelligence have revolutionized objective speech analysis. Given the complex nature of speech impairment, acoustic speech analysis offers unique biomarkers for neuroprotective treatments from the prodromal stages of PD. Digital speech biomarkers can monitor levodopa-induced motor complications, detect the effects of deep brain stimulation, and provide feedback for behavioral speech therapy. This review updates the mechanisms underlying speech impairment, the impact of speech phenotypes, and the effects of interventions on speech. We evaluate the strengths, potential weaknesses, and suitability of promising digital speech biomarkers in PD for capturing disease progression and treatment efficacy. Additionally, we explore the translational potential of PD speech biomarkers to other neuropsychiatric diseases, offering insights into motion, cognition, and emotion. Finally, we highlight knowledge gaps and suggest directions for future research to enhance the use of quantitative speech measures in disease-modifying clinical trials. The findings demonstrate that one year is sufficient to detect disease progression in early PD through speech biomarkers. Voice quality, pitch, loudness, and articulation measures appear to capture the efficacy of treatment interventions most effectively. Certain speech features, such as loudness and articulation rate, behave oppositely in different neurological diseases, offering valuable insights for differential diagnosis. In conclusion, this review highlights speech as a biomarker in tracking disease progression, especially in the prodromal stages of PD, and calls for further longitudinal studies to establish its efficacy across diverse populations.","2024-12","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","167","","","","","","","","","","English","","","","WOS:001344387900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;164</p>","","","Acoustic; ARTICULATION; DEEP BRAIN-STIMULATION; Dysarthria; DYSARTHRIA; DYSFLUENCY; FLUCTUATIONS; FOLLOW-UP; IMPAIRMENT; LARYNGEAL; Machine learning; Neurological diseases; Parkinson's disease; Speech; SUBTHALAMIC NUCLEUS STIMULATION; Voice; VOICE DISORDERS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S6YY9SPK","journalArticle","2023","Kim, JY","Spanish-English Cross-Linguistic Influence on Heritage Bilinguals' Production of Uptalk","LANGUAGES","","2226-471X","10.3390/languages8010022","","The present study examines the production of uptalk in Spanish and in English by Spanish heritage speakers in Southern California. Following the L2 Intonation Learning Theory, we propose that cross-linguistic influence in heritage bilinguals' uptalk may occur along multiple dimensions of intonation. In this study, we examined the systemic dimension (i.e., presence of uptalk and presence of uptalk with IP-final deaccenting), the frequency dimension (i.e., frequency of uptalk and frequency of uptalk with IP-final deaccenting), and the realizational dimension (i.e., pitch excursion and rise duration) of heritage bilinguals' uptalk. Our data showed that the three dimensions of intonation demonstrate varying degrees of cross-linguistic influence. The heritage bilinguals produced uptalk with IP-final deaccenting in both languages (i.e., systemic dimension), but produced it more in English than in Spanish (i.e., frequency dimension). That is, IP-final deaccenting emerges in heritage bilinguals' uptalk in Spanish, but heritage bilinguals seem to recognize that this is an English feature that is not allowed in Spanish and try to suppress it as much as possible when producing uptalk in Spanish. However, in the realizational dimension, the heritage bilinguals demonstrated either phonetic assimilation to English (i.e., pitch excursion) or individual variability conditioned by language learning experience (i.e., rise duration). The asymmetry found across the dimensions suggests that, when bilinguals' two languages are in competition for finite online resources, such as in the case of spontaneous speech production, phonological distinctions between L1 and L2 prosodic structures are kept, whereas phonetic differences that do not lead to any change in meaning are more prone to undergo cross-linguistic influence in order to reduce online processing cost. This study attempts to fill a gap in the literature on the cross-linguistic influence of intonation by bringing attention to heritage bilinguals. Heritage bilingualism introduces bilingual contexts that are often left unnoticed in traditional L2 acquisition scenarios (e.g., transfer from L2 to L1 intonation, asymmetry between order of acquisition and language dominance). Given that many aspects of cross-linguistic influence are shared across bilinguals, the investigation of heritage bilinguals' intonation will contribute to building robust models of bilingual intonation.","2023-03","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","1","8","","","","","","","","","","English","","","","WOS:000959064900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;148</p>","","","ACQUISITION; CONTACT; cross-linguistic influence; heritage language intonation; heritage speakers; INTONATION; L2 ENGLISH; L2 Intonation Learning Theory; LEARNERS; MARKING; PITCH; PROSODY; SPEAKERS; TUNES; uptalk","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7D58RRU2","journalArticle","2024","Guo, L","Research on automatic error-checking in English short text translation by a neural network algorithm","ARTIFICIAL LIFE AND ROBOTICS","","1433-5298","10.1007/s10015-024-00952-9","","With the growing population of English learners, how to improve the efficiency of English learning has become a focus of research. This article focuses on automatic error-checking in English short text translation. The Transformer model was enhanced by combining with the bidirectional gated recurrent unit (BiGRU) algorithm to create a dual-encoder model that better captures information within input sequences. Experiments were then conducted on different corpora. The improved Transformer model obtained a F0.5\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$${\text{F}}_{0.5}$$\end{document} of 59.09 on CoNLL-2014 and 61.05 Google-bilingual evaluation understudy (GLEU) on JFLEG, both of which were better than the other methods compared. The case analysis showed that the improved Transformer model accurately found errors in short text translation. The findings indicate that the proposed approach is reliable in the automatic error-checking of English short text translation and can be applied in practice.","2024-08","2025-02-26 20:37:01","2025-02-26 20:37:01","","423-429","","3","29","","","","","","","","","","English","","","","WOS:001236114300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","Automatic error-checking; English; Neural network algorithm; Short text translation; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VUCZ8TQ7","journalArticle","2024","Fu, YQ; Xu, L; Zhang, YJ; Zhang, LS; Zhang, PF; Cao, L; Jiang, T","Classification and diagnosis model for Alzheimer's disease based on multimodal data fusion","MEDICINE","","0025-7974","10.1097/MD.0000000000041016","","Alzheimer disease (AD) is the most commonly occurring neurodegenerative disease. However, current diagnostics for AD primarily rely on invasive tests, which limit the application of diagnostic procedures in early screening. Speech, as a noninvasive biomarker, is closely associated with AD but has not been fully leveraged as a diagnostic tool. This study develops a novel early AD diagnosis method that uses primitive speech and explores its potential application in community screening. Moreover, the study proposes an innovative multimodal method for speech feature fusion that combines acoustic and semantic information to differentiate patients with AD from normal controls. This method uses the ImageBind audio encoder to extract acoustic features and the Embeddings from Language Model to extract semantic features, thereby effectively integrating the features by mid-level fusion. The training set comprises 166 speech recordings, which comprise 87 samples from individuals with AD and 79 samples from healthy control subjects. The ratio of training set to test set is 7:3. Evaluation of the Alzheimer dementia recognition through spontaneous speech only dataset showed that the proposed model achieved a classification accuracy of 0.903 and a recall rate of 1, and it considerably outperformed existing baseline models, thereby confirming the effectiveness of the proposed approach to AD diagnosis. This study applies the multimodal fusion of speech features to an early AD diagnostic procedure and achieves excellent performance. The findings of this study not only provide a new approach to noninvasive AD screening but also open new pathways to the early diagnosis of other neurodegenerative diseases.","2024-12-27","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","52","103","","","","","","","","","","English","","","","WOS:001386155600050","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Alzheimer disease; classification; deep learning; DEMENTIA; LANGUAGE; multimodal fusion; speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3RV3Z4LP","journalArticle","2023","Peng, PA; Lei, R; Wang, JM","Enhancing Microseismic Signal Classification in Metal Mines Using Transformer-Based Deep Learning","SUSTAINABILITY","","2071-1050","10.3390/su152014959","","As microseismic monitoring technology gains widespread application in mine risk pre-warning, the demand for automatic data processing has become increasingly evident. One crucial requirement that has emerged is the automatic classification of signals. To address this, we propose a Transformer-based method for signal classification, leveraging the global feature extraction capability of the Transformer model. Firstly, the original waveform data were framed, windowed, and feature-extracted to obtain a 16 x 16 feature matrix, serving as the primary input for the subsequent microseismic signal classification models. Then, we verified the classification performance of the Transformer model compared with five microseismic signal classification models, including VGG16, ResNet18, ResNet34, SVM, and KNN. The experimental results demonstrate the effectiveness of the Transformer model, which outperforms previous methods in terms of accuracy, precision, recall, and F1 score. In addition, a comprehensive analysis was performed to investigate the impact of the Transformer model's parameters and feature importance on outcomes, which provides a valuable reference for further enhancing microseismic signal classification performance.","2023-10","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","20","15","","","","","","","","","","English","","","","WOS:001089764600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","automatic classification; deep learning; metal mines; microseismic monitoring; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HE4R2RM2","journalArticle","2024","Zhou, MX; Cheng, B; Liu, JB; Pei, YK; Yao, RN; Liu, Y; Li, F","Research on the Prediction Method of Conducted Interference in Flyback Converters based on the High-frequency Transformer Model","APPLIED COMPUTATIONAL ELECTROMAGNETICS SOCIETY JOURNAL","","1054-4887","10.13052/2024.ACES.J.390110","","Conducted electromagnetic interference (EMI) has always been a challenge for designers of switched -mode power supplies. Flyback converters are used in various applications. However, as the switching frequency of these converters increases, the issue of electromagnetic interference becomes progressively more severe. In light of this, this paper presents a predictive method for conducted interference in flyback converters, based on a high -frequency transformer model. A high -frequency transformer model topology is proposed, integrating traditional inductance models with a three -capacitor model. Subsequently, a self -organizing migrating algorithm (SOMA) is employed for the extraction of parameters from the high -frequency transformer model, and a high -frequency model is established for a transformer. Finally, the high -frequency model is applied to the prediction of conducted interference in flyback converters. The results demonstrate that the proposed predictive method can effectively forecast the actual conducted interference, thereby providing a reference for suppression of conducted electromagnetic interference.","2024-01","2025-02-26 20:37:01","2025-02-26 20:37:01","","81-90","","1","39","","","","","","","","","","English","","","","WOS:001258729600010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","Conducted interference; high-frequency model; interference prediction; self-organizing migrating algorithm (SOMA); STRAY CAPACITANCES; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BBUYYQAV","journalArticle","2022","Zhang, YW; Wang, ZX; Sun, ZH; Huang, JP","A DEEP LEARNING PROGRAM FOR PREDICTING SAP FLOW OF LARIX OLGENSIS","WOOD RESEARCH","","1336-4561","10.37763/wr.1336-4561/67.5.875887","","Plant sap flow is crucial to understanding plant transpiration, plant hydraulic functioning and physiological properties. In this study, a method for predicting trunk sap flow of Larix olgensis using deep learning was proposed. The method is based on the combined use of Long-short term memory network (LSTM) and transformer model, noted as LSTM-transformer model. The experimental results show that the proposed method provides more accurate prediction quality in terms of correlation coefficient (R2), root mean square error (RMSE) and mean absolute error (MAE), compared to the state of the art forecast methods such as BP, DNN, LSTM, and transformer models.","2022","2025-02-26 20:37:01","2025-02-26 20:37:01","","875-887","","5","67","","","","","","","","","","English","","","","WOS:000876996600014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Larix olgensis; LSTM-transformer model; MAIZE; NEURAL-NETWORK; sap flow prediction; stem sap flow density; TRANSPIRATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3KSEKSNA","journalArticle","2023","Gao, Y; Miyata, S; Matsunami, Y; Akashi, Y","Spatio-temporal interpretable neural network for solar irradiation prediction using transformer","ENERGY AND BUILDINGS","","0378-7788","10.1016/j.enbuild.2023.113461","","Deep learning models have been increasingly applied in the field of solar radiation prediction. However, the characteristics of a deep learning black box model restrict its application in practical scenarios such as model predictive control. Because energy system controllers may be unable to make final decisions based solely on the predictions of a black-box model. This study considers both the temporal and spatial dependencies of solar radiation predictions through unfolding sequences and applying a transformer model As the results indicate, the transformer model used can improve the mean absolute percent error by approximately 20.9% and the mean squared error by 14.3% compared to the baseline recurrent neural network model. At the same time, detailed case studies show that the transformer model heavily considers humidity and temperature when predicting the more significant outcomes Finally, the detailed results of a one-step analysis prove that the change in weight of the transformer model is related to the change in outdoor weather conditions.","2023-10-15","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","297","","","","","","","","","","English","","","","WOS:001069404900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","Building energy management; ENERGY-CONSUMPTION; IMPACT; Interpretable deep learning; JAPAN; RADIATION; Solar irradiation prediction; SYSTEM; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"954X6UIY","journalArticle","2022","Shi, C; Meng, QH; Nie, MS","A FEASIBLE ARRHYTHMIA CLASSIFICATION ALGORITHM BASED ON TRANSFORMER MODEL","JOURNAL OF NONLINEAR AND CONVEX ANALYSIS","","1345-4773","","","The auto-classification of arrhythmias plays an essential role in the earlier prevention and diagnosis of cardiovascular disease. Existing deep learning-based methods for arrhythmia classification commonly employ convolutional structures to process spatial information, and employ multiple approaches to process temporal information across data. We propose Arrhythmia Classification Algorithm Based on Transformer Model (CTA) that combines the Transformer model and the Attention mechanism for the prediction of ECG in order to leverage the spatial features and temporal information of the ECG signal. The results of experiments conducted on large datasets in the domain of ECG signals show that the proposed algorithm provides excellent prediction and classification per-formance and serves as a diagnostic aid for doctors.","2022","2025-02-26 20:37:01","2025-02-26 20:37:01","","2035-2047","","9","23","","","","","","","","","","English","","","","WOS:000883634900020","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Arrhythmia classification; attention mechanism; ECG; traneformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PXRBEXW7","journalArticle","2024","Janes, A; Mcclay, E; Gurm, M; Boucher, TQ; Yeung, HH; Iarocci, G; Scheerer, NE","Predicting Social Competence in Autistic and Non-Autistic Children: Effects of Prosody and the Amount of Speech Input","JOURNAL OF AUTISM AND DEVELOPMENTAL DISORDERS","","0162-3257","10.1007/s10803-024-06363-w","","Purpose: Autistic individuals often face challenges perceiving and expressing emotions, potentially stemming from differences in speech prosody. Here we explore how autism diagnoses between groups, and measures of social competence within groups may be related to, first, children's speech characteristics (both prosodic features and amount of spontaneous speech), and second, to these two factors in mothers' speech to their children. Methods: Autistic (n = 21) and non-autistic (n = 18) children, aged 7-12 years, participated in a Lego-building task with their mothers, while conversational speech was recorded. Mean F0, pitch range, pitch variability, and amount of spontaneous speech were calculated for each child and their mother. Results: The results indicated no differences in speech characteristics across autistic and non-autistic children, or across their mothers, suggesting that conversational context may have large effects on whether differences between autistic and non-autistic populations are found. However, variability in social competence within the group of non-autistic children (but not within autistic children) was predictive of children's mean F0, pitch range and pitch variability. The amount of spontaneous speech produced by mothers (but not their prosody) predicted their autistic children's social competence, which may suggest a heightened impact of scaffolding for mothers of autistic children. Conclusion: Together, results suggest complex interactions between context, social competence, and adaptive parenting strategies in driving prosodic differences in children's speech.","2024-05-04","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","","","","","","","","","","","English","","","","WOS:001233393800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;93</p>","","","ADULTS; ATTENTION; Autism spectrum disorder (ASD); COMMUNICATION; INDIVIDUALS; INFANT-DIRECTED SPEECH; LANGUAGE; MIND; Mothers; PERCEPTION; Pitch; Prosody; Social competence; SPECTRUM DISORDERS; Speech; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4AMQ7XDE","journalArticle","2022","Faes, J; Gillis, J; Gillis, S","Speech production accuracy of children with auditory brainstem implants: A comparison with peers with cochlear implants and typical hearing using Levenshtein Distance","FIRST LANGUAGE","","0142-7237","10.1177/01427237211042216","","Auditory brainstem implantation (ABI) is a recent innovation in pediatric hearing restoration in children with a sensorineural hearing impairment. Only limited information is available on the spontaneous speech development of severe-to-profound congenitally hearing-impaired children who received an ABI. The purpose of this study was to investigate longitudinally the accuracy of ABI children's word productions in spontaneous speech in comparison to the accuracy of children who received a cochlear implant and children with normal hearing. The data of this study consist of recordings of the spontaneous speech of the first three Dutch-speaking children living in Belgium who received an ABI. The children's utterances were phonemically transcribed and for each word, the distance between the child's production and the standard adult phonemic transcription was computed using the Levenshtein Distance as a metric. The same procedure was applied to the longitudinal data of the children with CI and the normally hearing children. The main result was that the Levenshtein Distance decreased in the three children with ABI but it remained significantly higher than that of children with typical hearing and cochlear implants matched on chronological age, hearing age, and lexicon size. In other words, the phonemic accuracy increased in the children with ABI but stayed well below that of children without hearing loss and children with cochlear implants. Moreover, the analyses revealed considerable individual variation between the children with ABI.","2022-02","2025-02-26 20:37:01","2025-02-26 20:37:01","","22-50","","1","42","","","","","","","","","","English","","","","WOS:000702467400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","AGE; Auditory brainstem implantation; INDIVIDUAL-DIFFERENCES; LENGTH; Levenshtein Distance; oral language; OUTCOMES; pediatric; PERCEPTION; PHONOLOGICAL DEVELOPMENT; REHABILITATION; SIMILARITY; speech production; STIMULATION; WORD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3DH3TC6J","journalArticle","2022","Silva, LFLE; Mello, H","A probabilistic approach to the distribution of subject and anacoluthon NPs in Topics in spontaneous speech","GRAGOATA-UFF","","1413-9073","10.22409/gragoata.v27i58.50708","","The definition of Topic as well as that of information structure in the literature is very broad (cf. BARBOSA, 2005; MELLO; SILVA, 2015). Here we assume the definition as proposed by the Language into Act Theory (CRESTI, 2000), which says that Topic is the textual unit that is performed by an intonational profile of the prefix type ('t HART et al. 1990), and that has the function of constituting the domain over which the illocutionary force applies. An NP in Topic either can be the subject of the following verb in Comment or an anacoluthon. Anacolutha NPs are phrases that bear no syntactic relations with the predication in Comment. In this paper, we show how NPs are distributed probabilistically between these two conditions when they are performed as Topics in spontaneous speech. For this purpose, we collected data from available spontaneous speech corpora informationally labeled - including the Topic unit as defined above - from three languages: European Spanish (NICOLAS MARTINEZ; LOMBAN SOMACARRERA, 2018), American English (CAVALCANTE; RAMOS, 2016), and Brazilian Portuguese (PANUNZI; GREGORI; MITTMANN, 2014). The statistical method used to calculate the probability was a mixed-effects logistic regression with crossed random effects conducted with the aid of R (R CORE TEAM, 2018). Three variables were chosen: accessibility of referent, animacy, and definiteness. The model showed that there are about five times more chances for an NP performed in Topic to be the subject of the verb in Comment if it is animate, definite, and given.","2022-05","2025-02-26 20:37:01","2025-02-26 20:37:01","","86-117","","58","27","","","","","","","","","","English","","","","WOS:000796475900004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","INFORMATION; NP; Probabilistic grammar; RECALL; Spoken syntax; Subject; SYNTAX; Topic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TTGJWNJI","journalArticle","2022","Eaton, CT; Burrowes, L","Comparing patterns of familiar language use across spontaneous speech contexts in individuals with nonfluent aphasia and healthy controls","APHASIOLOGY","","0268-7038","10.1080/02687038.2021.1966375","","Background: It is well-established that individuals with nonfluent aphasia produce proportionally more familiar or non-propositional language than neurotypical adults. Much less is known about the types of familiar language used or about the effects of either language context or impairment on usage patterns. Aims: The purpose of this study was to identify and compare types of familiar language across several spontaneous speech contexts in individuals with and without aphasia in order to refine models of familiar language use for clinical application. Methods & Procedures: Language transcripts from Aphasiabank of 154 individuals with moderate to severe post-stroke Broca's aphasia and gender- and age-matched controls were coded to identify and classify nine types of familiar language. Language samples included a story-telling task and three conversational topics. Non-parametric comparisons and Spearman's correlations were used to analyze usage patterns. Outcomes & Results: Individuals with aphasia produced significantly higher proportions of formulaic expressions (context-bound, stereotyped utterances) as compared to controls, but proportions of lexical bundles (connotation-free, multi-word utterances) did not significantly differ. Familiar language usage varied by language contexts and level of severity for individuals with aphasia, whereas production patterns of healthy controls were remarkably stable. Conclusions: This study offers insights into patterns of familiar language usage affected by linguistic ability and language context. A theoretical framework for conceptualising familiar language will result in improvements to existing interventions.","2022-12-02","2025-02-26 20:37:01","2025-02-26 20:37:01","","1397-1416","","12","36","","","","","","","","","","English","","","","WOS:000686024200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","ACHIEVEMENT; ALZHEIMERS-DISEASE; ENGLISH; EXPRESSIONS; Familiar language; formulaic; FORMULAIC LANGUAGE; FREQUENCY; nonfluent aphasia; PEOPLE; SPEAKERS; spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D9X89AWU","journalArticle","2021","Alonso-Hernández, JB; Barragán-Pulido, ML; Gil-Bordón, JM; Ferrer-Ballester, MA; Travieso-González, CM","Using a Human Interviewer or an Automatic Interviewer in the Evaluation of Patients with AD from Speech","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app11073228","","Currently, there are more and more frequent studies focused on the evaluation of Alzheimer's disease (AD) from the automatic analysis of the speech of patients, in order to detect the presence of the disease in an individual or for the evolutionary control of the disease. However, studies focused on analyzing the effect of the methodology used to generate the spontaneous speech of the speaker who undergoes this type of analysis are rare. The objective of this work is to study two different strategies to facilitate the generation of the spontaneous speech of a speaker for further analysis: the use of a human interviewer that promotes the generation of speech through an interview and the use of an automatic system (an automatic interviewer) that invites the speaker to describe certain visual stimuli. In this study, a database called Cross-Sectional Alzheimer Prognosis R2019 has been created, consisting of speech samples from speakers recorded using both methodologies. The speech recordings have been studied through a feature extraction based on five basic temporal measurements. This study demonstrates the discriminatory capacity between the speakers with AD and the control subjects independent of the strategy used in the generation of spontaneous speech. These results are promising and can serve as a basis for knowing the effectiveness and extension of automated interview processes, especially in telemedicine and telecare scenarios.","2021-04","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","7","11","","","","","","","","","","English","","","","WOS:000638335600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;105</p>","","","Alzheimer’; ALZHEIMERS-DISEASE; ASSOCIATION; automatic interviewer; automatic voice recognition; DEMENTIA; DIAGNOSIS; FEATURE-SELECTION; LANGUAGE; MARKERS; MILD COGNITIVE IMPAIRMENT; RECOGNITION; s disease (AD); telecare; telemedicine; TOOLS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D7732PRC","journalArticle","2024","Kappen, M; Vanhollebeke, G; van der Donckt, J; Van Hoecke, S; Vanderhasselt, MA","Acoustic and prosodic speech features reflect physiological stress but not isolated negative affect: a multi-paradigm study on psychosocial stressors","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-55550-3","","Heterogeneity in speech under stress has been a recurring issue in stress research, potentially due to varied stress induction paradigms. This study investigated speech features in semi-guided speech following two distinct psychosocial stress paradigms (Cyberball and MIST) and their respective control conditions. Only negative affect increased during Cyberball, while self-reported stress, skin conductance response rate, and negative affect increased during MIST. Fundamental frequency (F0), speech rate, and jitter significantly changed during MIST, but not Cyberball; HNR and shimmer showed no expected changes. The results indicate that observed speech features are robust in semi-guided speech and sensitive to stressors eliciting additional physiological stress responses, not solely decreases in negative affect. These differences between stressors may explain literature heterogeneity. Our findings support the potential of speech as a stress level biomarker, especially when stress elicits physiological reactions, similar to other biomarkers. This highlights its promise as a tool for measuring stress in everyday settings, considering its affordability, non-intrusiveness, and ease of collection. Future research should test these results' robustness and specificity in naturalistic settings, such as freely spoken speech and noisy environments while exploring and validating a broader range of informative speech features in the context of stress.","2024-03-06","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","1","14","","","","","","","","","","English","","","","WOS:001180936100034","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","CORTISOL; ISSUES; RESPONSES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EK9KAJ2J","journalArticle","2023","Candido, A Jr; Casanova, E; Soares, A; de Oliveira, FS; Oliveira, L; Fernandes, RC Jr; da Silva, DPP; Fayet, FG; Carlotto, BB; Gris, LRS; Aluísio, SM","CORAA ASR: a large corpus of spontaneous and prepared speech manually validated for speech recognition in Brazilian Portuguese","LANGUAGE RESOURCES AND EVALUATION","","1574-020X","10.1007/s10579-022-09621-4","","Automatic Speech recognition (ASR) is a complex and challenging task. In recent years, there have been significant advances in the area. In particular, for the Brazilian Portuguese (BP) language, there were around 376 h publicly available for the ASR task until the second half of 2020. With the release of new datasets in early 2021, this number increased to 574 h. The existing resources, however, are composed of audios containing only read and prepared speech. There is a lack of datasets including spontaneous speech, which are essential in several ASR applications. This paper presents CORAA (Corpus of Annotated Audios) ASR with 290 h, a publicly available dataset for ASR in BP containing validated pairs of audio-transcription. CORAA ASR also contains European Portuguese audios (4.6 h). We also present a public ASR model based on Wav2Vec 2.0 XLSR-53, fine-tuned over CORAA ASR. Our model achieved a Word Error Rate (WER) of 24.18% on CORAA ASR test set and 20.08% on Common Voice test set. When measuring the Character Error Rate (CER), we obtained 11.02% and 6.34% for CORAA ASR and Common Voice, respectively. CORAA ASR corpora were assembled to both improve ASR models in BP with phenomena from spontaneous speech and motivate young researchers to start their studies on ASR for Portuguese. All the corpora are publicly available at under the CC BY-NC-ND 4.0 license.","2023-09","2025-02-26 20:37:01","2025-02-26 20:37:01","","1139-1171","","3","57","","","","","","","","","","English","","","","WOS:000886416400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Automatic speech recognition; Brazilian Portuguese; Prepared speech; Public datasets; Public speech corpora; Spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LGQRMAPI","journalArticle","2021","García, AM; Arias-Vergara, T; Vasquez-Correa, JC; Nöth, E; Schuster, M; Welch, AE; Bocanegra, Y; Baena, A; Orozco-Arroyave, JR","Cognitive Determinants of Dysarthria in Parkinson's Disease: An Automated Machine Learning Approach","MOVEMENT DISORDERS","","0885-3185","10.1002/mds.28751","","Background Dysarthric symptoms in Parkinson's disease (PD) vary greatly across cohorts. Abundant research suggests that such heterogeneity could reflect subject-level and task-related cognitive factors. However, the interplay of these variables during motor speech remains underexplored, let alone by administering validated materials to carefully matched samples with varying cognitive profiles and combining automated tools with machine learning methods. Objective We aimed to identify which speech dimensions best identify patients with PD in cognitively heterogeneous, cognitively preserved, and cognitively impaired groups through tasks with low (reading) and high (retelling) processing demands. Methods We used support vector machines to analyze prosodic, articulatory, and phonemic identifiability features. Patient groups were compared with healthy control subjects and against each other in both tasks, using each measure separately and in combination. Results Relative to control subjects, patients in cognitively heterogeneous and cognitively preserved groups were best discriminated by combined dysarthric signs during reading (accuracy = 84% and 80.2%). Conversely, patients with cognitive impairment were maximally discriminated from control subjects when considering phonemic identifiability during retelling (accuracy = 86.9%). This same pattern maximally distinguished between cognitively spared and impaired patients (accuracy = 72.1%). Also, cognitive (executive) symptom severity was predicted by prosody in cognitively preserved patients and by phonemic identifiability in cognitively heterogeneous and impaired groups. No measure predicted overall motor dysfunction in any group. Conclusions Predominant dysarthric symptoms appear to be best captured through undemanding tasks in cognitively heterogeneous and preserved cohorts and through cognitively loaded tasks in patients with cognitive impairment. Further applications of this framework could enhance dysarthria assessments in PD. (c) 2021 International Parkinson and Movement Disorder Society","2021-12","2025-02-26 20:37:01","2025-02-26 20:37:01","","2862-2873","","12","36","","","","","","","","","","English","","","","WOS:000684841800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;45<br/>Total Times Cited:&nbsp;&nbsp;47<br/>Cited Reference Count:&nbsp;&nbsp;112</p>","","","automated speech analysis; cognitive demands; COMMUNICATION; CONVERSATIONAL SPEECH; dysarthria; IMPAIRMENT; INDIVIDUALS; LANGUAGE; mild cognitive impairment; NOISE-REDUCTION; NORMAL-HEARING; Parkinson's disease; PROGRESSIVE SUPRANUCLEAR PALSY; SCREENING TOOL; VOWEL ARTICULATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KA3ZSBTD","journalArticle","2022","Zheng, XF; Tomiura, Y; Hayashi, K","Investigation of the structure-odor relationship using a Transformer model","JOURNAL OF CHEMINFORMATICS","","1758-2946","10.1186/s13321-022-00671-y","","The relationships between molecular structures and their properties are subtle and complex, and the properties of odor are no exception. Molecules with similar structures, such as a molecule and its optical isomer, may have completely different odors, whereas molecules with completely distinct structures may have similar odors. Many works have attempted to explain the molecular structure-odor relationship from chemical and data-driven perspectives. The Transformer model is widely used in natural language processing and computer vision, and the attention mechanism included in the Transformer model can identify relationships between inputs and outputs. In this paper, we describe the construction of a Transformer model for predicting molecular properties and interpreting the prediction results. The SMILES data of 100,000 molecules are collected and used to predict the existence of molecular substructures, and our proposed model achieves an F1 value of 0.98. The attention matrix is visualized to investigate the substructure annotation performance of the attention mechanism, and we find that certain atoms in the target substructures are accurately annotated. Finally, we collect 4462 molecules and their odor descriptors and use the proposed model to infer 98 odor descriptors, obtaining an average F1 value of 0.33. For the 19 odor descriptors that achieved F1 values greater than 0.45, we also attempt to summarize the relationship between the molecular substructures and odor quality through the attention matrix.","2022-12-29","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","1","14","","","","","","","","","","English","","","","WOS:000905921100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","FEATURES; Molecular structure-odor relation; Odor descriptor; OLFACTORY PERCEPTION; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZY3TBNYQ","journalArticle","2021","Rusz, J; Hlavnicka, J; Novotny, M; Tykalová, T; Pelletier, A; Montplaisir, J; Gagnon, JF; Dusek, P; Galbiati, A; Marelli, S; Timm, PC; Teigen, LN; Janzen, A; Habibi, M; Stefani, A; Holzknecht, E; Seppi, K; Evangelista, E; Rassu, AL; Dauvilliers, Y; Högl, B; Oertel, W; St Louis, EK; Ferini-Strambi, L; Ruzicka, E; Postuma, RB; Sonka, K","Speech Biomarkers in Rapid Eye Movement Sleep Behavior Disorder and Parkinson Disease","ANNALS OF NEUROLOGY","","0364-5134","10.1002/ana.26085","","Objective This multilanguage study used simple speech recording and high-end pattern analysis to provide sensitive and reliable noninvasive biomarkers of prodromal versus manifest alpha-synucleinopathy in patients with idiopathic rapid eye movement sleep behavior disorder (iRBD) and early-stage Parkinson disease (PD). Methods We performed a multicenter study across the Czech, English, German, French, and Italian languages at 7 centers in Europe and North America. A total of 448 participants (337 males), including 150 with iRBD (mean duration of iRBD across language groups 0.5-3.4 years), 149 with PD (mean duration of disease across language groups 1.7-2.5 years), and 149 healthy controls were recorded; 350 of the participants completed the 12-month follow-up. We developed a fully automated acoustic quantitative assessment approach for the 7 distinctive patterns of hypokinetic dysarthria. Results No differences in language that impacted clinical parkinsonian phenotypes were found. Compared with the controls, we found significant abnormalities of an overall acoustic speech severity measure via composite dysarthria index for both iRBD (p = 0.002) and PD (p < 0.001). However, only PD (p < 0.001) was perceptually distinct in a blinded subjective analysis. We found significant group differences between PD and controls for monopitch (p < 0.001), prolonged pauses (p < 0.001), and imprecise consonants (p = 0.03); only monopitch was able to differentiate iRBD patients from controls (p = 0.004). At the 12-month follow-up, a slight progression of overall acoustic speech impairment was noted for the iRBD (p = 0.04) and PD (p = 0.03) groups. Interpretation Automated speech analysis might provide a useful additional biomarker of parkinsonism for the assessment of disease progression and therapeutic interventions. ANN NEUROL 2021","2021-07","2025-02-26 20:37:01","2025-02-26 20:37:01","","62-75","","1","90","","","","","","","","","","English","","","","WOS:000647838200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;77<br/>Total Times Cited:&nbsp;&nbsp;80<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","ENGLISH; PATTERNS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9A3ID957","journalArticle","2024","Rios-Urrego, CD; Rusz, J; Orozco-Arroyave, JR","Automatic speech-based assessment to discriminate Parkinson's disease from essential tremor with a cross-language approach","NPJ DIGITAL MEDICINE","","2398-6352","10.1038/s41746-024-01027-6","","Parkinson's disease (PD) and essential tremor (ET) are prevalent movement disorders that mainly affect elderly people, presenting diagnostic challenges due to shared clinical features. While both disorders exhibit distinct speech patterns-hypokinetic dysarthria in PD and hyperkinetic dysarthria in ET-the efficacy of speech assessment for differentiation remains unexplored. Developing technology for automatic discrimination could enable early diagnosis and continuous monitoring. However, the lack of data for investigating speech behavior in these patients has inhibited the development of a framework for diagnostic support. In addition, phonetic variability across languages poses practical challenges in establishing a universal speech assessment system. Therefore, it is necessary to develop models robust to the phonetic variability present in different languages worldwide. We propose a method based on Gaussian mixture models to assess domain adaptation from models trained in German and Spanish to classify PD and ET patients in Czech. We modeled three different speech dimensions: articulation, phonation, and prosody and evaluated the models' performance in both bi-class and tri-class classification scenarios (with the addition of healthy controls). Our results show that a fusion of the three speech dimensions achieved optimal results in binary classification, with accuracies up to 81.4 and 86.2% for monologue and /pa-ta-ka/ tasks, respectively. In tri-class scenarios, incorporating healthy speech signals resulted in accuracies of 63.3 and 71.6% for monologue and /pa-ta-ka/ tasks, respectively. Our findings suggest that automated speech analysis, combined with machine learning is robust, accurate, and can be adapted to different languages to distinguish between PD and ET patients.","2024-02-17","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","1","7","","","","","","","","","","English","","","","WOS:001163792400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","ARTICULATION; DYSARTHRIA; PERFORMANCE; SCALE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KAPLRGE2","journalArticle","2022","Zhou, Y; Yao, XY; Han, W; Wang, YD; Li, Z; Li, YX","Distinguishing apathy and depression in older adults with mild cognitive impairment using text, audio, and video based on multiclass classification and shapely additive explanations","INTERNATIONAL JOURNAL OF GERIATRIC PSYCHIATRY","","0885-6230","10.1002/gps.5827","","Objectives: This study aimed to develop a classification model to detect and distinguish apathy and depression based on text, audio, and video features and to make use of the shapely additive explanations (SHAP) toolkit to increase the model interpretability. Methods: Subjective scales and objective experiments were conducted on 319 mild cognitive impairment (MCI) patients to measure apathy and depression. The MCI patients were classified into four groups, depression only, apathy only, depressed-apathetic, and the normal group. Speech, facial and text features were extracted using the open-source data analysis toolkits. Multiclass classification and SHAP toolkits were used to develop a classification model and explain the contribution of specific features. Results: The macro-averaged f1 score and accuracy for overall model were 0.91 and 0.90, respectively. The accuracy for the apathetic, depressed, depressed-apathetic, and normal groups were 0.98, 0.88, 0.93, and 0.82, respectively. The SHAP toolkit identified speech features (Mel-frequency cepstral coefficient (MFCC) 4, spectral slopes, F0, F1), facial features (action unit (AU) 14, 26, 28, 45), and text feature (text 6 semantic) associated with apathy. Meanwhile, speech features (spectral slopes, shimmer, F0) and facial expression (AU 2, 6, 7, 10, 14, 26, 45) were associated with depression. Apart from the shared features mentioned above, new speech (MFCC 2, loudness) and facial (AU 9) features were observed in the depressive-apathetic group. Conclusions: Apathy and depression shared some verbal and facial features while also exhibited distinct features. A combination of text, audio, and video could be used to improve the early detection and differential diagnosis of apathy and depression in MCI patients.","2022-11","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","11","37","","","","","","","","","","English","","","","WOS:000928435800010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","apathy; depression; facial analysis; mild cognitive impairment; multiclass classification; NEUROPSYCHIATRIC SYMPTOMS; shapely additive explanations; speech analysis; text analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9MTHFK5G","journalArticle","2023","Mackinley, M; Limongi, R; Silva, AM; Richard, J; Subramanian, P; Ganjavi, H; Palaniyappan, L","More than words: Speech production in first-episode psychosis predicts later social and vocational functioning","FRONTIERS IN PSYCHIATRY","","1664-0640","10.3389/fpsyt.2023.1144281","","BackgroundSeveral disturbances in speech are present in psychosis; however, the relationship between these disturbances during the first-episode of psychosis (FEP) and later vocational functioning is unclear. Demonstrating this relationship is critical if we expect speech and communication deficits to emerge as targets for early intervention. MethodWe analyzed three 1-min speech samples using automated speech analysis and Bayes networks in an antipsychotic-naive sample of 39 FEP patients and followed them longitudinally to determine their vocational status (engaged or not engaged in employment education or training-EET vs. NEET) after 6-12 months of treatment. Five baseline linguistic variables with prior evidence of clinical relevance (total and acausal connectives use, pronoun use, analytic thinking, and total words uttered in a limited period) were included in a Bayes network along with follow-up NEET status and Social and Occupational Functioning Assessment Scale (SOFAS) scores to determine dependencies among these variables. We also included clinical (Positive and Negative Syndrome Scale 8-item version (PANSS-8)), social (parental socioeconomic status), and cognitive features (processing speed) at the time of presentation as covariates. ResultsThe Bayes network revealed that only total words spoken at the baseline assessment were directly associated with later NEET status and had an indirect association with SOFAS, with a second set of dependencies emerging among the remaining linguistic variables. The primary (speech-only) model outperformed models including parental socioeconomic status, processing speed or both as latent variables. ConclusionImpoverished speech, even at subclinical levels, may hold prognostic value for functional outcomes and warrant consideration when providing measurement based care for first-episode psychosis.","2023-04-14","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","14","","","","","","","","","","English","","","","WOS:000976019000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","ABNORMALITIES; COHESION; First Episode Psychosis; FORMAL THOUGHT-DISORDER; language; LANGUAGE; NARRATIVES; NEET (neither education employment or training); NEGATIVE SYMPTOMS; PEOPLE; REMISSION; schizophrenia; SCHIZOPHRENIA; thought disorder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V6ZHNMW5","journalArticle","2024","Yao, LS; Zheng, N","Sentiment Analysis Based on Improved Transformer Model and Conditional Random Fields","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3418847","","With the rapid development of the Internet, people independently write comments with emotional characteristics on e-commerce platforms, which express consumers' emotional tendencies towards products or services from multiple perspectives. The sentiment analysis technology of product reviews has attracted more and more attention. In recent years, the Transformer model has performed well in the field of text sentiment analysis. However, in the process of text emotion classification, the Transformer basic model cannot be well obtained when the distance between words is relatively long, and there are problems such as a low accuracy rate and recall rate and too much time spent on the overall training of model construction. Using conditional random field (CRF) as a classifier can effectively solve the problem of too long text segmentation distance, reduce model training time, and increase the accuracy of text sentiment analysis. Therefore, this paper proposes a new method for text sentiment analysis combining the improved Transformer model and a conditional random field. First of all, this paper enhances the Transformer model by adapting the decoder to better suit the task of sentiment classification, and introduces an enhanced version of the Transformer model. It is then classified by combining long-short-term memory (LSTM) and CRF. The experimental results show that in the IMDB data set, the Transformer CRF model has higher accuracy, recall rate, and F1 value, reaching 85.51%, 83.77%, and 85.06%, respectively. Compared with other methods, the results of evaluation indicators further verify that the text method has better recognition performance and generalization ability, and at the same time, it has a better understanding of customers' emotions towards a specific aspect, provides users with accurate services, effectively improves user satisfaction, and has a high use value for enterprises' business decisions.","2024","2025-02-26 20:37:01","2025-02-26 20:37:01","","90145-90157","","","12","","","","","","","","","","English","","","","WOS:001263413700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Accuracy; Analytical models; attention mechanism; conditional random field; Conditional random fields; COVID-19; deep learning; Long short term memory; LSTM; sentiment analysis; Sentiment analysis; Training; Transformer model; Transformers; TWITTER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E2FTC8CT","journalArticle","2024","Carl, M; Rudyk, E; Shapira, Y; Rusiewicz, HL; Icht, M","Accuracy of Speech Sound Analysis: Comparison of an Automatic Artificial Intelligence Algorithm With Clinician Assessment","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2024_JSLHR-24-00009","","Purpose: Automatic speech analysis (ASA) and automatic speech recognition systems are increasingly being used in the treatment of speech sound disorders (SSDs). When utilized as a home practice tool or in the absence of the clinician, the ASA system has the potential to facilitate treatment gains. However, the feedback accuracy of such systems varies, a factor that may impact these gains. The current research analyzes the feedback accuracy of a novel ASA algorithm (Amplio Learning Technologies), in comparison to clinician judgments. Method: A total of 3,584 consonant stimuli, produced by 395 American English-speaking children and adolescents with SSDs (age range: 4-18 years), were analyzed with respect to automatic classification of the ASA algorithm, clinician-ASA agreement, and interclinician agreement. Further analysis of results as related to phoneme acquisition categories (early-, middle-, and lateacquired phonemes) was conducted. Results: Agreement between clinicians and ASA classification for sounds produced accurately was above 80% for all phonemes, with some variation based on phoneme acquisition category (early, middle, late). This variation was also noted for ASA classification into ""acceptable,"" ""unacceptable,"" and ""unknown"" (which means no determination of phoneme accuracy) categories, as well as interclinician agreement. Clinician-ASA agreement was reduced for misarticulated sounds. Conclusions: The initial findings of Amplio's novel algorithm are promising for its potential use within the context of home practice, as it demonstrates high feedback accuracy for correctly produced sounds. Furthermore, complexity of sound influences consistency of perception, both by clinicians and by automated platforms, indicating variable performance of the ASA algorithm across phonemes. Taken together, the ASA algorithm may be effective in facilitating speech sound practice for children with SSDs, even in the absence of the clinician.","2024-09","2025-02-26 20:37:01","2025-02-26 20:37:01","","3004-3021","","9","67","","","","","","","","","","English","","","","WOS:001329427300016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;83</p>","","","CHILDHOOD APRAXIA; CHILDREN; FEEDBACK FREQUENCY; HIGH AGREEMENT; INTELLIGIBILITY; INTERVENTION; LOW KAPPA; RECOGNITION; TREATMENT INTENSITY; VARIABILITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3YZ5NR22","journalArticle","2022","Zhang, YY","Russian Speech Conversion Algorithm Based on a Parallel Corpus and Machine Translation","WIRELESS COMMUNICATIONS & MOBILE COMPUTING","","1530-8669","10.1155/2022/8023115","","The phonetic conversion technology is crucial in the resource construction of Russian phonetic information processing. This paper explains how to build a corpus and the key algorithms that are used, as well as how to design auxiliary translation software and implement the key algorithms. This paper focuses on the ""parallel corpus"" method of problem solving and the indispensable role of a parallel corpus in Russian learning. This paper examines the foundations, motivations, and methods for using parallel corpora in translation instruction. The main way of using a parallel corpus in the classroom environment is to present data, so that learners can be exposed to a large amount of easily screened bilingual data, and translation skills and specific language item translation can be taught in a concentrated and focused manner. Among them, the creation of a large-scale Russian-Chinese parallel corpus will play an important role not only in improving the translation quality of Russian-Chinese machine translation systems but also in Chinese and Russian teaching as well as other branches of linguistics and translation studies, all of which should be given sufficient attention. This paper proposes the use of automatic speech analysis technology to assist Russian pronunciation learning and designs a Russian word pronunciation learning assistant system with demonstration, scoring, and feedback functions, in response to the shortcomings of pronunciation teaching in Russian teaching in China. It can provide corpus support for gathering a large number of parallel corpora and, in the future, enabling online translation. This system is used for corpus automatic construction, and future corpus automatic construction systems could be built on top of it. The proper application of parallel corpus data will aid in the development of a high-quality autonomous learning and translation teaching environment.","2022-03-23","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","2022","","","","","","","","","","English","","","","WOS:000814567700012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YWAHDWDA","journalArticle","2022","Domain, L; Guillery, M; Linz, N; König, A; Batail, JM; David, R; Corouge, I; Bannier, E; Ferré, JC; Dondaine, T; Drapier, D; Robert, GH","Multimodal MRI cerebral correlates of verbal fluency switching and its impairment in women with depression","NEUROIMAGE-CLINICAL","","2213-1582","10.1016/j.nicl.2021.102910","","Background: The search of biomarkers in the field of depression requires easy implementable tests that are biologically rooted. Qualitative analysis of verbal fluency tests (VFT) are good candidates, but its cerebral correlates are unknown. Methods: We collected qualitative semantic and phonemic VFT scores along with grey and white matter anatomical MRI of depressed (n = 26) and healthy controls (HC, n = 25) women. Qualitative VFT variables are the ""clustering score"" (i.e. the ability to produce words within subcategories) and the ""switching score"" (i.e. the ability to switch between clusters). The clustering and switching scores were automatically calculated using a data-driven approach. Brain measures were cortical thickness (CT) and fractional anisotropy (FA). We tested for associations between CT, FA and qualitative VFT variables within each group. Results: Patients had reduced switching VFT scores compared to HC. Thicker cortex was associated with better switching score in semantic VFT bilaterally in the frontal (superior, rostral middle and inferior gyri), parietal (inferior parietal lobule including the supramarginal gyri), temporal (transverse and fusiform gyri) and occipital (lingual gyri) lobes in the depressed group. Positive association between FA and the switching score in semantic VFT was retrieved in depressed patients within the corpus callosum, right inferior fronto-occipital fasciculus, right superior longitudinal fasciculus extending to the anterior thalamic radiation (all p < 0.05, corrected). Conclusion: Together, these results suggest that automatic qualitative VFT scores are associated with brain anatomy and reinforce its potential use as a surrogate for depression cerebral bases.","2022","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","33","","","","","","","","","","English","","","","WOS:000744096400005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","Automatic speech analysis; CORTEX; Cortical Thickness; CORTICAL THICKNESS; EXECUTIVE FUNCTION; Fractional Anisotropy; HEALTHY; LOCALIZATION; Major depressive disorder; METAANALYSIS; MICROSTRUCTURE; POWER ANALYSIS; SEX-DIFFERENCES; Switching; Verbal fluency; WHITE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NCK9BPNV","journalArticle","2024","Riad, R; Denais, M; de Gennes, M; Lesage, A; Oustric, V; Cao, XN; Mouchabac, S; Bourla, A","Automated Speech Analysis for Risk Detection of Depression,Anxiety, Insomnia, and Fatigue:Algorithm Development andValidation Study","JOURNAL OF MEDICAL INTERNET RESEARCH","","1438-8871","10.2196/58572","","Background: While speech analysis holds promise for mental health assessment, research often focuses on single symptoms,despite symptom co-occurrences and interactions. In addition, predictive models in mental health do not properly assess thelimitations of speech-based systems, such as uncertainty, or fairness for a safe clinical deployment.Objective: We investigated the predictive potential of mobile-collected speech data for detecting and estimating depression,anxiety, fatigue, and insomnia, focusing on other factors than mere accuracy, in the general population. Methods: We included 865 healthy adults and recorded their answers regarding their perceived mental and sleep states. Weasked how they felt and if they had slept well lately. Clinically validated questionnaires measuring depression, anxiety, insomnia,and fatigue severity were also used. We developed a novel speech and machine learning pipeline involving voice activity detection,feature extraction, and model training. We automatically modeled speech with pretrained deep learning models that were pretrainedon a large, open, and free database, and we selected the best one on the validation set. Based on the best speech modeling approach,clinical threshold detection, individual score prediction, model uncertainty estimation, and performance fairness across demographics(age, sex, and education) were evaluated. We used a train-validation-test split for all evaluations: to develop our models, selectthe best ones, and assess the generalizability of held-out data.Results: The best model was Whisper M with a max pooling and oversampling method. Our methods achieved good detectionperformance for all symptoms, depression (Patient Health Questionnaire-9: area under the curve [AUC]=0.76; F1-score=0.49and Beck Depression Inventory: AUC=0.78; F1-score=0.65), anxiety (Generalized Anxiety Disorder 7-item scale: AUC=0.77;F1-score=0.50), insomnia (Athens Insomnia Scale: AUC=0.73; F1-score=0.62), and fatigue (Multidimensional Fatigue Inventorytotal score: AUC=0.68; F1-score=0.88). The system performed well when it needed to abstain from making predictions, asdemonstrated by low abstention rates in depression detection with the Beck Depression Inventory and fatigue, with risk-coverageAUCs below 0.4. Individual symptom scores were accurately predicted (correlations were all significant with Pearson strengthsbetween 0.31 and 0.49). Fairness analysis revealed that models were consistent for sex (average disparity ratio [DR] 0.86, SD0.13), to a lesser extent for education level (average DR 0.47, SD 0.30), and worse for age groups (average DR 0.33, SD 0.30). Conclusions: This study demonstrates the potential of speech-based systems for multifaceted mental health assessment in thegeneral population, not only for detecting clinical thresholds but also for estimating their severity. Addressing fairness andincorporating uncertainty estimation with selective classification are key contributions that can enhance the clinical utility andresponsible implementation of such systems","2024-10-31","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","26","","","","","","","","","","English","","","","WOS:001360844200006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","anxiety; computer-aided diagnosis; depression; DISORDERS; fatigue; FATIGUE; INSTRUMENT; INVENTORY; machine learning; mental health; mentalhealth symptom detection; MODELS; NETWORK; SEVERITY; speech analysis; speech biomarkers; speech-based systems; SYMPTOMS; VALIDATION; VALIDITY; voice analysis; voice detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"64YGJBFS","journalArticle","2022","Khare, E; Gonzalez-Obeso, C; Kaplan, DL; Buehler, MJ","CollagenTransformer: End-to-End Transformer Model to Predict Thermal Stability of Collagen Triple Helices Using an NLP Approach","ACS BIOMATERIALS SCIENCE & ENGINEERING","","2373-9878","10.1021/acsbiomaterials.2c00737","","Collagen is one of the most important structural proteins in biology, and its structural hierarchy plays a crucial role in many mechanically important biomaterials. Here, we demonstrate how transformer models can be used to predict, directly from the primary amino acid sequence, the thermal stability of collagen triple helices, measured via the melting temperature Tm. We report two distinct transformer architectures to compare performance. First, we train a small transformer model from scratch, using our collagen data set featuring only 633 sequence-toTm pairings. Second, we use a large pretrained transformer model, ProtBERT, and fine-tune it for a particular downstream task by utilizing sequence-to-Tm pairings, using a deep convolutional network to translate natural language processing BERT embeddings into required features. Both the small transformer model and the fine-tuned ProtBERT model have similar R-2 values of test data (R-2 = 0.84 vs 0.79, respectively), but the ProtBERT is a much larger pretrained model that may not always be applicable for other biological or biomaterials questions. Specifically, we show that the small transformer model requires only 0.026% of the number of parameters compared to the much larger model but reaches almost the same accuracy for the test set. We compare the performance of both models against 71 newly published sequences for which Tm has been obtained as a validation set and find reasonable agreement, with ProtBERT outperforming the small transformer model. The results presented here are, to our best knowledge, the first demonstration of the use of transformer models for relatively small data sets and for the prediction of specific biophysical properties of interest. We anticipate that the work presented here serves as a starting point for transformer models to be applied to other biophysical problems.","2022-09-23","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","","","","","","","","","","","English","","","","WOS:000864160900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;20<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","ABSENCE; ACID; deep learning; DISEASES; FIBRILS; HYDROXYPROLINE; LYSINE; mechanical properties; MECHANISM; modeling; OSTEOGENESIS IMPERFECTA; stability; STABILIZATION; Structural protein; temperature; VISCOELASTIC PROPERTIES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AHTFP26R","journalArticle","2024","Zou, Y; Xue, MH; Hossain, MI; Zhu, Q","Ultrasound and diffuse optical tomography-transformer model for assessing pathological complete response to neoadjuvant chemotherapy in breast cancer","JOURNAL OF BIOMEDICAL OPTICS","","1083-3668","10.1117/1.JBO.29.7.076007","","Significance We evaluate the efficiency of integrating ultrasound (US) and diffuse optical tomography (DOT) images for predicting pathological complete response (pCR) to neoadjuvant chemotherapy (NAC) in breast cancer patients. The ultrasound-diffuse optical tomography (USDOT)-Transformer model represents a significant step toward accurate prediction of pCR, which is critical for personalized treatment planning. Aim We aim to develop and assess the performance of the USDOT-Transformer model, which combines US and DOT images with tumor receptor biomarkers to predict the pCR of breast cancer patients under NAC. Approach We developed the USDOT-Transformer model using a dual-input transformer to process co-registered US and DOT images along with tumor receptor biomarkers. Our dataset comprised imaging data from 60 patients at multiple time points during their chemotherapy treatment. We used fivefold cross-validation to assess the model's performance, comparing its results against a single modality of US or DOT. Results The USDOT-Transformer model demonstrated excellent predictive performance, with a mean area under the receiving characteristic curve of 0.96 (95%CI: 0.93 to 0.99) across the fivefold cross-validation. The integration of US and DOT images significantly enhanced the model's ability to predict pCR, outperforming models that relied on a single imaging modality (0.87 for US and 0.82 for DOT). This performance indicates the potential of advanced deep learning techniques and multimodal imaging data for improving the accuracy (ACC) of pCR prediction. Conclusion The USDOT-Transformer model offers a promising non-invasive approach for predicting pCR to NAC in breast cancer patients. By leveraging the structural and functional information from US and DOT images, the model offers a faster and more reliable tool for personalized treatment planning. Future work will focus on expanding the dataset and refining the model to further improve its accuracy and generalizability.","2024-07-01","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","7","29","","","","","","","","","","English","","","","WOS:001296807800004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","ACCURACY; breast cancer; diffuse optical tomography; dual input transformer; pathological complete response; PET/CT; PREDICTION; THERAPY; TUMOR RESPONSE; ULTRASONOGRAPHY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M7VBFDHD","journalArticle","2022","Moneglia, M; Panunzi, A","Micro-Diachronic Corpora for Measuring the Lexical Change of Spontaneous Speech in Florence Compared to Standard Italian","LANGAGES","","0458-726X","","","This paper aims to give a realistic measure of the distance between the spoken lexicon used by Florentine people in 1965 and current standard Italian, and to evaluate the changes that occurred in the last forty years. To this purpose, we compared the lexicons derived from two spoken resources collected in the Florence area: the STAMMERJOHANN corpus (1965) and a specifically designed sampling of the LABLITA corpus (recordings after the year 2000). The pan-Italianness of the language spoken in Florence has been evaluated by means of a parallel annotation of the same corpora performed by two Italian linguists born respectively in Northern and Southern Italy. Results show that the overall percentage of regional forms in the spontaneous speech of Florence, albeit generally limited, has undergone a significant reduction over the last decades, while the high-frequency lexicon has remained more stable.","2022-06","2025-02-26 20:37:01","2025-02-26 20:37:01","","41-+","","226","","","","","","","","","","","English","","","","WOS:000821189200004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","diachronic change; frequency lexicon; non-standard Italian; Tuscan variety","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C2Q9BMT9","journalArticle","2021","Alderete, J; Baese-Berk, M; Leung, K; Goldrick, M","Cascading activation in phonological planning and articulation: Evidence from spontaneous speech errors","COGNITION","","0010-0277","10.1016/j.cognition.2020.104577","","Speaking involves both retrieving the sounds of a word (phonological planning) and realizing these selected sounds in fluid speech (articulation). Recent phonetic research on speech errors has argued that multiple candidate sounds in phonological planning can influence articulation because the pronunciation of mis-selected error sounds is slightly skewed towards unselected target sounds. Yet research to date has only examined these phonetic distortions in experimentally-elicited errors, leaving doubt as to whether they reflect tendencies in spontaneous speech. Here, we analyzed the pronunciation of speech errors of English-speaking adults in natural conversations relative to matched correct words by the same speakers, and found the conjectured phonetic distortions. Comparison of these data with a larger set of experimentally-elicited errors failed to reveal significant differences between the two types of errors. These findings provide ecologically-valid data supporting models that allow for information about multiple planning representations to simultaneously influence speech articulation.","2021-05","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","210","","","","","","","","","","English","","","","WOS:000635450600009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Articulation; Cascading activation; Phonetics; Phonological encoding; Speech errors; Speech production","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3KYR44AN","journalArticle","2022","Bueno-Cayo, AM; Carmona, MD; Castell-Enguix, R; Iborra-Marmolejo, I; Murphy, M; Irigaray, TQ; Cervera, JF; Moret-Tatay, C","Predicting Scores on the Mini-Mental State Examination (MMSE) from Spontaneous Speech","BEHAVIORAL SCIENCES","","2076-328X","10.3390/bs12090339","","The aim of this study was to examine the relationship between language components, such as lexical density, length, and content in terms of ""Time, Space and Action"", with MMSE scores. For this reason, a group of 33 older participants, without a diagnosis of dementia, was examined, providing information regarding recent and future events. Participants with higher MMSE scores showed higher lexical density, speech length, as well as number of tokens related to Time, Place and Action in their speech. However, these differences only reach the statistical level for lexical density when participants were divided into two groups (MCI and healthy controls). Word frequency was lower for participants with MCI but this difference was not statistically significant. Lastly, lexical density was positively correlated with MMSE scores and predicted MMSE scores. These results could be of interest at the applied level in the screening of MCI.","2022-09","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","9","12","","","","","","","","","","English","","","","WOS:000858018600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","ALZHEIMERS-DISEASE; cognitive impairment; language; LANGUAGE PERFORMANCE; MILD COGNITIVE IMPAIRMENT; Mini-Mental State Examination; MMSE; MODEL; OLDER-ADULTS; PROGRESSION; spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"36MRV2LD","journalArticle","2022","Larson, JE; Figueroa, MA; Pérez, HE","Impact of elocution task on the measurements of rhythmic patterns in Chilean Spanish","SPANISH IN CONTEXT","","1571-0718","10.1075/sic.00082.lar","","In this paper, we put to the test the validity of the theory of isochrony using data from Chilean Spanish. Spanish has been historically classified as syllable-timed, meaning its basic unit of prosody is the syllable. However, recent studies have shown that different methods of elicitation can have a significant effect on rhythm metrics (i.e., Arvaniti 2012). The present study measured a series of rhythm metrics from samples of 30 native Chilean Spanish speakers producing spontaneous speech and reading aloud. Using MANOVA analyses, the study determined that method of elicitation had a significant effect on the metrics: while spontaneous speech tended to produce values indicative of accent-timed rhythm, reading aloud yielded values which placed them closer to the syllable-timed rhythm category. This study helps to contribute to the notion that speech rhythm is not necessarily determined by language, but rather that there are other relevant factors.","2022-12-20","2025-02-26 20:37:01","2025-02-26 20:37:01","","405-431","","3","19","","","","","","","","","","English","","","","WOS:000901762300002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","accent-timed; Chilean Spanish; LANGUAGE; Spanish; speech rhythm; syllable-timed; theory of isochrony","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NBYDTANY","journalArticle","2023","Sola, A; Torregrosa-Azor, J","Intonation of Wh-questions in Northern British English Spontaneous Speech","INTERNATIONAL JOURNAL OF ENGLISH STUDIES","","1578-7044","10.6018/ijes.559521","","In this paper, we report the analysis of the melodic behavior of wh-questions from the North of England. The corpus contains 107 utterances issued by 19 different native informants in real communicative situations, extracted from recordings of street interviews published on YouTube and carried out in the cities of York, Manchester, Sheffield and Liverpool. The analysis is conducted through the Melodic Analysis of Speech (MAS) method (Cantero, 2002) which allows us to quantify, standardize and compare melodic configurations. The results describe four different intonation patterns for this type of question. A rising final inflection pattern (E1: 27%); a falling final inflection pattern (E2: 58%); a circumflex rising-falling final inflection pattern (E3: 5%); and a high nucleus falling pattern (E4: 10%). After describing and quantifying each of these patterns, the results are discussed in relation to those melodic descriptions made by precedent authors in the existing literature.","2023","2025-02-26 20:37:01","2025-02-26 20:37:01","","1-25","","1","23","","","","","","","","","","English","","","","WOS:001032314800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Acoustic Phonetics; British English; Intonation; Melodic Analysis of Speech (MAS); Melodic Patterns; Spontaneous Speech; Wh-questions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NP6HP8BI","journalArticle","2021","Wu, YJ; Zhang, CY; Wang, L; Duan, HL","A graph-convolutional neural network for addressing small-scale reaction prediction†","CHEMICAL COMMUNICATIONS","","1359-7345","10.1039/d1cc00586c","","We describe a graph-convolutional neural network (GCN) model, the reaction prediction capabilities of which are as potent as those of the transformer model based on sufficient data, and we adopt the Baeyer-Villiger oxidation reaction to explore their performance differences based on limited data. The top-1 accuracy of the GCN model (90.4%) is higher than that of the transformer model (58.4%).","2021-04-30","2025-02-26 20:37:01","2025-02-26 20:37:01","","4114-4117","","34","57","","","","","","","","","","English","","","","WOS:000637059100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","LANGUAGE; MODEL; OUTCOMES; TRANSFORMER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YWZUQ289","journalArticle","2024","Choi, HS","Feasibility of Transformer Model for User Authentication Using Electromyogram Signals","ELECTRONICS","","2079-9292","10.3390/electronics13204134","","Transformer models are widely used in natural language processing (NLP) and time-series data analysis. Applications of these models include prediction systems and hand gesture recognition using electromyogram (EMG) signals. However, in the case of time-series analysis, the models perform similarly to traditional networks, contrary to expectations. This study aimed to compare the performance of the transformer model and its various modified versions in terms of accuracy through a user authentication system using EMG signals, which exhibit significant variability and pose challenges in feature extraction. A Siamese network was employed to distinguish subtle differences in the EMG signals between users, using Euclidean distance. Data from 100 individuals were used to create a challenging scenario while ensuring accuracy. Three scenarios were considered: data preprocessing, integration with existing models, and the modification of the internal structure of the transformer model. The method that achieved the highest accuracy was the bidirectional long short-term memory (BiLSTM)-transformer approach. Based on this, a network was further constructed and optimized, resulting in a user authentication accuracy of 99.7% using EMG data from 100 individuals.","2024-10","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","20","13","","","","","","","","","","English","","","","WOS:001341710200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","bidirectional long short-term memory; electromyogram; NETWORK; RECOGNITION; Siamese network; time-series data; transformer model; user authentication system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4QLKMLUN","journalArticle","2023","Upadhyay, A; Garg, D; Singh, M","SHORT TERM LOAD FORECASTING FOR SMART GRIDS USING APACHE SPARK AND A MODIFIED TRANSFORMER MODEL","COMPUTING AND INFORMATICS","","1335-9150","10.31577/cai_2023_1_75","","Smart grid is an advanced electrical grid that enables more efficient distribution of electricity. It counters many of the problems presented by renewable energy sources such as variability in production through techniques like load forecasting and dynamic pricing. Smart grid generates massive amounts of data through smart meters, this data is used to forecast future load to adjust distribution. To process all this data, big data analysis is necessary. Most existing schemes use Apache Hadoop for big data processing and various techniques for load forecasting that include methods based on statistical theory, machine learning and deep learning. This paper proposes using Apache Spark for big data analysis and a modified version of the transformer model for forecasting load profiles of households. The modified transformer model has been tested against several state-of-the-art machine learning models. The proposed scheme was tested against several baseline and state-of-the-art machine learning models and evaluated in terms of the RMSE, when evaluating a regression model on data with a large number of outliers.","2023","2025-02-26 20:37:01","2025-02-26 20:37:01","","75-97","","1","42","","","","","","","","","","English","","","","WOS:001014429100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Apache Spark; big data; deep learning; HYBRID; load forecasting; NEURAL-NETWORK; REGRESSION; smart grid; time-series forecasting; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"38QWPV3Q","journalArticle","2021","Mao, JC; Yang, HR; Li, A; Li, H; Chen, YR","TPrune: Efficient Transformer Pruning for Mobile Devices","ACM TRANSACTIONS ON CYBER-PHYSICAL SYSTEMS","","2378-962X","10.1145/3446640","","The invention of Transformer model structure boosts the performance of Neural Machine Translation (NMI) tasks to an unprecedented level. Many previous works have been done to make the Transformer model more execution-friendly on resource-constrained platforms. These researches can be categorized into three key fields: Model Pruning, Transfer Learning, and Efficient Transformer Variants. The family of model pruning methods are popular for their simplicity in practice and promising compression rate and have achieved great success in the field of convolution neural networks (CNNs) for many vision tasks. Nonetheless, previous Transformer pruning works did not perform a thorough model analysis and evaluation on each Transformer component on off-the-shelf mobile devices. In this work, we analyze and prune transformer models at the line-wise granularity and also implement our pruning method on real mobile platforms. We explore the properties of all Transformer components as well as their sparsity features, which are leveraged to guide Transformer model pruning. We name our whole Transformer analysis and pruning pipeline as TPrune. In TPrune, we first propose Block-wise Structured Sparsity Learning (BSSL) to analyze Transformer model property. Then, based on the characters derived from BSSL, we apply Structured Hoycr Square (SHS) to derive the final pruned models. Comparing with the state-of-the-art Transformer pruning methods, TPrune is able to achieve a higher model compression rate with less performance degradation. Experimental results show that our pruned models achieve 1.16x-1.92x speedup on mobile devices with 0%-8% BLEU score degradation compared with the original Transformer model.","2021-07","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","3","5","","","","","","","","","","English","","","","WOS:000679964300006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;26<br/>Total Times Cited:&nbsp;&nbsp;28<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","embedded software; mobile computing; model pruning; Neural machine translation; neural networks; real-time system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"79C4MU4Y","journalArticle","2023","He, YC; Wang, X; Yang, ZJ; Xue, LB; Chen, YM; Ji, JY; Wan, F; Mukhopadhyay, SC; Men, L; Tong, MCF; Li, GL; Chen, SX","Classification of attention deficit/hyperactivity disorder based on EEG signals using a EEG-Transformer model","JOURNAL OF NEURAL ENGINEERING","","1741-2560","10.1088/1741-2552/acf7f5","","Objective. Attention-deficit/hyperactivity disorder (ADHD) is the most common neurodevelopmental disorder in adolescents that can seriously impair a person's attention function, cognitive processes, and learning ability. Currently, clinicians primarily diagnose patients based on the subjective assessments of the Diagnostic and Statistical Manual of Mental Disorders-5, which can lead to delayed diagnosis of ADHD and even misdiagnosis due to low diagnostic efficiency and lack of well-trained diagnostic experts. Deep learning of electroencephalogram (EEG) signals recorded from ADHD patients could provide an objective and accurate method to assist physicians in clinical diagnosis. Approach. This paper proposes the EEG-Transformer deep learning model, which is based on the attention mechanism in the traditional Transformer model, and can perform feature extraction and signal classification processing for the characteristics of EEG signals. A comprehensive comparison was made between the proposed transformer model and three existing convolutional neural network models. Main results. The results showed that the proposed EEG-Transformer model achieved an average accuracy of 95.85% and an average AUC value of 0.9926 with the fastest convergence speed, outperforming the other three models. The function and relationship of each module of the model are studied by ablation experiments. The model with optimal performance was identified by the optimization experiment. Significance. The EEG-Transformer model proposed in this paper can be used as an auxiliary tool for clinical diagnosis of ADHD, and at the same time provides a basic model for transferable learning in the field of EEG signal classification.","2023-10-01","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","5","20","","","","","","","","","","English","","","","WOS:001074313900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","ADHD; attention deficit/hyperactivity disorder (ADHD); attention mechanism; electroencephalogram (EEG); REPRESENTATION; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CVD277VZ","journalArticle","2024","Zhang, GL; Zhang, Y; Li, L; Zhou, JY; Chen, HL; Ji, JW; Li, YR; Cao, Y; Xu, ZH; Pian, C","Exploring Novel Fentanyl Analogues Using a Graph-Based Transformer Model","INTERDISCIPLINARY SCIENCES-COMPUTATIONAL LIFE SCIENCES","","1913-2751","10.1007/s12539-024-00623-0","","The structures of fentanyl and its analogues are easy to be modified and few types have been included in database so far, which allow criminals to avoid the supervision of relevant departments. This paper introduces a molecular graph-based transformer model, which is combined with a data augmentation method based on substructure replacement to generate novel fentanyl analogues. 140,000 molecules were generated, and after a set of screening, 36,799 potential fentanyl analogues were finally obtained. We calculated the molecular properties of 36,799 potential fentanyl analogues. The results showed that the model could learn some properties of original fentanyl molecules. We compared the generated molecules from transformer model and data augmentation method based on substructure replacement with those generated by the other two molecular generation models based on deep learning, and found that the model in this paper can generate more novel potential fentanyl analogues. Finally, the findings of the paper indicate that transformer model based on molecular graph helps us explore the structure of potential fentanyl molecules as well as understand distribution of original molecules of fentanyl.","2024-09","2025-02-26 20:37:01","2025-02-26 20:37:01","","712-726","","3","16","","","","","","","","","","English","","","","WOS:001211241000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Deep generative model; DISCOVERY; Fentanyl analogues; Molecular graph; Molecule generation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T5ZCNT9F","journalArticle","2024","Bingöl, G; Porcu, S; Floris, A; Atzori, L","QoE Estimation of WebRTC-based Audio-visual Conversations from Facial and Speech Features","ACM TRANSACTIONS ON MULTIMEDIA COMPUTING COMMUNICATIONS AND APPLICATIONS","","1551-6857","10.1145/3638251","","The utilization of user's facial- and speech-related features for the estimation of the Quality of Experience (QoE) of multimedia services is still underinvestigated despite its potential. Currently, only the use of either facial or speech features individually has been proposed, and relevant limited experiments have been performed. To advance in this respect, in this study, we focused on WebRTC-based videoconferencing, where it is often possible to capture both the facial expressions and vocal speech characteristics of the users. First, we performed thorough statistical analysis to identify the most significant facial- and speech-related features for QoE estimation, which we extracted from the participants' audio-video data collected during a subjective assessment. Second, we trained individual QoE estimation machine learning-based models on the separated facial and speech datasets. Finally, we employed data fusion techniques to combine the facial and speech datasets into a single dataset to enhance the QoE estimation performance due to the integrated knowledge provided by the fusion of facial and speech features. The obtained results demonstrate that the data fusion technique based on the Improved Centered Kernel Alignment (ICKA) allows for reaching a mean QoE estimation accuracy of 0.93, whereas the values of 0.78 and 0.86 are reached when using only facial or speech features, respectively.","2024-05","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","5","20","","","","","","","","","","English","","","","WOS:001192177900010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","Data Fusion; EXPRESSION; Facial Expressions; Machine Learning; Quality of Experience; RECOGNITION; Speech; WebRTC","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NUCEUVZN","journalArticle","2024","Chu, ZJ; Guo, KL; Xing, XF; Lan, YL; Cai, BL; Xu, XM","CorrTalk: Correlation Between Hierarchical Speech and Facial Activity Variances for 3D Animation","IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY","","1051-8215","10.1109/TCSVT.2024.3386836","","Speech-driven 3D facial animation is a challenging cross-modal task that has attracted growing research interest. During speaking activities, the mouth displays strong motions, while the other facial regions typically demonstrate comparatively weak activity levels. Existing approaches often simplify the process by directly mapping single-level speech features to the entire facial animation, which overlook the differences in facial activity intensity leading to overly smoothed facial movements. In this study, we propose a novel framework, CorrTalk, which effectively establishes the temporal correlation between hierarchical speech features and facial activities of different intensities across distinct regions. A novel facial activity intensity prior is defined to distinguish between strong and weak facial activity, obtained by statistically analyzing facial animations. Based on the facial activity intensity prior, we propose a dual-branch decoding framework to synchronously synthesize strong and weak facial activity, which guarantees wider intensity facial animation synthesis. Furthermore, a weighted hierarchical feature encoder is proposed to establish temporal correlation between hierarchical speech features and facial activity at different intensities, which ensures lip-sync and plausible facial expressions. Extensive qualitatively and quantitatively experiments as well as a user study indicate that our CorrTalk outperforms existing state-of-the-art methods. The source code and supplementary video are publicly available at: https://zjchu.github.io/projects/CorrTalk/.","2024-09","2025-02-26 20:37:01","2025-02-26 20:37:01","","8953-8965","","9","34","","","","","","","","","","English","","","","WOS:001409508700080","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","3D facial animation; 3D talking head; facial activity variance; hierarchical speech features; NETWORK; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4AE5IRRY","journalArticle","2024","Sun, YZ; Pang, SC; Zhang, YA","Advancing fluid identification via well-logging data: Leveraging persistent initialization and transformer modeling","PHYSICS OF FLUIDS","","1070-6631","10.1063/5.0201664","","In the domain of energy exploration, the forecasting of fluid via well logging is pivotal in directing exploration endeavors. Understanding the composition of fluid underground is key for exploration teams to accurately determine the size, potential reserves, and quality of oil and gas resources. This knowledge is critical in refining exploration tactics and employing resources wisely. We present a novel machine learning architecture termed ""PIFormer"" for predicting fluid. This design merges Persistence Initialization with a Transformer module. The combination of persistent initialization and Transformer modules is achieved by using the persistent initialization feature representation as input to the Transformer model. Persistent initialization provides a stable starting point, enabling the Transformer model to converge to effective feature representations more rapidly during the learning process. This combination helps address issues in existing methods such as training instability, slow convergence, and local optima problems caused by random initialization. By integrating persistent initialization and the Transformer model, prior knowledge and global information can be more effectively utilized, enhancing the accuracy and robustness of fluid identification. Compared to existing models, the combination of persistent initialization and the Transformer model demonstrates higher accuracy and robustness in fluid identification tasks. Specifically, our approach achieves significant improvements in fluid identification accuracy and outperforms existing models across various types of fluid identification problems. Additionally, our method significantly reduces model training time and improves convergence speed. These results clearly indicate that the combination of persistent initialization and the Transformer model effectively addresses limitations in existing models for fluid identification tasks, providing new avenues and methods for further research and application in this field.","2024-04","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","4","36","","","","","","","","","","English","","","","WOS:001205325600009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","LITHOLOGY; PREDICTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S42DQRE9","journalArticle","2023","Ash, S; Nevler, N; Shellikeri, S; Rascovsky, K; Shaw, L; Lee, EB; Trojanowsk, JQ; Grossman, M","Apraxia of Speech in the Spontaneous Speech of Nonfluent/Agrammatic Primary Progressive Aphasia","JOURNAL OF ALZHEIMERS DISEASE REPORTS","","2542-4823","10.3233/ADR-220089","","Background: Apraxia of speech (AOS) is a core feature of nonfluent/agrammatic primary progressive aphasia (naPPA), but its precise characteristics and the prevalence of AOS features in spontaneous speech are debated. Objective: To assess the frequency of features of AOS in the spontaneous, connected speech of individuals with naPPA and to evaluate whether these features are associated with an underlying motor disorder such as corticobasal syndrome or progressive supranuclear palsy. Methods: We examined features of AOS in 30 patients with naPPA using a picture description task. We compared these patients to 22 individuals with behavioral variant frontotemporal dementia and 30 healthy controls. Each speech sample was evaluated perceptually for lengthened speech segments and quantitatively for speech sound distortions, pauses between and within words, and articulatory groping. We compared subgroups of naPPA with and without at least two features of AOS to assess the possible contribution of a motor impairment to speech production deficits. Results: naPPA patients produced both speech sound distortions and other speech sound errors. Speech segmentation was found in 27/30 (90%) of individuals. Distortions were identified in 8/30 (27%) of individuals, and other speech sound errors occurred in 18/30 (60%) of individuals. Frequent articulatory groping was observed in 6/30 (20%) of individuals. Lengthened segments were observed rarely. There were no differences in the frequencies of AOS features among naPPA subgroups as a function of extrapyramidal disease. Conclusion: Features of AOS occur with varying frequency in the spontaneous speech of individuals with naPPA, independently of an underlying motor disorder.","2023","2025-02-26 20:37:01","2025-02-26 20:37:01","","589-604","","1","7","","","","","","","","","","English","","","","WOS:001065785300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","3 VARIANTS; ACQUIRED APRAXIA; CORTICOBASAL SYNDROME; CRITERIA; DIAGNOSIS; Language; NONFLUENT APHASIA; PATHOLOGY; phonetics; primary progressive nonfluent aphasia; RATING-SCALE; RELIABILITY; speech; SUPRANUCLEAR PALSY; verbal apraxia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6748BEQS","journalArticle","2023","Tienkamp, TB; Son, RJJHV; Halpern, BM","Objective speech outcomes after surgical treatment for oral cancer: An acoustic analysis of a spontaneous speech corpus containing 32.850 tokens","JOURNAL OF COMMUNICATION DISORDERS","","0021-9924","10.1016/j.jcomdis.2022.106292","","Introduction: Surgical treatment for oral cancer leads to lasting changes of the vocal tract and individuals treated for oral cancer (ITOC) often experience speech problems. The purpose of this study was to analyse the acoustic properties of the spontaneous speech of individuals who were surgically treated for oral cancer. It was investigated (1) how key spectral measures of articula-tion change post-treatment; (2) whether changes are more related to target manner or place of articulation; and (3) how spectral measures develop at various time points following treatment.Method: A corpus consisting of 32.850 tokens was constructed by manually segmenting the speech of five (four female -one male) American English speaking ITOC. General acoustic characteristics (duration and spectral tilt), plosives (burst frequency), fricatives (centre of gravity and spectral skewness), and vowels (F1 and F2) were analysed using linear mixed effects regression and compared to control speech. Moreover, a within speaker analysis was performed for speakers with multiple recordings.Results: Manner of articulation is more predictive of post-treatment changes than place of articulation. Compared to controls, ITOC produced the fricatives /f, v, theta, eth , s, z, ?, / with a lower centre of gravity while no differences were found for plosives and vowels. Longitudinal analyses show high within-speaker variation, but general improvements one-year post-treatment.Conclusions: Surgical oral cancer treatment changes the spectral properties of speech. Fricatives with varying manner of articulations were distorted, suggesting that manner of articulation is more predictive than place of articulation in identifying general problem areas for ITOC.","2023-01","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","101","","","","","","","","","","English","","","","WOS:000906564900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Acoustic analysis; ARTICULATION; Oral cancer; PARTIAL GLOSSECTOMY; REHABILITATION; Spontaneous speech; TONGUE; Tongue reconstruction; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GPVMWMI4","journalArticle","2025","Gerona, J; de Kok, D; Salis, C; Webster, J; Jonkers, R","Characterization of agrammatism in Tagalog: Evidence from narrative spontaneous speech","APHASIOLOGY","","0268-7038","10.1080/02687038.2024.2353164","","BackgroundAgrammatism in agglutinative languages exhibits preservation of verb morphology due to their rich morphological paradigms. Tagalog, an agglutinative language mainly spoken in the Philippines, remains uncharacterized in agrammatism yet holds potential for future research that can challenge existing theories and help advance novel ones.AimsThe purpose of this study is to quantify and describe the characteristics of agrammatism in Tagalog in narrative spontaneous speech, to examine whether these patterns resemble those reported in other agglutinative languages, and to compare the results obtained to those emerging in literature for non-agglutinative languages.Methods & ProceduresNarrative spontaneous speech was elicited from 10 individuals with non-fluent Broca's aphasia and 12 matched controls. A series of parameters, both conventional and language-specific measures, were selected for analyses.Outcomes & ResultsTagalog-speaking individuals with agrammatism exhibited slow and fragmented speech, with a strong preference for minor and simple constructions resulting to decrease in overall grammaticality and sentence complexity. Verb deficits were also found specifically in verbal predication, lexical diversity, and finiteness. There is a prevalent use of bare verb forms, consequently resulting to the decline of verb finiteness and inflections. Code-mixing is found to be extremely variable and statistically non-prominent between groups but patterns may be attributed to personal and sociolinguistic factors.ConclusionPatterns of agrammatism in Tagalog majorly mirror the trends reported in other agglutinative and non-agglutinative languages. Where Tagalog agrammatism departs from other agglutinative languages is the increased use of bare verbs as opposed to the obligatory inflected forms. Although still many questions are unresolved, Tagalog offers an interesting testing ground for variety of topics and issues in agrammatic aphasia.","2025-03-04","2025-02-26 20:37:01","2025-02-26 20:37:01","","385-417","","3","39","","","","","","","","","","English","","","","WOS:001250526000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;104</p>","","","agglutinative language; Agrammatism; aphasia; APHASIA RESEARCH; ARGUMENT STRUCTURE; BROCAS; MORPHOLOGY; narrative speech; PATTERNS; QUANTITATIVE-ANALYSIS; RETRIEVAL; SYMPTOMS; Tagalog; TURKISH; VERB PRODUCTION; verbs","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RH9ARAWS","journalArticle","2022","Garcia, TFM; Vallero, CND; de Assumpçao, D; Aprahamian, I; Sanches, YM; Borim, FSA; Neri, AL","Number of ideas in spontaneous speech predicts cognitive impairment and frailty in community-dwelling older adults nine years later","AGING & MENTAL HEALTH","","1360-7863","10.1080/13607863.2021.1998347","","Objective To investigate the associations between linguistic parameters in spontaneous speech at baseline and cognitive impairment and frailty nine years later. Methods A prospective analysis was carried out on data of the Frailty in Brazilian Older People Study (FIBRA) Study, a population-based study on frailty. From a probabilistic sample of 384 individuals aged 65 and older at baseline (2008-2009), 124 aged 73 years and older at follow-up were selected, as they had scored above the cutoff values of cognitive screening for dementia adjusted by years of schooling at baseline and had answered to the question What is healthy aging and had no frailty at baseline. Verbal responses were submitted to content analysis and had its ideas and words counted. Number of ideas corresponded to the frequency of meaning categories and number of words to all identified significant textual elements in the text constituted by the sample answers to that question. Results Multivariate logistic regression analyses, controlling for the effects of age, sex, and education, showed that individuals with a high number of ideas at baseline had lower chance of having cognitive impairment (OR = 0.39; 95% CI 0.22 - 0.69) and frailty (OR 0.66; 95% CI 0.44 - 0.99) nine years later than those with low number of ideas. Conclusions Higher number of ideas, but not number of words, in spontaneous speech seems to be associated to a more positive prognosis in mental and physical health nine years later. Linguistic markers may be used to predict cognitive impairment and frailty in older individuals.","2022-10-03","2025-02-26 20:37:01","2025-02-26 20:37:01","","2022-2030","","10","26","","","","","","","","","","English","","","","WOS:000721236200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","ASSOCIATION; CITIES; cognition; DECLINE; DEMENTIA; frailty; LANGUAGE; LIFE; longitudinal studies; MINI-MENTAL-STATE; older adults; PERFORMANCE; PREVALENCE; PROPOSITIONAL DENSITY; Verbal behavior","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J4IFHNYU","journalArticle","2023","Nekrasova, GA","Self-correction in the spontaneous speech of Komi speakers","VESTNIK UGROVEDENIYA-BULLETIN OF UGRIC STUDIES","","2220-4156","10.30624/2220-4156-2023-13-3-452-460","","Introduction: an integral feature of oral discourse is the discontinuity of the act of speech, which informs about the difficulties in finding and verbalization of a speaker's speech intention and consists in the presence of hesitations, repetitions, self-corrections, as well as in the use of non-verbal means of communication. Traditional Finno-Ugric studies are focused primarily on written language. Oral speech rarely is an independent object of study. The study of the peculiarities of oral speech is relevant for determination of the current state of the language, establishment of the main trends in its development, as well as phenomena characteristic only of this form of language. Objective: to reveal the main types of self-correction in spontaneous speech of Komi speakers and possible causes of their occurrence. Research materials: samples of public speech of television programs that sufficiently fully reflect the features of spontaneous monologue and dialog speech of Komi speakers. Results and novelty of the research: for the first time the article analyzes various types of self-corrections in the spontaneous speech of Komi speakers. It is established that in the process of speech generation, a speaker may encounter phonetic, grammatical and lexical problems. It is revealed that self-corrections occur within the predication. Contact corrections are frequent. A speaker tries to immediately correct an erroneous or inappropriate fragment of speech from his point of view, then after a hesitative marker to bring a full-meaning word and to find a Komi equivalent for a Russian insertion. Self-corrections in speech can be caused by clarification and explanation of a fragment of speech, incorrect or inaccurate use of a word form, and interlanguage interference.","2023","2025-02-26 20:37:01","2025-02-26 20:37:01","","452-460","","3","13","","","","","","","","","","English","","","","WOS:001109919200003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","code switching; hesitation; Komi language; oral speech; preparative substitution; REPETITIONS; self-corrections of a speaker; speech shifts; spontaneous monologue","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UDILYTZV","journalArticle","2024","Wang, LF; Liu, RX; Wang, Y; Xu, X; Zhang, R; Wei, YE; Zhu, RX; Zhang, XZ; Wang, F","Effectiveness of a Biofeedback Intervention Targeting Mental and Physical Health Among College Students Through Speech and Physiology as Biomarkers Using Machine Learning: A Randomized Controlled Trial","APPLIED PSYCHOPHYSIOLOGY AND BIOFEEDBACK","","1090-0586","10.1007/s10484-023-09612-3","","Biofeedback therapy is mainly based on the analysis of physiological features to improve an individual's affective state. There are insufficient objective indicators to assess symptom improvement after biofeedback. In addition to psychological and physiological features, speech features can precisely convey information about emotions. The use of speech features can improve the objectivity of psychiatric assessments. Therefore, biofeedback based on subjective symptom scales, objective speech, and physiological features to evaluate efficacy provides a new approach for early screening and treatment of emotional problems in college students. A 4-week, randomized, controlled, parallel biofeedback therapy study was conducted with college students with symptoms of anxiety or depression. Speech samples, physiological samples, and clinical symptoms were collected at baseline and at the end of treatment, and the extracted speech features and physiological features were used for between-group comparisons and correlation analyses between the biofeedback and wait-list groups. Based on the speech features with differences between the biofeedback intervention and wait-list groups, an artificial neural network was used to predict the therapeutic effect and response after biofeedback therapy. Through biofeedback therapy, improvements in depression (p = 0.001), anxiety (p = 0.001), insomnia (p = 0.013), and stress (p = 0.004) severity were observed in college-going students (n = 52). The speech and physiological features in the biofeedback group also changed significantly compared to the waitlist group (n = 52) and were related to the change in symptoms. The energy parameters and Mel-Frequency Cepstral Coefficients (MFCC) of speech features can predict whether biofeedback intervention effectively improves anxiety and insomnia symptoms and treatment response. The accuracy of the classification model built using the artificial neural network (ANN) for treatment response and non-response was approximately 60%. The results of this study provide valuable information about biofeedback in improving the mental health of college-going students. The study identified speech features, such as the energy parameters, and MFCC as more accurate and objective indicators for tracking biofeedback therapy response and predicting efficacy. Trial Registration ClinicalTrials.gov ChiCTR2100045542.","2024-03","2025-02-26 20:37:01","2025-02-26 20:37:01","","71-83","","1","49","","","","","","","","","","English","","","","WOS:001132558600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","AGE-OF-ONSET; ANXIETY; Biofeedback; College students; DEPRESSION; DISORDERS; FEATURES; Formant; INSOMNIA; Machine learning; SEVERITY; Speech acoustic features; STRESS; VOCAL INDICATORS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PVR4JP2Y","journalArticle","2023","Park, H; Lee, Y","Korean Mothers' Speech to Young Children with Cochlear Implants in Parent-Child Interaction","COMMUNICATION SCIENCES AND DISORDERS-CSD","","2288-1328","10.12963/csd.231019","","Objectives: Infant-directed speech is the particular form of spontaneous speech observed in interactions between parents and their young children. There are reasons to believe that infant-directed speech may help to make language acquisition easier for young children. Thus, this study investigates the effects of cochlear implantation on mothers' speech to their young children. Methods: Fourteen children with cochlear implants (CIs) and 14 agematched children with normal hearing (NH), aged 12 to 35 months, participated in this study. We recorded mothers' utterances through a parent-child interaction task. Mothers ' speech features such as fundamental frequency, utterance length, speech rate, and pause duration were measured across speech samples. Results: There were no significant differences between the CI and NH groups in fundamental frequency, utterance length, and pause duration variables. However, the speech of mothers in the CI group was significantly slower than that of the NH group. Conclusion: Mothers used typical infant-directed speech styles when speaking to their children with CIs. Additionally, mothers of the CI group tended to speak more slowly than mothers of the NH group in the parent-child interactions. Given that the language skills of children with CIs are significantly lower than those of children with NH in this study, mothers of the CI group may speak to their children at a slower rate than those of the NH group to provide their linguistic input more efficiently. These findings suggest that children with CIs are exposed to infant-directed speech with similar acoustic qualities as children with NH.","2023-12","2025-02-26 20:37:01","2025-02-26 20:37:01","","862-872","","4","28","","","","","","","","","","English","","","","WOS:001165342500010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Cochlear implants; INFANT; Infant-directed speech; LANGUAGE; LITERACY; Mothers; PITCH; RESPONSIVENESS; TODDLERS; Young children","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9VGX7CI6","journalArticle","2024","Wang, YS; Zhang, L; Qi, X; Yang, XP; Tan, QL","A Baseline Drift-Elimination Algorithm for Strain Measurement-System Signals Based on the Transformer Model","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14114447","","Strain measurements are vital in engineering trials, testing, and scientific research. In the process of signal acquisition, baseline drift has a significant impact on the accuracy and validity of data. Traditional solutions, such as discrete wavelet transform and empirical mode decomposition, cannot be used in real-time systems. To solve this problem, this paper proposes a Transformer-based model to eliminate the drift in the signal. A self-attentive mechanism is utilized in the encoder of the model to learn the interrelationships between the components of the input signal, and captures the key features. Then, the decoder generates a corrected signal. Meanwhile, a high-precision strain acquisition system is constructed. The experiments tested the model's ability to remove drift from simulated voltage signals with and without Gaussian noise. The results demonstrated that the transformer model excels at eliminating signal baseline drift. Additionally, the performance of the model was investigated under different temperature conditions and with different levels of force applied by the electronic universal testing machine to produce strain. The experimental results indicate that the Transformer model can largely eliminate drift in dynamic signals l and has great potential for practical applications.","2024-06","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","11","14","","","","","","","","","","English","","","","WOS:001245712100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","baseline drift mitigation; drift signal; GAUGE; REMOVAL; strain measurement; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2RSYY5NV","journalArticle","2023","Wu, C; Huang, HW; Zhang, L; Chen, JY; Tong, Y; Zhou, ML","Towards automated 3D evaluation of water leakage on a tunnel face via improved GAN and self-attention DL model","TUNNELLING AND UNDERGROUND SPACE TECHNOLOGY","","0886-7798","10.1016/j.tust.2023.105432","","Grasping the segmentation and three-dimensional (3D) positioning information of the water leakage area on a rock tunnel face is of great significance for determining the necessary construction arrangements to ensure the safety of tunnel excavation. This paper presents a novel method for automated 3D evaluation of a tunnel leakage area based on an improved Generative adversarial network (GAN) and Swin Transformer model. First, this paper solves the shortcomings of insufficient and unbalanced data in the original leakage image datasets obtained from mountain and submarine tunnel projects, by using new images generated by an improved lightweight GAN model that establishes the GAN-based WIIN-2 dataset. The leakage images in this dataset are then divided into five categories. Afterwards, a newly developed high-performance Swin Transformer model combines shift windows and a self-attention mechanism to produce intelligent segmentation of the leakage area. The segmentation results of the Swin Transformer model on the GAN-based WIIN-2 dataset achieves mAcc, mIoU, mF score, mPrecision and mRecall metrics of 93.1%, 91.5%, 82.83%, 85.62% and 80.3%, respectively. The segmentation results of the DL models (Swin Transformer, Deeplab V3+, Fast CNN and Unet) are subsequently compared. The Swin Transformer model performs better than the other three models in terms of the five evaluation metrics and segmentation efficiency, which indicates that the Swin Transformer model is an improvement on current methods for segmenting leakage areas on a rock tunnel face. Finally, the novel 3D leakage area location model proposed in this work is used to visualize and reconstruct the 3D coordinates of the leakage area on the rock tunnel face.","2023-12","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","142","","","","","","","","","","English","","","","WOS:001088680900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","3D reconstruction; Improved GAN; Swin transformer; Tunnel leakage segmentation; Unbalanced image dataset","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RPFPNKS9","journalArticle","2024","Srinivas, B; Bagadi, L; Darimireddy, NK; Prasad, PS; Satrupalli, S; Kumar, BA","DEEP LEARNING-BASED MODIFIED TRANSFORMER MODEL FOR AUTOMATED NEWS ARTICLE SUMMARIZATION","FACTA UNIVERSITATIS-SERIES ELECTRONICS AND ENERGETICS","","0353-3670","10.2298/FUEE2402261S","","The amount of textual data on the internet is increasing enormously, so data summarization into text has become essential. As generating text summaries manually is an arduous task and humans are generally prone to make mistakes, deep learning techniques have evolved to overcome this problem. Modified transformer-based deep learning models with varying encoder-decoder and feed-forward network layers are proposed to develop an abstractive summary of the news articles. The proposed transformer model provides the advantage of parallelization with the help of multiple attention head layers to process long sentences, and hence, better text summarization performance is achieved. These models are trained on an 'in - shorts' dataset, and the proposed model is compared with the PEGASUS-CNNdaily-mail, BART-large-CNN, and DistilBART-CNN-12-6 models on the CNN/DailyMail dataset. The performance is evaluated in terms of the ROUGE score by comparing it with the existing Recurrent Neural Network (RNN) model. The suggested transformer model achieved a ROUGE score of 0.33, surpassing the RNN model score of 0.17. This innovative approach can be employed on extensive textual data to extract summaries or headlines.","2024-06","2025-02-26 20:37:01","2025-02-26 20:37:01","","261-276","","2","37","","","","","","","","","","English","","","","WOS:001262372400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Abstractive summarization; Deep Learning; Large Language Model; Natural Language Processing; News Article Summarization; RNN; Transformer Model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FCKTEB9W","journalArticle","2023","Muhammad, T; Aftab, AB; Ibrahim, M; Ahsan, MM; Muhu, MM; Khan, SI; Alam, MS","Transformer-Based Deep Learning Model for Stock Price Prediction: A Case Study on Bangladesh Stock Market","INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE AND APPLICATIONS","","1469-0268","10.1142/S146902682350013X","","In modern capital market the price of a stock is often considered to be highly volatile and unpredictable because of various social, financial, political and other dynamic factors. With calculated and thoughtful investment, stock market can ensure a handsome profit with minimal capital investment, while incorrect prediction can easily bring catastrophic financial loss to the investors. This paper introduces the application of a recently introduced machine learning model - the Transformer model, to predict the future price of stocks of Dhaka Stock Exchange (DSE), the leading stock exchange in Bangladesh. The transformer model has been widely leveraged for natural language processing and computer vision tasks, but, to the best of our knowledge, has never been used for stock price prediction task at DSE. Recently the introduction of time2vec encoding to represent the time series features has made it possible to employ the transformer model for the stock price prediction. This paper concentrates on the application of transformer-based model to predict the price movement of eight specific stocks listed in DSE based on their historical daily and weekly data. Our experiments demonstrate promising results and acceptable root mean squared error on most of the stocks.","2023-09","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","03","22","","","","","","","","","","English","","","","WOS:000967586500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","artificial neural network; Dhaka stock exchange; Machine learning; stock price prediction; time series analysis; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7CPZXVZC","journalArticle","2023","Tharmakulasingam, M; Wang, WW; Kerby, M; La Ragione, R; Fernando, A","TransAMR: An Interpretable Transformer Model for Accurate Prediction of Antimicrobial Resistance Using Antibiotic Administration Data","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3296221","","Antimicrobial Resistance (AMR) is a growing public and veterinary health concern, and the ability to accurately predict AMR from antibiotics administration data is crucial for effectively treating and managing infections. While genomics-based approaches can provide better results, sequencing, assembling, and applying Machine Learning (ML) methods can take several hours. Therefore, alternative approaches are required. This study focused on using ML for antimicrobial stewardship by utilising data extracted from hospital electronic health records, which can be done in real-time, and developing an interpretable 1D-Transformer model for predicting AMR. A multi-baseline Integrated Gradient pipeline was also incorporated to interpret the model, and quantitative validation metrics were introduced to validate the model. The performance of the proposed 1D-Transformer model was evaluated using a dataset of urinary tract infection (UTI) patients with four antibiotics. The proposed 1D-Transformer model achieved 10% higher area under curve (AUC) in predicting AMR and outperformed traditional ML models. The Explainable Artificial Intelligence (XAI) pipeline also provided interpretable results, identifying the signatures contributing to the predictions. This could be used as a decision support tool for personalised treatment, introducing AMR-aware food and management of AMR, and it could also be used to identify signatures for targeted interventions.","2023","2025-02-26 20:37:01","2025-02-26 20:37:01","","75337-75350","","","11","","","","","","","","","","English","","","","WOS:001038324800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","antimicrobial stewardship; missing labels; multi-drug AMR; multi-label prediction; Transformer; XAI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C384EB4Z","journalArticle","2022","Dan, YP; Zhu, ZN; Jin, WS; Li, Z","S-Swin Transformer: simplified Swin Transformer model for offline handwritten Chinese character recognition","PEERJ COMPUTER SCIENCE","","2376-5992","10.7717/peerj-cs.1093","","The Transformer shows good prospects in computer vision. However, the Swin Transformer model has the disadvantage of a large number of parameters and high computational effort. To effectively solve these problems of the model, a simplified Swin Transformer (S-Swin Transformer) model was proposed in this article for handwritten Chinese character recognition. The model simplifies the initial four hierarchical stages into three hierarchical stages. In addition, the new model increases the size of the window in the window attention; the number of patches in the window is larger; and the perceptual field of the window is increased. As the network model deepens, the size of patches becomes larger, and the perceived range of each patch increases. Meanwhile, the purpose of shifting the window's attention is to enhance the information interaction between the window and the window. Experimental results show that the verification accuracy improves slightly as the window becomes larger. The best validation accuracy of the simplified Swin Transformer model on the dataset reached 95.70%. The number of parameters is only 8.69 million, and FLOPs are 2.90G, which greatly reduces the number of parameters and computation of the model and proves the correctness and validity of the proposed model.","2022-09-20","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","8","","","","","","","","","","English","","","","WOS:000863162200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","Handwritten Chinese character recognition; ONLINE; Shifting the window?s attention; Simplified Swin Transformer; Window attention","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TZBH44BX","journalArticle","2024","Cheung, LH; Di Marco, G","Composing Conversational Architecture by Integrating Large Language Model: From Reactive to Suggestive Architecture through Exploring the Mathematical Nature of the Transformer Model","NEXUS NETWORK JOURNAL","","1590-5896","10.1007/s00004-024-00805-9","","First proposed in the 1960s, Conversational Architecture enhances human and computer-integrated built environment interaction. Nowadays, most interactive designs are based on reaction and automation, rarely on conversation. Despite Natural Language Processing, including Large Language Model (LLM), being considered a candidate for Human-Computer Interaction (HCI), LLM applications are limited to verbal communication. The syntactic relationship between LLM, and architectural composition is underexplored. The paper proposes a qualitative framework to integrate the theoretical research of LLM and HCI in Conversational Architecture design. Through a mathematical and algorithmic analysis of a transformer model, the key component of LLM, its attributes are mapped onto Conversational Architecture parameters. With the identified design implications, a theatre hall design experiment is conducted. Through observation, the feasibility and challenges of the proposed framework are analysed.","2024-11-26","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","","","","","","","","","","","English","","","","WOS:001363462800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Computational design; Conversational architecture; Large language model; Performative optimisation; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y7ZAXBWZ","journalArticle","2024","Meng, X; Mei, J; Tang, XW; Jiang, JH; Sun, CY; Song, K","The Degradation Prediction of Proton Exchange Membrane Fuel Cell Performance Based on a Transformer Model","ENERGIES","","1996-1073","10.3390/en17123050","","Proton exchange membrane fuel cells have attracted widespread attention due to their cleanliness and high energy density, but the performance degradation during operation greatly limits their commercialization. Therefore, the reliable degradation prediction of fuel cell performance is of great significance. The recovery phenomenon of the reversible voltage loss that occurs during the operation of fuel cells has posed great difficulties for model training and prediction. Moreover, the models may easily and erroneously learn the combined trends in the recovery of reversible voltage loss and performance degradation. To address this issue, this paper employs the Transformer model to predict the performance degradation of fuel cells. By utilizing the unique self-attention structure and masking mechanism of the Transformer model, the signal for the recovery of the reversible voltage loss is adopted as the input for the model to avoid interference from information before voltage recovery on subsequent predictions. Experimental results show that the model has the highest prediction accuracy at various prediction starting points. Meanwhile, it can predict the accelerated performance degradation of fuel cells, which has positive implications for health management.","2024-06","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","12","17","","","","","","","","","","English","","","","WOS:001256599200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;18<br/>Total Times Cited:&nbsp;&nbsp;18<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","health management; PEMFC; performance degradation prediction; PROGNOSTIC METHOD; proton exchange membrane fuel cells; recovery of the reversible voltage loss; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BEM583Z5","journalArticle","2021","Lee, C; Cho, GJ; Kim, J","Development of Scott Transformer Model in Electromagnetic Transients Programs for Real-Time Simulations","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app11125752","","This paper presents a Scott transformer model to be applied in electromagnetic transients (EMT) programs, particularly in the absence of a detailed Scott transformer model for performing real-time simulations (RTS). Regarding a Scott transformer, a common topology for converting a three-phase network into two single-phase networks, the transformer model in EMT programs is essential to simulate large-scale electric railway systems. A code-based model has been developed to simulate the transformer in RTS directly and contain the transformer's actual impedance characteristics. By establishing a mathematical foundation with the current injection method, we presented a matrix representation in conjunction with a network solution of EMT programs. The proposed model can handle more practical parameters of Scott transformers with a relatively low computational load. Thus, it supports the flexible computation of real-time simulators with a finite number of processor units. The accuracy of the model is verified by simulating it and comparing the simulation results with an industrial transformer's certified performance. Furthermore, a case study involving a comparison of the results with the field measurement data of an actual Korean railway system demonstrated the efficacy of the model.","2021-06","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","12","11","","","","","","","","","","English","","","","WOS:000666250000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","electric railway system; RAILWAY ELECTRIFICATION; real-time simulation; Scott transformer; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V2QP8J8L","journalArticle","2022","Chen, HY; Li, C; Wang, G; Li, XY; Rahaman, MM; Sun, HZ; Hu, WM; Li, YX; Liu, WL; Sun, CH; Ai, SL; Grzegorzek, M","GasHis-Transformer: A multi-scale visual transformer approach for gastric histopathological image detection","PATTERN RECOGNITION","","0031-3203","10.1016/j.patcog.2022.108827","","In this paper, a multi-scale visual transformer model, referred as GasHis-Transformer, is proposed for Gastric Histopathological Image Detection (GHID), which enables the automatic global detection of gastric cancer images. GasHis-Transformer model consists of two key modules designed to extract global and local information using a position-encoded transformer model and a convolutional neural network with local convolution, respectively. A publicly available hematoxylin and eosin (H&E) stained gastric histopathological image dataset is used in the experiment. Furthermore, a Dropconnect based lightweight network is proposed to reduce the model size and training time of GasHis-Transformer for clinical applications with improved confidence. Moreover, a series of contrast and extended experiments verify the robustness, extensibility and stability of GasHis-Transformer. In conclusion, GasHis-Transformer demonstrates high global detection performance and shows its significant potential in GHID task. (C) 2022 Elsevier Ltd. All rights reserved.","2022-10","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","130","","","","","","","","","","English","","","","WOS:000833526700007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;123<br/>Total Times Cited:&nbsp;&nbsp;126<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Gastric histropathological image; Image detection; Multi-scale visual transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"53W3KI2A","journalArticle","2021","Yoon, Y; Son, Y; Cho, J; Jang, S; Kim, YG; Choi, S","High-Frequency Modeling of a Three-Winding Power Transformer Using Sweep Frequency Response Analysis","ENERGIES","","1996-1073","10.3390/en14134009","","A power transformer is an essential device for stable and reliable power transfer to customers. Therefore, accurate modeling of transformers is required for simulation-based analysis with the model. The paper proposes an efficient and straightforward parameter estimation of power transformers based on sweep frequency response analysis (SFRA) test data. The method first develops a transformer model consisting of repetitive RLC sections and mutual inductances and then aligns the simulated SFRA curve with the measured one by adjusting parameters. Note that this adjustment is based on individual parameter impacts on the SFRA curve. After aligning the two curves, the final transformer model can be obtained. In this paper, actual single-phase, three-winding transformer model parameters were estimated based on field SFRA data, showing that SFRA curves simulated from the estimated model are consistent with the measured data.","2021-07","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","13","14","","","","","","","","","","English","","","","WOS:000671078300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","DIAGNOSIS; FAULTS; FRA; parameter estimation; power transformer; RADIAL DEFORMATION; SFRA; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U7JIT5I9","journalArticle","2022","Alerskans, E; Nyborg, J; Birk, M; Kaas, E","A transformer neural network for predicting near-surface temperature","METEOROLOGICAL APPLICATIONS","","1350-4827","10.1002/met.2098","","A new method based on the Transformer model is proposed for post-processing of numerical weather prediction (NWP) forecasts of 2 m air temperature. The Transformer is a machine learning (ML) model based on self-attention, which extracts information about which inputs are most important for the prediction. It is trained using time series input from NWP variables and crowd-sourced 2 m air temperature observations from more than 1000 private weather stations (PWSs). The performance of the new post-processing model is evaluated using both observational data from PWSs and completely independent observations from the Danish Meteorological Institute (DMI) network of surface synoptic observations (SYNOP) stations. The performance of the Transformer model is compared against the raw NWP forecast, as well as against two benchmark post-processing models; a linear regression (LR) model and a neural network (NN). The results evaluated using PWS observations show an improvement in the 2 m temperature forecasts with respect to both bias and standard deviation (STD) for all three post-processing models, with the Transformer model showing the largest improvement. The raw NWP forecast, LR, NN and Transformer model have a bias and STD of 0.34 and 1.96 degrees C, 0.03 and 1.63 degrees C, 0.10 and 1.53 degrees C and 0.02 and 1.13 degrees C, respectively. The corresponding results using DMI SYNOP stations also show improved forecasts, where the Transformer model performs better than both the raw NWP forecast and the two benchmark models. However, a dependence on distance to the coast and cold temperatures is observed.","2022-09","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","5","29","","","","","","","","","","English","","","","WOS:000869968900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;109</p>","","","ENSEMBLE FORECASTS; KALMAN FILTER; machine learning; MODEL OUTPUT STATISTICS; MOS; NUMERICAL WEATHER PREDICTION; NWP; post-processing; private weather stations; REGION; SYSTEM; TERRAIN; WIND-SPEED","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"83DDFH3Z","journalArticle","2025","Jiang, C; Jiang, ZK; Zhang, ZT; Huang, HX; Zhou, H; Jiang, QH; Teng, Y; Li, H; Xu, B; Li, X; Xu, JY; Ding, CY; Li, K; Tian, R","An explainable transformer model integrating PET and tabular data for histologic grading and prognosis of follicular lymphoma: a multi-institutional digital biopsy study","EUROPEAN JOURNAL OF NUCLEAR MEDICINE AND MOLECULAR IMAGING","","1619-7070","10.1007/s00259-025-07090-9","","Background Pathological grade is a critical determinant of clinical outcomes and decision-making of follicular lymphoma (FL). This study aimed to develop a deep learning model as a digital biopsy for the non-invasive identification of FL grade. Methods This study retrospectively included 513 FL patients from five independent hospital centers, randomly divided into training, internal validation, and external validation cohorts. A multimodal fusion Transformer model was developed integrating 3D PET tumor images with tabular data to predict FL grade. Additionally, the model is equipped with explainable modules, including Gradient-weighted Class Activation Mapping (Grad-CAM) for PET images, SHapley Additive exPlanations analysis for tabular data, and the calculation of predictive contribution ratios for both modalities, to enhance clinical interpretability and reliability. The predictive performance was evaluated using the area under the receiver operating characteristic curve (AUC) and accuracy, and its prognostic value was also assessed. Results The Transformer model demonstrated high accuracy in grading FL, with AUCs of 0.964-0.985 and accuracies of 90.2-96.7% in the training cohort, and similar performance in the validation cohorts (AUCs: 0.936-0.971, accuracies: 86.4-97.0%). Ablation studies confirmed that the fusion model outperformed single-modality models (AUCs: 0.974 - 0.956, accuracies: 89.8%-85.8%). Interpretability analysis revealed that PET images contributed 81-89% of the predictive value. Grad-CAM highlighted the tumor and peri-tumor regions. The model also effectively stratified patients by survival risk (P < 0.05), highlighting its prognostic value. Conclusions Our study developed an explainable multimodal fusion Transformer model for accurate grading and prognosis of FL, with the potential to aid clinical decision-making. [GRAPHICS]","2025-01-30","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","","","","","","","","","","","English","","","","WOS:001411098300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Digital biopsy; Follicular lymphoma; Histologic grade; PET/CT; Prognosis; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9AXJYR4D","journalArticle","2023","Agilandeeswari, L; Chunduri, A","Detection of malicious network activity using the Feature-Tokenizer Transformer model","JOURNAL OF INFORMATION ASSURANCE AND SECURITY","","1554-1010","","",": In the dynamic landscape of cybersecurity, the advancement of machine learning (ML) and deep learning (DL) models, particularly the Transformer model, has become crucial for enhancing Intrusion Detection Systems (IDS). Traditional signature -based IDS are increasingly insufficient due to the evolving nature of cyber threats. The world of deep learning converging to the transformer model due to its con -text recognition features and multi -modality. This paper explores the application of the Feature Tokenizer Transformer (FTTransformer) in cybersecurity for distinguishing malicious from benign network packets. The FT -Transformer is a variant of the Transformer model tailored for tabular data. Employing the CIC-IDS 2017 dataset, our study showcases FT -Transformer's remarkable accuracy exceeding 97%, highlighting its potential to outperform traditional IDS solutions. The dataset was normalized using Min -Max normalization and useful features were extracted using Random Forest classifier. Only 24 out of the initial 79 columns were selected due to the threshold value being 0.015. This reduces the computational complexity and reduces the noise in the dataset resulting in an increase of accuracy. We also compared the FT -Transformer with the Tab -Transformer and the tradition -al Transformer model showcasing FTtransformer's impressive performance in a data set with only numerical features. The model's self -attention mechanism enables deep contextual analysis, suggesting its suitability as a versatile and comprehensive IDS capable of safeguarding diverse endpoints. Our findings suggest a shift towards AI -driven IDS that offer superior precision, scalability, and adaptability, underscoring the FT -Transformer's role in preemptive threat detection and anomaly identification in an ever-changing threat landscape.","2023","2025-02-26 20:37:01","2025-02-26 20:37:01","","192-202","","6","18","","","","","","","","","","English","","","","WOS:001239898600003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Cybersecurity; Deep Learning; FT-Transformer; Intrusion Detection; INTRUSION-DETECTION; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XMKLG9AI","journalArticle","2024","Xing, F; Gao, YL; Kang, LP; Zhang, MM; Qin, CY","KAN-Transformer Model for UltraShort-Term Wind Power Prediction Based on EWMA Data Processing","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14219630","","When using the Transformer model for wind power prediction, the presence of noise in wind power data and the model's final layer relying solely on a simple linear output reduces the model's ability to capture nonlinear relationships, leading to a decrease in prediction accuracy. To address these issues, this paper proposes an ultrashort-term wind power prediction model based on exponential weighted moving average (EWMA) data processing and Kolmogorov-Arnold Network (KAN)-Transformer. First, multiple variable features are smoothed using EWMA, which suppresses noise while preserving the original data trends. Then, the EWMA-processed data is input into the Encoder and Decoder modules of the Transformer model to extract features. The output from the Decoder layer is then passed through the KAN layer, built using a cubic B-spline function, to enhance the model's ability to capture nonlinear relationships, thereby improving the prediction accuracy of the Transformer model for wind power. Finally, experimental analysis is conducted, and it shows that the proposed model achieves the highest prediction accuracy, with a mean absolute error of 4.38 MW, a root mean squared error of 7.37 MW, and a coefficient of determination of 98.73%.","2024-11","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","21","14","","","","","","","","","","English","","","","WOS:001351029900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","EWMA; KAN; noise; nonlinear relationship; transformer; wind power prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KQGXPL26","journalArticle","2024","Saha, DK; Hossain, T; Safran, M; Alfarhood, S; Mridha, MF; Che, DR","Segmentation for mammography classification utilizing deep convolutional neural network","BMC MEDICAL IMAGING","","1471-2342","10.1186/s12880-024-01510-2","","BackgroundMammography for the diagnosis of early breast cancer (BC) relies heavily on the identification of breast masses. However, in the early stages, it might be challenging to ascertain whether a breast mass is benign or malignant. Consequently, many deep learning (DL)-based computer-aided diagnosis (CAD) approaches for BC classification have been developed.MethodsRecently, the transformer model has emerged as a method for overcoming the constraints of convolutional neural networks (CNN). Thus, our primary goal was to determine how well an improved transformer model could distinguish between benign and malignant breast tissues. In this instance, we drew on the Mendeley data repository's INbreast dataset, which includes benign and malignant breast types. Additionally, the segmentation anything model (SAM) method was used to generate the optimized cutoff for region of interest (ROI) extraction from all mammograms. We implemented a successful architecture modification at the bottom layer of a pyramid transformer (PTr) to identify BC from mammography images.ResultsThe proposed PTr model using a transfer learning (TL) approach with a segmentation technique achieved the best accuracy of 99.96% for binary classifications with an area under the curve (AUC) score of 99.98%, respectively. We also compared the performance of the proposed model with other transformer model vision transformers (ViT) and DL models, MobileNetV3 and EfficientNetB7, respectively.ConclusionsIn this study, a modified transformer model is proposed for BC prediction and mammography image classification using segmentation approaches. Data segmentation techniques accurately identify the regions affected by BC. Finally, the proposed transformer model accurately classified benign and malignant breast tissues, which is vital for radiologists to guide future treatment.","2024-12-18","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","1","24","","","","","","","","","","English","","","","WOS:001381000800003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Breast cancer; CANCER; Classification; Mammography; SAM; Segmentation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y6KFIVQL","journalArticle","2024","Guan, H; Xu, H; Cai, L","Requirement Dependency Extraction Based on Improved Stacking Ensemble Machine Learning","MATHEMATICS","","2227-7390","10.3390/math12091272","","To address the cost and efficiency issues of manually analysing requirement dependency in requirements engineering, a requirement dependency extraction method based on part-of-speech features and an improved stacking ensemble learning model (P-Stacking) is proposed. Firstly, to overcome the problem of singularity in the feature extraction process, this paper integrates part-of-speech features, TF-IDF features, and Word2Vec features during the feature selection stage. The particle swarm optimization algorithm is used to allocate weights to part-of-speech tags, which enhances the significance of crucial information in requirement texts. Secondly, to overcome the performance limitations of standalone machine learning models, an improved stacking model is proposed. The Low Correlation Algorithm and Grid Search Algorithms are utilized in P-stacking to automatically select the optimal combination of the base models, which reduces manual intervention and improves prediction performance. The experimental results show that compared with the method based on TF-IDF features, the highest F1 scores of a standalone machine learning model in the three datasets were improved by 3.89%, 10.68%, and 21.4%, respectively, after integrating part-of-speech features and Word2Vec features. Compared with the method based on a standalone machine learning model, the improved stacking ensemble machine learning model improved F1 scores by 2.29%, 5.18%, and 7.47% in the testing and evaluation of three datasets, respectively.","2024-05","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","9","12","","","","","","","","","","English","","","","WOS:001220106200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","ensemble learning; grid search algorithm; low correlation algorithm; machine learning; part-of-speech features; particle swarm optimization; requirement dependency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZXKS6L5C","journalArticle","2024","Jia, GM","Heading Towards Robust Solutions: GAN-Transformer Model Ensuring Secure Sharing of Medical Data","JOURNAL OF ORGANIZATIONAL AND END USER COMPUTING","","1546-2234","10.4018/JOEUC.354413","","With the rapid development of information technology in the field of medicine, the acquisition and sharing of medical data show a significant growth trend. However, medical data involves sensitive information such as patients' clinical records, diagnostic results, and medical images, making data security and reasonable sharing a pressing challenge. Despite some progress in research on medical data sharing, the complexity and diversity of the issues persist. Various stakeholders in medical data, including medical institutions, researchers, and patients, have different expectations for data privacy protection, adding to the complexity of the challenge. Against this background, this paper focuses on the application of anomaly detection technology and proposes the GAN-Transformer model. This model cleverly combines Generative Adversarial Networks (GAN) with Transformer networks, creating a powerful and balanced framework for anomaly detection.","2024","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","1","36","","","","","","","","","","English","","","","WOS:001381886800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Anomaly Detection Technology; Complex Associations in Medical Data; Deep Learning; GAN-Transformer Model; Medical Data Sharing; Privacy Protection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T2NVM29T","journalArticle","2021","Klimovich-Gray, A; Barrena, A; Agirre, E; Molinaro, N","One Way or Another: Cortical Language Areas Flexibly Adapt Processing Strategies to Perceptual And Contextual Properties of Speech","CEREBRAL CORTEX","","1047-3211","10.1093/cercor/bhab071","","Cortical circuits rely on the temporal regularities of speech to optimize signal parsing for sound-to-meaning mapping. Bottom-up speech analysis is accelerated by top-down predictions about upcoming words. In everyday communications, however, listeners are regularly presented with challenging input-fluctuations of speech rate or semantic content. In this study, we asked how reducing speech temporal regularity affects its processing-parsing, phonological analysis, and ability to generate context-based predictions. To ensure that spoken sentences were natural and approximated semantic constraints of spontaneous speech we built a neural network to select stimuli from large corpora. We analyzed brain activity recorded with magnetoencephalography during sentence listening using evoked responses, speech-to-brain synchronization and representational similarity analysis. For normal speech theta band (6.5-8 Hz) speech-to-brain synchronization was increased and the left fronto-temporal areas generated stronger contextual predictions. The reverse was true for temporally irregular speech-weaker theta synchronization and reduced top-down effects. Interestingly, delta-band (0.5 Hz) speech tracking was greater when contextual/semantic predictions were lower or if speech was temporally jittered. We conclude that speech temporal regularity is relevant for (theta) syllabic tracking and robust semantic predictions while the joint support of temporal and contextual predictability reduces word and phrase-level cortical tracking (delta).","2021-09","2025-02-26 20:37:01","2025-02-26 20:37:01","","4092-4103","","9","31","","","","","","","","","","English","","","","WOS:000741349100009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","coherence; COMPREHENSION; ENTRAINMENT; INFORMATION; MEG; NEURAL ACTIVITY; neural network; phonological processing; PREDICTION; representational similarity analysis; semantic predictions; SPECIALIZATION; THETA OSCILLATIONS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z2GVD8W9","journalArticle","2024","Zeulner, T; Hagerer, GJ; Mueller, M; Vazquez, I; Gloor, PA","Predicting Individual Well-Being in Teamwork Contexts Based on Speech Features","INFORMATION","","2078-2489","10.3390/info15040217","","Current methods for assessing individual well-being in team collaboration at the workplace often rely on manually collected surveys. This limits continuous real-world data collection and proactive measures to improve team member workplace satisfaction. We propose a method to automatically derive social signals related to individual well-being in team collaboration from raw audio and video data collected in teamwork contexts. The goal was to develop computational methods and measurements to facilitate the mirroring of individuals' well-being to themselves. We focus on how speech behavior is perceived by team members to improve their well-being. Our main contribution is the assembly of an integrated toolchain to perform multi-modal extraction of robust speech features in noisy field settings and to explore which features are predictors of self-reported satisfaction scores. We applied the toolchain to a case study, where we collected videos of 20 teams with 56 participants collaborating over a four-day period in a team project in an educational environment. Our audiovisual speaker diarization extracted individual speech features from a noisy environment. As the dependent variable, team members filled out a daily PERMA (positive emotion, engagement, relationships, meaning, and accomplishment) survey. These well-being scores were predicted using speech features extracted from the videos using machine learning. The results suggest that the proposed toolchain was able to automatically predict individual well-being in teams, leading to better teamwork and happier team members.","2024-04","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","4","15","","","","","","","","","","English","","","","WOS:001221381700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;80</p>","","","affective computing; explainable AI; multi-modal speaker diarization; PERSONALITY; social signal processing; team collaboration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QFHX5WQG","journalArticle","2021","Amjad, A; Khan, L; Chang, HT","Semi-Natural and Spontaneous Speech Recognition Using Deep Neural Networks with Hybrid Features Unification","PROCESSES","","2227-9717","10.3390/pr9122286","","Recently, identifying speech emotions in a spontaneous database has been a complex and demanding study area. This research presents an entirely new approach for recognizing semi-natural and spontaneous speech emotions with multiple feature fusion and deep neural networks (DNN). A proposed framework extracts the most discriminative features from hybrid acoustic feature sets. However, these feature sets may contain duplicate and irrelevant information, leading to inadequate emotional identification. Therefore, an support vector machine (SVM) algorithm is utilized to identify the most discriminative audio feature map after obtaining the relevant features learned by the fusion approach. We investigated our approach utilizing the eNTERFACE05 and BAUM-1s benchmark databases and observed a significant identification accuracy of 76% for a speaker-independent experiment with SVM and 59% accuracy with, respectively. Furthermore, experiments on the eNTERFACE05 and BAUM-1s dataset indicate that the suggested framework outperformed current state-of-the-art techniques on the semi-natural and spontaneous datasets.","2021-12","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","12","9","","","","","","","","","","English","","","","WOS:000737443100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","EMOTION RECOGNITION; INFORMATION; multiple feature fusion; semi-natural database; SPACE; speech emotion recognition; spontaneous database; support vector machine","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DKHK3AJD","journalArticle","2022","Wang, HY; Zhao, XH; Zhao, YP","Investigation of the Effect of Increased Dimension Levels in Speech Emotion Recognition","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3194039","","In human-machine interaction systems, speech emotion recognition plays a key role. Recognition of categorical emotions has made a great improvement during the last few decades, but emotion recognition of spontaneous speech is still very challenging. This paper aims to investigate emotion recognition from the spontaneous speech in the three-dimensional model. Each dimension represents one primitive, generic attribute of an emotion. Middle levels of each dimension were introduced in this paper. LSTM network was employed to estimate the dimensions due to its effectiveness in speech emotion recognition. In the experiments, we use the IEMOCAP database and the accuracy is 30-35%. The confusion matrixes show that our method leads to a more concentrated dimension location. Furthermore, dimensions were applied in categorical emotion recognition. This indicates that increasing dimension levels could provide a possibility of dimension estimation, and suggests that it is possible to promote speech emotion recognition with dimensions.","2022","2025-02-26 20:37:01","2025-02-26 20:37:01","","78123-78134","","","10","","","","","","","","","","English","","","","WOS:000832930000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","CLASSIFICATION; Databases; Emotion recognition; FEATURES; Licenses; Long short term memory; LSTM network; MODEL; multi-dimensional space; SELECTION; Solid modeling; speech emotion recognition; Speech recognition; Support vector machines","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GP22XAZT","journalArticle","2024","Xiao, L; Ju, CY; Shiau, WL","How patients evaluate physicians in live Video: An empirical study from a dual process perspective","JOURNAL OF BUSINESS RESEARCH","","0148-2963","10.1016/j.jbusres.2023.114471","","Live diagnosis is an application of live streaming in online health communities, through which physicians share knowledge and interact with patients in real time. Live videos enable patients to evaluate physicians comprehensively before a paid consultation. By applying dual-process theory, we examine the relationships between physicians' speech features, demographic characteristics, the information quality of live content in live videos and patients' subscription and consultation behavior. Data from 992 physicians who provided live diagnoses were collected from an online health community. Results show that physicians' speech features and live content quality are significantly associated with patients' subscription behavior, which is further associated with their online consultation behavior. This study provides a new perspective for investigating patients' consultation behavior in the online health community context. It enriches the application of dual-process theory, and offers implications for physicians and online health community administrators in providing better live diagnosis services.","2024-02","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","173","","","","","","","","","","English","","","","WOS:001150185500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","Demographic characteristics; Dual-process theory; IMPACT; INFORMATION; Information quality; Live streaming; ONLINE; Online health communities; QUALITY; REPUTATION; SATISFACTION; SPEECH; Speech features; TRUST; USERS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BDGFMDEV","journalArticle","2023","Nagano, M; Ijima, Y; Hiroya, S","Perceived emotional states mediate willingness to buy from advertising speech","FRONTIERS IN PSYCHOLOGY","","1664-1078","10.3389/fpsyg.2022.1014921","","Previous studies have shown that stimulus-organism-response (SOR) theory can well explain the willingness to buy from stores, products, and advertising-related stimuli. However, few studies have investigated advertising speech stimulus that is not influenced by visual design. We examined whether SOR theory using emotional states can explain the willingness to buy from advertising speech stimulus. Participants listened to speech with modified speech features (mean F0, speech rate, and standard deviation of F0) and rated their willingness to buy the advertised products and their perceived emotional states (pleasure, arousal, dominance). We found that emotional states partially mediate the influence of speech features on the willingness to buy. We further analyzed the moderating effects of listeners' attributes and found that listeners' gender and age group moderated the relationship between speech features, emotional states, and willingness to buy. These results indicate that perceived emotional states mediate the willingness to buy from advertising speech.","2023-01-09","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","13","","","","","","","","","","English","","","","WOS:000916785000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","advertising speech; age difference; BEHAVIOR; emotional states; EXPRESSION; gender difference; MUSIC; PAD model; PERCEPTION; REAL; SEX-DIFFERENCES; SOR theory; STORE ATMOSPHERE; willingness to buy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JL2E7L6Q","journalArticle","2023","Bernard, M; Poli, M; Karadayi, J; Dupoux, E","Shennong: A Python toolbox for audio speech features extraction","BEHAVIOR RESEARCH METHODS","","1554-351X","10.3758/s13428-022-02029-6","","We introduce Shennong, a Python toolbox and command-line utility for audio speech features extraction. It implements a wide range of well-established state-of-the-art algorithms: spectro-temporal filters such as Mel-Frequency Cepstral Filterbank or Predictive Linear Filters, pre-trained neural networks, pitch estimators, speaker normalization methods, and post-processing algorithms. Shennong is an open source, reliable and extensible framework built on top of the popular Kaldi speech processing library. The Python implementation makes it easy to use by non-technical users and integrates with third-party speech modeling and machine learning tools from the Python ecosystem. This paper describes the Shennong software architecture, its core components, and implemented algorithms. Then, three applications illustrate its use. We first present a benchmark of speech features extraction algorithms available in Shennong on a phone discrimination task. We then analyze the performances of a speaker normalization model as a function of the speech duration used for training. We finally compare pitch estimation algorithms on speech under various noise conditions.","2023-12","2025-02-26 20:37:01","2025-02-26 20:37:01","","4489-4501","","8","55","","","","","","","","","","English","","","","WOS:000930778900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Features extraction; Pitch estimation; Python; Software; Speech processing; SPOKEN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KQQC5A5Q","journalArticle","2024","Ma, YK; Zhang, C; Chen, Q; Wang, W; Ma, B","Tuning Large Language Model for Speech Recognition With Mixed-Scale Re-Tokenization","IEEE SIGNAL PROCESSING LETTERS","","1070-9908","10.1109/LSP.2024.3419719","","Large Language Models (LLMs) have proven successful across a spectrum of speech-related tasks, such as speech recognition, text-to-speech, and spoken language understanding. Recently, the use of discretized speech features has gained attention as an efficient and compatible alternative to continuous features for LLMs. This is mainly due to their reduced storage requirements and better alignment of these features with LLM's input space. However, the typical practice of freezing the speech encoder during training poses challenges in bridging the modality gap between speech and text. To address this, we propose to use a mixed-scale re-tokenization layer, integrating multiple granularities in discretized speech features directly within the LLM's input module. Our experimental results demonstrated that the proposed method can effectively enhance the performance of ASR in the setting of continuous learning of an LLM, highlighting the importance of a meticulously designed input module for the integration of discretized speech features with an LLM.","2024","2025-02-26 20:37:01","2025-02-26 20:37:01","","1740-1744","","","31","","","","","","","","","","English","","","","WOS:001263367500004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Acoustics; Adaptation models; Automatic speech recognition; discrete speech unit; re-tokenization; Speech processing; Speech recognition; Task analysis; Tokenization; Training","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4R7Q9X3M","journalArticle","2025","Guo, JW; Zhang, S; Amiri, N; Yu, LY; Wang, Y","An adversarial transformer for anomalous lamb wave pattern detection","NEURAL NETWORKS","","0893-6080","10.1016/j.neunet.2025.107153","","Lamb waves are widely used for defect detection in structural health monitoring, and various methods are developed for Lamb wave data analysis. This paper presents an unsupervised Adversarial Transformer model for anomalous Lamb wave pattern detection by analyzing the spatiotemporal images generated by a hybrid PZTscanning laser Doppler vibrometer (SLDV). The model includes the global attention and the local attention mechanisms, and both are trained adversarially. Given the different natures between the normal and anomalous wave patterns, global attention allows accurate reconstruction of normal wave data but is less capable of reproducing anomalous data and, hence, can be used for anomalous wave pattern detection. Local attention, however, serves as a sparring partner in the proposed adversarial training process to boost the quality of global attention. In addition, a new segment replacement strategy is also proposed to make global attention consistently extract textural contents found in normal data, which, however, are noticeably different from anomalies, leading to superior model performance. Our Adversarial Transformer model is also compared with several benchmark models and demonstrates an overall accuracy of 97.1 % for anomalous wave pattern detection. It is also confirmed that global attention and local attention in adversarial training are responsible for the superior performance of our model over the benchmark models (including the native Transformer model).","2025-05","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","185","","","","","","","","","","English","","","","WOS:001414322000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Adversarial learning; Anomaly detection; Computer vision; Deep learning; Time-series data analysis; Transformer model; Unsupervised learning; WAFER ACTIVE SENSORS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JSQBADVY","journalArticle","2025","Zhou, YL; Fu, HY; Zhou, MZ; Zhao, YY; Chen, JH","High-accuracy slope stability analysis using data-driven and attention-based deep learning model","EARTH SCIENCE INFORMATICS","","1865-0473","10.1007/s12145-024-01600-3","","Because of the abrupt occurrence and severe consequences of slope disasters, the analysis of slope stability has been a focal point in the field of slope disaster prevention. Traditional methods require considerable investments and fail to effectively predict the development trends of slope stability. However, the emergence of data-driven approaches based on deep learning has forged a novel avenue. Recently, a transformer model is proposed, which has an attention module to learn the high dimensionality correlation between the properties and the stability of slopes. In this study, the transformer model is used to predict the slope safety factor and evaluate the slope stability, and a dataset consisting of 72,000 slope samples is created based on the computer-generated method. The superior predictive capabilities of the transformer model are demonstrated in comparison to LSTM and Attention-LSTM models. Subsequently, the transformer-based multi-classification and regression models are discussed. The regression model outperformed in predicting slope safety factor, reaching an impressive accuracy of 99.983%. The results indicate that the deep learning approach based on the transformer model has shown great potential and advantages for slope stability analysis. Its high accuracy and short computation time will contribute to rapid on-site decision-making in geotechnical engineering applications.","2025-01","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","1","18","","","","","","","","","","English","","","","WOS:001374831100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;81</p>","","","Attention module; Deep learning; LIMIT EQUILIBRIUM; NETWORKS; PREDICTION; REGRESSION; SAFETY; Slope disaster; Slope safety factor; Slope stability analysis; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W9ZSD3FH","journalArticle","2022","Jia, M; Li, JL; Hu, TY; Jiang, YZ; Luo, J","Feature Normalization Reweighting Regression Network for Sugar Content Measurement of Grapes","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app12157474","","The measurement of grape sugar content is an important index for classifying grapes based on their quality. Owing to the correlation between grape sugar content and appearance, non-destructive measurements are possible using computer vision and deep learning. This study investigates the quality classification of the Red Globe grape. The number of collected grapes in the range of the 15 similar to 16% measure is three times more than in the range of 18% measure. This study presents a framework named feature normalization reweighting regression (FNRR) to address this imbalanced distribution of sugar content of the grape datasets. The experimental results show that the FNRR framework can measure the sugar content of a whole bunch of grapes with high accuracy using typical convolution neural networks and a visual transformer model. Specifically, the visual transformer model achieved the best accuracy with a balanced loss function, with the coefficient of determination R = 0.9599 and the root mean squared error RMSE = 0.3841%. The results show that the effect of the visual transformer model is better than that of the convolutional neural network. The research findings also indicate that the visual transformer model based on the proposed framework can accurately predict the sugar content of grapes, non-destructive evaluation of grape quality, and could provide reference values for grape harvesting.","2022-08","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","15","12","","","","","","","","","","English","","","","WOS:000839057200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","convolution neural network; feature normalization reweighting regression; grape sugar content; regression; visual transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XGSFVJNU","journalArticle","2024","Shi, JW; Wang, SQ; Qu, PF; Shao, JL","Time series prediction model using LSTM-Transformer neural network for mine water inflow","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-69418-z","","Mine flooding accidents have occurred frequently in recent years, and the predicting of mine water inflow is one of the most crucial flood warning indicators. Further, the mine water inflow is characterized by non-linearity and instability, making it difficult to predict. Accordingly, we propose a time series prediction model based on the fusion of the Transformer algorithm, which relies on self-attention, and the LSTM algorithm, which captures long-term dependencies. In this paper, Baotailong mine water inflow in Heilongjiang Province is used as sample data, and the sample data is divided into different ratios of the training set and test set in order to obtain optimal prediction results. In this study, we demonstrate that the LSTM-Transformer model exhibits the highest training accuracy when the ratio is 7:3. To improve the efficiency of search, the combination of random search and Bayesian optimization is used to determine the network model parameters and regularization parameters. Finally, in order to verify the accuracy of the LSTM-Transformer model, the LSTM-Transformer model is compared with LSTM, CNN, Transformer and CNN-LSTM models. The results prove that LSTM-Transformer has the highest prediction accuracy, and all the indicators of its model are well improved.","2024-08-07","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","1","14","","","","","","","","","","English","","","","WOS:001286763200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","DEFECTS; Long short-term memory; LSTM-Transformer model; Mine water inflow; Self-attention mechanism; Time series prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T9D4A2YS","journalArticle","2022","Ogawa, M; Oyama, G; Morito, K; Kobayashi, M; Yamada, Y; Shinkawa, K; Kamo, H; Hatano, T; Hattori, N","Can AI make people happy? The effect of AI-based chatbot on smile and speech in Parkinson's disease","PARKINSONISM & RELATED DISORDERS","","1353-8020","10.1016/j.parkreldis.2022.04.018","","Introduction: Approaches for objectively measuring facial expressions and speech may enhance clinical and research evaluation in telemedicine, which is widely employed for Parkinson's disease (PD). This study aimed to assess the feasibility and efficacy of using an artificial intelligence-based chatbot to improve smile and speech in PD. Further, we explored the potential predictive value of objective face and speech parameters for motor symptoms, cognition, and mood. Methods: In this open-label randomized study, we collected a series of face and conversational speech samples from 20 participants with PD in weekly teleconsultation sessions for 5 months. We investigated the effect of daily chatbot conversations on smile and speech features, then we investigated whether smile and speech features could predict motor, cognitive, and mood status. Results: A repeated-measures analysis of variance revealed that the chatbot conversations had a significant interaction effect on the mean and standard deviation of the smile index during smile sections (both P = .02), maximum duration of the initial rise of the smile index (P = .04), and frequency of filler words (P = .04), but no significant interaction effects were observed for clinical measurements including motor, cognition, depression, and quality of life. Explorative analysis using statistical and machine-learning models revealed that the smile indices and several speech features were associated with motor symptoms, cognition, and mood in PD. Conclusion: An artificial intelligence-based chatbot may positively affect smile and speech in PD. Smile and speech features may capture the motor, cognitive, and mental status of patients with PD.","2022-06","2025-02-26 20:37:01","2025-02-26 20:37:01","","43-46","","","99","","","","","","","","","","English","","","","WOS:000808090200007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;16<br/>Cited Reference Count:&nbsp;&nbsp;11</p>","","","Facial expression; Parkinson's disease; Speech; Telemedicine","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QH8AP7U9","journalArticle","2024","Lu, JZ; Jiang, W; Xu, YH; Chen, Z; Ni, KJ","Measurement of aero-engine feature-hierarchy fusion degradation trend based on parameter-adaptive VMD method and improved transformer model","MEASUREMENT SCIENCE AND TECHNOLOGY","","0957-0233","10.1088/1361-6501/ad3b2e","","The accumulation of operational time in aero-engines leads to irreversible mechanical wear and tear, necessitating accurate measurement of the health evolution trend for effective predictive maintenance, thus reducing the risk of accidents and ensuring personnel safety. In this paper, a parameter-adaptive variational mode decomposition (VMD) method and improved transformer model are proposed to forecast the degradation trend of aero-engine feature hierarchy fusion. Firstly, in order to quantitatively evaluate the engine health evolution process, the health state aggregate indicator (HSAI) is innovatively constructed by employing the deep blend auto-encoder and self-organizing map network, which facilitate the feature-hierarchy fusion of multi-source sensory data. Secondly, for the significant characteristics with nonlinearity and stochastic fluctuation of the HSAI sequence, the multiscale frequency features are extracted by the parameter-adaptive VMD method with the improved gray wolf optimizer, which analyzes the inherent degradation law. Finally, considering the problem of parameter sharing in the transformer model, a simplified mixture of experts routing algorithm is introduced to implement the switch transformer model to further measure the future aero-engine health trends. Extensive experiments on the multi-source dataset of aero-engine confirm that the proposed method accomplishes the more superior performance for health evolution measurement compared with other available methods.","2024-07-01","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","7","35","","","","","","","","","","English","","","","WOS:001201274100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","auto-encoder; degradation trend measurements; mixture of experts; transformer; VMD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MH7TMJTY","journalArticle","2021","Yamada, Y; Shinkawa, K; Kobayashi, M; Takagi, H; Nemoto, M; Nemoto, K; Arai, T","Using Speech Data From Interactions With a Voice Assistant to Predict the Risk of Future Accidents for Older Drivers: Prospective Cohort Study","JOURNAL OF MEDICAL INTERNET RESEARCH","","1438-8871","10.2196/27667","","Background: With the rapid growth of the older adult population worldwide, car accidents involving this population group have become an increasingly serious problem. Cognitive impairment, which is assessed using neuropsychological tests, has been reported as a risk factor for being involved in car accidents; however, it remains unclear whether this risk can be predicted using daily behavior data. Objective: The objective of this study was to investigate whether speech data that can be collected in everyday life can be used to predict the risk of an older driver being involved in a car accident. Methods: At baseline, we collected (1) speech data during interactions with a voice assistant and (2) cognitive assessment data-neuropsychological tests (Mini-Mental State Examination, revised Wechsler immediate and delayed logical memory, Frontal Assessment Battery, trail making test-parts A and B, and Clock Drawing Test), Geriatric Depression Scale, magnetic resonance imaging, and demographics (age, sex, education)-from older adults. Approximately one-and-a-half years later, we followed up to collect information about their driving experiences (with respect to car accidents) using a questionnaire. We investigated the association between speech data and future accident risk using statistical analysis and machine learning models. Results: We found that older drivers (n=60) with accident or near-accident experiences had statistically discernible differences in speech features that suggest cognitive impairment such as reduced speech rate (P=.048) and increased response time (P=.040). Moreover, the model that used speech features could predict future accident or near-accident experiences with 81.7% accuracy, which was 6.7% higher than that using cognitive assessment data, and could achieve up to 88.3% accuracy when the model used both types of data. Conclusions: Our study provides the first empirical results that suggest analysis of speech data recorded during interactions with voice assistants could help predict future accident risk for older drivers by capturing subtle impairments in cognitive function.","2021-04-08","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","4","23","","","","","","","","","","English","","","","WOS:000639244800004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","accident; AGE; ALZHEIMERS-DISEASE; assistant; cognitive impairment; COGNITIVE IMPAIRMENT; CRASH RISK; older adults; PERFORMANCE; prediction; prevention; RELIABILITY; risk; SAFETY; smart speaker; speech analysis; YOUNGER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8KWRY6DK","journalArticle","2024","Ampazis, N; Sakketou, F","Diversifying Multi-Head Attention in the Transformer Model","MACHINE LEARNING AND KNOWLEDGE EXTRACTION","","2504-4990","10.3390/make6040126","","Recent studies have shown that, due to redundancy, some heads of the Transformer model can be pruned without diminishing the efficiency of the model. In this paper, we propose a constrained optimization algorithm based on Hebbian learning, which trains specific layers in the Transformer architecture in order to enforce diversification between the different heads in the multi-head attention module. The diversification of the heads is achieved through a single-layer feed-forward neural network that is added to the Transformer architecture and is trained with the proposed algorithm. We utilize the algorithm in three different architectural variations of the baseline Transformer model. In addition to the diversification of the heads, the proposed methodology can be used to prune the heads that capture redundant information. Experiments on diverse NLP tasks, including machine translation, text summarization, question answering and large language modeling, show that our proposed approach consistently improves the performance of baseline Transformer models.","2024-12","2025-02-26 20:37:01","2025-02-26 20:37:01","","2618-2638","","4","6","","","","","","","","","","English","","","","WOS:001384635600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","deep learning; multi-head attention; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ECUSDJDB","journalArticle","2024","Tibo, A; He, JZ; Janet, JP; Nittinger, E; Engkvist, O","Exhaustive local chemical space exploration using a transformer model","NATURE COMMUNICATIONS","","2041-1723","10.1038/s41467-024-51672-4","","How many near-neighbors does a molecule have? This fundamental question in chemistry is crucial for molecular optimization problems under the similarity principle assumption. Generative models can sample molecules from a vast chemical space but lack explicit knowledge about molecular similarity. Therefore, these models need guidance from reinforcement learning to sample a relevant similar chemical space. However, they still miss a mechanism to measure the coverage of a specific region of the chemical space. To overcome these limitations, a source-target molecular transformer model, regularized via a similarity kernel function, is proposed. Trained on a largest dataset of >= 200 billion molecular pairs, the model enforces a direct relationship between generating a target molecule and its similarity to a source molecule. Results indicate that the regularization term significantly improves the correlation between generation probability and molecular similarity, enabling exhaustive exploration of molecule near-neighborhoods. Understanding molecular near neighbours is key for molecular optimization. Here, authors propose a transformer model that improves correlation between generation probability and molecular similarity, enhancing exploration of molecular neighbourhoods.","2024-08-25","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","1","15","","","","","","","","","","English","","","","WOS:001298087400009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","DRUG DISCOVERY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3BP297ZQ","journalArticle","2021","Liu, XX; Lu, HY; Nayak, A","A Spam Transformer Model for SMS Spam Detection","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2021.3081479","","In this paper, we aim to explore the possibility of the Transformer model in detecting the spam Short Message Service (SMS) messages by proposing a modified Transformer model that is designed for detecting SMS spam messages. The evaluation of our proposed spam Transformer is performed on SMS Spam Collection v.1 dataset and UtkMl's Twitter Spam Detection Competition dataset, with the benchmark of multiple established machine learning classifiers and state-of-the-art SMS spam detection approaches. In comparison to all other candidates, our experiments on SMS spam detection show that the proposed modified spam Transformer has the optimal results on the accuracy, recall, and F1-Score with the values of 98.92%, 0.9451, and 0.9613, respectively. Besides, the proposed model also achieves good performance on the UtkMl's Twitter dataset, which indicates a promising possibility of adapting the model to other similar problems.","2021","2025-02-26 20:37:01","2025-02-26 20:37:01","","80253-80263","","","9","","","","","","","","","","English","","","","WOS:000673861500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;23<br/>Total Times Cited:&nbsp;&nbsp;26<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","attention; Computational modeling; deep learning; Deep learning; Feature extraction; Logic gates; Machine learning; Recurrent neural networks; SECURITY MODEL; Semantics; SMS spam detection; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EW2G9SMN","journalArticle","2022","Altiparmak, A","An Analysis of Turkish Interactional Discourse Markers 'SEY', 'YANI', And 'ISTE'","JOURNAL OF PSYCHOLINGUISTIC RESEARCH","","0090-6905","10.1007/s10936-022-09840-4","","This paper examines (1) the developmental aspects of the frequency and a range of functions expressed by Turkish interactional discourse markers sey 'uh', yani 'I mean', and iste 'you know' in child speech (4-8 year-olds), and (2) age and gender-related changes in the frequency and functional uses of these three DMs in the speeches of 84 Turkish speakers from four different age groups (4-8, 18-23, 33-50, and over 50 year-olds). Except for the children, the analyses were conducted in two different corpora, spontaneous and planned speech. As a result, in child speech, a developmental pattern from local to global in the use of the DMs yani 'I mean', and iste 'you know' was observed. Similarly, the frequency of these two DMs increased with aging among the four age groups in spontaneous speech. However, in planned speech, it was the case for the DM iste 'you know' only. Over 50 year-old men used sey 'uh' more frequently in their spontaneous speech compared to women, whereas 33-50 year-old women produced more iste 'you know' in their planned speech than men. The frequencies of sey 'uh', yani 'I mean', and iste 'you know' were lower in the planned speech condition compared to the spontaneous speech condition in general. Core functions of the three Turkish DMs under focus were described by conducting further analyses. These analyses also revealed that although there are some patterns that apply to all or a group of the DMs under focus, different variables interact in complicated ways resulting in differences in the functional uses of sey 'uh', yani 'I mean', and iste 'you know' by males and females among different age groups in two different speech conditions.","2022-08","2025-02-26 20:37:01","2025-02-26 20:37:01","","729-762","","4","51","","","","","","","","","","English","","","","WOS:000769882200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","ACQUISITION; CHILDRENS USE; Frequency of discourse markers; Functional uses of discourse markers; SPEECH; Speech condition; Turkish speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BDTWLWFX","journalArticle","2023","Liu, Y; Yuan, K; Li, T; Li, S","NDT Method for Weld Defects Based on FMPVit Transformer Model","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3283589","","The primary NDT method for welding defects is the image-based detection. Currently, the best performance for image-based detection is based on the transformer model. However, with its high accuracy, it has many limitations, such as large model parameters, large data sample requirements, and expensive computer resources. This model has a weaker ability to capture local features compared with global features. In this study, an improved and optimized welding defect detection and identification framework named Fast Multi-Path Vision transformer (FMPVit) is proposed based on the transformer model. This model uses a multilayer parallel architecture and enhances the local information capture ability of the model through advanced multiscale convolution feature aggregation and the addition of a new local convolution module. Finally, a validation test is carried out using an open dataset of weld seams. The model is proven to exhibit an evident performance improvement over the mainstream model baseline.","2023","2025-02-26 20:37:01","2025-02-26 20:37:01","","61390-61400","","","11","","","","","","","","","","English","","","","WOS:001015279400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","CONVOLUTIONAL NEURAL-NETWORKS; Deep learning; line laser; one-dimensional sequential time series; weld detection classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FTCJL5VM","journalArticle","2023","Leyns, C; Daelman, J; Adriaansen, A; Tomassen, P; Morsomme, D; T'Sjoen, G; D'haeseleer, E","Short-Term Acoustic Effects of Speech Therapy in Transgender Women: A Randomized Controlled Trial","AMERICAN JOURNAL OF SPEECH-LANGUAGE PATHOLOGY","","1058-0360","10.1044/2022_AJSLP-22-00135","","Purpose: This study measured and compared the acoustic short-term effects of pitch elevation training (PET) and articulation-resonance training (ART) and the combination of both programs, in transgender women.Method: A randomized controlled study with cross-over design was used. Thirty transgender women were included and received 14 weeks of speech training. All participants started with 4 weeks of sham training; after which they were randomly assigned to one of two groups: One group continued with PET (5 weeks), followed by ART (5 weeks); the second group received both trainings in opposite order. Participants were recorded 4 times, in between the training blocks: pre, post 1 (after sham), post 2 (after training 1), and post 3 (after train-ing 2). Speech samples included a sustained vowel, continuous speech during reading, and spontaneous speech and were analyzed using Praat software. Fundamental frequency (fo), intensity, voice range profile, vowel formant fre-quencies (F1-2-3-4-5 of /a/-/i/-/u/), formant contrasts, vowel space, and vocal quality (Acoustic Voice Quality Index) were determined.Results and Conclusions: Fundamental frequencies increased after both the PET and ART program, with a higher increase after PET. The combination of both interventions showed a mean increase of the fo of 49 Hz during a sus-tained vowel, 49 Hz during reading, and 29 Hz during spontaneous speech. However, the lower limit (percentile 5) of the fo during spontaneous speech did not change. Higher values were detected for F1-2 of /a/, F3 of /u/, and vowel space after PET and ART separately. F1-2-3 of /a/, F1-3-4 of /u/, vowel space, and formant contrasts increased after the combination of PET and ART; hence, the combination induced more increases in formant frequencies. Intensity and voice quality measurements did not change. No order effect was detected; that is, starting with PET or ART did not change the outcome.","2023-01","2025-02-26 20:37:01","2025-02-26 20:37:01","","145-168","","1","32","","","","","","","","","","English","","","","WOS:000919666000010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","FEMALE; FEMININITY; FORMANT FREQUENCIES; FUNDAMENTAL-FREQUENCY; INDIVIDUALS; LISTENER PERCEPTIONS; SPEAKER GENDER; VOICE THERAPY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K3SZAUC8","journalArticle","2024","Shellikeri, S; Cho, S; Ash, S; Gonzalez-Recober, C; Mcmillan, CT; Elman, L; Quinn, C; Amado, DA; Baer, M; Irwin, DJ; Massimo, L; Olm, CA; Liberman, MY; Grossman, M; Nevler, N","Digital markers of motor speech impairments in spontaneous speech of patients with ALS-FTD spectrum disorders","AMYOTROPHIC LATERAL SCLEROSIS AND FRONTOTEMPORAL DEGENERATION","","2167-8421","10.1080/21678421.2023.2288106","","Objective: To evaluate automated digital speech measures, derived from spontaneous speech (picture descriptions), in assessing bulbar motor impairments in patients with ALS-FTD spectrum disorders (ALS-FTSD). Methods: Automated vowel algorithms were employed to extract two vowel acoustic measures: vowel space area (VSA), and mean second formant slope (F2 slope). Vowel measures were compared between ALS with and without clinical bulbar symptoms (ALS + bulbar (n = 49, ALSFRS-r bulbar subscore: x<overline> = 9.8 (SD = 1.7)) vs. ALS-nonbulbar (n = 23), behavioral variant frontotemporal dementia (bvFTD, n = 25) without a motor syndrome, and healthy controls (HC, n = 32). Correlations with bulbar motor clinical scales, perceived listener effort, and MRI cortical thickness of the orobuccal primary motor cortex (oral PMC) were examined. We compared vowel measures to speaking rate, a conventional metric for assessing bulbar dysfunction. Results: ALS + bulbar had significantly reduced VSA and F2 slope than ALS-nonbulbar (|d|=0.94 and |d|=1.04, respectively), bvFTD (|d|=0.89 and |d|=1.47), and HC (|d|=0.73 and |d|=0.99). These reductions correlated with worse bulbar clinical scores (VSA: R = 0.33, p = 0.043; F2 slope: R = 0.38, p = 0.011), greater listener effort (VSA: R=-0.43, p = 0.041; F2 slope: p > 0.05), and cortical thinning in oral PMC (F2 slope: beta = 0.0026, p = 0.017). Vowel measures demonstrated greater sensitivity and specificity for bulbar impairment than speaking rate, while showing independence from cognitive and respiratory impairments. Conclusion: Automatic vowel measures are easily derived from a brief spontaneous speech sample, are sensitive to mild-moderate stage of bulbar disease in ALS-FTSD, and may present better sensitivity to bulbar impairment compared to traditional assessments such as speaking rate.","2024-04-02","2025-02-26 20:37:01","2025-02-26 20:37:01","","317-325","","3-4","25","","","","","","","","","","English","","","","WOS:001123500500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","AMYOTROPHIC-LATERAL-SCLEROSIS; biomarker; CRITERIA; digital speech; DISEASE; dysarthria; INTELLIGIBILITY; motor speech; MOVEMENTS; PATTERNS; SCALE; SPEAKERS; VOWEL SPACE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P9W777J8","journalArticle","2024","Xie, Y; Lu, ZJ","Novel deep-learning method based on LSA-Transformer for fault detection and its implementation in penicillin fermentation process","MEASUREMENT","","0263-2241","10.1016/j.measurement.2024.114871","","Transformer models have proved to be excellent in solving long-distance dependency problems for many tasks. However, a large amount of computation is required to achieve a high performance. In addition, this model has certain limitations in its ability to extract local information. In this paper, a local information enhancement and sparse attention mechanism Transformer (LSA-Transformer) model is proposed to address these issues. First, local information between data is captured from deep and multiple scales to achieve feature fusion and enhancement of local information. Second, by the sparse attention mechanism, the longdistance dependency relationship of the data is preserved. Third, the computational complexity of the improved model is reduced from quadratic to linear, while retaining the ability to capture long-distance dependencies. Finally, experiments in the penicillin fermentation process show that the improved Transformer model achieves significant improvements compared to existing methods.","2024-08","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","235","","","","","","","","","","English","","","","WOS:001245172000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Confusion matrix; DIAGNOSIS; Fault detection; Heatmap; LSA-Transformer model; Penicillin fermentation process","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F2JHVED8","journalArticle","2021","Astapov, S; Gusev, A; Volkova, M; Logunov, A; Zaluskaia, V; Kapranova, V; Timofeeva, E; Evseeva, E; Kabarov, V; Matveev, Y","Application of Fusion of Various Spontaneous Speech Analytics Methods for Improving Far-Field Neural-Based Diarization","MATHEMATICS","","2227-7390","10.3390/math9232998","","Recently developed methods in spontaneous speech analytics require the use of speaker separation based on audio data, referred to as diarization. It is applied to widespread use cases, such as meeting transcription based on recordings from distant microphones and the extraction of the target speaker's voice profiles from noisy audio. However, speech recognition and analysis can be hindered by background and point-source noise, overlapping speech, and reverberation, which all affect diarization quality in conjunction with each other. To compensate for the impact of these factors, there are a variety of supportive speech analytics methods, such as quality assessments in terms of SNR and RT60 reverberation time metrics, overlapping speech detection, instant speaker number estimation, etc. The improvements in speaker verification methods have benefits in the area of speaker separation as well. This paper introduces several approaches aimed towards improving diarization system quality. The presented experimental results demonstrate the possibility of refining initial speaker labels from neural-based VAD data by means of fusion with labels from quality estimation models, overlapping speech detectors, and speaker number estimation models, which contain CNN and LSTM modules. Such fusing approaches allow us to significantly decrease DER values compared to standalone VAD methods. Cases of ideal VAD labeling are utilized to show the positive impact of ResNet-101 neural networks on diarization quality in comparison with basic x-vectors and ECAPA-TDNN architectures trained on 8 kHz data. Moreover, this paper highlights the advantage of spectral clustering over other clustering methods applied to diarization. The overall quality of diarization is improved at all stages of the pipeline, and the combination of various speech analytics methods makes a significant contribution to the improvement of diarization quality.","2021-12","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","23","9","","","","","","","","","","English","","","","WOS:000734540400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","artificial neural networks; distant speech processing; model fusion; overlapping speech detection; quality estimation; speaker diarization; SPEAKER DIARIZATION; speaker extractor models; speaker number estimation; spontaneous speech processing; voice activity detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RZW8ZB2F","journalArticle","2022","Li, Q","Machine Translation of English Language Using the Complexity-Reduced Transformer Model","MOBILE INFORMATION SYSTEMS","","1574-017X","10.1155/2022/6603576","","Previous translation models like statistical machine translation (SMT), rule-based machine translation (RBMT), hybrid machine translation (HMT), and neural machine translation (NMT) have reached their performance bottleneck. The new Transformer-based machine translation model has become the favorite choice for English language translation. For instance, Google's BERT translation model organizes the Transformer module into bidirectional encoder representations. It is aware of the users' search intentions as well as the material that the search engine has indexed. It does not need to evaluate previous searches to comprehend what people mean, unlike RankBrain. BERT comprehends words, sentences, and complete information in the same way that we do. It achieves remarkable translation quality improvement over the other state-of-the-art benchmarks. It demonstrates the great potential of the Transformer model. The Transformer-based translation model mainly improves the performance at the cost of growing model sizes and complexity, usually requiring million-scale parameters. It is hard for the traditional computing systems to cope with the growing memory and computation requirements. However, the latest computers can easily run this model without any lag. The biggest challenge of applying the Transformer model is to deploy these models efficiently onto real-time or embedded devices. In this work, we propose a quantization scheme to reduce the parameter and computation complexity. It is of great importance to promote the usage of the Transformer model. Our experiment results show that the original Transformer model in 32 bit floating-point can be quantized to only 8 bits to 12 bits with only negligible translation quality loss. However, due to the perfect transformation of the block part, this quality loss part can easily be managed by the users. Meanwhile, our algorithm achieves 2.6x to 4.0x compression ratio, which is helpful to save the required complexity and energy during the inference phase.","2022-06-07","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","2022","","","","","","","","","","English","","","","WOS:000813927700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;15</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PBGSUAG3","journalArticle","2023","Zhou, Y; Li, YZ; Wang, DJ; Liu, YF","A multi-step ahead global solar radiation prediction method using an attention-based transformer model with an interpretable mechanism","INTERNATIONAL JOURNAL OF HYDROGEN ENERGY","","0360-3199","10.1016/j.ijhydene.2023.01.068","","The conventional multi-step ahead solar radiation prediction method ignores the time -dependence of a future solar radiation time series. Therefore, according to sequence-to -sequence (seq2seq) model theory, this paper proposes the seq2seq long-and short-term memory model (seq2seq-LSTM), the seq2seq-LSTM model with an attention mechanism (seq2seq-at-LSTM), and a transformer model, which consists only of the attention mech-anism. The hourly global solar radiation data between 2016 and 2018 from Shaanxi, China, is used to train and validate the models. The results show that the introduction of the attention mechanism can effectively improve the prediction accuracy of the seq2seq-LSTM model. However, the model is still not very good at capturing the long-distance depen-dence of the solar radiation time series due to the inherent properties of LSTM. In com-parison, the transformer model, which is based entirely on the attention mechanism, performs much better at capturing the long-distance dependence of the solar radiation time series. Furthermore, as the number of time-steps increases, the performance of the solar radiation prediction decreases relatively smoothly and slowly. The obtained average coefficient of determination, root mean square error (RMSE), relative RMSE, and mean bias error are 0.9788, 72.91 W/m2, 25.25%, and 38.35 W/m2, respectively. In addition, the average skill score of the transformer model is around 44.9%, which is 20.54% higher than that of the seq2seq-at-LSTM model and about 40.84% higher than that of the seq2seq-LSTM model. Besides, the use of the attention mechanism can explain the improved prediction compared to other models. This model developed in this study could also be used for","2023-05-08","2025-02-26 20:37:01","2025-02-26 20:37:01","","15317-15330","","40","48","","","","","","","","","","English","","","","WOS:000984565000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;16<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","FORECASTS; Global solar radiation; MACHINE; Model predictions; Multi-step ahead; NEURAL-NETWORK; PERSISTENCE; Sequence-to-sequence model; STRATEGIES; Transformer model; ZONES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VABI7XCB","journalArticle","2021","Cho, S; Nevler, N; Parjane, N; Cieri, C; Liberman, M; Grossman, M; Cousins, KAQ","Automated Analysis of Digitized Letter Fluency Data","FRONTIERS IN PSYCHOLOGY","","1664-1078","10.3389/fpsyg.2021.654214","","Y The letter-guided naming fluency task is a measure of an individual's executive function and working memory. This study employed a novel, automated, quantifiable, and reproducible method to investigate how language characteristics of words produced during a fluency task are related to fluency performance, inter-word response time (RT), and over task duration using digitized F-letter-guided fluency recordings produced by 76 young healthy participants. Our automated algorithm counted the number of correct responses from the transcripts of the F-letter fluency data, and individual words were rated for concreteness, ambiguity, frequency, familiarity, and age of acquisition (AoA). Using a forced aligner, the transcripts were automatically aligned with the corresponding audio recordings. We measured inter-word RT, word duration, and word start time from the forced alignments. Articulation rate was also computed. Phonetic and semantic distances between two consecutive F-letter words were measured. We found that total F-letter score was significantly correlated with the mean values of word frequency, familiarity, AoA, word duration, phonetic similarity, and articulation rate; total score was also correlated with an individual's standard deviation of AoA, familiarity, and phonetic similarity. RT was negatively correlated with frequency and ambiguity of F-letter words and was positively correlated with AoA, number of phonemes, and phonetic and semantic distances. Lastly, the frequency, ambiguity, AoA, number of phonemes, and semantic distance of words produced significantly changed over time during the task. The method employed in this paper demonstrates the successful implementation of our automated language processing pipelines in a standardized neuropsychological task. This novel approach captures subtle and rich language characteristics during test performance that enhance informativeness and cannot be extracted manually without massive effort. This work will serve as the reference for letter-guided category fluency production similarly acquired in neurodegenerative patients.","2021-07-29","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","12","","","","","","","","","","English","","","","WOS:000684981900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","ABILITY; automated speech analysis; DEFICITS; executive function; MEMORY; neuropsychological test; PERFORMANCE; phonetic similarity; RETRIEVAL; SEMANTIC FLUENCY; TASK; TIME; verbal fluency; VERBAL FLUENCY; verbal retrieval","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YFS3374E","journalArticle","2024","Cao, WY; Qi, WW; Lu, PQ","Air Quality Prediction Based on Time Series Decomposition and Convolutional Sparse Self-Attention Mechanism Transformer Model","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3484579","","This study introduces an innovative air quality prediction model, TD-CS-Transformer, which fuses time series decomposition and convolutional sparse self-attention Transformer model. It solves inefficient and limited long-distance dependency capture of traditional models in long sequence data. The model simplifies the structure and reduces the amount of computation by decomposing the series into components. Convolutional sparse self-attention enhances long-distance dependent capture and improves accuracy. Experiments on public datasets show that the TD-CS-Transformer outperforms existing methods in PM2.5 and PM10 concentration prediction and has the characteristics of high accuracy, low error, fast training, and minimal memory footprint, showing strong practicality and scalability. In the study of air quality prediction based on time series decomposition and convolutional sparse self-attention mechanism Transformer model, we use this model to conduct an in-depth analysis of air quality data containing more than 180,000 records in the last 5 years. The time series decomposition technique decomposes the complex time series data into trend, season, period and irregular components, which simplifies the data pattern. Subsequently, the Transformer model with convolutional sparse self-attention mechanism is used for processing, which significantly improves the model's ability to capture long-distance dependencies and reduces the computational complexity through sparse connections, enabling the model to maintain high-accuracy predictions.","2024","2025-02-26 20:37:01","2025-02-26 20:37:01","","155340-155350","","","12","","","","","","","","","","English","","","","WOS:001346095900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Accuracy; air quality; Atmospheric modeling; attention mechanisms; Computational modeling; convolutional sparsity; Data models; Feature extraction; FUSION; Mathematical models; Predictive models; Time series analysis; Time series decomposition; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J8HKNKWT","journalArticle","2024","Sun, YZ; Pang, SC; Zhang, JH; Zhang, YA","Porosity prediction through well logging data: A combined approach of convolutional neural network and transformer model (CNN-transformer)","PHYSICS OF FLUIDS","","1070-6631","10.1063/5.0190078","","Porosity, as a key parameter to describe the properties of rock reservoirs, is essential for evaluating the permeability and fluid migration performance of underground rocks. In order to overcome the limitations of traditional logging porosity interpretation methods in the face of geological complexity and nonlinear relationships, this study introduces a CNN (convolutional neural network)-transformer model, which aims to improve the accuracy and generalization ability of logging porosity prediction. CNNs have excellent spatial feature capture capabilities. The convolution operation of CNNs can effectively learn the mapping relationship of local features, so as to better capture the local correlation in the well log. Transformer models are able to effectively capture complex sequence relationships between different depths or time points. This enables the model to better integrate information from different depths or times, and improve the porosity prediction accuracy. We trained the model on the well log dataset to ensure that it has good generalization ability. In addition, we comprehensively compare the performance of the CNN-transformer model with other traditional machine learning models to verify its superiority in logging porosity prediction. Through the analysis of experimental results, the CNN-transformer model shows good superiority in the task of logging porosity prediction. The introduction of this model will bring a new perspective to the development of logging technology and provide a more efficient and accurate tool for the field of geoscience.","2024-02","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","2","36","","","","","","","","","","English","","","","WOS:001159051800007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","BASIN; GENETIC ALGORITHM; RESERVOIRS; SANDSTONE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3BRNUG8V","journalArticle","2023","Ahmed, HOA; Nandi, AK","Convolutional-Transformer Model with Long-Range Temporal Dependencies for Bearing Fault Diagnosis Using Vibration Signals","MACHINES","","2075-1702","10.3390/machines11070746","","Fault diagnosis of bearings in rotating machinery is a critical task. Vibration signals are a valuable source of information, but they can be complex and noisy. A transformer model can capture distant relationships, which makes it a promising solution for fault diagnosis. However, its application in this field has been limited. This study aims to contribute to this growing area of research by proposing a novel deep-learning architecture that combines the strengths of CNNs and transformer models for effective fault diagnosis in rotating machinery. Thus, it captures both local and long-range temporal dependencies in the vibration signals. The architecture starts with CNN-based feature extraction, followed by temporal relationship modelling using the transformer. The transformed features are used for classification. Experimental evaluations are conducted on two datasets with six and ten health conditions. In both case studies, the proposed model achieves high accuracy, precision, recall, F1-score, and specificity all above 99% using different training dataset sizes. The results demonstrate the effectiveness of the proposed method in diagnosing bearing faults. The convolutional-transformer model proves to be a promising approach for bearing fault diagnosis. The method shows great potential for improving the accuracy and efficiency of fault diagnosis in rotating machinery.","2023-07","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","7","11","","","","","","","","","","English","","","","WOS:001035853400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","attention mechanism; bearing fault diagnosis; CLASSIFICATION; deep-learning architecture; FEATURES; LOCAL MEAN DECOMPOSITION; long-range temporal dependencies; MAINTENANCE; NEURAL-NETWORK; ROTATING MACHINERY; SELECTION; temporal relationships; TIME-FREQUENCY ANALYSIS; transformer model; vibration signals","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FPGCQ2Y6","journalArticle","2025","Yu, L; Zhang, X; Lin, Y; Yu, YY; Wu, JY; Dai, DS","Forecasting Crude Oil Prices: Evidence From WOA-VMD-FE-Transformer Model","COMPUTATIONAL ECONOMICS","","0927-7099","10.1007/s10614-025-10861-z","","The wild fluctuations in crude oil prices in recent years have increased the urgent need for accurate price estimates. A reliable method for crude oil price forecasting is essential to guide production and investment. Therefore, this paper proposes a new crude oil futures price series decomposition and reconstruction prediction model called WOA-VMD-FE-Transformer model. Firstly, the parameters of the variational mode decomposition (VMD) method are optimized by using the Whale optimization algorithm (WOA), and then the optimized WOA-VMD method is used to decompose the crude oil futures price series into multiple sub-sequences. Then, according to the fuzzy entropy (FE) value of the sub-sequence, it is reorganized into three subsequences: low frequency, medium frequency and high frequency. Finally, we trained these three subsequences using the Transformer model and applied them to the test set to make predictions. By adding the forecasts together, we get the final forecast and use multiple metrics to assess the accuracy of the forecast. After experimental verification, WOA-VMD-FE-Transformer model shows high accuracy in predicting crude oil futures prices. The application of the model presented in this study can help decision-makers develop strategies, help investors make informed investment decisions, and also promote the equilibrium between energy supply and demand in the market. Hence, the research holds considerable importance in fostering the sustainable growth of the energy market and related industries.","2025-01-27","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","","","","","","","","","","","English","","","","WOS:001406608300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","ALGORITHM; Crude oil futures forecast; DECOMPOSITION; Fuzzy entropy; MEMORY; MULTISTEP; NEURAL-NETWORK MODEL; PREDICTION; Transformer; Variational modal decomposition; Whale optimization algorithm","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MC5NNZLS","journalArticle","2021","Duan, P; Yang, M; Liu, YL; Zou, BY; Ye, SY; Sima, WX","Low-frequency dual reversible model of the single-phase two-winding transformer considering the gradually quicker saturation process of the core","INTERNATIONAL JOURNAL OF ELECTRICAL POWER & ENERGY SYSTEMS","","0142-0615","10.1016/j.ijepes.2020.106531","","The major nonlinear effects in the transformer core are saturation and hysteresis, in which saturation is the predominant effect for the transients involving saturation of transformers. A detailed representation of the saturation of the core is required. However, the available methods seldom provided experimental methods to represent the transients of the two magnetizing curves of the duality-based transformer model from slight saturation to deep saturation. This paper proposes a method to retrofitting the dual reversible transformer model with the gradually quicker saturation process of the core. Methods are proposed to measure the incremental inductances of the saturated core and using them to compute flux-current data of magnetizing branches of the proposed dual reversible pi model. The entire magnetization curve is obtained by combining the unsaturated region by the available methods with the saturated region determined using the proposed methods. A singlephase two-winding transformer with a rated capacity of 500 VA is used to perform the proposed method to extract the required parameters of the proposed dual reversible transformer model. Inrush current tests are carried out and compared with simulations using ATP-EMTP to validate the model. Results show that the proposed model has better accuracy to simulate the first peak of the inrush current compared with the available model, contributing to the simulation involving low-frequency electromagnetic transients.","2021-02","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","125","","","","","","","","","","English","","","","WOS:000594691900015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","ACCURATE; Dual reversible model; Incremental inductance; Inrush current; PI; Saturation; Transformer model; TRANSIENTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SYYFZZQI","journalArticle","2025","Snyder, Q; Jiang, QT; Tripp, E","Integrating self-attention mechanisms in deep learning: A novel dual-head ensemble transformer with its application to bearing fault diagnosis","SIGNAL PROCESSING","","0165-1684","10.1016/j.sigpro.2024.109683","","In this paper, we propose a novel dual-head ensemble Transformer (DHET) algorithm for the classification of signals with time-frequency features such as bearing vibration signals. The DHET model employs a dual- input time-frequency architecture, integrating a 1D Transformer model and a 2D Vision Transformer model to capture the spatial and time-frequency features. By utilizing data from both the time and time-frequency domains, the proposed algorithm broadens its feature extraction capabilities and enhances the model's capacity for generalization. In our DHET structure, the original Transformer model leverages self-attention mechanisms to consider relationships among signal input segmentations, which makes it effective at capturing long-range dependencies in signal data, while the Vision Transformer model takes 2D images as input and creates the image patches for embedding and each patch is linearly embedded into a flat vector and treated as a 'token,' then the 'tokens' are processed by the Transformer layers to learn global contextual representations, enabling the model to perform signal classification task. This integration notably enhances the performance and capability of the model. Our DHET is especially effective for rolling bearing fault diagnosis. The simulation results show that the proposed DHET has higher classification accuracy for bearing fault diagnosis and outperforms CNN-based methods.","2025-02","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","227","","","","","","","","","","English","","","","WOS:001309086000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;80</p>","","","ALGORITHMS; Bearing fault diagnosis; CLASSIFICATION; CONVOLUTIONAL NEURAL-NETWORK; Deep learning; Dual-head ensemble Transformer; INSTANTANEOUS FREQUENCY; ROTATING MACHINERY; Short-time Fourier transform; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U4AX6K6N","journalArticle","2021","Azadi, H; Akbarzadeh-T, MR; Shoeibi, A; Kobravi, H","Evaluating the effect of Parkinson's disease on jitter and shimmer speech features","ADVANCED BIOMEDICAL RESEARCH","","2277-9175","10.4103/abr.abr_254_21","","Background: Parkinson's disease (PD) is a neurological disorder caused by decreasing dopamine in the brain. Speech is one of the first functions that are disrupted. Accordingly, speech features are a promising indicator in PD diagnosis for telemedicine applications. The purpose of this study is to investigate the impact of Parkinson's disease on a minimal set of Jitter and Shimmer voice indicators and studying the difference between male and female speech features in noisy/noiseless environments. Materials and Methods: Our data includes 47 samples from nursing homes and neurology clinics, with 23 patients and 24 healthy individuals. The optimal feature for each category is studied separately for the men's and women's samples. The focus here is on the phonation in which the vowel/a/is expressed by the participants. The main features, including Jitter and Shimmer perturbations, are extracted. To find an optimal pair under both noisy and noiseless circumstance, we use the Relief feature selection strategy. Results: This research shows that the Jitter feature for men and women with Parkinson's is 21 and 33.4, respectively. While the Shimmer feature is 0.1 and 0.06. In addition, by using these two features alone, we reach a correct diagnosis rate of 79% and 81% for noisy and noiseless states, respectively. Conclusion: The PD effects on the speech features can be accurately identified. Evaluating the extracted features suggests that the absolute value of the selected feature in men with PD is higher than for healthy ones. Whereas, in the case of women, this is the opposite.","2021-01","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","1","10","","","","","","","","","","English","","","","WOS:000741071900010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","ACCURACY; Classification; DIAGNOSIS; dysphonia; Parkinson disease; phonation; speech disorders; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FDBK8KUU","journalArticle","2024","Gao, Y; Cao, BF; Yu, WH; Yi, L; Guo, FQ","Short-Term Wind Speed Prediction for Bridge Site Area Based on Wavelet Denoising OOA-Transformer","MATHEMATICS","","2227-7390","10.3390/math12121910","","Predicting wind speed in advance at bridge sites is essential for ensuring bridge construction safety under high wind conditions. This study proposes a short-term speed prediction model based on outlier correction, Wavelet Denoising, the Osprey Optimization Algorithm (OOA), and the Transformer model. The outliers caused by data entry and measurement errors are processed by the interquartile range (IQR) method. By comparing the performance of four different wavelets, the best-performing wavelet (Bior2.2) was selected to filter out sharp noise from the data processed by the IQR method. The OOA-Transformer model was utilized to forecast short-term wind speeds based on the filtered time series data. With OOA-Transformer, the seven hyperparameters of the Transformer model were optimized by the Osprey Optimization Algorithm to achieve better performance. Given the outstanding performance of LSTM and its variants in wind speed prediction, the OOA-Transformer model was compared with six other models using the actual wind speed data from the Xuefeng Lake Bridge dataset to validate our proposed model. The experimental results show that the mean absolute percentage error (MAPE), root mean square error (RMSE), and coefficient of determination (R2) of this paper's method on the test set were 4.16%, 0.0152, and 0.9955, respectively, which are superior to the other six models. The prediction accuracy was found to be high enough to meet the short-term wind speed prediction needs of practical projects.","2024-06","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","12","12","","","","","","","","","","English","","","","WOS:001255789000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","interquartile range; osprey optimization algorithm; time-series prediction; transformer; wavelet denoising","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NM2FVLXM","journalArticle","2023","Zhang, BY; Lin, JP; Du, L; Zhang, LS","Harnessing Data Augmentation and Normalization Preprocessing to Improve the Performance of Chemical Reaction Predictions of Data-Driven Model","POLYMERS","","2073-4360","10.3390/polym15092224","","As a template-free, data-driven methodology, the molecular transformer model provides an alternative by which to predict the outcome of chemical reactions and design the route of the retrosynthetic plane in the field of organic synthesis and polymer chemistry. However, in consideration of the small datasets of chemical reactions, the data-driven model suffers from the difficulty of low accuracy in the prediction tasks of chemical reactions. In this contribution, we integrate the molecular transformer model with the strategies of data augmentation and normalization preprocessing to accomplish the three tasks of chemical reactions, including the forward predictions of chemical reactions, and single-step retrosynthetic predictions with and without the reaction classes. It is clearly demonstrated that the prediction accuracy of the molecular transformer model can be significantly raised by the use of proposed strategies for the three tasks of chemical reactions. Notably, after the introduction of the 40-level data augmentation and normalization preprocessing, the top-1 accuracy of the forward prediction increases markedly from 71.6% to 84.2% and the top-1 accuracy of the single-step retrosynthetic prediction with additional reaction class increases from 53.2% to 63.4%. Furthermore, it is found that the superior performance of the data-driven model originates from the correction of the grammatical errors of the SMILES strings, especially for the case of the reaction classes with small datasets.","2023-05-08","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","9","15","","","","","","","","","","English","","","","WOS:000987633800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","chemical reaction; CHEMISTRY; data augmentation; DESIGN; machine learning; molecular transformer model; NEURAL-NETWORKS; OUTCOMES; retrosynthesis; SMILES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XSFDZBZH","journalArticle","2025","Subert, M; Tykalová, T; Novotny, M; Dusek, P; Klempír, J; Rusz, J","Automated analysis of spoken language differentiates multiple system atrophy from Parkinson's disease","JOURNAL OF NEUROLOGY","","0340-5354","10.1007/s00415-024-12828-w","","Background and objectivesPatients with synucleinopathies such as multiple system atrophy (MSA) and Parkinson's disease (PD) frequently display speech and language abnormalities. We explore the diagnostic potential of automated linguistic analysis of natural spontaneous speech to differentiate MSA and PD.MethodsSpontaneous speech of 39 participants with MSA compared to 39 drug-naive PD and 39 healthy controls matched for age and sex was transcribed and linguistically annotated using automatic speech recognition and natural language processing. A quantitative analysis was performed using 6 lexical and syntactic and 2 acoustic features. Results were compared with human-controlled analysis to assess the robustness of the approach. Diagnostic accuracy was evaluated using sensitivity analysis.ResultsDespite similar disease duration, linguistic abnormalities were generally more severe in MSA than in PD, leading to high diagnostic accuracy with an area under the curve of 0.81. Compared to controls, MSA showed decreased grammatical component usage, more repetitive phrases, shorter sentences, reduced sentence development, slower articulation rate, and increased duration of pauses, whereas PD had only shorter sentences, reduced sentence development, and longer pauses. Only slower articulation rate was distinctive for MSA while unchanged for PD relative to controls. The highest correlation was found between bulbar/pseudobulbar clinical score and sentence length (r = -0.49, p = 0.002). Despite the relatively high severity of dysarthria in MSA, a strong agreement between manually and automatically computed results was achieved.DiscussionAutomated linguistic analysis may offer an objective, cost-effective, and widely applicable biomarker to differentiate synucleinopathies with similar clinical manifestations.","2025-02","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","2","272","","","","","","","","","","English","","","","WOS:001398122800033","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Automated linguistic analysis; Language; Multiple system atrophy; Natural language processing; SPEECH ANALYSIS; Spontaneous discourse","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HUUQGU84","journalArticle","2022","Carney, N","L2 comprehension of filled pauses and fillers in unscripted speech","SYSTEM","","0346-251X","10.1016/j.system.2022.102726","","One ubiquitous feature of unscripted speech across languages is the use of filled pauses and fillers. However, research has hitherto yielded opposing or ambiguous results about whether filled pauses and fillers in spontaneous speech aid or hinder L2 listeners' comprehension. In the current study, 30 L1 Japanese participants of three English proficiency levels viewed two video texts spoken by two different speakers of General American English. The video texts contained four occurrences of the filled pause um and two occurrences of the filler like. Participants had multiple opportunities to view and comprehend the texts. Comprehension, decoding, and internal pro-cessing of the video texts were elicited through a three-task assessment procedure of L1 recalls, L2 repetitions, and verbal reports. Results revealed that some occurrences of um and like caused comprehension difficulties for most participants while other occurrences caused no noticeable difficulty for any participants. The findings suggest that the location of filled pauses and fillers, L2 listeners' language proficiency, and multiple other factors can determine whether or not filled pauses and fillers will affect L2 listening comprehension of spontaneous speech.","2022-04","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","105","","","","","","","","","","English","","","","WOS:000788085600009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","ACQUISITION; Disfluencies; DISFLUENCIES; ENGLISH; Filled pauses; Fillers; Hesitation phenomena; HESITATION PHENOMENA; L2 listening comprehension; LANGUAGE; LEARNERS; PRAGMATIC MARKER LIKE; PROFICIENCY; UH; UM; Unscripted speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RC6FI67I","journalArticle","2024","Connaghan, KP; Green, JR; Eshghi, M; Haenssler, AE; Scheier, ZA; Clark, A; Iyer, A; Richburg, BD; Rowe, HP; Okada, J; Johnson, SA; Onnela, JP; Burke, KM; Berry, JD","The relationship of rate and pause features to the communicative participation of people living with ALS","MUSCLE & NERVE","","0148-639X","10.1002/mus.28170","","Introduction/Aims: Many people living with amyotrophic lateral sclerosis (PALS) report restrictions in their day-to-day communication (communicative participation). However, little is known about which speech features contribute to these restrictions. This study evaluated the effects of common speech symptoms in PALS (reduced overall speaking rate, slowed articulation rate, and increased pausing) on communicative participation restrictions. Methods: Participants completed surveys (the Communicative Participation Item Bank-short form; the self-entry version of the ALS Functional Rating Scale-Revised) and recorded themselves reading the Bamboo Passage aloud using a smartphone app. Rate and pause measures were extracted from the recordings. The association of various demographic, clinical, self-reported, and acoustic speech features with communicative participation was evaluated with bivariate correlations. The contribution of salient rate and pause measures to communicative participation was assessed using multiple linear regression. Results: Fifty seven people living with ALS participated in the study (mean age = 61.1 years). Acoustic and self-report measures of speech and bulbar function were moderately to highly associated with communicative participation (Spearman rho coefficients ranged from rs = 0.48 to rs = 0.77). A regression model including participant age, sex, articulation rate, and percent pause time accounted for 57% of the variance of communicative participation ratings. Discussion: Even though PALS with slowed articulation rate and increased pausing may convey their message clearly, these speech features predict communicative participation restrictions. The identification of quantitative speech features, such as articulation rate and percent pause time, is critical to facilitating early and targeted intervention and for monitoring bulbar decline in ALS.","2024-08","2025-02-26 20:37:01","2025-02-26 20:37:01","","217-225","","2","70","","","","","","","","","","English","","","","WOS:001238253200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","amyotrophic lateral sclerosis; communicative participation; DIAGNOSIS; DOPPLER SONOGRAPHY; ELBOW; pause; speaking rate; speech function; speech-language pathology; ULNAR NEUROPATHY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MX5AUCJT","journalArticle","2024","Zheng, ZS; Wang, KXL; Millan, H; Lee, S; Howard, M; Rothbart, A; Rosario, E; Schnakers, C","Transcranial direct stimulation over left inferior frontal gyrus improves language production and comprehension in post-stroke aphasia: A double-blind randomized controlled study","BRAIN AND LANGUAGE","","0093-934X","10.1016/j.bandl.2024.105459","","Transcranial direct current stimulation (tDCS) targeting Broca's area has shown promise for augmenting language production in post-stroke aphasia (PSA). However, previous research has been limited by small sample sizes and inconsistent outcomes. This study employed a double-blind, parallel, randomized, controlled design to evaluate the efficacy of anodal Broca's tDCS, paired with 20-minute speech and language therapy (SLT) focused primarily on expressive language, across 5 daily sessions in 45 chronic PSA patients. Utilizing the Western Aphasia Battery-Revised, which assesses a spectrum of linguistic abilities, we measured changes in both expressive and receptive language skills before and after intervention. The tDCS group demonstrated significant improvements over sham in aphasia quotient, auditory verbal comprehension, and spontaneous speech. Notably, tDCS improved both expressive and receptive domains, whereas sham only benefited expression. These results underscore the broader linguistic benefits of Broca's area stimulation and support the integration of tDCS with SLT to advance aphasia rehabilitation.","2024-10","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","257","","","","","","","","","","English","","","","WOS:001313541200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Aphasia; Auditory verbal comprehension; Broca's area; FUNCTIONAL CONNECTIVITY; HEALTHY; NONINVASIVE BRAIN-STIMULATION; RECOVERY; Spontaneous speech; Stroke; STROKE; TDCS; Transcranial direct current stimulation (tDCS); Western Aphasia Battery-Revised; WORD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RPH7NF4E","journalArticle","2024","Raso, T; Rocha, BNRD; Salgado, JV; Cruz, BF; Mantovani, LM; Mello, H","The C-ORAL-ESQ project: a corpus for the study of spontaneous speech of individuals with schizophrenia","LANGUAGE RESOURCES AND EVALUATION","","1574-020X","10.1007/s10579-023-09675-y","","This paper presents the C-ORAL-ESQ corpus project, which is dedicated to the study of the speech of individuals with schizophrenia. The main aim of the project is to investigate cognitive aspects of individuals with schizophrenia. This investigation is carried through the compilation of a spontaneous speech corpus and its study, which focuses mainly on the analysis of information structuring and its prosodic correlates. The paper mainly deals with the methodological aspects of the corpus compilation and reports its present stage: it informs about the environment and the setting of the sound file recordings, the medical and ethical criteria for the selection of the participants, the corpus aimed dimensions and the present stage of compilation, as well as its design and compilation criteria, which include attention to prosodic annotation, and metadata related to the participants' characteristics. Additionally, the theory adopted for the study of information structure is summarized, focusing on those aspects that can better address cognitive processes of individuals with schizophrenia and their prosodic correlates. Finally, the perspectives for future studies and resource compilations are presented.","2024-09","2025-02-26 20:37:01","2025-02-26 20:37:01","","903-923","","3","58","","","","","","","","","","English","","","","WOS:001017574400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","COGNITION; Corpus; Information structure; Prosody; PROSODY; RATING-SCALE; RECOGNITION; Schizophrenic speech; SYMPTOM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UN79RBQT","journalArticle","2021","Hahn, W; Domahs, F; Straube, B; Kircher, T; Nagels, A","Neural processing of nouns and verbs in spontaneous speech of patients with schizophrenia","PSYCHIATRY RESEARCH-NEUROIMAGING","","0925-4927","10.1016/j.pscychresns.2021.111395","","Previous fMRI-studies investigating the production of nouns and verbs in healthy participants reported predominantly activation in the left inferior frontal gyrus (IFG) for both classes of words with increased neural responses for verbs. To date, comparable imaging data for spontaneous speech in patients with schizophrenia is missing. These results are novel and may contribute to understand the neural basis of noun and verb production in a ""natural"" environment. Fifteen patients with schizophrenia and fifteen healthy control participants described pictures for one minute each while BOLD signal changes were measured with fMRI. In an event-related design, activations related to noun and verb production were extracted in the imaging analysis. Imaging results revealed increased activation for nouns and decreased activation for verbs in the left IFG in the patients. A post-hoc analysis revealed that patients produced significantly more transitive verbs which were negatively associated with activation in the left IFG. We conclude that a subtle linguistic processing deficit in schizophrenia may lead to an increased use of transitive as compared to intransitive verbs in connected speech and to a deviant pattern of brain activation related to the processing of verbs.","2021-12-30","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","318","","","","","","","","","","English","","","","WOS:000713295500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","BRAIN; ENGLISH; fMRI; FMRI; IFG; LANGUAGE; OBJECT; transitivity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3ZJ4RDP4","journalArticle","2022","Galatà, V; Avesani, C; Best, CT; Di Biase, B; Vayra, M","The Italian Roots in Australian Soil (IRIAS) multilingual speech corpus. Speech variation in two generations of Italo-Australians","LANGUAGE RESOURCES AND EVALUATION","","1574-020X","10.1007/s10579-021-09539-3","","We present and describe the Italian Roots in Australian Soil (IRIAS) speech corpus. Following a sociophonetic approach, our aim is to extend and complement the frequently investigated macro-structures of lexical, syntactic and morphological interactions among immigrants' languages and common sociolinguistic investigations about immigrants' language attitudes. We first discuss and motivate the creation of the IRIAS corpus. We then focus on the specific methodological issues we addressed in compiling a corpus of natural spontaneous speech collected in Veneto or Calabrese dialects, Italian and English from first and second generation Italo-Australian speakers originating from two specific regions in Italy (Veneto and Calabria). A detailed description of the IRIAS corpus follows, including its design, collection procedure and processing. The latter focuses on novel manual and automatic solutions we implemented to overcome the challenging dearth of existing resources. These solutions help advance work on spontaneous speech data. We conclude by providing some insights on what has been achieved thus far as well as the analyses currently being carried out on subsets of the IRIAS corpus.","2022-03","2025-02-26 20:37:01","2025-02-26 20:37:01","","37-78","","1","56","","","","","","","","","","English","","","","WOS:000641679200002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;95</p>","","","Annotation; Australian community; Automatic transcription; COMMUNITY; ENGLISH; Forced alignment; Italo‐; Language change; LANGUAGE CONTACT; Multilingual speech resource; Sociophonetics; Speech corpus compilation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NR6IPVDJ","journalArticle","2024","Qiao, XS; Jiao, SW; Li, H; Liu, GY; Gao, X; Li, ZS","Infant cry classification using an efficient graph structure and attention-based model","KUWAIT JOURNAL OF SCIENCE","","2307-4108","10.1016/j.kjs.2024.100221","","Crying serves as the primary means through which infants communicate, presenting a significant challenge for new parents in understanding its underlying causes. This study aims to classify infant cries to ascertain the reasons behind their distress. In this paper, an efficient graph structure based on multi -dimensional hybrid features is proposed. Firstly, infant cries are processed to extract various speech features, such as spectrogram, mel-scaled spectrogram, MFCC, and others. These speech features are then combined across multiple dimensions to better utilize the information in the cries. Additionally, in order to better classify the efficient graph structure, a local -to -global convolutional neural network (AlgNet) based on convolutional neural networks and attention mechanisms is proposed. The experimental results demonstrate that the use of the efficient graph structure improved the accuracy by an average of 8.01% compared to using standalone speech features, and the AlgNet model achieved an average accuracy improvement of 5.62% compared to traditional deep learning models. Experiments were conducted using the Dunstan baby language, Donate a cry, and baby cry datasets with accuracy rates of 87.78%, 93.83%, and 93.14% respectively.","2024-07","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","3","51","","","","","","","","","","English","","","","WOS:001218519000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Audio classification; IDENTIFICATION; Infant cry; Multi-head attention; Neural network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H2LBZU4A","journalArticle","2024","Kachare, PH; Sangle, SB; Puri, DV; Khubrani, MM; Al-Shourbaji, I","STEADYNet: Spatiotemporal EEG analysis for dementia detection using convolutional neural network","COGNITIVE NEURODYNAMICS","","1871-4080","10.1007/s11571-024-10153-6","","Dementia is a neuro-degenerative disorder with a high death rate, mainly due to high human error, time, and cost of the current clinical diagnostic techniques. The existing dementia detection methods using hand-crafted electroencephalogram (EEG) signal features are unreliable. A convolution neural network using spatiotemporal EEG signals (STEADYNet) is presented to improve the dementia detection. The STEADYNet uses a multichannel temporal EEG signal as input. The network is grouped into feature extraction and classification components. The feature extraction comprises two convolution layers to generate complex features, a max-pooling layer to reduce the EEG signal's spatiotemporal redundancy, and a dropout layer to improve the network's generalization. The classification processes the feature extraction output nonlinearly using two fully-connected layers to generate salient features and a softmax layer to generate disease probabilities. Two publicly available multiclass datasets of dementia are used for evaluation. The STEADYNet outperforms existing automatic dementia detection methods with accuracies of 99.29%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$99.29\%$$\end{document}, 99.65%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$99.65\%$$\end{document}, and 92.25%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$92.25\%$$\end{document} for Alzheimer's disease, mild cognitive impairment, and frontotemporal dementia, respectively. The STEADYNet has a low inference time and floating point operations, suitable for real-time applications. It may aid neurologists in efficient detection and treatment. A Python implementation of the STEADYNet is available at https://github.com/SandeepSangle12/STEADYNet.git","2024-10","2025-02-26 20:37:01","2025-02-26 20:37:01","","3195-3208","","5","18","","","","","","","","","","English","","","","WOS:001272289000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Alzheimer's disease; Convolution neural network; Electroencephalogram; Frontotemporal dementia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K5ZL6V4L","journalArticle","2024","Mauricio-Alvarez, LE; Aceves-Fernandez, MA; Pedraza-Ortega, JC; Ramos-Arreguín, JM","Evaluation of a transformer-based model for the temporal forecast of coarse particulate matter (PMCO) concentrations","EARTH SCIENCE INFORMATICS","","1865-0473","10.1007/s12145-024-01330-6","","Accurate forecasting of coarse particulate matter (PMCO) concentrations is crucial for mitigating health risks and environmental impacts in urban areas. This study evaluates the performance of a transformer-based deep learning model for predicting PMCO levels using 2022 data from four monitoring stations (BJU, MER, TLA, UIZ) in Mexico City. The transformer model's forecasting accuracy is assessed for horizons of 12, 24, 48, and 72 hours ahead and compared against conventional autoregressive integrated moving average (ARIMA) and long short-term memory (LSTM) models. Error metrics including root mean square error (RMSE), mean absolute error (MAE), and mean absolute percentage error (MAPE) are employed for evaluation. Results demonstrate the transformer model's superior performance, achieving the lowest error values across multiple stations and prediction horizons. However, challenges are identified for short-term forecasts and sites near industrial areas with high PMCO variability. The study highlights the transformer model's potential for accurate PMCO forecasting while underscoring the need for interdisciplinary approaches to address complex air pollution dynamics in urban environments.","2024-08","2025-02-26 20:37:01","2025-02-26 20:37:01","","3095-3110","","4","17","","","","","","","","","","English","","","","WOS:001229218000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Air pollution; Deep learning; Forecasting; NEURAL-NETWORK; PMCO; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E8QEEKRL","journalArticle","2022","Huang, SC; Zhang, J; He, Y; Fu, XF; Fan, LQ; Yao, G; Wen, YJ","Short-Term Load Forecasting Based on the CEEMDAN-Sample Entropy-BPNN-Transformer","ENERGIES","","1996-1073","10.3390/en15103659","","Aiming at the problem that power load data are stochastic and that it is difficult to obtain accurate forecasting results by a single algorithm, in this paper, a combined forecasting method for short-term power load was proposed based on the Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN)-sample entropy (SE), the BP neural network (BPNN), and the Transformer model. Firstly, the power load data were decomposed into several power load subsequences with obvious complexity differences by using the CEEMDAN-SE. Then, BPNN and Transformer model were used to forecast the subsequences with low complexity and the subsequences with high complexity, respectively. Finally, the forecasting results of each subsequence were superimposed to obtain the final forecasting result. The simulation was taken from our proposed model and six forecasting models by using the load dataset from a certain area of Spain. The results showed that the MAPE of our proposed CEEMDAN-SE-BPNN-Transformer model was 1.1317%, while the RMSE was 304.40, which was better than the selected six forecasting models.","2022-05","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","10","15","","","","","","","","","","English","","","","WOS:000801481500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;21<br/>Total Times Cited:&nbsp;&nbsp;22<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","BPNN; CEEMDAN; load forecasting; MODEL; sample entropy; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LTTRT5AC","journalArticle","2025","Zhang, D; Ma, WP; Jiao, LC; Liu, X; Yang, YT; Liu, F","Multiple Hierarchical Cross-Scale Transformer for Remote Sensing Scene Classification","REMOTE SENSING","","2072-4292","10.3390/rs17010042","","The Transformer model can capture global contextual information but does not have an inherent inductive bias. In contrast, convolutional neural networks (CNNs) are highly praised in computer vision due to their strong inductive bias and local spatial correlation. To combine the advantages of the two model types, we propose a multiple hierarchical cross-scale Transformer model that efficiently combines the Transformer model with CNNs and is specifically designed for complex remote sensing scene classification. Firstly, a feature pyramid network with attention aggregation extracts the multi-scale base features. Then, these base features are fed into the proposed multi-scale channel Transformer (MSCT) module to derive the global features with channel-wise attention. Additionally, the base features are also fed into the proposed hierarchical cross-scale Transformer (HCST) module, which can obtain multi-level cross-scale representations. Lastly, the outputs from both modules are taken into account to calculate the final classification score. The performance of the proposed method has been validated for its effectiveness on three public datasets: AID, UCM, and NWPU-RESISC45.","2025-01","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","1","17","","","","","","","","","","English","","","","WOS:001393801600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","ATTENTION; FEATURES; hierarchical; multiple cross-scale; NETWORK; scene classification; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XMAZSYVI","journalArticle","2024","Long, ZY; Yan, HR; Shen, GQ; Zhang, XL; He, HY; Cheng, L","A Transformer-based network intrusion detection approach for cloud security","JOURNAL OF CLOUD COMPUTING-ADVANCES SYSTEMS AND APPLICATIONS","","2192-113X","10.1186/s13677-023-00574-9","","The distributed architecture of cloud computing necessitates robust defense mechanisms to secure network-accessible resources against a diverse and dynamic threat landscape. A Network Intrusion Detection System (NIDS) is pivotal in this context, with its efficacy in cloud environments hinging on its adaptability to evolving threat vectors while mitigating false positives. In this paper, we present a novel NIDS algorithm, anchored in the Transformer model and finely tailored for cloud environments. Our algorithm melds the fundamental aspects of network intrusion detection with the sophisticated attention mechanism inherent to the Transformer model, facilitating a more insightful examination of the relationships between input features and diverse intrusion types, thereby bolstering detection accuracy. We provide a detailed design of our approach and have conducted a thorough comparative evaluation. Our experimental results demonstrate that the accuracy of our model is over 93%, which is comparable to that of the CNN-LSTM model, underscoring the effectiveness and viability of our Transformer-based intrusion detection algorithm in bolstering cloud security.","2024-01-02","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","1","13","","","","","","","","","","English","","","","WOS:001133120700003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Attention mechanism; Cloud computing; Network intrusion detection; Network security; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZYJUVMIP","journalArticle","2022","Bhattacharya, A; Baweja, T; Karri, SPK","Epileptic Seizure Prediction Using Deep Transformer Model","INTERNATIONAL JOURNAL OF NEURAL SYSTEMS","","0129-0657","10.1142/S0129065721500581","","The electroencephalogram (EEG) is the most promising and efficient technique to study epilepsy and record all the electrical activity going in our brain. Automated screening of epilepsy through data-driven algorithms reduces the manual workload of doctors to diagnose epilepsy. New algorithms are biased either towards signal processing or deep learning, which holds subjective advantages and disadvantages. The proposed pipeline is an end-to-end automated seizure prediction framework with a Fourier transform feature extraction and deep learning-based transformer model, a blend of signal processing and deep learning - this imbibes the potential features to automatically identify the attentive regions in EEG signals for effective screening. The proposed pipeline has demonstrated superior performance on the benchmark dataset with average sensitivity and false-positive rate per hour (FPR/h) as 98.46%, 94.83% and 0.12439, 0, respectively. The proposed work shows great results on the benchmark datasets and a big potential for clinics as a support system with medical experts monitoring the patients.","2022-02","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","02","32","","","","","","","","","","English","","","","WOS:000745070100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;51<br/>Total Times Cited:&nbsp;&nbsp;52<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","deep learning; EEG; epilepsy; intracranial electroencephalogram; Machine learning; scalp electroencephalogram; seizure prediction; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EP4H2RAI","journalArticle","2024","Peng, C; Luo, L; Luo, H; Tang, ZH","Study on Prediction of Zinc Grade by Transformer Model with De-Stationary Mechanism","MINERALS","","2075-163X","10.3390/min14030230","","At present, in the mineral flotation process, flotation data are easily influenced by various factors, resulting in non-stationary time series data, which lead to overfitting of prediction models, ultimately severely affecting the accuracy of grade prediction. Thus, this study proposes a de-stationary attention mechanism based on the transformer model (DST) to learn non-stationary information in raw mineral data sequences. First, normalization processing is performed on matched flotation data and mineral grade values, to make the data sequences stationary, thereby enhancing model prediction capabilities. Then, the proposed de-stationary attention mechanism is employed to learn the temporal dependencies of mineral flotation data in the transformed vanilla transformer model, i.e., non-stationary information in the mineral data sequences. Lastly, de-normalization processing is conducted to maintain the mineral prediction results within the same scale as the original data. Compared with existing models such as RNN, LSTM, transformer, Enc-Dec (RNN), and STS-D, the DST model reduced the RMSE by 20.8%, 20.8%, 62.8%, 20.5%, and 49.1%, respectively.","2024-03","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","3","14","","","","","","","","","","English","","","","WOS:001192581900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","grade prediction; non-stationary information; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LXTSWIUU","journalArticle","2025","Li, YW; Jiang, YZ; Wu, XK","TrajPT: A trajectory data-based pre-trained transformer model for learning multi-vehicle interactions","TRANSPORTATION RESEARCH PART C-EMERGING TECHNOLOGIES","","0968-090X","10.1016/j.trc.2025.105013","","Modeling and learning interactions with surrounding vehicles are critical for the safety and efficiency of autonomous vehicles. In this paper, we propose TrajPT, a Trajectory data-based Pretrained Transformer model designed to learn spatial-temporal interactions among vehicles from large-scale real-world trajectory data. Inspired by pre-trained large language models, TrajPT adopts an autoregressive learning framework and a pre-training paradigm, and can be fine-tuned for different autonomous driving downstream tasks. To capture complex spatial-temporal interactions among vehicles, we utilize a spatial-temporal scene graph to encode observed vehicle trajectories and introduce a novel graph-based joint spatial-temporal attention module, which extracts spatial interactions within single frames and temporal dependencies across frames. TrajPT is pre-trained on pNEUMA, the largest publicly available vehicle trajectory dataset. We validate the performance of TrajPT by fine-tuning it on two downstream tasks: lane-changing prediction and trajectory prediction. Extensive experimental results demonstrate that the proposed TrajPT outperforms the baseline model and exhibits significant generalization performance across multiple datasets.","2025-02","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","171","","","","","","","","","","English","","","","WOS:001407319200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Autonomous driving; Interaction; Motion prediction; Pre-trained transformer model; PREDICTION; Vehicle trajectory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YTYXHNCB","journalArticle","2023","Khan, AA; Jahangir, R; Alroobaea, R; Alyahyan, SY; Almulhi, AH; Alsafyani, M; Wechtaisong, C","An Efficient Text-Independent Speaker Identification Using Feature Fusion and Transformer Model","CMC-COMPUTERS MATERIALS & CONTINUA","","1546-2218","10.32604/cmc.2023.036797","","Automatic Speaker Identification (ASI) involves the process of distinguishing an audio stream associated with numerous speakers' utterances. Some common aspects, such as the framework difference, overlapping of different sound events, and the presence of various sound sources during recording, make the ASI task much more complicated and complex. This research proposes a deep learning model to improve the accuracy of the ASI system and reduce the model training time under limited computation resources. In this research, the performance of the transformer model is investigated. Seven audio features, chromagram, Mel-spectrogram, tonnetz, Mel-Frequency Cepstral Coefficients (MFCCs), delta MFCCs, delta-delta MFCCs and spectral contrast, are extracted from the ELSDSR, CSTR-VCTK, and Ar-DAD, datasets. The evaluation of various experiments demon-strates that the best performance was achieved by the proposed transformer model using seven audio features on all datasets. For ELSDSR, CSTR-VCTK, and Ar-DAD, the highest attained accuracies are 0.99, 0.97, and 0.99, respectively. The experimental results reveal that the proposed technique can achieve the best performance for ASI problems.","2023","2025-02-26 20:37:01","2025-02-26 20:37:01","","4085-4100","","2","75","","","","","","","","","","English","","","","WOS:000992747000015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Arabic; deep learning; RECOGNITION; signal processing; Speaker identification; SPEECH; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JHJ7G3SX","journalArticle","2023","Xu, YF; Wang, Y; Peeta, S","Leveraging Transformer Model to Predict Vehicle Trajectories in Congested Urban Traffic","TRANSPORTATION RESEARCH RECORD","","0361-1981","10.1177/03611981221109594","","Accurate vehicle trajectory prediction enables safe, comfortable, and optimal proactive motion planning for connected and autonomous vehicles (CAVs). Because of rapid advances in learning techniques and increasing access to massive amounts of data, deep learning techniques have been applied to predict vehicle trajectories, especially the long short-term memory (LSTM) model. However, the accurate prediction of vehicle trajectories for congested urban traffic remains problematic, as existing LSTM models do not perform well. To address this gap, this paper proposes to leverage an emerging deep learning technique-transformer-and utilizes a recently released dataset (pNEUMA) for predicting vehicle trajectories in congested urban traffic. The proposed transformer model uses the self-attention mechanism, which helps to identify dependencies within the model inputs, to systematically determine the impacts of vehicular interactions on the target vehicle's future trajectory. The pNEUMA dataset, which provides drone-based large-scale data of congested urban traffic, is processed to fit a typical trajectory prediction scenario, and used to train the transformer model. Numerical studies are conducted to analyze the effectiveness of the proposed modeling approach. A comparison of the proposed model with representative LSTM models highlights the advantages of leveraging the transformer model characteristics for the vehicle trajectory prediction of congested urban traffic. By contrast, existing LSTM models may suffice for the trajectory prediction of freeway traffic. The results also indicate that, unlike for vehicle trajectory prediction for freeway traffic, a longer time window of inputs does not guarantee better prediction performance for congested urban traffic.","2023-02","2025-02-26 20:37:01","2025-02-26 20:37:01","","898-909","","2","2677","","","","","","","","","","English","","","","WOS:000835913300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","big data analytics; data analytics; data and data science; deep learning; traffic prediction; trajectory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UYUZGRTJ","journalArticle","2021","Wang, XY; Tong, YX","Application of an emotional classification model in e-commerce text based on an improved transformer model","PLOS ONE","","1932-6203","10.1371/journal.pone.0247984","","With the rapid development of the mobile internet, people are becoming more dependent on the internet to express their comments on products or stores; meanwhile, text sentiment classification of these comments has become a research hotspot. In existing methods, it is fairly popular to apply a deep learning method to the text classification task. Aiming at solving information loss, weak context and other problems, this paper makes an improvement based on the transformer model to reduce the difficulty of model training and training time cost and achieve higher overall model recall and accuracy in text sentiment classification. The transformer model replaces the traditional convolutional neural network (CNN) and the recurrent neural network (RNN) and is fully based on the attention mechanism; therefore, the transformer model effectively improves the training speed and reduces training difficulty. This paper selects e-commerce reviews as research objects and applies deep learning theory. First, the text is preprocessed by word vectorization. Then the IN standardized method and the GELUs activation function are applied based on the original model to analyze the emotional tendencies of online users towards stores or products. The experimental results show that our method improves by 9.71%, 6.05%, 5.58% and 5.12% in terms of recall and approaches the peak level of the F1 value in the test model by comparing BiLSTM, Naive Bayesian Model, the serial BiLSTM_CNN model and BiLSTM with an attention mechanism model. Therefore, this finding proves that our method can be used to improve the text sentiment classification accuracy and effectively apply the method to text classification.","2021-03-05","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","3","16","","","","","","","","","","English","","","","WOS:000626604300008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;12</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I3K2SYZK","journalArticle","2024","Jung, M; Lee, J; Kim, J","A lightweight CNN-transformer model for learning traveling salesman problems","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-024-05603-x","","Several studies have attempted to solve traveling salesman problems (TSPs) using various deep learning techniques. Among them, Transformer-based models show state-of-the-art performance even for large-scale Traveling Salesman Problems (TSPs). However, they are based on fully-connected attention models and suffer from large computational complexity and GPU memory usage. Our work is the first CNN-Transformer model based on a CNN embedding layer and partial self-attention for TSP. Our CNN-Transformer model is able to better learn spatial features from input data using a CNN embedding layer compared with the standard Transformer-based models. It also removes considerable redundancy in fully-connected attention models using the proposed partial self-attention. Experimental results show that the proposed CNN embedding layer and partial self-attention are very effective in improving performance and computational complexity. The proposed model exhibits the best performance in real-world datasets and outperforms other existing state-of-the-art (SOTA) Transformer-based models in various aspects. Our code is publicly available at https://github.com/cm8908/CNN_Transformer3.","2024-09","2025-02-26 20:37:01","2025-02-26 20:37:01","","7982-7993","","17-18","54","","","","","","","","","","English","","","","WOS:001251064300002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","CNN-Transformer; Combinatorial optimization problem; EFFICIENT TRANSFORMER; Lightweight model; NEURAL-NETWORK; Traveling salesman problem","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XYMFS2UA","journalArticle","2023","Hu, BJ; Jin, B; Xue, H; Zhang, ZK; Xu, ZY; Zhu, XH","Heartbeat information prediction based on transformer model using millimetre-wave radar","IET BIOMETRICS","","2047-4938","10.1049/bme2.12116","","Millimetre-wave radar offers high ranging accuracy and can capture subtle vibration information of the human heart. This study proposes a heartbeat prediction method based on the transformer model using millimetre-wave radar. Firstly, the millimetre-wave radar was used to collect the heartbeat data and conduct normalisation processing. Secondly, a position coding was introduced to assign sine or cosine variables to input data and extract their relative position relationship. Subsequently, the transformer encoder was adopted to allocate attention to input data through the multi-head attention mechanism, using a mask layer before the decoding layer to prevent the leakage of future information. Finally, we employ the fully connected layer was employed in the linear decoder for regression and output the predicted results. Our experimental results demonstrate that the proposed transformer model achieves nearly 30% higher prediction accuracy than traditional long short-term memory models while improving both the prediction accuracy and convergence rate. The proposed method has great potential in predicting the heartbeat state of elderly and sick patients.","2023-07","2025-02-26 20:37:01","2025-02-26 20:37:01","","235-243","","4","12","","","","","","","","","","English","","","","WOS:001031506900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","ECG biometrics; Fourier transforms; low-pass filters; medical signal processing; neural nets; signal processing for biometrics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BM7JCAP3","journalArticle","2021","Liu, H; Liu, ZY; Jia, WQ; Zhang, DH; Wang, QD; Tan, JR","Tool wear estimation using a CNN-transformer model with semi-supervised learning","MEASUREMENT SCIENCE AND TECHNOLOGY","","0957-0233","10.1088/1361-6501/ac22ee","","In the machining industry, tool wear has a great influence on machining efficiency, product quality, and production costs. To achieve accurate tool wear estimation, a novel CNN-transformer neural network (CTNN) model is proposed in this paper. In the CTNN model, the transformer model and convolutional neural networks (CNN) are used to process condition monitoring (CM) data in parallel, such as cutting force. The motivations are as follows. For one thing, both the transformer model and CNN can extract useful temporal features from CM data, and the learned temporal features by these two parts are fused to achieve accurate tool wear estimation. For another, CNN contributes to enhancing the transformer's ability to capture the sequence order. In addition, data noise introduces the aleatoric uncertainty to the estimation results. To quantify the aleatoric uncertainty, a negative log-likelihood loss function is employed to enable the model to output the probabilistic distribution associated with tool wear. In such cases, the model outputs both the tool wear and variance, and the variance is learned within the model in an unsupervised manner. Finally, the effectiveness and superiority of the proposed method are validated on a public milling dataset. It is found by experiments that both the transformer model and CNN play important roles in tool wear estimation, and better performance can be obtained when they are used in parallel. In summary, the experimental results suggest that the proposed model can obtain promising results in tool wear estimation.","2021-12","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","12","32","","","","","","","","","","English","","","","WOS:000697834200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;42<br/>Total Times Cited:&nbsp;&nbsp;44<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","aleatoric uncertainty; convolutional neural networks; NEURAL-NETWORK; tool wear estimation; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AH2RM4TM","journalArticle","2024","Han, JY; Xu, LJ; Yang, Q","AN EMOTION ANALYSIS METHOD THAT INTEGRATES EEG SIGNALS AND MUSIC THERAPY USING A TRANSFORMER MODEL","JOURNAL OF MECHANICS IN MEDICINE AND BIOLOGY","","0219-5194","10.1142/S0219519424400396","","The need for sentiment analysis in the mental health field is increasing, and electroencephalogram (EEG) signals and music therapy have attracted extensive attention from researchers as breakthrough ideas. However, the existing methods still face the challenge of integrating temporal and spatial features when combining these two types, especially when considering the volume conduction differences among multichannel EEG signals and the different response speeds of subjects; moreover, the precision and accuracy of emotion analysis have yet to be improved. To solve this problem, we integrate the idea of top-k selection into the classic transformer model and construct a novel top-k sparse transformer model. This model captures emotion-related information in a finer way by selecting k data segments from an EEG signal with distinct signal features. However, this optimization process is not without its challenges, and we need to balance the selected k values to ensure that the important features are preserved while avoiding excessive information loss. Experiments conducted on the DEAP dataset demonstrate that our approach achieves significant improvements over other models. By enhancing the sensitivity of the model to the emotion-related information contained in EEG signals, our method achieves an overall emotion classification accuracy improvement and obtains satisfactory results when classifying different emotion dimensions. This study fills a research gap in the field of sentiment analysis involving EEG signals and music therapy, provides a novel and effective method, and is expected to lead to new ideas regarding the application of deep learning in sentiment analysis.","2024-10","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","08","24","","","","","","","","","","English","","","","WOS:001305391600012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","EEG; music therapy; self-attention mechanism; sentiment analysis; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2W7K72YA","journalArticle","2024","Xin, L; Xie, PH; Wen, T; Niu, GQ; Yuan, J","Transfer learning enables predictions in soil-borne diseases","SOIL ECOLOGY LETTERS","","2662-2289","10.1007/s42832-024-0258-y","","The Transformer model precisely predicts soil health status from high-throughput sequencing data.The SMOTE algorithm addresses data imbalance issues, improving model accuracy.Transfer learning validates the model on small samples, strengthening its generalization capabilities.Inhibiting the occurrence of soil-borne diseases is considered as the most favorable approach for promoting sustainable agricultural development. Constructing soil disease prediction models can serve precision agriculture. However, the analysis results of the metaframework often contradict each other, causing inconsistency in the important features of machine learning results. Therefore, it is necessary to compare the classification accuracy of various machine learning models and further optimize the features of the models to enhance their classification accuracy. Here, we conducted a comparison of eight common machine learning algorithms (XGBoost, CatBoost, Decision Tree, LGBM, Na & iuml;ve Byes, Perceptron, Logistic, and Random Forest) at the levels of family, genus, and class. The important features of the model were extracted based on the differences in model accuracy and important features, followed by an interpretable analysis of these important features using feature importance. Subsequently, the data underwent resampling using the SMOTE algorithm, and the results show that the SMOTE-Transformer model performs well, surpassing the training results of the voting and stacking strategies, with an accuracy reaching 90%. We have also deployed the SMOTE-Transformer model on sequencing data, which has an accuracy of over 80%. The construction of SMOTE-Transformer model provides a new idea for soil microbial data analysis by greatly improving the accuracy and robustness of soil microbial data processing tools.","2024-12","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","4","6","","","","","","","","","","English","","","","WOS:001278996600002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","APPORTIONMENT; BIOLOGY; feature importance; heterogeneous integration strategy; soil disease; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8JDWPD3E","journalArticle","2024","Dong, YQ; Pan, Y; Wang, DL; Chen, AR","Traffic Load Simulation for Long-Span Bridges Using a Transformer Model Incorporating In-Lane Transverse Vehicle Movements","IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS","","1524-9050","10.1109/TITS.2024.3452106","","Traffic load simulation (TLS) is critical for the design and assessment of long-span bridges. Traditional methods, such as Monte-Carlo sampling and Cellular Automaton, rely on actual traffic data for load generation and evolution. However, they often overlook in-lane transverse movements, which are vital for precise bridge component assessment. This paper presents a TLS framework that incorporates in-lane transverse movements for long-span bridges. We select eight parameters as input features for a Transformer-based deep learning model, designed to predict both longitudinal and transverse vehicle speeds. The TLS process begins with spatial-temporal traffic load monitoring on the target bridge. Monte-Carlo sampling generates vehicle data, and the trained Transformer model simulates traffic evolution. A case study on a 1490-meter main-span suspension bridge illustrates the proposed method. Traffic trajectories were captured using a multi-vision system and reconstructed to minimize errors. The Transformer model was trained with optimized hyperparameters, enabling the completion of TLS on the entire bridge deck. We also compare the performance of other deep learning models, evaluate the accuracy of transverse distribution in TLS, and discuss its potential applications in future bridge assessments. The proposed TLS method enhances current practices by accurately simulating transverse vehicle positions on bridge decks, thereby improving the fidelity of microscopic traffic simulations and enabling more precise fatigue damage assessments of bridge components.","2024-11","2025-02-26 20:37:01","2025-02-26 20:37:01","","15600-15613","","11","25","","","","","","","","","","English","","","","WOS:001312157700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","BEHAVIORS; bridge maintenance; Bridges; CAR-FOLLOWING MODEL; CELLULAR-AUTOMATON; deep learning; DRIVEN; Fatigue; INFORMATION; Load modeling; Long-span bridge; MEMORY; Monitoring; Telecommunication traffic; traffic load simulation; Trajectory; Transformer model; Transformers; transverse movement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EK9RLULJ","journalArticle","2024","Wei, JJ; Yu, L; Wei, YS; Xu, RQ","A rapid recognition method for radar active jamming based on the Hybrid 3_CNN-Transformer model","IET RADAR SONAR AND NAVIGATION","","1751-8784","10.1049/rsn2.12651","","As the electromagnetic environment becomes increasingly complex, radar encounters more intricate jamming patterns. Accurate and real-time jamming recognition is crucial for effective radar anti-jamming decisions. For scenarios with limited data, a rapid active jamming recognition method based on the Hybrid 3_CNN-Transformer model is proposed. To thoroughly evaluate and validate this method, we simulated nine jamming types and used pulse compression for preprocessing. Combining the strengths of CNNs and Transformers, we constructed the Hybrid 3_CNN-Transformer model, which employs three CNNs to extract local features from the complex domain, real part, and imaginary part of the jamming signals. After concatenating these features and performing position encoding, the model utilises Transformers to capture global features, enhancing recognition accuracy and reducing training time. To enhance computational efficiency and reduce storage, we applied an L1 norm-based unstructured pruning algorithm for model compression, achieving an 82% pruning rate and cutting inference time to 33 ms. Experiments show that the Hybrid 3_CNN-Transformer model significantly boosts recognition accuracy and speed over other models. On a small dataset with nine jamming types, it achieved 95.1% accuracy after 25 epochs and 100% after 90 epochs. This approach enhances training speed and accuracy, allowing rapid and reliable jamming recognition in resource-limited environments. To enhance radar systems' adaptability to complex jamming environments and real-time response capability under small sample data scenarios, this investigation proposes a rapid jamming recognition method based on the Hybrid 3_CNN-Transformer model. This method combines the strengths of CNN and Transformers, capturing local features of jamming signals in the complex domain, real part, and imaginary part through three CNN networks, concatenating these features and performing position encoding. Then, utilising Transformers to capture global features, thereby effectively improving jamming recognition accuracy and training speed. Additionally, the authors optimise the model using an L1 norm-based unstructured pruning algorithm, reducing the model's storage space and improving computational efficiency. image","2024-11","2025-02-26 20:37:01","2025-02-26 20:37:01","","2377-2395","","11","18","","","","","","","","","","English","","","","WOS:001333669300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","intelligent networks; jamming; radar; radar interference","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2H9UDWMU","journalArticle","2021","Lu, XY; Shi, DM; Liu, Y; Yuan, JY","Speech depression recognition based on attentional residual network","FRONTIERS IN BIOSCIENCE-LANDMARK","","2768-6701","10.52586/5066","","Background: Depressive disorder is a common affective disorder, also known as depression, which is characterized by sadness, loss of interest, feelings of guilt or low self-worth and poor concentration. As speech is easy to obtain non-offensively with low-cost, many researchers explore the possibility of depression prediction through speech. Adopting speech signals to recognize depression has important practical significance. Aiming at the problem of the complex structure of the deep neural network method used in the recognition of speech depression and the traditional machine learning methods need to manually extract the features and the low recognition rate. Methods: This paper proposes a model that combines residual thinking and attention mechanism. First, depression corpus is designed based on the classic psychological experimental paradigm self-reference effect (SRE), and the speech dataset is labeled; then the attention module is introduced into the residual, and the channel attention is used to learn the features of the channel dimension, the spatial attention feedback the features of the spatial dimension, and the combination of the two to obtain the attention residual unit; finally the stacking unit constructs a speech depression recognition model based on the attention residual network. Results: Experimental results show that compared with traditional machine learning methods, this model obtains better results in the recognition of depression, which can meet the need for actual recognition application of depression. Conclusions: In this study, we not only predict whether person is depressed, but also estimate the severity of depression. In the designed corpus, the depression binary classification of an individual is given based on the severity of depression which is measured using BDI-II scores. Experimental results show that spontaneous speech can obtain better results than automatic speech, and the classification of speech features corresponding to negative questions is better than other tasks under negative emotions. Besides, the recognition accuracy rate of both male and female subjects is higher than that under other emotions.","2021-12-30","2025-02-26 20:37:01","2025-02-26 20:37:01","","1746-1759","","12","26","","","","","","","","","","English","","","","WOS:000742514300036","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","Attention mechanism; Automatic recognition of depression; MFCC; Residual neural network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7GWLKVL2","journalArticle","2023","Zhu, Y; Tiwari, A; Monteiro, J; Kshirsagar, S; Falk, TH","COVID-19 Detection via Fusion of Modulation Spectrum and Linear Prediction Speech Features","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2023.3265603","","The coronavirus disease 2019 (COVID-19) pandemic has drastically impacted life around the globe. As life returns to pre-pandemic routines, COVID-19 testing has become a key component, assuring that travellers and citizens are free from the disease. Conventional tests can be expensive, time-consuming (results can take up to 48 h), and require laboratory testing. Rapid antigen testing, in turn, can generate results within 15-30 minutes and can be done at home, but research shows they achieve very poor sensitivity rates. In this paper, we propose an alternative based on speech signals recorded at home with a portable device. It has been well-documented that the virus affects many of the speech production systems (e.g., lungs, larynx, and articulators). As such, we propose the use of new modulation spectral features and linear prediction analysis to characterize these changes via a two-stage classification system. Experiments on three COVID-19 speech datasets show that the proposed two-stage system outperforms several state-of-the-art benchmarks, relies on interpretable features, as well as generalizes well to unseen datasets. Overall, the proposed system shows promise as an accessible, low-cost, at-home method for COVID-19 detection.","2023","2025-02-26 20:37:01","2025-02-26 20:37:01","","1536-1549","","","31","","","","","","","","","","English","","","","WOS:000979606400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","COVID-19; COVID-19 diagnostics; Diseases; Feature extraction; Frequency modulation; linear predictive analysis; Modulation; modulation spectrogram; Spectrogram; speech analysis; Time-frequency analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R9RN62RA","journalArticle","2021","Yan, YG; Mao, Y; Shen, ZY; Wei, YT; Pan, GZ; Zhu, JF","A High-Efficiency Fatigued Speech Feature Selection Method for Air Traffic Controllers Based on Improved Compressed Sensing","JOURNAL OF HEALTHCARE ENGINEERING","","2040-2295","10.1155/2021/2292710","","Air traffic controller fatigue has recently received considerable attention from researchers because it is one of the main causes of air traffic incidents. Numerous research studies have been conducted to extract speech features related to fatigue, and their practical utilization has achieved some positive detection results. However, there are still challenges associated with the applied speech features usually being of high dimension, which leads to computational complexity and inefficient fatigue detection. This situation makes it meaningful to reduce the dimensionality and select only a few efficient features. This paper addresses these problems by proposing a high-efficiency fatigued speech selection method based on improved compressed sensing. For adapting a method to the specific field of fatigued speech, we propose an improved compressed sensing construction algorithm to decrease the reconstruction error and achieve superior sparse coding. The proposed feature selection method is then applied to optimize the high-dimension fatigued speech features based on the fractal dimension. Finally, a support vector machine classifier is applied to a series of comparative experiments using the Civil Aviation Administration of China radiotelephony corpus to demonstrate that the proposed method provides a significant improvement in the precision of fatigue detection compared with current state-of-the-art approaches.","2021-09-26","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","2021","","","","","","","","","","English","","","","WOS:000704323400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","MENTAL FATIGUE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IVMT53CY","journalArticle","2023","Jiang, WQ; Sun, CL; Chen, FL; Leng, Y; Guo, QS","A novel skip connection mechanism based on channel-wise cross transformer for speech enhancement","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-023-16977-4","","The skip connection mechanism has been proven to be an effective approach for improving speech enhancement networks. By strengthening the information transfer between the encoder and the decoder, it facilitates the restoration of speech features during the up-sampling process. However, simple skip connection mechanism that directly connect corresponding layers of the encoder and decoder have several issues. Firstly, it only forces the features of the same scale to be aggregated, ignoring the potential relationships between different scales. Secondly, the shallow encoder feature contains a lot of redundant information. Studies have shown that coarse skip connections can even be detrimental to model performance in some cases. In this work, we propose a novel skip connection mechanism based on channel-wise Transformer for speech enhancement, comprising two components: multi-scale channel-wise cross fusion and channel-wise cross attention. This proposed skip connection mechanism can fuse multi-scale speech features from different levels of the encoder and effectively connect the reconstructed features to the decoder. Building on this, we propose a lightweight U-shaped network (UNet) structure called UCTNet. Experimental results show that UCTNet is comparable to other competitive models in terms of various objective speech quality metrics with only a few parameters.","2023-09-27","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","","","","","","","","","","","English","","","","WOS:001076019000017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Channel-wise cross Transformer; Multi-scale speech features; NOISE; Skip connection; Speech enhancement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LILN2MTV","journalArticle","2025","Ku, H; Lee, J; Lee, M; Kim, S; Yoon, J","Age Prediction from Korean Speech Data Using Neural Networks with Diverse Voice Features","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app15031337","","A person's voice serves as an indicator of age, as it changes with anatomical and physiological influences throughout their life. Although age prediction is a subject of interest across various disciplines, age-prediction studies using Korean voices are limited. The few studies that have been conducted have limitations, such as the absence of specific age groups or detailed age categories. Therefore, this study proposes an optimal combination of speech features and deep-learning models to recognize detailed age groups using a large Korean-speech dataset. From the speech dataset, recorded by individuals ranging from their teens to their 50s, four speech features were extracted: the Mel spectrogram, log-Mel spectrogram, Mel-frequency cepstral coefficients (MFCCs), and Delta MFCCs. Using these speech features, four deep-learning models were trained: ResNet-50, 1D-CNN, 2D-CNN, and a vision transformer. A performance comparison of speech feature-extraction methods and models indicated that MFCCs + Delta MFCCs was the best for both sexes when trained on the 1D-CNN model; it achieved an accuracy of 88.16% for males and 81.95% for females. The results of this study are expected to contribute to the future development of Korean speaker-recognition systems.","2025-02","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","3","15","","","","","","","","","","English","","","","WOS:001418481400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","age prediction; CLASSIFICATION; convolutional neural network; MFCC; SPEAKER AGE; speaker recognition; vision transformer; voice feature extraction; WOMEN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PINND6AD","journalArticle","2022","Liu, D; Chen, LX; Wang, LF; Wang, ZY","A multi-modal emotion fusion classification method combined expression and speech based on attention mechanism","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-021-11260-w","","This paper researches how to use attention mechanism to fuse the time series information of facial expression and speech, and proposes a multi-modal feature fusion emotion recognition model based on attention mechanism. First, facial expression features and speech features are extracted. Facial expression feature extraction, based on C3D-LSTM hybrid model, can effectively obtain the temporal and spatial expression features in videos. For speech feature extraction, Mel Frequency Cepstral Coefficient (MFCC) is used for extracting the initial speech features, and convolution neural network is for further features. Then, a face and speech recognition method based on attention mechanism is proposed. Through the attention analysis of the fusion features, the proposed method can obtain the relationship between the features, so that the features without noise and with strong distinguishability obtain more weight, and reduce the weight of noisy features at the same time. Finally, this method is applied to face expression and speech fusion recognition. The experimental results show that the proposed multi-modal emotion classification model is better than those in other literatures in RML dataset, with an average recognition rate of up to 81.18%.","2022-12","2025-02-26 20:37:01","2025-02-26 20:37:01","","41677-41695","","29","81","","","","","","","","","","English","","","","WOS:000682496300004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;16</p>","","","Attention mechanism; Feature fusion; Mel Frequency Cepstral Coefficient (MFCC); Multi-modal emotion classification; Spatiotemporal emotional characteristics; Speech features","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CBH88UE8","journalArticle","2024","Wu, ZX; Lam, C; To, CKS","Spontaneous Generation of Unconventional Language and Its Link with Grammatical Performance in Chinese Adults With and Without ASD","JOURNAL OF AUTISM AND DEVELOPMENTAL DISORDERS","","0162-3257","10.1007/s10803-024-06415-1","","This study investigated the generation of unconventional language in the spontaneous speech of Chinese adults with autism spectrum disorder (ASD), and how it was related to their grammatical performance, when compared to neurotypical (NT) controls. Twenty Cantonese-speaking adults with ASD and 20 NT controls completed three interview tasks in the Autism Diagnostic Observation Schedule, Second Edition (ADOS-2), and their spontaneous speech was recorded and transcribed. Utterances containing unconventional language (neologisms, idiosyncratic phrases, and pedantic language), morphosyntactic errors, mean length of utterance (MLU), and mazes were computed. The ASD group produced more neologisms, idiosyncratic phrases, and pedantic language than the NT group and their grammatical difficulties were shown in shorter MLU but not morphosyntactic errors. Mazes were more frequent in the ASD than the NT group. While the use of unconventional language increased with MLU in the NT group, it correlated positively with mazes in the ASD group. Generation of unconventional language, particularly pedantic language, in Cantonese-speaking NT adults is linked to more advanced grammar, while it appears to be a common speech characteristic among autistic speakers regardless of individual grammatical performance.","2024-07-05","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","","","","","","","","","","","English","","","","WOS:001262874700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","ADOLESCENTS; Autism; CANTONESE; CHILDREN; DISORDERS; Grammar; HIGH-FUNCTIONING AUTISM; IMPAIRMENT; INDIVIDUALS; INHIBITORY CONTROL; INTERESTS; Language production; MORPHEMES; Morphosyntax; Unconventional language","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N7RJ7DZZ","journalArticle","2021","Meghanani, A; Anoop, CS; Ramakrishnan, AG","Recognition of Alzheimer's Dementia From the Transcriptions of Spontaneous Speech Using fastText and CNN Models","FRONTIERS IN COMPUTER SCIENCE","","2624-9898","10.3389/fcomp.2021.624558","","Alzheimer's dementia (AD) is a type of neurodegenerative disease that is associated with a decline in memory. However, speech and language impairments are also common in Alzheimer's dementia patients. This work is an extension of our previous work, where we had used spontaneous speech for Alzheimer's dementia recognition employing log-Mel spectrogram and Mel-frequency cepstral coefficients (MFCC) as inputs to deep neural networks (DNN). In this work, we explore the transcriptions of spontaneous speech for dementia recognition and compare the results with several baseline results. We explore two models for dementia recognition: 1) fastText and 2) convolutional neural network (CNN) with a single convolutional layer, to capture the n-gram-based linguistic information from the input sentence. The fastText model uses a bag of bigrams and trigrams along with the input text to capture the local word orderings. In the CNN-based model, we try to capture different n-grams (we use n = 2, 3, 4, 5) present in the text by adapting the kernel sizes to n. In both fastText and CNN architectures, the word embeddings are initialized using pretrained GloVe vectors. We use bagging of 21 models in each of these architectures to arrive at the final model using which the performance on the test data is assessed. The best accuracies achieved with CNN and fastText models on the text data are 79.16 and 83.33%, respectively. The best root mean square errors (RMSE) on the prediction of mini-mental state examination (MMSE) score are 4.38 and 4.28 for CNN and fastText, respectively. The results suggest that the n-gram-based features are worth pursuing, for the task of AD detection. fastText models have competitive results when compared to several baseline methods. Also, fastText models are shallow in nature and have the advantage of being faster in training and evaluation, by several orders of magnitude, compared to deep models.","2021-03-24","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","3","","","","","","","","","","English","","","","WOS:000705870000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;18<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Alzheimer's; convolutional neural network; dementia; fastText; FEATURES; LANGUAGE; mini-mental state examination; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BRM8IEJE","journalArticle","2024","He, R; Al-Tamimi, J; Sanchez-Benavides, G; Montana-Valverde, G; Gispert, JD; Grau-Rivera, O; Suarez-Calvet, M; Minguillon, C; Fauria, K; Navarro, A; Hinzen, W","Atypical cortical hierarchy in Aß-positive older adults and its reflection in spontaneous speech","BRAIN RESEARCH","","0006-8993","10.1016/j.brainres.2024.148806","","Abnormal deposition of A beta amyloid is an early neuropathological marker of Alzheimer's disease (AD), arising long ahead of clinical symptoms. Non-invasive measures of associated early neurofunctional changes, together with easily accessible behavioral readouts of these changes, could be of great clinical benefit. We pursued this aim by investigating large-scale cortical gradients of functional connectivity with functional MRI, which capture the hierarchical integration of cortical functions, together with acoustic-prosodic features from spontaneous speech, in cognitively unimpaired older adults with and without A beta positivity (total N = 188). We predicted distortions of the cortical hierarchy associated with prosodic changes in the A beta + group. Results confirmed substantially altered cortical hierarchies and less variability in these in the A beta + group, together with an increase in quantitative prosodic measures, which correlated with gradient variability as well as digit span test scores. Overall, these findings confirm that long before the clinical stage and objective cognitive impairment, increased risk of cognitive decline as indexed by A beta accumulation is marked by neurofunctional changes in the cortical hierarchy, which are related to automatically extractable speech patterns and alterations in working memory functions.","2024-05-01","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","1830","","","","","","","","","","English","","","","WOS:001205471100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","A beta amyloid; Cognitive decline; COGNITIVE DECLINE; Cortical gradient; DEFAULT-MODE NETWORK; Dementia; DEMENTIA; Functional connectivity; LANGUAGE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HNK8NTH7","journalArticle","2023","Gallagher, G","The phonetic realization of the plain uvular/q/in a variety of South Bolivian Quechua","JOURNAL OF THE INTERNATIONAL PHONETIC ASSOCIATION","","0025-1003","10.1017/S0025100322000135","","This paper presents an acoustic description of the production of the plain uvular /q/ in the speech of eight speakers of South Bolivian Quechua. While this sound patterns phonologically as a stop, its primary realization is as a voiced continuant. Variation is documented with respect to segmental and prosodic position. Segmentally, a voiced continuant is the most common realization intervocalically and after a rhotic, while a voiceless continuant is comparatively more frequent after a voiceless sibilant, and voiced stops are most common after a nasal. In post-pausal position, voiced continuant productions are still attested and are particularly common for certain speakers, suggesting that this sound category has been reanalyzed as a continuant. For other speakers, voiceless stop productions are common or preferred in post-pausal position, reflecting a standard prosodically conditioned lenition pattern. Interestingly, voiced stops also show increased frequency in post-pausal position. The production of the plain uvular is analyzed in spontaneous speech collected in an interview format, as well as in scripted speech from a word list task. A second analysis compares the realization of /q/ to the other three stops /p t k/ in the language in spontaneous speech, and finds significantly more continuant productions for /q/.","2023-12","2025-02-26 20:37:01","2025-02-26 20:37:01","","869-887","","3","53","","","","","","","","","","English","","","","WOS:000867448400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","CONTRASTS; LENITION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9B8936QI","journalArticle","2022","Zhang, SQ; Zhao, XM; Tian, Q","Spontaneous Speech Emotion Recognition Using Multiscale Deep Convolutional LSTM","IEEE TRANSACTIONS ON AFFECTIVE COMPUTING","","1949-3045","10.1109/TAFFC.2019.2947464","","Recently, emotion recognition in real sceneries such as in the wild has attracted extensive attention in affective computing, because existing spontaneous emotions in real sceneries are more challenging and difficult to identify than other emotions. Motivated by the diverse effects of different lengths of audio spectrograms on emotion identification, this paper proposes a multiscale deep convolutional long short-term memory (LSTM) framework for spontaneous speech emotion recognition. Initially, a deep convolutional neural network (CNN) model is used to learn deep segment-level features on the basis of the created image-like three channels of spectrograms. Then, a deep LSTM model is adopted on the basis of the learned segment-level CNN features to capture the temporal dependency among all divided segments in an utterance for utterance-level emotion recognition. Finally, different emotion recognition results, obtained by combining CNN with LSTM at multiple lengths of segment-level spectrograms, are integrated by using a score-level fusion strategy. Experimental results on two challenging spontaneous emotional datasets, i.e., the AFEW5.0 and BAUM-1s databases, demonstrate the promising performance of the proposed method, outperforming state-of-the-art methods.","2022-04","2025-02-26 20:37:01","2025-02-26 20:37:01","","680-688","","2","13","","","","","","","","","","English","","","","WOS:000804643000010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;62<br/>Total Times Cited:&nbsp;&nbsp;66<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Acoustics; CLASSIFICATION; convolutional neural networks; Emotion recognition; Feature extraction; FEATURES; Image segmentation; LSTM; multiscale; Neural networks; NEURAL-NETWORK; Spectrogram; Speech emotion recognition; Speech recognition; WILD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JYWY2NGB","journalArticle","2023","Thomas, JB; Shihabudheen, KV","Neural architecture search algorithm to optimize deep Transformer model for fault detection in electrical power distribution systems","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2023.105890","","This paper proposes a neural architecture search algorithm for obtaining an optimum Transformer model to detect and localize different power system faults and uncertain conditions, such as symmetrical shunt faults, unsymmetrical shunt faults, high-impedance faults, switching conditions (capacitor switching, load switching, transformer switching, DG switching and feeder switching), insulator leakage and transformer inrush current in a distribution system. The Transformer model was proposed to tackle the high memory consumption of the deep CNN attention models and the long-term dependency problem of the RNN attention models. There exist different types of attention mechanisms and feedforward networks for designing a Transformer architecture. Hand engineering of these layers can be inefficient and time-consuming. Therefore, this paper makes use of the Differential Architecture Search (DARTS) algorithm to automatically generate optimal Transformer architectures with less search time cost. The algorithm achieves this by making the search process differentiable to architecture hyperparameters thus making the network search process an end-to-end problem. The proposed model attempts to automatically detect faults in a bus using current measurements from distant monitoring points. The proposed fault analysis was conducted on the standard IEEE 14 bus distribution system and the VSB power line fault detection database. The proposed model was found to produce better performance on the test database when evaluated using F1-Score (99.4% for fault type classification and 97.7% for fault location classification), Matthews Correlation Coefficient (MCC) (99.3% for fault type classification and 97.6% for fault location classification), accuracy and Area Under the Curve (AUC). The architecture transferability of the proposed method was also studied using real-world power line data for fault detection.","2023-04","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","120","","","","","","","","","","English","","","","WOS:000963617700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;16<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","ATTENTION MECHANISM; CLASSIFICATION; Deep learning; Fault detection; LOCATION; MICROGRIDS; NETWORK; Power distribution system; PREDICTION; SCHEME; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VLE54AI8","journalArticle","2023","Sato, M; Moriyama, M; Fukumoto, T; Yamada, T; Wake, T; Nakagomi, R; Nakatsuka, T; Minami, T; Uchino, K; Enooku, K; Nakagawa, H; Shiina, S; Koike, K; Fujishiro, M; Tateishi, R","Development of a transformer model for predicting the prognosis of patients with hepatocellular carcinoma after radiofrequency ablation","HEPATOLOGY INTERNATIONAL","","1936-0533","10.1007/s12072-023-10585-y","","Introduction Radiofrequency ablation (RFA) is a widely accepted, minimally invasive treatment modality for patients with hepatocellular carcinoma (HCC). Accurate prognosis prediction is important to identify patients at high risk for cancer progression/recurrence after RFA. Recently, state-of-the-art transformer models showing improved performance over existing deep learning- based models have been developed in several fields. This study was aimed at developing and validating a transformer model to predict the overall survival in HCC patients with treated by RFA. Methods We enrolled a total of 1778 treatment-naive HCC patients treated by RFA as the first-line treatment. We developed a transformer-based machine learning model to predict the overall survival in the HCC patients treated by RFA and compared its predictive performance with that of a deep learning-based model. Model performance was evaluated by determining the Harrel's c-index and validated externally by the split-sample method. Results The Harrel's c-index of the transformer-based model was 0.69, indicating its better discrimination performance than that of the deep learning model (Harrel's c-index, 0.60) in the external validation cohort. The transformer model showed a high discriminative ability for stratifying the external validation cohort into two or three different risk groups (p < 0.001 for both risk groupings). The model also enabled output of a personalized cumulative recurrence prediction curve for each patient. Conclusions We developed a novel transformer model for personalized prediction of the overall survival in HCC patients after RFA treatment. The current model may offer a personalized survival prediction schema for patients with HCC undergoing RFA treatment.","2023-09-09","2025-02-26 20:37:01","2025-02-26 20:37:01","","","","","","","","","","","","","","","English","","","","WOS:001064984800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Hepatocellular carcinoma; LIVER; Prognosis; Radiofrequency ablation; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IZZGS6BT","journalArticle","2022","Hu, YW; Buehler, MJ","End-to-End Protein Normal Mode Frequency Predictions Using Language and Graph Models and Application to Sonification","ACS NANO","","1936-0851","10.1021/acsnano.2c07681","","The prediction of mechanical and dynamical properties of proteins is an important frontier, especially given the greater availability of proteins structures. Here we report a series of models that provide end-to-end predictions of nanodynamical properties of proteins, focused on high-throughput normal mode predictions directly from the amino acid sequence. Using neural network models within the family of Natural Language Processing and graph-based methods, we offer atomistically based mechanistic predictions of key protein mechanical features. The models include an end-to-end long short-term memory (LSTM) model, an end-to-end transformer model, a graph-based transformer model, and an equivariant graph neural network. All four models show exceptional performance, with the graph-based transformer architecture offering the best results but at the cost of requiring a graph structure as input. Conversely, the LSTM and transformer models offer end-to-end sequence to-property prediction capabilities, providing efficient avenues for protein engineering, analysis, and design. We compare our results against published data based on a Principal Neighborhood Aggregation graph neural network, revealing that the transformer model offers better performance while also being able to predict a large set of the first 64 normal mode frequencies, simultaneously. The use of the end-to-end transformer model may facilitate other downstream applications through the use of transfer learning, and it offers a comprehensive prediction of dynamical properties without any structural knowledge, directly from the amino acid sequence. We demonstrate a potential application in scientific sonification, where the normal mode frequencies are transposed to generate audible signals for a detailed analysis of subtle changes of protein sequences.","2022-11-23","2025-02-26 20:37:01","2025-02-26 20:37:01","","20656-20670","","12","16","","","","","","","","","","English","","","","WOS:000890879000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","ARTIFICIAL-INTELLIGENCE; attention models; Biomaterials; deep learning; DESIGN; materiomics; mechanics; MINIMIZATION; proteins; SPIKE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K48CCX9L","journalArticle","2025","Saeed, F; Rehman, A; Shah, HA; Diyan, M; Chen, J; Kang, JM","SmartFormer: Graph-based transformer model for energy load forecasting","SUSTAINABLE ENERGY TECHNOLOGIES AND ASSESSMENTS","","2213-1388","10.1016/j.seta.2024.104133","","Electric load forecasting is a pivotal component in the power industry, providing essential intelligence for optimizing smart grid operations. Energy load data, inherently characterized as a multivariate time series, is influenced by various interdependent factors such as weather conditions, economic activity, and seasonal variations, all of which significantly impact the overall load dynamics. Though deep learning techniques, particularly with transformer-based models, have achieved significant progress in forecasting time series data, a gap exists in adequately acknowledging the importance of inter-series dependencies in multi-series load data. This paper proposes a novel graph-nested transformer model to effectively capture inter-series dependencies and forecast the load using a graph structure. The proposed Transformer model addresses two primary challenges: efficiently representing various temporal patterns and reducing redundant information within the series. In the proposed model, the graph neural network components are seamlessly integrated into the Transformer layers, allowing for the fusion of sequence encoding and graph aggregation in an iterative workflow. Evaluations across four distinct datasets demonstrate the superiority of the proposed model over state-of-the-art techniques in power load forecasting.","2025-01","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","73","","","","","","","","","","English","","","","WOS:001391634100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Graph neural network; Load forecasting; Power industry; Self-attention; Smart grid; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"26VUTCPZ","journalArticle","2022","Zhou, ML; Xing, ZH; Nie, C; Shi, ZG; Hou, B; Fu, K","Accurate Prediction of Tunnel Face Deformations in the Rock Tunnel Construction Process via High-Granularity Monitoring Data and Attention-Based Deep Learning Model","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app12199523","","Monitoring and predicting the deformation of surrounding rocks in the rock tunnel construction process is of great significance. This study implemented a wireless sensor network (WSN), including gateway transmission, relay point, and sensor nodes, to obtain high granularity deformation data during construction. A transformer model is proposed, which considers the construction sequence into the positional embedding and has an attention module to deeply learn the high dimensionality correlation between the nearby deformation data and the tunnel face deformation. The attention-enhanced LSTM model and the LSTM model are also constructed to compare them with the performance of the transformer model. A site study conducted on a shallow buried tunnel section suggested an excellent performance of the proposed WSN system. The transformer model shows the best performance in terms of the model prediction results, which can extract more information from the time sequence data than the attention-enhanced LSTM and LSTM models. The proposed system has great value as guidance and reference for the construction of rock tunnel projects in complex and unfavourable geological conditions.","2022-10","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","19","12","","","","","","","","","","English","","","","WOS:000866609300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","attention module; deep learning model; rock tunnel construction; tunnel face deformation; tunnel monitoring; UNDERGROUND SPACE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MXCQDFE3","journalArticle","2021","Gao, M; Zhang, WF","Power transmission line anomaly detection scheme based on CNN-transformer model","INTERNATIONAL JOURNAL OF GRID AND UTILITY COMPUTING","","1741-847X","10.1504/IJGUC.2021.119565","","The anomaly of power transmission lines has resulted in the failure of power delivery system, which brings about tremendous loss for the economy and industry. The wider distribution of power delivery system has imposed huge challenges on monitoring and making response to the anomaly cases in a short time. In this work, we introduce an autonomous anomaly detection system by exploiting the Computer Vision (CV) and Internet of Thing (IoT) techniques. At the first step, we design and develop an IoT sensor that can detect and feedback physical conditions around the power tower. Once the anomaly situation occurs, the on-site image acquisition is carried out by drones. To simplify the construction of image analysis pipelines while maintaining high accuracy, we adopt the State-of-The-Art (SOTA) cascaded Convolutional Neural Network (CNN)-transformer model. According to our experiment results, the CNN-transformer model is able to provide promising performance for anomaly detection of power lines, achieving higher average precision while consuming almost the same computing resources. The proposed anomaly detection scheme is of importance for realising large-scale and autonomous anomaly detection for power lines.","2021","2025-02-26 20:37:02","2025-02-26 20:37:02","","388-395","","4","12","","","","","","","","","","English","","","","WOS:000728873100004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","anomaly detection; computer vision; IoT sensor; neural network; power automation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8E9Y7D3X","journalArticle","2024","Lu, ZL; Liu, T; Ni, YW; Liu, HY; Guan, LN","ChoroidSeg-ViT: A Transformer Model for Choroid Layer Segmentation Based on a Mixed Attention Feature Enhancement Mechanism","TRANSLATIONAL VISION SCIENCE & TECHNOLOGY","","2164-2591","10.1167/tvst.13.9.7","","Purpose: To develop a Vision Transformer (ViT) model based on the mixed attention feature enhancement mechanism, ChoroidSeg-ViT, for choroid layer segmentation in optical coherence tomography (OCT) images. Methods: This study included a dataset of 100 OCT B-scans images. Ground truths were carefully labeled by experienced ophthalmologists. An end-to-end local-enhanced Transformer model, ChoroidSeg-ViT, was designed to segment the choroid layer by integrating the local enhanced feature extraction and semantic feature fusion paths. Standard segmentation metrics were selected to evaluate ChoroidSeg-ViT. Results: Experimental results demonstrate that ChoroidSeg-ViT exhibited superior segmentation performance (mDice: 98.31, mIoU: 96.62, mAcc: 98.29) compared to other deep learning approaches, thus indicating the effectiveness and superiority of this proposed model for the choroid layer segmentation task. Furthermore, ablation and generalization experiments validated the reasonableness of the module design. Conclusions: We developed a novel Transformer model to precisely and automatically segment the choroid layer and achieved the state-of-the-art performance. Translational Relevance: ChoroidSeg-ViT could segment precise and smooth choroid layers and form the basis of an automatic choroid analysis system that would facilitate future choroidal research in ophthalmology.","2024-09","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","9","13","","","","","","","","","","English","","","","WOS:001340164700005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","choroid layer segmentation; deep learning; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XM943V3P","journalArticle","2022","Liu, LB; Perez-Concha, O; Nguyen, A; Bennett, V; Jorm, L","Hierarchical label-wise attention transformer model for explainable ICD coding","JOURNAL OF BIOMEDICAL INFORMATICS","","1532-0464","10.1016/j.jbi.2022.104161","","International Classification of Diseases (ICD) coding plays an important role in systematically classifying morbidity and mortality data. In this study, we propose a hierarchical label-wise attention Transformer model (HiLAT) for the explainable prediction of ICD codes from clinical documents. HiLAT firstly fine-tunes a pretrained Transformer model to represent the tokens of clinical documents. We subsequently employ a two-level hierarchical label-wise attention mechanism that creates label-specific document representations. These representations are in turn used by a feed-forward neural network to predict whether a specific ICD code is assigned to the input clinical document of interest. We evaluate HiLAT using hospital discharge summaries and their corresponding ICD-9 codes from the MIMIC-III database. To investigate the performance of different types of Transformer models, we develop ClinicalplusXLNet, which conducts continual pretraining from XLNet-Base using all the MIMIC-III clinical notes. The experiment results show that the F1 scores of the HiLAT + ClinicalplusXLNet outperform the previous state-of-the-art models for the top-50 most frequent ICD-9 codes from MIMIC-III. Visualisations of attention weights present a potential explainability tool for checking the face validity of ICD code predictions.","2022-09","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","133","","","","","","","","","","English","","","","WOS:000847355000004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Explainability; Hierarchical label-wise attention; ICD coding; MIMIC-III; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PD2282HL","journalArticle","2024","Dong, GQ; Li, WR; Dong, ZZ; Wang, C; Qian, SH; Zhang, TY; Ma, XL; Zou, L; Lin, KZ; Liu, ZX","Enhancing Dynagraph Card Classification in Pumping Systems Using Transfer Learning and the Swin Transformer Model","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14041657","","Featured Application The developed prototype provides a more efficient and accurate solution for classifying dynagraph cards, meeting the requirements of oil field operations and enhancing economic benefits and work efficiency.Abstract The dynagraph card plays a crucial role in evaluating oilfield pumping systems' performance. Nevertheless, classifying dynagraph cards can be quite difficult because certain operating conditions may exhibit similar patterns. Conventional classification approaches mainly involve labor-intensive manual analysis of these cards, leading to subjectivity, prolonged processing times, and vulnerability to human prejudices. In response to this challenge, our study introduces a novel approach that leverages transfer learning and the Swin Transformer model for classifying dynagraph cards across various operating conditions in rod pumping systems. Initially, the Swin Transformer model undergoes pre-training using the ImageNet-22k dataset. Subsequently, we fine-tune the model's weights using actual dynagraph card datasets, facilitating direct classification analysis with dynagraph cards as input variables. The adoption of transfer learning significantly reduces the training time while enhancing the accuracy of condition diagnosis. To assess the effectiveness of our proposed method, we conducted a comparative evaluation against conventional models like ResNet50, DenseNet121, LeNet, and ViT. The findings demonstrate that our approach outperforms other methods, achieving an accuracy of 96%, thereby improving classification accuracy by 3-4%. Therefore, our approach, based on transfer learning and the Swin Transformer model, provides a better solution for practical problems involving similar dynagraph cards. It meets the requirements of oil field operations, enhancing economic benefits and work efficiency.","2024-02","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","4","14","","","","","","","","","","English","","","","WOS:001168336000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","convolutional neural network; CONVOLUTIONAL NEURAL-NETWORKS; CURVE; dynagraph card; rod pump; self-attention; swin transformer; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"693FSDFP","journalArticle","2024","Long, ZC; Fan, SD; Gao, Q; Wei, W; Jiang, P","Replacement of Fault Sensor of Cutter Suction Dredger Mud Pump Based on MCNN Transformer","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14104186","","The mud pump water sealing system (MPWSS) is important in the efficient operation and prolonged service life of the cutter suction dredger's (CSD) mud pump. Considering that the underwater pump operates underwater and the shaft seal water pressure sensor is prone to failure, a hybrid deep learning model MCNN transformer is proposed to predict the underwater pump shaft seal water pressure in the event of sensor failure. This paper uses big data from the dredging project to deeply excavate the relationship between the shaft end sealing water pressure and other construction data by combining experience and artificial intelligence, and then uses multi-scale convolutional neural network (MCNN) to reconstruct the data, highlighting the time series characteristics of the multi-scale data were then input into the transformer model for prediction, and compared with a single MCNN, transformer model and four other neural networks. Finally, the cutter suction dredger ""Hua An Long"" was selected as an application research case; experimental comparisons were conducted on seven different models to verify the accuracy and applicability of the MCNN-transformer model.","2024-05","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","10","14","","","","","","","","","","English","","","","WOS:001234148100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","cutter suction dredger; MCNN-transformer; mud pump water sealing system; shaft seal water pressure prediction; WEAR","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NB8CNWSM","journalArticle","2025","Zheng, SG; Guo, CH; Tu, DB; Xu, JP; Weng, SZ; Zhu, GQ","Spectral super-resolution for high-accuracy rice variety classification using hybrid CNN-Transformer model","JOURNAL OF FOOD COMPOSITION AND ANALYSIS","","0889-1575","10.1016/j.jfca.2024.106891","","Rice variety classification is crucial for ensuring the purity and quality of rice production. In this study, hyperspectral images (HSI) of rice varieties were reconstructed using a spectral super-resolution technique, serving as a basis for an enhanced classification process. RGB images of various rice varieties were utilized to reconstruct the HSI, and a hybrid CNN-Transformer model featuring an efficient feature fusion module aimed at reducing redundancy was developed. Building on the spectral super-resolution model, a Swin-Transformer model was employed for rice variety classification, chosen for its capacity to effectively handle high-dimensional data with fewer parameters and lower FLOPs. The classification accuracy based on actual HSI reached an impressive 99.961 %, while the accuracy based on reconstructed HSI was a close 99.413 %. These results demonstrate that the spectral super-resolution method not only effectively reconstructs HSI images of rice varieties but also supports highly reliable classification. It is indicated by the study that spectral super-resolution can significantly outperform advanced CNN and Transformer-based methods in terms of accuracy and computational efficiency, offering a promising approach for precise rice variety classification and potentially other agricultural applications.","2025-01","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","137","","","","","","","","","","English","","","","WOS:001359162400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","RGB; Rice variety classification; SEEDS; Spectral super-resolution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VMCDAHKM","journalArticle","2021","Debnath, S; Roy, P","Audio-Visual Automatic Speech Recognition Using PZM, MFCC and Statistical Analysis","INTERNATIONAL JOURNAL OF INTERACTIVE MULTIMEDIA AND ARTIFICIAL INTELLIGENCE","","1989-1660","10.9781/ijimai.2021.09.001","","Audio-Visual Automatic Speech Recognition (AV-ASR) has become the most promising research area when the audio signal gets corrupted by noise. The main objective of this paper is to select the important and discriminative audio and visual speech features to recognize audio-visual speech. This paper proposes Pseudo Zernike Moment (PZM) and feature selection method for audio-visual speech recognition. Visual information is captured from the lip contour and computes the moments for lip reading. We have extracted 19th order of Mel Frequency Cepstral Coefficients (MFCC) as speech features from audio. Since all the 19 speech features are not equally important, therefore, feature selection algorithms are used to select the most efficient features. The various statistical algorithm such as Analysis of Variance (ANOVA), Kruskal-wallis, and Friedman test are employed to analyze the significance of features along with Incremental Feature Selection (IFS) technique. Statistical analysis is used to analyze the statistical significance of the speech features and after that IFS is used to select the speech feature subset. Furthermore, multiclass Support Vector Machine (SVM), Artificial Neural Network (ANN) and Naive Bayes (NB) machine learning techniques are used to recognize the speech for both the audio and visual modalities. Based on the recognition rate combined decision is taken from the two individual recognition systems. This paper compares the result achieved by the proposed model and the existing model for both audio and visual speech recognition. Zernike Moment (ZM) is compared with PZM and shows that our proposed model using PZM extracts better discriminative features for visual speech recognition. This study also proves that audio feature selection using statistical analysis outperforms methods without any feature selection technique.","2021-12","2025-02-26 20:37:02","2025-02-26 20:37:02","","121-133","","2","7","","","","","","","","","","English","","","","WOS:000724919200012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","ANOVA; Audio-visual Speech Recognition; CLASSIFICATION; ENHANCEMENT; FEATURE-SELECTION; Incremental Feature Selection (IFS); Lip Tracking; Mel Frequency Cepstral Coefficients (MFCC); Pseudo Zernike Moment; Statistical Analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PY9JFK7J","journalArticle","2024","Bing, QC; Zhao, PP; Ren, CZ; Wang, XQ; Zhao, YM","Short-Term Traffic Flow Forecasting Method Based on Secondary Decomposition and Conventional Neural Network-Transformer","SUSTAINABILITY","","2071-1050","10.3390/su16114567","","Because of the random volatility of traffic data, short-term traffic flow forecasting has always been a problem that needs to be further researched. We developed a short-term traffic flow forecasting approach by applying a secondary decomposition strategy and CNN-Transformer model. Firstly, traffic flow data are decomposed by using a Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN) algorithm, and a series of intrinsic mode functions (IMFs) are obtained. Secondly, the IMF1 obtained from the CEEMDAN is further decomposed into some sub-series by using Variational Mode Decomposition (VMD) algorithm. Thirdly, the CNN-Transformer model is established for each IMF separately. The CNN model is employed to extract local spatial features, and then the Transformer model utilizes these features for global modeling and long-term relationship modeling. Finally, we obtain the final results by superimposing the forecasting results of each IMF component. The measured traffic flow dataset of urban expressways was used for experimental verification. The experimental results reveal the following: (1) The forecasting performance achieves remarkable improvement when considering secondary decomposition. Compared with the VMD-CNN-Transformer, the CEEMDAN-VMD-CNN-Transformer method declined by 25.84%, 23.15% and 22.38% in three-step-ahead forecasting in terms of MAPE. (2) It has been proven that our proposed CNN-Transformer model could achieve more outstanding forecasting performance. Compared with the CEEMDAN-VMD-CNN, the CEEMDAN-VMD-CNN-Transformer method declined by 13.58%, 11.88% and 11.10% in three-step-ahead forecasting in terms of MAPE.","2024-06","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","11","16","","","","","","","","","","English","","","","WOS:001245355700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","CEEMDAN-VMD; CNN-Transformer; MODEL; PREDICTION; secondary decomposition; short-term traffic flow forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RLCB5DSY","journalArticle","2022","Riad, R; Lunven, M; Titeux, H; Cao, XN; Bagnou, JH; Lemoine, L; Montillot, J; Sliwinski, A; Youssov, K; de Langavant, LC; Dupoux, E; Bachoud-Lévi, AC","Predicting clinical scores in Huntington's disease: a lightweight speech test","JOURNAL OF NEUROLOGY","","0340-5354","10.1007/s00415-022-11148-1","","Objectives Using brief samples of speech recordings, we aimed at predicting, through machine learning, the clinical performance in Huntington's Disease (HD), an inherited Neurodegenerative disease (NDD). Methods We collected and analyzed 126 samples of audio recordings of both forward and backward counting from 103 Huntington's disease gene carriers [87 manifest and 16 premanifest; mean age 50.6 (SD 11.2), range (27-88) years] from three multicenter prospective studies in France and Belgium (MIG-HD (ClinicalTrials.gov NCT00190450); BIO-HD (ClinicalTrials.gov NCT00190450) and Repair-HD (ClinicalTrials.gov NCT00190450). We pre-registered all of our methods before running any analyses, in order to avoid inflated results. We automatically extracted 60 speech features from blindly annotated samples. We used machine learning models to combine multiple speech features in order to make predictions at individual levels of the clinical markers. We trained machine learning models on 86% of the samples, the remaining 14% constituted the independent test set. We combined speech features with demographics variables (age, sex, CAG repeats, and burden score) to predict cognitive, motor, and functional scores of the Unified Huntington's disease rating scale. We provided correlation between speech variables and striatal volumes. Results Speech features combined with demographics allowed the prediction of the individual cognitive, motor, and functional scores with a relative error from 12.7 to 20.0% which is better than predictions using demographics and genetic information. Both mean and standard deviation of pause durations during backward recitation and clinical scores correlated with striatal atrophy (Spearman 0.6 and 0.5-0.6, respectively). Interpretation Brief and examiner-free speech recording and analysis may become in the future an efficient method for remote evaluation of the individual condition in HD and likely in other NDD.","2022-09","2025-02-26 20:37:02","2025-02-26 20:37:02","","5008-5021","","9","269","","","","","","","","","","English","","","","WOS:000795517700002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","ACOUSTIC ANALYSIS; BATTERY; Huntington's disease; LANGUAGE; Machine learning; MOTOR; PREMANIFEST; RELIABILITY; SAMPLE; Speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AQGALEAQ","journalArticle","2022","Zhu, M","The Application of Intelligent Speech Analysis Technology in the Spoken English Language Learning Model","MOBILE INFORMATION SYSTEMS","","1574-017X","10.1155/2022/3192892","","In order to improve the effect of spoken English processing, it is necessary to improve the spoken English processing technology from the perspective of the characteristics of spoken English, combined with intelligent algorithms. This paper combines the intelligent speech analysis technology to improve the spoken English recognition technology and combines the actual and needs of English learning to improve the system algorithm. Moreover, this paper combines the intelligent speech analysis to construct the intelligent spoken English learning model structure and combines the statistical method and the intelligent evaluation method to analyze the model effect. After obtaining the system function structure, this paper designs experiments to verify the effect of the model proposed in this paper. From the experimental analysis results, it can be seen that the intelligent English speech analysis model proposed in this paper can play an important role in the learning of spoken English.","2022-05-09","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","2022","","","","","","","","","","English","","","","WOS:000815805000009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","CONVOLUTIONAL NEURAL-NETWORKS; RECOGNITION; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GJ6K2Z4T","journalArticle","2025","Waisbren, SE; Norel, R; Agurto, C; Singh, S; Connor, ZA; Ebrahim, MG; Cecchi, GA","Beyond neuropsychological tests: AI speech analysis in PKU","JOURNAL OF INHERITED METABOLIC DISEASE","","0141-8955","10.1002/jimd.12831","","Phenylketonuria (PKU) is a rare inherited metabolic disorder characterized by toxic phenylalanine (Phe) concentrations in blood and brain. State-of-the-art analyses of speech detected a dimension of verbal discourse providing insights that extend beyond those captured by existing paradigms to measure performance associated with biochemical markers in PKU. The Cookie Theft Picture Task provided a standardized stimulus for eliciting spontaneous speech from 42 adults with PKU and 41 adults without PKU. Subtests measuring language and memory from the Wechsler Adult Intelligence Scale-Fourth Edition showed no differences between the groups and no correlations with biomarkers in PKU. In contrast, AI analyses of responses to the Cookie Theft Task revealed significant differences between the PKU and non-PKU groups on 23 linguistic features. Using multidimensional scaling (MDS), these features were aggregated into a single quantifiable Dimension 1 that significantly correlated with biomarkers. When extreme examples of Dimension 1 were presented to chatGPT, the differences noted reflected attention to detail, clarity in word choice, expression cohesion, contextual awareness and emotion recognition. We subsequently defined Dimension 1 as Proficiency in Verbal Discourse. This novel measure elucidated discourse styles possibly associated with suboptimal achievement and learning disabilities, often reported in PKU. In summary, AI captured a characteristic associated with metabolic status undetectable through traditional neuropsychological measures. Future studies will expand upon this novel paradigm, leveraging speech AI to quantify meaningful aspects of everyday functioning and possibly provide information for management decisions. Once validated, this measure holds promise for extension to other rare diseases and incorporation into clinical trials.","2025-01","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","1","48","","","","","","","","","","English","","","","WOS:001379521300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","ADULTS; AI; CHILDREN; clinical trials; Cookie Theft Picture Task; DISCOURSE; IMPAIRMENTS; LANGUAGE; Natural Language Processing; phenylketonuria; PHENYLKETONURIA; Proficiency in Verbal Discourse; PROGRESSIVE APHASIA; SYMPTOMS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IQ77R8DQ","journalArticle","2024","Ma, QQ","Research on English-Chinese machine translation shift based on word vector similarity","ARTIFICIAL LIFE AND ROBOTICS","","1433-5298","10.1007/s10015-024-00964-5","","In English-Chinese machine translation shift, the processing of out-of-vocabulary (OOV) words has a great impact on translation quality. Aiming at OOV, this paper proposed a method based on word vector similarity, calculated the word vector similarity based on the Skip-gram model, used the most similar words to replace OOV in the source sentences, and used the replaced corpus to train the Transformer model. It was found that when the original corpus was used for training, the bilingual evaluation understudy-4 (BLEU-4) of the Transformer model on NIST2006 and NIST2008 was 37.29 and 30.73, respectively. However, when the word vector similarity was used for processing and low-frequency OOV words were retained, the BLEU-4 of the Transformer model on NIST2006 and NIST2008 was improved to 37.36 and 30.78 respectively, showing an increase. Moreover, the translation quality obtained by retaining low-frequency OOV words was better than that obtained by removing low-frequency OOV words. The experimental results prove that the English-Chinese machine translation shift method based on word vector similarity is reliable and can be applied in practice.","2024-11","2025-02-26 20:37:02","2025-02-26 20:37:02","","585-589","","4","29","","","","","","","","","","English","","","","WOS:001313537000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","English-Chinese translation; Machine translation; Word vector similarity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PB6EBNE6","journalArticle","2023","Liu, ZK; Chen, Y; Zhang, JW","Neural Machine Translation of Electrical Engineering Based on Integrated Convolutional Neural Networks","ELECTRONICS","","2079-9292","10.3390/electronics12173604","","Research has shown that neural machine translation performs poorly on low-resource and specific domain parallel corpora. In this paper, we focus on the problem of neural machine translation in the field of electrical engineering. To address the mistranslation caused by the Transformer model's limited ability to extract feature information from certain sentences, we propose two new models that integrate a convolutional neural network as a feature extraction layer into the Transformer model. The feature information extracted by the CNN is fused separately in the source-side and target-side models, which enhances the Transformer model's ability to extract feature information, optimizes model performance, and improves translation quality. On the dataset of the field of electrical engineering, the proposed source-side and target-side models improved BLEU scores by 1.63 and 1.12 percentage points, respectively, compared to the baseline model. In addition, the two models proposed in this paper can learn rich semantic knowledge without relying on auxiliary knowledge such as part-of-speech tagging and named entity recognition, which saves a certain amount of human resources and time costs.","2023-09","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","17","12","","","","","","","","","","English","","","","WOS:001061045200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","convolutional neural network; electrical engineering; feature information; low resource; neural machine translation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BRMM8ZG3","journalArticle","2024","Khan, ZA; Xia, YQ; Aurangzeb, K; Khaliq, F; Alam, M; Khan, JA; Anwar, MS","Emotion detection from handwriting and drawing samples using an attention-based transformer model","PEERJ COMPUTER SCIENCE","","2376-5992","10.7717/peerj-cs.1887","","Emotion detection (ED) involves the identification and understanding of an individual's emotional state through various cues such as facial expressions, voice tones, physiological changes, and behavioral patterns. In this context, behavioral analysis is employed to observe actions and behaviors for emotional interpretation. This work specifically employs behavioral metrics like drawing and handwriting to determine a person's emotional state, recognizing these actions as physical functions integrating motor and cognitive processes. The study proposes an attention-based transformer model as an innovative approach to identify emotions from handwriting and drawing samples, thereby advancing the capabilities of ED into the domains of fine motor skills and artistic expression. The initial data obtained provides a set of points that correspond to the handwriting or drawing strokes. Each stroke point is subsequently delivered to the attention-based transformer model, which embeds it into a high-dimensional vector space. The model builds a prediction about the emotional state of the person who generated the sample by integrating the most important components and patterns in the input sequence using self-attentional processes. The proposed approach possesses a distinct advantage in its enhanced capacity to capture long -range correlations compared to conventional recurrent neural networks (RNN). This characteristic makes it particularly well-suited for the precise identification of emotions from samples of handwriting and drawings, signifying a notable advancement in the field of emotion detection. The proposed method produced cutting-edge outcomes of 92.64% on the benchmark dataset known as EMOTHAW (Emotion Recognition via Handwriting and Drawing).","2024-03-29","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","10","","","","","","","","","","English","","","","WOS:001194752800004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Behavioral biometrics; Emotion detection; Emotional intelligence; Emotional state recognition; FUSION; Handwriting/Drawing analysis; Human-computer Interaction; STATE RECOGNITION; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BTF25UYH","journalArticle","2022","Pérez-Toro, PA; Arias-Vergara, T; Klumpp, P; Vásquez-Correa, JC; Schuster, M; Nöth, E; Orozco-Arroyave, JR","Depression assessment in people with Parkinson's disease: The combination of acoustic features and natural language processing","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2022.09.001","","Parkinson's disease produces motor impairments such as bradykinesia, rigidity, and different speech impair-ments, as same as non-motor symptoms like cognitive decline and depression disturbances. Most studies are focused on the analysis of motor symptoms, and only few works study non-motor impairments. Depression is one of the typical non-motor symptoms developed by many Parkinson's patients. Impairments in speech production together with depression produce negative effects in the communication capabilities and social interaction of patients. This study proposes a combination of speech analysis and natural language processing methods to extract features from spontaneous speech utterances and their transcripts. We consider state-of-the-art word-embedding methods like Bidirectional Encoder Representations from Transformer (BERT) to process the transcripts, and traditional acoustic features such as Bark band energies and Mel frequency cepstral coefficients to model the speech signals. The features are processed with supervectors generated by Gaussian Mixture Model-Universal Background Model (GMM-UBM) and Support Vector Machine (SVM) classifiers. The dataset consists of 60 Parkinson's patients divided into two classes according to the depression item of the MDS-UPDRS. The automatic classification of depressed and non-depressed Parkinson's patients showed F-scores of up to 0.77, which confirms that acoustic and linguistic information embedded in language production can be used for depression analysis in Parkinson's patients. We present one of the few studies that evaluates depression in Parkinson's patients considering the combination of acoustic and linguistic information.","2022-11","2025-02-26 20:37:02","2025-02-26 20:37:02","","10-20","","","145","","","","","","","","","","English","","","","WOS:000876462300002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","Acoustics analysis; AUDIO; Depression; DISORDERS; EMOTION RECOGNITION; MODELS; Natural language processing; Parkinson?s disease; PSYCHOMOTOR RETARDATION; QUALITY-OF-LIFE; SYMPTOMS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3SF68P8K","journalArticle","2022","Luptáková, ID; Kubovcík, M; Pospíchal, J","Wearable Sensor-Based Human Activity Recognition with Transformer Model","SENSORS","","1424-8220","10.3390/s22051911","","Computing devices that can recognize various human activities or movements can be used to assist people in healthcare, sports, or human-robot interaction. Readily available data for this purpose can be obtained from the accelerometer and the gyroscope built into everyday smartphones. Effective classification of real-time activity data is, therefore, actively pursued using various machine learning methods. In this study, the transformer model, a deep learning neural network model developed primarily for the natural language processing and vision tasks, was adapted for a time-series analysis of motion signals. The self-attention mechanism inherent in the transformer, which expresses individual dependencies between signal values within a time series, can match the performance of state-of-the-art convolutional neural networks with long short-term memory. The performance of the proposed adapted transformer method was tested on the largest available public dataset of smartphone motion sensor data covering a wide range of activities, and obtained an average identification accuracy of 99.2% as compared with 89.67% achieved on the same data by a conventional machine learning method. The results suggest the expected future relevance of the transformer model for human activity recognition.","2022-03","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","5","22","","","","","","","","","","English","","","","WOS:000769236300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;91<br/>Total Times Cited:&nbsp;&nbsp;95<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","human activity recognition; sequence-to-sequence prediction; time series; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VXB2KDW5","journalArticle","2024","Zou, Y; Wu, HC; Yin, YQ; Dhamotharan, L; Chen, DQ; Tiwari, AK","An improved transformer model with multi-head attention and attention to attention for low-carbon multi-depot vehicle routing problem","ANNALS OF OPERATIONS RESEARCH","","0254-5330","10.1007/s10479-022-04788-z","","Low-carbon logistics is an emerging and sustainable development industry in the era of a low-carbon economy. The end-to-end deep reinforcement learning (DRL) method with an encoder-decoder framework has been proven effective for solving logistics problems. However, in most cases, the recurrent neural networks (RNN) and attention mechanisms are used in encoders and decoders, which may result in the long-distance dependence problem and the neglect of the correlation between query vectors. To surround this problem, we propose an improved transformer model (TAOA) with both multi-head attention mechanism (MHA) and attention to attention mechanism (AOA), and apply it to solve the low-carbon multi-depot vehicle routing problem (MDVRP). In this model, the MHA and AOA are implemented to solve the probability of route nodes in the encoder and decoder. The MHA is used to process different parts of the input sequence, which can be calculated in parallel, and the AOA is used to deal with the deficiency problem of correlation between query results and query vectors in the MHA. The actor-critic framework based on strategy gradient is constructed to train model parameters. The 2opt operator is further used to optimize the resulting routes. Finally, extensive numerical studies are carried out to verify the effectiveness and operation efficiency of the proposed TAOA, and the results show that the proposed TAOA performs better in solving the MDVRP than the traditional transformer model (Kools), genetic algorithm (GA), and Google OR-Tools (Ortools).","2024-08","2025-02-26 20:37:02","2025-02-26 20:37:02","","517-536","","1-2","339","","","","","","","","","","English","","","","WOS:000813608200003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","End-to-end deep reinforcement learning; GA algorithm; Low-carbon multi-depot vehicle routing problem; Multi-head attention mechanism; Transformer model; VARIABLE NEIGHBORHOOD SEARCH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"APCPZHHZ","journalArticle","2024","Sun, YZ; Pang, SC; Zhang, YA; Zhang, JH","Application of the dynamic transformer model with well logging data for formation porosity prediction","PHYSICS OF FLUIDS","","1070-6631","10.1063/5.0193903","","Porosity, as a key parameter to describe the properties of rock reservoirs, is essential for evaluating the permeability and fluid migration performance of underground rocks. In order to overcome the limitations of traditional logging porosity interpretation methods in the face of geological complexity and nonlinear relationships, the Dynamic Transformer model in machine learning was introduced in this study, aiming to improve the accuracy and generalization ability of logging porosity prediction. Dynamic Transformer is a deep learning model based on the self-attention mechanism. Compared with traditional sequence models, Dynamic Transformer has a better ability to process time series data and is able to focus on different parts of the input sequence in different locations, so as to better capture global information and long-term dependencies. This is a significant advantage for logging tasks with complex geological structures and time series data. In addition, the model introduces Dynamic Convolution Kernels to increase the model coupling, so that the model can better understand the dependencies between different positions in the input sequence. The introduction of this module aims to enhance the model's ability to model long-distance dependence in sequences, thereby improving its performance. We trained the model on the well log dataset to ensure that it has good generalization ability. In addition, we comprehensively compare the performance of the Dynamic Transformer model with other traditional machine learning models to verify its superiority in logging porosity prediction. Through the analysis of experimental results, the Dynamic Transformer model shows good superiority in the task of logging porosity prediction. The introduction of this model will bring a new perspective to the development of logging technology and provide a more efficient and accurate tool for the field of geoscience.","2024-03","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","3","36","","","","","","","","","","English","","","","WOS:001187954900008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","CLASSIFICATION; LSTM; NEURAL-NETWORKS; PERMEABILITY; RESERVOIRS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3RKTCVL9","journalArticle","2025","Diao, L; Tao, M; Feng, FF","Optimization and imputation of acoustic absorption sequence prediction for transversely isotropic porous materials: A MultiScaleCNN-Transformer-PSO model approach","MEASUREMENT","","0263-2241","10.1016/j.measurement.2024.116098","","To address the limitations of traditional methods in real-time prediction and adaptive optimization of sound absorption coefficients for transversely isotropic porous materials. This study introduces a method combining a Multi-Scale Convolutional Neural Network (MultiScaleCNN) and a Transformer model to improve real-time prediction and optimization of sound absorption coefficients in transversely isotropic porous materials. Using a validated transfer matrix method based on the Biot model and acoustic analysis via COMSOL 6.2, a database of sound absorption curves was created. MultiScaleCNN extracts multi-scale features, which the Transformer model uses for sequence-to-sequence modeling with a self-attention mechanism, effectively managing complex dependencies. The model achieves high accuracy in full-mask prediction, closely aligning with actual values. Additionally, Particle Swarm Optimization (PSO) optimizes sound absorption coefficients in the 1000-2000 Hz range, meeting the fitness function's criteria. For partial-mask imputation, the model uses adjacent frequency data and features to enhance accuracy. Results show that the MultiScaleCNN-Transformer-PSO model offers a robust, data-driven approach for predicting and optimizing sound absorption coefficients, advancing the field.","2025-01","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","242","","","","","","","","","","English","","","","WOS:001351180300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Acoustic Absorption Coefficient; MultiScaleCNN; Particle Swarm Optimization; Transformer Model; Transversely Isotropic Porous Materials","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6VC4KWXJ","journalArticle","2024","Chen, JYF; Lin, K; Hu, LF; Zhang, P; Liu, LT; Pan, JJ; Li, ZY","Invisible track bed defect classification method based on distributed optical fiber sensing system and FFT Attention Transformer model","OPTICAL ENGINEERING","","0091-3286","10.1117/1.OE.63.3.031005","","An invisible track bed defect classification method based on distributed optical fiber sensing data acquisition and an attention Transformer model mechanism under the frequency domain is proposed. The vibration sensing data contain structural safety information of vehicles, rails, track beds, etc., covering the entire time period and entire track area of subway operation. To classify the invisible track bed defect rapidly and accurately, the original vibration signals are first reduced by down-sampling and envelope signal extraction. According to the regular characteristics of different types of signals, an fast Fourier transform (FFT) Attention Transformer (FFT-Attn-Transformer) sequence feature extraction architecture with a high recognition accuracy is proposed for model training. The results demonstrate that the accuracy, precision, recall rate, and F1-score are all above 98% using the proposed model, and the recognition accuracy of the defect test area is 99.47%, which has extremely high stability and accuracy, providing an innovative and feasible idea for the lack of effective monitoring scheme for invisible track bed defects.","2024-03-01","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","3","63","","","","","","","","","","English","","","","WOS:001230092500043","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","distributed optical fiber sensing; FBG ARRAY; frequency domain attention mechanism; invisible track bed defect; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KQXCE4BA","journalArticle","2022","Liu, D; Wang, GF; Yang, JL","Help Transformer Improve Performance in Automatic Mathematics Word Problem-Solving","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3220777","","Solving Mathematics Word Problem (MWP) is a basic ability of humanity, which can be mastered by most students at a young age. The existing artificial intelligence system is not good enough in numerical questions, like MWPs. The hard part of this problem is translating natural language sentences in MWP into mathematical expressions or equations. In recent researches, the Transformer network, which proved a great success in machine translation, is applied to automatic mathematic word problem-solving. While previous works have only shown the ability of Transformer model in MWP, how multiple factors such as encoding, decoding, and pre-training affect the performance of Transformer model has not received enough attention. The study is the first to examine the role of these factors experimentally. This paper proposes several methods to improve Transformer network performance in MWPs under the basis of previous studies, achieves higher accuracy compared to the previous state of the art. Pre-training on target tasks dataset improves the translation quality of the Transformer model greatly. Different token encoding and search algorithms also benefit prediction accuracy at the expense of more training and testing time.","2022","2025-02-26 20:37:02","2025-02-26 20:37:02","","123020-123027","","","10","","","","","","","","","","English","","","","WOS:000892892300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Arithmetic; Decoding; Machine translation; Mathematical models; Mathematics; mathematics word problem; Seq2Seq model; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SKJY8855","journalArticle","2021","Kawara, Y; Chu, CH; Arase, Y","Preordering Encoding on Transformer for Translation","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2020.3042001","","The difference in word orders between source and target languages is a serious hurdle for machine translation. Preordering methods, which reorder the words in a source sentence before translation to obtain a similar word ordering with a target language, significantly improve the quality in statistical machine translation. While the information on the preordering position improved the translation quality in recurrent neural network-based models, questions such as how to use preordering information and whether it is helpful for the Transformer model remain unaddressed. In this article, we successfully employed preordering techniques in the Transformer-based neural machine translation. Specifically, we proposed a novel preordering encoding that exploits the reordering information of the source and target sentences as positional encoding in the Transformer model. Experimental results on ASPEC Japanese-English and WMT 2015 English-German, English-Czech, and English-Russian translation tasks confirmed that the proposed method significantly improved the translation quality evaluated by the BLEU scores of the Transformer model 1.34 points in the Japanese-to-English task, 2.19 points in the English-to-German task, 0.15 points in the Czech-to-English task, and 1.48 points in the English-to-Russian task.","2021","2025-02-26 20:37:02","2025-02-26 20:37:02","","644-655","","","29","","","","","","","","","","English","","","","WOS:000608675900003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Neural machine translation; preordering; transformer; word-order","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"366ZY43D","journalArticle","2024","Dutta, K; Rehman, R; Sarmah, A","Analysis of Speech Features for Gender Identification in Tai Language","COMMUNICATIONS IN MATHEMATICS AND APPLICATIONS","","0976-5905","10.26713/cma.v15i1.2450","","The vast number of information packed into the human speech signal makes analysis atough undertaking. This intricacy is notably noticeable in tasks like speaker recognition, especiallywhen it comes to gender distinction. In this paper, we address this issue by conducting a thoroughexamination of the effectiveness of various speech features, namely Pitch, Formant Frequency, MFCC(Mel Frequency Cepstral Coefficients), and Chroma, in the context of gender identification in theTai Language, which is spoken by the Tai people of Assam. In this study, we use machine learning(SVM, KNN, Decision Tree, Neural Network) to analyze speech features (Pitch, Formant Frequency,MFCC, Chroma) for gender identification in the Tai language spoken by the Tai people of Assam. Ourresults show that MFCC consistently outperforms other features, delivering the highest accuracyrates across all approaches. This demonstrates MFCC's ability to extract gender information fromTai Language speech signals, suggesting more accurate gender identification systems. Beyond genderidentification, our study extends voice analysis in linguistics and improves the application of spokenlanguage data, allowing for improved communication systems and linguistic insights. In summary,our findings highlight the critical significance of MFCC in gender identification in the Tai language,with ramifications that extend far beyond its local context, promising advances in voice analysis andimproving our understanding of language and human communication.","2024","2025-02-26 20:37:02","2025-02-26 20:37:02","","315-327","","1","15","","","","","","","","","","English","","","","WOS:001347851800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","Chroma; Formant frequency; Gender identification; Machine learning methods; MFCC; Neural networks; Pitch","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"95MG5WQZ","journalArticle","2024","Mao, WF; Liu, P; Huang, JX","SF-Transformer: A Mutual Information-Enhanced Transformer Model with Spot-Forward Parity for Forecasting Long-Term Chinese Stock Index Futures Prices","ENTROPY","","1099-4300","10.3390/e26060478","","The complexity in stock index futures markets, influenced by the intricate interplay of human behavior, is characterized as nonlinearity and dynamism, contributing to significant uncertainty in long-term price forecasting. While machine learning models have demonstrated their efficacy in stock price forecasting, they rely solely on historical price data, which, given the inherent volatility and dynamic nature of financial markets, are insufficient to address the complexity and uncertainty in long-term forecasting due to the limited connection between historical and forecasting prices. This paper introduces a pioneering approach that integrates financial theory with advanced deep learning methods to enhance predictive accuracy and risk management in China's stock index futures market. The SF-Transformer model, combining spot-forward parity and the Transformer model, is proposed to improve forecasting accuracy across short and long-term horizons. Formulated upon the arbitrage-free futures pricing model, the spot-forward parity model offers variables such as stock index price, risk-free rate, and stock index dividend yield for forecasting. Our insight is that the mutual information generated by these variables has the potential to significantly reduce uncertainty in long-term forecasting. A case study on predicting major stock index futures prices in China demonstrates the superiority of the SF-Transformer model over models based on LSTM, MLP, and the stock index futures arbitrage-free pricing model, covering both short and long-term forecasting up to 28 days. Unlike existing machine learning models, the Transformer processes entire time series concurrently, leveraging its attention mechanism to discern intricate dependencies and capture long-range relationships, thereby offering a holistic understanding of time series data. An enhancement of mutual information is observed after introducing spot-forward parity in the forecasting. The variation of mutual information and ablation study results highlights the significant contributions of spot-forward parity, particularly to the long-term forecasting. Overall, these findings highlight the SF-Transformer model's efficacy in leveraging spot-forward parity for reducing uncertainty and advancing robust and comprehensive approaches in long-term stock index futures price forecasting.","2024-06","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","6","26","","","","","","","","","","English","","","","WOS:001256746700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;98</p>","","","DISCOVERY; ENTROPY; financial complexity; long-term forecasting; LSTM; MARKETS EVIDENCE; mutual information; PREDICTION; SIZE; stock index futures; transformer; TRANSMISSION; VOLATILITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L5LH5PZK","journalArticle","2023","Fukuoka, T; Fujiu, M","Detection of Bridge Damages by Image Processing Using the Deep Learning Transformer Model","BUILDINGS","","2075-5309","10.3390/buildings13030788","","In Japan, bridges are inspected via close visual examinations every five years. However, these inspections are labor intensive, and a shortage of engineers and budget constraints will restrict such inspections in the future. In recent years, efforts have been made to reduce the labor required for inspections by automating various aspects of the inspection process. In particular, image processing technology, such as transformer models, has been used to automatically detect damage in images of bridges. However, there has been insufficient discussion on the practicality of applying such models to damage detection. Therefore, this study demonstrates how they may be used to detect bridge damage. In particular, delamination and rebar exposure are targeted using three different models trained with datasets containing different size images. The detection results are compared and evaluated, which shows that the detection performance of the transformer model can be improved by increasing the size of the input image. Moreover, depending on the target, it may be desirable to avoid changing the detection target. The result of the largest size of the input image shows that around 3.9% precision value or around 19.9% recall value is higher than one or the other models.","2023-03","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","3","13","","","","","","","","","","English","","","","WOS:000953688300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","bridge maintenance; damage detection; image size; INSPECTION; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PQ7KUQZL","journalArticle","2022","Shishah, W; Fajri, RM","Large Comparative Study of Recent Computational Approach in Automatic Hate Speech Detection","TEM JOURNAL-TECHNOLOGY EDUCATION MANAGEMENT INFORMATICS","","2217-8309","10.18421/TEM111-10","","Social media has become a constant in our everyday life. However, its steady growth has increased the hate speech and hostile content problem. To curb this, hate speech detection and recognition is required, but it is faced to two major challenges - laws and enforcement, and automatic computerized hate speech detection. Although many studies are already implemented in detecting hate content, many of these are done in a single setting showing a single dataset in comparison to machine learning or deep learning models. Thus, there is no comparison between previous approaches and recent inventions such as transformer model. Therefore, in this work we explored and compared recent advanced approaches in automatic hate speech detection. Our aim is to analyze the influence different approaches in detecting hate content and its applicability in the real world. Several experiments were conducted on eight real hate speech datasets from recent studies. We present the results of each comparison which shows that the recent transformer model approach is able to outmatch many of the previous hate speech recognition models by significant G-Means and F1 scores. To the author's knowledge, this paper is the first attempt to present a large comparative study of approaches in hate speech detection.","2022-02","2025-02-26 20:37:02","2025-02-26 20:37:02","","82-93","","1","11","","","","","","","","","","English","","","","WOS:000776574300010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Hate speech; machine learning and deep learning; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FG98CRPG","journalArticle","2021","Hannan, MA; How, DNT; Lipu, MSH; Mansor, M; Ker, PJ; Dong, ZY; Sahari, KSM; Tiong, SK; Muttaqi, KM; Mahlia, TMI; Blaabjerg, F","Deep learning approach towards accurate state of charge estimation for lithium-ion batteries using self-supervised transformer model","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-021-98915-8","","Accurate state of charge (SOC) estimation of lithium-ion (Li-ion) batteries is crucial in prolonging cell lifespan and ensuring its safe operation for electric vehicle applications. In this article, we propose the deep learning-based transformer model trained with self-supervised learning (SSL) for end-to-end SOC estimation without the requirements of feature engineering or adaptive filtering. We demonstrate that with the SSL framework, the proposed deep learning transformer model achieves the lowest root-mean-square-error (RMSE) of 0.90% and a mean-absolute-error (MAE) of 0.44% at constant ambient temperature, and RMSE of 1.19% and a MAE of 0.7% at varying ambient temperature. With SSL, the proposed model can be trained with as few as 5 epochs using only 20% of the total training data and still achieves less than 1.9% RMSE on the test data. Finally, we also demonstrate that the learning weights during the SSL training can be transferred to a new Li-ion cell with different chemistry and still achieve on-par performance compared to the models trained from scratch on the new cell.","2021-10-01","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","1","11","","","","","","","","","","English","","","","WOS:000702752900021","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;76<br/>Total Times Cited:&nbsp;&nbsp;77<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","DATA-DRIVEN; GATED RECURRENT UNIT; LSTM; NEURAL-NETWORK; OF-CHARGE; SOC ESTIMATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CTCYPPKK","journalArticle","2024","Wang, TW; Lai, SH","Multi-Modal Pedestrian Crossing Intention Prediction with Transformer-Based Model","APSIPA TRANSACTIONS ON SIGNAL AND INFORMATION PROCESSING","","2048-7703","10.1561/116.20240019","","Pedestrian crossing intention prediction based on computer vision plays a pivotal role in enhancing the safety of autonomous driving and advanced driver assistance systems. In this paper, we present a novel multi-modal pedestrian crossing intention prediction framework leveraging the transformer model. By integrating diverse sources of information and leveraging the transformer's sequential modeling and parallelization capabilities, our system accurately predicts pedestrian crossing intentions. We introduce a novel representation of traffic environment data and incorporate lifted 3D human pose and head orientation data to enhance the model's understanding of pedestrian behavior. Experimental results demonstrate the state-of-the-art accuracy of our proposed system on benchmark datasets.","2024","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","5","13","","","","","","","","","","English","","","","WOS:001332566200003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","human posture; multi-modal learning; Pedestrian crossing intention prediction; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X8MWP9XH","journalArticle","2022","Wang, QT; Huang, HQ; Ma, XK; Shen, ZW; Zhong, CL; Ding, WC; Zhou, W; Zhou, JB","Trapezoidal pile-up nuclear pulse parameter identification method based on deep learning transformer model","APPLIED RADIATION AND ISOTOPES","","0969-8043","10.1016/j.apradiso.2022.110515","","Pile-up between adjacent nuclear pulses is unavoidable in the actual detection process. Some scholars have tried to apply deep learning techniques to identify pile-up nuclear pulse parameters. However, traditional deep learning recurrent neural networks (RNNs) suffer from inefficient pulse recognition and poor recognition of pile-up nuclear pulses with short intervals between adjacent pulses. In this paper, a Transformer model with an attention mechanism as the core to recognize pile-up nuclear pulses is innovatively applied, aiming to provide a more accurate and efficient method for pile-up nuclear pulse recognition. Thus, it gives a better help for the spectrum correction with a high count rate.","2022-12","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","190","","","","","","","","","","English","","","","WOS:000882464600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;16</p>","","","Attention mechanism; IMPLEMENTATION; Nuclear pulse; REAL-TIME; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U4XNCE92","journalArticle","2024","Igarashi, T; Iijima, K; Nitta, K; Chen, Y","Estimation of the Cognitive Functioning of the Elderly by AI Agents: A Comparative Analysis of the Effects of the Psychological Burden of Intervention","HEALTHCARE","","2227-9032","10.3390/healthcare12181821","","In recent years, an increasing number of studies have begun to use conversational data in spontaneous speech to estimate cognitive function in older people. The targets of spontaneous speech with older people used to be physicians and licensed psychologists, but it is now possible to have conversations with fully automatic AI agents. However, it has not yet been clarified what difference there is in conversational communication with older people when the examiner is a human or an AI agent. This study explored the psychological burden experienced by elderly participants during cognitive function assessments, comparing interactions with human and AI conversational partners. Thirty-four participants, averaging 78.71 years of age, were evaluated using the Mini-Mental State Examination (MMSE), the Visual Analogue Scale (VAS), and the State-Trait Anxiety Inventory (STAI). The objective was to assess the psychological impact of different conversational formats on the participants. The results indicated that the mental strain, as measured by VAS and STAI scores, was significantly higher during the MMSE sessions compared to other conversational interactions (p < 0.01). Notably, there was no significant difference in the mental burden between conversations with humans and AI agents, suggesting that AI-based systems could be as effective as human interaction in cognitive assessments.","2024-09","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","18","12","","","","","","","","","","English","","","","WOS:001326306600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","AI agents; Alzheimer's disease; cognitive function estimation; COSTS; dementia; DEMENTIA; EDUCATION; MENTAL-STATE-EXAMINATION; psychological burden","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W9DJEJYT","journalArticle","2024","Zhang, T; Zhang, TT; Ma, F","IMAGE CAPTIONING MODEL BASED ON MULTIPLE ATTENTION PATTERNS","JOURNAL OF NONLINEAR AND CONVEX ANALYSIS","","1345-4773","","","As a cross-field of computer vision and natural language processing, image caption generation has been a widely concerned research topic. However, it is challenging because the automatically generated captioning needs to conform to the image content and language logic. In this paper, we propose a multiple attention model that combines DenseNet169 pre-trained convolutional neural networks and an improved Transformer language model to construct novel CATANIC picture description models, which follow an encoding-decoding architecture. Firstly, we use the DenseNet169 network as the encoder to extract the initial features of the image, and then introduce the AoA attention mechanism as the first attention on the encoder to correct the initial features of the images and increase the correlation between each feature vector. Also, the AOA attention mechanism is added to the decoder of the Transformer model as the second attention, and the modified Transformer model is used as a decoder for the image caption model to convert the modified image feature vectors into textual descriptions. The experimental results show that the CATANIC model is not only able to generate captions that match the picture content as well as the language logic, but also has a simpler model structure and requires fewer parameters than traditional image captioning models.","2024","2025-02-26 20:37:02","2025-02-26 20:37:02","","191-206","","1","25","","","","","","","","","","English","","","","WOS:001245046800014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","DenseNet169; Image caption; multiple attention patternss; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MKPAV38B","journalArticle","2024","Wu, ZD; He, LS; Wang, W; Ju, YZ; Guo, Q","A Fault Prediction Method for CNC Machine Tools Based on SE-ResNet-Transformer","MACHINES","","2075-1702","10.3390/machines12060418","","Aiming at the problem that predicted data do not reflect the operating status of computer numerical control (CNC) machine tools, this article proposes a new combined model based on SE-ResNet and Transformer for CNC machine tool failure prediction. Firstly, the Transformer model is utilised to build a non-linear temporal feature mapping using the attention mechanism in multidimensional data. Secondly, the predicted data are transformed into 2D features by the SE-ResNet model, which is adept at processing 2D data, and the spatial feature relationships between predicted data are captured, thus enhancing the state recognition capability. Through experiments, data involving the CNC machine tools in different states are collected to build a dataset, and the method is validated. The SE-ResNet-Transformer model can accurately predict the state of CNC machine tools with a recognition rate of 98.56%. Results prove the effectiveness of the proposed method in CNC machine tool failure prediction. The SE-ResNet-Transformer model is a promising approach for CNC machine tool failure prediction. The method shows great potential in improving the accuracy and efficiency of CNC machine tool failure prediction. Feasible methods are provided for precise control of the state of CNC machine tools.","2024-06","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","6","12","","","","","","","","","","English","","","","WOS:001256490000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","CNC machine tools; deep learning; SE-ResNet; state prediction; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2K4WE4MT","journalArticle","2024","Zhao, AT; Wang, NN; Niu, XS; Chen, M; Wu, HM","A Triplet Multimodel Transfer Learning Network for Speech Disorder Screening of Parkinson's Disease","INTERNATIONAL JOURNAL OF INTELLIGENT SYSTEMS","","0884-8173","10.1155/2024/8890592","","Deterioration in the quality of a person's voice and speech is an early sign of Parkinson's disease (PD). Although a number of computer-based methods have been invested to use patients' speech for early diagnosis of Parkinson's disease, they only focus on a fixed pronunciation test, such as the subjects' monosyllabic pronunciation is analyzed to determine whether they have potential possibility of PD. Moreover, only using traditional speech analysis methods to extract single-view speech features cannot provide a comprehensive feature representation. This paper is dedicated to the study of various pronunciation tests for patients with PD, including the pronunciation of five monosyllabic vowels and a spontaneous dialogue. A triplet multimodel transfer learning network is designed and proposed for identifying subjects with PD in these two groups of tests. First, multisource data extract mel frequency cepstrum coefficient (MFCC) features of speech for preprocessing. Subsequently, a pretrained triplet model represents features from three dimensions as the upstream task of the transfer learning framework. Finally, the pretrained model is reconstructed as a novel model that integrates the triplet model, temporal model, and auxiliary layer as the downstream task, and weights are updated through fine-tuning to identify abnormal speech. Experimental results show that the highest PD detection rates in the two groups of tests are 99% and 90% , respectively, which outperform a large number of internationally popular pattern recognition algorithms and serve as a baseline for other academic researchers in this field.","2024-03-20","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","2024","","","","","","","","","","English","","","","WOS:001194033800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","RECOGNITION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SNPWKT9G","journalArticle","2021","Marzi, C; Greco, A; Scilingo, EP; Vanello, N","Towards a model of arousal change after affective word pronunciation based on electrodermal activity and speech analysis","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2021.102517","","In this paper, we explore the possibility of building a model of subject arousal by exploiting the acquisition and the analysis of speech and electrodermal activity (EDA). Several issues have to be addressed to reach this goal as the estimation of the relationship between arousal and behavioral measures and the reliability of EDA signal during speech production. To accomplish this task, we will investigate the relation among EDA, speech activity and subject arousal, during isolated affective word pronunciation. Our results show that significant information on subject arousal can be obtained by analyzing EDA during the processing of out-of-context words with an emotional content in a reading aloud task. Based on a sample of eighteen Italian participants, we observed a significant relation between EDA features and self-reported arousal scores. Quantitative models relating EDAand speech-derived features are proposed and discussed. We found that increasing values of tonic and phasic components of EDA signals correspond to increasing self-assessed arousal scores; Mel-frequency cepstral analysis of speech was also shown to carry relevant information about subject arousal, with a significant inverse relation to self-assessed scores. Our results suggest how the analysis of concurrent acquisition of EDA and speech features may offer a valid approach for the prediction of subject arousal during speech production, as well as a method for validating self-assessment ratings themselves.","2021-05","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","67","","","","","","","","","","English","","","","WOS:000640913800012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","Arousal; Electrodermal activity; EMOTION RECOGNITION; FEATURE-SELECTION; Speech; Statistical models; Word pronunciation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4DFGUFLR","journalArticle","2022","Xu, JC; Zhang, Y; Han, JL; Su, A; Qiao, HR; Zhang, CY; Tang, J; Shen, X; Sun, B; Yu, WB; Zhai, SL; Wang, XQ; Wu, YJ; Su, WK; Duan, HL","Providing direction for mechanistic inferences in radical cascade cyclization using a Transformer model","ORGANIC CHEMISTRY FRONTIERS","","2052-4129","10.1039/d2qo00188h","","Even in modern organic chemistry, predicting or proposing a reaction mechanism and speculating on reaction intermediates remains challenging. For example, it is challenging to predict the regioselectivity of radical addition in radical cascade cyclization, which finds wide application in life sciences and pharmaceutical industries. In this work, radical cascade cyclization is considered to demonstrate that Transformer, a sequence-to-sequence deep learning model, is capable of predicting the reaction intermediates. A major challenge is that the number of intermediates involved in the different reactions is variable. By defining ""key intermediates"", this thorny problem was avoided. We curated a database of 874 chemical equations and corresponding 1748 key intermediates and used the dataset to fine-tune a model pretrained based on the USPTO dataset. The format of the dataset is very different between pretraining and fine-tuning. Correspondingly, the resulting Transformer model achieves remarkable accuracy in predicting the structures and stereochemistry of the key intermediates. The interpretability produced by attention weights of the resulting Transformer model shows a mindset similar to that of an experienced chemist. Hence, our study provides a novel approach to help chemists discover the mechanisms of organic reactions.","2022-05-03","2025-02-26 20:37:02","2025-02-26 20:37:02","","2498-2508","","9","9","","","","","","","","","","English","","","","WOS:000774047100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","1,6-ENYNES; ADDITIONS; C(SP(2))-H ARYLSULFONYLATION; ENAMIDES; FUNCTIONALIZATION; INSERTION; MOLECULES; SULFONES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"779QNAUQ","journalArticle","2024","Li, PP; Lv, Y; Shang, HY","A cancer diagnosis transformer model based on medical IoT data for clinical measurements in predictive care systems","BIOIMPACTS","","2228-5652","10.34172/bi.30640","","Introduction: In recent years, advancements in information and communication technology (ICT) and the internet of things (IoT) have revolutionized the healthcare industry, enabling the collection, analysis, and utilization of medical data to improved patient care. One critical area of focus is the development of predictive care systems for early diagnosis and treatment of cancer and disease. Methods: Leveraging medical IoT data, this study proposes a novel approach based on transformer model for disease diagnosis. In this paper, features are first extracted from IoT images using a transformer network. The network utilizes a convolutional neural network (CNN) in the encoder part to extract suitable features and employs decoder layers along with attention mechanisms in the decoder part. In the next step, considering that the extracted features have high dimensions and many of these features are irrelevant and redundant, relevant features are selected using the Harris hawk optimization algorithm. Results: Various classifiers are used to label the input data. The proposed method is evaluated using a dataset consisting of 5 classes for testing and evaluation, and all results are provided into tables and plots. Conclusion: The experimental results demonstrate that the proposed method acceptable performance compared to other methods.","2024-12-04","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","15","","","","","","","","","","English","","","","WOS:001371714500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","Cancer diagnosis; Clinical measurement; Deep learning; Medical IoT data; Predictive care systems; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2NLY5UVG","journalArticle","2021","Voppel, AE; de Boer, JN; Brederoo, SG; Schnack, HG; Sommer, IEC","Quantified language connectedness in schizophrenia-spectrum disorders","PSYCHIATRY RESEARCH","","0165-1781","10.1016/j.psychres.2021.114130","","Language abnormalities are a core symptom of schizophrenia-spectrum disorders and could serve as a potential diagnostic marker. Natural language processing enables quantification of language connectedness, which may be lower in schizophrenia-spectrum disorders. Here, we investigated connectedness of spontaneous speech in schizophrenia-spectrum patients and controls and determine its accuracy in classification. Using a semistructured interview, speech of 50 patients with a schizophrenia-spectrum disorder and 50 controls was recorded. Language connectedness in a semantic word2vec model was calculated using consecutive word similarity in moving windows of increasing sizes (2-20 words). Mean, minimal and variance of similarity were calculated per window size and used in a random forest classifier to distinguish patients and healthy controls. Classification based on connectedness reached 85% cross-validated accuracy, with 84% specificity and 86% sensitivity. Features that best discriminated patients from controls were variance of similarity at window sizes between 5 and 10. We show impaired connectedness in spontaneous speech of patients with schizophrenia-spectrum disorders even in patients with low ratings of positive symptoms. Effects were most prominent at the level of sentence connectedness. The high sensitivity, specificity and tolerability of this method show that language analysis is an accurate and feasible digital assistant in diagnosing schizophrenia-spectrum disorders.","2021-10","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","304","","","","","","","","","","English","","","","WOS:000697776300016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;43<br/>Total Times Cited:&nbsp;&nbsp;43<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","Biomarker; DIAGNOSIS; FLUENCY; LATENT SEMANTIC ANALYSIS; Natural language processing; Psychosis; PSYCHOSIS; REVEALS; RISK; Semantic model; Speech; SPEECH; Word similarity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I229IBW6","journalArticle","2023","Baqué, L; Machuca, MJ","Hesitations in Primary Progressive Aphasia","LANGUAGES","","2226-471X","10.3390/languages8010045","","Hesitations are often used by speakers in spontaneous speech not only to organise and prepare their speech but also to address any obstacles that may arise during delivery. Given the relationship between hesitation phenomena and motor and/or cognitive-linguistic control deficits, characterising the form of hesitation could be potentially useful in diagnosing specific speech and language disorders, such as primary progressive aphasia (PPA). This work aims to analyse the features of hesitations in patients with PPA compared to healthy speakers, with hesitations understood here as those related to speech planning, that is, silent or empty pauses, filled pauses, and lengthened syllables. Forty-three adults took part in this experiment, of whom thirty-two suffered from some form of PPA: thirteen from logopenic PPA (lvPPA), ten from nonfluent PPA (nfvPPA), and nine from semantic PPA (svPPA). The remaining 11 were healthy speakers who served as a control group. An analysis of audio data recorded when participants produced spontaneous speech for a picture description task showed that the frequency of silent pauses, especially those classified as long (>1000 ms) was particularly useful to distinguish PPA participants from healthy controls and also to differentiate among PPA types. This was also true, albeit to a lesser extent, of the frequency of filled pauses and lengthened syllables.","2023-03","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","1","8","","","","","","","","","","English","","","","WOS:000968276300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;83</p>","","","APRAXIA; BIOMARKERS; CLASSIFICATION; CONNECTED SPEECH; fillers; FLUENCY; hesitations; LOGOPENIC VARIANTS; MOTOR SPEECH; NARRATIVE SPEECH; NONFLUENT; pauses; primary progressive aphasia (PPA); SPEECH PRODUCTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5D66Z246","journalArticle","2024","Kachel, S; Simpson, AP; Steffens, MC","Speakers' vocal expression of sexual orientation depends on experimenter gender","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2023.103023","","Since the early days of (phonetic) convergence research, one of the main questions is which individuals are more likely to adapt their speech to others. Especially differences between women and men have been researched with a high intensity. Using a differential approach as well, we complement the existing literature by focusing on another gender-related characteristic, namely sexual orientation. The present study aims to investigate whether and how women differing in sexual orientation vary in their speaking behavior, especially mean fundamental frequency (f0), in the presence of a female vs. male experimenter. Lesbian (n = 19) and straight female speakers (n = 18) engaged in two interactions each: First, they either engaged with a female or male experimenter, and second with the other-gender experimenter (counter-balanced and random assignment to conditions). For each interaction, recordings of read and spontaneous speech were collected. Analyses of read speech demonstrated mirroring of the first experimenter's mean f0 which persisted even in the presence of the second experimenter. In spontaneous speech, this order effect interacted with exclusiveness of sexual orientation: Mirroring was found for participants who reported being exclusively lesbian/straight, not for those who reported being mainly lesbian/ straight. We discuss implications for studies on convergence and research practice in general.","2024-01","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","156","","","","","","","","","","English","","","","WOS:001138792500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","ACCOMMODATION; Experimenter effects; Fundamental frequency; FUNDAMENTAL-FREQUENCY; Gender; Intragroup differences; PERCEPTION; Phonetic convergence; PHONETIC CONVERGENCE; Sexual orientation; SPEECH; VOICES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3ITJ5QDD","journalArticle","2023","Song, R; Zhang, X; Chen, X; Chen, X; Chen, X; Yang, S; Yin, ER","Decoding silent speech from high-density surface electromyographic data using transformer","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2022.104298","","Recent silent speech recognition (SSR) studies based on surface electromyography (sEMG) have been conducted by classifying a finite number of words or phrases without sufficient understanding of temporally semantic in-formation compared to sequential decoding at a fine-grained syllable or phoneme level. This paper presents a syllable-level sequential decoding method using a transformer model for sEMG-based SSR. The proposed method consists of a transformer model and a language model. The input sEMG data was first translated into a sequence of syllable-level decisions by the transformer model. Then, these sequential syllable-level decisions were tuned as a final syllable sequence to approximate natural language through the language model. To verify the effec-tiveness of the proposed method, experiment data were recorded using two high-density electrode arrays with 64 channels from a total of eight subjects during subvocally reading a corpus of 33 Chinese phrases generated from a dictionary of 82 syllables. The proposed method achieved the lowest character error rate of 5.14 +/- 3.28 % and the highest phrase recognition accuracy of 96.37 +/- 2.06 %, and it significantly outperformed other common methods for sEMG-based SSR. These findings demonstrated the feasibility and usability of the proposed method for practical SSR applications.","2023-02","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","80","","","","","","","","","","English","","","","WOS:000890503700003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","COMMUNICATION; Language model; MODELS; RECOGNITION; Sequential decoding; Silent speech recognition; Surface electromyography; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JEKSB2D7","journalArticle","2022","Merritt, B; Bent, T","Revisiting the acoustics of speaker gender perception: A gender expansive perspective","JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA","","0001-4966","10.1121/10.0009282","","Examinations of speaker gender perception have primarily focused on the roles of fundamental frequency (f(o)) and formant frequencies from structured speech tasks using cisgender speakers. Yet, there is evidence to suggest that f(o) and formants do not fully account for listeners' perceptual judgements of gender, particularly from connected speech. This study investigated the perceptual importance of f(o), formant frequencies, articulation, and intonation in listeners' judgements of gender identity and masculinity/femininity from spontaneous speech from cisgender male and female speakers as well as transfeminine and transmasculine speakers. Stimuli were spontaneous speech samples from 12 speakers who are cisgender (6 female and 6 male) and 12 speakers who are transgender (6 transfeminine and 6 transmasculine). Listeners performed a two-alternative forced choice (2AFC) gender identification task and masculinity/femininity rating task in two experiments that manipulated which acoustic cues were available. Experiment 1 confirmed that f(o) and formant frequency manipulations were insufficient to alter listener judgements across all speakers. Experiment 2 demonstrated that articulatory cues had greater weighting than intonation cues on the listeners' judgements when the f(o) and formant frequencies were in a gender ambiguous range. These findings counter the assumptions that f(o) and formant manipulations are sufficient to effectively alter perceived speaker gender. (C) 2022 Acoustical Society of America.","2022-01","2025-02-26 20:37:02","2025-02-26 20:37:02","","484-499","","1","151","","","","","","","","","","English","","","","WOS:000874485100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;79</p>","","","AUDITORY FREE CLASSIFICATION; FEMALE; FORMANT FREQUENCIES; FUNDAMENTAL-FREQUENCY; IDENTIFICATION; IDENTITY; RESONANCE; TALKER SEX; VOCAL-TRACT; VOICE QUALITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F42MJ9R6","journalArticle","2025","Zhang, H; He, R; Palominos, C; Hsu, N; Cheung, H; Hinzen, W","The structure of meaning in schizophrenia: A study of spontaneous speech in Chinese","PSYCHIATRY RESEARCH","","0165-1781","10.1016/j.psychres.2024.116347","","Narrative speech production requires the retrieval of concepts to refer to entities, which need to be referenceable more than once for any form of narrative coherence to arise. Such coherence has long been observed to be affected in schizophrenia spectrum disorders (SSD), yet the underlying mechanisms have been a longstanding puzzle, with existing evidence predominantly derived from Indo-European languages. Here we analyzed two picture descriptions from 22 native Mandarin Chinese speakers with SSD and 15 healthy controls. An analysis scheme was created targeting key mechanisms in the genesis of referential meaning in speech. Results revealed that individuals with SSD used more definite-anaphoric noun phrases (NPs), which refer back to a previously mentioned entity in a narrative, and fewer NPs with adjectival modifiers. Definite NPs appeared earlier in their speech, and both definite and indefinite NPs occurred at shorter temporal distances. Participants with SSD referenced fewer entities, which in turn were more recurrent (referenced more than once). Furthermore, speech graphs capturing how entities are referenced across a narrative exhibited higher clustering, centrality, density, and shorter characteristic path lengths in SSD. Overall, these results from a non-Indo-European language support the new concept of a 'shrinking' or more condensed semantic space in SSD, impeding normal mental navigation across the concepts we retrieve during speech.","2025-02","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","344","","","","","","","","","","English","","","","WOS:001402479500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","FEATURES; Graph theory; LANGUAGE; Mandarin Chinese; Narrative coherence; PSYCHOSIS; Referential function; Schizophrenia; Semantic similarity; Semantic structure; Spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CYS33ZCE","journalArticle","2022","O'Keeffe, C; Yap, SM; Davenport, L; Cogley, C; Craddock, F; Kennedy, A; Tubridy, N; De Looze, C; Suleyman, N; O'Keeffe, F; Reilly, RB; McGuigan, C","Association between speech rate measures and cognitive function in people with relapsing and progressive multiple sclerosis","MULTIPLE SCLEROSIS JOURNAL-EXPERIMENTAL TRANSLATIONAL AND CLINICAL","","2055-2173","10.1177/20552173221119813","","Background Cognitive impairments are well-documented in multiple sclerosis (MS), while speech impairments are often overlooked despite their significant effect on quality of life. For effective clinical management of multisystem conditions such as MS, consideration should be given to the interaction between deficits in multiple domains, such as speech and cognition. To evaluate speech rate measures of spontaneous and read speech, in people with MS and to examine the link between speech and cognition. Methods Forty-five people with MS and 25 controls underwent an extensive cognitive battery, including executive functioning, information processing and memory tasks, and completed two speech tasks: a reading task and a picture description task, from which speech rate measures were derived. Results The progressive MS cohort had reduced articulation (p < 0.04) and speech rate (p < 0.02) compared to controls and those with relapsing MS. Regression models also revealed information processing speed accounted for 18% to 30% of the variance of spontaneous speech rate measures, and 27% of read speech. Executive functioning accounted for a further 10% of the variance of speech rate in those with MS. Conclusions The present study suggests that speech production is contingent on cognitive ability, with information processing speed and executive functioning linked with speech timing patterns.","2022-07","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","3","8","","","","","","","","","","English","","","","WOS:000842966400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","ARTICULATION RATE; cognition; DECLINE; information processing; INFORMATION-PROCESSING SPEED; multiple sclerosis; regression; SEVERITY; spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"948REWAA","journalArticle","2022","Ri, HC; Kim, C; Jo, MR","A method for constructing Korean spontaneous spoken language corpus based on an imitation of abbreviated and transformed particles","INTERNATIONAL JOURNAL OF SPEECH TECHNOLOGY","","1381-2416","10.1007/s10772-021-09937-6","","In the paper, we proposed a method of constructing a language corpus based on the imitation of abbreviated and transformed particles that are distinctive feature of Korean spontaneous spoken language. Since it is not practical to train a spoken-style model using numerous spoken transcripts, the proposed approach generates a spoken-style text from a written-style one such as newspapers, based on characteristics of pronouncing variations, dependent on spoken styles, of typical particles. This method for constructing spoken-style text is based on statistical analysis on particles that play same function in both of written and spoken language. We analyze grammatical functions and pronouncing features of particles that distinguish between written and spoken language, and generate spoken-style text from written-style text by imitating typical abbreviated and transformed particles which play same function. Abbreviated and transformed particles to be imitated have proper and typical pronouncing features of spoken language. We replace particles with abbreviated and transformed particles in written-style text according to correspondence of written particles to spoken ones, which results in spoken-style text. The language model, which is trained from spoken-style text imitating abbreviated and transformed particles, significantly improved a word error rate (WER) on spontaneous speech.","2022-03","2025-02-26 20:37:02","2025-02-26 20:37:02","","205-210","","1","25","","","","","","","","","","English","","","","WOS:000714851700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","Automatic speech recognition (ASR); Language corpus; Language model (LM); Spontaneous speech; TRANSCRIPTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SNPD8EZK","journalArticle","2024","Balamurali, BT; Chen, JM","Performance Assessment of ChatGPT versus Bard in Detecting Alzheimer's Dementia","DIAGNOSTICS","","2075-4418","10.3390/diagnostics14080817","","Large language models (LLMs) find increasing applications in many fields. Here, three LLM chatbots (ChatGPT-3.5, ChatGPT-4, and Bard) are assessed in their current form, as publicly available, for their ability to recognize Alzheimer's dementia (AD) and Cognitively Normal (CN) individuals using textual input derived from spontaneous speech recordings. A zero-shot learning approach is used at two levels of independent queries, with the second query (chain-of-thought prompting) eliciting more detailed information than the first. Each LLM chatbot's performance is evaluated on the prediction generated in terms of accuracy, sensitivity, specificity, precision, and F1 score. LLM chatbots generated a three-class outcome (""AD"", ""CN"", or ""Unsure""). When positively identifying AD, Bard produced the highest true-positives (89% recall) and highest F1 score (71%), but tended to misidentify CN as AD, with high confidence (low ""Unsure"" rates); for positively identifying CN, GPT-4 resulted in the highest true-negatives at 56% and highest F1 score (62%), adopting a diplomatic stance (moderate ""Unsure"" rates). Overall, the three LLM chatbots can identify AD vs. CN, surpassing chance-levels, but do not currently satisfy the requirements for clinical application.","2024-04","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","8","14","","","","","","","","","","English","","","","WOS:001210190500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Alzheimer's dementia; Bard; chain-of-thought; chatbots; ChatGPT; DISEASE; ecological diagnostic screening; GPT-3.5; GPT-4; IMPAIRMENT; INTERVENTION; Large Language Models; MENTAL-STATE-EXAMINATION; MOCA; PREVENTION; spontaneous speech; zero-shot learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EHZN5WI4","journalArticle","2024","Casillas, M; Foushee, R; Girón, JM; Polian, G; Brown, P","Little evidence for a noun bias in Tseltal spontaneous speech","FIRST LANGUAGE","","0142-7237","10.1177/01427237231216571","","This study examines whether children acquiring Tseltal (Mayan) demonstrate a noun bias - an overrepresentation of nouns in their early vocabularies. Nouns, specifically concrete and animate nouns, are argued to universally predominate in children's early vocabularies because their referents are naturally available as bounded concepts to which linguistic labels can be mapped. This early advantage for noun learning has been documented using multiple methods and across a diverse collection of language populations. However, past evidence bearing on a noun bias in Tseltal learners has been mixed. Tseltal grammatical features and child-caregiver interactional patterns dampen the salience of nouns and heighten the salience of verbs, leading to the prediction of a diminished noun bias and perhaps even an early predominance of verbs. We here analyze the use of noun and verb stems in children's spontaneous speech from egocentric daylong recordings of 29 Tseltal learners between 0;9 and 4;4. We find weak to no evidence for a noun bias using two separate analytical approaches on the same data; one analysis yields a preliminary suggestion of a flipped outcome (i.e. a verb bias). We discuss the implications of these findings for broader theories of learning bias in early lexical development.","2024-12","2025-02-26 20:37:02","2025-02-26 20:37:02","","600-628","","6","44","","","","","","","","","","English","","","","WOS:001139687300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;84</p>","","","2-YEAR-OLDS; ACQUISITION; CATEGORIES; CHILDREN; daylong recordings; EARLY LEXICAL DEVELOPMENT; ENGLISH; INPUT; lexical development; Mayan; noun bias; SPANISH; SPEAKING; Tseltal; VERBS; vocabulary","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"92K2N6FM","journalArticle","2024","Cheng, S; Lin, JL; Emani, M; Raskar, S; Foreman, S; Xie, Z; Vishwanath, V; Kandemir, MT","Thorough Characterization and Analysis of Large Transformer Model Training At-Scale","PROCEEDINGS OF THE ACM ON MEASUREMENT AND ANALYSIS OF COMPUTING SYSTEMS","","2476-1249","10.1145/3639034","","Large transformer models have recently achieved great success across various domains. With a growing number of model parameters, a large transformer model training today typically involves model sharding, data parallelism, and model parallelism. Thus, the throughput of large-scale model training depends heavily on the network bandwidth since a combination of model sharding and multiple parallelism strategies incurs various costs. However, prior characterizations of transformer models on high-bandwidth DGX machines that use TFLOPS as a metric may not reflect the performance of a system with lower bandwidth. Furthermore, data and model parallelism reveal significantly distinct training profiles on different system bandwidths at scale and, thus, need a thorough study. In this paper, we provide a bottom-up breakdown of training throughput into compute and communication time, and quantitatively analyze their respective influences on overall end-to-end training scaling. Our evaluation involves an in-depth exploration of data parallelism, scaling up to 512 GPUs with limited bandwidth, and examines three model sharding strategies among six model sizes. We also evaluate three combinations of model parallelism on both high and low bandwidth supercomputing systems. Overall, our work provides a broader perspective on large-scale transformer model training, and our analysis and evaluation yield practical insights for predicting training scaling, shaping the future development of supercomputing system design.","2024-03","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","1","8","","","","","","","","","","English","","","","WOS:001193440400007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","large language model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LPE7FTRL","journalArticle","2023","Shi, LF; Zhang, F; Xia, JS; Xie, JB","Scene-level buildings damage recognition based on Cross Conv-Transformer","INTERNATIONAL JOURNAL OF DIGITAL EARTH","","1753-8947","10.1080/17538947.2023.2261770","","Different to pixel-based and object-based image recognition, a larger perspective based on the scene can improve the efficiency of assessing large-scale building damage. However, the complexity of disaster scenes and the scarcity of datasets are major challenges in identifying building damage. To address these challenges, the Cross Conv-Transformer model is proposed to classify and evaluate the degree of damage to buildings using aerial images taken after earthquake. We employ Conv-Embedding and Conv-Projection to extract features from the images. The integration of convolution and Transformer reduces the computational burden of the model while enhancing its feature extraction capabilities. Furthermore, the two branch Conv-Transformer architecture with global and local attention is designed, allowing each branch to focus on global and local features respectively. The cross-attention fusion module merges feature information from the two branches to enrich classification features. At last, we utilize aerial images captured during the Beichuan and Yushu earthquakes as both the training and test sets to assess the model. The proposed Cross Conv-Transformer model improved classification accuracy by 4.7% and 2.1% compared to the ViT and EfficientNet. The results show that the Cross Conv-Transformer model could significantly reduces misclassification between severely and moderately damaged categories.","2023-12-08","2025-02-26 20:37:02","2025-02-26 20:37:02","","3987-4007","","2","16","","","","","","","","","","English","","","","WOS:001075352800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","aerial images; damaged buildings; Scene recognition; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4T4W8ABR","journalArticle","2024","Visconte, P; Sessarego, S; Rao, RJ","A Comparative Analysis of Declarative Sentences in the Spontaneous Speech of Two Puerto Rican Communities","LANGUAGES","","2226-471X","10.3390/languages9030090","","This paper applies the Autosegmental Metrical (AM) model of intonation phonology and the Spanish Tones and Break Indices (Sp_ToBI) annotation conventions to compare the intonational contours of declarative sentences in two varieties of Puerto Rican Spanish: (1) San Juan Spanish, spoken in the capital city of San Juan, and (2) Loiza Spanish, an Afro-Hispanic vernacular spoken in Loiza. The geographical proximity between these two municipalities entails constant contact within a shared linguistic space. However, speakers from San Juan perceive Loiza as a municipality that has its own peculiar way of speaking. The acoustic and phonological analysis was carried out with PRAAT to verify whether pitch accents coincide in the spontaneous speech of the two analyzed varieties. The data we examined contain an overall predominance of the bitonal pitch accents L*+H and L+<H* in San Juan Spanish, and L+H* in Loiza Spanish. Findings show both similarities and differences within the two speech communities, as well as with intonational patterns in other (Afro-)Hispanic varieties. These results provide new information on spontaneous declarative intonation in (Afro-)Puerto Rican Spanish by offering a new perspective on the origin of a set of the prosodic phenomena found in these two varieties.","2024-03","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","3","9","","","","","","","","","","English","","","","WOS:001192423900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;105</p>","","","autosegmental metrical; declarative intonation; INTONATION; Loiza Spanish; San Juan Spanish; Sp_ToBI; SPANISH; Spanish creole debate","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P8Z9QXI3","journalArticle","2022","DiCanio, C","The evolution of tonally conditioned allomorphy in Triqui: evidence from spontaneous speech corpora","LINGUISTICS VANGUARD","","2199-174X","10.1515/lingvan-2021-0093","","One of the defining characteristics of tonal systems in phonological theory is the notion of tonal stability (Goldsmith, John. 1990. Autosegmental and metrical phonology. Oxford: Blackwell; Yip, Moira. 2002. Tone. Cambridge: Cambridge University Press). Tones remain stable even if their tone-bearing unit changes or is deleted. In the context of historical sound change, tones may either persist as floating tones (from an autosegmental-metrical perspective) or fuse with adjacent syllables and give rise to more complex tonal inventories. However, the process of segmental loss which ultimately conditions historical tonal change is gradual in nature. Tone-bearing units may lenite or they may be optionally realized, leading listeners to rely on coarticulatory cues or phonetic information on adjacent syllables. In the current paper, I examine how variation in the realization of clitic pronouns is conditioned by adjacent tonal cues in Itunyoso Triqui (Otomanguean) within a corpus of spontaneous speech recordings. This research examines and provides evidence for the hypothesis that tonally conditioned allomorphy arises specifically when two conditions are met: (a) there is a morphological context where prosodic units are likely to lenite (highly redundant contexts); and (b) adjacent tonal cues are most informative at this morphophonological boundary. The findings shed light not only on how phonologically conditioned allomorphy arises but also on how variable deletion is sensitive to patterns of multiple exponence during language use.","2022-09-28","2025-02-26 20:37:02","2025-02-26 20:37:02","","545-556","","","8","","","","","","","","","","English","","","","WOS:000822066400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","CONSONANTS; ITUNYOSO; morphophonology; Otomanguean; speech corpora; tone; variation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JFBCZRD4","journalArticle","2021","Ali, M; VandenBerg, K; Williams, LJ; Williams, LR; Abo, M; Becker, F; Bowen, A; Brandenburg, C; Breitenstein, C; Bruehl, S; Copland, DA; Cranfill, TB; Di Pietro-Bachmann, M; Enderby, P; Fillingham, J; Galli, FL; Gandolfi, M; Glize, B; Godecke, E; Hawkins, N; Hilari, K; Hinckley, J; Horton, S; Howard, D; Jaecks, P; Jefferies, E; Jesus, LMT; Kambanaros, M; Kang, EK; Khedr, EM; Kong, APH; Kukkonen, T; Laganaro, M; Ralph, MAL; Laska, AC; Leemann, B; Leff, AP; Lima, RR; Lorenz, A; Mac Whinney, B; Marshall, RS; Meinzer, M; Nilipour, R; Noé, E; Paik, NJ; Palmer, R; Papathanasiou, I; Patricio, BF; Martins, IP; Price, C; Jakovac, TP; Rochon, E; Rose, ML; Rosso, C; Rubi-Fessen, I; Ruiter, MB; Snell, C; Stahl, B; Szaflarski, JP; Thomas, SA; Van De Sandt-Koenderman, M; van der Meulen, I; Visch-Brink, E; Worrall, L; Wright, HH; Brady, MC; StrokE Release Collaborators","Predictors of Poststroke Aphasia Recovery A Systematic Review-Informed Individual Participant Data Meta-Analysis","STROKE","","0039-2499","10.1161/STROKEAHA.120.031162","","Background and Purpose: The factors associated with recovery of language domains after stroke remain uncertain. We described recovery of overall-language-ability, auditory comprehension, naming, and functional-communication across participants' age, sex, and aphasia chronicity in a large, multilingual, international aphasia dataset. Methods: Individual participant data meta-analysis of systematically sourced aphasia datasets described overall-language ability using the Western Aphasia Battery Aphasia-Quotient; auditory comprehension by Aachen Aphasia Test (AAT) Token Test; naming by Boston Naming Test and functional-communication by AAT Spontaneous-Speech Communication subscale. Multivariable analyses regressed absolute score-changes from baseline across language domains onto covariates identified a priori in randomized controlled trials and all study types. Change-from-baseline scores were presented as estimates of means and 95% CIs. Heterogeneity was described using relative variance. Risk of bias was considered at dataset and meta-analysis level. Results: Assessments at baseline (median=43.6 weeks poststroke; interquartile range [4-165.1]) and first-follow-up (median=10 weeks from baseline; interquartile range [3-26]) were available for n=943 on overall-language ability, n=1056 on auditory comprehension, n=791 on naming and n=974 on functional-communication. Younger age (<55 years, +15.4 Western Aphasia Battery Aphasia-Quotient points [CI, 10.0-20.9], +6.1 correct on AAT Token Test [CI, 3.2-8.9]; +9.3 Boston Naming Test points [CI, 4.7-13.9]; +0.8 AAT Spontaneous-Speech Communication subscale points [CI, 0.5-1.0]) and enrollment <1 month post-onset (+19.1 Western Aphasia Battery Aphasia-Quotient points [CI, 13.9-24.4]; +5.3 correct on AAT Token Test [CI, 1.7-8.8]; +11.1 Boston Naming Test points [CI, 5.7-16.5]; and +1.1 AAT Spontaneous-Speech Communication subscale point [CI, 0.7-1.4]) conferred the greatest absolute change-from-baseline across each language domain. Improvements in language scores from baseline diminished with increasing age and aphasia chronicity. Data exhibited no significant statistical heterogeneity. Risk-of-bias was low to moderate-low. Conclusions: Earlier intervention for poststroke aphasia was crucial to maximize language recovery across a range of language domains, although recovery continued to be observed to a lesser extent beyond 6 months poststroke.","2021-05","2025-02-26 20:37:02","2025-02-26 20:37:02","","1778-1787","","5","52","","","","","","","","","","English","","","","WOS:000644656300040","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;47<br/>Total Times Cited:&nbsp;&nbsp;48<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","aphasia; BURDEN; COMMUNICATION; comprehension; demography; language; PROGNOSIS; RANDOMIZED CONTROLLED-TRIAL; REHABILITATION; STROKE PATIENTS; survivor; THERAPY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"63YLKR42","journalArticle","2022","Kappen, M; van der Donckt, J; Vanhollebeke, G; Allaert, J; Degraeve, V; Madhu, N; Van Hoecke, S; Vanderhasselt, MA","Acoustic speech features in social comparison: how stress impacts the way you sound","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-022-26375-9","","The use of speech as a digital biomarker to detect stress levels is increasingly gaining attention. Yet, heterogeneous effects of stress on specific acoustic speech features have been observed, possibly due to previous studies' use of different stress labels/categories and the lack of solid stress induction paradigms or validation of experienced stress. Here, we deployed a controlled, within-subject psychosocial stress induction experiment in which participants received both neutral (control condition) and negative (negative condition) comparative feedback after solving a challenging cognitive task. This study is the first to use a (non-actor) within-participant design that verifies a successful stress induction using both self-report (i.e., decreased reported valence) and physiological measures (i.e., increased heart rate acceleration using event-related cardiac responses during feedback exposure). Analyses of acoustic speech features showed a significant increase in Fundamental Frequency (F0) and Harmonics-to-Noise Ratio (HNR), and a significant decrease in shimmer during the negative feedback condition. Our results using read-out-loud speech comply with earlier research, yet we are the first to validate these results in a well-controlled but ecologically-valid setting to guarantee the generalization of our findings to real-life settings. Further research should aim to replicate these results in a free speech setting to test the robustness of our findings for real-world settings and should include semantics to also take into account what you say and not only how you say it.","2022-12-20","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","1","12","","","","","","","","","","English","","","","WOS:000969800000039","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","CORTISOL; PSYCHOLOGICAL STRESS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SWEFTCXS","journalArticle","2023","Tan, XH; Tong, JC; Matsumaru, T; Dutta, V; He, X","An End-to-End Air Writing Recognition Method Based on Transformer","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3321807","","The air-writing recognition task entails the computer's ability to directly recognize and interpret user input generated by finger movements in the air. This form of interaction between humans and computers is considered natural, cost-effective, and immersive within the domain of human-computer interaction (HCI). While conventional air-writing recognition has primarily focused on recognizing individual characters, a recent advancement in 2022 introduced the concept of writing in the air (WiTA) to address continuous air-writing tasks. In this context, we assert that the Transformer-based approach can offer improved performance for the WiTA task. To solve the WiTA task, this study formulated an end-to-end air-writing recognition method called TR-AWR, which leverages the Transformer model. Our proposed method adopts a holistic approach by utilizing video frame sequences as input and generating letter sequences as outputs. To enhance the performance of the WiTA task, our method combines the vision transformer model with the traditional transformer model, while introducing data augmentation techniques for the first time. Our approach achieves a character error rate (CER) of 29.86% and a decoding frames per second (D-fps) value of 194.67 fps. Notably, our method outperforms the baseline models in terms of recognition accuracy while maintaining a certain level of real-time performance. The contributions of this paper are as follows: Firstly, this study is the first to incorporate the Transformer method into continuous air-writing recognition research, thereby reducing overall complexity and attaining improved results. Additionally, we adopt an end-to-end approach that streamlines the entire recognition process. Lastly, we propose specific data augmentation guidelines tailored explicitly for the WiTA task. In summary, our study presents a promising direction for effectively addressing the WiTA task and holds potential for further advancements in this domain.","2023","2025-02-26 20:37:02","2025-02-26 20:37:02","","109885-109898","","","11","","","","","","","","","","English","","","","WOS:001085254400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Air writing recognition; Character recognition; Data augmentation; Human computer interaction; human-computer interaction (HCI); Task analysis; Trajectory; transformer model; Transformers; Visualization; Writing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HQ8Y93LP","journalArticle","2024","Nunes, AS; Pawlik, M; Mishra, RK; Waddell, E; Coffey, M; Tarolli, CG; Schneider, RB; Dorsey, ER; Vaziri, A; Adams, JL","Digital assessment of speech in Huntington disease","FRONTIERS IN NEUROLOGY","","1664-2295","10.3389/fneur.2024.1310548","","Background: Speech changes are an early symptom of Huntington disease (HD) and may occur prior to other motor and cognitive symptoms. Assessment of HD commonly uses clinician-rated outcome measures, which can be limited by observer variability and episodic administration. Speech symptoms are well suited for evaluation by digital measures which can enable sensitive, frequent, passive, and remote administration. Methods: We collected audio recordings using an external microphone of 36 (18 HD, 7 prodromal HD, and 11 control) participants completing passage reading, counting forward, and counting backwards speech tasks. Motor and cognitive assessments were also administered. Features including pausing, pitch, and accuracy were automatically extracted from recordings using the BioDigit Speech software and compared between the three groups. Speech features were also analyzed by the Unified Huntington Disease Rating Scale (UHDRS) dysarthria score. Random forest machine learning models were implemented to predict clinical status and clinical scores from speech features. Results: Significant differences in pausing, intelligibility, and accuracy features were observed between HD, prodromal HD, and control groups for the passage reading task (e.g., p < 0.001 with Cohen'd = -2 between HD and control groups for pause ratio). A few parameters were significantly different between the HD and control groups for the counting forward and backwards speech tasks. A random forest classifier predicted clinical status from speech tasks with a balanced accuracy of 73% and an AUC of 0.92. Random forest regressors predicted clinical outcomes from speech features with mean absolute error ranging from 2.43-9.64 for UHDRS total functional capacity, motor and dysarthria scores, and explained variance ranging from 14 to 65%. Montreal Cognitive Assessment scores were predicted with mean absolute error of 2.3 and explained variance of 30%. Conclusion: Speech data have the potential to be a valuable digital measure of HD progression, and can also enable remote, frequent disease assessment in prodromal HD and HD. Clinical status and disease severity were predicted from extracted speech features using random forest machine learning models. Speech measurements could be leveraged as sensitive marker of clinical onset and disease progression in future clinical trials.","2024-01-23","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","15","","","","","","","","","","English","","","","WOS:001157454900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","DIAGNOSIS; digital speech aid; Huntington (disease); machine learing; MARKERS; remote monitoring; speech assessment; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KHS3YFK7","journalArticle","2021","Pompodakis, EE; Kryonidis, GC; Alexiadis, MC","OLTC transformer model connecting 3-wire MV with 4-wire multigrounded LV networks","ELECTRIC POWER SYSTEMS RESEARCH","","0378-7796","10.1016/j.epsr.2020.107003","","This short communication presents a comprehensive model of on-load tap-changer (OLTC) transformers that connects 3-wire medium voltage (MV) with 4-wire multigrounded low voltage (LV) networks. The proposed model enables the inclusion of the 3-wire MV network and the 4-wire multigrounded LV network into a single YBUS matrix without any assumption or simplification. Its distinct feature is that the tap changer of the transformer is simulated outside the YBUS matrix, thus a refactorization of the YBUS matrix is not required in every tap change. The proposed transformer model has been validated in a 4-Bus network, while its performance has been tested in the IEEE 8500-Node and IEEE 906-Bus test networks.","2021-03","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","192","","","","","","","","","","English","","","","WOS:000613249300007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;8</p>","","","Multi-grounded networks; OLTC transformer; ZBUS power flow","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JRLT5S3I","journalArticle","2025","Lin, YJ","Multi-scale seismic impedance inversion based on Transformer model and deep learning","ENGINEERING RESEARCH EXPRESS","","2631-8695","10.1088/2631-8695/ada48d","","In this paper, we delve into the field of improving the accuracy and efficiency of seismic data processing through innovative applications of multiscale seismic impedance inversion techniques, underpinned by the transformative power of Transformer model architectures and the complexity of deep learning approaches. By crafting a deep learning model that seamlessly integrates the Transformer model framework with multi-faceted feature extraction strategies, we have achieved a breakthrough in accurate inversion of seismic wave impedance in complex geological landscapes, marking an important step forward in this field. In the experiments, we used a large dataset containing more than 1000 seismic data samples covering sandstone layers of varying thicknesses (3-15 m). After meticulous training and rigorous testing, our proposed method has surpassed conventional seismic impedance inversion methods, achieving a notable surge in accuracy. Precisely, the average error margin between the retrieved impedance data and the authentic logging data has been trimmed from 15% down to 12%. This improvement is particularly pronounced in the prediction of thin sand bodies with thicknesses ranging from 5 to 10 meters, where accuracy enhancements of up to 25% have been observed. This outcome not only validates the potency of Transformer models and deep learning technologies in tackling intricate seismic data processing challenges but also underscores the pivotal role of multi-scale analysis in elevating inversion precision to new heights. We also evaluated the computational efficiency of the model. Through optimization algorithm and hardware acceleration technology, the method in this paper achieves faster inversion speed while maintaining high accuracy, and the average single inversion time is shortened to 60% of that of the traditional method. This improvement is of great significance to improve the real-time and efficiency of seismic exploration. The multi-scale seismic impedance inversion technology based on Transformer model and deep learning proposed in this paper performs well in data analysis and practical applications, bringing new solutions and technical means to the field of seismic exploration.","2025-03-31","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","1","7","","","","","","","","","","English","","","","WOS:001393167500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","deep learning; geological structure prediction; multiscale analysis; PREDICTION; STATE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"49MMKR4R","journalArticle","2024","Chandrashekar, M; Lyngaas, I; Hanson, HA; Gao, S; Wu, XC; Gounley, J","Path-BigBird: An AI-Driven Transformer Approach to Classification of Cancer Pathology Reports","JCO CLINICAL CANCER INFORMATICS","","2473-4276","10.1200/CCI.23.00148","","PURPOSESurgical pathology reports are critical for cancer diagnosis and management. To accurately extract information about tumor characteristics from pathology reports in near real time, we explore the impact of using domain-specific transformer models that understand cancer pathology reports.METHODSWe built a pathology transformer model, Path-BigBird, by using 2.7 million pathology reports from six SEER cancer registries. We then compare different variations of Path-BigBird with two less computationally intensive methods: Hierarchical Self-Attention Network (HiSAN) classification model and an off-the-shelf clinical transformer model (Clinical BigBird). We use five pathology information extraction tasks for evaluation: site, subsite, laterality, histology, and behavior. Model performance is evaluated by using macro and micro F1 scores.RESULTSWe found that Path-BigBird and Clinical BigBird outperformed the HiSAN in all tasks. Clinical BigBird performed better on the site and laterality tasks. Versions of the Path-BigBird model performed best on the two most difficult tasks: subsite (micro F1 score of 72.53, macro F1 score of 35.76) and histology (micro F1 score of 80.96, macro F1 score of 37.94). The largest performance gains over the HiSAN model were for histology, for which a Path-BigBird model increased the micro F1 score by 1.44 points and the macro F1 score by 3.55 points. Overall, the results suggest that a Path-BigBird model with a vocabulary derived from well-curated and deidentified data is the best-performing model.CONCLUSIONThe Path-BigBird pathology transformer model improves automated information extraction from pathology reports. Although Path-BigBird outperforms Clinical BigBird and HiSAN, these less computationally expensive models still have utility when resources are constrained. Exploring advancements in cancer pathology research: Path-BigBird, a specialized transformer model, shows promise in extracting crucial tumor information from SEER cancer registry reports. Outperforming HiSAN and Clinical BigBird, it offers improved insights. A step toward enhanced pathology report analysis. #PathologyResearch #SEER #Transformers #LLM","2024-02","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","8","","","","","","","","","","English","","","","WOS:001261798900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y97BLRTL","journalArticle","2023","Ho, TL; Le, AC; Vu, DH","Multiview Fusion Using Transformer Model for Recommender Systems: Integrating the Utility Matrix and Textual Sources","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13106324","","Recommender systems are challenged with providing accurate recommendations that meet the diverse preferences of users. The main information sources for these systems are the utility matrix and textual sources, such as item descriptions, users' reviews, and users' profiles. Incorporating diverse sources of information is a reasonable approach to improving recommendation accuracy. However, most studies primarily use the utility matrix, and when they use textual sources they do not integrate them with the utility matrix. This is due to the risk of combined information causing noise and reducing the effectiveness of good sources. To overcome this challenge, in this study we propose a novel method that utilizes the Transformer Model, a deep learning model that efficiently integrates textual and utility matrix information. The study suggests feature extraction techniques suitable for each information source and an effective integration method in the Transformer model. The experimental results indicate that the proposed model significantly improves recommendation accuracy compared to the baseline model (MLP) for the Mean Absolute Error (MAE) metric, with a reduction range of 10.79% to 31.03% for the Amazon sub-datasets. Furthermore, when compared to SVD, which is known as one of the most efficient models for recommender systems, the proposed model shows a decrease in the MAE metric by a range of 34.82% to 56.17% for the Amazon sub-datasets. Our proposed model also outperforms the graph-based model with an increase of up to 108% in Precision, a decrease of up to 65.37% in MAE, and a decrease of up to 59.24% in RMSE. Additionally, experimental results on the Movielens and Amazon datasets also demonstrate that our proposed model, which combines information from the utility matrix and textual sources, yields better results compared to using only information from the utility matrix.","2023-05-22","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","10","13","","","","","","","","","","English","","","","WOS:000995524900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","deep neural network recommender system; FACTORIZATION; multiview; recommender system; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZYUZRPQG","journalArticle","2022","Wu, ZP; Cai, X; Zhang, CY; Qiao, HR; Wu, YJ; Zhang, Y; Wang, XQ; Xie, HY; Luo, F; Duan, HL","Self-Supervised Molecular Pretraining Strategy for Low-Resource Reaction Prediction Scenarios","JOURNAL OF CHEMICAL INFORMATION AND MODELING","","1549-9596","10.1021/acs.jcim.2c00588","","In the face of low-resource reaction training samples, we construct a chemical platform for addressing small-scale reaction prediction problems. Using a self-supervised pretraining strategy called MAsked Sequence to Sequence (MASS), the Transformer model can absorb the chemical information of about 1 billion molecules and then fine-tune on a small-scale reaction prediction. To further strengthen the predictive performance of our model, we combine MASS with the reaction transfer learning strategy. Here, we show that the average improved accuracies of the Transformer model can reach 14.07, 24.26, 40.31, and 57.69% in predicting the Baeyer-Villiger, Heck, C-C bond formation, and functional group interconversion reaction data sets, respectively, marking an important step to low-resource reaction prediction.","2022-09-21","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","","","","","","","","","","","English","","","","WOS:000864063600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","DISCOVERY; DRIVEN; MODEL; SYSTEM; TRANSFORMER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3Z4WF5HE","journalArticle","2023","Jiang, T; Feng, F; Cao, Y; Yang, HT; Raj, RSP","Image Segmentation Method for Athlete Knee Joint Injury Using Transformer Model by MIoT","BRAZILIAN ARCHIVES OF BIOLOGY AND TECHNOLOGY","","1516-8913","10.1590/1678-4324-2023230325","","The segmentation of athlete knee joint injury images can provide doctors with information about the location and extent of the athlete knee joint injury. Therefore, it is significant to segment the images of athlete knee joint injury. However, the traditional image segmentation method of athlete knee injury has the problems of low accuracy of mask region extraction, completion time of extraction and high error rate of segmentation. In the paper, we propose image segmentation method for athlete knee joint injury using the transformer model by the medical Internet of Things (MIoT). First, the MIoT was used as a way to obtain images of knee joint injury of athletes, and the images of knee joint injury of athletes were derived using the MIoT. Second, the exported image is input into the shadow expansion layer of the transformer model, which performs shadow expansion on the athlete knee joint injury image to obtain its mask region, and then the image is input into the patch embedding layer. Finally, after the patch embedding layer extracts the mask patch of the athlete knee joint injury image, the mask patch is input into the transformer block for down-sampling and up-sampling processing, and then the athlete knee joint injury image segmentation result is output using the end backpropagation layer. The results show that the proposed method has a low error rate in extracting the mask region from the knee joint injury image of athletes, and a short completion time for extracting the mask region, the most detailed and comprehensive segmented athlete knee joint injury image, the maximum error rate of image segmentation is only 6.8%, and the maximum value of segmentation time is only 3.96s. It has important research value in the field of athlete knee joint injury diagnosis.","2023","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","66","","","","","","","","","","English","","","","WOS:001151667400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","Athletes; Image segmentation; Knee joint injury; Mask patch; Medical Internet of Things; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TZ4H2VYI","journalArticle","2023","Grigoras, A; Leon, F","Transformer-Based Model for Predicting Customers' Next Purchase Day in e-Commerce","COMPUTATION","","2079-3197","10.3390/computation11110210","","The paper focuses on predicting the next purchase day (NPD) for customers in e-commerce, a task with applications in marketing, inventory management, and customer retention. A novel transformer-based model for NPD prediction is introduced and compared to traditional methods such as ARIMA, XGBoost, and LSTM. Transformers offer advantages in capturing long-term dependencies within time series data through self-attention mechanisms. This adaptability to various time series patterns, including trends, seasonality, and irregularities, makes them a promising choice for NPD prediction. The transformer model demonstrates improvements in prediction accuracy compared to the baselines. Additionally, a clustered transformer model is proposed, which further enhances accuracy, emphasizing the potential of this architecture for NPD prediction.","2023-11","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","11","11","","","","","","","","","","English","","","","WOS:001115345800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","e-commerce; forecasting; next purchase day; time series; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3HJUG9VI","journalArticle","2024","Ye, P; Chen, YF; Ma, SH; Xue, F; Crespi, N; Chen, XH; Fang, X","Security in Transformer Visual Trackers: A Case Study on the Adversarial Robustness of Two Models","SENSORS","","1424-8220","10.3390/s24144761","","Visual object tracking is an important technology in camera-based sensor networks, which has a wide range of practicability in auto-drive systems. A transformer is a deep learning model that adopts the mechanism of self-attention, and it differentially weights the significance of each part of the input data. It has been widely applied in the field of visual tracking. Unfortunately, the security of the transformer model is unclear. It causes such transformer-based applications to be exposed to security threats. In this work, the security of the transformer model was investigated with an important component of autonomous driving, i.e., visual tracking. Such deep-learning-based visual tracking is vulnerable to adversarial attacks, and thus, adversarial attacks were implemented as the security threats to conduct the investigation. First, adversarial examples were generated on top of video sequences to degrade the tracking performance, and the frame-by-frame temporal motion was taken into consideration when generating perturbations over the depicted tracking results. Then, the influence of perturbations on performance was sequentially investigated and analyzed. Finally, numerous experiments on OTB100, VOT2018, and GOT-10k data sets demonstrated that the executed adversarial examples were effective on the performance drops of the transformer-based visual tracking. White-box attacks showed the highest effectiveness, where the attack success rates exceeded 90% against transformer-based trackers.","2024-07","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","14","24","","","","","","","","","","English","","","","WOS:001277416900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","adversarial attacks; autonomous driving; transformer model; visual tracking","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ECWIQHAW","journalArticle","2024","Mei, YX; Jin, ZC; Ma, WG; Ma, YJ; Deng, N; Fan, ZY; Wei, SJ","Optimizing Acute Coronary Syndrome Patient Treatment: Leveraging Gated Transformer Models for Precise Risk Prediction and Management","BIOENGINEERING-BASEL","","2306-5354","10.3390/bioengineering11060551","","Background: Acute coronary syndrome (ACS) is a severe cardiovascular disease with globally rising incidence and mortality rates. Traditional risk assessment tools are widely used but are limited due to the complexity of the data. Methods: This study introduces a gated Transformer model utilizing machine learning to analyze electronic health records (EHRs) for an enhanced prediction of major adverse cardiovascular events (MACEs) in ACS patients. The model's efficacy was evaluated using metrics such as area under the curve (AUC), precision-recall (PR), and F1-scores. Additionally, a patient management platform was developed to facilitate personalized treatment strategies. Results: Incorporating a gating mechanism substantially improved the Transformer model's performance, especially in identifying true-positive cases. The TabTransformer+Gate model demonstrated an AUC of 0.836, a 14% increase in average precision (AP), and a 6.2% enhancement in accuracy, significantly outperforming other deep learning approaches. The patient management platform enabled healthcare professionals to effectively assess patient risks and tailor treatments, improving patient outcomes and quality of life. Conclusion: The integration of a gating mechanism within the Transformer model markedly increases the accuracy of MACE risk predictions in ACS patients, optimizes personalized treatment, and presents a novel approach for advancing clinical practice and research.","2024-06","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","6","11","","","","","","","","","","English","","","","WOS:001254658700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","acute coronary syndrome; machine learning; major adverse cardiovascular events; patient management; risk assessment; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IB49U89S","journalArticle","2024","Khalil, IU; Ul Haq, A; ul Islam, N","A deep learning-based transformer model for photovoltaic fault forecasting and classification","ELECTRIC POWER SYSTEMS RESEARCH","","0378-7796","10.1016/j.epsr.2023.110063","","According to the US-based National Renewable Energy Lab (NREL), solar energy losses due to faults were 3.5 % in 2004, which increased to 17.5 % in 2018. Therefore, the fault prediction mechanism will enable PV practitioners to reduce losses effectively, enhancing the solar system's efficiency and power output. This paper proposes a deep learning-based Transformer model for robust fault prediction in photovoltaic. Transformer uses attention mechanism that considers data points as a language units ""word"" and learn dependencies among them to predict upcoming data points. Unlike other forecasting algorithms, our proposed approach does not rely on previous trends. In case of PV faults, trends do not exist. The proposed algorithm utilizes rate of change of solar cell parameters for establishing a trend to forecast faults, enabling proactive fault mitigation. It also classifies faults with different severity levels to identify the level of predictive maintenance required. The proposed approach is extensively evaluated using MATLAB on datasets of several faults with low, medium, and high severity levels. The proposed Transformer model achieves a forecasting mean average error (MAE) of 0.09377. Performance of the proposed forecasting and classification algorithm is compared with existing machine learning-based regression and classification techniques such as KNN, SVM, and NN, where proposed approach outperforms state-of-the-art approaches.","2024-03","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","228","","","","","","","","","","English","","","","WOS:001139374400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Fault classification; Fault forecasting; Fault ride through; NETWORKS; Solar cell parameters; Transformers; WIND","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9JTRS9KS","journalArticle","2025","Özen, S; Yazici, A; Atalay, V","Hybrid deep learning models with data fusion approach for electricity load forecasting","EXPERT SYSTEMS","","0266-4720","10.1111/exsy.13741","","This study explores the application of deep learning in forecasting electricity consumption. Initially, we assess the performance of standard neural networks, such as convolutional neural networks (CNN) and long short-term memory (LSTM), along with basic methods like ARIMA and random forest, on a univariate electricity consumption data set. Subsequently, we develop hybrid models for a comprehensive multivariate data set created by merging weather and electricity data. These hybrid models demonstrate superior performance compared to individual models on the univariate data set. Our main contribution is the introduction of a novel hybrid data fusion model. This model integrates a single-model approach for univariate data, a hybrid model for multivariate data, and a linear regression model that processes the outputs from both. Our hybrid fusion model achieved an RMSE value of 0.0871 on the Chicago data set, outperforming other models such as Random Forest (0.2351), ARIMA (0.2184), CNN (0.1802), LSTM + LSTM (0.1496), and CNN + LSTM (0.1587). Additionally, our model surpassed the performance of our base transformer model. Furthermore, combining the best-performing transformer model, with a Gaussian Process model resulted in further improvement in performance. The Transformer + Gaussian model achieved an RMSE of 0.0768, compared with 0.0781 for the single transformer model. Similar trends were observed in the Pittsburgh and IHEC data sets.","2025-02","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","2","42","","","","","","","","","","English","","","","WOS:001321463600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","data fusion; deep learning; hybrid models; load forecasting; NEURAL-NETWORKS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DMJUDCPG","journalArticle","2024","Li, ZY; Zhang, XW; Gao, W","State of health estimation of lithium-ion battery during fast charging process based on BiLSTM-Transformer","ENERGY","","0360-5442","10.1016/j.energy.2024.133418","","Lithium-ion batteries are the main energy source of electric vehicles, and the fast charging with a high-rate current is usually used to shorten the charging time. However, the high-rate current may accelerate the performance degradation of lithium-ion batteries and cause thermal runaway safety problems. Therefore, it is important to monitor the state of health (SOH) of lithium-ion batteries during the fast charging process. In this paper, a BiLSTM-Transformer model is proposed to estimate SOH of lithium-ion batteries during the fast charging process. Aging tests of lithium-ion batteries are performed at four different charging currents, and four features highly correlated with SOH are extracted from the voltage curve of the constant current charging stage. A BiLSTM-Transformer model is established with the four features as input and the SOH as output. The model was verified with the experimental dataset and the public dataset at different charging conditions separately, and it was also compared with other popular data-driven methods. The results show that the errors of the BiLSTMTransformer model are all within 0.6%, which has the highest accuracy and best generalization performance compared with SVR and LSTM. Therefore, the BiLSTM-Transformer model is an effective SOH estimation method of lithium-ion batteries during the fast charging process.","2024-12-01","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","311","","","","","","","","","","English","","","","WOS:001337148000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","BiLSTM-Transformer; Fast charging; Lithium-ion battery; SOH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZTA34IZ4","journalArticle","2023","Zhao, JW; Nie, GZ; Yan, M; Wang, YW; Wang, LY","A novel approach to precipitation prediction using a coupled CEEMDAN-GRU-Transformer model with permutation entropy algorithm","WATER SCIENCE AND TECHNOLOGY","","0273-1223","10.2166/wst.2023.257","","The accurate forecasting of precipitation in the upper reaches of the Yellow River is imperative for enhancing water resources in both the local and broader Yellow River basin in the present and future. While many models exist for predicting precipitation by analyzing historical data, few consider the impact of different frequency sequences on model accuracy. In this study, we propose a coupled monthly precipitation prediction model that leverages the adaptive noise complete ensemble empirical mode decomposition with adaptive noise (CEEMDAN), gated recurrent unit neural network (GRU), and attention mechanism-based transformer model. The permutation entropy (PE) algorithm is employed to partition the data processed by CEEMDAN into different frequencies, with different models utilized to predict different frequencies. The predicted results are subsequently combined to obtain the monthly precipitation prediction value. The model is applied to precipitation prediction in four regions in the upper reaches of the Yellow River and compared with other models. Evaluation results demonstrate that the CEEMDAN-GRU-Transformer model outperforms other models in predicting precipitation for these regions, with a coefficient of determination R-2 greater than 0.8. These findings suggest that the proposed model provides a novel and effective method for improving the accuracy of regional medium and long-term precipitation prediction.","2023-08-15","2025-02-26 20:37:02","2025-02-26 20:37:02","","1015-1038","","4","88","","","","","","","","","","English","","","","WOS:001047066200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","combined model; DECOMPOSITION; MACHINE; monthly precipitation prediction; permutation entropy algorithm; upper Yellow River; water resources","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PVV37X64","journalArticle","2023","Al-Ali, EM; Hajji, Y; Said, Y; Hleili, M; Alanzi, AM; Laatar, AH; Atri, M","Solar Energy Production Forecasting Based on a Hybrid CNN-LSTM-Transformer Model","MATHEMATICS","","2227-7390","10.3390/math11030676","","Green energy is very important for developing new cities with high energy consumption, in addition to helping environment preservation. Integrating solar energy into a grid is very challenging and requires precise forecasting of energy production. Recent advances in Artificial Intelligence have been very promising. Particularly, Deep Learning technologies have achieved great results in short-term time-series forecasting. Thus, it is very suitable to use these techniques for solar energy production forecasting. In this work, a combination of a Convolutional Neural Network (CNN), a Long Short-Term Memory (LSTM) network, and a Transformer was used for solar energy production forecasting. Besides, a clustering technique was applied for the correlation analysis of the input data. Relevant features in the historical data were selected using a self-organizing map. The hybrid CNN-LSTM-Transformer model was used for forecasting. The Fingrid open dataset was used for training and evaluating the proposed model. The experimental results demonstrated the efficiency of the proposed model in solar energy production forecasting. Compared to existing models and other combinations, such as LSTM-CNN, the proposed CNN-LSTM-Transformer model achieved the highest accuracy. The achieved results show that the proposed model can be used as a trusted forecasting technique that facilitates the integration of solar energy into grids.","2023-02","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","3","11","","","","","","","","","","English","","","","WOS:000930377500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;35<br/>Total Times Cited:&nbsp;&nbsp;36<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","convolutional neural network; forecasting; long short-term memory network; MACHINE MODEL; solar energy production; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PVU7MNVI","journalArticle","2024","Zhao, N; Duan, ZG; Li, Q; Guo, K; Zhang, ZG; Liu, BA","A cable insulation defect classification method based on CNN-transformer","FRONTIERS IN PHYSICS","","2296-424X","10.3389/fphy.2024.1432527","","Cable insulation defect detection ensures electrical safety, prevents accidents, extends equipment life and guarantees stable system operation. For the traditional cable insulation defect detection and identification of difficult problems, this paper proposes the use of ultrasonic cable insulation defect detection and combined with the Convolutional Neural Network (CNN)-transformer model of cable insulation defect classification method. Firstly, the ultrasonic probe is used to obtain different cable insulation defect signals, and then the CNN-transformer model is used to classify different cable insulation defects. The CNN is used to initially extract the characteristics of the cable insulation defects from the input signals, and then the multi-attention mechanism in the time series Transformer is used to extract the transient local and periodic global characteristics of the cable insulation defect signals. The deeper transient local features and periodic global features of the cable insulation defect signal are extracted by the multi-attention mechanism in the time series Transformer; finally, the recognition results are outputted by the fully connected layer and softmax classifier. The results show that ultrasonic reflection and transmission phenomena occur at the defects, and different defects can be accurately reflected by the defect echo time and amplitude, and the accuracy of cable insulation defect recognition using the CNN-transformer model reaches 100%, with good generalization ability.","2024-08-01","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","12","","","","","","","","","","English","","","","WOS:001290701500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","cable; CNN-transformer; defect recognition; ELEMENT-METHOD; insulation defect; ultrasonic reflection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WRAXCP8N","journalArticle","2024","Guo, X; Yang, D; Jiang, L; Du, T; Lyu, S","Full-field temperature prediction in tunnel fires using limited monitored ceiling flow temperature data with transformer-based deep learning models","FIRE SAFETY JOURNAL","","0379-7112","10.1016/j.firesaf.2024.104232","","In practical tunnel scenarios, full-field coverage of sensors is impractical and costly. During a tunnel fire, the available information is constrained and localized, making the prediction of full-field smoke temperature distribution becoming a noteworthy challenge. This study proposes a transformer-based deep learning model to predict full-field smoke temperature distributions during fire incidents in real-time using limited temporal data from the sensors installed in localized regions below the ceiling, considering heat release rate of the fire source is unknown. The results indicate that proposed approach can predict the longitudinal temperature distribution throughout the tunnel with a length of 750 m by leveraging temperature data from limited sensors within a monitoring length of 210 m. It can further predict the vertical temperature profiles, and eventually estimate the full-field temperature distribution within the tunnel. The transformer model achieved R2 of 0.95 and 0.87 for longitudinal and vertical temperature distribution predictions, respectively. Under the influence of the selfattention mechanism, the transformer model has an advantage over the long short-term memory model in capturing global information, enhancing the accuracy of longitudinal temperature distribution predictions by 18.8 %. This study significantly contributes to effective emergency response and rescue strategies during tunnel fire incidents.","2024-09","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","148","","","","","","","","","","English","","","","WOS:001279844800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Attention-based transformer model; Full-field prediction; LENGTH; Limited monitored data; SAFETY; Smoke temperature","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DIPK7AZ8","journalArticle","2024","Li, ZC; Peng, YP; Li, J; Tang, ZY","Composite Foundation Settlement Prediction Based on LSTM-Transformer Model for CFG","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14020732","","Roadbed construction typically employs layered and staged filling, characterized by a periodic feature of 'layered filling-filling interval'. The load and settlement histories established during staged construction offer crucial insights into long-term deformation under filling loads. However, models often rely solely on post-construction settlement data, neglecting the rich filling data. To accurately predict composite foundation ground (CFG) settlement, an LSTM-Transformer deep learning model is used. Five factors from the 'fill height-time-foundation settlement' curve are extracted as input variables. The first-layer LSTM model's gate units capture long-term dependencies, while the second-layer Transformer model's self-attention mechanism focuses on key features, efficiently and accurately predicting ground settlement. The model is trained and analyzed based on the newly constructed Changsha-Zhuzhou-Xiangtan intercity railway section CSLLXZQ-1, which has a CFG pile composite foundation. The research shows that the proposed LSTM-Transformer model for the settlement prediction of composite foundations has an average absolute error, mean absolute percentage error, and root mean square error of 0.224, 0.563%, and 0.274, respectively. Compared to SVM, LSTM, and Transformer neural network models, it demonstrates higher prediction accuracy, indicating better reliability and practicality. This can provide a new approach and method for the settlement prediction of newly constructed CFG composite foundations.","2024-01","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","2","14","","","","","","","","","","English","","","","WOS:001148971800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","deep learning; filling information; ground settlement; LSTM-Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4CUKPLDF","journalArticle","2024","Li, C; Fan, MB; Cao, BH; Ye, B; Wang, Q; Jiang, JY","Thickness Measurement of Thermal Barrier Coating Based on Mutual Inductance of Eddy Current System","IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS","","0278-0046","10.1109/TIE.2023.3312422","","Thickness of thermal barrier coating (TBC) plays an important role in the insulation property of coating. Eddy current (EC) testing could be used to measure the thickness of ceramic coating (TC) for TBCs. However, previous EC testing has made it difficult to decouple the relationship between TC, bond coating (BC), and substrate. In this study, an accurate and simple method of TC thickness measurement is proposed based on the mutual inductance and the transformer model, which is immune to the BC and the substrate. First, an EC system is analyzed using the transformer model. Second, mutual inductance is formulated with the Neumann formula and the Taylor series, and the coupling coefficient is established according to the approximate and simplified mutual inductance expression. Third, the coupling relationship is revealed, and the combination of the change in inductance and the phase signature serves as the new feature to characterize the thickness of TC immune to the variation in BC and substrate. Finally, an EC detection system is designed, and experiments are carried out to evaluate the thickness of TC. The results show that the relative errors are less than 5% and the method has a good inhibition effect on the change in temperature.","2024-07","2025-02-26 20:37:02","2025-02-26 20:37:02","","8102-8112","","7","71","","","","","","","","","","English","","","","WOS:001076255700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","COILS; CONDUCTIVITY; Detecting system; DRIFT COMPENSATION; eddy current (EC); FORMULA; inductance; SENSORS; thermal barrier coating (TBC); thickness of ceramic layer; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UYW82QQ7","journalArticle","2023","Zai, ZP; Zhao, S; Zhang, ZJ; Li, HL; Sun, NQ","Non-Intrusive Load Monitoring Based on the Combination of Gate-Transformer and CNN","ELECTRONICS","","2079-9292","10.3390/electronics12132824","","Non-intrusive load monitoring (NILM) is the practice of estimating power consumption of a single household appliance using data from a total power meter of the user's house. The transformer model has emerged as a popular method for handling NILM problems. However, with the increase in data from electricity meters, there is a need for research focusing on the accuracy and computational complexity of the transformer model. To address this, this paper proposes a sequence-to-sequence load decomposition structure named GTCN, which combines the gate-transformer and convolutional neural networks (CNNs). GTCN introduces a gating mechanism to reduce the number of parameters for training the model while maintaining performance. The introduction of CNNs can effectively capture local features that the gate-transformer may not be able to capture, thereby improving the accuracy of power estimation of individual household appliances. The results of the experiments, based on the UK-DALE dataset, illustrate that GTCN not only demonstrates excellent decomposition performance but also reduces the model parameters compared to conventional transformers. Moreover, the proposed GTCN structure, despite maintaining the same number of model parameters as the traditional transformer architecture after incorporating CNNs, outperforms the conventional transformer model, as well as current seq2seq and R-LSTM technologies, and achieves enhanced prediction accuracy and improved generalization capability.","2023-07","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","13","12","","","","","","","","","","English","","","","WOS:001028152100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","convolutional neural network; gate-transformer; gating mechanism; generalization ability; non-intrusive load monitoring","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XPCTNS3F","journalArticle","2024","Cao, Y; Zhou, XY; Yu, YQ; Rao, SY; Wu, YH; Li, CP; Zhu, ZL","Forest Fire Prediction Based on Time Series Networks and Remote Sensing Images","FORESTS","","1999-4907","10.3390/f15071221","","Protecting forest resources and preventing forest fires are vital for social development and public well-being. However, current research studies on forest fire warning systems often focus on extensive geographic areas like states, counties, and provinces. This approach lacks the precision and detail needed for predicting fires in smaller regions. To address this gap, we propose a Transformer-based time series forecasting model aimed at improving the accuracy of forest fire predictions in smaller areas. Our study focuses on Quanzhou County, Guilin City, Guangxi Province, China. We utilized time series data from 2021 to 2022, along with remote sensing images and ArcGIS technology, to identify various factors influencing forest fires in this region. We established a time series dataset containing twelve influencing factors, each labeled with forest fire occurrences. By integrating these data with the Transformer model, we generated forest fire danger level prediction maps for Quanzhou County. Our model's performance is compared with other deep learning methods using metrics such as RMSE, and the results reveal that the proposed Transformer model achieves higher accuracy (ACC = 0.903, MAPE = 0.259, MAE = 0.053, RMSE = 0.389). This study demonstrates that the Transformer model effectively takes advantage of spatial background information and the periodicity of forest fire factors, significantly enhancing predictive accuracy.","2024-07","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","7","15","","","","","","","","","","English","","","","WOS:001277481900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","ATTENTION; BURNED AREA; deep learning; forest fire; prediction; RISK; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6MH6W9TH","journalArticle","2022","Fuad, A; Al-Yahya, M","Cross-Lingual Transfer Learning for Arabic Task-Oriented Dialogue Systems Using Multilingual Transformer Model mT5","MATHEMATICS","","2227-7390","10.3390/math10050746","","Due to the promising performance of pre-trained language models for task-oriented dialogue systems (DS) in English, some efforts to provide multilingual models for task-oriented DS in low-resource languages have emerged. These efforts still face a long-standing challenge due to the lack of high-quality data for these languages, especially Arabic. To circumvent the cost and time-intensive data collection and annotation, cross-lingual transfer learning can be used when few training data are available in the low-resource target language. Therefore, this study aims to explore the effectiveness of cross-lingual transfer learning in building an end-to-end Arabic task-oriented DS using the mT5 transformer model. We use the Arabic task-oriented dialogue dataset (Arabic-TOD) in the training and testing of the model. We present the cross-lingual transfer learning deployed with three different approaches: mSeq2Seq, Cross-lingual Pre-training (CPT), and Mixed-Language Pre-training (MLT). We obtain good results for our model compared to the literature for Chinese language using the same settings. Furthermore, cross-lingual transfer learning deployed with the MLT approach outperform the other two approaches. Finally, we show that our results can be improved by increasing the training dataset size.","2022-03","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","5","10","","","","","","","","","","English","","","","WOS:000768172700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","Arabic language; cross-lingual transfer learning; mixed-language pre-training; mT5; multilingual transformer model; natural language processing; task-oriented dialogue systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RPD6H9D2","journalArticle","2025","Zhang, H; Yang, G; Yu, HL; Zheng, Z","Traffic flow prediction based on the RETGCN model","COMPUTING","","0010-485X","10.1007/s00607-024-01402-x","","Traffic flow prediction, as a key link in the intelligent transportation system, assumes the important role of efficiently guiding the traffic flow, evacuating, congestion, reducing traffic accidents, and so on. However, due to the complex spatial and temporal correlation of traffic flow data, it faces the problem of inaccurate short-term prediction. In this paper, we adopt retentive network (RETNET) as the infrastructure of large-scale language model, which is similar to the Transformer model, but combines the recursive advantage of RNN to realize the efficient operation of parallelism and recursion. The RETNET model also handles the long sequences of information by stacking the same modules, but the difference is that it introduces multi-scale retention module (MSR) instead of the multi-head attention mechanism in the Transformer model, and adopts the chunked recursive approach to reduce the inference cost and improve the decoding throughput. Transformer model, and adopts chunked recursive parallel processing to reduce the inference cost and improve the decoding throughput. It is then combined with a Chebyshev graph convolutional neural network to utilize the spatial correlation of graph nodes to aggregate and update the features of road intersection nodes. The temporal and spatial information of traffic flow data is fully utilized by the combined spatial and temporal feature extraction, which improves the accuracy and robustness of traffic flow prediction.","2025-01","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","1","107","","","","","","","","","","English","","","","WOS:001392369400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","GCN; ITS; RETNET; Spatio-temporal","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W7KD6KDA","journalArticle","2024","Li, YC; Chen, SX; Liu, ZY; Che, C; Zhong, ZQ","Translation model based on discrete Fourier transform and Skipping Sub-Layer methods","INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS","","1868-8071","10.1007/s13042-024-02156-w","","Machine translation quality has seen tremendous improvement since the development of neural machine translation. However, translation models are memory intensive, with expensive hardware facilities and slow training speed. To reduce memory requirements and speed up translation, we propose the Transformer Discrete Fourier method with Skipping Sub-Layer (TF-SSL), which incorporates the discrete Fourier transform and a Skipping Sub-Layer algorithm, after relative positional embedding for Chinese and English source sentences. The input sequence is based on a Transformer model in the relative positional embedding layer, and the text is transformed into word vectors with information encoding via the embedding matrix, so that the word vectors can effectively capture interdependences between the texts. We distribute the transform coefficient matrix after the 2D Fourier transform near the center of the Encoder layer with a short matrix of transform coefficients, which accelerates translation on a GPU. The accuracy and speed are improved by skipping the sub-layer method, and the sub-layer is randomly omitted to introduce disturbance to the training, thus imposing greater constraint effects on the sub-layers. We conduct the ablation study and comparative analyses. Results show that our approach achieves improvement in both BLEU scores and GFLOPS values compared to the baseline Transformer model and other deep learning models.","2024-10","2025-02-26 20:37:02","2025-02-26 20:37:02","","4435-4444","","10","15","","","","","","","","","","English","","","","WOS:001206027100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Discrete Fourier transform; Neural machine translation; Relative positional embedding; Skipping Sub-Layer method; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T3W2VN2V","journalArticle","2022","Paul, A; Mitra, S","Deep reinforcement learning based cooperative control of traffic signal for multi-intersection network in intelligent transportation system using edge computing","TRANSACTIONS ON EMERGING TELECOMMUNICATIONS TECHNOLOGIES","","2161-3915","10.1002/ett.4588","","In the current era, the coordination of traffic flow is hindered by the discrepancy between road infrastructure and the number of vehicles which leads to traffic congestion. One of the widely used strategies to mitigate traffic congestion is to control traffic signals with the help of deep reinforcement learning (DRL) in edge computing based intelligent transportation system. This article provides a comprehensive analysis of the most recent DRL algorithms, advantage actor-critic and proximal policy optimization in multiple deep neural networks (DNNs), including a state-of-the-art transformer model for effective traffic signal management. Here, a single DRL agent is used, which obtains the spatio-temporal information of the traffic to identify traffic patterns from complex intersection environments. The agent uses this information as the input to the DNNs and then applies the algorithms to retrieve the essential parameters of DNN to seek an optimal action selection policy to mitigate congestion. Different real-time maps and small city networks are explored here to determine which DNN is best suited for traffic congestion management. The simulation study reveals that both the algorithms significantly outperform the baseline. The transformer model gives the best result when compared to other DNNs. The transformer model decreases average waiting time by 96.16%, implying that it has a higher capability of dealing with congested environments.","2022-11","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","11","33","","","","","","","","","","English","","","","WOS:000881472000014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TC3L55P8","journalArticle","2024","Li, LL; Li, JX; Wang, HL; Nie, JN","Application of the transformer model algorithm in chinese word sense disambiguation: a case study in chinese language","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-56976-5","","This study aims to explore the research methodology of applying the Transformer model algorithm to Chinese word sense disambiguation, seeking to resolve word sense ambiguity in the Chinese language. The study introduces deep learning and designs a Chinese word sense disambiguation model based on the fusion of the Transformer with the Bi-directional Long Short-Term Memory (BiLSTM) algorithm. By utilizing the self-attention mechanism of Transformer and the sequence modeling capability of BiLSTM, this model efficiently captures semantic information and context relationships in Chinese sentences, leading to accurate word sense disambiguation. The model's evaluation is conducted using the PKU Paraphrase Bank, a Chinese text paraphrase dataset. The results demonstrate that the model achieves a precision rate of 83.71% in Chinese word sense disambiguation, significantly outperforming the Long Short-Term Memory algorithm. Additionally, the root mean squared error of this algorithm is less than 17, with a loss function value remaining around 0.14. Thus, this study validates that the constructed Transformer-fused BiLSTM-based Chinese word sense disambiguation model algorithm exhibits both high accuracy and robustness in identifying word senses in the Chinese language. The findings of this study provide valuable insights for advancing the intelligent development of word senses in Chinese language applications.","2024-03-15","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","1","14","","","","","","","","","","English","","","","WOS:001185967600034","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","BiLSTM; Chinese language; Root mean squared error; Transformer model algorithm; Word sense disambiguation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YCD7XMKX","journalArticle","2025","Ma, K; Zhang, JZ; Huang, XH; Wang, MY","Leveraging transformer models to predict cognitive impairment: accuracy, efficiency, and interpretability","BMC PUBLIC HEALTH","","1471-2458","10.1186/s12889-025-21762-z","","ObjectiveThis study aims to develop an enhanced Transformer model for predicting mild cognitive impairment (MCI) using data from the China Health and Retirement Longitudinal Study (CHARLS), focusing on handling mixed data types and improving predictive accuracy.MethodsThe Transformer integrates categorical (integer-encoded) and continuous (floating-point) data, using multi-head attention with four heads to capture complex relationships. Preprocessing involved separate embedding layers for categorical data and feed-forward networks for continuous data. The model was compared with SVM and XGBoost, trained for 150 epochs with RMSProp and a cosine annealing scheduler. Key metrics included accuracy, Mean Absolute Error (MAE) tolerance, and training loss. An attention heatmap was generated to visualize feature importance.ResultsThe Transformer outperformed SVM and XGBoost, achieving over 90% accuracy at an MAE tolerance of 3.5. The model showed rapid convergence, with loss stabilizing within 20 epochs. The attention heatmap highlighted key features, confirming the effectiveness of the multi-head attention mechanism in identifying relevant variables.ConclusionThe enhanced Transformer model offers superior accuracy and efficiency in predicting cognitive decline compared to traditional models. Its capacity to process both continuous and categorical data and its interpretability through attention mechanisms make it a promising tool for early detection of neurodegenerative diseases, potentially improving clinical decision-making and interventions.","2025-02-07","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","1","25","","","","","","","","","","English","","","","WOS:001416350900017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","Alzheimer's disease (AD); CHINA HEALTH; DEPRESSIVE SYMPTOMS; Machine learning; Mild cognitive impairment (MCI); Neurodegenerative disease prediction; OLDER-ADULTS; POPULATION; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8PYU6DA6","journalArticle","2024","Zhang, WW; Jia, JF; Pang, XQ; Wen, J; Shi, YH; Zeng, JC","An Improved Transformer Model for Remaining Useful Life Prediction of Lithium-Ion Batteries under Random Charging and Discharging","ELECTRONICS","","2079-9292","10.3390/electronics13081423","","With the development of artificial intelligence and deep learning, deep neural networks have become an important method for predicting the remaining useful life (RUL) of lithium-ion batteries. In this paper, drawing inspiration from the transformer sequence-to-sequence task's transformation capability, we propose a fusion model that integrates the functions of the stacked denoising autoencoder (SDAE) and the Transformer model in order to improve the performance of RUL prediction. Firstly, the health factors under three different conditions are extracted from the measurement data as model inputs. These conditions include constant current and voltage, random discharge, and the application of principal component analysis (PCA) for dimensionality reduction. Then, SDAE is responsible for denoising and feature extraction, and the Transformer model is utilized for sequence modeling and RUL prediction of the processed data. Finally, accurate prediction of the RUL of the four battery cells is achieved through cross-validation and four sets of comparison experiments. Three evaluation metrics, MAE, RMSE, and MAPE, are selected, and the values of these metrics are 0.170, 0.202, and 19.611%, respectively. The results demonstrate that the proposed method outperforms other prediction models in terms of prediction accuracy, robustness, and generalizability. This provides a new solution direction for the daily life prediction research of lithium-ion batteries.","2024-04","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","8","13","","","","","","","","","","English","","","","WOS:001210060700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","health factors; lithium-ion batteries; remaining useful life; stacked denoising autoencoders; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BSFTBQMG","journalArticle","2024","Chen, ZC; Wang, GQ; Lv, T; Zhang, X","Using a Hybrid Convolutional Neural Network with a Transformer Model for Tomato Leaf Disease Detection","AGRONOMY-BASEL","","2073-4395","10.3390/agronomy14040673","","Diseases of tomato leaves can seriously damage crop yield and financial rewards. The timely and accurate detection of tomato diseases is a major challenge in agriculture. Hence, the early and accurate diagnosis of tomato diseases is crucial. The emergence of deep learning has dramatically helped in plant disease detection. However, the accuracy of deep learning models largely depends on the quantity and quality of training data. To solve the inter-class imbalance problem and improve the generalization ability of the classification model, this paper proposes a cycle-consistent generative-adversarial-network-based Transformer model to generate diseased tomato leaf images for data augmentation. In addition, this paper uses a Transformer model and densely connected CNN architecture to extract multilevel local features. The Transformer module is utilized to capture global dependencies and contextual information accurately to expand the sensory field of the model. Experiments show that the proposed model achieved 99.45% accuracy on the PlantVillage dataset. The 2018 Artificial Intelligence Challenger dataset and the private dataset attained accuracies of 98.30% and 95.4%, and the proposed classification model achieved a higher accuracy and smaller model size compared to previous deep learning models. The classification model is generalizable and robust and can provide a stable theoretical framework for crop disease prevention and control.","2024-04","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","4","14","","","","","","","","","","English","","","","WOS:001210211300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","cycle-consistent generative adversarial network; deep learning; tomato disease; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y8VKAJIS","journalArticle","2022","Fuad, A; Al-Yahya, M","AraConv: Developing an Arabic Task-Oriented Dialogue System Using Multi-Lingual Transformer Model mT5","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app12041881","","Task-oriented dialogue systems (DS) are designed to help users perform daily activities using natural language. Task-oriented DS for English language have demonstrated promising performance outcomes; however, developing such systems to support Arabic remains a challenge. This challenge is mainly due to the lack of Arabic dialogue datasets. This study introduces the first Arabic end-to-end generative model for task-oriented DS (AraConv), which uses the multi-lingual transformer model mT5 with different settings. We also present an Arabic dialogue dataset (Arabic-TOD) and used it to train and test the proposed AraConv model. The results obtained are reasonable compared to those reported in the studies of English and Chinese using the same mono-lingual settings. To avoid problems associated with a small training dataset and to improve the AraConv model's results, we suggest joint-training, in which the model is jointly trained on Arabic dialogue data and data from one or two high-resource languages such as English and Chinese. The findings indicate the AraConv model performed better in the joint-training setting than in the mono-lingual setting. The results obtained from AraConv on the Arabic dialogue dataset provide a baseline for other researchers to build robust end-to-end Arabic task-oriented DS that can engage with complex scenarios.","2022-02","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","4","12","","","","","","","","","","English","","","","WOS:000767573500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","Arabic; mT5; multi-lingual transformer model; natural language processing; task-oriented dialogue systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RI4YNXZ3","journalArticle","2024","Li, C; Fan, MB; Cao, BH; Ye, B; Yan, JH","Eddy Current Instrumentation of Bond Coating Thickness by Developing Three-Winding Transformer Model","IEEE-ASME TRANSACTIONS ON MECHATRONICS","","1083-4435","10.1109/TMECH.2024.3427330","","The thickness of the metal bond coating (BC) is an important indicator to characterize the quality of thermal barrier coating (TBC). The previous eddy current (EC) testing could hardly establish a direct method to characterize the BC thickness and reduce the influence of the ceramic coating (TC). In this article, an efficient, simple, and direct method of the BC thickness measurement was proposed, which could reduce the influence of the TC. First, the three-winding transformer model was creatively built to analyze the relationships among the impedance signal, the electromagnetic parameters, and the geometric structure of the TBC, and it was found that the phase signature has a linear relationship with the exponential square of the BC thickness. Second, the influences of the TC thickness were considered using the finite-element model in the BC thickness measurement. The intercept of the phase signature could reflect the change of the TC thickness linearly. The measurement errors of the BC thicknesses were greatly reduced after compensating the TC thicknesses. Finally, an EC detection instrument was designed, and the experiments were carried out to evaluate the BC thickness. The results show that the maximum relative error is less than 10%.","2024-07-25","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","","","","","","","","","","","English","","","","WOS:001279052900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Coatings; Coils; Detecting system; eddy current (EC); Inductance; phase signature; Substrates; Testing; thermal barrier coating (TBC); Thickness measurement; thickness of bond coating (BC); three-winding transformer model; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HXA9XPH9","journalArticle","2025","Ma, XT; Zeng, TC; Zhang, M; Zeng, PY; Lin, BR; Lu, S","Street microclimate prediction based on Transformer model and street view image in high-density urban areas","BUILDING AND ENVIRONMENT","","0360-1323","10.1016/j.buildenv.2024.112490","","The frequent occurrence of extreme heat highlights the need to provide pedestrians with street microclimatic information. However, existing microclimate prediction methods can't achieve both high computational efficiency and fine accuracy over large areas. This study addresses this issue by employing a deep learning algorithm and a transformer model integrated with street view images. The model was trained and tested in high-density areas of Hong Kong. The results showed that the model can predict hourly mean radiant temperature (MRT) and wind speed with high spatial resolution accurately and efficiently, with high R2 of 0.99 and 0.82 and low RMSE of 1.53 degrees C and 0.14 m/s, respectively. Our model demonstrated higher prediction accuracy than two existing models. Moreover, our model exhibited a strong ability to generalize in new areas and real-life scenarios, particularly for MRT, with R2 of 0.98 and 0.93 and RMSE of 2.34 degrees C and 4.15 degrees C, respectively. The significance of the model lies not only in predicting hourly microclimate in high spatial resolution efficiently using easily acquirable street view images instead of 3D models, but also in facilitating pedestrians to choose walk paths, assisting in accurate building energy estimations, and designing thermally comfortable streets through 2D street view images.","2025-02-01","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","269","","","","","","","","","","English","","","","WOS:001401431500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","HEAT-ISLAND; Pedestrian comfort; Street microclimate prediction; Street view image; THERMAL COMFORT; Transformer model; Urban design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TJ5NFT39","journalArticle","2024","To, D; Quinting, J; Hoshyaripour, GA; Götz, M; Streit, A; Debus, C","Architectural insights into and training methodology optimization of Pangu-Weather","GEOSCIENTIFIC MODEL DEVELOPMENT","","1991-959X","10.5194/gmd-17-8873-2024","","Data-driven medium-range weather forecasts have recently outperformed classical numerical weather prediction models, with Pangu-Weather (PGW) being the first breakthrough model to achieve this. The Transformer-based PGW introduced novel architectural components including the three-dimensional attention mechanism (3D Transformer) in the Transformer blocks. Additionally, it features an Earth-specific positional bias term which accounts for weather states being related to the absolute position on Earth. However, the effectiveness of different architectural components is not yet well understood. Here, we reproduce the 24 h forecast model of PGW based on subsampled 6-hourly data. We then present an ablation study of PGW to better understand the sensitivity to the model architecture and training procedure. We find that using a two-dimensional attention mechanism (2D Transformer) yields a model that is more robust to training, converges faster, and produces better forecasts compared to using the 3D Transformer. The 2D Transformer reduces the overall computational requirements by 20 %-30 %. Further, the Earth-specific positional bias term can be replaced with a relative bias, reducing the model size by nearly 40 %. A sensitivity study comparing the convergence of the PGW model and the 2D-Transformer model shows large batch effects; however, the 2D-Transformer model is more robust to such effects. Lastly, we propose a new training procedure that increases the speed of convergence for the 2D-Transformer model by 30 % without any further hyperparameter tuning.","2024-12-13","2025-02-26 20:37:02","2025-02-26 20:37:02","","8873-8884","","23","17","","","","","","","","","","English","","","","WOS:001376000900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4YYBXKV3","journalArticle","2024","Cheng, YM; Hu, HX; Dong, X; Hao, XR; Li, Y","Exploring Transformer Model in Longitudinal Pharmacokinetic/ Pharmacodynamic Analyses and Comparing with Alternative Natural Language Processing Models","JOURNAL OF PHARMACEUTICAL SCIENCES","","0022-3549","10.1016/j.xphs.2024.02.008","","There remains a substantial need for a comprehensive assessment of various natural language processing (NLP) algorithms in longitudinal pharmacokinetic/pharmacodynamic (PK/PD) modeling despite recent advances in machine learning in the space of quantitative pharmacology. We herein investigated the application of the transformer model and further compared the performance among several different NLP models, including long short -term memory (LSTM) and neural -ODE (Ordinary Differential Equation) in analyzing longitudinal PK/PD data using virtual data containing three different regimens. Results suggested that LSTM and neural -ODE, along with their respective variants provide a strong performance when predicting from training-included (seen) regimens, albeit with slight information loss for training-excluded (unseen) regimens. Similarly, as with neural -ODE, the transformer exhibited superior performance in describing time -series PK/ PD data. Nonetheless, when extrapolating to unseen regimens, while outlining the general data trends, it encountered difficulties in precisely capturing data fluctuations. Remarkably, a small integration of unseen data into the training dataset significantly bolsters predictive performance for both seen and unseen regimens. Our study marks a pioneering effort in deploying the transformer model for time -series PK/PD analysis and provides a systematic exploration of the currently available NLP models in this field. (c) 2024 American Pharmacists Association. Published by Elsevier Inc. All rights reserved.","2024-05","2025-02-26 20:37:02","2025-02-26 20:37:02","","1368-1375","","5","113","","","","","","","","","","English","","","","WOS:001235572600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","Machine learning; Pharmacokinetic/pharmacodynamic (PK/PD) modeling; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IPVJ43EC","journalArticle","2024","Samin, AM; Kobir, MH; Rafee, MMS; Ahmed, MF; Hasan, M; Ghosh, P; Kibria, S; Rahman, MS","BanSpeech: A Multi-Domain Bangla Speech Recognition Benchmark Toward Robust Performance in Challenging Conditions","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3371478","","Despite huge improvements in automatic speech recognition (ASR) employing neural networks, ASR systems still suffer from a lack of robustness and generalizability issues due to domain shifting. This is mainly because principal corpus design criteria are often not identified and examined adequately while compiling ASR datasets. In this study, we investigate the robustness of the fully supervised convolutional neural networks (CNNs), and the state-of-the-art transfer learning approaches, namely self-supervised wav2vec 2.0 and weakly supervised Whisper for multi-domain ASR. We also demonstrate the significance of domain selection while building a corpus by assessing these models on a novel multi-domain Bangladeshi Bangla ASR evaluation benchmark-BanSpeech, which contains approximately 6.52 hours of human-annotated speech, totaling 8085 utterances, across 13 distinct domains. SUBAK.KO, a mostly read speech corpus for the morphologically rich language Bangla, has been used to train the ASR systems. Experimental evaluation reveals that self-supervised cross-lingual pre-training with wav2vec 2.0 is the best strategy compared to weak supervision and full supervision to tackle the multi-domain ASR task. Moreover, the ASR models trained on SUBAK.KO face difficulty recognizing speech from domains with mostly spontaneous speech. The BanSpeech is publicly available to meet the need for a challenging evaluation benchmark for Bangla ASR.1","2024","2025-02-26 20:37:02","2025-02-26 20:37:02","","34527-34538","","","12","","","","","","","","","","English","","","","WOS:001178187200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Automatic speech recognition; Bangla; Benchmark testing; Convolutional neural networks; Data models; domain shifting; Neural networks; read speech; Robustness; Solid modeling; Speech processing; Speech recognition; spontaneous speech; Supervised learning; Task analysis; transfer learning; Transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MZ4TNW4J","journalArticle","2024","Zhang, J; Hu, GT","Transformer model-based multi-scale fine- grained identification and classification of regional traffic states","PEERJ COMPUTER SCIENCE","","2376-5992","10.7717/peerj-cs.2625","","To address the limitations in precision of conventional traffic state estimation methods, this article introduces a novel approach based on the Transformer model for traffic state identification and classification. Traditional methods commonly categorize traffic states into four or six classes; however, they often fail to accurately capture the nuanced transitions in traffic states before and after the implementation of traffic congestion reduction strategies. Many traffic congestion reduction strategies can alleviate congestion, but they often fail to effectively transition the traffic state from a congested condition to a free-flowing one. To address this issue, we propose a classification framework that divides traffic states into sixteen distinct categories. We design a Transformer model to extract features from traffic data. The k-means algorithm is then applied to these features to group similar traffic states. The resulting clusters are ranked by congestion level using non-dominated sorting, thereby dividing the data into 16 levels, from Level 1 (free-flowing) to Level 16 (congested). Extensive experiments are conducted using a large-scale simulated traffic dataset. The results demonstrate significant advancements in traffic state estimation achieved by our Transformer-based approach. Compared to baseline methods, our model exhibits marked improvements in both clustering quality and generalization capabilities.","2024-12-18","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","10","","","","","","","","","","English","","","","WOS:001414734900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Artificial intelligent; Complex network; Deep learning; HIGHWAY; Intelligent transportation systems; Non- dominated sorting; SCHEME; Traffic state estimation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A8C3XAWD","journalArticle","2021","Jang, SH; Seo, JP; Kwon, YH","Recovery of an injured arcuate fasciculus via transcallosal fiber in a stroke patient A case report","MEDICINE","","0025-7974","10.1097/MD.0000000000026840","","Rationale: We report on a patient whose arcuate fasciculus (AF) and corticobulbar tract (CBT) recovered following an infarct in the middle cerebral artery (MCA) territory, demonstrated on serial diffusion tensor tractography (DTT). Patient concerns: The patient showed moderate conduction aphasia on the Western Aphasia Battery with an aphasia quotient of 46.5 parts per thousand (spontaneous speech: 35.0 parts per thousand, auditory comprehension: 36.0 parts per thousand, and naming: 53.1 parts per thousand) at 1 month after onset. His aphasia improved with an aphasia quotient of 49 parts per thousand (spontaneous speech: 71.0 parts per thousand, auditory comprehension: 52.0 parts per thousand, and naming: 59.0 parts per thousand) at 10 months after onset. Diagnosis: A 44-year-old right-handed male patient presented with aphasia and quadriplegia, which occurred at the onset of an infarct in the left MCA territory. Intervention: Diffusion tensor imaging data were acquired twice (1 month and 10 months after onset). Outcomes: On one-month DTT, the discontinuation of the left AF and severe narrowing of the right CBT were observed. However, on ten-month DTT, the left AF was connected to the opposite AF by a new tract that passed through the splenium of corpus callosum, and the right CBT had become thicker. Lessons: We believe that our results suggest a recovery mechanism of injured AF and CBT in stroke patients.","2021-08-06","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","31","100","","","","","","","","","","English","","","","WOS:000680622300028","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;17</p>","","","aphasia; APHASIA; arcuate fasciculus; diffusion tensor imaging; diffusion tensor tractography; DOMINANT HEMISPHERE; stroke","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WUA947Z4","journalArticle","2023","Gósy, M","Occurrences and Durations of Filled Pauses in Relation to Words and Silent Pauses in Spontaneous Speech","LANGUAGES","","2226-471X","10.3390/languages8010079","","Filled pauses (i.e., gaps in speech production filled with non-lexical vocalizations) have been studied for more than sixty years in different languages. These studies utilize many different approaches to explore the origins, specific patterns, forms, incidents, positions, and functions of filled pauses. The present research examines the presence of filled pauses by considering the adjacent words and silent pauses that define their immediate positions as well as the influence of the immediate position on filled pause duration. The durations of 2450 filled pauses produced in 30 narratives were analyzed in terms of their incidence, immediate positions, neighboring silent pauses, and surrounding word types. The data obtained showed that filled pauses that were attached to a word on one side were the most frequent. Filled pauses occurring within a word and between two silent pauses were the longest of all. Hence, the durations of filled pauses were significantly influenced by the silent pauses occurring in their vicinity. The durations and occurrence of filled pauses did not differ when content or function words preceded the filled pause or followed it. These findings suggest that the incidence and duration of filled pauses as influenced by the neighboring words and silent pauses may be indicative of their information content, which is related to the processes of transforming ideas into grammatical structures.","2023-03","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","1","8","","","","","","","","","","English","","","","WOS:000982794500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","content words; DISFLUENCY; durations; ENGLISH; filled pause positions; function words; functions; HESITATION; LANGUAGE; MARKERS; SIGNAL; silent pauses; spontaneous speech planning; UH; UM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"78KMV8KA","journalArticle","2023","Heide, J; Netzebandt, J; Ahrens, S; Brüsch, J; Saalfrank, T; Schmitz-Antonischki, D","Improving lexical retrieval with LingoTalk: an app-based, self-administered treatment for clients with aphasia","FRONTIERS IN COMMUNICATION","","2297-900X","10.3389/fcomm.2023.1210193","","IntroductionLingoTalk is a German speech-language app designed to enhance lexical retrieval in individuals with aphasia. It incorporates automatic speech recognition (ASR) to provide therapist-independent feedback. The execution and effectiveness of a self-administered intervention with LingoTalk was explored in a case series study.MethodsThree individuals with chronic aphasia participated in a highly individualized, supervised self-administered intervention lasting 3 weeks. The LingoTalk app closely monitored the frequency, intensity and progress of the intervention. Treatment efficacy was assessed using a multiple baseline design, examining both item-specific treatment effects and generalization to untreated items, an untreated task, and spontaneous speech.ResultsAll participants successfully completed the intervention with LingoTalk, although one participant was not able to use the ASR feature. None of the participants fully adhered to the treatment protocol. All participants demonstrated significant and sustained improvement in the naming of practiced items, although there was limited evidence of generalization. Additionally, there was a slight reduction in word-finding difficulties during spontaneous speech.DiscussionThis small-scale study indicates that self-administered intervention with LingoTalk can improve oral naming of treated items. Thus, it has the potential to complement face-to-face speech-language therapy, such as within in a ""flipped speech room"" approach. The choice of feedback mode is discussed. Transparent progress monitoring of the intervention appears to positively influence patients' motivation.","2023-12-01","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","8","","","","","","","","","","English","","","","WOS:001130478400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","anomia; ANOMIA; aphasia; app-based intervention; automatic speech recognition (ASR); CARE; DIFFICULTIES; FUNCTIONALLY RELEVANT; LANGUAGE THERAPY; lexical retrieval; LingoTalk; oral naming; self-training; SPEECH; STROKE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZGN73MDB","journalArticle","2021","Pisanski, K; Groyecka-Bernard, A; Sorokowski, P","Human voice pitch measures are robust across a variety of speech recordings: methodological and theoretical implications","BIOLOGY LETTERS","","1744-9561","10.1098/rsbl.2021.0356","","Fundamental frequency (f(o)), perceived as voice pitch, is the most sexually dimorphic, perceptually salient and intensively studied voice parameter in human nonverbal communication. Thousands of studies have linked human f(o) to biological and social speaker traits and life outcomes, from reproductive to economic. Critically, researchers have used myriad speech stimuli to measure f(o) and infer its functional relevance, from individual vowels to longer bouts of spontaneous speech. Here, we acoustically analysed f(o) in nearly 1000 affectively neutral speech utterances (vowels, words, counting, greetings, read paragraphs and free spontaneous speech) produced by the same 154 men and women, aged 18-67, with two aims: first, to test the methodological validity of comparing f(o) measures from diverse speech stimuli, and second, to test the prediction that the vast inter-individual differences in habitual f(o) found between same-sex adults are preserved across speech types. Indeed, despite differences in linguistic content, duration, scripted or spontan--eous production and within-individual variability, we show that 42-81% of inter-individual differences in f(o) can be explained between any two speech types. Beyond methodological implications, together with recent evidence that inter-individual differences in f(o) are remarkably stable across the lifespan and generalize to emotional speech and nonverbal vocalizations, our results further substantiate voice pitch as a robust and reliable biomarker in human communication.","2021-09-29","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","9","17","","","","","","","","","","English","","","","WOS:000700684200002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","COMMUNICATION; fundamental frequency; nonverbal communication; SEX; sexual selection; SIZE; source-filter theory; speech; WINDOW; WOMEN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HMMHMXTF","journalArticle","2024","Kovac, D; Mekyska, J; Aharonson, V; Harar, P; Galaz, Z; Rapcsak, S; Orozco-Arroyave, JR; Brabenec, L; Rektorova, I","Exploring digital speech biomarkers of hypokinetic dysarthria in a multilingual cohort","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2023.105667","","Hypokinetic dysarthria, a motor speech disorder characterized by reduced movement and control in the speech -related muscles, is mostly associated with Parkinson's disease. Acoustic speech features thus offer the potential for early digital biomarkers to diagnose and monitor the progression of this disease. However, the influence of language on the successful classification of healthy and dysarthric speech remains crucial. This paper explores the analysis of acoustic speech features, both established and newly proposed, in a multilingual context to support the diagnosis of PD. The study aims to identify language-independent and highly discriminative digital speech biomarkers using statistical analysis and machine learning techniques. The study analyzes thirty-three acoustic features extracted from Czech, American, Israeli, Columbian, and Italian PD patients, as well as healthy controls. The analysis employs correlation and statistical tests, descriptive statistics, and the XGBoost classifier. Feature importances and Shapley values are used to provide explanations for the classification results. The study reveals that the most discriminative features, with reduced language dependence, are those measuring the prominence of the second formant, monopitch, and the frequency of pauses during text reading. Classification accuracies range from 67% to 85%, depending on the language. This paper introduces the concept of language robustness as a desirable quality in digital speech biomarkers, ensuring consistent behaviour across languages. By leveraging this concept and employing additional metrics, the study proposes several language-independent digital speech biomarkers with high discrimination power for diagnosing PD.","2024-02","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","88","","","","","","","","","","English","","","","WOS:001108281100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Acoustic speech features; Hypokinetic dysarthria; IMPAIRMENT; INTELLIGIBILITY; Machine learning; Multilingual study; Parkinson's disease; PARKINSONS-DISEASE; Statistical analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HPZ6KRPE","journalArticle","2021","Sidtis, DV; Kim, Y; Ahn, JS; Sidtis, J","Do Singing and Talking Arise From the Same or Different Neurological Systems? Dissociations of Pitch, Timing, and Rhythm in Two Dysprosodic Singers","PSYCHOMUSICOLOGY","","0275-3987","10.1037/pmu0000270","","The relationship between speech and singing in cerebral function is not fully understood. The effects of focal brain damage on pitch, timing, and rhythm in speech and singing were retrospectively investigated in 2 persons diagnosed with dysprosodic speech following cerebral vascular accidents; both were experienced singers. Participant 1 suffered a large right hemisphere infarct encompassing frontal, parietal. and temporal lobes extending partly into subcortical structures, and Participant 2 sustained a right-sided ischemic subcortical lesion, affecting globus pallidus, caudate and medial putamen. Pitch and timing in lexical contrasts were acoustically analyzed, rhythm and pitch in spontaneous speech were quantified, and accuracies of pitch and rhythm in familiar songs were measured acoustically and rated by listeners. Both participants produced lexical contrasts with disordered pitch but normal timing. Pitch was abnormal in spontaneous speech in both cases, but in singing, pitch was impaired in Participant 1, not in Participant 2. Speech rhythm deviated from normal values for Participant 1 but not for Participant 2, whereas rhythm in singing was accurate for both persons. These studies reveal dissociations between pitch, rhythm, and timing in speech versus singing,. suggesting that talking and singing arise from disparate neurological systems. Better understanding of these dissociations may lead to improved models of speaking and singing in cerebral function and may assist in assessment and treatment of dysprosody and amusia.","2021-03","2025-02-26 20:37:02","2025-02-26 20:37:02","","18-34","","1","31","","","","","","","","","","English","","","","WOS:000710266300002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;90</p>","","","BRAIN; DAMAGE; dysprosody; FUNCTIONAL LATERALIZATION; HEMISPHERE; INTONATION; LESION; pitch; PROSODIC DISTURBANCE; rhythm; singing; SPEAKING; speech; SPEECH TASK; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XZE4B289","journalArticle","2025","Hua, AQ; Yang, CF; Li, JW; Lan, QS; Yun, LJ; Xia, YL","Design of Rectangular Microstrip Patch Antenna Based on Dual Neural Network Model","IETE JOURNAL OF RESEARCH","","0377-2063","10.1080/03772063.2024.2449239","","A new method for designing rectangular microstrip patch antennas using a dual neural network model has been proposed. First, it is proposed to use LSTM + Attention model to predict the amplitude and phase spectrum of the rectangular microstrip patch antenna according to the structural parameter, breaking through the limitations of predicting S11 amplitude spectrum curve solely based on structural parameters in the past. Second, a transformer model was proposed to perform high-precision back prediction of structural parameters using S-parameter points and phase points. Finally, transfer learning was applied to the mutual prediction of structural parameters and gain points, as well as the design of U-shaped slot microstrip patch antennas, all of which achieved good experimental results.","2025-01-18","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","","","","","","","","","","","English","","","","WOS:001398952600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","Antenna structure parameter; ARRAY; Attention mechanism; LSTM; Rectangular microstrip patch antenna; Transfer learning; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8A35ZA5S","journalArticle","2025","Harlev, D; Singer, S; Goldshalger, M; Wolpe, N; Bergmann, E","Acoustic speech features are associated with late-life depression and apathy symptoms: Preliminary findings","ALZHEIMER'S & DEMENTIA: DIAGNOSIS, ASSESSMENT & DISEASE MONITORING","","2352-8729","10.1002/dad2.70055","","BACKGROUNDLate-life depression (LLD) is a heterogenous disorder related to cognitive decline and neurodegenerative processes, raising a need for the development of novel biomarkers. We sought to provide preliminary evidence for acoustic speech signatures sensitive to LLD and their relationship to depressive dimensions.METHODSForty patients (24 female, aged 65-82 years) were assessed with the Geriatric Depression Scale (GDS). Vocal features were extracted from speech samples (reading a pre-written text) and tested as classifiers of LLD using random forest and XGBoost models. Post hoc analyses examined the relationship between these acoustic features and specific depressive dimensions.RESULTSThe classification models demonstrated moderate discriminative ability for LLD with receiver operating characteristic = 0.78 for random forest and 0.84 for XGBoost in an out-of-sample testing set. The top classifying features were most strongly associated with the apathy dimension (R2 = 0.43).DISCUSSIONAcoustic vocal features that may support the diagnosis of LLD are preferentially associated with apathy.Highlights The depressive dimensions in late-life depression (LLD) have different cognitive correlates, with apathy characterized by more pronounced cognitive impairment. Acoustic speech features can predict LLD. Using acoustic features, we were able to train a random forest model to predict LLD in a held-out sample. Acoustic speech features that predict LLD are preferentially associated with apathy. These results indicate a predominance of apathy in the vocal signatures of LLD, and suggest that the clinical heterogeneity of LLD should be considered in development of acoustic markers.","2025-01","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","1","17","","","","","","","","","","English","","","","WOS:001396967300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","acoustic vocal features; aging; apathy; CLASSIFICATION; classification models; DISEASE; late-life depression; RISK; VALIDITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FEE3SW46","journalArticle","2023","Ma, T; Wang, WW; Chen, Y","Attention is all you need: An interpretable transformer-based asset allocation approach","INTERNATIONAL REVIEW OF FINANCIAL ANALYSIS","","1057-5219","10.1016/j.irfa.2023.102876","","Deep learning technology is rapidly adopted in financial market settings. Using a large data set from the Chinese stock market, we propose a return-risk trade-off strategy via a new transformer model. The empirical findings show that these updates, such as the self-attention mechanism in technology, can improve the use of time-series information related to returns and volatility, increase predictability, and capture more economic gains than other nonlinear models, such as LSTM. Our model employs Shapley additive explanations (SHAP) to measure the ""economic feature importance"" and tabulates the different important features in the prediction process. Finally, we document several economic explanations for the TF model. This paper sheds light on the burgeoning field on asset allocation in the age of big data.","2023-11","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","90","","","","","","","","","","English","","","","WOS:001062770300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Asset allocation; Chinese stock market; RETURNS; SHAP; Transformer model; VOLATILITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VGCC39J5","journalArticle","2021","Hu, WX; Zhao, SK","Study of employee behaviour based on artificial intelligence linguistic and speech analysis","INTERNATIONAL JOURNAL OF TECHNOLOGY MANAGEMENT","","0267-5730","10.1504/IJTM.2021.118318","","Recently, the difference between the vision and experience of human resource management has been validated using artificial intelligence (AI) techniques. Further, computational strategies help to analyse the employees linguistic and speech analysis (AILSA) in an effective manner. This research recognises four difficulties in human resource (HR) usage of data science practices: 1) HR concept complexity; 2) limited data collection limitations; 3) justice and legal limitations linked ethics issues; 4) management feedback from workers by evidence-based algorithms. Furthermore, to analyse the real solutions for these problems, AI-assisted concepts of superposition-causal reasoning, randomisation and the formalisation of procedures could be economically validated and socially appropriate to use managerial data analysis which have been designed and developed.","2021","2025-02-26 20:37:02","2025-02-26 20:37:02","","183-195","","2-4","86","","","","","","","","","","English","","","","WOS:000709420000006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","artificial intelligence; AUTHENTIC LEADERSHIP; employee behaviour; linguistic; managerial data analysis; MEDIATING ROLE; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J2JHUJHG","journalArticle","2023","Duey, AH; Rana, A; Siddi, F; Hussein, H; Onnela, JP; Smith, TR","Daily Pain Prediction Using Smartphone Speech Recordings of Patients With Spine Disease","NEUROSURGERY","","0148-396X","10.1227/neu.0000000000002474","","BACKGROUND:Pain evaluation remains largely subjective in neurosurgical practice, but machine learning provides the potential for objective pain assessment tools.OBJECTIVE:To predict daily pain levels using speech recordings from personal smartphones of a cohort of patients with diagnosed neurological spine disease.METHODS:Patients with spine disease were enrolled through a general neurosurgical clinic with approval from the institutional ethics committee. At-home pain surveys and speech recordings were administered at regular intervals through the Beiwe smartphone application. Praat audio features were extracted from the speech recordings to be used as input to a K-nearest neighbors (KNN) machine learning model. The pain scores were transformed from a 0 to 10 scale to low and high pain for better discriminative capacity.RESULTS:A total of 60 patients were enrolled, and 384 observations were used to train and test the prediction model. Using the KNN prediction model, an accuracy of 71% with a positive predictive value of 0.71 was achieved in classifying pain intensity into high and low. The model showed 0.71 precision for high pain and 0.70 precision for low pain. Recall of high pain was 0.74, and recall of low pain was 0.67. The overall F1 score was 0.73.CONCLUSION:Our study uses a KNN to model the relationship between speech features and pain levels collected from personal smartphones of patients with spine disease. The proposed model is a stepping stone for the development of objective pain assessment in neurosurgery clinical practice.","2023-09","2025-02-26 20:37:02","2025-02-26 20:37:02","","670-677","","3","93","","","","","","","","","","English","","","","WOS:001050079800037","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","ARTIFICIAL-INTELLIGENCE; Digital phenotyping; Machine learning; MANAGEMENT; Patient-reported outcome measures; Smartphone; Speech analysis; Spine surgery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4XWIPB63","journalArticle","2024","Wadle, LM; Ebner-Priemer, UW; Foo, JC; Yamamoto, Y; Streit, F; Witt, SH; Frank, J; Zillich, L; Limberger, MF; Ablimit, A; Schultz, T; Gilles, M; Rietschel, M; Sirignano, L","Speech Features as Predictors of Momentary Depression Severity in Patients With Depressive Disorder Undergoing Sleep Deprivation Therapy: Ambulatory Assessment Pilot Study","JMIR MENTAL HEALTH","","2368-7959","10.2196/49222","","Background: The use of mobile devices to continuously monitor objectively extracted parameters of depressive symptomatology is seen as an important step in the understanding and prevention of upcoming depressive episodes. Speech features such as pitch variability, speech pauses, and speech rate are promising indicators, but empirical evidence is limited, given the variability of study designs. Objective: Previous research studies have found different speech patterns when comparing single speech recordings between patients and healthy controls, but only a few studies have used repeated assessments to compare depressive and nondepressive episodes within the same patient. To our knowledge, no study has used a series of measurements within patients with depression (eg, intensive longitudinal data) to model the dynamic ebb and flow of subjectively reported depression and concomitant speech samples. However, such data are indispensable for detecting and ultimately preventing upcoming episodes. Methods: In this study, we captured voice samples and momentary affect ratings over the course of 3 weeks in a sample of patients (N=30) with an acute depressive episode receiving stationary care. Patients underwent sleep deprivation therapy, a chronotherapeutic intervention that can rapidly improve depression symptomatology. We hypothesized that within-person variability in depressive and affective momentary states would be reflected in the following 3 speech features: pitch variability, speech pauses, and speech rate. We parametrized them using the extended Geneva Minimalistic Acoustic Parameter Set (eGeMAPS) from open-source Speech and Music Interpretation by Large-Space Extraction (openSMILE; audEERING GmbH) and extracted them from a transcript. We analyzed the speech features along with self-reported momentary affect ratings, using multilevel linear regression analysis. We analyzed an average of 32 (SD 19.83) assessments per patient. Results: Analyses revealed that pitch variability, speech pauses, and speech rate were associated with depression severity, positive affect, valence, and energetic arousal; furthermore, speech pauses and speech rate were associated with negative affect, and speech pauses were additionally associated with calmness. Specifically, pitch variability was negatively associated with improved momentary states (ie, lower pitch variability was linked to lower depression severity as well as higher positive affect, valence, and energetic arousal). Speech pauses were negatively associated with improved momentary states, whereas speech rate was positively associated with improved momentary states. Conclusions: Pitch variability, speech pauses, and speech rate are promising features for the development of clinical prediction technologies to improve patient care as well as timely diagnosis and monitoring of treatment response. Our research is a step forward on the path to developing an automated depression monitoring system, facilitating individually tailored treatments and increased patient empowerment. (JMIR Ment Health 2024;11:e49222) doi: 10.2196/49222","2024","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","11","","","","","","","","","","English","","","","WOS:001164748700002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","ambulatory assessment; DAILY-LIFE; depression; ecological momentary assessment; experience sampling; HETEROGENEITY; INTERVIEWS; mobile phone; MOOD; RELIABILITY; SCALE; sleep deprivation therapy; speech features; speech pattern; VALIDITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MLCJ2QDW","journalArticle","2022","Hernández, JBA; Pulido, MLB; Bordón, JMG; Ballester, MAF; González, CMT","Speech evaluation of patients with Alzheimer's disease using an automatic interviewer","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2021.116386","","The used of speech analysis in detection or evolutionary control of Alzheimer's disease and the numerous advantages that it has proven to have as screening method make that, to day, it continues raising interest in researchers. At the present day, the most recent studies are focus on automatic analysis of speech recordings rather than in the possible influence of the methodology used for obtain these recordings. The main aim of this work is to find out whether the results obtained after analyzing the recordings obtained by means of an automatic interviewer have the same statistical significance as those obtained from a human interviewer in relation to the detection or evolutionary control of Alzheimer's disease. To this effect, two methodologies for acquiring audio recordings have been compared. The first one is focuses on the use of a human interviewer to generate spontaneous speech and the second one makes use of an automatic system that, by means of visual stimuli, invites the subject to speak. For carrying out this study, Cross-Sectional Alzheimer Prognosis R2019 database has been used, in which the same speakers with AD and control have been recorded following both methodologies. A characteristics extraction process based on 5 basic temporal measures has been applied to each speech sample. Subsequently, the results obtained have been submitted to a univariate statistical analysis and a multivariate analysis in order to evaluate the discriminative capacity obtained with each methodology. The results of the statistical study of these five temporal measures used show that, regardless the methodology used in speech generation, is possible discriminate Alzheimer's patients. Furthermore, in some cases, the results obtained for the automatic interviewer have achieved performances close to those of the traditional human interviewer. These results are promising and can serve as the basis to learn about its effectiveness and extension and to further deepen the automation of interviews, especially in telemedicine and teleservice scenarios.","2022-04-15","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","192","","","","","","","","","","English","","","","WOS:000736288000006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Alzheimer 's disease; Automatic interviewer; Automatic voice recognition; MILD COGNITIVE IMPAIRMENT; Telecare; Telemedicine","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CAHYZQX3","journalArticle","2025","Li, YY; Guan, QF; Gu, JF; Jiang, XT; Li, Y","A hierarchical deep reinforcement learning method for solving urban route planning problems under large-scale customers and real-time traffic conditions","INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE","","1365-8816","10.1080/13658816.2024.2413394","","As urbanization and economic growth advance, large-scale customers and real-time traffic conditions have become crucial factors in urban route planning. Deep reinforcement learning is considered the most effective method for solving urban route planning problems involving large-scale customers and real-time traffic conditions. Due to memory usage limitations, existing deep reinforcement learning methods cannot identify candidate customers or determine optimal travel routes in large-scale and real-time environments. To tackle these problems, this study introduces a hierarchical deep reinforcement learning method utilizing an improved transformer model (HDRLITF) based on the divide-and-conquer concept. Graph attention networks and gate mechanisms are integrated into the transformer model to capture dynamic features and improve the model's performance. A two-stage training method, based on the actor-critic algorithm, is proposed to determine the optimal policy function. To evaluate the HDRLITF method, experiments were conducted using datasets from the cities of Shenzhen and Chengdu in China. The experimental results suggest that the HDRLITF method can effectively interact with real-time traffic environments and obtain high-quality solutions compared to other deep reinforcement learning methods. The robustness and reliability of HDRLITF were further validated across multiple traffic scenarios and indicators.","2025-01-02","2025-02-26 20:37:02","2025-02-26 20:37:02","","118-141","","1","39","","","","","","","","","","English","","","","WOS:001333031700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","ALGORITHM; ATTENTION NETWORK; FRAMEWORK; GRAPH CONVOLUTIONAL NETWORK; hierarchical deep reinforcement learning; large-scale customers; MODEL; OPTIMIZATION; real-time traffic; transformer model; TRAVELING SALESMAN PROBLEM; Urban route planning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9NHF2ZJF","journalArticle","2024","Zhang, K; Zhang, YW; Wu, J; Wang, T; Jiang, WK; Zeng, M; Yang, Z","Detection of Harmful H2S Concentration Range, Health Classification, and Lifespan Prediction of CH4 Sensor Arrays in Marine Environments","CHEMOSENSORS","","2227-9040","10.3390/chemosensors12090172","","Underwater methane (CH4) detection technology is of great significance to the leakage monitoring and location of marine natural gas transportation pipelines, the exploration of submarine hydrothermal activity, and the monitoring of submarine volcanic activity. In order to improve the safety of underwater CH4 detection mission, it is necessary to study the effect of hydrogen sulfide (H2S) in leaking CH4 gas on sensor performance and harmful influence, so as to evaluate the health status and life prediction of underwater CH4 sensor arrays. In the process of detecting CH4, the accuracy decreases when H2S is found in the ocean water. In this study, we proposed an explainable sorted-sparse (ESS) transformer model for concentration interval detection under industrial conditions. The time complexity was decreased to O (n log(n)) using an explainable sorted-sparse block. Additionally, we proposed the Ocean X generative pre-trained transformer (GPT) model to achieve the online monitoring of the health of the sensors. The ESS transformer model was embedded in the Ocean X GPT model. When the program satisfied the special instructions, it would jump between models, and the online-monitoring question-answering session would be completed. The accuracy of the online monitoring of system health is equal to that of the ESS transformer model. This Ocean-X-generated model can provide a lot of expert information about sensor array failures and electronic noses by text and speech alone. This model had an accuracy of 0.99, which was superior to related models, including transformer encoder (0.98) and convolutional neural networks (CNN) + support vector machine (SVM) (0.97). The Ocean X GPT model for offline question-and-answer tasks had a high mean accuracy (0.99), which was superior to the related models, including long short-term memory-auto encoder (LSTM-AE) (0.96) and GPT decoder (0.98).","2024-09","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","9","12","","","","","","","","","","English","","","","WOS:001326542400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","CONDITION-BASED MAINTENANCE; generated pre-trained transformer model; GROUP DECISION-MAKING; lifespan prediction; MODEL; ocean methane detection; sensor health management; signal processing; STRATEGY; SYSTEM; toxic gas detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z2YIYTV9","journalArticle","2023","Park, Y; Sung, YS","Imitation Learning through Image Augmentation Using Enhanced Swin Transformer Model in Remote Sensing","REMOTE SENSING","","2072-4292","10.3390/rs15174147","","In unmanned systems, remote sensing is an approach that collects and analyzes data such as visual images, infrared thermal images, and LiDAR sensor data from a distance using a system that operates without human intervention. Recent advancements in deep learning enable the direct mapping of input images in remote sensing to desired outputs, making it possible to learn through imitation learning and for unmanned systems to learn by collecting and analyzing those images. In the case of autonomous cars, raw high-dimensional data are collected using sensors, which are mapped to the values of steering and throttle through a deep learning network to train imitation learning. Therefore, by imitation learning, the unmanned systems observe expert demonstrations and learn expert policies, even in complex environments. However, in imitation learning, collecting and analyzing a large number of images from the game environment incurs time and costs. Training with a limited dataset leads to a lack of understanding of the environment. There are some augmentation approaches that have the limitation of increasing the dataset because of considering only the locations of objects visited and estimated. Therefore, it is required to consider the diverse kinds of the location of objects not visited to solve the limitation. This paper proposes an enhanced model to augment the number of training images comprising a Preprocessor, an enhanced Swin Transformer model, and an Action model. Using the original network structure of the Swin Transformer model for image augmentation in imitation learning is challenging. Therefore, the internal structure of the Swin Transformer model is enhanced, and the Preprocessor and Action model are combined to augment training images. The proposed method was verified through an experimental process by learning from expert demonstrations and augmented images, which reduced the total loss from 1.24068 to 0.41616. Compared to expert demonstrations, the accuracy was approximately 86.4%, and the proposed method achieved 920 points and 1200 points more than the comparison model to verify generalization.","2023-09","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","17","15","","","","","","","","","","English","","","","WOS:001065125100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","action classification; data augmentation; deep learning; image processing; imitation learning; Swin Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EPJUALJX","journalArticle","2023","Wu, GW; Liu, SP; Fan, XY","The Power of Fragmentation: A Hierarchical Transformer Model for Structural Segmentation in Symbolic Music Generation","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2023.3263797","","Symbolic music generation relies on the contextual representation capabilities of the generative model, where the most prevalent approach is the Transformer-based model. Learning contextual representations are also related to the structural elements in music, i.e., intro, verse, and chorus, which have not received much attention of scientific publications. In this paper, we propose a hierarchical Transformer model to learn multiscale contexts in music. In the encoding phase, we first design a fragment scope localization module to separate the music parts into chords and sections. Then, we use a multiscale attention mechanism to learn note-, chord-, and section-level contexts. In the decoding phase, we propose a hierarchical Transformer model that uses fine decoders to generate sections in parallel and a coarse decoder to decode the combined music. We also designed a music style normalization layer to achieve a consistent music style between the generated sections. Our model is evaluated on two open MIDI datasets. Experiments show that our model outperforms other comparative models in 50% (6 out of 12 metrics) and 83.3% (10 out of 12 metrics) of the quantitative metrics for short- and long-term music generation, respectively. Preliminary visual analysis also suggests its potential in following compositional rules, such as reuse of rhythmic patterns and critical melodies, which are associated with improved music quality.","2023","2025-02-26 20:37:02","2025-02-26 20:37:02","","1409-1420","","","31","","","","","","","","","","English","","","","WOS:000970499600006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Bars; Computational modeling; Context modeling; Decoding; Encoding; multiscale attention; Music; structural segmentation; Symbolic music generation; Transformer-based model; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BYUIZZ4K","journalArticle","2023","Li, X; Yang, SY; Guo, HM","Application of virtual human sign language translation based on speech recognition","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2023.06.001","","For the application problem of speech recognition to sign language translation, we conducted a study in two parts: improving speech recognition's effectiveness and promoting the application of sign language translation. The mainstream frequency-domain feature has achieved great success in speech recognition. However, it fails to capture the instantaneous gap in speech, and the time-domain feature makes up for this deficiency. In order to combine the advantages of frequency and time domain features, an acoustic architecture with a joint time domain encoder and frequency domain encoder is proposed. A new time-domain feature based on SSM (StateSpace-Model) is proposed in the time- domain encoder and encoded using the GRU model. A new model, ConFLASH, is proposed in the frequency domain encoder, which is a lightweight model combining CNN and FLASH (a variant of the Transformer model). It not only reduces the computational complexity of the Transformer model but also effectively integrates the global modeling advantages of the Transformer model and the local modeling advantages of CNN. The Transducer structure is used to decode speech after the encoders are joined. This acoustic model is named GRU-ConFLASH- Transducer. On the self-built dataset and open-source dataset speechocean, it achieves optimal WER (Word Error Rate) of 2.6% and 4.7%. In addition, to better realize the visual application of sign language translation, a 3D virtual human model is designed and developed.","2023-07","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","152","","","","","","","","","","English","","","","WOS:001035706900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","FLASH; NEURAL-NETWORKS; Sign language translation; Speech recognition; SSM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UNU96UM5","journalArticle","2023","Shi, J; Su, TY; Li, XF; Wang, FW; Cui, JJ; Liu, ZD; Wang, J","A Machine-Learning Approach Based on Attention Mechanism for Significant Wave Height Forecasting","JOURNAL OF MARINE SCIENCE AND ENGINEERING","","2077-1312","10.3390/jmse11091821","","Significant wave height (SWH) is a key parameter for monitoring the state of waves. Accurate and long-term SWH forecasting is significant to maritime shipping and coastal engineering. This study proposes a transformer model based on an attention mechanism to achieve the forecasting of SWHs. The transformer model can capture the contextual information and dependencies between sequences and achieves continuous time series forecasting. Wave scale classification is carried out according to the forecasting results, and the results are compared with gated recurrent unit (GRU) and long short-term memory (LSTM) machine-learning models and the key laboratory of MArine Science and NUmerical Modeling (MASNUM) numerical wave model. The results show that the machine-learning models outperform the MASNUM within 72 h, with the transformer being the best model. For continuous 12 h, 24 h, 36 h, 48 h, 72 h, and 96 h forecasting, the average mean absolute errors (MAEs) of the test sets were, respectively, 0.139 m, 0.186 m, 0.223 m, 0.254 m, 0.302 m, and 0.329 m, and the wave scale classification accuracies were, respectively, 91.1%, 99.4%, 86%, 83.3%, 78.9%, and 77.5%. The experimental results validate that the transformer model can achieve continuous and accurate SWH forecasting, as well as accurate wave scale classification and early warning of waves, providing technical support for wave monitoring.","2023-09","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","9","11","","","","","","","","","","English","","","","WOS:001072057200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","long-sequence forecasting; NEURAL-NETWORKS; significant wave height forecasting; transformer; TRANSFORMER; wave scale classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FLZQTWC9","journalArticle","2024","Mohammed, SA","Day Trading Strategy Based on Transformer Model, Technical Indicators and Multiresolution Analysis","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","Stock prices are very volatile because they are affected by infinite number of factors, such as economical, social, political, and human behavior. This makes finding consistently profitable day trading strategy extremely challenging and that is why an overwhelming majority of stock traders loose money over time. Professional day traders, who are very few in number, have a trading strategy that can exploit this price volatility to consistently earn profit from the market. This study proposes a consistently profitable day trading strategy based on price volatility, transformer model, time2vec, technical indicators, and multiresolution analysis. The proposed trading strategy has eight trading systems, each with a different profit-target based on the risk taken per trade. This study shows that the proposed trading strategy results in consistent profits when the profit-target is 1.5 to 3.5 times the risk taken per trade. If the profit-target is not in that range, then it may result in a loss. The proposed trading strategy was compared with the buy-and-hold strategy and it showed consistent profits with all the stocks whereas the buy-and-hold strategy was inconsistent and resulted in losses in half the stocks. Also three of the consistently profitable trading systems showed significantly higher average profits and expectancy than the buy-and-hold trading strategy.","2024-04","2025-02-26 20:37:02","2025-02-26 20:37:02","","1077-1089","","4","15","","","","","","","","","","English","","","","WOS:001317491800107","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Artificial neural network; BIDIRECTIONAL LSTM; CLASSIFICATION; DECOMPOSITION; deep learning; machine learning; multiresolution analysis; saudi stock exchange; stock price prediction; technical analysis; time series analysis; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RZC6T9UU","journalArticle","2024","Xie, JJ; Chen, Y; Luo, SJ; Yang, WX; Lin, YX; Wang, LS; Ding, X; Tong, MS; Yu, RS","Tracing unknown tumor origins with a biological-pathway-based transformer model","CELL REPORTS METHODS","","2667-2375","10.1016/j.crmeth.2024.100797","","Cancer of unknown primary (CUP) represents metastatic cancer where the primary site remains unidentified despite standard diagnostic procedures. To determine the tumor origin in such cases, we developed BPformer, a deep learning method integrating the transformer model with prior knowledge of biological pathways. Trained on transcriptomes from 10,410 primary tumors across 32 cancer types, BPformer achieved remarkable accuracy rates of 94%, 92%, and 89% in primary tumors and primary and metastatic sites of metastatic tumors, respectively, surpassing existing methods. Additionally, BPformer was validated in a retrospective study, demonstrating consistency with tumor sites diagnosed through immunohistochemistry and histopathology. Furthermore, BPformer was able to rank pathways based on their contribution to tumor origin identification, which helped to classify oncogenic signaling pathways into those that are highly conservative among different cancers versus those that are highly variable depending on their origins.","2024-06-17","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","6","4","","","","","","","","","","English","","","","WOS:001259021200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","CANCER; CLASSIFIER; DIAGNOSIS; PRIMARY SITE; TISSUE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LZI7AAC3","journalArticle","2023","Faiz, MF; Sajid, M; Ali, S; Javed, K; Ayaz, Y","Energy modeling and predictive control of environmental quality for building energy management using machine learning","ENERGY FOR SUSTAINABLE DEVELOPMENT","","0973-0826","10.1016/j.esd.2023.04.017","","Heating, Ventilation, and Air Conditioning (HVAC) systems play a vital role in building energy management by controlling the indoor temperature and ensuring the occupant's comfort. However, the energy consumption of HVACs contributes significantly towards overall energy usage of a building and carbon footprint. To address this challenge, this research proposes the development of a predictive model for HVAC temperature forecasting using Machine Learning (ML) algorithms to optimize energy efficiency while maintaining thermal comfort in buildings. The study focuses on comparing the performance of Transformer Neural Networks and CNN-LSTM, a seq2seq model combining Convolutional Neural Networks (CNN) and Long-Short Term Memory (LSTM) on multiple forecasting horizons using data obtained from multiple devices deployed in a room verified by feedback survey forms filled by occupants. The transformer model outperformed, achieving an R2 score of 0.936 at a 1-minute forecasting horizon, surpassing the performance of CNN-LSTM model at all tested forecasting horizons. The transformer model yielded significant energy savings thereby reducing energy consumption by almost 50 % compared to the non-AI conventional methods, particularly at forecasting horizons of 1 min and 60 min, while the occupant survey also favoured a 60-minute forecasting horizon. The performance of transformer model particularly with a 60-minute forecasting horizon underscores its potential to optimize energy efficiency while ensuring thermal comfort in building energy management systems.","2023-06","2025-02-26 20:37:02","2025-02-26 20:37:02","","381-395","","","74","","","","","","","","","","English","","","","WOS:001001339200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","(HVAC); COMFORT MODELS; Energy optimization; Heating Ventilation and Air Conditioning; Indoor environment; Transformer -based model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DRCVQRZY","journalArticle","2021","Zhang, CK; Wang, XY; Zhang, HY; Zhang, HY; Han, PY","Log Sequence Anomaly Detection Based on Local Information Extraction and Globally Sparse Transformer Model","IEEE TRANSACTIONS ON NETWORK AND SERVICE MANAGEMENT","","1932-4537","10.1109/TNSM.2021.3125967","","Anomaly detection for log sequences is a necessary task for system intelligent operation and fault diagnosis. In a log sequence, adjacent logs have the property of local correlation, while long-distance logs have remote dependencies. It is helpful to fully mine these information during modeling for improving the performance of anomaly detection. Meanwhile, there are some redundant information or noise in the log sequence, which has no contribution to the detection, and may even bring negative impact. The existing methods for log sequence anomaly detection do not take the above problems into account when constructing models. In this paper, we propose LSADNET, an unsupervised log sequence anomaly detection network based on local information extraction and globally sparse Transformer model. LSADNET applies multi-layer convolution to capture the local correlation between adjacent logs, and utilizes Transformer to learn the global dependency among long-distance logs. Meanwhile, we propose a globally sparse Transformer model to improve the self-attention mechanism, which can help to retain important information adaptively and eliminate the irrelevant information in the log sequence. In addition, according to the co-occurrence mode of log templates, we put forward the calculation formula of log template transfer value, and apply it to log vectorization. Through sufficient experiments on two public datasets, it is confirmed that LSADNET has better performance than the state-of-art methods.","2021-12","2025-02-26 20:37:02","2025-02-26 20:37:02","","4119-4133","","4","18","","","","","","","","","","English","","","","WOS:000728930000015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;20<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","anomaly detection; Anomaly detection; Correlation; Feature extraction; globally sparse transformer; Information retrieval; local information extraction; Log parsing; Principal component analysis; Task analysis; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S4MWY7CH","journalArticle","2022","Wang, JM; Song, YJ; Zhao, WB; Jia, ZY; Wu, F","A Novel Joint Entity Relation Extraction Based on Capsule Network and Part-of-Speech Weighting","MOBILE INFORMATION SYSTEMS","","1574-017X","10.1155/2022/2714700","","With the development of science and technology, science and technology policies are increasing year by year. Science and technology policies are literature existing in the form of texts, which are characterized by rigorous structure, clear hierarchy, and standard language. Mining template information from policies can optimize data templates and improve the efficiency of recommending data to users. This paper proposes a joint entity relation extraction model based on capsule networks and part-of-speech weighting. In order to learn more feature information from word vector, capsule network based on bidirectional gated cyclic unit is used to replace the traditional convolutional neural network. In view of the phenomenon of imperfect semantic expression of word vector, part-of-speech features are added to enrich text information. Meanwhile, in order to solve the weight distribution problem of word features and part-of-speech features, an artificial fish swarm algorithm is proposed to optimize the two feature weights by iterative optimization, and the effectiveness of the proposed model is proved by experiments.","2022-08-09","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","2022","","","","","","","","","","English","","","","WOS:000843343500004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JGNI7IV4","journalArticle","2024","Riverin-Coutlée, J; Kapia, E; Gubian, M","Dialect change and language attitudes in Albania","LANGUAGE VARIATION AND CHANGE","","0954-3945","10.1017/S0954394524000103","","This study is concerned with attitudes of Albanian listeners toward the two main dialects spoken in Albania: Gheg and Tosk. The study seeks to establish a connection between attitudes and speech features which have been shown to be changing in Gheg, and other features found to be stable. Ratings of four speech features on visual analog scales (VASs) pertaining to dialect identification, status, and solidarity were collected from 125 Albanian listeners and modeled with Bayesian regressions. The results revealed lower status for variants of features found to be changing in Gheg, contrary to stable variants, suggesting a connection between attitudes and dialect change, and highlighting the relevance of both language-external and internal factors in understanding change. All stimuli were also rated as more friendly than unfriendly, which could be related to sociocultural specificities of Albania. The study finally identifies methodological challenges to do with modeling responses from VASs.","2024-07","2025-02-26 20:37:02","2025-02-26 20:37:02","","219-242","","2","36","","","","","","","","","","English","","","","WOS:001314774800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;93</p>","","","Albanian; dialect change; dialect identification; DURATION; ENGLISH; INFORMATION; language attitudes; PACKAGE; PERCEPTION; PSYTOOLKIT; REAL-TIME REACTIONS; VARIABLES; visual analog scales","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EYC6MFTA","journalArticle","2024","Liang, PF; Yang, LN; Xiong, ZG; Zhang, XM; Liu, G","Multilevel Intrusion Detection Based on Transformer and Wavelet Transform for IoT Data Security","IEEE INTERNET OF THINGS JOURNAL","","2327-4662","10.1109/JIOT.2024.3369034","","The Internet of Things (IoT) technology and systems have penetrated every aspect of our lives and generated enormous economic benefits. At the same time, research on the data security of IoT systems has been one of the key topics in IoT fields. Network attacks and intrusions have become the main threats to the data security of the IoTs, which have become the main obstacles to the development and application of the IoTs. In this article, we propose an intrusions and attack detection model to ensure the data security of IoT systems by using the Transformer model and multiwavelets learning. Based on the architecture of IoT systems, we first proposed a multilevel intrusion detection model to detect attack data in the cloud layer and edge terminal layer. In this detection model, a Transformer model and discrete wavelet transform (DWT)-based approach are proposed to ensure the effectiveness and accuracy of the model. To extract and make full use of frequency information of traffic data in an IoT network, we embed DWT technique and multiwavelets learning into the Transformer model to propose a novel DWT-based Transformer architecture, which achieves outstanding performance in detecting intrusion actions. Simulating on IoT system in the laboratory environment, the proposed security prediction model achieves pretty good performance in predicting intrusion actions.","2024-08-01","2025-02-26 20:37:02","2025-02-26 20:37:02","","25613-25624","","15","11","","","","","","","","","","English","","","","WOS:001277988600068","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","Computational modeling; Data models; Data security; discrete wavelet transform (DWT); Discrete wavelet transforms; INTERNET; Internet of Things; Internet of Things (IoT); intrusion detection; Intrusion detection; multiwavelets learning; THINGS; Transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MRIH9VLY","journalArticle","2022","Liu, HI; Chen, WL","X-Transformer: A Machine Translation Model Enhanced by the Self-Attention Mechanism","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app12094502","","Machine translation has received significant attention in the field of natural language processing not only because of its challenges but also due to the translation needs that arise in the daily life of modern people. In this study, we design a new machine translation model named X-Transformer, which refines the original Transformer model regarding three aspects. First, the model parameter of the encoder is compressed. Second, the encoder structure is modified by adopting two layers of the self-attention mechanism consecutively and reducing the point-wise feed forward layer to help the model understand the semantic structure of sentences precisely. Third, we streamline the decoder model size, while maintaining the accuracy. Through experiments, we demonstrate that having a large number of decoder layers not only affects the performance of the translation model but also increases the inference time. The X-Transformer reaches the state-of-the-art result of 46.63 and 55.63 points in the BiLingual Evaluation Understudy (BLEU) metric of the World Machine Translation (WMT), from 2014, using the English-German and English-French translation corpora, thus outperforming the Transformer model with 19 and 18 BLEU points, respectively. The X-Transformer significantly reduces the training time to only 1/3 times that of the Transformer. In addition, the heat maps of the X-Transformer reach token-level precision (i.e., token-to-token attention), while the Transformer model remains at the sentence level (i.e., token-to-sentence attention).","2022-05","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","9","12","","","","","","","","","","English","","","","WOS:000794535400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","machine translation; natural language processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I58IEIC3","journalArticle","2023","Wang, CT; Zhang, JH; Liu, SY","Medical Ultrasound Image Segmentation With Deep Learning Models","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3225101","","This work aimed to adopt a transformer model combined with deep learning neural network to discuss the segmentation of medical ultrasound images. A network combining a transformer model with a deep neural network model (ConvTrans-Net) is proposed. The image content is preselected based on a multilayer perceptron and attention mechanism, different feature vectors are concatenated and fed into the multilayer perceptron, and the results of multiple attentions are mapped to a larger dimensional space using a feed-forward network. The lesion areas segmented by ultrasonic scan were analysed, and an attention mechanism and multilayer perceptron were combined to preselect image content. The performance and convergence of the model were analysed, and the Jaccard similarity coefficient precision and recall of the model were measured. In the experiment, two different iterative step sizes were selected, the convergence trend of the model increased with the increase in the number of iterative steps, and the model gradually stabilized. The Jaccard of ConvTrans-Net was 85.21%. The precision (85.17%) and recall (89.65%) were significantly higher than those of EfficientNet and DeepViT-L, and the differences were significant (P < 0.05). The experimental results show that the proposed model is stable, and the combination of Transformer model and deep learning neural network has a good effect on ultrasound image segmentation, which has some practical application value.","2023","2025-02-26 20:37:02","2025-02-26 20:37:02","","10158-10168","","","11","","","","","","","","","","English","","","","WOS:000927830700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","ARTIFICIAL-INTELLIGENCE; Biomedical imaging; Deep learning; Feature extraction; image features; Image segmentation; Medical diagnostic imaging; medical images; neural networks; Neural networks; Transformers; ultrasound","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CR2PJ7BX","journalArticle","2023","Tsai, YC; Lin, FC","Paraphrase Generation Model Integrating Transformer Architecture, Part-of-Speech Features, and Pointer Generator Network","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3260849","","In recent years, hardware advancements have enabled natural language processing tasks that were previously difficult to achieve due to their intense computing requirements. This study focuses on paraphrase generation, which entails rewriting a sentence using different words and sentence structures while preserving its original meaning. This increases sentence diversity, thereby improving the performance of downstream tasks, such as question-answering systems and machine translation. This study proposes a novel paraphrase generation model that combines the Transformer architecture with part-of-speech features, and this model is trained using a Chinese corpus. New features are incorporated to improve the performance of the Transformer architecture, and the pointer generation network is used when the training data contain low-frequency words. This allows the model to focus on input words with important information according to their attention distributions.","2023","2025-02-26 20:37:02","2025-02-26 20:37:02","","30109-30117","","","11","","","","","","","","","","English","","","","WOS:000965622400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","Data models; Data preprocessing; Decoding; Measurement; Multi-encoder; Network architecture; paraphrase generation; pointer generation network; Task analysis; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UZNDG6SI","journalArticle","2023","Yang, ZH; Wang, GJ; Feng, L; Wang, YX; Wang, GW; Liang, SH","A Transformer Model for Coastline Prediction in Weitou Bay, China","REMOTE SENSING","","2072-4292","10.3390/rs15194771","","The simulation and prediction of coastline changes are of great significance for the development and scientific management of coastal zones. Coastline changes are difficult to capture completely but appear significantly periodic over a long time series. In this paper, the transformer model is used to learn the changing trend of the coastline so as to deduce the position of the coastline in the coming year. First, we use the distance regularization level set evolution (DRLSE) model for instantaneous waterline extraction (IWE) from preprocessed Landsat time-series images from 2010-2020 in Weitou Bay, China. Then, tidal correction (TC) is performed on the extracted instantaneous waterline dataset to obtain coastlines projected to a single reference tidal datum. Finally, the coastline datasets from 2010-2019 are used for model training, and the coastline in 2020 is used for accuracy assessment. Three precision evaluation methods, including receiver operating characteristic curve matching, the mean offset, and the root mean square error, were used to verify the predicted coastline data. The receiver operating characteristic curve was specifically designed and improved to evaluate the accuracy of the obtained coastline. Compared with the support vector regression (SVR) and long-short-term memory (LSTM) methods, the results showed that the coastline predicted by the transformer model was the closest to the accurate extracted coastline. The accuracies of the correct values corresponding to SVR, LSTM, and transformer models were 88.27%, 94.08%, and 98.80%, respectively, which indicated the accuracy of the coastline extraction results. Additionally, the mean offset and root mean square error were 0.32 pixels and 0.57 pixels, respectively. In addition, the experimental results showed that tidal correction is important for coastline prediction. Moreover, through field investigations of coastlines, the predicted results obtained for natural coastlines were more accurate, while the predicted results were relatively poor for some artificial coastlines that were intensely influenced by human activities. This study shows that the transformer model can provide natural coastline changes for coastal management.","2023-10","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","19","15","","","","","","","","","","English","","","","WOS:001083260700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","CLOUD SHADOW; COASTAL EROSION; coastline prediction; coastline types; IMAGES; Landsat time-series images; LONG; MAUI; QUANZHOU BAY; ROC curve matching; SHORELINE CHANGES; SUPPORT VECTOR REGRESSION; tidal correction; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JX7AIIB8","journalArticle","2023","He, K; Ding, HT; Xu, N; Guo, KH","Wheel Odometry with Deep Learning-Based Error Prediction Model for Vehicle Localization","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13095588","","Wheel odometry is a simple and low-cost localization technique that can be used for localization in GNSS-deprived environments; however, its measurement accuracy is affected by many factors, such as wheel slip, wear, and tire pressure changes, resulting in unpredictable and variable errors, which in turn affect positioning performance. To improve the localization performance of wheel odometry, this study developed a wheel odometry error prediction model based on a transformer neural network to learn the measurement uncertainty of wheel odometry and accurately predict the odometry error. Driving condition characteristics including features describing road types, road conditions, and vehicle driving operations were considered, and models both with and without driving condition characteristics were compared and analyzed. Tests were performed on a public dataset and an experimental vehicle. The experimental results demonstrate that the proposed model can predict the odometry error with higher accuracy, stability, and reliability than the LSTM and WhONet models under multiple challenging and longer GNSS outage driving conditions. At the same time, the transformer model's overall performance can be improved in longer GNSS outage driving conditions by considering the driving condition characteristics. Tests on the experimental vehicle demonstrate the model's generalization capability and the improved positioning performance of dead reckoning when using the proposed model. This study explored the possibility of applying a transformer model to wheel odometry and provides a new solution for using deep learning in localization.","2023-04-30","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","9","13","","","","","","","","","","English","","","","WOS:000986703000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","autonomous driving; deep learning; localization; transformer model; wheel odometry","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6ED6V2B3","journalArticle","2022","Hameed, A; Violos, J; Leivadeas, A; Santi, N; Grünblatt, R; Mitton, N","Toward QoS Prediction Based on Temporal Transformers for IoT Applications","IEEE TRANSACTIONS ON NETWORK AND SERVICE MANAGEMENT","","1932-4537","10.1109/TNSM.2022.3217170","","Internet of Things (IoT) devices generate a tremendous amount of time series data that is extremely dynamic, heterogeneous and time dependent. Such types of data introduce significant challenges for the real-time prediction of QoS metrics of IoT applications with different traffic characteristics. To this end, in this paper, we propose a temporal transformer model and a unified system to predict several QoS metrics of heterogeneous IoT applications when they communicate with the Edge of the network. The transformer model also leverages an attention module to provide a solution for both short-term and long-term sequence prediction of QoS metrics that allows to better extract any time dependencies. In particular, in our framework, we firstly generate a set of datasets containing real-time traffic information of five different IoT applications such as Heating, Ventilation, and Air Conditioning (HVAC), lighting, Voice over Internet Protocol (VoIP), surveillance and emergency response using the 802.15.4 access technology and the RPL routing protocol. Following, we perform the data cleaning, downsampling and pre-processing of the datasets and we construct the QoS datasets, which include four QoS metrics, namely throughput, packet delivery ratio, packet loss ratio and latency. Finally, we evaluate the transformer model through extensive experimentation using both short-term and long-term dependencies and we show that our model can guarantee a robust performance and accurate QoS prediction.","2022-12","2025-02-26 20:37:02","2025-02-26 20:37:02","","4010-4027","","4","19","","","","","","","","","","English","","","","WOS:000965915200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","ARCHITECTURE; DEEP; Deep learning; edge computing; Internet of Things; Measurement; NETWORKS; Predictive models; QoS prediction; Quality of service; Throughput; time series; Time series analysis; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8FRBW3BV","journalArticle","2023","Kaselimi, M; Voulodimos, A; Daskalopoulos, I; Doulamis, N; Doulamis, A","A Vision Transformer Model for Convolution-Free Multilabel Classification of Satellite Imagery in Deforestation Monitoring","IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS","","2162-237X","10.1109/TNNLS.2022.3144791","","Understanding the dynamics of deforestation and land uses of neighboring areas is of vital importance for the design and development of appropriate forest conservation and management policies. In this article, we approach deforestation as a multilabel classification (MLC) problem in an endeavor to capture the various relevant land uses from satellite images. To this end, we propose a multilabel vision transformer model, ForestViT, which leverages the benefits of the self-attention mechanism, obviating any convolution operations involved in commonly used deep learning models utilized for deforestation detection. Experimental evaluation in open satellite imagery datasets yields promising results in the case of MLC, particularly for imbalanced classes, and indicates ForestViT's superiority compared with well-established convolutional structures (ResNET, VGG, DenseNet, and ModileNet neural networks). This superiority is more evident for minority classes.","2023-07","2025-02-26 20:37:02","2025-02-26 20:37:02","","3299-3307","","7","34","","","","","","","","","","English","","","","WOS:000754279200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;63<br/>Total Times Cited:&nbsp;&nbsp;64<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Artificial satellites; Deforestation; Earth; Forestry; Monitoring; multilabel image classification; Remote sensing; Satellites; self-attention; Transformers; vision transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DBLRCGFV","journalArticle","2024","Jiao, J; Aljuaid, H","Research on the prediction of English topic richness in the context of multimedia data","PEERJ COMPUTER SCIENCE","","2376-5992","10.7717/peerj-cs.1967","","With the evolution of the Internet and multimedia technologies, delving deep into multimedia data for predicting topic richness holds significant practical implications in public opinion monitoring and data discourse power competition. This study introduces an algorithm for predicting English topic richness based on the Transformer model, applied specifically to the Twitter platform. Initially, relevant data is organized and extracted following an analysis of Twitter's characteristics. Subsequently, a feature fusion approach is employed to mine, extract, and construct features from Twitter blogs and users, encompassing blog features, topic features, and user features, which are amalgamated into multimodal features. Lastly, the combined features undergo training and learning using the Transformer model. Through experimentation on the Twitter topic richness dataset, our algorithm achieves an accuracy of 82.3%, affirming the efficacy and superior performance of the proposed approach.","2024-04-16","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","10","","","","","","","","","","English","","","","WOS:001206809100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","Multi-modal features extraction; Multimedia data; Topic richness; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QL2DSIUL","journalArticle","2024","Xiong, L; Chen, YY; Peng, Y; Ghadi, YY","Improving Robot-Assisted Virtual Teaching Using Transformers, GANs, and Computer Vision","JOURNAL OF ORGANIZATIONAL AND END USER COMPUTING","","1546-2234","10.4018/JOEUC.336481","","This study aims to enhance the efficacy of personalized learning paths by amalgamating transformer models, generative adversarial networks (GANs), and reinforcement learning techniques. To refine personalized learning trajectories, the authors integrated the transformer model for enhanced information assimilation and learning path planning. Through generative adversarial networks, the authors simulated the fusion and interaction of multi-modal information, refining the training of virtual teaching assistants. Lastly, reinforcement learning was employed to optimize the interaction strategies of these assistants, aligning them better with student needs. In the experimental phase, the authors benchmarked their approach against six state-of-the-art models to assess its effectiveness. The experimental outcomes highlight significant enhancements achieved by the authors' virtual teaching assistant compared to traditional methods. Precision improved to 95% and recall to 96%, and an F1 score exceeding 95% was attained.","2024","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","1","36","","","","","","","","","","English","","","","WOS:001165615200005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","computer vision assistance; multimodal perception; personalized learning path planning; robot decision making; transformer model; virtual robot teaching assistant","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8EQUMMTR","journalArticle","2022","Guo, J; Gu, XK; Liu, ZQ; Ji, MH; Wang, JW; Yin, XY; Xu, PF","CM-NET: Cross-Modal Learning Network for CSI-Based Indoor People Counting in Internet of Things","ELECTRONICS","","2079-9292","10.3390/electronics11244113","","In recent years, multiple IoT solutions have used computational intelligence technologies to identify people and count them. WIFI Channel State Information (CSI) has recently been applied to counting people with multiple benefits, such as being cost-effective, easily accessible, free of privacy concerns, etc. However, most current CSI-based work is limited to human location-fixed environments since human location-random environments are more complicated. Aiming to fix the problem of counting people in human location-random environments, we propose a solution using deep learning CM-NET, an end-to-end cross-modal learning network. Since it is difficult to count people with CSI straightforwardly, CM-NET approaches this problem using deep learning, utilizing a multi-layer transformer model to automatically extract the correlations between channels and the number of people. Owing to the complexity of human location-random environments, the transformer model cannot extract characteristics describing the number of people. To enhance the feature learning capability of the transformer model, CM-NET takes the feature knowledge learned by the image-based people counting model to supervise the learning process. In particular, CM-NET works with CSI alone during the testing phase without any image information, and ultimately achieves sound results with an average accuracy of 86%. Meanwhile, the superiority of CM-NET has been verified by comparison with the latest available related methods.","2022-12","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","24","11","","","","","","","","","","English","","","","WOS:000901207400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","computational intelligence; cross-modal learning network; CROWD; CSI; knowledge distillation; MULTIPLE; people counting; TRACKING","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"74GNBJXD","journalArticle","2023","Li, YC; Guo, JW; Qiu, HH; Chen, FY; Zhang, JQ","Denoising Diffusion Probabilistic Models and Transfer Learning for citrus disease diagnosis","FRONTIERS IN PLANT SCIENCE","","1664-462X","10.3389/fpls.2023.1267810","","ProblemsPlant Disease diagnosis based on deep learning mechanisms has been extensively studied and applied. However, the complex and dynamic agricultural growth environment results in significant variations in the distribution of state samples, and the lack of sufficient real disease databases weakens the information carried by the samples, posing challenges for accurately training models.AimThis paper aims to test the feasibility and effectiveness of Denoising Diffusion Probabilistic Models (DDPM), Swin Transformer model, and Transfer Learning in diagnosing citrus diseases with a small sample.MethodsTwo training methods are proposed: The Method 1 employs the DDPM to generate synthetic images for data augmentation. The Swin Transformer model is then used for pre-training on the synthetic dataset produced by DDPM, followed by fine-tuning on the original citrus leaf images for disease classification through transfer learning. The Method 2 utilizes the pre-trained Swin Transformer model on the ImageNet dataset and fine-tunes it on the augmented dataset composed of the original and DDPM synthetic images.Results and conclusionThe test results indicate that Method 1 achieved a validation accuracy of 96.3%, while Method 2 achieved a validation accuracy of 99.8%. Both methods effectively addressed the issue of model overfitting when dealing with a small dataset. Additionally, when compared with VGG16, EfficientNet, ShuffleNet, MobileNetV2, and DenseNet121 in citrus disease classification, the experimental results demonstrate the superiority of the proposed methods over existing approaches to a certain extent.","2023-12-11","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","14","","","","","","","","","","English","","","","WOS:001129429700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","citrus; Denoising Diffusion Probabilistic Models (DDPM); plant disease diagnosis; Swin Transformer; Transfer Learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9TNSA9FR","journalArticle","2022","Nguyen, T; Nguyen, T","Heavyweight Statistical Alignment to Guide Neural Translation","COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE","","1687-5265","10.1155/2022/6856567","","Transformer neural models with multihead attentions outperform all existing translation models. Nevertheless, some features of traditional statistical models, such as prior alignment between source and target words, prove useful in training the state-of-the-art Transformer models. It has been reported that lightweight prior alignment can effectively guide a head in the multihead cross-attention sublayer responsible for the alignment of Transformer models. In this work, we make a step further by applying heavyweight prior alignments to guide all heads. Specifically, we use the weight of 0.5 for the alignment cost added to the token cost in formulating the overall cost of training a Transformer model, where the alignment cost is defined as the deviation of the attention probability from the prior alignments. Moreover, we increase the role of prior alignment, computing the attention probability by averaging all heads of the multihead attention sublayer within the penultimate layer of Transformer model. Experimental results on an English-Vietnamese translation task show that our proposed approach helps train superior Transformer-based translation models. Our Transformer model (25.71) outperforms the baseline model (21.34) by the large 4.37 BLEU. Case studies by native speakers on some translation results validate the machine judgment. The results so far encourage the use of heavyweight prior alignments to improve Transformer-based translation models. This work contributes to the literature on the machine translation, especially, for unpopular language pairs. Since the proposal in this work is language-independent, it can be applied to different language pairs, including Slavic languages.","2022-06-03","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","2022","","","","","","","","","","English","","","","WOS:000811280800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4YTR7SCS","journalArticle","2024","Badrinarayanan, S; Guntuboina, C; Mollaei, P; Farimani, AB","Multi-Peptide: Multimodality Leveraged Language-Graph Learning of Peptide Properties","JOURNAL OF CHEMICAL INFORMATION AND MODELING","","1549-9596","10.1021/acs.jcim.4c01443","","Peptides are crucial in biological processes and therapeutic applications. Given their importance, advancing our ability to predict peptide properties is essential. In this study, we introduce Multi-Peptide, an innovative approach that combines transformer-based language models with graph neural networks (GNNs) to predict peptide properties. We integrate PeptideBERT, a transformer model specifically designed for peptide property prediction, with a GNN encoder to capture both sequence-based and structural features. By employing a contrastive loss framework, Multi-Peptide aligns embeddings from both modalities into a shared latent space, thereby enhancing the transformer model's predictive accuracy. Evaluations on hemolysis and nonfouling data sets demonstrate Multi-Peptide's robustness, achieving state-of-the-art 88.057% accuracy in hemolysis prediction. This study highlights the potential of multimodal learning in bioinformatics, paving the way for accurate and reliable predictions in peptide-based research and applications.","2024-12-19","2025-02-26 20:37:02","2025-02-26 20:37:02","","83-91","","1","65","","","","","","","","","","English","","","","WOS:001380408000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","DATABASE; PREDICTION; PROTEIN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SNLHXS8M","journalArticle","2021","Zirka, SE; Moroz, YI; Zhuykov, AV; Matveev, DA; Kubatkin, MA; Frolov, MV; Popov, M","Eliminating VT uncertainties in modeling ferroresonance phenomena caused by single phase-to-ground faults in isolated neutral network","INTERNATIONAL JOURNAL OF ELECTRICAL POWER & ENERGY SYSTEMS","","0142-0615","10.1016/j.ijepes.2021.107275","","It is commonly recognized that correct transformer model (particularly topological one) is a key element for any ferroresonance simulations. This paper represents a line of reasoning by which a reliable model of a voltage transformer (VT) can be constructed given substantial uncertainties in its parameters and characteristics. Starting with catalog data for electric steels and typical leakage inductances of 6-kV VTs, a model of an isolated neutral network with three inductive VTs is initially fitted to reproduce in detail its ferroresonant behavior for a chosen network capacitance. Then, validity of the network model is verified by accurate predictions of ferroresonance processes for all other capacitance values available and thus different ferroresonance modes recorded during fullscale factory tests. Possibilities to simplify the VT model by neglecting dynamic, and then entire core losses and hysteresis are also shown.","2021-12","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","133","","","","","","","","","","English","","","","WOS:000685650100007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Ferroresonance phenomena; Modeling; Modes; TRANSFORMER MODEL; TRANSIENTS; Voltage transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MWX5VJR9","journalArticle","2022","Lee, J; Kim, T; Park, J; Park, J","Smartphone Sensor-Based Human Motion Characterization with Neural Stochastic Differential Equations and Transformer Model","SENSORS","","1424-8220","10.3390/s22197480","","With many conveniences afforded by advances in smartphone technology, developing advanced data analysis methods for health-related information from smartphone users has become a fast-growing research topic in the healthcare field. Along these lines, this paper addresses smartphone sensor-based characterization of human motions with neural stochastic differential equations (NSDEs) and a Transformer model. NSDEs and modeling via Transformer networks are two of the most prominent deep learning-based modeling approaches, with significant performance yields in many applications. For the problem of modeling dynamical features, stochastic differential equations and deep neural networks are frequently used paradigms in science and engineering, respectively. Combining these two paradigms in one unified framework has drawn significant interest in the deep learning community, and NSDEs are among the leading technologies for combining these efforts. The use of attention has also become a widely adopted strategy in many deep learning applications, and a Transformer is a deep learning model that uses the mechanism of self-attention. This concept of a self-attention based Transformer was originally introduced for tasks of natural language processing (NLP), and due to its excellent performance and versatility, the scope of its applications is rapidly expanding. By utilizing the techniques of neural stochastic differential equations and a Transformer model along with data obtained from smartphone sensors, we present a deep learning method capable of efficiently characterizing human motions. For characterizing human motions, we encode the high-dimensional sequential data from smartphone sensors into latent variables in a low-dimensional latent space. The concept of the latent variable is particularly useful because it can not only carry condensed information concerning motion data, but also learn their low-dimensional representations. More precisely, we use neural stochastic differential equations for modeling transitions of human motion in a latent space, and rely on a Generative Pre-trained Transformer 2 (GPT2)-based Transformer model for approximating the intractable posterior of conditional latent variables. Our experiments show that the proposed method can yield promising results for the problem of characterizing human motion patterns and some related tasks including user identification.","2022-10","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","19","22","","","","","","","","","","English","","","","WOS:000867071100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","deep learning; GPT2; human motion; neural stochastic differential equations; smartphone sensors; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6ZEVIC9H","journalArticle","2024","Zhao, Y; Lu, JL","Spatiotemp oral Sequence Prediction Based on Spatiotemporal Self-Attention Mechanism","INTERNATIONAL JOURNAL OF COMPUTERS COMMUNICATIONS & CONTROL","","1841-9836","10.15837/ijccc.2024.6.6771","","This paper introduces the GCN-Transformer model, an innovative approach that combines Graph Convolutional Networks (GCNs) and Transformer architectures to enhance spatiotemp oral sequence prediction. Targeted at applications requiring precise analysis of complex spatial and temporal data, the model was tested on two distinct datasets: PeMSD8 for traffic flow and KnowAir for air quality monitoring. The GCN-Transformer demonstrated superior performance over traditional models such as LSTMs, standalone GCNs, and other GCN-hybrid models, evidenced by its lower Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE). An ablation study confirmed the importance of each component within the model, showing that removing elements like GCN layers, Transformer layers, attention mechanisms, or positional encoding detrimentally impacts performance. Overall, the GCN-Transformer model offers significant theoretical and practical contributions to the field of spatiotemp oral data analysis, with potential applications across traffic environmental and","2024-12","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","6","19","","","","","","","","","","English","","","","WOS:001348582100005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Graph Convolutional Net- works; Self-attention mechanisms; Spatiotemp oral prediction; Transformer architectures","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GQN3B8ET","journalArticle","2024","Ye, GT; Dai, W; Tao, JT; Qu, JS; Zhu, L; Jin, Q","An improved transformer-based concrete crack classification method","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-54835-x","","In concrete structures, surface cracks are an important indicator for assessing the durability and serviceability of the structure. Existing convolutional neural networks for concrete crack identification are inefficient and computationally costly. Therefore, a new Cross Swin transformer-skip (CSW-S) is proposed to classify concrete cracks. The method is optimized by adding residual links to the existing Cross Swin transformer network and then trained and tested using a dataset with 17,000 images. The experimental results show that the improved CSW-S network has an extended range of extracted image features, which improves the accuracy of crack recognition. A detection accuracy of 96.92% is obtained using the trained CSW-S without pretraining. The improved transformer model has higher recognition efficiency and accuracy than the traditional transformer model and the classical CNN model.","2024-03-14","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","1","14","","","","","","","","","","English","","","","WOS:001185787000035","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","CONVOLUTIONAL NEURAL-NETWORKS; Crack detection; Deep learning; DEFECT DETECTION; DETECTION SYSTEM; Image feature extraction; Structural health monitoring; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4AY3ULAL","journalArticle","2024","Zhu, GS; Deng, ER; Qin, Z; Khan, F; Wei, W; Srivastava, G; Xiong, H; Electronic, SK","Cross-modal interaction and multi-source visual fusion for video generation in fetal cardiac screening","INFORMATION FUSION","","1566-2535","10.1016/j.inffus.2024.102510","","To address the limitation of preserving data for dynamic visualization in fetal ultrasound screening, a novel framework is proposed to facilitate the generation of fetal four-chamber echocardiogram videos, incorporating multi-source visual fusion and understanding. The framework utilizes an effective spectrogram- ultrasound synchronizer to align the ultrasound images with time, ensuring the generated video matches the actual heartbeat rhythm. It further employs effective frame interpolation techniques to synthesize a video by incorporating a nonlinear bidirectional motion prediction. By integrating a Transformer model for the autoregressive generation of visual semantic sequence, the proposed framework demonstrates its capability to generate high-resolution frames. Experimental outcomes show the Clip-Similarity of 96.23% and DINOv2Similarity of 99.77%. Furthermore, a multimodal dataset of fetal echocardiogram examinations has been constructed.","2024-11","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","111","","","","","","","","","","English","","","","WOS:001345414200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","Cross-modal synchronization; Fetal echocardiogram scenario; Multi-source visual fusion and understanding; Transformer model; Visual data generation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PQYTZT6U","journalArticle","2024","Chen, RY; Li, Y; Jiang, YR; Sun, BC; Wang, JQ; Li, Z","Fact-Aware Generative Text Summarization with Dependency Graphs","ELECTRONICS","","2079-9292","10.3390/electronics13163230","","Generative text summaries often suffer from factual inconsistencies, where the summary deviates from the original text. This significantly reduces their usefulness. To address this issue, we propose a novel method for improving the factual accuracy of Chinese summaries by leveraging dependency graphs. Our approach involves analyzing the input text to build a dependency graph. This graph, along with the original text, is then processed by separate models: a Relational Graph Attention Neural Network for the dependency graph and a Transformer model for the text itself. Finally, a Transformer decoder generates the summary. We evaluate the factual consistency of the generated summaries using various methods. Experiments demonstrate that our approach improves about 7.79 points compared to the baseline Transformer model on the Chinese LCSTS dataset using ROUGE-1 metric, and 4.48 points in the factual consistency assessment model StructBERT.","2024-08","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","16","13","","","","","","","","","","English","","","","WOS:001305852900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","dependency graphs; generative text summarization; relational graph attention networks; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AJI85V45","journalArticle","2021","Wiese, LK; Williams, CL; Hain, D; Newman, D; Houston, CP; Kaack, C; Galvin, JE","Detecting dementia among older, ethnically diverse residents of rural subsidized housing","GERIATRIC NURSING","","0197-4572","10.1016/j.gerinurse.2020.09.005","","Rural, ethnically diverse residents face at least twice the risk of Alzheimer's disease than urban residents. Chronic diseases such as diabetes and hypertension which increase dementia risk are more prevalent in rural areas with less access to specialty providers. A home-based approach for increasing dementia detection and treatment rates was tested among rural residents of government-assisted independent living facilities (N = 139; 78% non-White, and 70% with health literacy below 5th grade). Of 28 residents identified at risk during cognitive screening, 25 agreed to further in-depth assessment by adult gerontological nurse practitioners (AGNP). Fifteen of 25 (60%) completing consequent primary provider referrals were diagnosed with dementia and receiving new care (statistically significant; [chi(2)(1) = 76.67, p < .001, Phi = 0.743]). Home-based dementia management through a community engagement approach can help to meet the Healthy People 2030 goals of earlier detection and treatment and reduce the length of costly institutionalizations. (C) 2020 Elsevier Inc. All rights reserved.","2021-03","2025-02-26 20:37:02","2025-02-26 20:37:02","","524-532","","2","42","","","","","","","","","","English","","","","WOS:000637535300031","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","ADULTS; AGNP; ALZHEIMERS-DISEASE; ASSOCIATION; Dementia detection; DIAGNOSIS; Ethnically diverse older adults; HEALTH LITERACY; INTERVENTION; MILD COGNITIVE IMPAIRMENT; PEOPLE; PREVENTION; RISK; Rural; Subsidized Housing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"49IGC7EI","journalArticle","2021","Li, H; Chen, W; Zhu, R; Xue, K; Liu, S; Cao, X; Lv, Y; Xiao, Y; Ouyang, H","Plasma impedance measurement of uncesiated RF-driven negative hydrogen ion source in CSNS","NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT","","0168-9002","10.1016/j.nima.2021.165149","","We developed and optimized an RF-driven H-source at the China Spallation Neutron Source (CSNS) to achieve the requirement of project phase-II. At the beginning of 2019, the first uncesiated H-beam was produced, but 15% RF power was reflected when the forward power was 20 kW. To decrease the reflection of the RF power, the RF power matching network was optimized based on the measurement of the plasma equivalent impedance, and the reflected power was decreased to less than 200W at the same forward power. The plasma equivalent impedance is studied with different conditions (RF power, hydrogen flow rate, and frequency). The results show that the plasma equivalent resistance increases at first and then decreases as the RF power increase. Then the transformer model is adopted to derive the plasma impedance.","2021-04-21","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","996","","","","","","","","","","English","","","","WOS:000632410600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;17</p>","","","Plasma equivalent impedance; Plasma impedance; RF-driven negative hydrogen ion source; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZSUS3NXP","journalArticle","2023","Liu, Z; Kang, X; Ren, FJ","Dual-TBNet: Improving the Robustness of Speech Features via Dual-Transformer-BiLSTM for Speech Emotion Recognition","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2023.3282092","","Speech emotion recognition has always been one of the topics that have attracted a lot of attention from many researchers. In traditional feature fusion methods, the speech features used only come from the data set, and the weak robustness of features can easily lead to overfitting of the model. In addition, these methods often use simple concatenation to fuse features, which will cause the loss of speech information. In this article, to solve the above problems and improve the recognition accuracy, we utilize self-supervised learning to enhance the robustness of speech features and propose a feature fusion model(Dual-TBNet) that consists of two 1D convolutional layers, two Transformer modules and two bidirectional long short-term memory (BiLSTM) modules. Our model uses 1D convolution to take features of different segment lengths and dimension sizes as input, uses the attention mechanism to capture the correspondence between the two features, and uses the bidirectional time series module to enhance the contextual information of the fused features. We designed a total of four fusion models to fuse five pre-trained features and acoustic features. In the comparison experiments, the Dual-TBNet model achieved a recognition accuracy and F1 score of 95.7% and 95.8% on the CASIA dataset, 66.7% and 65.6% on the eNTERFACE05 dataset, 64.8% and 64.9% on the IEMOCAP dataset, 84.1% and 84.3% on the EMO-DB dataset and 83.3% and 82.1% on the SAVEE dataset. The Dual-TBNet model effectively fuses acoustic features of different lengths and dimensions with pre-trained features, enhancing the robustness of the features, and achieved the best performance.","2023","2025-02-26 20:37:02","2025-02-26 20:37:02","","2193-2203","","","31","","","","","","","","","","English","","","","WOS:001012674500005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","affective computing; DATABASES; feature fusion transformer; MODEL; REPRESENTATION; Speech emotion recognition; speech representation learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MVDP5LQS","journalArticle","2022","Haider, CL; Suess, N; Hauswald, A; Park, H; Weisz, N","Masking of the mouth area impairs reconstruction of acoustic speech features and higher-level segmentational features in the presence of a distractor speaker","NEUROIMAGE","","1053-8119","10.1016/j.neuroimage.2022.119044","","Multisensory integration enables stimulus representation even when the sensory input in a single modality is weak. In the context of speech, when confronted with a degraded acoustic signal, congruent visual inputs promote comprehension. When this input is masked, speech comprehension consequently becomes more difficult. But it still remains inconclusive which levels of speech processing are affected under which circumstances by occluding the mouth area. To answer this question, we conducted an audiovisual (AV) multi-speaker experiment using naturalistic speech. In half of the trials, the target speaker wore a (surgical) face mask, while we measured the brain activity of normal hearing participants via magnetoencephalography (MEG). We additionally added a distractor speaker in half of the trials in order to create an ecologically difficult listening situation. A decoding model on the clear AV speech was trained and used to reconstruct crucial speech features in each condition. We found significant main effects of face masks on the reconstruction of acoustic features, such as the speech envelope and spectral speech features (i.e. pitch and formant frequencies), while reconstruction of higher level features of speech segmentation (phoneme and word onsets) were especially impaired through masks in difficult listening situations. As we used surgical face masks in our study, which only show mild effects on speech acoustics, we interpret our findings as the result of the missing visual input. Our findings extend previous behavioural results, by demonstrating the complex contextual effects of occluding relevant visual information on speech processing.","2022-05-15","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","252","","","","","","","","","","English","","","","WOS:000766272000006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","Audiovisual speech; CORTICAL ENTRAINMENT; Face masks; Formants; FREQUENCY; OSCILLATIONS; Speech envelope; Stimulus reconstruction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EE6LMBQI","journalArticle","2024","Nissen, SL; Kemmey, R; Hartshorn, KJ","Perceptual ratings of pronunciation for L2 learners of English as a function of task type, word position, and listener expertise","INTERNATIONAL JOURNAL OF APPLIED LINGUISTICS","","0802-6106","10.1111/ijal.12513","","Second language (L2) learners of English must learn to produce English phonemes, words, and sentences. These L2 learners make many errors when learning English; they may change the place or manner of articulation, insert vowels, or delete consonants. Obstruent sounds, such as fricatives, affricates, and stops, can be especially difficult for L2 learners. This study analyzed native English speakers' perception of the quality of obstruents produced by native Mandarin Chinese and Korean speakers. Target words containing obstruents had been produced in three different tasks: in a carrier phrase, in a paragraph, and in a spontaneous speech sample. Obstruents were produced in word-initial position andword-final position. Raters with differing levels of expertise listened to these words and rated the perceptual quality of the obstruents within the words. This study found that overall, English obstruent productions by native Mandarin and Korean L2 speakers learning English were rated most clear when produced in word-initial position in a carrier phrase or a paragraph. The lowest ratings given were of obstruents in word-final position in spontaneous speech. No significant differences were found for listener expertise level. Combinedwith future research, results from this study will help educate the field of second language instruction as to how the speech of Korean and Mandarin learners of English is perceived. It also provides additional information on the effect that listener expertise has on the judgment of L2 speech production.","2024-05","2025-02-26 20:37:02","2025-02-26 20:37:02","","550-567","","2","34","","","","","","","","","","English","","","","WOS:001089343900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","COMPREHENSIBILITY; ESL; EXPERIENCE; INTELLIGIBILITY; listener expertise; NATIVE SPEAKERS; OBSTRUENTS; perceptual ratings; second language acquisition; SPEECH; STOPS; task type; word position","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UNGYBR8G","journalArticle","2024","Dhanalakshmi, S; Das, S; Senthil, R","Speech features-based Parkinson's disease classification using combined SMOTE-ENN and binary machine learning","HEALTH AND TECHNOLOGY","","2190-7188","10.1007/s12553-023-00810-x","","PurposeParkinson's disease (PD) is one of the most prevalent neurodegenerative diseases in the global context. The presently available detecting process of PD is costly and labour-intensive. Along with a movement disorder, PD also affects speech differently. By causing variation in pitch, monotonicity, slurring of words, or slow speed of talking. This study uses different machine learning binary classification algorithms for the detection and classification of PD.MethodsThe publicly available Parkinson's disease speech features dataset is imbalanced, with only 192 healthy instances compared to 564 PD instances. Synthetic Minority Oversampling Technique - Edited Nearest Neighbours (SMOTE-ENN) algorithms rectify the class imbalance by oversampling and under sampling. Thus, it results in a balanced dataset free of noisy samples. Machine learning binary classifiers, Random Forest, K-Nearest Neighbours, Support Vector Machine, Extreme Gradient Boosting, Decision Tree, and Logistic Regression are investigated.ResultsThe classification algorithms have been analysed and compared based on several standard evaluation metrics. The classification model, resampling using SMOTE-ENN technique, and dimensionality reduction using principal component analysis (PCA) have been performed on the dataset to enhance the performance and prevent overfitting. The combination of SMOTE-ENN and Support Vector Machine (SVM) yields a good accuracy of 96.5%.ConclusionSpeech features are a predictive and non-intrusive method, thus making the diagnostic process painless and straightforward. The reported results are promising to aid the diagnosis of PD so that treatment can be administered as early as possible. Thus, the primary findings are beneficial to detect PD at an early stage with optimal accuracy.","2024-03","2025-02-26 20:37:02","2025-02-26 20:37:02","","393-406","","2","14","","","","","","","","","","English","","","","WOS:001142196900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","DIAGNOSIS; Healthcare; Machine Learning; MULTIPLE TYPES; Parkinsons' disease; Signal Processing; Speech Features","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RFIQK37S","journalArticle","2022","García, AM; Welch, AE; Mandelli, ML; Henry, ML; Lukic, S; Prioris, MJT; Deleon, J; Ratnasiri, BM; Lorca-Puls, DL; Miller, BL; Seeley, W; Vogel, AP; Gorno-Tempini, ML","Automated Detection of Speech Timing Alterations in Autopsy-Confirmed Nonfluent/Agrammatic Variant Primary Progressive Aphasia","NEUROLOGY","","0028-3878","10.1212/WNL.0000000000200750","","Background and Objectives Motor speech function, including speech timing, is a key domain for diagnosing nonfluent/agrammatic variant primary progressive aphasia (nfvPPA). Yet, standard assessments use subjective, specialist-dependent evaluations, undermining reliability and scalability. Moreover, few studies have examined relevant anatomo-clinical alterations in patients with pathologically confirmed diagnoses. This study overcomes such caveats using automated speech timing analyses in a unique cohort of autopsy-proven cases. Methods In a cross-sectional study, we administered an overt reading task and quantified articulation rate, mean syllable and pause duration, and syllable and pause duration variability. Neuroanatomical disruptions were assessed using cortical thickness and white matter (WM) atrophy analysis. Results We evaluated 22 persons with nfvPPA (mean age: 67.3 years; 13 female patients) and confirmed underlying 4-repeat tauopathy, 15 persons with semantic variant primary progressive aphasia (svPPA; mean age: 66.5 years; 8 female patients), and 10 healthy controls (HCs; 70 years; 5 female patients). All 5 speech timing measures revealed alterations in persons with nfvPPA relative to both the HC and svPPA groups, controlling for dementia severity. The articulation rate robustly discriminated individuals with nfvPPA from HCs (area under the ROC curve [AUC] = 0.95), outperforming specialist-dependent perceptual measures of dysarthria and apraxia of speech severity. Patients with nfvPPA exhibited structural abnormalities in left precentral and middle frontal as well as bilateral superior frontal regions, including their underlying WM. The articulation rate correlated with atrophy of the left pars opercularis and supplementary/presupplementary motor areas. Secondary analyses showed that, controlling for dementia severity, all measures yielded greater deficits in patients with nfvPPA and corticobasal degeneration (nfvPPA-CBD, n = 12) than in those with progressive supranuclear palsy pathology (nfvPPA-PSP, n = 10). The articulation rate robustly discriminated between individuals in each subgroup (AUC = 0.82). More widespread cortical thinning was observed for the nfvPPA-CBD than the nfvPPA-PSP group across frontal regions. Discussion Automated speech timing analyses can capture specific markers of nfvPPA while potentially discriminating between patients with different tauopathies. Thanks to its objectivity and scalability; this approach could support standard speech assessments. Classification of Evidence This study provides Class III evidence that automated speech analysis can accurately differentiate patients with nonfluent PPA from normal controls and patients with semantic variant PPA.","2022-08-02","2025-02-26 20:37:02","2025-02-26 20:37:02","","E500-E511","","5","99","","","","","","","","","","English","","","","WOS:000837525800016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;18<br/>Total Times Cited:&nbsp;&nbsp;18<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","APRAXIA; DEMENTIA; NONFLUENT APHASIA; PATHOLOGY; SUPRANUCLEAR PALSY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P8F8WZVK","journalArticle","2023","Shamei, A; Liu, YD; Gick, B","Reduction of vowel space in Alzheimer's disease","JASA EXPRESS LETTERS","","2691-1191","10.1121/10.0017438","","Reduced vowel space area (VSA) is a known effect of neurodegenerative diseases such as Parkinson's disease (PD). Using large publicly available corpuses, two experiments were conducted comparing the vowel space of speakers with and without Alzheimer's disease (AD) during spontaneous and read speech. First, a comparison of vowel distance found reduced distance in AD for English spontaneous speech, but not Spanish read speech. Findings were then verified using an unsupervised learning approach to quantify VSA through cluster center detection. These results corroborate observations for PD that VSA reduction is task-dependent, but further experiments are necessary to quantify the effect of language.","2023-03","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","3","3","","","","","","","","","","English","","","","WOS:000943160100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","ARTICULATION; INDIVIDUALS; LANGUAGE; SPEECH-INTELLIGIBILITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4A5GCLR2","journalArticle","2023","Al-Ghezi, R; Voskoboinik, K; Getman, Y; Von Zansen, A; Kallio, H; Kurimo, M; Huhta, A; Hildén, R","Automatic Speaking Assessment of Spontaneous L2 Finnish and Swedish","LANGUAGE ASSESSMENT QUARTERLY","","1543-4303","10.1080/15434303.2023.2292265","","The development of automated systems for evaluating spontaneous speech is desirable for L2 learning, as it can be used as a facilitating tool for self-regulated learning, language proficiency assessment, and teacher training programs. However, languages with fewer learners face challenges due to the scarcity of training data. Recent advancements in machine learning have made it possible to develop systems with a limited amount of target domain data. To this end, we propose automatic speaking assessment systems for spontaneous L2 speech in Finnish and Finland Swedish, comprising six machine learning models each, and report their performance in terms of statistical evaluation criteria.","2023-10-20","2025-02-26 20:37:02","2025-02-26 20:37:02","","421-444","","4-5","20","","","","","","","","","","English","","","","WOS:001129284900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","FLUENCY; PROFICIENCY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4XQIVURA","journalArticle","2021","Rhee, N; Chen, AJ; Kuang, JJ","Going beyond F0: The acquisition of Mandarin tones","JOURNAL OF CHILD LANGUAGE","","0305-0009","10.1017/S0305000920000239","","Using a semi-spontaneous speech corpus, we present evidence from computational modelling of tonal productions from Mandarin-speaking children (4- to 11-years old) and adults, showing that children exceed the adult-level tonal distinction at the age of 7 to 8 years using F0 cues, but do not reach the high adult-level distinction using spectral cues even at the age of 10 to 11 years. The difference in the developmental curves of F0 and spectral cues suggests that, in Mandarin tone production, secondary cues continue to develop even after the mastery of primary cues.","2021-03","2025-02-26 20:37:02","2025-02-26 20:37:02","","387-398","","2","48","","","","","","","","","","English","","","","WOS:000618013600008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","AMPLITUDE; CUES; FREQUENCY; INFORMATION; Mandarin; PERCEPTION; QUALITY; spectral cues; SPEECH; tone acquisition; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N75MHJ8F","journalArticle","2024","Peck, N; Becker, L","Syntactic pausing? Re-examining the associations","LINGUISTICS VANGUARD","","2199-174X","10.1515/lingvan-2022-0156","","In this study, we look at the distribution of silent pauses within existing multi-language corpora to see whether their location and duration correlate with clause boundaries. Our study is based on data of seven languages from Multi-CAST. We supplemented the original clause boundary annotations with information about silent pauses in order to investigate the alignment of clause boundaries and pausing. We find a gradient association between clause boundary strength and the probability of a pause and a two-way distinction for pause duration within clauses and at clause boundaries.","2024-12-31","2025-02-26 20:37:02","2025-02-26 20:37:02","","223-237","","1","10","","","","","","","","","","English","","","","WOS:001294798500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;81</p>","","","CLAUSES; COMPLEXITY; corpus typology; ENGLISH; INTONATION; LENGTH; PAUSES; pausing; PERFORMANCE STRUCTURES; PROSODY; prosody-syntax interface; SPEECH; spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ELJFPLTW","journalArticle","2023","Muñoz-Builes, DM","PROSODIC FOCUS IN SPANISH SPOKEN IN MEDELL?N AND APARTAD?: SOCIAL FACTORS FOR ITS UNDERSTANDING","LINGUISTICA Y LITERATURA","","0120-5587","10.17533/udea.lyl.n83a06","","This article describes the prosodic characteristics of utterances with a broad focus, narrow informative focus and narrow corrective contrastive focus in Apartado and Medellin, Colombia. A corpus of 195 utterances elicited from semi -spontaneous speech and sentence reading is analyzed. The prosodic analysis is based on the metric-autosegmental model, with its Sp_ToBI labeling system and the behavior of declination, speed, tonal range, intensity, and duration. The results suggest a relevant influence of the acoustic parameters and some social variables of the collaborators in the performance of the different types of focus.","2023-01","2025-02-26 20:37:02","2025-02-26 20:37:02","","139-164","","83","","","","","","","","","","","English","","","","WOS:000961211600008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","broad focus; Colombian Spanish; intonation; narrow focus; prosody","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UTL9A4HW","journalArticle","2022","Yang, RS; Gan, Y; Zhang, CF","Chinese Named Entity Recognition Based on BERT and Lightweight Feature Extraction Model","INFORMATION","","2078-2489","10.3390/info13110515","","In the early named entity recognition models, most text processing focused only on the representation of individual words and character vectors, and paid little attention to the semantic relationships between the preceding and following text in an utterance, which led to the inability to handle the problem of multiple meanings of a word during recognition. To address this problem, most models introduce the attention mechanism of Transformer model to solve the problem of multiple meanings of a word in text. However, the traditional Transformer model leads to a high computational overhead due to its fully connected structure. Therefore, this paper proposes a new model, the BERT-Star-Transformer-CNN-BiLSTM-CRF model, to solve the problem of the computational efficiency of the traditional Transformer. First, the input text is dynamically generated into a character vector using the BERT model pre-trained in large-scale preconditioning to solve the problem of multiple meanings of words, and then the lightweight Star-Transformer model is used as the feature extraction module to perform local feature extraction on the word vector sequence, while the CNN-BiLSTM joint model is used to perform global feature extraction on the context in the text. The obtained feature sequences are fused. Finally, the fused feature vector sequences are input to CRF for prediction of the final results. After the experiments, it is shown that the model has a significant improvement in precision, recall and Fl value compared with the traditional model, and the computational efficiency is improved by nearly 40%.","2022-11","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","11","13","","","","","","","","","","English","","","","WOS:000881203700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","BERT; deep learning; named entity recognition; neural network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MLC5ZH6N","journalArticle","2024","Chaiwongyen, A; Duangpummet, S; Karnjana, J; Kongprawechnon, W; Unoki, M","Potential of Speech-Pathological Features for Deepfake Speech Detection","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3447582","","There is a great concern regarding the misuse of deepfake speech technology to synthesize a real person's voice. Therefore, developing speech-security systems capable of detecting deepfake speech remains paramount in safeguarding against such misuse. Although various speech features and methods have been proposed, their potential for distinguishing between genuine and deepfake speech remains unclear. Since speech-pathological features with deep learning are widely used to assess unnaturalness in disordered voices associated with voice-production mechanisms, we investigated the potential of eleven speech-pathological features for distinguishing between genuine and deepfake speech, i.e., jitter (three types), shimmer (four types), harmonics-to-noise ratio, cepstral-harmonics-to-noise ratio, normalized noise energy, and glottal-to-noise excitation ratio. This paper proposes a method of combining two models on the basis of two different dimensions of speech-pathological features to greatly improve the effectiveness of deepfake speech detection, along with mel-spectrogram features, to enhance detection efficiency. We evaluated the proposed method on the datasets of the Automatic Speaker Verification Spoofing and Countermeasures Challenges ASVspoof 2019 and 2021. The results indicate that the proposed method outperforms the baselines in terms of accuracy, recall, F1-score, and F2-score, achieving 95.06, 99.46, 97.30, and 98.59%, respectively, on the ASVspoof 2019 dataset. It also surpasses the baselines on the ASVspoof 2021 dataset in terms of recall, F1-score, F2-score, and equal error rate, achieving 99.96, 96.65, 98.18, and 15.97%, respectively.","2024","2025-02-26 20:37:02","2025-02-26 20:37:02","","121958-121970","","","12","","","","","","","","","","English","","","","WOS:001310669700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","cepstral-harmonics-to-noise ratio; Deepfake speech detection; Deepfakes; Feature extraction; FREQUENCY; glottal-to-noise; Harmonic analysis; harmonics-to-noise ratio; Jitter; jitter and shimmer; Noise measurement; normalized noise energy; Pathology; Speech analysis; speech-pathological feature; Training; Voice activity detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6PJSHUPA","journalArticle","2023","Sun, YL; Wang, H","Study of diagnosis for rotating machinery in advanced nuclear reactor based on deep learning model","FRONTIERS IN ENERGY RESEARCH","","2296-598X","10.3389/fenrg.2023.1210703","","Many types of rotating mechanical equipment, such as the primary pump, turbine, and fans, are key components of fourth-generation (Gen IV) advanced reactors. Given that these machines operate in challenging environments with high temperatures and liquid metal corrosion, accurate problem identification and health management are essential for keeping these machines in good working order. This study proposes a deep learning (DL)-based intelligent diagnosis model for the rotating machinery used in fast reactors. The diagnosis model is tested by identifying the faults of bearings and gears. Normalization, augmentation, and splitting of data are applied to prepare the datasets for classification of faults. Multiple diagnosis models containing the multi-layer perceptron (MLP), convolutional neural network (CNN), recurrent neural network (RNN), and residual network (RESNET) are compared and investigated with the Case Western Reserve University datasets. An improved Transformer model is proposed, and an enhanced embeddings generator is designed to combine the strengths of the CNN and transformer. The effects of the size of the training samples and the domain of data preprocessing, such as the time domain, frequency domain, time-frequency domain, and wavelet domain, are investigated, and it is found that the time-frequency domain is most effective, and the improved Transformer model is appropriate for the fault diagnosis of rotating mechanical equipment. Because of the low probability of the occurrence of a fault, the imbalanced learning method should be improved in future studies.","2023-07-18","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","11","","","","","","","","","","English","","","","WOS:001041047800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","advanced nuclear reactor; deep learning; fault diagnosis model; FAULT-DIAGNOSIS; improved transformer model; rotating machine","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LZ7CLV6B","journalArticle","2025","Du, P; Ye, YX; Wu, H; Wang, JZ","Study on deterministic and interval forecasting of electricity load based on multi-objective whale optimization algorithm and transformer model","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.126361","","Scientific and accurate electricity load forecasting is crucial for realizing effective power dispatch and ensuring the security, reliability and economy of power system operation. To this end, this research proposes a hybrid framework using data processing and analysis methods, deep learning and a multi-objective optimization algorithm. The framework includes four modules: data processing and mining module, optimization module, forecasting module, and evaluation module. Specifically, in the data processing and mining module, a longitudinal data selection method is used to extract sequence similarity features, while distribution functions are applied to capture the statistical properties of the data. In the optimization module, the multi-objective whale optimization algorithm is adopted to fine-tune the hyperparameters of the Transformer model to construct an optimized Transformer model. In the forecasting module, deterministic and uncertainty predictions of the developed model and comparison methods are carried out using two electricity load datasets to get the final predicted values. Furthermore, in the evaluation module, several deterministic prediction evaluation metrics and three uncertainty evaluation metrics are introduced to evaluate the prediction abilities of the methods. Ultimately, the numerical results display that compared with the optimal benchmark model, the developed model using two datasets can enhance the improvement percentage of mean absolute percentage error by 35.9327% and 23.7584%, respectively, which demonstrates its higher prediction performance than benchmark models, improves the prediction accuracy of electricity load, and provides valuable insights and references for other energy prediction fields.","2025-04-05","2025-02-26 20:37:02","2025-02-26 20:37:02","","","","","268","","","","","","","","","","English","","","","WOS:001399217900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Deterministic and interval forecasting; Electricity load forecasting; Multi-objective whale optimization algorithm; SYSTEM; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"45UTDMK8","journalArticle","2024","Wang, YH; Wang, YF; Cui, TY; Fang, ZJ","Fast Video-Based Point Cloud Compression Based on Early Termination and Transformer Model","IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTATIONAL INTELLIGENCE","","2471-285X","10.1109/TETCI.2024.3360290","","Video-based Point Cloud Compression (V-PCC) was proposed by the Moving Picture Experts Group (MPEG) to standardize Point Cloud Compression (PCC). The main idea of V-PCC is to project the Dynamic Point Cloud (DPC) into auxiliary information, occupancy, geometry, and attribute videos for encoding utilizing High Efficiency Video Coding (HEVC), Versatile Video Coding (VVC), etc. Compared with the previous PCC algorithms, V-PCC has achieved a significant improvement in compression efficiency. However, it is accompanied by substantial computational complexity. To solve this problem, this paper proposes a fast V-PCC method to decrease the coding complexity. Taking into account the coding characteristic of V-PCC, the geometry and attribute maps are first classified into occupied and unoccupied blocks. Moreover, we analyze Coding Unit (CU) splitting for geometry and attribute map. Finally, we propose fast V-PCC algorithms based on early termination algorithm and transformer model, in which the early termination method is proposed for low complexity blocks in the geometry and attribute map, and the transformer model-based fast method is designed to predict the optimal CU splitting modes for the occupied block of the attribute map. The proposed algorithms are implemented with typical DPC sequences on the Test Model Category 2 (TMC2). The experimental results imply that the average time of the proposed method can significantly reduce 56.39% and 55.10% in the geometry and attribute map, respectively, with negligible Bjontegaard-Delta bitrate (BD-rate) compared with the anchor method.","2024-06","2025-02-26 20:37:03","2025-02-26 20:37:03","","2336-2348","","3","8","","","","","","","","","","English","","","","WOS:001177060100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Low complexity; occupancy map; PARTITION; transformer; V-PCC; VVC","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XYRSBR59","journalArticle","2024","Zhang, XL; Hou, DD; Mao, Q; Wang, ZH","Predicting microseismic sensitive feature data using variational mode decomposition and transformer","JOURNAL OF SEISMOLOGY","","1383-4649","10.1007/s10950-024-10193-9","","Rock burst is one of the major disasters that endanger coal safety production. If a rock burst occurs, it will cause terrible casualties and significant property losses. Therefore, this article proposes to predict the sensitive characteristics of microseisms, which can achieve the prediction and early warning of rock burst disasters to a certain extent. To effectively improve the prediction accuracy and robustness of microseismic sensitive feature data, a hybrid model called VMD-Transformer is suggested in this study for predicting time series of microseismic sensitive features. This model is based on the variational mode decomposition (VMD) and transformer model and aims to predict future eigenvalue from the historical data of sensitive features. To a certain extent, the transformer model is used to predict the future eigenvalue, while the VMD is used to extract the features of the time series data at various frequency domain scales, which solves the problem of non-stationary time series data being difficult to predict accurately due to high fluctuations. This study extracts sensitive features from microseismic events that the same source registered by a certain geophone after locating, decomposes the time series of the sensitive features using VMD, predicts each component of the decomposition separately using the transformer model, and then combines the component prediction results to produce the final prediction results. Experimental results indicate that our method has the features of a simple algorithm, strong adaptivity, and high prediction accuracy and can effectively predict time series of sensitive features extracted from microseismic signals.","2024-02","2025-02-26 20:37:03","2025-02-26 20:37:03","","229-250","","1","28","","","","","","","","","","English","","","","WOS:001154386700003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Hybrid model; Microseismic signal data predicting; Transformer; VMD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L7XFF62B","journalArticle","2022","Liu, HL; Zhan, YZ; Xia, HF; Mao, QR; Tan, YX","Self-supervised transformer-based pre-training method using latent semantic masking auto-encoder for pest and disease classification","COMPUTERS AND ELECTRONICS IN AGRICULTURE","","0168-1699","10.1016/j.compag.2022.107448","","Pest and disease classification is a challenging issue in agriculture. Currently, the classification algorithms of pests and diseases based on CNN models have become popular. However, these methods have a limited performance improvement due to a lack of global information interaction and discriminative feature represen-tation. Therefore, we propose a self-supervised transformer-based pre-training method using latent semantic masking auto-encoder (LSMAE). In this method, a feature relationship conditional filtering (FRCF) based on k-NN graph is proposed for filtering irrelevant data from the source domain and generating a subset of source domain. The data in this subset are similar to that of target domain which can supplement feature learning of the target domain. To further improve the performance, a novel auto-encoder based on latent semantic masking is proposed for transformer model pre-training. This auto-encoder can select key patches of each image in the subset of the source domain and let the transformer model learn a more discriminative feature representation. Finally, the target domain data are utilized to fine-tune the pre-trained transformer model. Experiments conducted on public datasets, such as IP102, CPB, and Plant Village, show that our method outperforms the state-of-the-art methods. For example, our method achieves 74.69%/76.99%/99.93% accuracy on IP102/CPB/Plant Village, demonstrating that the proposed self-supervised transformer-based pre-training method is more effective in the pest and disease classification field than CNN-based methods.","2022-12","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","203","","","","","","","","","","English","","","","WOS:000900129400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Feature relationship conditional filtering; Latent semantic masking; Pest and disease classification; Self-supervised; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CK6DTXSB","journalArticle","2025","Zhu, GP; Jia, WQ; Cheng, LF; Xiang, L; Hu, AJ","A Non-stationary Transformer model for power forecasting with dynamic data distillation and wake effect correction suitable for large wind farms","ENERGY CONVERSION AND MANAGEMENT","","0196-8904","10.1016/j.enconman.2024.119292","","Reliable, high-precision short-term power forecasting is crucial for ensuring power safety and improving wind energy utilization. However, the randomness and non-stationary features of wind present significant challenges in enhancing the precision and efficiency of power forecasts in large-scale wind farm (WF). Previous research often fails to adaptively enhance the original data's features and neglects the impact of wake effects between wind turbines (WTs), leading to reduced forecasting accuracy. In this paper, a novel method is proposed for power forecasting based on non-stationary Transformer model, which also incorporates dynamic data distillation and wake effect correction to improve forecasting performance. In this proposed method, a non-stationary Transformer model is proposed for extracting features from supervisory control and data acquisition (SCADA) data, which significantly improved the feature extraction capability for non-stationary SCADA data. A dynamic data distillation technique is proposed to remove redundant data and enhance dataset quality, and the wake effect is developed to correct forecasting results and reducing error sources. Dynamic data distillation addresses the loss of data features caused by dataset preprocessing, while wake correction reduces the forecasting errors caused by the wake effect between WTs. The SCADA datasets are used from northwest and northeast China WFs, and the forecasting results demonstrate the effectiveness and superiority of the proposed method. Ablation experiments further confirm that dynamic data distillation and wake effect effectively enhance wind power forecasting accuracy.","2025-01-15","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","324","","","","","","","","","","English","","","","WOS:001378440200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Dynamic data distillation; Non-stationary transformer; OPTIMIZATION; SPEED; Wake effect; Wind power forecasting; Wind turbine","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MVGR45XB","journalArticle","2024","Gao, SQ; Zhou, HY; Chen, TY; He, MR; Xu, RH; Li, JX","PE-Attack: On the Universal Positional Embedding Vulnerability in Transformer-Based Models","IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY","","1556-6013","10.1109/TIFS.2024.3442617","","The Transformer model has gained significant recognition for its remarkable computational capabilities and versatility, positioning itself as a fundamental component in numerous practical applications. However, the robustness of the Transformer model, specifically its stability and reliability under various types of adversarial attacks, is of utmost importance for its practical applicability. Furthermore, it offers valuable insights for the design of more efficient and secure models. In contrast with conventional investigations into adversarial robustness, our study focuses on the analysis of Positional Embeddings (PEs), a crucial component that sets the Transformer model apart from previous model architectures. Theoretical analysis of PEs has been limited due to previous predominantly empirical design, which includes features such as sinusoidal or linear patterns, learned or fixed characteristics, and absolute or relative measurements. Our investigation delves deep into potential vulnerabilities within PEs. Initially, we develop a set of input infection techniques that can be universally applied to exploit vulnerabilities present in the Transformer architecture and its variants. In addition, we propose a novel adversarial attack that manipulates the model by providing it with incorrect positional information, enabling an evasion attack. Significantly, in contrast to previous attacks that were limited to a single task, our conducted experiments involving time-series analysis, natural language processing, and computer vision indicate that the susceptibility of PEs could be universal and transferable. This finding serves as a significant warning for future Transformer-based model design, urging researchers to consider potential security risks inherent in the model's structure.","2024","2025-02-26 20:37:03","2025-02-26 20:37:03","","9359-9373","","","19","","","","","","","","","","English","","","","WOS:001336220200004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","adversarial attack; Analytical models; Computational modeling; Neural networks; Noise; Predictive models; robustness; Robustness; ROBUSTNESS; Task analysis; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JFHYAKUD","journalArticle","2023","Xing, LM; Liu, WJ; Liu, XL; Li, X","An Enhanced Vision Transformer Model in Digital Twins Powered Internet of Medical Things for Pneumonia Diagnosis","IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS","","0733-8716","10.1109/JSAC.2023.3310096","","The computer-aided system and chest X-ray images play an important role in the diagnosis of pneumonia, which are the main way of pneumonia diagnosis. The traditional deep learning models have achieved some success in medical images, which captures the potential features of the image by continuously sliding the fixed convolution kernel. The disadvantage of this method is that it cannot effectively capture the long-distance dependencies in the image, and it does not have the ability of dynamic adaptive modeling. Next, the high-quality labeled data of chest X-ray images are very scarce. In order to achieve high-quality artificial intelligence diagnosis, a large number of high-quality annotated chest X-ray images are required. In this work, based on technologies such as Internet of Medical Things (IoMT) and Digital Twins, we built an intelligent IoMT platform for automatic diagnosis of pneumonia. For the digital twin of the lung, we propose an enhanced vision transformer model (EVTM) for analyzing chest X-ray images to determine whether the patient is infected with pneumonia. The EVTM model utilizes the vision transformer for training and inference on chest X-ray images. Then the EVTM model uses the variational autoencoder model for data augmentation, so that the amount of chest X-ray images meets the training requirements of the model. Finally, we conducted extensive experiments on the standard chest X-ray image dataset to verify the effectiveness of the EVTM model.","2023-11","2025-02-26 20:37:03","2025-02-26 20:37:03","","3677-3689","","11","41","","","","","","","","","","English","","","","WOS:001105001400017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","digital twins; enhanced vision transformer model; Internet of Medical Things; NEURAL-NETWORK; pneumonia diagnosis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4NRDZP6M","journalArticle","2023","Vaaras, E; Ahlqvist-Björkroth, S; Drossos, K; Lehtonen, L; Räsänen, O","Development of a speech emotion recognizer for large-scale child-centered audio recordings from a hospital environment","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2023.02.001","","In order to study how early emotional experiences shape infant development, one approach is to analyze the emotional content of speech heard by infants, as captured by child-centered daylong recordings, and as analyzed by automatic speech emotion recognition (SER) systems. However, since large-scale daylong audio is initially unannotated and differs from typical speech corpora from controlled environments, there are no existing in-domain SER systems for the task. Based on existing literature, it is also unclear what is the best approach to deploy a SER system for a new domain. Consequently, in this study, we investigated alternative strategies for deploying a SER system for large-scale child-centered audio recordings from a neonatal hospital environment, comparing cross-corpus generalization, active learning (AL), and domain adaptation (DA) methods in the process. We first conducted simulations with existing emotion-labeled speech corpora to find the best strategy for SER system deployment. We then tested how the findings generalize to our new initially unannotated dataset. As a result, we found that the studied AL method provided overall the most consistent results, being less dependent on the specifics of the training corpora or speech features compared to the alternative methods. However, in situations without the possibility to annotate data, unsupervised DA proved to be the best approach. We also observed that deployment of a SER system for real-world daylong child-centered audio recordings achieved a SER performance level comparable to those reported in literature, and that the amount of human effort required for the system deployment was overall relatively modest.","2023-03","2025-02-26 20:37:03","2025-02-26 20:37:03","","9-22","","","148","","","","","","","","","","English","","","","WOS:000991843700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Daylong audio; LENA recorder; Real-world audio; Speech analysis; Speech emotion recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3I95MDAS","journalArticle","2022","He, F; Hu, XY; Zhu, C; Li, Y; Liu, YP","Multi-Scale Spatial and Temporal Speech Associations to Swallowing for Dysphagia Screening","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2022.3203235","","Dysphagia is a common symptom of many neurological diseases. It often occurs in older adults and increases the risk of aspiration pneumonia. Existing diagnosis systems of dysphagia are invasive or require patients to swallow liquids, which are costly and harmful to the patients. In this work, we propose an early screening system of dysphagia based on two kinds of throat signals, i.e., vowels and sentences. Based on the vowels, two new speech feature sets are developed: PET (pitch/energy trajectory) and FS-Conts (full spectrogram contours). The PET focuses on the prominent resonance energy of speech to track the pitch and energy fluctuations. It can reflect the stability of vocal cords in the speech generation process. The FS-Conts feature set is proposed to emphasize the spatial details of formants based on three-dimensional contours. Concerning the sentences, three categories of speech features are proposed, called LSSDL (log symmetric spectral difference level), C-coes (crucial energy coefficients), and LDF (local dynamic features). The three features explore the speech representations of dysphagia from global variations to local associations. The LSSDL highlights the global spectral differences in the interested frequency region. The C-coes and LDF locate local speech differences in specific frequency regions and time duration. In addition, a new feature selection algorithm is developed to search for distinguishing features. In the experiments, the SVM classifier is adopted and the dysphagia detection accuracy reaches 95.07%. The results of comparative experiments indicate that our system performs better than the existing methods.","2022","2025-02-26 20:37:03","2025-02-26 20:37:03","","2888-2899","","","30","","","","","","","","","","English","","","","WOS:000853834700002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","AUTOMATIC DETECTION; DYSARTHRIA; Dysphagia; Feature extraction; Hospitals; multi-scale speech analysis; Pipelines; quantitative feature selection; SCHIZOPHRENIA; spatial spectrogram contours; Spectrogram; Speech processing; throat signal; Trajectory; Vibrations; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C6KDJPTN","journalArticle","2021","Fernandes, SV; Ullah, MS","Use of Machine Learning for Deception Detection From Spectral and Cepstral Features of Speech Signals","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2021.3084200","","In this research, four unique nonlinear speech features are extracted and analyzed to study the dissimilarity pattern between when the speaker is being deceitful and truthful based on how human speech is perceived. The speaker was under stress in a police interrogation where two ground truth and two deceitful responses were recorded during three different times of the day. Using the audio recordings from all three sessions, the cepstral features and spectral energy features are extracted. Cepstral features are the Mel frequency cepstrum coefficient, from where the delta cepstrum and the time-difference cepstrum features are developed. On the other hand, the spectral energy features are the energy of Bark band energy from where the delta energy and the time-difference energy features are developed. The Levenberg-Marquardt classification method and the long short-term memory classification method are then applied to evaluate the accuracy of detecting deception based on the nine unique training and testing combinations of the three different sessions and their extracted cepstrum and spectral energy features. In addition, the principal component analysis is applied to reduce the dimensionality from the extracted features for further improvement. The projected principal components of the four types of features showed improved accuracy in order to distinguish between truthful and deceptive speech pattern. After incorporating with principal component analysis, the long short-term memory classification method with time-difference spectral energy feature shows the highest recognition rate compared to Levenberg-Marquardt algorithm with other cepstral and spectral features.","2021","2025-02-26 20:37:03","2025-02-26 20:37:03","","78925-78935","","","9","","","","","","","","","","English","","","","WOS:000673787700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Cepstral features; Cepstrum; deception detection; ENHANCEMENT; Feature extraction; Law enforcement; machine learning; Mel frequency cepstral coefficient; NEURAL-NETWORK; principal component analysis; Principal component analysis; spectral features; speech analysis; Speech recognition; Support vector machines","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6C4CLA4Q","journalArticle","2022","Lin, CS; Hsieh, HY","An Automatic Defect Detection System for Synthetic Shuttlecocks Using Transformer Model","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3165224","","With an estimation of 220 million people playing badminton on a regular basis, it was particularly popular in Asia but has growing popularity in different regions of the world. The demands of the relevant products, such as shuttlecocks and rackets, are also increasing in the sports industry. Synthetic shuttlecock, produced to offer similar experience and feel as feather shuttlecocks to players, is a more economical alternative to feather shuttlecocks. In addition to maintaining high throughput production for synthetic shuttlecocks with cost reduction, a more substantial improvement in quality control is desired as well. Since the defect detection of synthetic shuttlecocks is a challenging task, it heavily relies on human visual inspection at present. The existing manual quality-inspection process is not only error-prone but also considerably less efficient. In this paper, we propose an intelligent system to overcome these difficulties and bridge the gap between research and practice. Two cylinder grippers are designed to automatically deliver the shuttlecocks, a camera is used for capturing images and an end-to-end objection detection approach based on the Transformer model is investigated to recognize defects. Empirical results show that the proposed system obtains encouraging performance with AP(50) value of 87.5% and outperforms other methods. Ablation studies demonstrate that our approach can considerably boost the detection performance of synthetic shuttlecocks. Moreover, the processing speed is much faster than human operators and suitable for industrial applications.","2022","2025-02-26 20:37:03","2025-02-26 20:37:03","","37412-37421","","","10","","","","","","","","","","English","","","","WOS:000782403700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","cylinder gripper; defect detection; Detectors; Feathers; Feature extraction; Inspection; intelligent system; Manuals; Synthetic shuttlecocks; Task analysis; transformer model; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9BCNKC25","journalArticle","2025","Xiao, CW; Dong, J; Dou, HF; Li, YN; Wang, WJ; Ren, FC","A Transformer Network Air Temperature and Humidity Inversion Method Based on ATMS Brightness Temperature Data","IEEE GEOSCIENCE AND REMOTE SENSING LETTERS","","1545-598X","10.1109/LGRS.2024.3507938","","Accurately measuring and inverting air parameters, such as air temperature and humidity, is crucial for weather forecasting, climate research, and environmental monitoring. In this letter, we propose an inversion method based on the transformer model to accurately estimate the spatial distribution of air temperature and humidity. Compared with traditional methods, the transformer model demonstrates superior ability in capturing nonlinear relationships and spatial dependencies in observational data, thereby improving inversion accuracy. Experiments conducted on real observational data have shown that compared to traditional techniques, the proposed method achieves a reduction of over 4.8% in the root mean square error (RMSE) of air temperature and over 14.2% in humidity estimation, demonstrating its high accuracy and reliability in inverting air temperature and humidity. This method provides a new approach for advancing air parameter inversion technology.","2025","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","22","","","","","","","","","","English","","","","WOS:001380677800018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;10</p>","","","Air temperature and humidity; Atmospheric modeling; Brightness temperature; Data models; Distributed databases; Humidity; inversion method; Temperature dependence; Temperature distribution; Temperature measurement; transformer; Transformers; Tropical cyclones","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MQNGZGH6","journalArticle","2022","Miao, PC; Li, G; Qu, L","Accurate Current Drive Modeling on EAST","IEEE TRANSACTIONS ON PLASMA SCIENCE","","0093-3813","10.1109/TPS.2022.3179023","","A nonlinear transformer model is used for describing the tokamak discharge with fraction of noninductive current. The nonlinear model accurately identifies the tokamak as a toroidal transformer by a voltage balance equation. In order to verify the feasibility of the application of the nonlinear model in the experimental advanced superconducting tokamak (EAST), the voltage balance equation is checked for the different scenarios and applied to calculate and analyze the noninductive current in shots #73999 and #66740, respectively. Calculation results indicate that the #73999 shot H-mode plasma discharge is full noninductive current drive and occupies approximately 99% of plasma current. It is a good agreement with the simulation result (98%) by the integrated modeling under the framework OMFIT with equilibrium code EAST equilibrium fitting (EFIT), and transport codes TGYRO and ONETWO in EAST. For the #66740 shot, it is nearly full noninductive current drive.","2022-07","2025-02-26 20:37:03","2025-02-26 20:37:03","","2245-2250","","7","50","","","","","","","","","","English","","","","WOS:000826401800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","CONSUMPTION; Discharges (electric); Experimental advanced superconducting tokamak (EAST); Mathematical models; noninductive current drive fraction; nonlinear transformer model; Plasmas; Tokamak devices; Toroidal magnetic fields; Transformers; Voltage","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HUIVH3W2","journalArticle","2024","Wang, L; Dai, YF; Liu, W; Zhou, S; Long, X; Xi, ZZ; Xue, JP; Wang, W","Deep learning transient electromagnetic inversion for seawater intrusion","JOURNAL OF GEOPHYSICS AND ENGINEERING","","1742-2132","10.1093/jge/gxae107","","To enhance the capability of the transient electromagnetic method (TEM) in detecting seawater intrusion and delineating the boundaries in coastal areas, we developed a deep learning inversion method for TEM data based on the Swin Transformer model in this study. First many standardized resistivity models were designed and generated to describe the subsurface resistivity structures associated with seawater intrusion in coastal areas. Then, TEM forward modeling was performed to compute the corresponding TEM responses, thereby constructing a seawater intrusion-oriented training dataset. Next, the robust Swin Transformer model was employed as the backbone network to build a deep learning inversion model, named SITEMNet, to derive a direct nonlinear transformation that maps TEM responses to subsurface resistivity models. The proposed SITEMNet inversion technique was validated using simulated data scenarios and actual field TEM measurements, showing great promise in accurately identifying seawater intrusion interface and geological formations.","2024-11-26","2025-02-26 20:37:03","2025-02-26 20:37:03","","1810-1821","","6","21","","","","","","","","","","English","","","","WOS:001364227600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","AQUIFER; AREA; deep learning; DELINEATION; resistivity model; SALTWATER INTRUSION; seawater intrusion; Swin Transformer; transient electromagnetic method","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8YV28ZYS","journalArticle","2023","Utianski, RL; Meade, G; Duffy, JR; Clark, HM; Botha, H; Machulda, MM; Dickson, DW; Whitwell, JL; Josephs, KA","Longitudinal characterization of patients with progressive apraxia of speech without clearly predominant phonetic or prosodic speech features","BRAIN AND LANGUAGE","","0093-934X","10.1016/j.bandl.2023.105314","","Most recent studies of progressive apraxia of speech (PAOS) have focused on patients with phonetic or prosodic predominant PAOS to understand the implications of the presenting clinical phenotype. Patients without a clearly predominating speech quality, or mixed AOS, have been excluded. Given the implications for disease progression, it is important to understand these patients early in the disease course to inform appropriate education and prognostication. The aim of this study was to describe a cohort of ten patients with initially mixed PAOS and how their clinical course evolves. Four patients were rated prosodic predominant later on (mild AOS at first visit); five were later designated phonetic (four with more than mild AOS at first visit); one was judged mixed at all visits. The study suggests patients without a clear predominance of speech features should still be included in PAOS studies and thought of on the continuum of the disease spectrum.","2023-10","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","245","","","","","","","","","","English","","","","WOS:001061339700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","AGRAMMATIC APHASIA; Aphasia; Apraxia of speech; DEGENERATION; Degenerative; DIAGNOSIS; Dysarthria; EVOLUTION; MOTOR SPEECH; Neurologic disorders; NEUROPATHOLOGIC CRITERIA; RATING-SCALE; TOOL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GT5XXHDT","journalArticle","2023","Allison, K; Stoeckel, R; Olsen, E; Tallman, S; Iuzzini-Seigel, J","Motor Speech Phenotypes in Children With Epilepsy: Preliminary Findings","AMERICAN JOURNAL OF SPEECH-LANGUAGE PATHOLOGY","","1058-0360","10.1044/2022_AJSLP-22-00176","","Purpose: This exploratory study aimed to characterize motor speech impairments in a small sample of children with epilepsy, both with and without a known seizure etiology. A secondary aim was to evaluate the validity of the Profile for Childhood Apraxia of speech and Dysarthria (ProCAD), a newly developed tool for differential diagnosis of childhood apraxia of speech and dysarthria. Method: Thirteen children with seizure disorders completed a comprehensive speech and language assessment. Three expert speech-language pathologists rated the presence of auditory-perceptual features of motor speech impairment using the ProCAD. Motor speech features, diagnoses, and standardized test scores were compared between children with a known seizure etiology and children with idiopathic epilepsy. Results: Nine of the 13 children exhibited motor speech impairment; dysarthria was the most common diagnosis. Most children (11/13) exhibited language impairment. Group comparisons showed that children with a known seizure etiology had more atypical motor speech features and lower language scores than children with idiopathic seizures. Conclusion: These preliminary findings suggest a high rate of motor speech impairment among children with epilepsy.","2023-08","2025-02-26 20:37:03","2025-02-26 20:37:03","","1912-1922","","4","32","","","","","","","","","","English","","","","WOS:001057852400009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","AGE; CHILDHOOD APRAXIA; DISORDERS; LANGUAGE; PREVALENCE; SEIZURES; UNITED-STATES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"45JEIRRV","journalArticle","2022","Kanwal, S; Asghar, S; Ali, H","Feature selection enhancement and feature space visualization for speech-based emotion recognition","PEERJ COMPUTER SCIENCE","","2376-5992","10.7717/peerj-cs.1091","","Robust speech emotion recognition relies on the quality of the speech features. We present speech features enhancement strategy that improves speech emotion recognition. We used the INTERSPEECH 2010 challenge feature-set. We identified subsets from the features set and applied principle component analysis to the subsets. Finally, the features are fused horizontally. The resulting feature set is analyzed using t-distributed neighbour embeddings (t-SNE) before the application of features for emotion recognition. The method is compared with the state-of-the-art methods used in the literature. The empirical evidence is drawn using two well-known datasets: Berlin Emotional Speech Dataset (EMO-DB) and Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) for two languages, German and English, respectively. Our method achieved an average recognition gain of 11.5% for six out of seven emotions for the EMO-DB dataset, and 13.8% for seven out of eight emotions for the RAVDESS dataset as compared to the baseline study.","2022-11-04","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","8","","","","","","","","","","English","","","","WOS:000882607600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","CLASSIFICATION; Feature selection; Feature space visualization; Machine learning; Speaker-independent emotion recognition; Speech emotion recognition; SVM; t-SNE graphs; VOICE QUALITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N6EL7UL2","journalArticle","2021","Deng, N","English Semantic Recognition Based on an Intelligent Algorithm","INFORMATICA-AN INTERNATIONAL JOURNAL OF COMPUTING AND INFORMATICS","","0350-5596","10.31449/inf.v45i6.3728","","In the process of translation, semantic barriers have attracted extensive attention from researchers. Taking the translation between Chinese and English as an example, this paper used intelligent algorithms to recognize the semantic role of English, introduced the semantic role labeling, designed a semantic role encoder, integrated the encoder with the transformer model, and tested the translation performance of the system. The experimental results showed that the BLEU-4 score of the combined system was significantly higher than the baseline system and the traditional transformer system. The average BLEU-4 values of the three systems were 35.02, 35.78, and 36.9, respectively, and the score of the combined system was the highest. The specific analysis of several examples also found that the translation results of the combined system were more reliable. The experimental results verify the effectiveness of the combined system in machine translation and the importance of semantic recognition in translation.","2021-09","2025-02-26 20:37:03","2025-02-26 20:37:03","","115-118","","6","45","","","","","","","","","","English","","","","WOS:000740358800011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;17</p>","","","BLEU; English translation; intelligent algorithm; MACHINE TRANSLATION; semantic recognition; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CX2I8SP4","journalArticle","2024","McCall, S; Kolawole, SS; Naz, A; Gong, LY; Ahmed, SW; Prasad, PS; Yu, M; Wingate, J; Ardakani, SP","Computer Vision Based Transfer Learning-Aided Transformer Model for Fall Detection and Prediction","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3368065","","Falls bring about significant risks to individuals' well-being and independence, prompting widespread public health concerns. Swift detection and even predicting the risk of falls are crucial for implementing effective measures to alleviate the adverse consequences associated with such incidents. This study presents a new framework for identifying and forecasting fall risks. Our approach utilizes a novel transformer model trained on 2D poses extracted through an off-the-shelf pose extractor, incorporating transfer learning techniques. Initially, the transformer is trained on a large dataset containing 2D poses of general actions. Subsequently, we freeze the majority of its layers and fine-tune only the last few layers using relatively smaller datasets for fall detection and prediction tasks. Experimental results indicate that our proposed method outperforms traditional machine learning (e.g., SVM, Decision Tree, etc.) and deep learning approaches (e.g., LSTM, CNN, ST-GCN, PoseC3D, etc.) in both fall detection and prediction tasks across various datasets.","2024","2025-02-26 20:37:03","2025-02-26 20:37:03","","28798-28809","","","12","","","","","","","","","","English","","","","WOS:001173904300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Computer vision; deep learning; fall detection; fall prediction; healthcare; transfer learning; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HX8TVQ5C","journalArticle","2023","Humayun, MA; Yassin, H; Abas, PE","Estimating Social Background Profiling of Indian Speakers by Acoustic Speech Features","JOURNAL OF SCIENTIFIC & INDUSTRIAL RESEARCH","","0022-4456","10.56042/jsir.v82i08.3122","","Social background profiling of speakers refers to estimating the geographical origin of speakers by their speech features. Methods for accent profiling that use linguistic features, require phoneme alignment and transcription of the speech samples. This paper proposes a purely acoustic accent profiling model, composed of multiple convolutional networks with global average-pooling layers, to classify the temporal sequence of acoustic features. The bottleneck representations of the convolutional networks, trained with the original signals and their low-pass filtered copies, are fed to a Support Vector Machine classifier for final prediction. The model has been analysed for a speech dataset of Indian speakers from social backgrounds spread across India. It has been shown that up to 85% accuracy is achievable for classifying the geographic origin of speakers corresponding to regional Indian languages; 17% higher than the benchmark deep learning model using the same features. Results have also indicated that classification of accents is easier using the second language of the speakers, as compared to their native language.","2023-08","2025-02-26 20:37:03","2025-02-26 20:37:03","","851-860","","8","82","","","","","","","","","","English","","","","WOS:001049653500005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","Accent identification; ACCENT IDENTIFICATION; Ensemble learning; Low pass filtering; Native language identification; RECOGNITION; Speaker profiling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QFW3W78W","journalArticle","2024","Xiao, YT; Liu, ZY; Yin, HS; Wang, XG; Zhang, YD","STFormer: A dual-stage transformer model utilizing spatio-temporal graph embedding for multivariate time series forecasting","JOURNAL OF INTELLIGENT & FUZZY SYSTEMS","","1064-1246","10.3233/JIFS-237250","","Multivariate Time Series (MTS) forecasting has gained significant importance in diverse domains. Although Recurrent Neural Network (RNN)-based approaches have made notable advancements in MTS forecasting, they do not effectively tackle the challenges posed by noise and unordered data. Drawing inspiration from advancing the Transformer model, we introduce a transformer-based method called STFormer to address this predicament. The STFormer utilizes a two-stage Transformer to capture spatio-temporal relationships and tackle the issue of noise. Furthermore, the MTS incorporates adaptive spatio-temporal graph structures to tackle the issue of unordered data specifically. The Transformer incorporates graph embedding to combine spatial position information with long-term temporal connections. Experimental results based on typical finance and environment datasets demonstrate that STFormer surpasses alternative baseline forecasting models and achieves state-of-the-art results for single-step horizon and multistep horizon forecasting.","2024","2025-02-26 20:37:03","2025-02-26 20:37:03","","6951-6967","","3","46","","","","","","","","","","English","","","","WOS:001194580300092","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","ATTENTION; graph embedding; Multivariate time series forecasting; recurrent neural network; Spatio-temporal structure; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I498TVBI","journalArticle","2024","Fu, Y; Song, J; Guo, JR; Fu, YZ; Cai, Y","Prediction and analysis of sea surface temperature based on LSTM-transformer model","REGIONAL STUDIES IN MARINE SCIENCE","","2352-4855","10.1016/j.rsma.2024.103726","","This paper introduces a novel method for predicting sea surface temperature (SST) using a hybrid LSTMTransformer model. The study utilizes the ERA5 dataset for SST prediction at six specific locations near China. The LSTM-Transformer model combines the temporal processing capability of LSTM with the efficient data processing power of Transformer, showing superior performance in reducing Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE), as well as improving the R-squared (R2) 2 ) value, compared to standalone LSTM, Transformer, and traditional Logistic Regression (LR) models. This is particularly evident in spring and autumn, indicating its robustness to seasonal changes. The model's performance varies across different geographic locations, with lower prediction errors in low-latitude and open sea areas, attributed to the less complex environmental dynamics compared to continental shelf areas. Overall, the LSTM-Transformer hybrid model presents a significant advancement in SST prediction, providing important implications for fisheries, meteorology, and climate change research.","2024-12-15","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","78","","","","","","","","","","English","","","","WOS:001296970500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","FORECASTS; LSTM; LSTM-transformer; Neural networks; OCEAN; SST forecasting; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C83SJHM9","journalArticle","2024","Li, TT; Song, JB","Deep Learning-Powered Financial Product Recommendation System in Banks: Integration of Transformer and Transfer Learning","JOURNAL OF ORGANIZATIONAL AND END USER COMPUTING","","1546-2234","10.4018/JOEUC.343257","","With the rapid evolution of financial technology, the recommendation system for financial products, as a crucial technology to enhance user experience and reduce information search costs, is increasingly becoming the focus of the financial services sector. As market competition intensifies, the diversity of user demands, coupled with the continuous expansion of financial product types, has exposed limitations in traditional recommendation systems regarding accuracy and personalized services. Therefore, this study aims to explore the application of deep learning technology in the field of financial product recommendations, aiming to construct a more intelligent and precise financial product recommendation system. The metrics we focus on include precision, recall, and F1-score, comprehensively evaluating the effectiveness of the proposed methods. In terms of methodology, we first employ a Transformer model, leveraging its powerful self-attention mechanism to capture the complex relationships between user behavior sequences and financial product information.","2024","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","1","36","","","","","","","","","","English","","","","WOS:001293789600018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Banks; Financial Recommendation System; Graph Neural Networks; Intelligent Financial Technology Innovation; Transfer Learning; Transformer Model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C7TWI3RX","journalArticle","2023","Ilias, L; Askounis, D","Context-aware attention layers coupled with optimal transport domain adaptation and multimodal fusion methods for recognizing dementia from spontaneous speech","KNOWLEDGE-BASED SYSTEMS","","0950-7051","10.1016/j.knosys.2023.110834","","Alzheimer's disease (AD) constitutes a complex neurocognitive disease and is the main cause of dementia. Although many studies have been proposed targeting at diagnosing dementia through spontaneous speech, there are still limitations. Existing state-of-the-art approaches, which propose multimodal methods, train separately language and acoustic models, employ majority-vote approaches, and concatenate the representations of the different modalities either at the input level, i.e., early fusion, or during training. Also, some of them employ self-attention layers, which calculate the dependencies between representations without considering the contextual information. In addition, no prior work has taken into consideration the model calibration. To address these limitations, we propose some new methods for detecting AD patients, which capture the intra- and cross-modal interactions. First, we convert the audio files into log-Mel spectrograms, their delta, and delta-delta and create in this way an image per audio file consisting of three channels. Next, we pass each transcript and image through BERT and DeiT models respectively. After that, context-based self-attention layers, selfattention layers with a gate model, and optimal transport domain adaptation methods are employed for capturing the intra- and inter-modal interactions. Finally, we exploit two methods for fusing the self and cross-attention features. For taking into account the model calibration, we apply label smoothing. We use both performance and calibration metrics. Experiments conducted on the ADReSS and ADReSSo Challenge datasets indicate the efficacy of our introduced approaches over existing research initiatives with our best performing model reaching Accuracy and F1-score up to 91.25% and 91.06% respectively. & COPY; 2023 Elsevier B.V. All rights reserved.","2023-10-09","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","277","","","","","","","","","","English","","","","WOS:001052504400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;92</p>","","","BERT; Context-based self-attention; DeiT; Dementia; Label smoothing; Log -Mel spectrogram; Model calibration; Optimal transport; RECOGNITION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I79S77IU","journalArticle","2024","Martínez, V; Pérez, V; Antón, MA; Miranda, M; Vergara, P","Longitudinal profiles of late phonological development in children with Williams syndrome","FRONTIERS IN COMMUNICATION","","2297-900X","10.3389/fcomm.2024.1386899","","Williams syndrome (WS) is a genetic neurodevelopmental disorder characterized by language skills above what is expected considering non-verbal intelligence. Research on phonological development is scarce, with many studies focusing on grammar in children and adolescents. In one of our previous studies transversally explored the profiles of late phonological development in Spanish-speaking WS children, adolescents, and adults, while our objective is to longitudinally determine these profiles for WS children based on present error indexes in spontaneous speech. Participants were seven WS children (aged 3;7-8;2), engaging in two spontaneous conversations within a 6-month interval. They were compared cross-sectionally with 240 typically developing (TD) children aged 3-6 years, divided into six groups. All speech samples were transcribed and analyzed with the CLAN software package of the CHILDES Project. Phonological profiles were established on the basis of phonological error indexes obtained dividing absolute frequency of errors by the total number of words produced. WS children showed a mean reduction of more than 25% in the absolute frequency of phonological errors after 6 months. As for the comparison with the normative groups, their error index was consistent with the stage of expansion in TD, however, after 6 months, this was consistent with the stage of stabilization. This atypical acceleration in phonological development could be related to lexical growth in the context of relative preservation of phonological memory. Furthermore, the trajectories of late phonological development in WS children might not be linear, as postulated by neuroconstructivist models, suggesting the need for intervention approaches specifically adapted to the phonological profiles of WS children.","2024-04-16","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","9","","","","","","","","","","English","","","","WOS:001214440100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","ABILITIES; ATTENTION; atypical language development; DISSOCIATIONS; LANGUAGE-ACQUISITION; MORPHOLOGY; neurodevelopmental disorder; phonological profiles; spontaneous speech; STRENGTHS; TODDLERS; Williams syndrome","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YNGGRT8S","journalArticle","2024","Wang, J; Wen, LH; Xiao, L; Wang, CJ","Time-series forecasting of mortality rates using transformer","SCANDINAVIAN ACTUARIAL JOURNAL","","0346-1238","10.1080/03461238.2023.2218859","","Predicting mortality rates is a crucial issue in life insurance pricing and demographic statistics. Traditional approaches, such as the Lee-Carter model and its variants, predict the trends of mortality rates using factor models, which explain the variations of mortality rates from the perspective of ages, gender, regions, and other factors. Recently, deep learning techniques have achieved great success in various tasks and shown strong potential for time-series forecasting. In this paper, we propose a modified Transformer architecture for predicting mortality rates in major countries around the world. Through the multi-head attention mechanism and positional encoding, the proposed Transformer model extracts key features effectively and thus achieves better performance in time-series forecasting. By using empirical data from the Human Mortality Database, we demonstrate that our Transformer model has higher prediction accuracy of mortality rates than the Lee-Carter model and other classic neural networks. Our model provides a powerful forecasting tool for insurance companies and policy makers.","2024-02-07","2025-02-26 20:37:03","2025-02-26 20:37:03","","109-123","","2","2024","","","","","","","","","","English","","","","WOS:000998394400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","deep learning; LEE-CARTER; Mortality rates; NEURAL-NETWORKS; STOCHASTIC MORTALITY; time series forecasting; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZM8DGBYX","journalArticle","2023","Vogel, G; Balhorn, LS; Schweidtmann, AM","Learning from flowsheets: A generative transformer model for autocompletion of flowsheets","COMPUTERS & CHEMICAL ENGINEERING","","0098-1354","10.1016/j.compchemeng.2023.108162","","We propose a novel method enabling autocompletion of chemical flowsheets. This idea is inspired by the autocompletion of text. We represent flowsheets as strings using the text-based SFILES 2.0 notation and learn the grammatical structure of the SFILES 2.0 language and common patterns in flowsheets using a transformer -based language model. We pre-train our model on synthetically generated flowsheet topologies to learn the flowsheet language grammar. Then, we fine-tune our model in a transfer learning step on real flowsheet topologies. Finally, we use the trained model for causal language modeling to autocomplete flowsheets. Eventually, the proposed method can provide chemical engineers with recommendations during interactive flowsheet synthesis. The results demonstrate a high potential of this approach for future AI-assisted process synthesis but also reveal the limitations at the present state and the next steps that need to be taken to deploy this technique in realistic flowsheet synthesis scenarios.","2023-03","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","171","","","","","","","","","","English","","","","WOS:000930932000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;23<br/>Total Times Cited:&nbsp;&nbsp;23<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","0; Flowsheet completion; Flowsheet synthesis; Generative transformer model; Natural language processing; SFILES 2","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4H94IF78","journalArticle","2021","Broome, K; McCabe, P; Docking, K; Doble, M; Carrigg, B","Speech Abilities in a Heterogeneous Group of Children With Autism","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2021_JSLHR-20-00651","","Purpose: This study aimed to provide detailed descriptive information about the speech of a heterogeneous cohort of children with autism spectrum disorder (ASD) and to explore whether subgroups exist based on this detailed speech data. High rates of delayed and disordered speech in both low-verbal and high-functioning children with ASD have been reported. There is limited information regarding the speech abilities of young children across a range of functional levels. Method: Participants were 23 children aged 2;0-6;11 (years;months) with a diagnosis of ASD. Comprehensive speech and language assessments were administered. Independent and relational speech analyses were conducted from single-word naming tasks and spontaneous speech samples. Hierarchical clustering based on language, nonverbal communication, and spontaneous speech descriptive data was completed. Results: Independent and relational speech analyses are reported. These variables are used in the cluster analyses, which identified three distinct subgroups: (a) children with high language and high speech ability (n = 10), (b) children with low expressive language and low speech ability but higher receptive language and use of gestures (n = 3), and (c) children with low language and low speech development (n = 10). Conclusions: This is the first study to provide detailed descriptive speech data of a heterogeneous cohort of children with ASD and use this information to statistically explore potential subgroups. Clustering suggests a small number of children present with low levels of speech and expressive language in the presence of better receptive language and gestures. This communication profile warrants further exploration. Replicating these findings with a larger cohort of children is needed. Supplemental Material: https://doi.org/10.23641/asha.16906978","2021-12","2025-02-26 20:37:03","2025-02-26 20:37:03","","4599-4613","","12","64","","","","","","","","","","English","","","","WOS:000756142500004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","ADOLESCENTS; COMMUNICATIVE DEVELOPMENT; CONSONANT PRODUCTION; HIGH-FUNCTIONING AUTISM; INFANTS; LANGUAGE IMPAIRMENT; PREDICTORS; PRESCHOOL-CHILDREN; SPECTRUM DISORDER; TODDLERS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LAL2ICRM","journalArticle","2024","Zhou, Q; Wang, ZP","A Network Intrusion Detection Method for Information Systems Using Federated Learning and Improved Transformer","INTERNATIONAL JOURNAL ON SEMANTIC WEB AND INFORMATION SYSTEMS","","1552-6283","10.4018/IJSWIS.334845","","A network intrusion detection method for information systems using federated learning and improved transformer is proposed to address the problems of long detection time and low security and accuracy when analyzing massive data in most existing intrusion detection methods. Firstly, a network intrusion detection system is constructed based on a federated learning framework, and the transformer model is used as its universal detection model. Then, the dataset is divided and an improved generative adversarial network is used for data augmentation to generate a new sample set to overcome the influence of minority class samples. At the same time, the new samples are input into the transformer local model for network attack type detection and analysis. Finally, the authors aggregate the detection results of each local model and input them into the Softmax classifier to obtain the final classification prediction results.","2024","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","1","20","","","","","","","","","","English","","","","WOS:001163267100004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Deep Learning; Federated Learning; Improve the Generation of Adversarial Networks; Network Intrusion Detection; Softmax Classifier; Transformer Model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R62FYC9E","journalArticle","2025","Abdoune, R; Lazib, L; Dahmani-Bouarab, F; Mimouni, N","Semantic alignment in disciplinary tutoring system: leveraging sentence transformer technology","INTELIGENCIA ARTIFICIAL-IBEROAMERICAN JOURNAL OF ARTIFICIAL INTELLIGENCE","","1137-3601","10.4114/intartif.vol28iss75pp46-62","","In this work, we present a disciplinary e-tutoring system that integrates ONTO-TDM, an ontology designed for teaching domain modeling, with advanced transformer technology. Our primary objective is to enhance semantic similarity tasks within the system by fine-tuning a Sentence Transformer model. By carefully adjusting training parameters with a curated dataset of question-answer pairs focused on algorithms and data structures, we achieved a notable improvement in system performance. The Sentence Transformer model, combined with domain ontology, achieved an accuracy of 91%, a precision of 93%, a recall of 89%, and an F1- score of 90%, significantly surpassing the results of existing works. This methodology highlights the potential to deliver personalized support and guidance in tutoring scenarios. It effectively addresses the evolving needs of modern education by offering tailored answers and reducing the necessity for constant learner-tutor interaction, thereby improving the efficiency of educational support systems.","2025-06","2025-02-26 20:37:03","2025-02-26 20:37:03","","46-62","","75","28","","","","","","","","","","English","","","","WOS:001344084200004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Disciplinary e-tutoring system; domain ontology; education; question-answering system; sentence transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CPI6GYKR","journalArticle","2024","Luptáková, ID; Kubovcík, M; Pospíchal, J","Playing Flappy Bird Based on Motion Recognition Using a Transformer Model and LIDAR Sensor","SENSORS","","1424-8220","10.3390/s24061905","","A transformer neural network is employed in the present study to predict Q-values in a simulated environment using reinforcement learning techniques. The goal is to teach an agent to navigate and excel in the Flappy Bird game, which became a popular model for control in machine learning approaches. Unlike most top existing approaches that use the game's rendered image as input, our main contribution lies in using sensory input from LIDAR, which is represented by the ray casting method. Specifically, we focus on understanding the temporal context of measurements from a ray casting perspective and optimizing potentially risky behavior by considering the degree of the approach to objects identified as obstacles. The agent learned to use the measurements from ray casting to avoid collisions with obstacles. Our model substantially outperforms related approaches. Going forward, we aim to apply this approach in real-world scenarios.","2024-03","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","6","24","","","","","","","","","","English","","","","WOS:001193064100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","agent control; CLASSIFICATION; Flappy Bird game; motion sensors; ray casting; reinforcement learning; robotics; signal processing; time series processing; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y3VME9PD","journalArticle","2023","Cao, KY; Wang, MR","Human behavior recognition based on sparse transformer with channel attention mechanism","FRONTIERS IN PHYSIOLOGY","","1664-042X","10.3389/fphys.2023.1239453","","Human activity recognition (HAR) has recently become a popular research field in the wearable sensor technology scene. By analyzing the human behavior data, some disease risks or potential health issues can be detected, and patients' rehabilitation progress can be evaluated. With the excellent performance of Transformer in natural language processing and visual tasks, researchers have begun to focus on its application in time series. The Transformer model models long-term dependencies between sequences through self-attention mechanisms, capturing contextual information over extended periods. In this paper, we propose a hybrid model based on the channel attention mechanism and Transformer model to improve the feature representation ability of sensor-based HAR tasks. Extensive experiments were conducted on three public HAR datasets, and the results show that our network achieved accuracies of 98.10%, 97.21%, and 98.82% on the HARTH, PAMAP2, and UCI-HAR datasets, respectively, The overall performance is at the level of the most advanced methods.","2023-11-02","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","14","","","","","","","","","","English","","","","WOS:001102493000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","attention; human activity recognition; sparse transformer; time series; wearable biosensors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XSJ5XTFP","journalArticle","2021","Mishra, SK; Dhir, R; Saha, S; Bhattacharyya, P; Singh, AK","Image captioning in Hindi language using transformer networks","COMPUTERS & ELECTRICAL ENGINEERING","","0045-7906","10.1016/j.compeleceng.2021.107114","","Neural encoder-decoder architectures have been used extensively for image captioning. Con-volutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) are popularly used in encoder and decoder models. Recurrent Neural Networks are popular architectures in natural language processing used for language modeling, but they are sequential in nature. The transformer model can solve this problem of sequential dependency by using an attention mechanism. Many works are available for image captioning in the English language, but models for generating Hindi captions are limited; hence, we have tried to fill this gap. We have created the Hindi dataset for image captioning by manually translating the popular MSCOCO dataset from English to Hindi. Experimental results show that our proposed model outperforms other models. The proposed model has attained the BLEU-1 score of 62.9, BLEU-2 score of 43.3, BLEU-3 score of 29.1, and BLEU4 score of 19.0.","2021-06","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","92","","","","","","","","","","English","","","","WOS:000663707800014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","Deep learning; Encoder-decoder; Hindi language; Image captioning; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GCW97KLQ","journalArticle","2021","Pytel, V; Cabrera-Martín, MN; Delgado-Alvarez, A; Ayala, JL; Balugo, P; Delgado-Alonso, C; Yus, M; Carreras, MT; Carreras, JL; Matías-Guiu, J; Matías-Guiu, JA","Personalized Repetitive Transcranial Magnetic Stimulation for Primary Progressive Aphasia","JOURNAL OF ALZHEIMERS DISEASE","","1387-2877","10.3233/JAD-210566","","Background: Primary progressive aphasia (PPA) is a neurodegenerative syndrome for which no effective treatment is available. Objective: We aimed to assess the effect of repetitive transcranial magnetic stimulation (rTMS), using personalized targeting. Methods: We conducted a randomized, double-blind, pilot study of patients with PPA receiving rTMS, with a subgroup of patients receiving active-versus control-site rTMS in a cross-over design. Target for active TMS varied among the cases and was determined during a pre-treatment phase from a list of potential regions. The primary outcome was changes in spontaneous speech (word count). Secondary outcomes included changes in other language tasks, global cognition, global impression of change, neuropsychiatric symptoms, and brain metabolism using FDG-PET. Results: Twenty patients with PPA were enrolled (14 with nonfluent and 6 with semantic variant PPA). For statistical analyses, data for the two variants were combined. Compared to the control group (n = 7), the group receiving active-site rTMS (n = 20) showed improvements in spontaneous speech, other language tasks, patient and caregiver global impression of change, apathy, and depression. This group also showed improvement or stabilization of results obtained in the baseline examination. Increased metabolism was observed in several brain regions after the therapy, particularly in the left frontal and parieto-temporal lobes and in the precuneus and posterior cingulate bilaterally. Conclusion: We found an improvement in language, patient and caregiver perception of change, apathy, and depression using high frequency rTMS. The increase of regional brain metabolism suggests enhancement of synaptic activity with the treatment.","2021","2025-02-26 20:37:03","2025-02-26 20:37:03","","151-167","","1","84","","","","","","","","","","English","","","","WOS:000722639900013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;22<br/>Total Times Cited:&nbsp;&nbsp;24<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","ADDENBROOKES COGNITIVE EXAMINATION; Apraxia of speech; brain stimulation; CLASSIFICATION; DEMENTIA; frontotemporal dementia; IMPAIRMENT; LANGUAGE; NAMING ABILITIES; neuromodulation; OPERCULARIS; primary progressive aphasia; RIGHT PARS TRIANGULARIS; TMS; transcranial magnetic stimulation; VARIANT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A3UU4IED","journalArticle","2023","Jiang, Y; Chun, D","Web-based intonation training helps improve ESL and EFL Chinese students' oral speech","COMPUTER ASSISTED LANGUAGE LEARNING","","0958-8221","10.1080/09588221.2021.1931342","","This paper examines whether a web-based training on English discourse intonation leads to better spontaneous speech quality for Mandarin Chinese speakers who reside in the U.S. and in China. The four-week fully online training consisted of meta-instruction videos as well as listening and speaking activities, including instant visual pitch contour feedback and individualized evaluation. The students gave a one-minute spontaneous speech on a given topic at the beginning and the end of the study via videoconferencing. Four native English speakers judged the students' speech comprehensibility, fluidity, accent, confidence and attractiveness, in addition to their intonation performance. Two-way ANCOVA test results show that the experimental group made statistically significant improvement in their speech comprehensibility and speaking confidence. In contrast, the control group did not show improvement. The participants' residence in the U.S. or in China did not affect the training effects. There was not an interaction between the participants' residence and the training. The web-based training, visualization and CMC technology provided an effective scaffolding experience and benefited both EFL and ESL students equally. This study also explores Chinese students' challenges with specific intonation features based on both the raters' judgments and the learners' self-evaluations. The results suggest they have more difficulties with thought groups and prominence than with tone choices. While the trainees gave high ratings to all the activities, they preferred individualized evaluation from the researcher to self-created visual feedback using Praat. The findings have implications for Chinese L1-specific intonation instruction and developing web-based computer assisted pronunciation training systems.","2023-03-04","2025-02-26 20:37:03","2025-02-26 20:37:03","","457-485","","3","36","","","","","","","","","","English","","","","WOS:000664908500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","COMMUNICATION; Computer assisted pronunciation training; discourse intonation; feedback; INSTRUCTION; L2 environment; oral presentation; PRESENTATIONS; PROFICIENCY; PRONUNCIATION; web-based training","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XCYAR3TI","journalArticle","2024","Zhao, HC; Wang, ZC; Wang, GC; Yu, F","Dynamic chaos unveiled: enhancing ship's attitude time series prediction through spatiotemporal embedding and improved transformer model","MEASUREMENT SCIENCE AND TECHNOLOGY","","0957-0233","10.1088/1361-6501/ad6687","","During ship operations at sea, the vessel's attitude undergoes continuous changes due to various factors such as wind, waves, and its own motion. These influences are challenging to mathematically describe, and the changes in attitude are also influenced by multiple interconnected factors. Consequently, accurately predicting the ship's attitude presents significant challenges. Previous studies have demonstrated that phenomena like wind speed and wave patterns exhibit chaotic characteristics when affecting attitude changes. However, research on predicting ship attitudes lacks an exploration of whether chaotic characteristics exist and how they can be described and applied. This paper initially identifies the chaotic characteristics of ship attitude data through phase space reconstruction analysis and provides mathematical representations for them. Based on these identified chaotic characteristics, a Transformer model incorporating feature embedding layers is employed for time series prediction. Finally, a comparison with traditional methods validates the superiority of our proposed approach.","2024-11-01","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","11","35","","","","","","","","","","English","","","","WOS:001287503300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","CNN-transformer; MOTION; phase space reconstruction; ship motion attitude; time series forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CBHPF7YE","journalArticle","2024","Xiao, JL; Long, BC","A multi-channel spatial-temporal transformer model for traffic flow forecasting","INFORMATION SCIENCES","","0020-0255","10.1016/j.ins.2024.120648","","Traffic flow forecasting is a crucial task in transportation management and planning. The main challenges for traffic flow forecasting are that (1) as the length of prediction time increases, the accuracy of prediction will decrease; (2) the predicted results greatly rely on the extraction of temporal and spatial dependencies from the road networks. To overcome the challenges mentioned above, we propose a multi -channel spatial -temporal transformer model for traffic flow forecasting, which improves the accuracy of the prediction by fusing results from different channels of traffic data. Our approach leverages graph convolutional network to extract spatial features from each channel while using a transformer -based architecture to capture temporal dependencies across channels. We introduce an adaptive adjacency matrix to overcome limitations in feature extraction from fixed topological structures. Experimental results on six realworld datasets demonstrate that introducing a multi -channel mechanism into the temporal model enhances performance and our proposed model outperforms state-of-the-art models in terms of accuracy.","2024-06","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","671","","","","","","","","","","English","","","","WOS:001236807200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Graph convolutional network; Multi-channel; Traffic flow forecasting; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ULRVTDC9","journalArticle","2024","Jin, J; Zhang, YQ","Innovation in Financial Enterprise Risk Prediction Model: A Hybrid Deep Learning Technique Based on CNN-Transformer-WT","JOURNAL OF ORGANIZATIONAL AND END USER COMPUTING","","1546-2234","10.4018/JOEUC.361650","","In the context of predicting financial risks for enterprises, traditional methods are inadequate in capturing complex multidimensional data features, resulting in suboptimal prediction performance. Although existing deep learning techniques have shown some improvements, they still face challenges in processing time series data and detecting extended dependencies. To address these issues, this paper proposes an integrated deep learning framework utilizing Convolutional Neural Network (CNN), Transformer model, and Wavelet Transform (WT). The proposed model leverages CNN to derive local features from the data, employs the Transformer to capture long-term dependencies, and uses WT for multiscale analysis, thereby enhancing the accuracy and stability of predictions. Experimental results demonstrate that the CNN-Transformer-WT model performs excellently across various datasets, including Kaggle Dataset (Credit Card Fraud Detection Dataset), Bank Marketing Dataset, and Yahoo Finance Historical Stock Market Dataset.","2024","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","1","36","","","","","","","","","","English","","","","WOS:001389043400003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Convolutional Neural Network (CNN); Deep Learning; Financial Data Analysis; Financial Risk Prediction; Transformer Model; Wavelet Transform (WT)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QMFNIAGB","journalArticle","2023","Winter, P; Rabe, M; Bornman, J; de Wet, P; Graham, MA; van der Linde, J","Code-switching patterns in naturalspoken language in agroup ofyoungAfrikaans-speaking children: An exploratory study","TYDSKRIF VIR GEESTESWETENSKAPPE","","0041-4751","10.17159/2224-7912/2023/v63n1a3","","Code-switching is a complex skill that refers to the use of two or more languages by a speaker during one utterance or conversation (Gort, 2012:46; Van Dulm, 2007:1; Myers-Scotton, 2009:239). In South Africa, with its 11 offzcial languages, children are exposed to more than one language, and subsequently, code-switching is ubiquitous (Van Dulm, 2007). Code-switching was recently identifzed in the spontaneous language samples of young Afrikaans-speaking children (Liebenberg, 2021:74). Similar fzndings were described in Nel (2012:193), who recommended that future research should investigate code-switching occurrences in spontaneous speech. The current study, therefore, aimed to fzll this gap by describing the nature and extent of code-switching in the spontaneous speech of neurotypical Afrikaans-speaking children. The common phenomenon of code-switching is further relevant to speech-language therapists. Recent literature states that this phenomenon is often observed during children's speech and language assessments and it is noted in the speech and language samples of both children with and without language disorders, similar to the code-switching seen in spontaneous speech (Kapantzoglou, 2021:1605). This study confzrmed that code-switching was previously described as a function of language and that a relationship exists between code-switching and language functioning. Since speech-language therapists assess language and language functioning, the influences of code-switching are important to understand and consider as it may influence decision making in therapeutic contexts. The current paper focuses on children who are raised in Afrikaans and whose language of learning and teaching is also Afrikaans, but who use English code-switching in their utterances. Due to the paucity of research regarding this phenomenon, a descriptive, quantitative, cross-sectional research design was employed to analyse and describe in depth the spontaneous speech of 30 young Afrikaans-speaking children between the ages 3;6 (year; months) and 9;6. An equivalent number of boys and girls were included as participants and they had to match the following criteria (1) have Afrikaans as their fzrst language, (2) be typically developing), (3) come from a middle-class socio-economic status (therefore, the family should fall within the tax-paying bracket), (4) live in the broader Tshwane-area (to ensure no dialect differences amongst participants), and (5) have normal hearing status. Code-switching occurred in the spontaneous language of the monolingual Afrikaans-speaking children who were observed in the current study. The data also showed that these children primarily inserted English nouns in the matrix language utterances (in this case, Afrikaans) by means of intrasentential code-switching. Ninety percent of the code-switching in the dataset were examples of intrasentential code-switching. Across all the age groups, the percentage of English words that were used (in terms of the number of different words) was less than 10% overall. No signifzcant tendencies were noted between the fzve different age cohorts and genders. A relationship was, however, noted between higher language scores in terms of morphology and lower numbers of code-switching. Code-switching is a common phenomenon in the spontaneous, spoken language of young Afrikaans-speaking children. Although Afrikaans was the participants'home language, as well as their language of learning and teaching, they often used English code-switching in utterances. The Afrikaans-speaking children's use of code-switching may indicate second language acquisition of English or that they have already acquired English as a second language. The current study makes an important contribution to the existing literature as these results may prompt that more specifzc boundaries for the defznitions of monolingual and multilingual individuals should be described to classify","2023-03","2025-02-26 20:37:03","2025-02-26 20:37:03","","45-64","","1","63","","","","","","","","","","English","","","","WOS:001016573600003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Afrikaans; code-switching; English; intrasentential; matrix language; mean length of utterance; monolingual; South Africa; spoken language; spontaneous language","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T6YAWM5R","journalArticle","2024","Baqué, L; Machuca, MJ","Dysfluency in primary progressive aphasia: Temporal speech parameters","CLINICAL LINGUISTICS & PHONETICS","","0269-9206","10.1080/02699206.2024.2378345","","Analysing spontaneous speech in individuals experiencing fluency difficulties holds potential for diagnosing speech and language disorders, including Primary Progressive Aphasia (PPA). Dysfluency in the spontaneous speech of patients with PPA has mostly been described in terms of abnormal pausing behaviour, but the temporal features related to speech have drawn little attention. This study compares speech-related fluency parameters in the three main variants of PPA and in typical speech. Forty-three adults participated in this research, thirteen with the logopenic variant of PPA (lvPPA), ten with the non-fluent variant (nfvPPA), nine with the semantic variant (svPPA), and eleven who were healthy age-matched adults. Participants' fluency was assessed through a picture description task from which 42 parameters were computed including syllable duration, speaking pace, the duration of speech chunks (i.e. interpausal units, IPU), and the number of linguistic units per IPU and per second. The results showed that each PPA variant exhibited abnormal speech characteristics reflecting various underlying factors, from motor speech deficits to higher-level issues. Out of the 42 parameters considered, 37 proved useful for characterising dysfluency in the three main PPA variants and 35 in distinguishing among them. Therefore, taking into account not only pausing behaviour but also temporal speech parameters can provide a fuller understanding of dysfluency in PPA. However, no single parameter by itself sufficed to distinguish one PPA group from the other two, further evidence that dysfluency is not dichotomous but rather multidimensional, and that complementary multiparametric analyses are needed.","2024-08-07","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","","","","","","","","","","","English","","","","WOS:001284958400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;142</p>","","","ALZHEIMERS; APRAXIA; ARTICULATION RATE; CONNECTED SPEECH; DISEASE; fluency; FLUENCY; FRONTOTEMPORAL DEMENTIA; LANGUAGE; MOTOR SPEECH; Primary progressive aphasia; SEMANTIC VARIANT; speech; speech chunks; temporal parameters","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PBQVX322","journalArticle","2023","Zhu, CH; Ye, X; Lu, QD","Input enhanced asymmetric transformer for image captioning","SIGNAL IMAGE AND VIDEO PROCESSING","","1863-1703","10.1007/s11760-022-02350-9","","Image caption is a popular research direction in computer vision. It is a task that enables machines to convey the computer's perception and cognition of vision to the outside world in the form of human language. Currently, the most dominant models are Transformer-based architectures which achieve the cutting-edge performance. Inspired by the distinguished meshed-memory transformer model which uses a mesh-like connectivity at decoding stage. It let us see more possibilities in the Transformer model. With the aim to explore more possible connectivity schemas in Transformer, we propose the input enhanced asymmetric transformer (IEAT) model. It improves the connectivity between encoder layers and optimizes the generation effect of the captions. To better evaluate the final effect of our model, we conducted extensive experiments (offline evaluation, online evaluation and ablation study) on the MS-COCO benchmark and the ""Karpathy"" test split. And the results show that IEAT outperforms the previously proposed models to generate satisfactory image captions.","2023-06","2025-02-26 20:37:03","2025-02-26 20:37:03","","1419-1427","","4","17","","","","","","","","","","English","","","","WOS:000855990800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Adaptive sparse attention; Image caption; Language pretraining; Vision","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PBINCJ3C","journalArticle","2024","Ren, YZ; Wang, YH; Liu, CC","Low-Frequency Electromagnetic Transient Modeling of Shell-Type Transformers Based on Dynamic Jiles-Atherton Hysteresis Model","IEEE TRANSACTIONS ON MAGNETICS","","0018-9464","10.1109/TMAG.2024.3417021","","Transformers often encounter electromagnetic transients, such as ferromagnetic resonance and inrush currents. An accurate low-frequency modeling of transformers is essential for analyzing power system faults. However, the lack of accurate magnetic characteristic modeling in most commercial software results in the electromagnetic transient calculations of the shell-type transformer remaining challenging. In this article, a low-frequency shell-type transformer model for analyzing electromagnetic transients is proposed. By combining the static Jiles-Atherton (J-A) hysteresis model with loss separation theory, a modified dynamic J-A hysteresis model is established. The nonlinear excitation inductance module considering loss and hysteresis characteristics is developed. An improved topology-based shell-type transformer model is established based on the duality principle. The inrush current test results of shell-type transformers verified the accuracy of the proposed model.","2024-09","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","9","60","","","","","","","","","","English","","","","WOS:001302532700027","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;15</p>","","","Inductance; Inrush current; Jiles-Atherton (J-A) hysteresis model; Loss measurement; low-frequency electromagnetic transients; Magnetic hysteresis; Magnetization; Mathematical models; Power transformer insulation; shell-type transformers; Transformer cores","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SV8HZ8TB","journalArticle","2024","Wang, W; Zhou, L; Ye, K; Sun, HX; Hong, SH","A DOA Estimation Method Based on an Improved Transformer Model for Uniform Linear Arrays with Low SNR","IET SIGNAL PROCESSING","","1751-9675","10.1049/2024/6666395","","In this paper, the Star-Transformer model is improved to obtain more accurate direction of arrivals (DOA) estimation of underwater sonar uniform linear array (ULA) under low signal-to-noise ratio (SNR) conditions. The ideal real covariance matrix is divided into three channels: real part channel, imaginary part channel, and phase channel to obtain more input features. In training, the real covariance matrix is used under different SNRs. In testing, the covariance matrix of samples in the real environment is used as input. The on-grid form is used to estimate the DOA of multiple signal sources, which is modelled as a multilabel classification problem. The results show that the model can be effective and can still have a good DOA estimation performance under the conditions of trained and untrained SNRs, different snapshots, signal power mismatch, different separation angles, signal correlation, and so on. It shows that the model has excellent robustness.","2024-02-17","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","2024","","","","","","","","","","English","","","","WOS:001168746000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","ESPRIT; LOCATION; MUSIC; NETWORKS; OF-ARRIVAL ESTIMATION; PERFORMANCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X76ESEZZ","journalArticle","2022","Gordon, JK; Clough, S","How Do Clinicians Judge Fluency in Aphasia?","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2021_JSLHR-21-00484","","Purpose: Aphasia fluency is multiply determined by underlying impairments in lexical retrieval, grammatical formulation, and speech production. This poses challenges for establishing a reliable and feasible tool to measure fluency in the clinic. We examine the reliability and validity of perceptual ratings and clinical perspectives on the utility and relevance of methods used to assess fluency. Method: In an online survey, 112 speech-language pathologists rated spontaneous speech samples from 181 people with aphasia (PwA) on eight perceptual rating scales (overall fluency, speech rate, pausing, effort, melody, phrase length, grammaticality, and lexical retrieval) and answered questions about their current practices for assessing fluency in the clinic. Results: Interrater reliability for the eight perceptual rating scales ranged from fair to good. The most reliable scales were speech rate, pausing, and phrase length. Similarly, clinicians' perceived fluency ratings were most strongly correlated to objective measures of speech rate and utterance length but were also related to grammatical complexity, lexical diversity, and phonological errors. Clinicians' ratings reflected expected aphasia subtype patterns: Individuals with Broca's and transcortical motor aphasia were rated below average on fluency, whereas those with anomic, conduction, and Wernicke's aphasia were rated above average. Most respondents reported using multiple methods in the clinic to measure fluency but relying most frequently on subjective judgments. Conclusions: This study lends support for the use of perceptual rating scales as valid assessments of speech-language production but highlights the need for a more reliable method for clinical use. We describe next steps for developing such a tool that is clinically feasible and helps to identify the underlying deficits disrupting fluency to inform treatment targets.","2022-04","2025-02-26 20:37:03","2025-02-26 20:37:03","","1521-1542","","4","65","","","","","","","","","","English","","","","WOS:000830953900019","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","BRAIN-INJURY; DISCOURSE; GESTURE PRODUCTION; LANGUAGE; PEOPLE; SPONTANEOUS SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LPA8HAPA","journalArticle","2022","DiCanio, C; Chen, WR; Benn, J; Amith, JD; García, RC","Extreme stop allophony in Mixtec spontaneous speech: Data, word prosody, and modelling","JOURNAL OF PHONETICS","","0095-4470","10.1016/j.wocn.2022.101147","","Word-level prosody plays an important role in processes of consonant lenition. Typically, consonants in word-initial position are strengthened while those in word-medial position are lenited (Keating, Cho, Fougeron, & Hsu, 2003). In this paper we examine the relationship between word-prosodic position and obstruent lenition in a spontaneous speech corpus of Yoloxochitl Mixtec, an endangered Mixtecan language spoken in Mexico. The language exhibits a surprising amount of lenition in the realization of otherwise voiceless unaspirated stops and voiceless fricatives in careful speech. In Experiment 1, we examine the relationships between word position, consonant duration, and passive voicing and find that word-medial pre-tonic position is the locus of both consonant lengthening and less passive voicing. Non-pre-tonic consonants are produced with more voicing and shorter duration. We also find that the functional status of the morpheme plays a role in voicing lenition. In Experiment 2, we examine manner lenition and find a similar pattern - word-medial pre-tonic stops are more often realized with complete closure relative to non-pre-tonic stops, which are more often realized with incomplete closure. In Experiment 3, we model these lenition patterns using a series of deep neural networks and find that, even with limited training data, we can achieve reasonably high accuracy in the automatic categorization of lenition patterns. The results of this research both complement recent work on the phonetics of lenition in the world's languages (Katz and Fricke, 2018; White et al., 2020) and provide computational tools for modeling and predicting patterns of extreme lenition. CO 2022 Elsevier Ltd. All rights reserved.","2022-05","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","92","","","","","","","","","","English","","","","WOS:000807951900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;94</p>","","","Corpus phonetics; CROSS-LANGUAGE; DURATION; Endangered languages; ENGLISH; FEATURES; FREQUENCY; LENITION; Mixtecan; PERCEPTION; PHONETICS; Prosody; R PACKAGE; Speech reduction; VARIABILITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J6Y6IPPH","journalArticle","2024","Sheng, CC; Kuang, GY; Bai, L; Hou, CP; Guo, YL; Xu, X; Pietikäinen, M; Liu, L","Deep Learning for Visual Speech Analysis: A Survey","IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE","","0162-8828","10.1109/TPAMI.2024.3376710","","Visual speech, referring to the visual domain of speech, has attracted increasing attention due to its wide applications, such as public security, medical treatment, military defense, and film entertainment. As a powerful AI strategy, deep learning techniques have extensively promoted the development of visual speech learning. Over the past five years, numerous deep learning based methods have been proposed to address various problems in this area, especially automatic visual speech recognition and generation. To push forward future research on visual speech, this paper will present a comprehensive review of recent progress in deep learning methods on visual speech analysis. We cover different aspects of visual speech, including fundamental problems, challenges, benchmark datasets, a taxonomy of existing methods, and state-of-the-art performance. Besides, we also identify gaps in current research and discuss inspiring future research directions.","2024-09","2025-02-26 20:37:03","2025-02-26 20:37:03","","6001-6022","","9","46","","","","","","","","","","English","","","","WOS:001290498900023","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;196</p>","","","ACCURATE; ALIGNMENT; computer graphics; computer vision; Deep learning; Feature extraction; lip reading; Lips; NETWORK; RECOGNITION; Speech analysis; speech perception; Surveys; Task analysis; VIDEO; visual speech; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S6WA4ZVU","journalArticle","2024","Kim, H; Choi, H","The Relationship of Word-Finding Behaviors and Naming in Mild Cognitive Impairment and Dementia of Alzheimer's Type","COMMUNICATION SCIENCES AND DISORDERS-CSD","","2288-1328","10.12963/csd.240047","","Objectives: Anomia, a fundamental language difficulty, presents in various forms of wordfinding behaviors in individuals with Mild Cognitive Impairment (MCI) and Dementia of Alzheimer's Type (DAT). This study aims to compare the rates of word-finding behavior among these groups and determine the correlation between these rates and the results of naming tests. Methods: This study included 101 participants, consisting of forty-one healthy elderly adults, thirty individuals with MCI, and thirty individuals with DAT. Spontaneous speech data were collected using a picture description task. For the naming tests, we used the confrontation naming test (K-BNT) and the generative naming test (KCOWAT). Results: First, significant differences were observed in the rates of word-finding behavior among the three groups, especially in the global index, which indicates the overall rate of word-finding behaviors. Second, the correlation analysis results showed a significant negative correlation between the ratios of the global index, word reformulations, empty words, and performance on the confrontation naming test. Finally, there was a significant negative correlation between the ratios of the global index, word reformulations, repetitions, delays, insertions, and performance on the generative naming tests. Conclusion: These results suggest the necessity of developing a naming evaluation scale based on spontaneous speech to effectively assess anomia in individuals with MCI and DAT. The study found significant differences in the rates of word-finding behavior among healthy elderly adults, individuals with MCI, and individuals with DAT, and a correlation between the rates of word-finding behavior and naming tests.","2024-09","2025-02-26 20:37:03","2025-02-26 20:37:03","","618-630","","3","29","","","","","","","","","","English","","","","WOS:001344311500010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","ADULTS; Confrontation naming; Dementia of Alzheimer's type; DISCOURSE; DISEASE; Generative naming; Mild cognitive impairment; SYSTEM; VERSION; Word-finding behaviors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L376NMIF","journalArticle","2022","Johnson, L; Yourganov, G; Basilakos, A; Newman-Norlund, RD; Thors, H; Keator, L; Rorden, C; Bonilha, L; Fridriksson, J","Functional Connectivity and Speech Entrainment Speech Entrainment Improves Connectivity Between Anterior and Posterior Cortical Speech Areas in Non-fluent Aphasia","NEUROREHABILITATION AND NEURAL REPAIR","","1545-9683","10.1177/15459683211064264","","Background Speech entrainment (SE), the online mimicking of an audio-visual speech model, has been shown to increase speech fluency in individuals with non-fluent aphasia. One theory that may explain why SE improves speech output is that it synchronizes functional connectivity between anterior and posterior language regions to be more similar to that of neurotypical speakers. Objectives The present study tested this by measuring functional connectivity between 2 regions shown to be necessary for speech production, and their right hemisphere homologues, in 24 persons with aphasia compared to 20 controls during both free (spontaneous) speech and SE. Methods Regional functional connectivity in participants with aphasia were normalized to the control data. Two analyses were then carried out: (1) normalized functional connectivity was compared between persons with aphasia and controls during free speech and SE and (2) stepwise linear models with leave-one-out cross-validation including normed functional connectivity during both tasks and proportion damage to the left hemisphere as independent variables were created for each language score. Results Left anterior-posterior functional connectivity and left posterior to right anterior functional connectivity were significantly more similar to connectivity of the control group during SE compared to free speech. Additionally, connectivity during free speech was more associated with language measures than connectivity during SE. Conclusions Overall, these results suggest that SE promotes normalization of functional connectivity (i.e., return to patterns observed in neurotypical controls), which may explain why individuals with non-fluent aphasia produce more fluent speech during SE compared to spontaneous speech.","2022-02","2025-02-26 20:37:03","2025-02-26 20:37:03","","164-174","","2","36","","","","","","","","","","English","","","","WOS:000738768800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","aphasia; aphasia recovery; BRAIN; BROCAS APHASIA; chronic stroke; CHRONIC STROKE; functional connectivity; IMPAIRMENT; NETWORK; PERCEPTION; speech entrainment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y5X7VNCL","journalArticle","2023","Sun, RA; Pang, YX; Li, WF","Efficient Lung Cancer Image Classification and Segmentation Algorithm Based on an Improved Swin Transformer","ELECTRONICS","","2079-9292","10.3390/electronics12041024","","With the advancement of computer technology, transformer models have been applied to the field of computer vision (CV) after their success in natural language processing (NLP). In today's rapidly evolving medical field, radiologists continue to face multiple challenges, such as increased workload and increased diagnostic demands. The accuracy of traditional lung cancer detection methods still needs to be improved, especially in realistic diagnostic scenarios. In this study, we evaluated the performance of the Swin Transformer model in the classification and segmentation of lung cancer. The results showed that the pre-trained Swin-B model achieved a top-1 accuracy of 82.26% in the classification mission, outperforming ViT by 2.529%. In the segmentation mission, the Swin-S model demonstrated improvement over other methods in terms of mean Intersection over Union (mIoU). These results suggest that pre-training can be an effective approach for improving the accuracy of the Swin Transformer model in these tasks.","2023-02","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","4","12","","","","","","","","","","English","","","","WOS:000939160200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;22<br/>Total Times Cited:&nbsp;&nbsp;24<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","classification mission; computer vision; lung cancer; segmentation mission; Swin Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D8INK8K7","journalArticle","2024","Qi, ZB; Du, L; Huo, R; Huang, T","Predictive Maintenance Based on Identity Resolution and Transformers in IIoT","FUTURE INTERNET","","1999-5903","10.3390/fi16090310","","The burgeoning development of next-generation technologies, especially the Industrial Internet of Things (IIoT), has heightened interest in predictive maintenance (PdM). Accurate failure forecasting and prompt responses to downtime are essential for improving the industrial efficiency. Traditional PdM methods often suffer from high false alarm rates and inefficiencies in complex environments. This paper introduces a predictive maintenance framework using identity resolution and a transformer model. Devices receive unique IDs via distributed identifiers (DIDs), followed by a state awareness model to assess device health from sensor signals. A sequence prediction model forecasts future signal sequences, which are then used with the state awareness model to determine future health statuses. Combining these predictions with unique IDs allows for the rapid identification of facilities needing maintenance. Experimental results show superior performance, with 99% accuracy for the state awareness model and a mean absolute error (MAE) of 0.062 for the sequence prediction model, underscoring the effectiveness of the framework.","2024-09","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","9","16","","","","","","","","","","English","","","","WOS:001323922800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","edge computing; FAULT-DIAGNOSIS; identity resolution; IIoT; INDUSTRIAL INTERNET; PdM; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DPNWWBA7","journalArticle","2022","Lin, JH; Lu, EJL","SPARQL Generation with an NMT-based Approach","JOURNAL OF WEB ENGINEERING","","1540-9589","10.13052/jwe1540-9589.2155","","SPARQL is a powerful query language which has been widely used in various natural language question answering (QA) systems. As the advances of deep neural networks, Neural Machine Translation (NMT) models are employed to directly translate natural language questions to SPARQL queries in recent years. In this paper, we propose an NMT-based approach with Transformer model to generate SPARQL queries. Transformer model is chosen due to its relatively high efficiency and effectiveness. We design a format to encode a SPARQL query into a simple sequence with only RDF triples reserved. The main purpose of this step is to shorten the sequences and reduce the complexity of the target language. Moreover, we employ entity type tags to further resolve mistranslated problems. The proposed approach is evaluated against three open-domain question answering datasets (QALD-7, QALD-8, and LC-QuAD) on BLEU score and accuracy, and obtains outstanding results (83.49%, 90.13%, and 76.32% on BLEU score, respectively) which considerably outperform all known studies.","2022","2025-02-26 20:37:03","2025-02-26 20:37:03","","1471-1490","","5","21","","","","","","","","","","English","","","","WOS:000836845000005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","NATURAL-LANGUAGE; neural machine translation; question answering; SPARQL generation; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7QAWIC3S","journalArticle","2023","Douglas, CL; Tremblay, A; Newman, AJ","A two for one special: EEG hyperscanning using a single-person EEG recording setup","METHODSX","","2215-0161","10.1016/j.mex.2023.102019","","EEG hyperscanning refers to recording electroencephalographic (EEG) data from multiple partic-ipants simultaneously. Many hyperscanning experimental designs seek to mimic naturalistic be-havior, relying on unpredictable participant-generated stimuli. The majority of this research has focused on neural oscillatory activity that is quantified over hundreds of milliseconds or more. This contrasts with traditional event-related potential (ERP) research in which analysis focuses on transient responses, often only tens of milliseconds in duration. Deriving ERPs requires precise time-locking between stimuli and EEG recordings, and thus typically relies on pre-set stimuli that are presented to participants by a system that controls stimulus timing and synchronization with an EEG system. EEG hyperscanning methods typically use separate EEG amplifiers for each par-ticipant, increasing cost and complexity - including challenges in synchronizing data between systems. Here, we describe a method that allows for simultaneous acquisition of EEG data from a pair of participants engaged in conversation, using a single EEG system with simultaneous audio data collection that is synchronized with the EEG recording. This allows for the post-hoc insertion of trigger codes so that it is possible to analyze ERPs time-locked to specific events. We further demonstrate methods for deriving ERPs elicited by another person's spontaneous speech, using this setup.center dot EEG hyperscanning method using a single EEG amplifier center dot EEG hyperscanning method allowing simultaneous recording of audio data directly into the EEG data file for perfect synchronization center dot EEG method for naturalistic language and human interaction studies that allows the study of event-related potentials time-locked to spontaneous speech","2023","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","10","","","","","","","","","","English","","","","WOS:000977835600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","COMPONENT; EEG hyperscanning; Event-related potentials; Human interaction research; Multi-modal psycholinguistic methods","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BKGFVPQL","journalArticle","2022","Ditthapron, A; Lammert, AC; Agu, EO","Continuous TBI Monitoring From Spontaneous Speech Using Parametrized Sinc Filters and a Cascading GRU","IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS","","2168-2194","10.1109/JBHI.2022.3158840","","Traumatic Brain Injury (TBI) is caused by a head injury that affects the brain, impairing cognitive and communication function and resulting in speech and language disorders. Over 80,000 individuals in the US suffer from long-term TBI disabilities and continuous monitoring after TBI is essential to facilitate rehabilitation and prevent regression. Prior work has demonstrated the feasibility of TBI monitoring from speech by leveraging advancements in Artificial Intelligence (AI) and speech processing technology. However, much of prior work explored TBI detection using scripted speech tasks such as diadochokinesis tests or reading a passage. Such scripted approaches require active user involvement that significantly burdens participants. Moreover, they are episodic, are not realistic, and do not provide a longitudinal picture of the user's TBI condition. This study proposes a continuous TBI monitoring from changes in acoustic features of spontaneous speech collected passively using the smartphone. Low-level acoustic features are extracted using parametrized Sinc filters (pSinc) that are then classified TBI (yes/no) using a cascading Gated Recurrent Unit (cGRU). The cGRU model utilizes a cell gate unit in the GRU to store and incorporate each individual's prediction history as prior knowledge into the model. In rigorous evaluation, our proposed method outperformed prior TBI classification methods on conversational speech recorded during patient-therapist discourses following TBI, achieving 83.87% balanced accuracy. Furthermore, unique words that are important in TBI prediction were identified using SHapley Additive exPlanations (SHAP). A correlation was also found between features acquired by the proposed method and coordination deficits following TBI.","2022-07","2025-02-26 20:37:03","2025-02-26 20:37:03","","3517-3528","","7","26","","","","","","","","","","English","","","","WOS:000819832600066","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Acoustic features; Acoustics; CHALLENGES; continuous monitoring; deep learning; DEPRESSION; DISORDER; Feature extraction; FREQUENCY; Logic gates; Monitoring; PRIVACY; RECOGNITION; SEVERITY; SIGNALS; smartphone; SPEAKER; Speech processing; Support vector machines; Task analysis; traumatic brain injury; TRAUMATIC BRAIN-INJURY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V4V35LZ8","journalArticle","2022","Sánchez, IA","WHAT WE SAY ABOUT WHAT WE DO DEPENDING ON THE LISTENER. AN ANALYSIS ABOUT THE VARIATIONS IN THE INFORMANT'S SPEECH AND ITS USAGE IN OUR ETHNOGRAPHIC WORK","DISPARIDADES-REVISTA DE ANTROPOLOGIA","","2659-6881","10.3989/dra.2022.033","","In this paper we reflect on the possibilities to include in our ethnographic work other sources not from our own fieldwork, as tv interview, formal speech in front of evaluators or similar agents; we analyze the variations of the contents in these speeches and the position we have to place about it as ethnographers. A phenomenon that, usually is avoided in our research as ethnographers, but we have to bear in mind as anthropologists. We will use our own experience in the fieldwork and the fieldnotes in opposition to the discourses produced to the tv interview. We study these changings based on the Whetherell and Potter's speech analysis, the context situation, the Goffman's role studies or the habitus concept by Bourdieu. A reflection about the importance of the speech analysis in our research and how we could bear in mind in our ethnographic work.","2022-07","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","2","77","","","","","","","","","","English","","","","WOS:000993152700002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","Discourse; Ethnography; Informants; Social methodology; Speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2C6XKZ4T","journalArticle","2022","Chadwick, KA; Coleman, R; Andreadis, K; Pitti, M; Rameau, A","Outcomes of Gender-Affirming Voice and Communication Modification for Transgender Individuals","LARYNGOSCOPE","","0023-852X","10.1002/lary.29946","","Objectives Transgender individuals' voices are closely related to gender identity. A primary goal of gender-affirming voice modification is to help individuals alter their voices to improve gender congruence; however, there is a paucity of research to support this approach. This study aimed to evaluate the outcomes of a 12-week gender-affirming voice and communication modification program. Study Design Retrospective cohort study. Methods A retrospective consecutive case series of transgender women enrolled in a voice and communication modification program was performed. Demographics, Trans Woman Voice Questionnaire (TWVQ), fundamental frequency (F-0), and frequency range were collected before and after the program. A Wilcoxon signed-rank test assessed changes in outcomes. Spearman's rank-order correlation coefficients quantified associations between self-reported outcomes and acoustic measures. Results A total of 16 trans women individuals were enrolled. The mean age was 31.5 years. After program completion, TWVQ improved 20.4 points, F-0 increased 26.5 Hz (spontaneous speech) and 25.7 Hz (reading), and the range increased 24.7 Hz (spontaneous speech) and 0.1 Hz (reading). None of the changes in acoustic measures significantly correlated with improvement in TWVQ scores in the cohort. Conclusion Trans women experience improvements in self-reported outcomes and changes in acoustic measures after completing a gender-affirming voice and communication modification program. Individuals may experience significant improvement in subjective outcomes despite small changes in acoustic measures and vice versa. Level of Evidence Level 4 (case series) Laryngoscope, 2021","2022-08","2025-02-26 20:37:03","2025-02-26 20:37:03","","1615-1621","","8","132","","","","","","","","","","English","","","","WOS:000719358700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","ASSOCIATIONS; communication modification; FEMININITY; FORMANT FREQUENCIES; gender-affirming voice; MALE-TO-FEMALE; MANAGEMENT; PERCEPTION; QUESTIONNAIRE TVQ(MTF); SPEAKING FUNDAMENTAL-FREQUENCY; speech-language pathology; THERAPY; Transgender voice; VALIDITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y6NKQDYA","journalArticle","2024","Cheung, WS; You, MH; Syu, SY; Chou, YH; Chen, CY","Advancing semantic segmentation of two-dimensional materials using a semantic-adaptive transformer model","APPLIED PHYSICS LETTERS","","0003-6951","10.1063/5.0225989","","Accurate detection and characterization of two-dimensional (2D) materials are essential for their effective utilization in various applications. Traditional techniques, such as chemical vapor deposition, often produce materials with high defect density, while mechanical exfoliation is hindered by its labor-intensive and time-consuming nature. In this Letter, we propose a semantic-adaptive transformer model, termed Semptive, designed specifically for the precise detection of monolayer MoS2. Our approach integrates a semantic adaptation module with a multi-head self-attention mechanism, incorporating deep supervision and leveraging prior knowledge to enhance model performance. The model was trained on a dataset obtained through mechanical exfoliation and validated using photoluminescence spectroscopy. The experimental results reveal that Semptive significantly enhances segmentation performance compared to conventional models, achieving higher Intersection over Union and Dice scores while reducing computational demands. This method represents a notable advancement in the efficient and precise identification of 2D materials, providing substantial improvements for material characterization and device fabrication processes.","2024-09-23","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","13","125","","","","","","","","","","English","","","","WOS:001318792600013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","MONOLAYER; MOS2; PHOTOLUMINESCENCE; SHEETS; WS2","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4X8JQV9P","journalArticle","2022","Mamyrbayev, O; Oralbekova, D; Alimhan, K; Turdalykyzy, T; Othman, M","A study of transformer-based end-to-end speech recognition system for Kazakh language","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-022-12260-y","","Today, the Transformer model, which allows parallelization and also has its own internal attention, has been widely used in the field of speech recognition. The great advantage of this architecture is the fast learning speed, and the lack of sequential operation, as with recurrent neural networks. In this work, Transformer models and an end-to-end model based on connectionist temporal classification were considered to build a system for automatic recognition of Kazakh speech. It is known that Kazakh is part of a number of agglutinative languages and has limited data for implementing speech recognition systems. Some studies have shown that the Transformer model improves system performance for low-resource languages. Based on our experiments, it was revealed that the joint use of Transformer and connectionist temporal classification models contributed to improving the performance of the Kazakh speech recognition system and with an integrated language model it showed the best character error rate 3.7% on a clean dataset.","2022-05-18","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","1","12","","","","","","","","","","English","","","","WOS:000797636300045","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;20<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FTSTZMGT","journalArticle","2023","Niculescu, O","MODAL VERSUS CREAKY FILLER PARTICLES IN ROMANIAN CONNECTED SPEECH","REVUE ROUMAINE DE LINGUISTIQUE-ROMANIAN REVIEW OF LINGUISTICS","","0035-3957","","","This paper represents a preliminary acoustic analysis of filler particles in terms of voice quality (i.e., modal vs. creaky phonation). The main research questions addressed in this study revolve around which particular voice parameters are indicative of (non)modal phonation of fillers used by healthy speakers of Standard Romanian, and whether the function of the filler particle varies with different voice qualities. The analysis is carried out on Romanian connected speech data extracted from the Ro-Phon corpus (non-pathological speech), an open-access linguistic resource developed during our postdoctoral research project financed by UEFISCDI (2020 - 2022).","2023","2025-02-26 20:37:03","2025-02-26 20:37:03","","413-429","","4","68","","","","","","","","","","English","","","","WOS:001165039500007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","creaky voice; filler particles; GENDER; PHONATION; Romanian data; RoPhon corpus; spontaneous speech; voice quality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y3PCQEZQ","journalArticle","2024","Zhang, L; Gu, HR; Li, ZQ; Liu, ZH; Zhang, Y; Xie, YS; Zhang, ZH; Ji, Z; Li, ZY; Yan, CY","A Sequence-to-Sequence Transformer Model for Satellite Retrieval of Aerosol Optical and Microphysical Parameters from Space","REMOTE SENSING","","2072-4292","10.3390/rs16244659","","Aerosol optical and microphysical properties determine their radiative capabilities, climatic impacts, and health effects. Satellite remote sensing is a crucial tool for obtaining aerosol parameters on a global scale. However, traditional physical and statistical retrieval methods face bottlenecks in data mining capacity as the volume of satellite observation information increases rapidly. Artificial intelligence methods are increasingly applied to aerosol parameter retrieval, yet most current approaches focus on end-to-end single-parameter retrieval without considering the inherent relationships among multiple aerosol properties. In this study, we propose a sequence-to-sequence aerosol parameter joint retrieval algorithm based on the transformer model S2STM. Unlike conventional end-to-end single-parameter retrieval methods, this algorithm leverages the encoding-decoding capabilities of the transformer model, coupling multi-source data such as polarized satellite, meteorological, model, and surface characteristics, and incorporates a physically coherent consistency loss function. This approach transforms traditional single-parameter numerical regression into a sequence-to-sequence relationship mapping. We applied this algorithm to global observations from the Chinese polarimetric satellite (the Particulate Observing Scanning Polarimeter, POSP) and simultaneously retrieved multiple key aerosol optical and microphysical parameters. Event analyses, including dust and pollution episodes, demonstrate the method's responsiveness in hotspot regions and events. The retrieval results show good agreement with ground-based observation products. This method is also adaptable to satellite instruments with various configurations (e.g., multi-wavelength, multi-angle, and multi-dimensional polarization) and can further improve its spatiotemporal generalization performance by enhancing the spatial balance of ground station training datasets.","2024-12","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","24","16","","","","","","","","","","English","","","","WOS:001384589300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","ABSORPTION; aerosol retrieval; ALGORITHM; AREA; LAND; polarimetric remote sensing; POSP; transformer; UNCERTAINTIES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T29AM88X","journalArticle","2024","Li, MX; Wan, ZZ; Zou, TR; Shen, ZY; Li, MZ; Wang, CS; Xiao, XQ","Artificial intelligence enabled self-powered wireless sensing for smart industry","CHEMICAL ENGINEERING JOURNAL","","1385-8947","10.1016/j.cej.2024.152417","","Traditional batteries or external supply powered wireless sensing system are needed to be improved for realizing the development of the smart industry with low-carbon, green and sustainable. This paper proposes and develops a self-powered wireless sensing system for smart industry (SPOT), utilizing a triboelectric nanogenerator (TENG) coupled with an artificial intelligence (AI) transformer model. The SPOT system includes the TENG-based self- powered flexible sensor (SWNG), the wireless aggregate node (WAN), the electromagnetic and TENG hybrid generator (ETCG), and the monitoring and management center with an AI model (MACA). The ETCG serves as a power source for the WAN. The SWNG acquires voltage signals from products on the conveyor belt in the smart industry, powered by the TENG, and transmits the sensor data wirelessly to the MACA via the WAN for processing. The MACA processes the data using the transformer AI model, which not only ensures self-sustainability and long-term stability but also enables intelligent recognition and monitoring of industrial products by their packaging materials, thereby providing precise status information and decision support for the smart industry. The transformer model's deployment in the MACA has demonstrated robustness and a high classification success rate of up to 97.8 %, efficiently categorizing multiple targets. Additionally, the SWNG and WAN exhibit low power consumption of approximately 80 mW, successfully contributing to the realization of green, low-carbon objectives. The SPOT system significantly enhances the efficiency of product transportation and management within the smart industry and contributes to the advancement of a sustainable, low-carbon, and green smart industry, offering novel technological insights and pathways for future development.","2024-07-15","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","492","","","","","","","","","","English","","","","WOS:001291576400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","Artificial intelligence; BLOCKCHAIN; DESIGN; Self-powered wireless sensing; Smart industry; SYSTEMS; TECHNOLOGY; Transformer model; Triboelectric nanogenerator; TRIBOELECTRIC NANOGENERATORS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"REH8JIF4","journalArticle","2024","Wang, XY; Lin, WF; Zhang, WT; Huang, YW; Li, ZY; Liu, Q; Yang, XZ; Yao, YF; Lv, CL","Integrating Merkle Trees with Transformer Networks for Secure Financial Computation","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14041386","","In this paper, the Merkle-Transformer model is introduced as an innovative approach designed for financial data processing, which combines the data integrity verification mechanism of Merkle trees with the data processing capabilities of the Transformer model. A series of experiments on key tasks, such as financial behavior detection and stock price prediction, were conducted to validate the effectiveness of the model. The results demonstrate that the Merkle-Transformer significantly outperforms existing deep learning models (such as RoBERTa and BERT) across performance metrics, including precision, recall, accuracy, and F1 score. In particular, in the task of stock price prediction, the performance is notable, with nearly all evaluation metrics scoring above 0.9. Moreover, the performance of the model across various hardware platforms, as well as the security performance of the proposed method, were investigated. The Merkle-Transformer exhibits exceptional performance and robust data security even in resource-constrained environments across diverse hardware configurations. This research offers a new perspective, underscoring the importance of considering data security in financial data processing and confirming the superiority of integrating data verification mechanisms in deep learning models for handling financial data. The core contribution of this work is the first proposition and empirical demonstration of a financial data analysis model that fuses data integrity verification with efficient data processing, providing a novel solution for the fintech domain. It is believed that the widespread adoption and application of the Merkle-Transformer model will greatly advance innovation in the financial industry and lay a solid foundation for future research on secure financial data processing.","2024-02","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","4","14","","","","","","","","","","English","","","","WOS:001170109200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","artificial intelligence; deep learning; financial computation model; Merkle tree; MODEL; PREDICTION; secure data handling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4RTAVAUD","journalArticle","2023","Markus, E; Rozhanskiy, F","FUNCTIONS OF DEMONSTRATIVE PRONOUNS IN CONTEMPORARY SOIKKOLA INGRIAN","EESTI JA SOOME-UGRI KEELETEADUSE AJAKIRI-JOURNAL OF ESTONIAN AND FINNO-UGRIC LINGUISTICS","","1736-8987","10.12697/jeful.2023.14.2.03","","This article discusses demonstrative pronouns in the Soikkola dialect of the Ingrian language. The material for the research comes from a collection of spontaneous speech samples recorded in the 21st century. Most examples are being published for the first time. The article presents mainly a qualitative analysis and aims to provide an overview of the basic functions of the Ingrian demonstrative pronouns tama and se. It is shown that in contemporary Ingrian the demonstratives are used as deictic and anaphoric devices, and also as discourse markers. Individual speakers demonstrate differences in the use of these pronouns due to the contact influence from neighbouring languages.","2023","2025-02-26 20:37:03","2025-02-26 20:37:03","","41-74","","2","14","","","","","","","","","","English","","","","WOS:001104722200012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","anaphora; deixis; demonstrative pronouns; discourse markers; GRAMMAR; Ingrian; language contact; pronouns","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E4APVHL2","journalArticle","2023","Yu, MZ; Masrur, A; Blaszczak-Boxe, C","Predicting hourly PM2.5 concentrations in wildfire-prone areas using a SpatioTemporal Transformer model","SCIENCE OF THE TOTAL ENVIRONMENT","","0048-9697","10.1016/j.scitotenv.2022.160446","","Globally, wildfires are becoming more frequent and destructive, generating a significant amount of smoke that can transport thousands of miles. Therefore, improving air pollution forecasts from wildfires is essential and informing cit-izens of more frequent, accurate, and interpretable updates related to localized air pollution events. This research pro-poses a multi-head attention-based deep learning architecture, SpatioTemporal (ST)-Transformer, to improve spatiotemporal predictions of PM2.5 concentrations in wildfire-prone areas. The ST-Transformer model employed a sparse attention mechanism that concentrates on the most useful contextual information across spatial, temporal, and variable-wise dimensions. The model includes critical driving factors of PM2.5 concentrations as predicting factors, including wildfire perimeter and intensity, meteorological factors, road traffic, PM2.5, and temporal indicators from the past 24 h. The model is trained to conduct time series forecasting on PM2.5 concentrations at EPA's air quality sta-tions in the greater Los Angeles area. Prediction results were compared with other existing time series forecasting methods and exhibited better performance, especially in capturing abrupt changes or spikes in PM2.5 concentrations during wildfire situations. The attention matrix learned by the proposed model enabled interpretation of the complex spatial, temporal, and variable-wise dependencies, indicating that the model can differentiate between wildfires and non-wildfires. The ST-Transformer model's accurate predictability and interpretation capacity can help effectively monitor and predict the impacts of wildfire smoke and be applicable to other complex spatiotemporal prediction problems.","2023-02-20","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","860","","","","","","","","","","English","","","","WOS:000921863700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;46<br/>Total Times Cited:&nbsp;&nbsp;47<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Air pollution; AIR-QUALITY; BEHAVIOR; CLIMATE; FINE PARTICULATE MATTER; FIRE; HEALTH; PM2.5; SMOKE; Sparse self-attention; Spatiotemporal prediction; SYSTEM; Transformer neural network; Wildfire","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CGTPTI62","journalArticle","2023","Thomas, JB; Chaudhari, SG; Shihabudheen, KV; Verma, NK","CNN-Based Transformer Model for Fault Detection in Power System Networks","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2023.3238059","","Fault detection and localization in electrical power lines has long been a crucial challenge for electrical engineers as it allows the detected fault to be isolated and recovered promptly. These faults, if neglected, can rupture the normal operation of the network and drastically damage the power lines and the equipment attached to it. The wastage of power and money due to these faults can be harmful to the economy of an industry or even a country. Therefore, efficient fault detection mechanisms have become crucial for the well-being of this power-hungry world. This research presents an end-to-end deep learning strategy to detect and localize symmetrical and unsymmetrical faults as well as high-impedance faults (HIFs) in a distribution system. This research proposes a novel deep convolutional neural network (CNN) transformer model to automatically detect the type and phase of the fault as well as the location of the fault. The proposed model utilizes 1-D deep CNNs for feature extraction and transformer encoder for sequence learning. The transformer encoder utilizes an attention mechanism to integrate the sequence embeddings and focus on significant time steps to learn long-term dependence to extract the context of the temporal current data. The different faults were simulated in MATLAB Simulink using IEEE 14-bus distribution system. The proposed models were found to produce better performance on the test database when evaluated using F1-Score, Matthews correlation coefficient (MCC), and accuracy. The models also produced better predictions on HIFs compared to conventional fault-detection techniques.","2023","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","72","","","","","","","","","","English","","","","WOS:001159218000003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;58<br/>Total Times Cited:&nbsp;&nbsp;58<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","ATTENTION MECHANISM; CLASSIFICATION; Data models; Databases; Deep learning; fault detection; Fault detection; Feature extraction; high-impedance fault (HIF); Impedance; LOCATION; MICROGRIDS; PREDICTION; PROTECTION SCHEME; transformer model; Transformers; WAVELET","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QT9KINUF","journalArticle","2024","Lu, YC; Lu, XY; Zheng, LP; Sun, M; Chen, SY; Chen, BY; Wang, T; Yang, JM; Lv, CL","Application of Multimodal Transformer Model in Intelligent Agricultural Disease Detection and Question-Answering Systems","PLANTS-BASEL","","2223-7747","10.3390/plants13070972","","In this study, an innovative approach based on multimodal data and the transformer model was proposed to address challenges in agricultural disease detection and question-answering systems. This method effectively integrates image, text, and sensor data, utilizing deep learning technologies to profoundly analyze and process complex agriculture-related issues. The study achieved technical breakthroughs and provides new perspectives and tools for the development of intelligent agriculture. In the task of agricultural disease detection, the proposed method demonstrated outstanding performance, achieving a precision, recall, and accuracy of 0.95, 0.92, and 0.94, respectively, significantly outperforming the other conventional deep learning models. These results indicate the method's effectiveness in identifying and accurately classifying various agricultural diseases, particularly excelling in handling subtle features and complex data. In the task of generating descriptive text from agricultural images, the method also exhibited impressive performance, with a precision, recall, and accuracy of 0.92, 0.88, and 0.91, respectively. This demonstrates that the method can not only deeply understand the content of agricultural images but also generate accurate and rich descriptive texts. The object detection experiment further validated the effectiveness of our approach, where the method achieved a precision, recall, and accuracy of 0.96, 0.91, and 0.94. This achievement highlights the method's capability for accurately locating and identifying agricultural targets, especially in complex environments. Overall, the approach in this study not only demonstrated exceptional performance in multiple tasks such as agricultural disease detection, image captioning, and object detection but also showcased the immense potential of multimodal data and deep learning technologies in the application of intelligent agriculture.","2024-04","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","7","13","","","","","","","","","","English","","","","WOS:001201060600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","agricultural disease detection; agricultural large model; deep learning; FUSION; smart agriculture; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U56Y5LN2","journalArticle","2025","Vazrala, S; Mohammed, TK","RBTM: A Hybrid gradient Regression-Based transformer model for biomedical question answering","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2024.107325","","Background: The biomedical field faces substantial challenges in addressing health-related queries due to the vast and complex body of literature available. Traditional keyword-based search methods and current Question Answering (QA) systems are often inadequate in capturing the nuanced semantic relationships within biomedical texts, which hampers the delivery of accurate and relevant answers. Aim: This research aims to develop an advanced QA system capable of capturing complex conceptual relationships within biomedical literature to improve accuracy and relevance in responses. Methods: A Hybrid Gradient Regression-Based Transformer Model (RBTM) that integrates semantic similarity quantification with deep learning is proposed. The methodology includes three main phases: component identification, semantic similarity measurement at component and sentence levels, and similarity scoring. The model uses the LemmaChase Lemmatizer for feature extraction, SNOMED-CT ontology for domain-specific concept identification, and the concept2Vec approach to generate enhanced vector representations of input phrases. RBTM, combining XGBoost with transformer architecture, calculates similarity scores that guide answer selection. Results: The proposed RBTM model was evaluated on the MedQuAD dataset, achieving high performance with a notable accuracy of 99.09%, an R2 score of 97.07%, and an MSE of 0.00227. These results demonstrate RBTM's robustness and its superiority over existing models in accurately identifying relevant biomedical answers. Conclusion: The RBTM model represents a solution for biomedical QA by effectively addressing limitations in current systems, such as computational complexity and semantic inaccuracies. Future work will involve expanding the SNOMED-CT ontology and incorporating reinforcement learning to further enhance accuracy and applicability in biomedical information retrieval.","2025-04","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","102","","","","","","","","","","English","","","","WOS:001393371600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Biomedical QA; Concept modelling; Concept2Vec; Deep learning; Hybrid Gradient Regression-Based Transformer; Model (RBTM); Semantic similarity; SNOMED-CT; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NGPVYJ9I","journalArticle","2022","Zirka, SE; Moroz, YI; Arturi, CM","Once again about the Steinmetz transformer model and the ongoing subdivision of its leakage inductance","COMPEL-THE INTERNATIONAL JOURNAL FOR COMPUTATION AND MATHEMATICS IN ELECTRICAL AND ELECTRONIC ENGINEERING","","0332-1649","10.1108/COMPEL-06-2021-0190","","Purpose Despite its well-founded criticism and lack of proper justification under core saturation conditions, the T-equivalent transformer model (Steinmetz scheme) is obviously championing in the literature. This educational paper aims to explain in a simple manner the limitations of the T-model of a low-frequency transformer and critically analyses some attempts to improve it. Design/methodology/approach Using a simplified examination of magnetic fluxes in the core and windings and using the modeling in ATPDraw, it is shown that transient transformer models with the indivisible leakage inductance allow circumventing the drawbacks of the T-model. Findings The authors show the absence of valid grounds for subdividing the leakage inductance of a transformer between its primary and secondary windings. The connection between the use of individual leakage inductances and inaccurate prediction of inrush current peaks is outlined as an important example. Practical implications The presented models can be used either as independent tools or serve as a reference for subsequent developments. Social implications Over generations, the habitual transformer T-equivalent is widely used by engineers and Electromagnetic Transients Program experts with no attention to its inadequacy under core saturation conditions. Having studied typical winding configurations, the authors have shown that neither of them has any relation to the T-equivalent. Originality/value This educational paper will contribute to the correct understanding of the transients occurring in a transformer under abnormal conditions such as inrush current or ferroresonance events, as well as during an out-of-phase synchronization of step-up generator transformers.","2022-01-11","2025-02-26 20:37:03","2025-02-26 20:37:03","","81-95","","1","41","","","","","","","","","","English","","","","WOS:000713331900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","3-PHASE; Core saturation; Field circuit models; Leakage field; Leakage inductance; PART I; Time-domain modeling; Transformer model; TRANSIENT SIMULATION; Transients","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"II55929A","journalArticle","2023","Medeiros, BD; Pessôa, LD; Martins, AL; Gomes, JCD","MORPHOLOGICAL REALIZATIONS OF PERFECT ASSOCIATED WITH THE FUTURE IN BRAZILIAN PORTUGUESE","LINGUISTICA Y LITERATURA","","0120-5587","10.17533/udea.lyl.n84a07","","In this study, we investigated the morphological realizations of universal (UP) and existential perfect (EP) associated with the future tense in Brazilian Portuguese. We analyzed spontaneous speech data and applied a cloze linguistic test. The results revealed that UP is realized by estar (<< to be >>) in the future + gerund and simple present and EP is realized by ter (<< to have >>) or haver (<< there to be >>) in the future + past participle, simple past and estar (<< to be >>) in the future + predicative. We discussed the results supporting the proposal of dissociation of UP and EP in the syntactic representation.","2023-07","2025-02-26 20:37:03","2025-02-26 20:37:03","","154-184","","84","","","","","","","","","","","English","","","","WOS:001110156700012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","Brazilian Portuguese; future tense; morphological realizations; perfect aspect; universal and existential perfect","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SY98WXPZ","journalArticle","2024","Qing, Y","DESIGN AND APPLICATION OF AUTOMATIC ENGLISH TRANSLATION GRAMMAR ERROR DETECTION SYSTEM BASED ON BERT MACHINE VISION","SCALABLE COMPUTING-PRACTICE AND EXPERIENCE","","1895-1767","10.12694/scpe.v25i3.2770","","Given the traditional handwritten English fonts, the accuracy of grammar error detection is unsatisfactory. This attribute leads to poor grammar error correction. Based on the optimized BERT machine vision model, an automatic English translation grammar error detection system is proposed in this paper. First, the basic architecture of the Transformer model and BERT model is considered, and a mixed attention module is discussed into the Transformer model to capture the features of the target in space and channel dimensions and realize the modeling of the context dependence of the target features. The feature maps are sampled by multiple parallel only if then cavity convolutions with different void rates to obtain multi -scale features and enhance local feature representation. Then, the input words of the BERT model are weighted by TFIDF to improve the feature extraction ability of the BERT model and construct the TF-BERT model. A database query rewriting model based on BERT and Transformer is proposed. The construction details of the model are described from the aspects of encoding processing, table embedding, and decoding processing respectively. Based on the principles of English translation, we extract grammatical features and build a grammar error detection method. TF-BERT model is selected as the basic framework. Combined with the hybrid attention mechanism, an automatic error correction model of English grammar is constructed. Finally, it is found that the loss value of the traditional system is as high as 0.7411, and the accuracy rate is 75%, while the loss value of the English grammar error detection system proposed in this paper is 0.2639, and the accuracy rate is 100%, which is 25% higher than that of the traditional system, and the performance is remarkable.","2024-04-12","2025-02-26 20:37:03","2025-02-26 20:37:03","","2088-2102","","3","25","","","","","","","","","","English","","","","WOS:001206408600070","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;0</p>","","","BERT; Empty convolution; Grammar error correction; Mixed attention; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WN6QWCNR","journalArticle","2022","Park, S; Araki, M; Nakajima, A; Lee, H; Fuster, V; Ye, JC; Jang, IK","Enhanced Diagnosis of Plaque Erosion by Deep Learning in Patients With Acute Coronary Syndromes","JACC-CARDIOVASCULAR INTERVENTIONS","","1936-8798","10.1016/j.jcin.2022.08.040","","BACKGROUND Acute coronary syndromes caused by plaque erosion might be potentially managed conservatively without stenting. Currently, the diagnosis of plaque erosion requires expertise in optical coherence tomographic (OCT) image interpretation. In addition, the current deep learning (DL) approaches for OCT image interpretation are based on a single frame, without integrating the information from adjacent frames. OBJECTIVES The aim of this study was to develop a novel DL model to facilitate an accurate diagnosis of plaque erosion. METHODS A novel ""Transformer""-based DL model was developed that integrates information from adjacent frames emulating the cardiologists who review consecutive OCT frames to make a diagnosis and compared with the standard convolutional neural network (CNN) DL model. A total of 237,021 cross-sectional OCT images from 581 patients were used for training and internal validation, and 65,394 images from 292 patients from another dataset were used for external validation. Model performances were evaluated using the area under the receiver-operating characteristic curve (AUC). RESULTS For the frame-level diagnosis of plaque erosion, the Transformer model showed superior performance than the CNN model, with an AUC of 0.94 compared with 0.85 in the external validation. For the lesion-level diagnosis, the Transformer model showed improved diagnostic performance compared with the CNN model, with an AUC of 0.91 compared with 0.84 in the external validation. CONCLUSIONS This newly developed Transformer model will help cardiologists diagnose plaque erosion with high accuracy in patients with acute coronary syndromes. (c) 2022 by the American College of Cardiology Foundation.","2022-10-24","2025-02-26 20:37:03","2025-02-26 20:37:03","","2020-2031","","20","15","","","","","","","","","","English","","","","WOS:001008375200005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","acute coronary syndrome; CLASSIFICATION; deep learning; optical coherence tomography; OPTICAL COHERENCE TOMOGRAPHY; plaque erosion; RUPTURE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FELN4IHH","journalArticle","2024","Zhao, JW; He, TT; Wang, LY; Wang, YW","Forecasting Gate-Front Water Levels Using a Coupled GRU-TCN-Transformer Model and Permutation Entropy Algorithm","WATER","","2073-4441","10.3390/w16223310","","Water level forecasting has significant impacts on transportation, agriculture, and flood control measures. Accurate water level values can enhance the safety and efficiency of water conservancy hub operation scheduling, reduce flood risks, and are essential for ensuring sustainable regional development. Addressing the nonlinearity and non-stationarity characteristics of gate-front water level sequences, this paper introduces a gate-front water level forecasting method based on a GRU-TCN-Transformer coupled model and permutation entropy (PE) algorithm. Firstly, an analysis method combining Singular Spectrum Analysis (SSA) and Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN) is used to separate the original water level data into different frequency modal components. The PE algorithm subsequently divides each modal component into sequences of high and low frequencies. The GRU model is applied to predict the high-frequency sequence part, while the TCN-Transformer combination model is used for the low-frequency sequence part. The forecasting from both models are combined to obtain the final water level forecasting value. Multiple evaluation metrics are used to assess the forecasting performance. The findings indicate that the combined GRU-TCN-Transformer model achieves a Mean Absolute Error (MAE) of 0.0154, a Root Mean Square Error (RMSE) of 0.0205, and a Coefficient of Determination (R2) of 0.8076. These metrics indicate that the model outperforms machine learning Support Vector Machine (SVM) models, GRU models, Transformer models, and TCN-Transformer combination models in forecasting performance. The forecasting results have high credibility. This model provides a new reference for improving the accuracy of gate-front water level forecasting and offers significant insights for water resource management and flood prevention, demonstrating promising application prospects.","2024-11","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","22","16","","","","","","","","","","English","","","","WOS:001366585700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","complete ensemble empirical mode decomposition with adaptive noise; deep learning; GRU-TCN-Transformer model; singular spectrum analysis; water level forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3KNKMADV","journalArticle","2024","Wu, Y","Enterprise financial sharing and risk identification model combining recurrent neural networks with transformer model supported by blockchain","HELIYON","","2405-8440","10.1016/j.heliyon.2024.e32639","","The objective of this study is to investigate methodologies concerning enterprise financial sharing and risk identification to mitigate concerns associated with the sharing and safeguarding of financial data. Initially, the analysis examines security vulnerabilities inherent in conventional financial information sharing practices. Subsequently, blockchain technology is introduced to transition various entity nodes within centralized enterprise financial networks into a decentralized blockchain framework, culminating in the formulation of a blockchain-based model for enterprise financial data sharing. Concurrently, the study integrates the Bi-directional Long ShortTerm Memory (BiLSTM) algorithm with the transformer model, presenting an enterprise financial risk identification model referred to as the BiLSTM-fused transformer model. This model amalgamates multimodal sequence modeling with comprehensive understanding of both textual and visual data. It stratifies financial values into levels 1 to 5, where level 1 signifies the most favorable financial condition, followed by relatively good (level 2), average (level 3), high risk (level 4), and severe risk (level 5). Subsequent to model construction, experimental analysis is conducted, revealing that, in comparison to the Byzantine Fault Tolerance (BFT) algorithm mechanism, the proposed model achieves a throughput exceeding 80 with a node count of 146. Both data message leakage and average packet loss rates remain below 10 %. Moreover, when juxtaposed with the recurrent neural networks (RNNs) algorithm, this model demonstrates a risk identification accuracy surpassing 94 %, an AUC value exceeding 0.95, and a reduction in the time required for risk identification by approximately 10 s. Consequently, this study facilitates the more precise and efficient identification of potential risks, thereby furnishing crucial support for enterprise risk management and strategic decision-making endeavors.","2024-06-30","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","12","10","","","","","","","","","","English","","","","WOS:001258356500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","BiLSTM; Blockchain; Enterprise financial sharing; Recurrent neural networks; Risk identification; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7VQS6WEH","journalArticle","2023","Li, XF; Huang, HY","An IoT-Based Intelligent Selection of Multidomain Feature for Smart Healthcare Using Reinforcement Learning in Schizophrenia","IEEE INTERNET OF THINGS JOURNAL","","2327-4662","10.1109/JIOT.2023.3281509","","Currently, the health industry by the Internet of Things (IoT) is developing rapidly, and electroencephalogram (EEG) signal has become a bridge for human-machine communication. EEG signal feature selection is a key link in brain nerves research and has important practical application value. Therefore, we propose an IoT-based intelligent selection of multidomain feature for multimodal transformer EEG signal using reinforcement learning in Schizophrenia. First of all, the features of the multimodal EEG signal sequence by the IoT were extracted from time domain, frequency domain, and spatial domain; second, the average pooling layer was added to improve the design of the transformer model for deep feature extraction of EEG signal; finally, reinforcement learning was introduced to run operation with the extracted features as input and the improved transformer model as agent. At the same time, entropy and Pearson correlation coefficient calculation were introduced to select feature subsets, and feature intelligent selection of EEG signal in multiple domains was completed through interaction between the agent and the environment. Experiments were performed on DEAP, EEG Motor Movement/Imagery Data set, BCI2008 competition data set, and data set of a hospital. The results show that the feature extraction and feature visualization effect of the proposed algorithm is good, and the feature selection precision is as high as about 90%, and the average time is only about 13 s. These findings indicate the feasibility of the proposed feature intelligent selection algorithm in the study of EEG signal in schizophrenia, which provides a good basis for further study on the integration of IoT with the healthy industry.","2023-11-01","2025-02-26 20:37:03","2025-02-26 20:37:03","","18517-18528","","21","10","","","","","","","","","","English","","","","WOS:001098109800009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","ALGORITHM; EEG; Intelligent selection; Internet of Things (IoT); MODEL; multidomain feature; multimodal electroencephalogram (EEG) signal; NETWORK; reinforcement learning; schizophrenia; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TGGM5ZTN","journalArticle","2023","Asudani, DS; Nagwani, NK; Singh, P","A comparative evaluation of machine learning and deep learning algorithms for question categorization of VQA datasets","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-023-17797-2","","Question classification primarily involves categorizing questions based on the type of answer, with less emphasis on the words or phrases used to form the query. Question classification is crucial in the Visual Question Answering (VQA) system, and the dataset's quality plays an essential role in the system's development. The available question categorization in the VQA and TDIUC datasets shows imbalance, and the VQA model trained on imbalanced datasets performs poorly in handling language-prior problems, failing to categorize questions, and predicting incorrect outcomes. Therefore, developing a better classification method for classifying questions into appropriate categories based on phrases is necessary. This paper examines the effectiveness of the synthetic minority oversampling technique (SMOTE) in addressing the class imbalance problem within the question classification task using the LSTM, selected machine learning models and BERT-based transformer model. The preprocessing and analysis module efficiently categorizes input question sets by identifying valuable phrases and obtaining an evenly distributed dataset based on question categories from both datasets. The performance evaluation of Naive Bayes, SVM, Random Forests, and XGBoost models shows that the XGBoost model outperforms other selected classifiers, and the LSTM model achieves higher accuracy but requires more computation time. The empirical assessment indicates that the BERT-based transformer model exceeds the traditional models employed for comparison. The ablation study also reveals that utilizing SMOTE techniques for question classification tasks achieves slightly improved accuracy at the expense of higher computation time and resources. It is concluded that the BERT-based transformer model efficiently and precisely performs question classification tasks.","2023-12-13","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","","","","","","","","","","","English","","","","WOS:001122700100004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","BERT-based Transformers; Deep Learning; Machine Learning; Question Classification; SMOTE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8BPP8FD2","journalArticle","2025","Jin, HY; Ru, R; Cai, L; Meng, JH; Wang, B; Peng, JC; Yang, SX","A synthetic data generation method and evolutionary transformer model for degradation trajectory prediction in lithium-ion batteries","APPLIED ENERGY","","0306-2619","10.1016/j.apenergy.2024.124629","","Identifying the long-term degradation of lithium-ion batteries in their early usage phase is crucial for the battery management system (BMS) to properly maintain the battery for practical use. Nevertheless, this procedure is challenging due to variations in the production and operating conditions of the battery. In recent years, it has been empirically proven that the data-driven method is a promising solution for handling the prediction of degradation. However, the lack of appropriate data remains the main obstacle that impacts the ultimate performance of the prediction. Furthermore, the prediction is also influenced by the setup of the predictor, which covers the structure of neural networks and their hyperparameters. The challenge of automating this process remains unresolved. In this study, we propose a novel degradation trajectory prediction framework. First, synthetic data is generated via a conditional generative adversarial network (CGAN), providing the characterization of the battery's degradation at an early stage and utilizing the argument data to alleviate the issue of insufficient data. Second, an evaluation method to evaluate the quality of the synthetic data is also provided. In addition, a selection method is proposed based on the diversity mechanism to further filter out the redundancy of synthetic data. These two sub-processes aim to promote the quality of the synthetic data. Finally, the synthetic data hybrid with real values is used for the training of a transformer model, whose architecture and hyper-parameters are automatically configured via an evolutionary framework. The experimental results show that the proposed method can achieve accurate predictions compared to its rivals, and its best configuration can be automatically configured without hand-crafted efforts.","2025-01-01","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","377","","","","","","","","","","English","","","","WOS:001342917400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Degradation trajectory prediction; Evolutionary framework; HEALTH ESTIMATION; Lithium-ion battery; STATE; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BFML6V38","journalArticle","2022","Santiago, F; Mairano, P","Spaniards articulate faster than Mexicans Temporal patterns in two varieties of Spanish","SPANISH IN CONTEXT","","1571-0718","10.1075/sic.20013.san","","We analyse articulation rate and speech rate, number and duration of pauses for 22 speakers of two regional varieties of Spanish (Madrilenian vs Mexican) in three different tasks (reading, picture description and interview). Our results show that speakers from Madrid have higher articulation rate and speech rate than speakers from Mexico, but that such differences are mainly observed in spontaneous speech (picture description). Instead, the number and duration of pauses were not significantly affected by the origin of speakers. Some methodological issues are discussed in order to make legitimate inferences from this exploratory study.","2022-12-01","2025-02-26 20:37:03","2025-02-26 20:37:03","","244-264","","2","19","","","","","","","","","","English","","","","WOS:000934050200003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","AMERICAN; articulation rate; BETWEEN-SPEAKER; DIALECT; LANGUAGE; Madrilenian Spanish; Mexican Spanish; MULTILEVEL; SPEECH RATE; WITHIN-SPEAKER VARIATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MN7WFVJ8","journalArticle","2021","Bhandari, B","Comparative Study of Popular Deep Learning Models for Machining Roughness Classification Using Sound and Force Signals","MICROMACHINES","","2072-666X","10.3390/mi12121484","","This study compared popular Deep Learning (DL) architectures to classify machining surface roughness using sound and force data. The DL architectures considered in this study include Multi-Layer Perceptron (MLP), Convolution Neural Network (CNN), Long Short-Term Memory (LSTM), and transformer. The classification was performed on the sound and force data generated during machining aluminum sheets for different levels of spindle speed, feed rate, depth of cut, and end-mill diameter, and it was trained on 30 s machining data (10-40 s) of the machining experiments. Since a raw audio waveform is seldom used in DL models, Mel-Spectrogram and Mel Frequency Cepstral Coefficients (MFCCs) audio feature extraction techniques were used in the DL models. The results of DL models were compared for the training-validation accuracy, training epochs, and training parameters of each model. Although the roughness classification by all the DL models was satisfactory (except for CNN with Mel-Spectrogram), the transformer-based modes had the highest training (>96%) and validation accuracies (approximate to 90%). The CNN model with Mel-Spectrogram exhibited the worst training and inference accuracy, which is influenced by limited training data. Confusion matrices were plotted to observe the classification accuracy visually. The confusion matrices showed that the transformer model trained on Mel-Spectrogram and the transformer model trained on MFCCs correctly predicted 366 (or 91.5%) and 371 (or 92.7%) out of 400 test samples. This study also highlights the suitability and superiority of the transformer model for time series sound and force data and over other DL models.","2021-12","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","12","12","","","","","","","","","","English","","","","WOS:000736499000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","attention mechanisms; classification; CNN; confusion matrix; Deep Learning; LSTM; MLP; precision machining; Smart Factory; sound feature extraction; SURFACE-ROUGHNESS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R6XC2XDC","journalArticle","2025","Liu, JB; Ang, MC; Chaw, JK; Ng, KW; Kor, AL","Personalized emotion analysis based on fuzzy multi-modal transformer model","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-024-05954-5","","Analyzing and detecting human intensions and emotions are important means to improve the communication between users and machines in the areas of human-computer interaction (HCI) and human-robot interaction (HRI). Despite significant progress in utilizing state-of-the-art (SOTA) Transformer-based models, various obstacles persist in managing complicated input interdependencies and extracting intricate contextual semantics. Moreover, it lacks practical applicability and struggles to accurately capture and effectively manage the inherent complexity and unpredictability of human emotions. In recognition of the identified research gaps, we introduce a robust and innovative fuzzy multi-modal Transformer (FMMT) model. Our novel fuzzy Transformer model uniquely heightens the comprehension of emotional contexts by concurrently analyzing audio, visual, and text data through three distinct branches. By incorporating fuzzy mathematic theory and introducing a unique temporal embedding technique to trace the evolution of emotional states, it effectively handles the inherent uncertainty in human emotions, thereby filling a significant void in emotional AI. Building upon the FMMT model, we further explored the emotion expression approach. Furthermore, performance comparison analysis with SOTA baseline methods and detailed ablation study were performed. The results show that the proposed FMMT performs better than the baseline methods. Finally, we conducted detailed experimental verification and empirical analyses of the practicality of the designed method by verifying uncertainty emotion and analyzing emotional state transitions combined with personalized factor. Overall, our research makes a significant contribution to emotion analysis through the implementation of a novel fuzzy Transformer model. This model enhances emotion perception and advances the methods for analyzing emotional expression, thus setting an edge over prior studies.","2025-02","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","3","55","","","","","","","","","","English","","","","WOS:001383633400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;123</p>","","","CNN; COEFFICIENT; Emotion analysis; FMMT; HCI; HRI; NEURAL-NETWORK; Personalized factor; RECOGNITION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZY278F43","journalArticle","2024","Zhang, Y; Zhou, P; Ma, EJ","Anomaly Detection of Industrial Smelting Furnace Incorporated With Accelerated Sampling Denoising Diffusion Probability Model and Conv-Transformer","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2024.3375410","","Industrial smelting furnace is the core device for various metal preparations, and its abnormality detection is essential for ensuring the safety, stability, and high quality of smelting production. Traditional manual inspections often struggle to detect them promptly and accurately. This difficulty primarily arises from the harsh environments characterized by high temperatures, intense lighting, substantial dust, and dense water mist, all of which significantly compromise the safety and stability of the melting process. To tackle this challenge, a novel intelligent detection approach incorporated with the accelerated sampling denoising diffusion probability model (DDPM) and the Conv-Transformer model is proposed, which can simultaneously enhance the accuracy of semi-molten condition detection and diminish the model complexity. First, in order to solve the limited availability of samples representing abnormal working conditions in the actual melting process, the DDPM is utilized for model training. Nonetheless, the standard sampling process of DDPM is time-consuming, and this article implements a step-by-step sampling strategy within the DDPM framework, aimed at accelerating the overall sampling process while simultaneously augmenting the detection stability under abnormal condition with small samples. Then, to overcome the challenge of incomplete feature extraction, this study introduces the Conv-Transformer model, which combines the local and global features of the images to improve the detection rate of abnormal condition. Finally, experimental results using industrial smelting data of fused magnesium furnace (FMF) indicate that the proposed detection method demonstrates superior performance, offering higher accuracy and demanding fewer computational resources.","2024","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","73","","","","","","","","","","English","","","","WOS:001189428000030","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Conv-Transformer model; Convolutional neural networks; denoising diffusion probability model (DDPM); Employee welfare; feature extraction; Feature extraction; Furnaces; IDENTIFICATION; industrial smelting furnace; Production; semi-molten condition detection; Smelting; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UZI2HJXR","journalArticle","2022","Hu, SC; Cai, WJ; Gao, TJ; Wang, MJ","A Hybrid Transformer Model for Obstructive Sleep Apnea Detection Based on Self-Attention Mechanism Using Single-Lead ECG","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2022.3193169","","Obstructive sleep apnea (OSA) is a widespread sleep disorder that seriously affects human health. Detection of OSA with low cost and high accuracy is of great clinical significance. This study proposes a hybrid transformer model based on self-attention mechanism for OSA detection using single-lead electrocardiogram. To reduce the introduction of expert knowledge, a new method for constructing raw inputs is proposed. The data inputs include the raw electrocardiogram (ECG) signal sequence, R-peak amplitude (RA) sequence, interbeat (RR) interval (RRI) sequence, and RR interval first-order difference (RRID) sequence. Then, a multiperspective channel-attention (MPCA) block is proposed to focus on the contribution of four input signals automatically and extract the fused multiperspective features. These features together with their position encodings were fed into transformer blocks to encode the most important information with self-attention mechanism. Finally, the prediction results were output through the linear layer. The proposed method was verified on the apnea-ECG database. The per-segment classification accuracy reached 0.91 and the area under the receiver operating characteristic (ROC) curve (AUC) was 0.96. The per-recording classification accuracy reached 100% and the mean absolute error (MAE) was 2.71. Our method achieved better classification performance than other state-of-the-art algorithms. The proposed hybrid transformer model is able to detect OSA accurately using single-lead ECG in a manner similar to the detection process by human experts. Our method provides a convenient and precise solution for clinical OSA detection.","2022","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","71","","","","","","","","","","English","","","","WOS:000833791900029","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;31<br/>Total Times Cited:&nbsp;&nbsp;32<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Apnea-electrocardiogram (ECG) database; Deep learning; electrocardiogram; Electrocardiography; Feature extraction; Hidden Markov models; hybrid transformer; obstructive sleep apnea (OSA); Recording; Support vector machines; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H8VICK5X","journalArticle","2024","Sun, YZ; Pang, SC; Zhang, YA","Innovative lithology identification enhancement via the recurrent transformer model with well logging data","GEOENERGY SCIENCE AND ENGINEERING","","2949-8929","10.1016/j.geoen.2024.213015","","In the field of oil and gas exploration and development, accurately predicting lithology is crucial for strategic decision-making. Identifying subsurface rock types helps determine the distribution, quantity, and recoverability of oil and gas reserves, guiding exploratory efforts and increasing the likelihood of successful resource extraction. Our research focuses on enhancing lithology prediction accuracy through the development of the Recurrent Transformer model. This innovative model combines the Transformer architecture with recurrent elements, optimizing the processing of well logging data, inherently comprising time-series information. The recurrent structure effectively learns local contextual information, improving responsiveness to geological variations impacting lithology. Additionally, we integrated the Recurrent Scale-wise Attention (RSA) mechanism into our model, uniquely suited to well logging data. RSA captures and interprets multi-scale information by implementing attention mechanisms at varying scales, enhancing the model's understanding of sequence data. The recursive element within RSA further strengthens the model's ability to process contextual nuances. Key well log curves, including Density (DEN), Acoustic (AC), Gamma-ray (GR), and Compensated Neutron Log (CNL), serve as primary data sources for extracting geological features. These features are input into the Recurrent Transformer, establishing correlations between lithological characteristics and well logging parameters. Comparative analysis with leading-edge models using an experimental dataset revealed the Recurrent Transformer's high prediction accuracy and remarkable generalization capabilities across diverse lithological prediction tasks and geological conditions. This model represents a significant advancement in machine learning for well logging lithology prediction, providing geologists and engineers with a precise and efficient tool, enhancing resource exploration and development quality and reliability. The Recurrent Transformer model showcases the potential of integrating advanced machine learning in geosciences, opening new horizons in oil and gas resource exploration and utilization.","2024-09","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","240","","","","","","","","","","English","","","","WOS:001258260100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Lithology prediction; Logging parameters; Machine learning; PREDICTION; Recurrent transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PTNZ97K2","journalArticle","2024","Minssen, FM; Klemm, J; Steidel, M; Niemi, A","Predicting Vessel Tracks in Waterways for Maritime Anomaly Detection","TRANSACTIONS ON MARITIME SCIENCE-TOMS","","1848-3305","10.7225/toms.v13.n01.002","","Many approaches to vessel track prediction and anomaly detection rely only on a vessel's positional data. This paper examines whether including tide and weather data into the track prediction model improves accuracy. We predict vessel tracks in waterways using a bi-directional Long Short -Term Memory (Bi-LSTM) approach and a transformer model. For this purpose, the boundaries of the Elbe and Weser river waterways are merged with vessel position data. Additionally, tide data, as well as weather information, will be used to train the model. To ascertain whether this additional data improves the accuracy, the models have been trained with and without tide and weather data and evaluated against each other. Furthermore, we have investigate whether the predictions can be used for detecting anomalous vessel behaviour. Our results show that the lowest average error and the best RMSE, MSE, and MAE values have been achieved with the Bi-LSTM, where no tide and weather data have been used for training. We have also found that the transformer model is more accurate than a linear prediction model, which is used as a baseline. In addition, we have shown that deviations between predicted and real tracks can be labelled as anomalous. The results have shown that including tide and weather data does not necessarily improve the predictions. Adding data with a low information content to train a machine learning model may introduce noise or bias into the model. We believe that this phenomenon explains our results. Thereby this paper shows that simply adding this data to train the track prediction model may not enhance the overall accuracy.","2024-04","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","1","13","","","","","","","","","","English","","","","WOS:001275502400005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","AIS data; Anomaly detection; Bi-directional LSTM; IMPACT; SHANGHAI; SOILS; Tide data; Transformer model; URBANIZATION; Vessel track prediction; Weather data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"62DYPW8Y","journalArticle","2023","Wang, D; Yang, RH; Wang, X; Li, SD; Tan, JX; Zhang, SQ; Wei, SY; Wu, ZY; Chen, C; Yang, XX","Evaluation of deep learning algorithms for landslide susceptibility mapping in an alpine-gorge area: a case study in Jiuzhaigou County","JOURNAL OF MOUNTAIN SCIENCE","","1672-6316","10.1007/s11629-022-7326-5","","With its high mountains, deep valleys, and complex geological formations, the Jiuzhaigou County has the typical characteristics of a disaster-prone mountainous region in southwestern China. On August 8, 2017, a strong Ms 7.0 earthquake occurred in this region, causing some of the mountains in the area to become loose and cracked. Therefore, a survey and evaluation of landslides in this area can help to reveal hazards and take effective measures for subsequent disaster management. However, different evaluation models can yield different spatial distributions of landslide susceptibility, and thus, selecting the appropriate model and performing the optimal combination of parameters is the most effective way to improve susceptibility evaluation. In order to construct an evaluation indicator system suitable for Jiuzhaigou County, we extracted 12 factors affecting the occurrence of landslides, including slope, elevation and slope surface, and made samples. At the core of the transformer model is a self-attentive mechanism that enables any two of the features to be interlinked, after which feature extraction is performed via a forward propagation network (FFN). We exploited its coding structure to transform it into a deep learning model that is more suitable for landslide susceptibility evaluation. The results show that the transformer model has the highest accuracy (86.89%), followed by the random forest and support vector machine models (84.47% and 82.52%, respectively), and the logistic regression model achieves the lowest accuracy (79.61%). Accordingly, this deep learning model provides a new tool to achieve more accurate zonation of landslide susceptibility in Jiuzhaigou County.","2023-02","2025-02-26 20:37:03","2025-02-26 20:37:03","","484-500","","2","20","","","","","","","","","","English","","","","WOS:000924142300014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;16<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","CERTAINTY FACTOR; DEBRIS FLOWS; DECISION TREE; Deep learning; ENTROPY; Forest; FREQUENCY RATIO; GIS; HIERARCHICAL PROCESS; Jiuzhaigou; Landslide susceptibility; LOGISTIC-REGRESSION; MACHINE; SPATIAL-DISTRIBUTION; Transformer Model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L7AIGQTV","journalArticle","2024","Zhou, Y; Mao, ZH; Mao, ZX; Zhang, XL; Zhang, LW; Huang, HQ","Benthic Mapping of Coral Reef Areas at Varied Water Depths Using Integrated Active and Passive Remote Sensing Data and Novel Visual Transformer Models","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2024.3468380","","In recent years, various coral reef retrieval methods have experienced considerable progress due to a variety of observational instruments and innovative parameter calculation techniques. However, these labor-intensive methods are deficient in handling high-precision remote sensing mapping of coral reef benthic environments, facing challenges, including enhancing the robustness of scaled coral reef retrieval against varying water depths and complex water column conditions. To overcome these limitations, we propose a novel method for coral reef benthic mapping. Our method primarily consists of two central components: water depth extraction and coral reef information acquisition. Accurate bathymetry is critical for coral reef remote sensing inversion. To obtain more precise water depth, we propose the Bathymetry Transformer model. Our Bathymetry Transformer model aggregates vast amounts of active and passive remote sensing data, generates accurate bathymetry (with a 0.375-m RMSE, ranging from 0- to 12-m water depth) that eliminates the need for in situ examinations, and maintains a harmonious balance between greater bathymetry precision and finer spatial resolution. Based on this, water column corrections are then applied, and the results derived from various active and passive remote sensing processes, along with their respective band calculation outcomes, are fed into the proposed coral reef Transformer (CR Transformer) model to generate high-accuracy coral reef benthic mapping results. Copious experimental outcomes affirm that our CR Transformer surpasses current state-of-the-art (SOTA) methods in computational efficiency and results accuracy. Impressively, the CR Transformer achieves a notable mean intersection over union (mIoU) of 91.25% and an accuracy of 95.71% on the validation dataset.","2024","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","62","","","","","","","","","","English","","","","WOS:001340858900015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Accuracy; Bathymetry; CLASSIFICATION; coral reef; Marine vegetation; Oceans; OPTICAL-PROPERTIES; PlanetScope; remote sensing; Remote sensing; Sea surface; Transformers; visual transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LI9PRT95","journalArticle","2022","Amanambu, AC; Mossa, J; Chen, YH","Hydrological Drought Forecasting Using a Deep Transformer Model","WATER","","2073-4441","10.3390/w14223611","","Hydrological drought forecasting is essential for effective water resource management planning. Innovations in computer science and artificial intelligence (AI) have been incorporated into Earth science research domains to improve predictive performance for water resource planning and disaster management. Forecasting of future hydrological drought can assist with mitigation strategies for various stakeholders. This study uses the transformer deep learning model to forecast hydrological drought, with a benchmark comparison with the long short-term memory (LSTM) model. These models were applied to the Apalachicola River, Florida, with two gauging stations located at Chattahoochee and Blountstown. Daily stage-height data from the period 1928-2022 were collected from these two stations. The two deep learning models were used to predict stage data for five different time steps: 30, 60, 90, 120, and 180 days. A drought series was created from the forecasted values using a monthly fixed threshold of the 75th percentile (75Q). The transformer model outperformed the LSTM model for all of the timescales at both locations when considering the following averages: MSE = 0.11, MAE = 0.21, RSME = 0.31, and R-2 = 0.92 for the Chattahoochee station, and MSE = 0.06, MAE = 0.19, RSME = 0.23, and R-2 = 0.93 for the Blountstown station. The transformer model exhibited greater accuracy in generating the same drought series as the observed data after applying the 75Q threshold, with few exceptions. Considering the evaluation criteria, the transformer deep learning model accurately forecasts hydrological drought in the Apalachicola River, which could be helpful for drought planning and mitigation in this area of contested water resources, and likely has broad applicability elsewhere.","2022-11","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","22","14","","","","","","","","","","English","","","","WOS:000887727100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;25<br/>Total Times Cited:&nbsp;&nbsp;27<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","AI; APALACHICOLA RIVER; deep learning; forecast; hydrological drought; INDEX; LIMITATIONS; LSTM; PREDICTION; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HLSBNSZZ","journalArticle","2023","Lu, P; Wang, CY; Hagenah, J; Ghiasi, S; Zhu, TT; Thwaites, L; Clifton, DA; VITAL Consortium","Improving Classification of Tetanus Severity for Patients in Low-Middle Income Countries Wearing ECG Sensors by Using a CNN-Transformer Network","IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING","","0018-9294","10.1109/TBME.2022.3216383","","is a life-threatening infectious dis-ease, which is still common in low-and middle-income countries, including in Vietnam. This disease is charac-terized by muscle spasm and in severe cases is compli-cated by autonomic dysfunction. Ideally continuous vital sign monitoring using bedside monitors allows the prompt detection of the onset of autonomic nervous system dys-function or avoiding rapid deterioration. Detection can be improved using heart rate variability analysis from ECG sig-nals. Recently, characteristic ECG and heart rate variability features have been shown to be of value in classifying tetanus severity. However, conventional manual analysis of ECG is time-consuming. The traditional convolutional neu-ral network (CNN) has limitations in extracting the global context information, due to its fixed-sized kernel filters. In this work, we propose a novel hybrid CNN-Transformer model to automatically classify tetanus severity using tetanus monitoring from low-cost wearable sensors. This model can capture the local features from the CNN and the global features from the Transformer. The time series imag-ing -spectrogram -is transformed from one-dimensional ECG signal and input to the proposed model. The CNN-Transformer model outperforms state-of-the-art methods in tetanus classification, achieves results with a F1 score of 0.82 +/- 0.03, precision of 0.94 +/- 0.03, recall of 0.73 +/- 0.07, specificity of 0.97 +/- 0.02, accuracy of 0.88 +/- 0.01 and AUC of 0.85 +/- 0.03. In addition, we found that Random Forest with enough manually selected features can be comparable with the proposed CNN-Transformer model.","2023-04","2025-02-26 20:37:03","2025-02-26 20:37:03","","1340-1350","","4","70","","","","","","","","","","English","","","","WOS:000967272000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Classification; CNN; electrocardiogram; spectrogram; tetanus; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GIH55TA4","journalArticle","2024","Li, A; Li, Y; Xu, YY; Li, XM; Zhang, CM","Multi-scale convolution enhanced transformer for multivariate long-term time series forecasting","NEURAL NETWORKS","","0893-6080","10.1016/j.neunet.2024.106745","","In data analysis and forecasting, particularly for multivariate long-term time series, challenges persist. The Transformer model in deep learning methods has shown significant potential in time series forecasting. The Transformer model's dot-product attention mechanism, however, due to its quadratic computational complexity, impairs training and forecasting efficiency. In addition, the Transformer architecture has limitations in modeling local features and dealing with multivariate cross-dimensional dependency relationship. In this article, a Multi-Scale Convolution Enhanced Transformer model (MSCformer) is proposed for multivariate longterm time series forecasting. As an alternative to modeling the time series in its entirety, a segmentation strategy is designed to convert the input original series into segmented forms with different lengths, then process time series segments using a new constructed multi-Dependency Aggregation module. This multi- Scale segmentation approach reduces the computational complexity of the attention mechanism part in subsequent models, and for each segment of length corresponds to a specific time scale, it also ensures that each segment retains the semantic information of the data sequence level, thereby comprehensively utilizing the multi-scale information of the data while more accurately capturing the real dependency of the time series. The Multi-Dependence Aggregate module captures both cross-temporal and cross-dimensional dependencies of multivariate long-term time series and compensates for local dependencies within the segments thereby captures local series features comprehensively and addressing the issue of insufficient information utilization. MSCformer synthesizes dependency information extracted from various temporal segments at different scales and reconstructs future series using linear layers. MSCformer exhibits higher forecasting accuracy, outperforming existing methods in multiple domains including energy, transportation, weather, electricity, disease and finance.","2024-12","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","180","","","","","","","","","","English","","","","WOS:001327845600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Attention; Forecasting; Long-term time series; Multi-scale segmentation; Multivariate time series; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KZ786YYT","journalArticle","2024","Xiong, YF; Shi, QL; Shen, LX; Chen, C; Lu, W; Xu, C","A hybrid neural network based on KF-SA-Transformer for SOC prediction of lithium-ion battery energy storage systems","FRONTIERS IN ENERGY RESEARCH","","2296-598X","10.3389/fenrg.2024.1424204","","With the widespread application of energy storage stations, BMS has become an important subsystem in modern power systems, leading to an increasing demand for improving the accuracy of SOC prediction in lithium-ion battery energy storage systems. Currently, common methods for predicting battery SOC include the Ampere-hour integration method, open circuit voltage method, and model-based prediction techniques. However, these methods often have limitations such as single-variable research, complex model construction, and inability to capture real-time changes in SOC. In this paper, a novel prediction method based on the KF-SA-Transformer model is proposed by combining model-based prediction techniques with data-driven methods. By using temperature, voltage, and current as inputs, the limitations of single-variable studies in the Ampere-hour integration method and open circuit voltage method are overcome. The Transformer model can overcome the complex modeling process in model-based prediction techniques by implementing a non-linear mapping between inputs and SOC. The presence of the Kalman filter can eliminate noise and improve data accuracy. Additionally, a sparse autoencoder mechanism is integrated to optimize the position encoding embedding of input vectors, further improving the prediction process. To verify the effectiveness of the algorithm in predicting battery SOC, an open-source lithium-ion battery dataset was used as a case study in this paper. The results show that the proposed KF-SA-Transformer model has superiority in improving the accuracy and reliability of battery SOC prediction, playing an important role in the stability of the grid and efficient energy allocation.","2024-06-21","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","12","","","","","","","","","","English","","","","WOS:001262252700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","Kalman filter; lithium-ion battery; MODEL; sparse autoencoder; state-of-charge; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KFTY85AV","journalArticle","2023","Sellner, MS; Mahmoud, AH; Lill, MA","Efficient virtual high-content screening using a distance-aware transformer model","JOURNAL OF CHEMINFORMATICS","","1758-2946","10.1186/s13321-023-00686-z","","Molecular similarity search is an often-used method in drug discovery, especially in virtual screening studies. While simple one- or two-dimensional similarity metrics can be applied to search databases containing billions of molecules in a reasonable amount of time, this is not the case for complex three-dimensional methods. In this work, we trained a transformer model to autoencode tokenized SMILES strings using a custom loss function developed to conserve similarities in latent space. This allows the direct sampling of molecules in the generated latent space based on their Euclidian distance. Reducing the similarity between molecules to their Euclidian distance in latent space allows the model to perform independent of the similarity metric it was trained on. While we test the method here using 2D similarity as proof-of-concept study, the algorithm will enable also high-content screening with time-consuming 3D similarity metrics. We show that the presence of a specific loss function for similarity conservation greatly improved the model's ability to predict highly similar molecules. When applying the model to a database containing 1.5 billion molecules, our model managed to reduce the relevant search space by 5 orders of magnitude. We also show that our model was able to generalize adequately when trained on a relatively small dataset of representative structures. The herein presented method thereby provides new means of substantially reducing the relevant search space in virtual screening approaches, thus highly increasing their throughput. Additionally, the distance awareness of the model causes the efficiency of this method to be independent of the underlying similarity metric.","2023-02-08","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","1","15","","","","","","","","","","English","","","","WOS:000928725400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Deep learning; FINGERPRINT SIMILARITY SEARCH; REPRESENTATION; Similarity search; Transformer model; Virtual screening; ZINC","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8FHR3RZJ","journalArticle","2023","Hu, SC; Liu, J; Yang, R; Wang, YN; Wang, AG; Li, KZ; Liu, WX; Yang, CW","Exploring the Applicability of Transfer Learning and Feature Engineering in Epilepsy Prediction Using Hybrid Transformer Model","IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING","","1534-4320","10.1109/TNSRE.2023.3244045","","Objective: Epilepsy prediction algorithms offer patients with drug-resistant epilepsy a way to reduce unintended harm from sudden seizures. The purpose of this study is to investigate the applicability of transfer learning (TL) technique and model inputs for different deep learning (DL) model structures, which may provide a reference for researchers to design algorithms. Moreover, we also attempt to provide a novel and precise Transformer-based algorithm. Methods: Two classical feature engineering methods and the proposed method which consists of various EEG rhythms are explored, then a hybrid Transformer model is designed to evaluate the advantages over pure convolutional neural networks (CNN)-based models. Finally, the performances of two model structures are analyzed utilizing patient-independent approach and two TL strategies. Results: We tested our method on the CHB-MIT scalp EEG database, the results showed that our feature engineering method gains a significant improvement in model performance and is more suitable for Transformer-based model. In addition, the performance improvement of Transformer-based model utilizing fine-tuning strategies is more robust than that of pure CNN-based model, and our model achieved an optimal sensitivity of 91.7% with false positive rate (FPR) of 0.00/h. Conclusion: Our epilepsy prediction method achieves excellent performance and demonstrates its advantage over pure CNN-based structure in TL. Moreover, we find that the information contained in the gamma ( $\gamma$ ) rhythm is helpful for epilepsy prediction. Significance: We propose a precise hybrid Transformer model for epilepsy prediction. The applicability of TL and model inputs is also explored for customizing personalized models in clinical application scenarios.","2023","2025-02-26 20:37:03","2025-02-26 20:37:03","","1321-1332","","","31","","","","","","","","","","English","","","","WOS:000937151800003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;25<br/>Total Times Cited:&nbsp;&nbsp;26<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Analytical models; Brain modeling; CLASSIFICATION; EEG SIGNALS; Electroencephalography; Epilepsy; Epilepsy prediction; feature engineering; Frequency-domain analysis; hybrid transformer; NETWORK; Predictive models; scalp electroencephalogram (sEEG); SEIZURE PREDICTION; transfer learning (TL); Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KFKBF7UH","journalArticle","2022","Chen, YB; Chen, XM; Xu, AL; Sun, Q; Peng, XY","A hybrid CNN-Transformer model for ozone concentration prediction","AIR QUALITY ATMOSPHERE AND HEALTH","","1873-9318","10.1007/s11869-022-01197-w","","Ozone concentration has come to the fore as an important air quality indicator. However, ozone concentrations vary with meteorological conditions and the presence of other pollutants such as sulfur dioxide (SO2), nitrogen oxides (NOx), and carbon monoxide (CO). These relationships are nonlinear and dynamic, which makes it difficult for existing statistical and deep learning methods, e.g., autoregressive integrated moving average model (ARIMA), convolutional neural network (CNN), and long short-term memory network (LSTM) to fully capture the interaction between these factors and provide accurate prediction results. To solve this problem, we propose a hybrid model based on a CNN and a Transformer model called CNN-Transformer to predict the ozone concentration. CNN layers extract valuable information on feature dimensions, compensating for the Transformer encoder's limited ability to mine information from a multivariate dataset. Using multi-head attention layers between different encoder layers effectively improves the prediction accuracy, indicating that the information captured by the attention mechanism between global time series data effectively promotes the forecasting precision of our model. According to the data obtained from 14 monitoring stations in Beijing between 1 January 2014 and 31 July 2021, we take both meteorological factors, including wind speed, wind direction, minimum and maximum temperatures, and other environmental variables, i.e., NO, NO2, SO2, and CO into account as the predictors. Experimental results show that our proposed CNN-Transformer model outperforms other models, achieving excellent performance on both short-term forecast with an RMSE value of 7.75 and long-term forecast with an RMSE value of 16.27.","2022-09","2025-02-26 20:37:03","2025-02-26 20:37:03","","1533-1546","","9","15","","","","","","","","","","English","","","","WOS:000785922700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;31<br/>Total Times Cited:&nbsp;&nbsp;32<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","AIR; CNN; Deep learning; HEALTH; Ozone concentration prediction; PM2.5; Transformer-based model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZW8AL9DB","journalArticle","2021","Sóskuthy, M","Evaluating generalised additive mixed modelling strategies for dynamic speech analysis","JOURNAL OF PHONETICS","","0095-4470","10.1016/j.wocn.2020.101017","","Generalised additive mixed models (GAMMs) are increasingly popular in dynamic speech analysis, where the focus is on measurements with temporal or spatial structure such as formant, pitch or tongue contours. GAMMs provide a range of tools for dealing with the non-linear contour shapes and complex hierarchical organisation characteristic of such data sets. This, however, means that analysts are faced with non-trivial choices, many of which have a serious impact on the statistical validity of their analyses. This paper presents type I and type II error simulations to help researchers make informed decisions about modelling strategies when using GAMMs to analyse phonetic data. The simulations are based on two real data sets containing F2 and pitch contours, and a simulated data set modelled after the F2 data. They reflect typical scenarios in dynamic speech analysis. The main emphasis is on (i) dealing with dependencies within contours and higher-level units using random structures and other tools, and (ii) strategies for significance testing using GAMMs. The paper concludes with a small set of recommendations for fitting GAMMs, and provides advice on diagnosing issues and tailoring GAMMs to specific data sets. It is also accompanied by a GitHub repository including a tutorial on running type I error simulations for existing data sets: https://github.com/soskuthy/gamm_strategies. (C) 2020 Elsevier Ltd. All rights reserved.","2021-01","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","84","","","","","","","","","","English","","","","WOS:000617782300003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;45<br/>Total Times Cited:&nbsp;&nbsp;49<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","BACK; COMPONENTS; Dynamic speech analysis; FRONT; Generalised additive mixed models; Random effects; Significance testing; SOUTHERN BRITISH; TRAJECTORIES; Type I/II error simulations; VOWELS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8BUK4N4W","journalArticle","2024","Tankus, A; Lustig-Barzelay, Y; Gurevitch, G; Faust-Socher, A; Strauss, I","Neuronal Encoding of Speech Features in the Human Thalamus in Parkinson's Disease and Essential Tremor Patients","NEUROSURGERY","","0148-396X","10.1227/neu.0000000000002665","","BACKGROUND AND OBJECTIVES: The human thalamus is known, from stimulation studies and functional imaging, to participate in high-level language tasks. The goal of this study is to find whether and how speech features, in particular, vowel phonemes, are encoded in the neuronal activity of the thalamus, and specifically of the left ventralis intermediate nucleus (Vim), during speech production, perception, and imagery. METHODS: In this cross-sectional study, we intraoperatively recorded single neuron activity in the left Vim of eight neurosurgical patients with Parkinson's disease (PD) (n = 4) or essential tremor (n =4) undergoing implantation of deep brain stimulation (n = 3) or radiofrequency lesioning (n = 5) while patients articulated the five monophthongal vowel sounds. RESULTS: In this article, we report that single neurons in the left Vim encode individual vowel phonemes mainly during speech production but also during perception and imagery. They mainly use one of two encoding schemes: broad or sharp tuning, with a similar percentage of units each. Sinusoidal tuning has been demonstrated in almost half of the broadly tuned units. Patients with PD had a lower percentage of speech-related units in each aspect of speech(production, perception, and imagery), a significantly lower percentage of broadly tuned units, and significantly lower median firing rates during speech production and perception, but significantly higher rates during imagery, than patients with essential tremor. CONCLUSION: The results suggest that the left Vim uses mixed encoding schemes for speech features. Our findings explain, at the single neuron level, why deep brain stimulation and radiofrequency lesioning of the left Vim are likely to cause speech side effects. Moreover, they may indicate that speech-related units in the left Vim of patients with PD maybe degraded even in the subclinical phase.","2024-02","2025-02-26 20:37:03","2025-02-26 20:37:03","","307-316","","2","94","","","","","","","","","","English","","","","WOS:001155432100017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","Articulation; Essential tremor; Human neurophysiology; Parkinson's disease; Single unit recording; Speech encoding; Ventralis intermediate nucleus (Vim) of the thalamus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7CU42B6C","journalArticle","2024","Bolt, E; Giroud, N","Neural encoding of linguistic speech cues is unaffected by cognitive decline, but decreases with increasing hearing impairment","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-69602-1","","The multivariate temporal response function (mTRF) is an effective tool for investigating the neural encoding of acoustic and complex linguistic features in natural continuous speech. In this study, we investigated how neural representations of speech features derived from natural stimuli are related to early signs of cognitive decline in older adults, taking into account the effects of hearing. Participants without (n=25\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$n = 25$$\end{document}) and with (n=19\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$n = 19$$\end{document}) early signs of cognitive decline listened to an audiobook while their electroencephalography responses were recorded. Using the mTRF framework, we modeled the relationship between speech input and neural response via different acoustic, segmented and linguistic encoding models and examined the response functions in terms of encoding accuracy, signal power, peak amplitudes and latencies. Our results showed no significant effect of cognitive decline or hearing ability on the neural encoding of acoustic and linguistic speech features. However, we found a significant interaction between hearing ability and the word-level segmentation model, suggesting that hearing impairment specifically affects encoding accuracy for this model, while other features were not affected by hearing ability. These results suggest that while speech processing markers remain unaffected by cognitive decline and hearing loss per se, neural encoding of word-level segmented speech features in older adults is affected by hearing loss but not by cognitive decline. This study emphasises the effectiveness of mTRF analysis in studying the neural encoding of speech and argues for an extension of research to investigate its clinical impact on hearing loss and cognition.","2024-08-17","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","1","14","","","","","","","","","","English","","","","WOS:001292901700046","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","AGE; Auditory speech processing; Cognitive decline; DEMENTIA; Electroencephalography; INTELLIGENCE; LANGUAGE; Linguistic speech processing; Natural continuous speech; NOISE; OLDER-ADULTS; REPRESENTATION; RESPONSES; Temporal response function","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4WKC32WH","journalArticle","2024","Maffei, MF; Chenausky, K; Haenssler, A; Abbiati, C; Tager-Flusberg, H; Green, JR","Exploring Motor Speech Disorders in Low and Minimally Verbal Autistic Individuals An Auditory-Perceptual Analysis","AMERICAN JOURNAL OF SPEECH-LANGUAGE PATHOLOGY","","1058-0360","10.1044/2024_AJSLP-23-00237","","Purpose: Motor deficits are widely documented among autistic individuals, and speech characteristics consistent with a motor speech disorder have been reported in prior literature. We conducted an auditory-perceptual analysis of speech production skills in low and minimally verbal autistic individuals as a step toward clarifying the nature of speech production impairments in this population and the potential link between oromotor functioning and language development. Method: Fifty-four low or minimally verbal autistic individuals aged 4-18 years were video-recorded performing nonspeech oromotor tasks and producing phonemes, syllables, and words in imitation. Three trained speech-language pathologists provided auditory perceptual ratings of 11 speech features reflecting speech subsystem performance and overall speech production ability. The presence, attributes, and severity of signs of oromotor dysfunction were analyzed, as were relative performance on nonspeech and speech tasks and correlations between perceptual speech features and language skills. Results and Conclusions: Our findings provide evidence of a motor speech disorder in this population, characterized by perceptual speech features including reduced intelligibility, decreased consonant and vowel precision, and impairments of speech coordination and consistency. Speech deficits were more associated with articulation than with other speech subsystems. Speech production was more impaired than nonspeech oromotor abilities in a subgroup of the sample. Oromotor deficits were significantly associated with expressive and receptive language skills. Findings are interpreted in the context of known characteristics of the pediatric motor speech disorders childhood apraxia of speech and childhood dysarthria. These results, if replicated in future studies, have significant potential to improve the early detection of language impairments, inform the development of speech and language interventions, and aid in the identification of neurobiological mechanisms influencing communication development.","2024-05","2025-02-26 20:37:03","2025-02-26 20:37:03","","1485-1503","","3","33","","","","","","","","","","English","","","","WOS:001239450900026","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;114</p>","","","ASPERGER SYNDROME; CEREBRAL-PALSY; CHILDHOOD APRAXIA; DEVELOPMENTAL APRAXIA; EXPRESSIVE LANGUAGE; HIGH-FUNCTIONING AUTISM; KINEMATIC ANALYSIS; LANGUAGE IMPAIRMENT; ORAL-MOTOR; SPECTRUM DISORDER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SK6DGGPZ","journalArticle","2022","Gao, XJ; Ma, KF; Yang, HL; Wang, K; Fu, B; Zhu, YW; She, XJ; Cui, B","A rapid, non-invasive method for fatigue detection based on voice information","FRONTIERS IN CELL AND DEVELOPMENTAL BIOLOGY","","2296-634X","10.3389/fcell.2022.994001","","Fatigue results from a series of physiological and psychological changes due to continuous energy consumption. It can affect the physiological states of operators, thereby reducing their labor capacity. Fatigue can also reduce efficiency and, in serious cases, cause severe accidents. In addition, it can trigger pathological-related changes. By establishing appropriate methods to closely monitor the fatigue status of personnel and relieve the fatigue on time, operation-related injuries can be reduced. Existing fatigue detection methods mostly include subjective methods, such as fatigue scales, or those involving the use of professional instruments, which are more demanding for operators and cannot detect fatigue levels in real time. Speech contains information that can be used as acoustic biomarkers to monitor physiological and psychological statuses. In this study, we constructed a fatigue model based on the method of sleep deprivation by collecting various physiological indexes, such as P300 and glucocorticoid level in saliva, as well as fatigue questionnaires filled by 15 participants under different fatigue procedures and graded the fatigue levels accordingly. We then extracted the speech features at different instances and constructed a model to match the speech features and the degree of fatigue using a machine learning algorithm. Thus, we established a method to rapidly judge the degree of fatigue based on speech. The accuracy of the judgment based on unitary voice could reach 94%, whereas that based on long speech could reach 81%. Our fatigue detection method based on acoustic information can easily and rapidly determine the fatigue levels of the participants. This method can operate in real time and is non-invasive and efficient. Moreover, it can be combined with the advantages of information technology and big data to expand its applicability.","2022-09-13","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","10","","","","","","","","","","English","","","","WOS:000884558300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","acoustic biomarkers; DISEASE; fatigue detection; fatigue scale; HAIR; IDENTIFICATION; MULTIPLE-SCLEROSIS; RECOGNITION; SALIVARY CORTISOL; SPEECH; speech features; STRESS; vocal print","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UK3W39R2","journalArticle","2021","Endo, S; Tanida, K","Detection of special scams by emotion analysis","IEICE COMMUNICATIONS EXPRESS","","2187-0136","10.1587/comex.2021COL0025","","Telephone scams called ""special scams"" have become a major problem, with people being defrauded of nearly 30 billion yen every year in Japan. In this study, we used emotion analysis techniques based on speech analysis to detect whether victims were being deceived by analyzing multiple emotional parameters of victims in a special scam. In the verification, we first clarified the characteristics of the emotions generated in victims by two scam methods. Next, we improved the accuracy of detecting the risk of a victim being deceived by limiting the analysis section.","2021","2025-02-26 20:37:03","2025-02-26 20:37:03","","985-990","","12","10","","","","","","","","","","English","","","","WOS:000740523400018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;14</p>","","","emotion; emotion analysis; special scam; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S69DJWEF","journalArticle","2022","Egas-López, JV; Balogh, R; Imre, N; Hoffmann, I; Szabó, MK; Tóth, L; Pákáski, M; Kálmán, J; Gosztolya, G","Automatic screening of mild cognitive impairment and Alzheimer's disease by means of posterior-thresholding hesitation representation","COMPUTER SPEECH AND LANGUAGE","","0885-2308","10.1016/j.csl.2022.101377","","Dementia is a chronic or progressive clinical syndrome, characterized by the deterioration of problem-solving skills, memory and language. In Mild Cognitive Impairment (MCI), which is often considered to be the prodromal stage of dementia, there is also a subtle deterioration of these cognitive functions; however, it does not affect the patients' ability to carry out simple everyday activities. The timely identification of MCI could provide more effective therapeutic interventions to delay progression, and to postpone the possible conversion to dementia. Since language changes in MCI are present even before the manifestation of other distinctive cognitive symptoms, a non-invasive way of early automatic screening could be the use of speech analysis. Earlier, our research team developed a set of temporal speech parameters that mainly focus on the amount of silence and hesitation, and demonstrated its applicability for MCI detection. However, for the automatic extraction of these attributes, the execution of a full Automatic Speech Recognition (ASR) process is necessary. In this study we propose a simpler feature extraction approach, which still quantifies the amount of silence and hesitation in the speech of the subject, but does not require the application of a full ASR system. We experimentally demonstrate that this approach, operating directly on the frame-level output of a HMM/DNN hybrid acoustic model, is capable of extracting attributes as useful as the ASR-based temporal parameter extraction workflow was able to. That is, on our corpus consisting of 25 healthy controls, 25 MCI and 25 mild AD subjects, we achieve a (three-class) classification accuracy of 70.7%, an F-measure score of 89.6 and a mean AUC score of 0.804. We also show that this approach can be applied on simpler, context-independent acoustic states with only a slight degradation of MCI and mild Alzheimer's detection performance. Lastly, we investigate the usefulness of the three speaker tasks which are present in our recording protocol.","2022-09","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","75","","","","","","","","","","English","","","","WOS:000821456000005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","Alzheimer's disease; Automatic speech recognition; CLASSIFICATION; Dementia; DEMENTIA; DIAGNOSIS; Feature extraction; LANGUAGE PERFORMANCE; Mild cognitive impairment; SPONTANEOUS SPEECH; Temporal speech parameters","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VIM9KH7A","journalArticle","2022","Ting, HN; Choo, YM; Kamar, AA","Classification of asphyxia infant cry using hybrid speech features and deep learning models","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2022.118064","","Single speech feature such as Mel-Frequency Cepstral Coefficient (MFCC) has been used in most of the studies to classify asphyxia cry among infants. Other speech features such as Chromagram, Mel-scaled Spectrogram, Spectral Contrast and Tonnetz have not been reported in any study related to the classification of asphyxia cry. The study investigated the use of hybrid features of MFCC, Chromagram, Mel-scaled Spectrogram, Spectral Contrast and Tonnetz and deep learning models in classifying asphyxia cry. Deep learning models such as Deep Neural Network (DNN) and Convolutional Neural Network (CNN) were used to classify infant cry between normal/non-asphyxia and asphyxia. The performance of the deep learning models was compared using concatenated hybrid features and single feature of MFCC. The Baby Chillanto Database was used in this study. CNN model performed better than DNN models when MFCC was used. DNN models performed better with hybrid features compared to that with single feature of MFCC. DNN with multiple hidden layers achieved an accuracy of 100% in classifying normal and asphyxia cry, and 99.96% for non-asphyxia and asphyxia cry when the hybrid features were used.","2022-12-01","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","208","","","","","","","","","","English","","","","WOS:000878501900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;16<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Asphyxia; Convolutional Neural Network; Deep Neural Network; Hybrid features; Infant cry","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RSSS7GBM","journalArticle","2022","Wangler, J; Jansky, M","Team players or lone fighters? Importance and utilization of practice staff in primary care dementia detection","ZEITSCHRIFT FUR EVIDENZ FORTBILDUNG UND QUALITAET IM GESUNDHEITSWESEN","","1865-9217","10.1016/j.zefq.2021.12.009","","Background: General practitioners (GP) face major challenges in everyday practice when it comes to identifying dementia cases as early as possible under the condition of time and resource constraints. The involvement of the practice staff promises decisive advantages in detection and diagnosis. So far, there has been a lack of studies exploring the extent to which non-medical practice employees in general practices are integrated into dementia detection, what experiences they have had and how they assess their own potential to contribute to more efficient dementia detection. Methods: Between August 2020 and August 2021, a total of 64 semi-structured, audio-technically recorded individual / expert interviews were conducted with non-medical practice employees (medical assistants) in general practices in all German federal states (four interviewees per federal state). The interview transcripts were evaluated using a qualitative, structuring content analysis according to Mayring (Software MAXQDA 2020).Results: The GP team members show a high degree of willingness and motivation to support the doctor in identifying and diagnosing dementia; situations have been reported where their assistance has led to an earlier identification of people with dementia. Observation and detection of dementia patients are rarely based on systematic criteria. On the whole, only some GPs entrust their staff with tasks like this. A large portion of the interviewees expressed considerable uncertainty regarding the assessment of possible signs of incipient dementia, which corresponds to the fact that only a minority of the interviewees have ever completed further training with a focus on dementia.Conclusions: Practice staff can provide invaluable support when it comes to the timely and consistent detection of incipient dementia in general practice. In addition to sensitizing GPs and optimizing practice management, targeted training with regard to geriatric issues will be instrumental in achieving this. Accordingly, more advanced training formats should be developed that are tailored to the perspective of practice employees and convey important dementia-specific diagnostics, action and communication skills.","2022-04","2025-02-26 20:37:03","2025-02-26 20:37:03","","75-83","","","169","","","","","","","","","","English","","","","WOS:000805275700008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Dementia care; Dementia diagnostics; Early detection; EARLY-DIAGNOSIS; FAMILY PHYSICIANS; General practitioner; GENERAL-PRACTITIONERS; GUIDELINES; PERSPECTIVES; Practice staff","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XWJZFJGP","journalArticle","2023","Kefalas, T; Fotiadou, E; Georgopoulos, M; Panagakis, Y; Ma, PC; Petridis, S; Stafylakis, T; Pantic, M","KAN-AV dataset for audio-visual face and speech analysis in the wild","IMAGE AND VISION COMPUTING","","0262-8856","10.1016/j.imavis.2023.104839","","Human-computer interaction is becoming increasingly prevalent in daily life with the adoption of intelligent devices. These devices must be capable of interacting in diverse settings, such as environments with noise, music and differing illumination and occlusion conditions. They must also interact with a variety of end users across ages and backgrounds. Therefore, the machine learning community needs in-the-wild multi-modal datasets to develop models for face and speech analysis so that they can be applicable in most real world scenarios. However, most existing audio and audio-visual databases are captured in controlled conditions with few or no age and kinship labels. In this paper, we introduce the KAN-AV dataset which contains 98 h of audio-visual data from 970 identities across ages. Two thirds of the identities have kin relations in the dataset. The dataset is manually annotated with labels for kinship, age, and gender and is intended to drive future research in face and speech analysis.","2023-12","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","140","","","","","","","","","","English","","","","WOS:001107197500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;89</p>","","","Age-invariant; Audio-visual; Cross-modal matching; DATABASE; FAMILIES; KAN-AV; Kinship verification; RECOGNITION; REPRESENTATIONS; Speaker verification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EI3RYFSY","journalArticle","2021","Jian, TY; Peng, YZ; Peng, WL; Yang, Z","Research on LSTM+Attention Model of Infant Cry Classification","JOURNAL OF ROBOTICS NETWORKING AND ARTIFICIAL LIFE","","2352-6386","10.2991/jrnal.k.210922.013","","According to the different emotional needs of infants, the effective acquisition of frame-level speech features is realized, and the infant speech emotion recognition model based on the improved Long- and Short-Term Memory (LSTM) network is established. The frame-level speech features are used instead of the traditional statistical features to preserve the temporal relationships in the original speech, and the traditional forgetting and input gates are transformed into attention gates by introducing an attention mechanism, to improve the performance of speech emotion recognition, the depth attention gate is calculated according to the self-defined depth strategy. The results show that, in Pau Aibo Children's emotional data corpus and baby crying emotional needs database, compared with the traditional LSTM based model, the recall rate and F1-score of this model are 3.14%, 5.50%, 1.84% and 5.49% higher, respectively, compared with the traditional model based on LSTM and gated recurrent unit, the training time is shorter and the speech emotion recognition rate of baby is higher. (C) 2021 The Authors. Published by Atlantis Press International B.V.","2021-12","2025-02-26 20:37:03","2025-02-26 20:37:03","","218-223","","3","8","","","","","","","","","","English","","","","WOS:000747752400013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Children's emotional; deep attention gate; EMOTION; frame-level speech feature; long- and short-term memory (LSTM); SYSTEM; time-sequence relationship","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ME95YRP4","journalArticle","2024","Zainal, NA; Asnawi, AL; Jusoh, AZ; Ibrahim, SN; Ramli, HAM","INTEGRATION OF MFCCS AND CNN FOR MULTICLASS STRESS SPEECH CLASSIFICATION ON UNSCRIPTED DATASET","IIUM ENGINEERING JOURNAL","","1511-788X","10.31436/iiumej.v25i2.3207","","Stress is an interaction between individuals and their environment, where perceived threats can lead to serious consequences if prolonged and consistently linked to adverse physical and mental health outcomes. Our study explores methods for stress classification via speech, utilizing an unscripted dataset from an experimental study that was able to show the spontaneous reactions of stressed individuals. Mel-Frequency Cepstral Coefficients (MFCCs) emerge as promising speech features, adept at representing the power spectrum crucial to human auditory perception, especially in stress speech recognition. Leveraging deep learning technology, specifically Convolutional Neural Network (CNN), our research optimally combines speech features and CNN algorithms for stress classification. Despite the scarcity of publications on unscripted datasets and multi-class stress classifications, our study advocates their adoption, aiming to enhance performance metrics and contribute to research expansion. The proposed system shows that MFCCs achieve an accuracy of 95.67% in distinguishing among three stress classes (low-stress, medium-stress, and high-stress), surpassing the prior unscripted dataset study by 81.86%. This highlights the efficacy of the proposed MFCCs-CNN system in stress classification.","2024-07","2025-02-26 20:37:03","2025-02-26 20:37:03","","381-395","","2","25","","","","","","","","","","English","","","","WOS:001275324200026","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","CNN; MFCCs; Multi-class stress classification; Speech stress detection; Unscripted dataset","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PTX58LMH","journalArticle","2023","Pietrzak, B; Kujawa, J; Lipert, A","Depressive Disorders, Cognitive and Physical Function of Older People in Early Dementia Detection","LIFE-BASEL","","2075-1729","10.3390/life13102010","","Background: Aging is associated with cognitive decline, leading to cognitive and physical impairments, which are risk factors for loss of independence and dementia development. Early diagnosis is beneficial for both, the patient and their family, to avoid long-term consequences. The aim of this study was to analyze the frequency of depressive disorders and their influence on cognitive and physical function of older people in early dementia detection. Methods: There were 852 patients, aged at least 60 years, from the Central Teaching Hospital. The study was conducted between September 2022 and June 2023. The qualified participants were examined using four tools: Geriatric Depression Scale (GDS), Instrumental Activities of Daily Living (IADL), Timed Up and Go (TUG) and Schulman's Clock-Drawing Test. Results: Over one-third had depressive disorders. A relationship with p < 0.05 was observed between GDS and IADL: r = -0.61. A relationship with p > 0.05 was observed between GDS and TUG: r = -024. A relationship with p < 0.05 was observed between GDS and CDT: r = 0.74. Conclusions: The first signs of depressive disorders in older people may be considered an indication for further diagnosis of dementia.","2023-10","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","10","13","","","","","","","","","","English","","","","WOS:001094126800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","cognitive function; COMMUNITY; dementia; depressive disorders; DISABILITY; ELDERLY POPULATION; FINANCIAL CAPACITY; FRAILTY; HEALTH OUTCOMES; IMPAIRMENT; older people; PERFORMANCE; physical function; PREVALENCE; SYMPTOMS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PY6FR5LZ","journalArticle","2023","Murton, OM; Dec, GW; Hillman, RE; Majmudar, MD; Steiner, J; Guttag, JV; Mehta, DD","Acoustic Voice and Speech Biomarkers of Treatment Status during Hospitalization for Acute Decompensated Heart Failure","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13031827","","Featured Application A key potential application of the current work is prospective at-home monitoring of patients at risk for acute decompensated heart failure using non-invasive acoustic voice and speech biomarkers, which can help avoid rehospitalization and reduce morbidity and mortality. This study investigates acoustic voice and speech features as biomarkers for acute decompensated heart failure (ADHF), a serious escalation of heart failure symptoms including breathlessness and fatigue. ADHF-related systemic fluid accumulation in the lungs and laryngeal tissues is hypothesized to affect phonation and respiration for speech. A set of daily spoken recordings from 52 patients undergoing inpatient ADHF treatment was analyzed to identify voice and speech biomarkers for ADHF and to examine the trajectory of biomarkers during treatment. Results indicated that speakers produce more stable phonation, a more creaky voice, faster speech rates, and longer phrases after ADHF treatment compared to their pre-treatment voices. This project builds on work to develop a method of monitoring ADHF using speech biomarkers and presents a more detailed understanding of relevant voice and speech features.","2023-02","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","3","13","","","","","","","","","","English","","","","WOS:000933790900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","AUTOMATIC DETECTION; congestive heart failure; daily monitoring; DYSPHONIA; PREVALENCE; THRESHOLD; VOCAL FUNCTION; voice and speech biomarkers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZSWGWXH4","journalArticle","2023","Tian, H; Zhu, Z; Jing, X","Deep learning for Depression Recognition from Speech","MOBILE NETWORKS & APPLICATIONS","","1383-469X","10.1007/s11036-022-02086-3","","In recent years, depression has been widely concerned, which makes people depressed, even suicidal, causing serious adverse consequences. In this paper, a multi information joint decision algorithm model is established by means of emotion recognition. The model is used to analyze the representative data of the subjects, and to assist in diagnosis of whether the subjects have depression. The main work is as follows: On the basis of exploring the speech characteristics of people with depressive disorder, this paper conducts an in-depth study of speech assisted depression diagnosis based on the speech data in the DAIC-WOZ dataset. First, the speech information is preprocessed, including speech signal pre emphasis, framing windowing, endpoint detection, noise reduction, etc. Secondly, OpenSmile is used to extract the features of speech signals, and the speech features that the features can reflect are studied and analyzed in depth. Then feature selection is carried out based on the influence of speech features and feature combination on depression diagnosis. Then, principal component analysis is used to reduce the dimension of data features. Finally, the convolutional neural network is used to modeling, testing and result analysis showed that the voice based diagnosis of depression was as high as 87%.","2023-01-26","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","","","","","","","","","","","English","","","","WOS:000918410700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","CNN; Depression recognition; EMOTIONS; PCA; speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YQDR4SSA","journalArticle","2021","Quan, CQ; Ren, K; Luo, ZW","A Deep Learning Based Method for Parkinson's Disease Detection Using Dynamic Features of Speech","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2021.3051432","","Detection of voice changes in Parkinson's Disease (PD) patients would make it possible for early detection and intervention before the onset of disabling physical symptoms. This study explores static and dynamic speech features relating to PD detection. A comparative analysis of the articulation transition characteristics shows that the number of articulation transitions and the trend of the fundamental frequency curve are significantly different between HC speakers and PD patients. Motivated by this observation, we propose to apply Bidirectional long-short term memory (LSTM) model to capture time-series dynamic features of a speech signal for detecting PD. The dynamic speech features are measured based on computing the energy content in the transition from unvoiced to voiced segments (onset), and in the transition from voiced to unvoiced segments (offset). Under the two evaluation methods of 10-fold cross validation (CV) and splitting the dataset without samples overlap of one individual, the experimental results show that the proposed method remarkably improves the accuracy of PD detection over traditional machine learning models using static features.","2021","2025-02-26 20:37:03","2025-02-26 20:37:03","","10239-10252","","","9","","","","","","","","","","English","","","","WOS:000609796700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;57<br/>Total Times Cited:&nbsp;&nbsp;59<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","ARTICULATION; bidirectional long short term memory; CLASSIFICATION; deep learning; dynamic features; DYSARTHRIA; Parkinson's disease; PHONATION; speech signal processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LNEK8CSM","journalArticle","2021","Cui, BY; Li, YM; Zhang, ZF","Joint structured pruning and dense knowledge distillation for efficient transformer model compression","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2021.05.084","","In this paper, we develop a novel Joint Model Compression (referred to as JMC) method by combining structured pruning and dense knowledge distillation techniques to significantly compress original large language model into a deep compressed shallow network. In particular, a new Direct Importance-aware Structured Pruning (referred as DISP) approach is proposed to structurally prune the redundant structures in the Transformer networks directly based on the corresponding parameter matrices in the model. Besides, a Dense Knowledge Distillation (referred to as DKD) method is developed with a many-to-one layer mapping strategy to leverage more comprehensive layer-wise linguistic knowledge for the distillation. Further, the proposed structured pruning and dense knowledge distillation are integrated together to perform the joint compression, which enables us to achieve a significant compression without sacrificing model accuracy. The extensive experimental results across four NLP tasks on seven datasets demonstrate its effectiveness and superiority to the baselines, while maintaining similar performance to original large model with further remarkable benefits for inference-time speedup and memory efficiency. (c) CO 2021 Elsevier B.V. All rights reserved.","2021-10-11","2025-02-26 20:37:03","2025-02-26 20:37:03","","56-69","","","458","","","","","","","","","","English","","","","WOS:000691559800006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;21<br/>Total Times Cited:&nbsp;&nbsp;25<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Knowledge Distillation; Structured Pruning; Transformer Model Compression","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4HTDZIAU","journalArticle","2021","Lee, S; Park, J; Um, D","Speech Characteristics as Indicators of Personality Traits","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app11188776","","This study examines the relationship between speech characteristics and personality traits by drawing on pseudo-naturalistic conversations and on personality dimensions identified by the Myers-Briggs Type Indicator (MBTI) model which assesses four personality dimensions of introversion-extroversion, sensing-intuiting, thinking-feeling, and judging-perceiving. The speech of 30 participants was recorded and transcribed, after which a number of speech features including pitch, loudness, response time (i.e., how fast one responds to a prompt), speech rate, and discourse markers were extracted and analyzed. Results show that several speech features correspond to different personality dimensions. Specifically, speech rate as measured by words per minute reveals significant differences between judging individuals and perceiving individuals (perceiving individuals speak faster than judging individuals); there is a significant difference in response time for extroverts and introverts (extroverts respond faster); a significant difference is observed in loudness between judging and perceiving individuals (judging individuals are louder). The frequency of discourse markers is significantly higher for intuiting individuals than sensing individuals. The study discusses these findings in further inquiring the relationship between language and personality.","2021-09","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","18","11","","","","","","","","","","English","","","","WOS:000699425900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","EXTROVERSION; INTROVERTS; LANGUAGE; Myers-Briggs Type Indicator (MBTI); naturalistic conversation; personality traits; speech characteristics; vocal features; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D44K2XTJ","journalArticle","2024","Toprak, A; Turan, M","Transformer-Based Approach for Automatic Semantic Financial Document Verification","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3477270","","Document verification is the process of verifying an original summary document on the original full-text document. Semantic control is very critical in these verification processes. In this study, an automatic document verification system based on Natural Language Processing techniques was designed to semantically check the consistency of the abstract summary produced especially for the original document or documents of the financial type. Verification of abstract summaries on original full-text documents was done through the Transformer-based model. Since the reference documents to be verified in the study belong to the financial type, the Transformer model was created by training with Reuters financial dataset. The proposed Transformer-based semantic document verification approach was tested on the original full-text and summary documents. The full text and summary documents were subjected to data pre-processing and Spell Checker processes. Then, since the summary document will be verified on the full-text document, the sentences most similar to the summary document sentences from the full-text document sentences were determined by using Simhash and Cross Encoder text similarity algorithms. It is a heuristic approach and completes the proposed verification system. Two (experimentally) original full-text document sentences most similar to the summary document sentence were selected. Then, these original full-text document sentences were inputted as training data to the Transformer model. Finally, the transformer model produced an abstract summary of original full-text sentences. In the last stage, the original summary and the summary produced by the Transformer model were compared with both Simhash and Cross Encoder text similarity algorithms in terms of their similarities, and the average document verification accuracy was calculated. The proposed Transformer-based semantic document verification approach achieved an average of 84.1% semantic financial document verification accuracy on the financial documents in the Reuters financial dataset. In this study, we present several key contributions to the field of semantic document verification: Firstly, we introduce a Transformer-based model tailored for financial texts, trained on the Reuters financial dataset, which offers enhanced precision in understanding financial language. Secondly, our approach employs advanced Natural Language Processing techniques for deep semantic analysis to verify the consistency of document summaries. Thirdly, we propose a novel hybrid methodology that integrates Transformer models with sentence grouping techniques for generating accurate and informative abstract summaries. These innovations collectively mark a substantial advancement in the automation and precision of document verification processes.","2024","2025-02-26 20:37:03","2025-02-26 20:37:03","","184327-184349","","","12","","","","","","","","","","English","","","","WOS:001377327300039","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;88</p>","","","abstract summarization; Accuracy; Costs; Data models; Document handling; Document verification; Feature extraction; Financial management; Manuals; Personnel; Reuters financial datasets; semantic analysis; Semantics; SIMILARITY; Training data; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P5XZY478","journalArticle","2024","Liu, MY; Raj, ANJ; Rajangam, V; Ma, KW; Zhuang, ZM; Zhuang, SX","Multiscale-multichannel feature extraction and classification through one-dimensional convolutional neural network for Speech emotion recognition","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2023.103010","","Speech emotion recognition (SER) is a crucial field of research in artificial intelligence and human-computer interaction. Extracting effective speech features for emotion recognition is a continuing research focus in SER. Most research has focused on finding an optimal speech feature to extract hidden local features while ignoring the global relationships of the speech signal. In this paper, we propose a method that utilizes a multiscale-multichannel feature extraction structure with global and local information to obtain comprehensive speech features. Our approach employs a one-dimensional convolutional neural network (1D CNN) for feature learning and emotion recognition, capturing both spectral and spatial characteristics of speech for superior learning capabilities with improved SER results. We conducted extensive experiments on publicly available emotion recognition datasets, employing three distinct data augmentation (DA) techniques to enhance model generalization. Our model utilized Mel-frequency cepstral coefficients and zero-crossing rate features from speech samples for training and outperformed state-of-the-art techniques in terms of accuracy. Additionally, we conducted experiments to validate the effectiveness and reliability of our proposed method.","2024-01","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","156","","","","","","","","","","English","","","","WOS:001124307500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","1D; 1D CNN; Data augmentation; Multiscale-multichannel; Speech emotion recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZAG6EM58","journalArticle","2022","Hu, ZF; Wang, L; Luo, Y; Xia, YL; Xiao, H","Speech Emotion Recognition Model Based on Attention CNN Bi-GRU Fusing Visual Information","ENGINEERING LETTERS","","1816-093X","","","The problem of low recognition accuracy of emotion recognition models is easily caused by interference such as data redundancy and irrelevant features. In this paper, we propose a speech emotion recognition (SER) method based on an attentional convolutional neural network (CNN) bidirectional gated recurrent unit (Bi-GRU) fusing visual information. First, we pretrained the log-mel spectrograms in a ResNet-based attentional convolutional neural network (RACNN) to extract speech features. Second, the CNN-extracted facial static appearance features are fused with speech features using a deep Bi-GRU to obtain speech appearance features. A series of gated recurrent units with attention mechanisms (AGRUs) are used to extract facial geometric features. Then, the hybrid features are obtained by further combining the integrated speech appearance features with facial geometric features, and kernel linear discriminant analysis (KLDA) is used to discriminate them. Finally, the proposed method in this paper obtained accuracies of 87.92% and 89.65% on the RAVDESS and eNTERFACE'05 emotion databases, respectively. The experimental results demonstrate that the method in this paper effectively improved the accuracy and robustness of SER.","2022-05-16","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","2","30","","","","","","","","","","English","","","","WOS:000803688800034","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","AGRUs; Bi-GRU; KLDA; NEURAL-NETWORK; SER; visual information","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VYH7AK3X","journalArticle","2021","Mathur, A; Kumar, R; Singh, VP","A new load flow and short-circuit analysis for unbalanced modern distribution system","INTERNATIONAL TRANSACTIONS ON ELECTRICAL ENERGY SYSTEMS","","2050-7038","10.1002/2050-7038.13257","","This paper proposes a new load flow and short-circuit analysis method for unbalanced distribution system incorporating three-phase transformer models and inverter-based distributed generation (IBDG). Initially, a load flow method of an unbalanced distribution system is developed in this paper, which incorporates the mathematical model of three-phase transformer of any vector group and different modes of operation of IBDG. The advantage of the proposed method is that the required simulation time for the proposed method is smaller than the backward/forward method available in the literature. The fault analysis method developed subsequently in this paper also incorporates three-phase transformer model and IBDG in the short-circuit calculations. The mode of operation of IBDG during short-circuit analysis depends upon the magnitude of its short-circuit capacity. The results obtained from the proposed method have been compared with the time domain simulation studies carried out using PSCAD/EMTDC software to verify the accuracy of the proposed method.","2021-12","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","12","31","","","","","","","","","","English","","","","WOS:000728231400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","3-PHASE TRANSFORMER MODEL; ALGORITHM; distribution system; IMPLEMENTATION; inverter-based distributed generation; load flow; POWER-FLOW; short-circuit analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4QHT222Q","journalArticle","2023","Xu, JX; Fan, HX; Luo, MH; Li, PJ; Jeong, T; Xu, LG","Transformer Based Water Level Prediction in Poyang Lake, China","WATER","","2073-4441","10.3390/w15030576","","Water level is an important indicator of lake hydrology characteristics, and its fluctuation significantly affects lake ecosystems. In recent years, deep learning models have shown their superiority in the long-time range prediction of hydrology processes, while the application of deep learning models with the attention mechanism for lake water level prediction is very rare. In this paper, taking Poyang Lake as a case study, the transformer neural network model is applied to examine the model performance in lake water level prediction, to explore the effects of the Yangtze River on lake water level fluctuations, and to analyze the influence of hyper-parameters (window size and model layers) and lead time on the model accuracy. The result indicated that the transformer model performs well in simulating the lake water level variations and can reflect the temporal water level variation characteristics in Poyang Lake. In the testing stage, the RMSE values were recorded in the range of 0.26-0.70 m, and the NSE values are higher than 0.94. Moreover, the Yangtze River inflow has a great influence on the lake water level fluctuation of Poyang Lake, especially in flood and receding periods. The contribution rate of the Yangtze River in RMSE and NSE is higher than 80% and 270%, respectively. Additionally, hyper-parameters, such as window size and model layers, significantly influence the transformer model simulation accuracy. In this study, a window size of 90 d and a model layer of 6 are the most suitable hyper-parameters for water level prediction in Poyang Lake. Additionally, lead time may affect the model accuracy in lake water level prediction. With the lead time varied from one to seven days, the model accuracy was high and RMSE values were in the range of 0.46-0.73 m, while the RMSE value increased to 1.37 m and 1.82 m with the lead time of 15 and 30 days, respectively. The transformer neural network model constructed in this paper was the first to be applied to lake water forecasting and showed high efficiency in Poyang Lake. However, few studies have tried to use transformer model coupling with the attention mechanism for forecasting hydrological processes. It is suggested that the model can be used for long sequence time-series forecasting in hydrological processes in other lakes to test its performance, providing further scientific evidence for the control of lake floods and management of lake resources.","2023-02","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","3","15","","","","","","","","","","English","","","","WOS:000930949800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","3 GORGES DAM; BASIN; CLIMATE; DROUGHT; FLUCTUATIONS; FREQUENCY; MACHINE; machine learning; MODEL; Poyang Lake; SYSTEM; transformer model; water level; Yangtze River; YANGTZE-RIVER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IEIB426U","journalArticle","2022","Yue, ZB; Lu, JB; Wan, L","Lightweight Transformer Network for Ship HRRP Target Recognition","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app12199728","","The traditional High-Resolution Range Profile (HRRP) target recognition method has difficulty automatically extracting target deep features, and has low recognition accuracy under low training samples. To solve these problems, a ship recognition method is proposed based on the lightweight Transformer model. The model enhances the representation of key features by embedding Recurrent Neural Networks (RNN) into Transformer's encoder. The Group Linear Transformations (GLTs) are introduced into Transformer to reduce the number of parameters in the model, and stable features are extracted through linear intergroup dimensional transformations. The adaptive gradient clipping algorithm is combined with the Stochastic Gradient Descent (SGD) optimizer to allow the gradient to change dynamically with the training process and to improve the training speed and generalization ability of the model. Experimental results on the simulated dataset show that multi-layer model stacking can effectively extract deep features of targets and raise recognition accuracy. At the same time, the lightweight Transformer model can maintain good recognition performance with low parameters and low training samples.","2022-10","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","19","12","","","","","","","","","","English","","","","WOS:000866649500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","attention model; High-Resolution Range Profile (HRRP); lightweight model; RADAR; Radar Automatic Target Recognition (RATR); RECURRENT ATTENTIONAL NETWORK; Recurrent Neural Network (RNN)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WYA9TZ5L","journalArticle","2023","Brunetto, V; Kershaw, C; Garraffa, M","When acquisition and aphasia converge: the case of copula omission","GLOSSA-A JOURNAL OF GENERAL LINGUISTICS","","2397-1835","10.16995/glossa.9326","","This paper reports evidence for a convergence between child language acquisition and Broca's aphasia in the domain of copula omission. Our data shows that, in the spontaneous speech of people with Broca's aphasia (PWBA), copula omission is confined to aspectual predicates, replicating a finding previously reported by Becker (2002) for child English. This grammatical property is a much stronger predictor of copula omission than alternative, extra-grammatical factors, such as predicate length or utterance length. We argue that grammatical accounts which predict the fragility of Tense by virtue of its cartographic location, in terms of 'treepruning'/'growing trees', fare better than others in explaining similarities in patterns of omission in these two populations.","2023-07-20","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","1","8","","","","","","","","","","English","","","","WOS:001052931900004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","AGRAMMATISM; AGREEMENT; FUNCTIONAL CATEGORIES; GREEK APHASIA; INFLECTION; SUBJECTLESS SENTENCES; TENSE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DUZF94XW","journalArticle","2024","Mol, EAN; Kumar, MBS","End-to-end framework for agricultural entity extraction - A hybrid model with transformer","COMPUTERS AND ELECTRONICS IN AGRICULTURE","","0168-1699","10.1016/j.compag.2024.109309","","Entity extraction is one prerequisite for various Natural Language Processing(NLP) applications like relation extraction, question answering and knowledge graph construction. This paper proposes a complete framework for extracting agricultural entities from unstructured textual documents by combining dictionary-based, rulebased and transformer-based deep learning techniques. Initially, an entity extraction method based on dictionaries is employed to obtain patterns for creating rules that could identify more similar entities. The dictionary has been updated with the newly obtained entities, and this combined dictionary-based and rule-based technique has been repeatedly applied in multiple steps to obtain enough sample data. The labeled dataset is constructed with these extracted entities to train the proposed BERT-based transformer model with Conditional Random Field(CRF) for agricultural entity extraction, and the performance is evaluated. The results show the enhanced performance of the proposed model compared to other state-of-the-art models with a Precision of 88.84%, Recall of 88.9 % and F1-Score of 88.87 %.","2024-10","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","225","","","","","","","","","","English","","","","WOS:001294530500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Agricultural entity extraction; Conditional Random Field(CRF); Corpus construction; Fine-tuned transformer model; Hybrid model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9YJNDCL9","journalArticle","2022","Ji, B; Wang, HB; Zhang, MX; Mao, BR; Li, XJ","An Efficient Lightweight Network Based on Magnetic Resonance Images for Predicting Alzheimer's Disease","INTERNATIONAL JOURNAL ON SEMANTIC WEB AND INFORMATION SYSTEMS","","1552-6283","10.4018/IJSWIS.313715","","Brain magnetic resonance images (MRI) are widely used for the classification of Alzheimer's disease (AD). The size of 3D images is, however, too large. Some of the sliced image features are lost, which results in conflicting network size and classification performance. This article uses key components in the transformer model to propose a new lightweight method, ensuring the lightness of the network and achieving highly accurate classification. First, the transformer model is imitated by using image patch input to enhance feature perception. Second, the Gaussian error linear unit (GELU), commonly used in transformer models, is used to enhance the generalization ability of the network. Finally, the network uses MRI slices as learning data. The depthwise separable convolution makes the network more lightweight. Experiments are carried out on the ADNI public database. The accuracy rate of AD vs. normal control (NC) experiments reaches 98.54%. The amount of network parameters is 1.3% of existing similar networks.","2022","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","1","18","","","","","","","","","","English","","","","WOS:001001216800004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Alzheimer's Disease Prediction; Computer-Aided Diagnosis; Convolutional Neural Network; DEEP LEARNING-MODEL; Depthwise Separable Convolution; EARLY-DIAGNOSIS; Magnetic Resonance Images","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T5GMNN6P","journalArticle","2022","Resch, S; Friedrich, J; Wagner, T; Mehlmann, G; Luther, M","Stability Analysis of Power Hardware-in-the-Loop Simulations for Grid Applications","ELECTRONICS","","2079-9292","10.3390/electronics11010007","","Power Hardware-in-the-Loop (PHiL) simulation is an emerging testing methodology of real hardware equipment within an emulated virtual environment. The closed loop interfacing between the Hardware under Test (HuT) and the Real Time Simulation (RTS) enables a realistic simulation but can also result in an unstable system. In addition to fundamentals in PHiL simulation and interfacing, this paper therefore provides a consistent and comprehensive study of PHiL stability. An analytic analysis is compared with a simulative approach and is supplemented by practical validations of the stability limits in PHiL simulation. Special focus is given on the differences between a switching and a linear amplifier as power interface (PI). Stability limits and the respective factors of influence (e.g., Feedback Current Filtering) are elaborated with a minimal example circuit with voltage-type Ideal Transformer Model (ITM) PHiL interface algorithm (IA). Finally, the findings are transferred to a real low-voltage grid PHiL application with residential load and photovoltaic system.","2022-01","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","1","11","","","","","","","","","","English","","","","WOS:000920510600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","ACCURACY; feedback current filtering; ideal transformer model; INTERFACE; interface algorithm; linear/switching amplifier; PHiL stability; power hardware-in-the-loop; real time simulation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KLH3PXG9","journalArticle","2024","Wang, T; Ge, YE; Wang, YJ; Chen, WQ; Niu, YC","Dynamic inferences of crash risks in freeway merging zones: a spatio-temporal deep learning model","TRANSPORTMETRICA B-TRANSPORT DYNAMICS","","2168-0566","10.1080/21680566.2024.2426727","","Freeway merging zones are critical for freeway operations and management due to potential crashes arising from complex vehicle merging behaviours. This paper investigates the application of a spatio-temporal deep learning model to infer crash risks in the zones. We first introduce a crash risk index based on Time-To-Collision and vehicle merging patterns. An innovation is that the developed spatio-temporal transformer model can analyze the evolving risk index. This model effectively captures dynamic risk features through a multi-head attention mechanism within its spatio-temporal learning components. Numerical experiments on nine inference tasks with varying spatial resolutions show improved performance of the model with lower resolution. Moreover, the ST-Transformer model is benchmarked against three advanced deep learning models, which consistently demonstrates its superiority in capturing spatio-temporal dependence in risk sequences. This investigation significantly contributes to a richer understanding of proactive traffic safety, providing valuable insights for advanced freeway management and driver assistance systems.","2024-12-31","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","1","12","","","","","","","","","","English","","","","WOS:001354224500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","AREAS; Crash risks; merging zone; PREDICTION; PROPAGATION; spatio-temporal dependence; surrogate safety measures; traffic safety; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IX24V2D4","journalArticle","2022","Dang, LX; Weng, LB; Dong, WC; Li, SS; Hou, YN","Spectral-Spatial Attention Transformer with Dense Connection for Hyperspectral Image Classification","COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE","","1687-5265","10.1155/2022/7071485","","In recent years, deep learning has been widely used in hyperspectral image (HSI) classification and has shown good capabilities. Particularly, the use of convolutional neural network (CNN) in HSI classification has achieved attractive performance. However, HSI contains a lot of redundant information, and the CNN-based model is limited by the receptive field of CNN and cannot balance the performance and depth of the model. Furthermore, considering that HSI can be regarded as sequence data, CNN-based models cannot mine sequence features well. In this paper, we propose a model named SSA-Transformer to address the above problems and extract spectral-spatial features of HSI more efficiently. The SSA-Transformer model combines a modified CNN-based spectral-spatial attention mechanism and a self-attention-based transformer with dense connection. The SSA-Transformer model can combine the local and global features of HSI to improve the performance of the model. A series of experiments showed that the SSA-Transformer achieved competitive classification accuracy compared with other CNN-based classification methods using three HSI datasets: University of Pavia (PU), Salinas (SA), and Kennedy Space Center (KSC).","2022-05-26","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","2022","","","","","","","","","","English","","","","WOS:000850369500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","NEURAL-NETWORK; REPRESENTATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BNIS3EJE","journalArticle","2024","Sui, LK; Jiang, YG","Argo data anomaly detection based on transformer and Fourier transform","JOURNAL OF SEA RESEARCH","","1385-1101","10.1016/j.seares.2024.102483","","Argo data is multidimensional observational data from ocean floats, which has long been plagued by data anomalies. Currently, the anomaly detection problem in Argo data still faces many challenges, as anomalies may involve complex relationships between multiple variables, leading to suboptimal performance with traditional machine learning methods. Thanks to the advancement of deep learning, it has become the predominant methodology for anomaly detection, demonstrating notable performance. The Transformer model has shown significant potential in the field of data anomaly detection, with its core Self-Attention mechanism capable of learning relationships between variables. We introduce Fast Fourier Transform (FFT) into the Transformer model, enabling the model to better capture periodic patterns and complex relationships in multivariate data, learning normal data patterns to improve the method for Argo data anomaly detection. Through experiments conducted on three public datasets and the Argo dataset, the enhanced model outperforms the original model in terms of performance. This also demonstrates the potential of FFT in multidimensional data anomaly detection, providing new insights into addressing anomaly detection challenges in real-world complex datasets.","2024-04","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","198","","","","","","","","","","English","","","","WOS:001196614500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","Anomaly detection; Argo data; Fast Fourier transform; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2U5QGIU7","journalArticle","2024","Xie, JJ; Song, YH; Zheng, HL; Luo, SJ; Chen, Y; Zhang, C; Yu, RS; Tong, MS","PathMethy: an interpretable AI framework for cancer origin tracing based on DNA methylation","BRIEFINGS IN BIOINFORMATICS","","1467-5463","10.1093/bib/bbae497","","Despite advanced diagnostics, 3%-5% of cases remain classified as cancer of unknown primary (CUP). DNA methylation, an important epigenetic feature, is essential for determining the origin of metastatic tumors. We presented PathMethy, a novel Transformer model integrated with functional categories and crosstalk of pathways, to accurately trace the origin of tumors in CUP samples based on DNA methylation. PathMethy outperformed seven competing methods in F1-score across nine cancer datasets and predicted accurately the molecular subtypes within nine primary tumor types. It not only excelled at tracing the origins of both primary and metastatic tumors but also demonstrated a high degree of agreement with previously diagnosed sites in cases of CUP. PathMethy provided biological insights by highlighting key pathways, functional categories, and their interactions. Using functional categories of pathways, we gained a global understanding of biological processes. For broader access, a user-friendly web server for researchers and clinicians is available at https://cup.pathmethy.com.","2024-10-11","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","6","25","","","","","","","","","","English","","","","WOS:001329875000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","biological pathway; cancer of unknown primary (CUP); CELL-FREE DNA; DNA methylation; tracing the origin of cancer; transformer model; UNKNOWN PRIMARY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AGRCUFFN","journalArticle","2024","Alshammari, SA","TLDViT: A Vision Transformer Model for Tomato Leaf Disease Classification","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","and efficient diagnostic methods are essential for crop health monitoring due to the substantial impact of tomato leaf diseases on crop yield and quality. Traditional machine learning models, such as convolutional neural networks (CNNs), have shown promise in plant disease classification; however, they often require extensive data preprocessing and struggle with complex variations in leaf appearance. This study introduces TLDViT (Tomato Leaf Disease Vision Transformer), a Vision Transformer model specifically designed for the classification of tomato leaf diseases. TLDViT reduces the need for preprocessing by learning disease-specific features directly from raw images, leveraging Vision Transformers' ability to capture long-range dependencies within images. We evaluated TLDViT on the Plant Village Dataset, which includes healthy and diseased samples across multiple classes. For comparative analysis, two Vision Transformer models, ViT-r50-l32 and ViT-l16-fe, were tested. Among these, ViT-r50-l32 achieved the highest performance, surpassing both ViT-l16-fe with an accuracy of 98%. These findings highlight TLDViT's potential as an effective tool for crop health monitoring and automated plant disease diagnosis.","2024-12","2025-02-26 20:37:03","2025-02-26 20:37:03","","841-848","","12","15","","","","","","","","","","English","","","","WOS:001395714100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","crop health monitoring; plant disease classification; Tomato Leaf Disease; Vision Transformer (ViT)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7DCMSWDK","journalArticle","2024","Wen, RY; Tao, CC; Ji, HL; Qiu, JH","Dual-Modal Fusion PRI-SWT Model for Eddy Current Detection of Cracks, Delamination, and Impact Damage in Carbon Fiber-Reinforced Plastic Materials","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app142210282","","Carbon fiber-reinforced plastic (CFRP) composites are prone to damage during both manufacturing and operational phases, making the classification and identification of defects critical for maintaining structural integrity. This paper presents a novel dual-modal feature classification approach for the eddy current detection of CFRP defects, utilizing a Parallel Real-Imaginary/Swin Transformer (PRI-SWT) model. Built using the Transformer architecture, the PRI-SWT model effectively integrates the real and imaginary components of sinusoidal voltage signals, demonstrating a significant performance improvement over traditional classification methods such as Support Vector Machine (SVM) and Vision Transformer (ViT). The proposed model achieved a classification accuracy exceeding 95%, highlighting its superior capability in terms of addressing the complexities of defect detection. Furthermore, the influence of key factors-including the real-imaginary fusion layer, the number of layers, the window shift size, and the model's scale-on the classification performance of the PRI-SWT model was systematically evaluated.","2024-11","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","22","14","","","","","","","","","","English","","","","WOS:001366758700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","CFRP; CFRP defect detection; CLASSIFICATION; COMPONENTS; eddy current nondestructive testing system; intelligent classification algorithm; Parallel Real-Imaginary/Swin Transformer model; Vision Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RX3ZGKYY","journalArticle","2023","Hossain, MA; Hasan, MAFMR; Hossen, E; Asraful, M; Faruk, MO; Abadin, AFMZ; Ali, MS","Automatic Bangla Image Captioning Based on Transformer Model in Deep Learning","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","Image Captioning has become a crucial aspect of contemporary artificial intelligence because it has tackled two crucial parts of the AI field: Computer Vision and Natural Language Processing. Currently, Bangla stands as the seventh most widely spoken language globally. Due to this, image captioning has gained recognition for its significant research accomplishments. Many established datasets are found in English but no standard datasets in Bangla. For our research, we have used the BAN-Cap dataset which contains 8091 images with 40455 sentences. Many effective encoder-decoder and Visual Attention approaches are used for image captioning where CNN is utilized for the encoder and RNN is used for the decoder. However, we suggested a transformer-based image captioning model in this study with different pre-train image feature extraction models like Resnet50, InceptionV3, and VGG16 using the BAN-Cap dataset and find out its effective efficiency and accuracy based on many performances measured methods like BLEU, METEOR, ROUGE, CIDEr and also find out the drawbacks of others model.","2023-11","2025-02-26 20:37:03","2025-02-26 20:37:03","","1110-1117","","11","14","","","","","","","","","","English","","","","WOS:001126027500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","-Bangla image captioning; attention mechanism; image processing; natural language processing; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NBCJ4BJR","journalArticle","2024","Kim, Y; Kim, J; Cho, S; Sim, H; Kim, JY","Enhancing Environmental Policy Decisions in Korea and Japan Through AI-Driven Air Pollution Forecast","SUSTAINABILITY","","2071-1050","10.3390/su162310436","","(1) Background: Although numerous artificial intelligence (AI)-based air pollution prediction models have been proposed, research that links key pollution drivers, such as regional industrial facilities, to actionable policy recommendations is required. (2) Methods: This study employs the radial basis function (RBF) and spatial lag features to capture spatial interactions among regions, utilizing a transformer model for analysis. The model was trained on air quality and industrial data from South Korea (2010-2022) and Japan (2017-2020). (3) Results: The transformer model achieved a mean squared error of 0.045 for the Korean dataset and 0.166 for the Japanese dataset, outperforming benchmark models, including Support Vector Regression, neural networks, and the AutoRegressive Integrated Moving Average model. (4) Conclusions: By capturing complex spatial dynamics, the proposed model provides valuable insights that can assist policymakers in developing effective, data-driven strategies for air pollution reduction at the national and regional levels, thereby supporting the broader goals of sustainability through informed, equitable environmental interventions.","2024-12","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","23","16","","","","","","","","","","English","","","","WOS:001377769200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","air pollution; artificial intelligence; MORTALITY; radial basis function; spatial Durbin model; sustainable environmental policy; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AI22CT94","journalArticle","2023","Xue, ZA; Fan, MB; Cao, BH; Ye, B","Efficient analytical modeling for pulsed eddy current signals using adaptive interpolation-based Fourier transform","NONDESTRUCTIVE TESTING AND EVALUATION","","1058-9759","10.1080/10589759.2022.2151598","","In the analytical modelling for pulsed eddy current (PEC) signals based on the Fourier transform, there is a computational burden caused by calculating hundreds of harmonic impedance changes. In this paper, an adaptive interpolation method that takes inflection points as the initial interpolation nodes is proposed for calculating harmonic impedance changes. The inflection points of impedance change with frequency are deduced from the transformer model to divide the initial interval of interpolation. In the process of the adaptive interpolation method, it is necessary to divide the subintervals which fail to meet the requirements of interpolation accuracy, and then calculate the harmonic impedance changes by the cubic spline interpolation method. The adaptive interpolation method was verified by the simulation and experimental results. The results show that the adaptive interpolation method interpolates hundreds of harmonic impedance changes with dozens of interpolation nodes. There is a good agreement between the experimental PEC signals and the PEC signals obtained by the adaptive interpolation method, and the relative errors of the peak values are about 0.1%.","2023-07-04","2025-02-26 20:37:03","2025-02-26 20:37:03","","631-647","","4","38","","","","","","","","","","English","","","","WOS:000915674100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","adaptive interpolation method; impedance change; Pulsed eddy current testing; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EU6P8S8Z","journalArticle","2025","Quan, KAC; Nguyen, VT; Nguyen, TV; Tran, MT","Unified ViT-CNN for few-shot object counting","SIGNAL IMAGE AND VIDEO PROCESSING","","1863-1703","10.1007/s11760-024-03792-z","","Few-shot object counting aims to count an object of an arbitrary category using only a few annotated exemplars, i.e., few-shot. Existing methods have shown promising results in few-shot counting by using the transformer model combined with convolutions. However, these methods' approaches to extracting the query and exemplars features using the separated feature extractors, namely Vision Transformer (ViT) and Convolution Neural Network (CNN), respectively, can cause the inconsistency of latent spaces. To address this issue, in this work, we proposed the ViT-CNN architecture sharing feature extraction for query and exemplar extraction by adapting the ViT-Adapter model as the backbone. Our proposed architecture also takes advantage of multi-scale features and the exemplar iterative interaction to enhance the result. Furthermore, we proposed a Density Map Refinement Module to refine the predicted density map using the exemplar information. Extensive experiments on the FSC-147 and CARPK datasets show that our approach significantly outperforms previous state-of-the-art approaches (7.20% error reduction w.r.t. test MAE and 6.35% w.r.t. test RMSE).","2025-03","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","3","19","","","","","","","","","","English","","","","WOS:001398315900027","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Class-agnostic counting; Few-shot counting; Transformer-model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8EY62TMM","journalArticle","2024","Sun, CL; Chen, BK; Chen, FL; Leng, Y; Guo, QS","Speech Keyword Spotting Method Based on Swin-Transformer Model","INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS","","1875-6891","10.1007/s44196-024-00448-1","","With the rapid advancements in deep learning technology, the Transformer-based attention neural network has shown promising performance in keyword spotting (KWS). However, this method suffers from high computational cost since the excessive parameters in the Transformer model and the computational burden of global attention, which limit its applicability in a resource-constrained KWS scenario. To overcome this issue, we propose a novel Swin-Transformer based KWS method. In this approach, first extract dynamic features using Temporal Convolutional Network (TCN) from input Mel-Frequency Cepstral Coefficients (MFCCs). Then, the Swin-Transformer is employed to capture hierarchical multi-scale features, where a window attention is designed to grasp dynamic time-frequency features. Furthermore, to enhance the extraction of contextual information from the spectrogram, a frame-level shifted window attention mechanism is proposed to enhance the inter-window interaction, thus extracting more contextual information from the spectrogram. Experimental results on the speech command V1 dataset verify the effectiveness of the proposal, which achieves a recognition accuracy of 98.01% with less model parameters, outperforming existing KWS methods.","2024-03-27","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","1","17","","","","","","","","","","English","","","","WOS:001195416200004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;1</p>","","","Keyword spotting; Swin-Transformer; Temporal Convolutional Network; Window self-attention mechanism","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EFCBH387","journalArticle","2022","Li, XY; Cheng, Y; Fang, Y; Liang, HM; Xu, SQ","2DSegFormer: 2-D Transformer Model for Semantic Segmentation on Aerial Images","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2022.3223416","","Two-dimensional position information of input tokens is essential for transformer-based semantic segmentation models, especially on high-resolution aerial images. However, recent transformer-based segmentation methods use position encoding to record position information and most position encoding methods encode the 1-D positions of tokens. Therefore, we propose a 2-D semantic transformer model (2DSegFormer) for semantic segmentation on aerial images. In 2DSegFormer, we design a novel 2-D positional attention to accurately record the 2-D position information required by the transformer. Furthermore, we design the dilated residual connection and use it instead of skip connection in the deep stages to get a larger receptive field. Skip connections are used in the shallow stages of 2DSegFormer to pass the details to the corresponding stages in the decoder. Experimental results on UAVid, Vaihingen, and AeroScapes datasets demonstrate the effectiveness of 2DSegFormer. Compared with the state-of-the-art methods, 2DSegFormer shows better performance and great robustness on three different datasets. In particular, 2DSegFormer-B2 achieves first place in the public ranking on the UAVid test set.","2022","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","60","","","","","","","","","","English","","","","WOS:000893634400021","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","2-D positional attention; aerial images; semantic segmentation; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HPL9KNTB","journalArticle","2023","Zou, RT; Wei, L; Guan, L","Super Resolution of Satellite-Derived Sea Surface Temperature Using a Transformer-Based Model","REMOTE SENSING","","2072-4292","10.3390/rs15225376","","Sea surface temperature (SST) is one of the most important factors related to the ocean and the climate. In studying the domains of eddies, fronts, and current systems, high-resolution SST data are required. However, the passive microwave radiometer achieves a higher spatial coverage but lower resolution, while the thermal infrared radiometer has a lower spatial coverage but higher resolution. In this paper, in order to improve the performance of the super-resolution SST images derived from microwave SST data, we propose a transformer-based SST reconstruction model comprising the transformer block and the residual block, rather than purely convolutional approaches. The outputs of the transformer model are then compared with those of the other three deep learning super-resolution models, and the transformer model obtains lower root-mean-squared error (RMSE), mean bias (Bias), and robust standard deviation (RSD) values than the other three models, as well as higher entropy and definition, making it the better performing model of all those compared.","2023-11","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","22","15","","","","","","","","","","English","","","","WOS:001113959500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","sea surface temperature; super-resolution; transformer-based model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UD2EBREF","journalArticle","2023","Pan, H; Xie, L; Wang, ZL","C3DBed: Facial micro-expression recognition with three-dimensional convolutional neural network embedding in transformer model","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2023.106258","","Facial micro-expression is often used for emotional recognition of people in a high-risk or pressure scene, which may reflect genuine emotions due to the low intensity of facial action units. Current methods focus on locating regions with emotional changes and cropping these regions for local feature extraction. However, these methods may lead to the problem of information redundancy caused by overlapping cropped regions. This paper proposes a novel three-dimensional convolutional neural network embedding in the transformer model (C3DBed). This model learns the attention weight of each local region of the micro-expression image, thereby perceiving the detail changes of the facial image and extracting robust local detail features. Solve the problem of model complexity and information redundancy caused by low-intensity local area positioning of facial muscle movement. The experiment results demonstrated that the proposed C3DBed model achieved competitive performance with accuracy rates of 78.04%, 77.64%, and 75.73% on SMIC, CASME II, and SAMM datasets, respectively.","2023-08","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","123","","","","","","","","","","English","","","","WOS:000979778200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","ATTENTION; Attention weight; C3D embedding; FEATURES; INFORMATION; Micro-expression recognition; OPTICAL-FLOW FEATURE; TOP; Transformer encoder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L9ZFNDUM","journalArticle","2022","Yi, H; Mu, YJ; Han, JQ; Li, L","Improved bandwidth and radiation efficiency of series-fed patch array using cascaded inset-fed mechanism","ELECTRONICS LETTERS","","0013-5194","10.1049/ell2.12641","","In this letter, a novel design approach of low-sidelobe series-fed patch antenna array is proposed which has enhanced bandwidth and radiation efficiency. It is based on the fact that the out-to-input voltage amplitude ratio of an inset-fed patch antenna element could be manipulated by changing the insert depth of the output microstrip line. Thus, by utilizing a cascaded inset-fed mechanism, the series-fed patch antenna array achieves voltage amplitude tapering for desired sidelobe suppression. The step-down transformer model and the cascaded step-down transformer model are presented to reveal the design approach as the equivalent circuit characterization of the antenna element. As a proof-of-concept, a 12-element series-fed patch antenna array operating 24 GHz with a 20 dB sidelobe level (SLL) is designed, simulated, and prototyped. It could be found that, in contrast to the conventional width-tapering patch antenna array, the proposed design achieves an impedance bandwidth broadening, from 1.7% to 2.5%, and a radiation efficiency improvement of 7% meanwhile.","2022-11","2025-02-26 20:37:03","2025-02-26 20:37:03","","866-868","","23","58","","","","","","","","","","English","","","","WOS:000864203100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;11</p>","","","MICROSTRIP ANTENNA-ARRAYS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UJ5W58JV","journalArticle","2024","Cui, XR; Zheng, QQ; Li, J; Jiang, B; Li, SB; Liu, JH","A parallel convolutional neural network-transformer model for underwater target recognition based on multimodal feature learning","PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART M-JOURNAL OF ENGINEERING FOR THE MARITIME ENVIRONMENT","","1475-0902","10.1177/14750902231215410","","Underwater acoustic target recognition is a hot research issue with a wide range of applications. The variable ocean environment and evolving underwater moving target noise reduction techniques greatly complicate the recognition task. Traditional recognition methods are difficult to obtain practical characterization features and robust recognition results due to the singular input features and the limitation of the network backbone. Therefore, We propose a parallel convolutional neural network (CNN)-Transformer model based on multimodal feature learning for underwater target recognition. The CNN module extracts deep features from the Mel-Frequency Cepstral Coefficients (MFCCs). The Transformer captures global information in the original time-domain signal. The two single-modal features are combined by an adaptive feature fusion module to construct joint features for target recognition. The effectiveness of the proposed method was verified in the Ships-Ear dataset, and the average accuracy of classification reached 98.58%. The experimental results show that our model works better than classical methods.","2024-11","2025-02-26 20:37:03","2025-02-26 20:37:03","","943-953","","4","238","","","","","","","","","","English","","","","WOS:001129077300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","adaptive feature fusion; convolutional neural network; EMOTION RECOGNITION; FUSION; transformer; Underwater acoustic target recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UZTLZ2DM","journalArticle","2024","Dönmez, E","Hybrid convolutional neural network and multilayer perceptron vision transformer model for wheat species classification task: E-ResMLP+","EUROPEAN FOOD RESEARCH AND TECHNOLOGY","","1438-2377","10.1007/s00217-024-04469-0","","Wheat plant is one of the most basic food sources for the whole world. There are many species of wheat that differ according to the conditions of the region where they are grown. In this context, wheat species can exhibit different characteristics. Issues such as resistance to geographical conditions and productivity are at the forefront in this plant as in all other plants. The wheat species should be correctly distinguished for correct agricultural practice. In this study, a hybrid model based on the Vision Transformer (VT) approach and the Convolutional Neural Network (CNN) model was developed to classify wheat species. For this purpose, ResMLP architecture was modified and the EfficientNetV2b0 model was fine-tuned and improved. A hybrid transformer model has been developed by combining these two methods. As a result of the experiments, the overall accuracy performance has been determined as 98.33%. The potential power of the proposed method for computer-aided agricultural analysis systems is demonstrated.","2024-05","2025-02-26 20:37:03","2025-02-26 20:37:03","","1379-1388","","5","250","","","","","","","","","","English","","","","WOS:001170621400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","CNN; Fine-tuning; Multi-layer perceptron; Vision transformer; Wheat species","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"856G7AGX","journalArticle","2023","Zirka, SE; Albert, D; Moroz, YI; Domenig, LD; Schürhuber, R","Toward a simple topological model of a three-phase transformer including deep saturation conditions","COMPEL-THE INTERNATIONAL JOURNAL FOR COMPUTATION AND MATHEMATICS IN ELECTRICAL AND ELECTRONIC ENGINEERING","","0332-1649","10.1108/COMPEL-12-2022-0427","","Purpose - This paper aims to propose a method of parametrizing topological transformer model at high flux densities in the core. Design/methodology/approach - The approach proposed is based on terminal voltages and currents measured in a special purpose saturation test whose data are combined with typical saturation curves of grain -oriented electrical steels; the modeling is carried out in the ATPDraw program. Findings - The authors corroborate experimentally the necessity of dividing the zero sequence impedance between all transformer phases and propose a method of the individual representation of the legs and yokes. This eliminates the use of nonexistent leakage inductances of primary and secondary windings. Practical implications - The presented modeling approach can be used for predicting inrush current events and in the evaluation of the impact caused by geomagnetically induced currents (GICs) .Originality/value - The proposed approach is completely original and will contribute to a better understanding of the transients occurring in a transformer under abnormal conditions, such as inrush current events and GICs.","2023-09-07","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","","","","","","","","","","","English","","","","WOS:001171025100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;14</p>","","","Core saturation; Transformer model; Zero sequence representation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VHF9LNWC","journalArticle","2023","Hernández-Mena, CD; Ruiz, IVM","The state of end-to-end systems for Mexican Spanish speech recognition","PROCESAMIENTO DEL LENGUAJE NATURAL","","1135-5948","10.26342/2023-70-11","","Current end-to-end speech recognizer systems report an excellent perfor-mance for Spanish. However, this is not reported for specific variants. Moreover, it is unclear if there would be a benefit in creating a fine-tuned version for a particular variant. To investigate these aspects, particularly for Mexican Spanish, we evaluate four different of-the-shelf speech recognizers (one commercial and three open-source); additionally, we fine-tune two systems for Mexican Spanish. We evaluate read and spontaneous speech, present an error analysis and show that fine-tuning for a vari-ant decreases the error rate. As a result of our experimentation, we build two new systems available to the community.","2023-03","2025-02-26 20:37:03","2025-02-26 20:37:03","","135-144","","70","","","","","","","","","","","English","","","","WOS:000964244000011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","acoustic models; mexican spanish; speech recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GGQXL5DE","journalArticle","2024","Feng, B; Zhou, XP","Energy-informed graph transformer model for solid mechanical analyses","COMMUNICATIONS IN NONLINEAR SCIENCE AND NUMERICAL SIMULATION","","1007-5704","10.1016/j.cnsns.2024.108103","","Physics-informed neural network (PINN) exists some challenges, such as independent and uncorrelated drawbacks leading to convergence impediments, limited interpretability and lack of generalization. In this paper, a novel energy-informed graph transformer model is proposed to overcome the drawbacks of PINN. In the proposed model, the graph neural network-basedattention mechanism is proposed to dynamically calculate weight coefficients between objects of graph-structured data, and then to aggregate weighted combinations of the neighbor objects features to update features of the target objects. The loss function is constructed with homoscedastic uncertainty by introducing trainable scalar parameters, which can be optimized to achieve the best performance of the network as it changes dynamically the topology of the loss function involved in the optimization process. Numerical results show that the proposed method can effectively increase the efficiency, robustness and accuracy of the network approximation of forward and inverse problems of solid mechanics. Furthermore, the proposed model demonstrates excellent generalization capabilities when applied to new problem using transfer learning strategy.","2024-10","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","137","","","","","","","","","","English","","","","WOS:001256891300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Attention mechanism; DEEP NEURAL-NETWORKS; Energy -informed graph transformer; Homoscedastic uncertainty; Solid mechanics; Transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LZ8P3QP5","journalArticle","2024","Sun, LN; Wang, H; Qi, LH; Yan, JY; Jiang, MJ","Composite Harmonic Source Detection with Multi-Label Approach Using Advanced Fusion Method","ELECTRONICS","","2079-9292","10.3390/electronics13071275","","With the integration of clean energy and new power electronic devices into the power grid, the superposition of harmonic sources has become increasingly apparent and common. There is an urgent need to effectively identify composite harmonic sources in the new energy grid. This article proposes a multi-label composite harmonic source classification method that integrates knowledge representation with the transformer model. First, triplets from harmonic monitoring data are extracted and TransR models are used to train time-frequency feature representation vectors. Then, the transformer model is trained to learn the data features of different harmonic sources. Finally, based on the multi-label classification method, composite harmonic sources are identified. This article integrates the semantic information of time-frequency features into the data samples, increasing the interpretability of the model while expanding the inter-class features, which is conducive to the classification and recognition of the model. Compared with other deep learning recognition methods, verification based on simulation data and measured data shows that this method has low training complexity and higher recognition accuracy.","2024-04","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","7","13","","","","","","","","","","English","","","","WOS:001200845400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","composite harmonic sources; multi-label classification; transformer; TransR","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8Q259T5E","journalArticle","2024","Lee, S; Kim, H","Bidirectional de novo peptide sequencing using a transformer model","PLOS COMPUTATIONAL BIOLOGY","","1553-734X","10.1371/journal.pcbi.1011892","","In proteomics, a crucial aspect is to identify peptide sequences. De novo sequencing methods have been widely employed to identify peptide sequences, and numerous tools have been proposed over the past two decades. Recently, deep learning approaches have been introduced for de novo sequencing. Previous methods focused on encoding tandem mass spectra and predicting peptide sequences from the first amino acid onwards. However, when predicting peptides using tandem mass spectra, the peptide sequence can be predicted not only from the first amino acid but also from the last amino acid due to the coexistence of b-ion (or a- or c-ion) and y-ion (or x- or z-ion) fragments in the tandem mass spectra. Therefore, it is essential to predict peptide sequences bidirectionally. Our approach, called NovoB, utilizes a Transformer model to predict peptide sequences bidirectionally, starting with both the first and last amino acids. In comparison to Casanovo, our method achieved an improvement of the average peptide-level accuracy rate of approximately 9.8% across all species. Understanding the characteristics of data is very important in deep learning methods. When predicting sentences, the transformer model naturally predicts from the first word. For this reason, previous methods predicted peptide sequences from the first amino acid. However, in tandem mass spectra, it is possible to predict peptide sequences bidirectionally. This method shows better results than previous approaches because it can better encode tandem mass spectra. We have demonstrated that good results can be achieved simply by understanding the characteristics of such data and using the model appropriately. We hope that this paper will help various readers improve the performance capabilities of their models. Furthermore, given that bidirectional peptide sequence prediction is crucial in de novo peptide sequence analysis, we hope that this approach will be applied to both existing and future methods utilizing deep learning techniques.","2024-02","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","2","20","","","","","","","","","","English","","","","WOS:001181561100004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","PROTEOME","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C28EDV9W","journalArticle","2022","Wang, NX; Cai, XY; Yang, LB; Mei, X","Safe medicine recommendation via star interactive enhanced-based transformer model","COMPUTERS IN BIOLOGY AND MEDICINE","","0010-4825","10.1016/j.compbiomed.2021.105159","","With the rapid development of electronic medical records (EMRs), most existing medicine recommendation systems based on EMRs explore knowledge from the diagnosis history to help doctors prescribe medication correctly. However, due to the limitations of the EMRs' content, recommendation systems cannot explicitly reflect relevant medical data, such as drug interactions. In recent years, medicine recommendation approaches based on medical knowledge graphs and graph neural networks have been proposed, and the methods based on the Transformer model have been widely used in medicine recommendation systems. Transformer-based medicine recommendation approaches are readily applicable to inductive problems. Unfortunately, traditional Transformer-based medicine recommendation approaches require complex computing power and suffer information loss among the multi-heads in Transformer model, which causes poor performance. At the same time, these approaches have rarely considered the side effects of drug interaction in traditional medical recommendation approaches. To overcome the drawbacks of the current medicine recommendation approaches, we propose a Star Interactive Enhanced-based Transformer (SIET) model. It first constructs a high-quality heterogeneous graph by bridging EMR (MIMIC-III) and a medical knowledge graph (ICD-9 ontology and DrugBank). Then, based on the constructed heterogeneous graph, it extracts a disease homogeneous graph, a medicine homogeneous graph, and a negative factors homogeneous graph to get auxiliary information of disease or drug (named enhanced neighbors). These are fed into the SIET model in conjunction with the relevant information in the EMRs to obtain representations of diseases and drugs. It finally generates the recommended drug list by calculating the cosine similarity between disease combination representations and drug combination representations. Extensive experiments on the MIMIC-III, DrugBank, and ICD-9 ontology datasets demonstrate the outstanding performance of our proposed model. Meanwhile, we show that our SIET model outperforms strong baselines on an inductive medicine recommendation task.","2022-02","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","141","","","","","","","","","","English","","","","WOS:000747358300004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Graph embedding; Medicine recommendation; ONTOLOGY; Star interactive enhanced-based transformer; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ILI277VB","journalArticle","2024","Pacal, I","Enhancing crop productivity and sustainability through disease identification in maize leaves: Exploiting a large dataset with an advanced vision transformer model","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2023.122099","","The timely identification of diseases in maize leaf offers several benefits such as increased crop productivity, reduced reliance on harmful chemicals, and improved production of healthy crops, resulting in enhanced economic returns. Computer-aided systems (CAD) play a crucial role in agriculture by enabling timely and efficient disease identification in plant leaves. Deep learning-based CAD systems facilitate accurate and rapid diagnosis of maize leaf diseases. In this research, we introduce an advanced vision transformer model that achieves exceptional accuracy and inference speed in detecting diseases in maize leaves. To begin with, we adapt the Multi-axis vision transformer (MaxViT) model to a 4-class maize dataset, creating a lightweight structure that offers improved accuracy and inference speed. Furthermore, we enhance the accuracy by replacing the conventional convolutional structure in the MaxViT architecture's Stem with a Squeeze-and-Excitation (SE) block. In addition, to boost accuracy further, we employ the Global Response Normalization (GRN)-based MLP from the ConvNexTv2 architecture instead of the MLP in the MaxViT architecture. Notably, we combine the PlantVillage, PlantDoc, and CD&S datasets from the literature, resulting in the creation of the most extensive dataset available. This dataset is then divided into three sets: training, validation, and testing, enabling the evaluation of the generalization abilities of the deep learning models. Our study goes beyond previous research by offering a comprehensive comparison of the performance of over 28 CNN models and more than 36 vision transformer models on the newly created dataset. By achieving a remarkable accuracy rate of 99.24% and a high inference speed, the proposed method outperforms all existing deep learning models in the literature. Therefore, it has been demonstrated that this advanced vision transformer model, based on MaxViT, is exceedingly effective for practical applications in agriculture.","2024-03-15","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","238","","","","","","","","","","English","","","","WOS:001097333500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;37<br/>Total Times Cited:&nbsp;&nbsp;37<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","CNN architectures; Maize disease classification; Multi-axis vision transformer; Plant disease detection; Vision Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UN2GBZSX","journalArticle","2022","Wang, HQ; Shang, SQ; Wang, DW; He, XN; Feng, K; Zhu, H; Li, CP; Wang, YT","Optimized lightweight CA-transformer: Using transformer for fine-grained visual categorization","ECOLOGICAL INFORMATICS","","1574-9541","10.1016/j.ecoinf.2022.101827","","As a rapidly developing research direction in computer vision (CV), related algorithms such as image classifi-cation and object detection have achieved inevitable research progress. Improving the accuracy and efficiency of algorithms for fine-grained identification of plant diseases and birds in agriculture is essential to the dynamic monitoring of agricultural environments. In this study, based on the computer vision detection and classification algorithm, combined with the architecture and ideas of the CNN model, the mainstream Transformer model was optimized, and then the CA-Transformer (Transformer Combined with Channel Attention) model was proposed to improve the ability to identify and classify critical areas. The main work is as follows: (1) The C-Attention mechanism is proposed to strengthen the feature information extraction within the patch and the communication between feature information so that the entire network can be fully attentive while reducing the computational overhead; (2) The weight-sharing method is proposed to transfer parameters between different layers, improve the reusability of model data, and at the same time increase the knowledge distillation link to reduce problems such as excessive parameters and overfitting; (3) Token Labeling is proposed to generate score labels according to the position of each Token, and the total loss function of this study is proposed according to the CA-Transformer model structure. The performance of the CA-Transformer model proposed in this study is compared with the current mainstream models on datasets of different scales, and ablation experiments are performed. The results show that the accuracy and mIoU of the CA-Transformer proposed in this study reach 82.89% and 53.17MS, respectively, and have good transfer learning ability, indicating that the model has good performance in fine-grained visual categorization tasks and can be used in ecological information. In the context of more diverse ecological information, this study can provide reference and inspiration for the practical application of information.","2022-11","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","71","","","","","","","","","","English","","","","WOS:000868913800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Attention mechanism; Fine-grained visual categorization; Group Conv; Instance segmentation; Object detection; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P9SB3IT2","journalArticle","2024","Shang, YT; Li, S","FedPT-V2G: Security enhanced federated transformer learning for real-time V2G dispatch with non-IID data","APPLIED ENERGY","","0306-2619","10.1016/j.apenergy.2024.122626","","The rising popularity of electric vehicles (EVs) underscores the potential of vehicle-to-grid (V2G) technology to contribute to load peak-shaving, valley-filling, and photovoltaic (PV) self-consumption. Effective V2G control strategies can be obtained by data-driven techniques, which is able to leverage historical and current data to inform future decision-making amidst uncertainties. However, the centralized collection and sharing of data among charging stations face challenges due to data asset concerns. Furthermore, even if data sharing hurdles are overcome, the non-independent and non-identically distributed (Non-IID) nature of data across charging stations can still negatively impact performance. In this study, we introduce FedPT-V2G, a security-enhanced federated transformer learning approach for real-time V2G dispatch that addresses Non-IID data. We employ deep learning models trained on historical and current data to enable real-time decision-making, facilitating both load shifting and PV self-consumption. Additionally, we utilize federated learning to jointly train a global model across all charging stations without collecting or sharing any local private data. We pioneer the application of the Proximal algorithm and Transformer model to tackle data distribution discrepancies within the V2G scheduling prediction task. The Proximal algorithm employs regularization techniques to align local models at each charging station more closely with the global model during updates. Concurrently, the multi-head attention mechanism within the Transformer model allows learned feature vectors to diverge, enabling better exploitation of variations across the entire feature space. Finally, we validate the proposed FedPT-V2G approach through extensive numerical simulations, demonstrating comparable performance to centralized learning on both balanced (98.93% vs 98.65%) and imbalanced (92.15% vs 92.20% in label skew) datasets.","2024-03-15","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","358","","","","","","","","","","English","","","","WOS:001156297700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;26<br/>Total Times Cited:&nbsp;&nbsp;26<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Digital asset security; Federated learning; High-efficient; Non-IID data; Proximal algorithm; Transformer model; Vehicle-to-grid","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YV93XJMK","journalArticle","2024","Kumar, N; Rajeswari, P; Priya, DJ; Maguesvari, MU","Forecasting municipal solid waste generation using advanced transformer and multi-layer perceptron techniques","CLEAN TECHNOLOGIES AND ENVIRONMENTAL POLICY","","1618-954X","10.1007/s10098-024-03091-8","","Municipal Solid Waste generation forecasting is crucial for the treatment process, policy decision-making, and waste management. The challenges of accurately predicting municipal solid waste generation have become increasingly crucial for effective urban waste management. Therefore, this paper presents a novel Lightweight GraphFormer model designed to enhance both the accuracy and efficiency of Municipal Solid Waste generation predictions by integrating temporal and spatial dependencies within waste data. This proposed approach is designed by combining a graph graph-based transformer model with a Lightweight Multi-Layer Perceptron. Statistics and World Bank Database is used to collect Municipal solid waste data and is preprocessed to handle the missing data in the database by using the imputation approach. Further, the embedded data are fed into the long short-term memory model for effectively learning and extracting temporal features. The objective of the graph-based transformer model is to extract potential spatial dependence and dominant attention. The novel Multi-Layer Perceptron such as Precurrent Multi-Layer Perceptron is used within the transformer model that perceives temporal locality features by fusing feature representations from different time steps. The performance evaluation is conducted through different time series data analyses and quantitative analyses that demonstrate better forecasting performance in municipal solid waste generation. The time series data analyses are conducted for different types of wastes such as textile, garden, metal, food, glass, plastic, paper, and others. The quantitative analysis provided that the proposed model attained better performances of 98.76%, 0.982, and 0.078 from forecasting accuracy, correlation coefficient, and RMSE respectively than other existing research articles. These results illustrate the model's potential to significantly enhance the field of waste management by providing improved predictive capabilities, while maintaining low computational complexity.","2024-12-16","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","","","","","","","","","","","English","","","","WOS:001378320000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","Dynamic graph learning; Graph convolutional network; Long-short term memory; Municipal solid waste generation; Precurrent multi-layer perceptron; Probsparse self-attention; Time series data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3IC5H5FR","journalArticle","2024","Huo, HR; Guo, WX; Yang, RN; Liu, XR; Xue, JY; Peng, QM; Deng, YW; Sun, XY; Lv, CL","Data-Driven Strategies for Complex System Forecasts: The Role of Textual Big Data and State-Space Transformers in Decision Support","SYSTEMS","","2079-8954","10.3390/systems12050171","","In this research, an innovative state space-based Transformer model is proposed to address the challenges of complex system prediction tasks. By integrating state space theory, the model aims to enhance the capability to capture dynamic changes in complex data, thereby improving the accuracy and robustness of prediction tasks. Extensive experimental validations were conducted on three representative tasks, including legal case judgment, legal case translation, and financial data analysis to assess the performance and application potential of the model. The experimental results demonstrate significant performance improvements of the proposed model over traditional Transformer models and other advanced variants such as Bidirectional Encoder Representation from Transformers (BERT) and Finsformer across all evaluated tasks. Specifically, in the task of legal case judgment, the proposed model exhibited a precision of 0.93, a recall of 0.90, and an accuracy of 0.91, significantly surpassing the traditional Transformer model (with precision of 0.78, recall of 0.73, accuracy of 0.76) and performances of other comparative models. In the task of legal case translation, the precision of the proposed model reached 0.95, with a recall of 0.91 and an accuracy of 0.93, also outperforming other models. Likewise, in the task of financial data analysis, the proposed model also demonstrated excellent performance, with a precision of 0.94, recall of 0.90, and accuracy of 0.92. The state space-based Transformer model proposed not only theoretically expands the research boundaries of deep learning models in complex system prediction but also validates its efficiency and broad application prospects through experiments. These achievements provide new insights and directions for future research and development of deep learning models, especially in tasks requiring the understanding and prediction of complex system dynamics.","2024-05","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","5","12","","","","","","","","","","English","","","","WOS:001231254900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;92</p>","","","big-data driven; complex system; deep learning; loss function optimization; PREDICTION; state-space models; transformer architecture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AJKUYSPL","journalArticle","2024","Lee, N; Kim, SH; Lee, M; Woo, J","Advancing Continuous Blood Pressure Estimation with Transformer on Photoplethysmography in Operation Room","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3417940","","Continuous invasive arterial blood pressure (ABP) monitoring can immediately monitor changes in blood pressure in the operating room and intensive care unit and detect hemodynamic disorders such as hypotension for faster response. We propose a transformer model for real-time blood pressure estimation using only noninvasive photoplethysmography (PPG) without specific feature engineering. We collected vital signs during the operation, including invasive arterial blood pressure (ABP) and PPG at the Soonchunhyang University Bucheon Hospital. The transformer model represents vital signs as high-dimensional vectors and includes context vectors using self-attention to understand them in the context of neighbouring values. We develop a unified model that estimates continuous blood pressure, offering insights for detecting abnormal signals and enabling early intervention, particularly in surgical scenarios under anaesthesia where hypotension symptoms may appear. Our model outperforms previous approaches for the intensive care unit data and the operation room data. The mean absolute error (MAE) +/- standard deviation (SD) was 1.20 +/- 1.04 mmHg for arterial blood pressure (ABP), 1.04 +/- 0.91 mmHg for systolic blood pressure (SBP), and 0.89 +/- 0.68 mmHg for diastolic blood pressure (DBP) on the operation room data. The performance of the proposed model based on MIMIC II data is 1.54 +/- 1.31 mmHg for arterial blood pressure (ABP), 1.24 +/- 1.14 mmHg for systolic blood pressure (SBP), and 1.59 +/- 0.82 mmHg for diastolic blood pressure (DBP). In this study, we succeeded in estimating real-time ABP using a transformer-based model, emphasizing its ability to handle vital signs data from the operating room, its use of token embedding and self-attention, and the unified modelling of continuous blood pressure for improved detection and intervention in medical scenarios.","2024","2025-02-26 20:37:03","2025-02-26 20:37:03","","90486-90500","","","12","","","","","","","","","","English","","","","WOS:001263413400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","BENCHMARK; Biomedical monitoring; Blood pressure; Electrocardiography; estimation; Feature extraction; HEART-RATE; Hospitals; MEASURING DEVICES; MIMICs; Monitoring; photoplethysmography; SOCIETY; time series; transformer model; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GIYTCWZY","journalArticle","2023","Kim, J; Kim, HS; Choi, SY","Forecasting the S&P 500 Index Using Mathematical-Based Sentiment Analysis and Deep Learning Models: A FinBERT Transformer Model and LSTM","AXIOMS","","2075-1680","10.3390/axioms12090835","","Stock price prediction has been a subject of significant interest in the financial mathematics field. Recently, interest in natural language processing models has increased, and among them, transformer models, such as BERT and FinBERT, are attracting attention. This study uses a mathematical framework to investigate the effects of human sentiment on stock movements, especially in text data. In particular, FinBERT, a domain-specific language model based on BERT tailored for financial language, was employed for the sentiment analysis on the financial texts to extract sentiment information. In this study, we use ""summary"" text data extracted from The New York Times, representing concise summaries of news articles. Accordingly, we apply FinBERT to the summary text data to calculate sentiment scores. In addition, we employ the LSTM (Long short-term memory) methodology, one of the machine learning models, for stock price prediction using sentiment scores. Furthermore, the LSTM model was trained by stock price data and the estimated sentiment scores. We compared the predictive power of LSTM models with and without sentiment analysis based on error measures such as MSE, RMSE, and MAE. The empirical results demonstrated that including sentiment scores through the LSTM model led to improved prediction accuracy for all three measures. These findings indicate the significance of incorporating news sentiment into stock price predictions, shedding light on the potential impact of psychological factors on financial markets. By using the FinBERT transformer model, this study aimed to investigate the interplay between sentiment and stock price predictions, contributing to a deeper understanding of mathematical-based sentiment analysis in finance and its role in enhancing forecasting in financial mathematics. Furthermore, we show that using summary data instead of entire news articles is a useful strategy for mathematical-based sentiment analysis.","2023-09","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","9","12","","","","","","","","","","English","","","","WOS:001074212800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","FinBERT; IMPACT; LSTM; machine learning model; MACROECONOMIC INDICATORS; mathematical-based sentiment analysis; NEWS SENTIMENT; PREDICTION; PRICE; SOCIAL MEDIA; stock price forecast; STOCK RETURNS; transformer model; TWITTER; VOLATILITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LD58YGEG","journalArticle","2025","Zuo, YQ; Zhang, YF; Zhang, QY; Zhang, WB","Knowledge-aware recommendation based on hypergraph representation learning and transformer model optimization","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-025-06257-z","","Recommendation algorithms based on knowledge graphs (KGs) have been a research focus and hotspot in the field of recommendation systems in recent years. This is mainly because the introduction of a KG can yield auxiliary information about the item of interest and achieve more accurate recommendation effects for users. However, such a model faces two major challenges in predictive tasks. First, these methods find it difficult to capture the interaction information between users and items from a global perspective. Second, in most cases, noisy data, which result from users mistakenly clicking on items they are not interested in, exist in KGs, and these noisy data have a negative impact on the resulting recommendation effect. To address these challenges, this paper proposes a knowledge-aware recommendation approach based on hypergraph representation learning and transformer model optimization (KHRT), which employs a hypergraph that can be used to directly model higher-order relations, thereby enriching the interaction information between users and items. Owing to the lack of global interaction information between users and items in local graphs, a global hypergraph is constructed within the given local graph. Conversely, nonglobal graphs contain redundant information; thus, a nonglobal hypergraph is constructed, enabling the capture of more comprehensive interaction information between users and items. Moreover, the multihead attention mechanism of the transformer model is used to enhance the cooperative relationships between user nodes and item nodes, and more valuable preference information is mined from noisy user interaction data, such as items that users are not interested in. The embeddings of user and item nodes are optimized to alleviate noise interference and achieve improved recommendation performance based on user preferences. Experiments conducted on three real recommendation datasets indicate that the proposed approach outperforms the state-of-the-art traditional recommendation methods and KG-based methods in almost all comparisons.","2025-04","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","5","55","","","","","","","","","","English","","","","WOS:001396810900003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Hypergraph; Knowledge graph; Knowledge-aware recommendation; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MZZ94ATJ","journalArticle","2022","Rimmele, JM; Kern, P; Lubinus, C; Frieler, K; Poeppel, D; Assaneo, MF","Musical Sophistication and Speech Auditory-Motor Coupling: Easy Tests for Quick Answers","FRONTIERS IN NEUROSCIENCE","","1662-453X","10.3389/fnins.2021.764342","","Musical training enhances auditory-motor cortex coupling, which in turn facilitates music and speech perception. How tightly the temporal processing of music and speech are intertwined is a topic of current research. We investigated the relationship between musical sophistication (Goldsmiths Musical Sophistication index, Gold-MSI) and spontaneous speech-to-speech synchronization behavior as an indirect measure of speech auditory-motor cortex coupling strength. In a group of participants (n = 196), we tested whether the outcome of the spontaneous speech-to-speech synchronization test (SSS-test) can be inferred from self-reported musical sophistication. Participants were classified as high (HIGHs) or low (LOWs) synchronizers according to the SSS-test. HIGHs scored higher than LOWs on all Gold-MSI subscales (General Score, Active Engagement, Musical Perception, Musical Training, Singing Skills), but the Emotional Attachment scale. More specifically, compared to a previously reported German-speaking sample, HIGHs overall scored higher and LOWs lower. Compared to an estimated distribution of the English-speaking general population, our sample overall scored lower, with the scores of LOWs significantly differing from the normal distribution, with scores in the similar to 30th percentile. While HIGHs more often reported musical training compared to LOWs, the distribution of training instruments did not vary across groups. Importantly, even after the highly correlated subscores of the Gold-MSI were decorrelated, particularly the subscales Musical Perception and Musical Training allowed to infer the speech-to-speech synchronization behavior. The differential effects of musical perception and training were observed, with training predicting audio-motor synchronization in both groups, but perception only in the HIGHs. Our findings suggest that speech auditory-motor cortex coupling strength can be inferred from training and perceptual aspects of musical sophistication, suggesting shared mechanisms involved in speech and music perception.","2022-01-04","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","15","","","","","","","","","","English","","","","WOS:000745232200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","auditory-motor coupling; CORTICAL TRACKING; ENTRAINMENT; EXPERTISE; musical sophistication; musical training; MUSICIANS; OSCILLATIONS; PERCEPTION; PERCUSSIONISTS; PLASTICITY; RHYTHM; speech; synchronization; VOCALISTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JNW4HS2P","journalArticle","2024","Zhang, RH; Zhou, L; Gao, C; Tao, LJ","Real-time predictions of the 2023-2024 climate conditions in the tropical Pacific using a purely data-driven Transformer model","SCIENCE CHINA-EARTH SCIENCES","","1674-7313","10.1007/s11430-024-1396-x","","Following triple La Ni & ntilde;a events during 2020-2022, the future evolution of climate conditions over the tropical Pacific has been a focused interest in ENSO-related communities. Observations and modeling studies indicate that an El Ni & ntilde;o event is occurring in 2023; however, large uncertainties remain in terms of its detailed evolution, and the factors affecting its resultant amplitude remain to be understood. Here, a novel deep learning-based Transformer model is adopted to make real-time predictions for the 2023-2024 climate conditions in the tropical Pacific. Several key fields vital to the El Ni & ntilde;o and Southern Oscillation (ENSO) in the tropical Pacific are collectively and simultaneously utilized in model training and in making predictions; therefore, this purely data-driven model is configured in both training and predicting procedures such that the coupled ocean-atmosphere interactions are adequately represented. Also similar to dynamic models, the prediction procedure is executed in a rolling manner to allow ocean-atmosphere anomaly exchanges month by month; the related key fields during multi-month time intervals (TIs) prior to prediction target months are taken as input predictors, serving as initial conditions to precondition the future evolution more effectively. Real-time predictions indicate that the climate conditions in the tropical Pacific are surely to develop into an El Ni & ntilde;o state in late 2023. Furthermore, sensitivity experiments are conducted to examine how prediction skills are affected by the input predictor specifications, including TIs during which information on initial conditions is retained for making predictions. A comparison with other dynamic coupled models is also made to demonstrate the prediction performance for the 2023-2024 El Ni & ntilde;o event.","2024-12","2025-02-26 20:37:03","2025-02-26 20:37:03","","3709-3726","","12","67","","","","","","","","","","English","","","","WOS:001335893900003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","3D-Geoformer; Coupling representation; EL-NINO; ENSO; EQUATORIAL PACIFIC; FORECASTS; INTERMEDIATE COUPLED MODEL; o; OCEAN; Performance and evaluation; PREDICTABILITY; Real-time prediction; REANALYSIS; The 2023-2024 El Ni & ntilde; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8WJF5PR3","journalArticle","2023","Zhang, Z; Liu, FC; Liu, CA; Tian, Q; Qu, HQ","ACTNet: A Dual-Attention Adapter with a CNN-Transformer Network for the Semantic Segmentation of Remote Sensing Imagery","REMOTE SENSING","","2072-4292","10.3390/rs15092363","","In recent years, the application of semantic segmentation methods based on the remote sensing of images has become increasingly prevalent across a diverse range of domains, including but not limited to forest detection, water body detection, urban rail transportation planning, and building extraction. With the incorporation of the Transformer model into computer vision, the efficacy and accuracy of these algorithms have been significantly enhanced. Nevertheless, the Transformer model's high computational complexity and dependence on a pre-training weight of large datasets leads to a slow convergence during the training for remote sensing segmentation tasks. Motivated by the success of the adapter module in the field of natural language processing, this paper presents a novel adapter module (ResAttn) for improving the model training speed for remote sensing segmentation. The ResAttn adopts a dual-attention structure in order to capture the interdependencies between sets of features, thereby improving its global modeling capabilities, and introduces a Swin Transformer-like down-sampling method to reduce information loss and retain the original architecture while reducing the resolution. In addition, the existing Transformer model is limited in its ability to capture local high-frequency information, which can lead to an inadequate extraction of edge and texture features. To address these issues, this paper proposes a Local Feature Extractor (LFE) module, which is based on a convolutional neural network (CNN), and incorporates multi-scale feature extraction and residual structure to effectively overcome this limitation. Further, a mask-based segmentation method is employed and a residual-enhanced deformable attention block (Deformer Block) is incorporated to improve the small target segmentation accuracy. Finally, a sufficient number of experiments were performed on the ISPRS Potsdam datasets. The experimental results demonstrate the superior performance of the model described in this paper.","2023-04-29","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","9","15","","","","","","","","","","English","","","","WOS:000987054500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","adapter; remote sensing; semantic segmentation; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KT9UJTY4","journalArticle","2025","Zhu, QL; Chen, DH; Wang, ZG; Lv, BB; Zhao, ZL; Zhao, J","VSPNet: a vehicle speed prediction model incorporating transformer and BiLSTM","MEASUREMENT SCIENCE AND TECHNOLOGY","","0957-0233","10.1088/1361-6501/ada3eb","","In recent years, with the increasing adoption of hybrid vehicles, energy management strategies have become a prominent research focus. Accurate vehicle speed prediction (VSP) is a critical prerequisite for achieving optimal results in predictive energy management strategies. However, existing speed prediction algorithms fail to fully leverage vehicle data to enhance prediction accuracy. Therefore, a novel VSP Net (VSPNet) is proposed in this study. Firstly, we constructed a combined cycle condition for model training through comprehensive analysis and analyzed the vehicle feature parameters through the random forest algorithm and Pearson correlation analysis to select the best input feature parameters. Then a VSPNet speed prediction model is proposed based on the Transformer model. In the encoder part, firstly, by assigning weights to the input feature parameters and incorporating the temporal attention mechanism, the model is made to make better use of the input features from two dimensions, and at the same time the Transformer model's encoder based on positional coding combined with Bi-directional Long Short-Term Memory belonging to recurrent neural networks, which is used as a decoder to better catch and handle long-term dependencies in sequence data. Finally, a comparative experiment between VSPNet and the classical speed prediction models was carried out. The proposed VSPNet model reduces the root mean square error (RMSE) by 37%, 22%, and 20% and mean absolute error (MAE) by 39%, 25, and 24% compared to the LSTM model for the prediction time horizons of 3, 5, and 8 s. The RMSE is reduced by 47%, 28%, and 7%, and the MAE is reduced by 47%, 30%, and 9% compared to the Transformer model for the prediction time horizons of 3, 5, and 8 s. The experimental results demonstrate the superiority of this speed prediction model.","2025-02-28","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","2","36","","","","","","","","","","English","","","","WOS:001393202200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","ARIMA; BiLSTM; ENERGY MANAGEMENT STRATEGY; random forest; time series forecast; transformer; vehicle speed prediction; VELOCITY PREDICTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3BTEM2HK","journalArticle","2024","Pan, SY; Shi, XD; Dong, BB; Skvaril, J; Zhang, HR; Liang, YT; Li, HL","Multivariate time series prediction for CO2 concentration and flowrate of flue gas from biomass-fired power plants","FUEL","","0016-2361","10.1016/j.fuel.2023.130344","","Integrating CO2 capture with biomass-fired combined heat and power (bio-CHP) plants is a promising method to achieve negative emissions. However, the use of versatile biomass, including waste, and the dynamic operation of bio-CHP plants leads to large fluctuations in the flowrate and CO2 concentration of the flue gas (FG), which further affect the operation of post-combustion CO2 capture. To optimize the dynamic operation of CO2 capture, a reliable model to predict the FG flowrate and CO2 concentration in real time is essential. In this paper, a datadriven model based on the Transformer architecture is developed. The model validation shows that the root mean squared error (RMSE), mean absolute percentage error (MAPE), and Pearson correlation coefficient (PPMCC) of Transformer are 0.3553, 0.0189, and 0.8099 respectively for the prediction of FG flowrate; and 13.137, 0.0318, and 0.8336 respectively for the prediction of CO2 concentration. The potential impact of various meteorological parameters on model accuracy is also assessed by analyzing the Shapley value. It is found that temperature and direct horizontal irradiance (DHI) are the most important factors, which should be selected as input features. In addition, using the near-infrared (NIR) spectral data as input features is also found to be an effective way to improve the prediction accuracy. It can reduce RMSE and MAPE for CO2 concentration from 0.2982 to 0.2887 and 0.0158 to 0.0157 respectively, and RMSE and MAPE for FG flowrate from 4.9854 to 4.7537 and 0.0141 to 0.0121 respectively. The Transformer model is also compared to other models, including long short-term memory network (LSTM) and artificial neural network (ANN), which results show that the Transformer model is superior in predicting complex dynamic patterns and nonlinear relationships.","2024-03-01","2025-02-26 20:37:03","2025-02-26 20:37:03","","","","","359","","","","","","","","","","English","","","","WOS:001125955300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Biomass fired combined heat and power plants; CAPTURE; CO 2 capture; CO 2 concentration; COMBUSTION; Deep learning; Flue gas flowrate; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3KACNXKA","journalArticle","2021","Nariai, T; Itai, S; Kojima, H","Speech Analysis to Evaluate Robot-Assisted Recreation of Older Adults with Dementia","JOURNAL OF ROBOTICS AND MECHATRONICS","","0915-3942","10.20965/jrm.2021.p0777","","We investigated robot-assisted recreation (RAR) for improving the quality of life (QoL) of older adults with dementia in an aged care facility. However, as a simple method to evaluate RAR has not been established at the field level, limited scientific data exists to show its effectiveness. To solve this problem, we studied a method to evaluate RAR based on speech analysis, which can reduce the burden on subjects (older adults) and data analysts. This study conducted both subjective and objective analyses of speech data. Subjective analysis based on the transcripts of speech data resulted in findings that supported and added to the knowledge of previous research, such as an increased willingness to participate in RAR, positive feelings toward the future, and interest in interacting with others. The results of the objective analysis based on the fundamental frequency (F0) demonstrated that there was a difference in the distribution of F0 during RAR and the interviews conducted before and after RAR. This study thus provides the prospect for easy evaluation of recreational activities, including RAR, in aged care facilities at the field level using speech analysis.","2021-08","2025-02-26 20:37:04","2025-02-26 20:37:04","","777-783","","4","33","","","","","","","","","","English","","","","WOS:000687135200009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","COMMUNICATION ROBOT; human-robot interaction; LONELINESS; neurological therapy; non-pharmacological therapy; robotic seals; technology acceptance; THERAPY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"24ISAKWR","journalArticle","2021","Friedmann, N; Reznick, J","Stages rather than ages in the acquisition of movement structures: Data from sentence repetition and 27696 spontaneous clauses","GLOSSA-A JOURNAL OF GENERAL LINGUISTICS","","2397-1835","10.16995/glossa.5716","","This study explored the order of acquisition of various types of syntactic-movement and embedding structures in Hebrew, using a sentence-repetition task, in which 60 children aged 2;2-3;10 repeated 80 sentences (with a total of 4800 sentences), and an analysis of the spontaneous speech of 61 children aged 1;6-6;1 (27,696 clauses: a group analysis of 56 children each with one sample, and a longitudinal analysis of 5 children). The sentence repetition task revealed a set order of acquisition of the various types of syntactic movement: A-movement is acquired first, then A-bar-movement, and finally movement of the verb to C. The analysis of spontaneous speech revealed the same order, and added several structures: A-movement of the object of unaccusative verbs to subject position appears first, together with simple SV sentences; then, wh-questions appear; then relative clauses and topicalization appear together with embedding of finite clauses, and lastly, V-to-C movement. Previous studies have shown that Hebrew speakers under age six have difficulty comprehending and producing sentences with A-bar-movement in which a lexically-restricted object crosses over a lexically-restricted subject. And indeed, whereas children produced A-bar structures very early (in the group samples, wh-questions appeared from age 1;6, relative-clauses and topicalization from age 2;6), until age 5;8 these structures never included a lexical DP crossing over another lexical DP. Both tasks indicated that the order of structure acquisition is fixed, creating Guttman scales between structures, but different children acquire the same structure at very different ages. It seems that whereas the syntactic path and the stages of structure acquisition along it are constant between children, each child walks this path in their own pace.","2021-12-23","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","1","6","","","","","","","","","","English","","","","WOS:000736135000005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;155</p>","","","COMPLEMENT CLAUSES; COMPREHENSION; ENGLISH; EUROPEAN PORTUGUESE; GERMAN; HEBREW-SPEAKING CHILDREN; LANGUAGE IMPAIRMENT; MORPHOLOGY; QUESTIONS; RELATIVE CLAUSES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BMUWA5F7","journalArticle","2021","Xu, S; Yan, ZJ; Pan, YQ; Yang, Q; Liu, ZL; Gao, JJ; Yang, YH; Wu, YF; Zhang, YA; Wang, JH; Zhuang, R; Li, C; Zhang, YL; Jia, J","Associations between Upper Extremity Motor Function and Aphasia after Stroke: A Multicenter Cross-Sectional Study","BEHAVIOURAL NEUROLOGY","","0953-4180","10.1155/2021/9417173","","Background and Purpose. Poststroke aphasia (PSA) often coexists with upper extremity (UE) motor dysfunction. However, whether the presence of PSA affects UE motor performance, and if language function associates with UE motor performance, are unclear. This study is aimed at (1) comparing the motor status of UE between patients with PSA and without PSA and (2) investigating the association between language function and UE motor status in patients with PSA. Methods. Patients with stroke were compared and correlated from overall and three periods (1-3 months, 4-6 months, and >6 months). Fugl-Meyer assessment for the upper extremity (FMA-UE) and action research and arm test (ARAT) were used to compare the UE motor status between patients with PSA and without PSA through a cross-sectional study among 435 patients. Then, the correlations between the evaluation scale scores of UE motor status and language function of patients with PSA were analyzed in various dimensions, and the language subfunction most closely related to UE motor function was analyzed by multiple linear regression analysis. Results. We found that the scores of FMA-UE and ARAT in patients with PSA were 14 points ((CI) 10 to 18, p<0.001) and 11 points lower ((CI) 8 to 13, p<0.001), respectively, than those without PSA. Their FMA-UE (r=0.70, p<0.001) and ARAT (r=0.62, p<0.001) scores were positively correlated with language function. Regression analysis demonstrated that spontaneous speech ability may account for UE motor function (R2=0.51, p<0.001; R2=0.42, p<0.001). Consistent results were also obtained from the analyses within the three time subgroups. Conclusion. Stroke patients with PSA have worse UE motor performance. UE motor status and language function showed positive correlations, in which spontaneous speech ability significantly accounts for the associations.","2021-11-09","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","2021","","","","","","","","","","English","","","","WOS:000727560000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","LANGUAGE; RECOVERY; SPEECH; THERAPY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WUZVMJRH","journalArticle","2023","Naranjo, NP; del Río, D; Nieva, S; Alted, C","Descriptive discourse in fluent aphasia: The predictive role of attention, phonology, lexical retrieval and semantics","JOURNAL OF COMMUNICATION DISORDERS","","0021-9924","10.1016/j.jcomdis.2023.106335","","Aims: To study the relationship between cognitive and linguistic skills (as measured through standardized tasks) over spontaneous speech elicited during a picture description task. Methods & procedures: 21 controls and 19 people with fluent aphasia matched by age and sex were evaluated using transcripts made from a picture description task coded using the CHAT format and analyzed using Computerized Language Analysis (CLAN). Indices obtained from the speech samples contained measures of lexical quantity and diversity, morphosyntactic complexity, informativeness, and speech fluency, along with different kinds of speech errors. We studied their correlations with attentional measures from Conners' Continuous Performance Test and with standardized measures of naming, pseudoword repetition and semantic non-verbal association. We further used stepwise linear regression to analyze the predictive value of standardized lin-guistic and cognitive skills over discursive indices. Outcomes & results: Contrary to our initial hypothesis, there were no significant correlations be-tween attentional scores and discourse variables in aphasic participants. Moreover, semantic association, along with naming, was the measure more related with discourse performance in people with fluent aphasia, but cognitive and linguistic standardized measures had overall little predictive power on most discourse indices. In the control group, there was a certain association of naming skills and attentional reaction time with discourse variables, but their predictive power was also low. Conclusions & implications: The current results do not support a strong relationship between basic attentional skills and performance in descriptive discourse in fluent aphasia. Although some of the standardized tasks seem to bear some relationship with spontaneous speech, there is a high amount of interindividual variability in discourse that is not captured by classical cognitive tasks routinely used in assessment. Further work on the determinants of discourse performance in aphasia and on the clinical application of discourse analysis is warranted.","2023-07","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","104","","","","","","","","","","English","","","","WOS:001008830900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","ADULTS; Aphasia; Attention; COMMUNICATION; Connected speech; CONNECTED SPEECH; Descriptive discourse; INDIVIDUALS; Language; LANGUAGE DEFICITS; MAIN CONCEPTS; PERFORMANCE; Stroke; VOCABULARY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z5W4TAT6","journalArticle","2021","Fiorin, M; Marconato, E; Palharini, TA; Picoloto, LA; Frizzo, ACF; Cardoso, ACV; de Oliveira, CMC","Impact of auditory feedback alterations in individuals with stuttering","BRAZILIAN JOURNAL OF OTORHINOLARYNGOLOGY","","1808-8694","10.1016/j.bjorl.2019.08.005","","Introduction: Electrophysiological evidence has reinforced the hypothesis that stuttering is associated with a deficit in modulation of the cortical auditory system during speech planning, contributing to an inefficient auditory feedback monitoring and, consequently, resulting in disfluencies. Objective: To verify the impact of auditory feedback modifications on the spontaneous speech of individuals with stuttering. Methods: Sixteen individuals, of both genders, aged 8--17 years and 11 months, with a diagnosis of persistent neurodevelopmental stuttering, were divided into two groups: Moderate Stuttering Group and Severe Stuttering Group. The testing procedures consisted of three stages: collection of identification data, audiological assessment and fluency evaluation of spontaneous speech in four auditory feedback conditions (non-altered, delayed, masked and amplified). The speech sample obtained in the non-altered feedback was considered the control; the others were considered as modified listening conditions. Results: Regarding the stuttering-like disfluencies, a statistically significant difference was observed in the intragroup analysis of the Moderate Stuttering Group between non-altered and masked auditory feedback (p = 0.042), as well as between non-altered and amplified (p = 0.042). There was a statistically significant difference in the Severe Stuttering Group for all auditory feedback modifications in relation to the non-altered (delayed p = 0.012, masked p = 0.025 and amplified p = 0.042). There was also a reduction in flows of syllables and words-per-minute in the Moderate Stuttering Group for the delayed auditory feedback, as compared to non-altered (p = 0.017 and p = 0.025, respectively). Conclusion: The effect of delayed auditory feedback was favorable for the Severe Stuttering Group, promoting speech fluency. The conditions of masked and amplified auditory feedback resulted in speech benefits in both groups, decreasing the number of stuttering-like disfluencies. The speech rate was not impaired by any listening condition analyzed. (C) 2019 Associacao Brasileira de Otorrinolaringologia e Cirurgia Cervico-Facial. Published by Elsevier Editora Ltda.","2021-05","2025-02-26 20:37:04","2025-02-26 20:37:04","","247-254","","3","87","","","","","","","","","","English","","","","WOS:000657140600002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","ADULTS; CONNECTIVITY; DEVICES; DISFLUENCY; Feedback; FLUENCY; Hearing; PRESCHOOL-CHILDREN; SPEECH; Speech disorders; Speech-language pathology; Stuttering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LUFS9GQ3","journalArticle","2025","Mayr, W; Triantafyllopoulos, A; Batliner, A; Schuller, BW; Berghaus, TM","Assessing the Clinical and Functional Status of COPD Patients Using Speech Analysis During and After Exacerbation","INTERNATIONAL JOURNAL OF CHRONIC OBSTRUCTIVE PULMONARY DISEASE","","1178-2005","10.2147/COPD.S480842","","Background: Chronic obstructive pulmonary disease (COPD) affects breathing, speech production, and coughing. We evaluated a machine learning analysis of speech for classifying the disease severity of COPD. Methods: In this single centre study, non-consecutive COPD patients were prospectively recruited for comparing their speech characteristics during and after an acute COPD exacerbation. We extracted a set of spectral, prosodic, and temporal variability features, which were used as input to a support vector machine (SVM). Our baseline for predicting patient state was an SVM model using self- reported BORG and COPD Assessment Test (CAT) scores. Results: In 50 COPD patients (52% males, 22% GOLD II, 44% GOLD III, 32% GOLD IV, all patients group E), speech analysis was superior in distinguishing during and after exacerbation status compared to BORG and CAT scores alone by achieving 84% accuracy in prediction. CAT scores correlated with reading rhythm, and BORG scales with stability in articulation. Pulmonary function testing (PFT) correlated with speech pause rate and speech rhythm variability. Conclusion: Speech analysis may be a viable technology for classifying COPD status, opening up new opportunities for remote disease monitoring.","2025","2025-02-26 20:37:04","2025-02-26 20:37:04","","137-147","","","20","","","","","","","","","","English","","","","WOS:001401984200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","COPD; digital health; feature interpretation; pathological speech; personalization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2G6RX5C5","journalArticle","2024","Eyre, M; Rose, S; Gwynn, R; Pressler, RM; Clark, M","Acquired motor speech disorders in childhood epilepsy","DEVELOPMENTAL MEDICINE AND CHILD NEUROLOGY","","0012-1622","10.1111/dmcn.16091","","AimTo evaluate a group of children with epilepsy and motor speech regression, with the aim of characterizing their speech disorders, electrographic features, and outcomes.MethodChildren referred to a tertiary developmental epilepsy clinic with epilepsy and motor speech regression were identified retrospectively. A clinical history was taken, and longitudinal speech and cognitive data were recorded. Speech samples were scored for severity and speech features. Seizure frequency and epileptiform discharges in the interictal electroencephalogram were analysed.ResultsEighteen children (10 female) were evaluated, including seven with Landau-Kleffner syndrome and six with Rasmussen syndrome. Speech regression occurred at a mean age of 5 years (SD = 2 years 6 months), which was concurrent with seizure onset or peak seizure burden in eight children. Speech features included dysarthria (n = 13), phonological errors (n = 7), and dyspraxia (n = 6). Electrographic abnormalities occurred most frequently in the left centrotemporal and right frontal regions. Among children who were followed up, intelligibility of speech was affected in 13 at baseline and seven at follow-up (p = 0.03). Expressive language standardized scores increased from a mean (SD) of 50.0 (11.3) to 91.4 (27.8) in children with Landau-Kleffner syndrome (mean change = 41.4, 95% confidence interval [CI] 0.04-82.8, p = 0.0498) and decreased from 75.2 (15.3) to 59.0 (9.8) in children with Rasmussen syndrome (mean change -16.2, 95% CI -9.0 to -23.4, p = 0.002) over the follow-up.InterpretationMotor speech disorders in epilepsy were severe, multifarious, and often fluctuated with seizure burden. Symptoms typically improved, especially in children with Landau-Kleffner syndrome, but rarely fully resolved. In this cohort of 18 children with acquired motor speech disorders in the context of epilepsy, patients typically presented with a mixed profile of speech features causing significant impact on functioning. The initial motor speech regression was often temporally associated with either epilepsy onset or peak seizure burden. Electrographic abnormalities were observed in brain regions involved in speech production. Difficulties typically persisted with some improvement over time, especially in children with Landau-Kleffner syndrome and/or those whose interictal EEG improved.image","2024-09-10","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","","","","","","","","","","","English","","","","WOS:001308844500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","CLASSIFICATION; PROSODY; SEIZURES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9YJBZ7B7","journalArticle","2024","Southby, L","Considering the role of speech processing in cleft-related speech sound disorders: Implications for causal pathways and classification systems","INTERNATIONAL JOURNAL OF LANGUAGE & COMMUNICATION DISORDERS","","1368-2822","10.1111/1460-6984.12993","","BackgroundClassification systems in healthcare support shared understanding of conditions for clinical communication, service monitoring and development, and research. Children born with cleft palate with or without cleft lip (CP+/-L) are at high risk of developing cleft-related speech sound disorder (SSD). The way cleft-related SSD is represented and described in SSD classification systems varies. Reflecting on the potential causal pathways for different cleft-related speech features, including the role of speech processing skills, may inform how cleft-related SSD is represented in classification systems.Aim & ApproachTo explore and reflect on how cleft-related SSD is represented in current SSD classification systems in the context of considering how speech processing skills and other factors may be involved in causal pathways of cleft speech characteristics (CSCs).Main ContributionVariation in the representation of cleft-related SSD in classification systems is described. Potential causal pathways for passive cleft- related speech features and different active CSCs are explored. The factors involved in the development and/or persistence of different active CSCs may vary. Some factors may be specific to children born with CP+/-L, but if speech processing skills are also involved, this is an overlap with other SSD subtypes. Current evidence regarding relationships between different speech processing skills and active CSCs is limited. Implications for the representation of cleft-related SSD in SSD classification systems are discussed.ConclusionThere are different categories of cleft-related speech features which are essential to understand and identify in children with cleft-related SSD to ensure appropriate management. Representation of these feature categories in classification systems could support understanding of speech in this population. Speech processing skills could be involved in the development and/or persistence of different active CSCs in individual children. Reflection and discussion on how cleft-related SSD is represented in classification systems in relation to other SSD subtypes may inform future iterations of these systems. Further work is needed to understand factors influencing the development and/or persistence of active CSCs, including speech processing skills.","2024-11","2025-02-26 20:37:04","2025-02-26 20:37:04","","2197-2207","","6","59","","","","","","","","","","English","","","","WOS:001140097400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","causal pathways; CHILDREN; classification; cleft-related SSD; DYSFUNCTION; LIP; MODEL; PALATE; speech processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F3ENL5ZR","journalArticle","2024","Zhang, SS; Wang, TT; Tang, LH; Li, X; Shang, ZB; Zhou, TY; Lan, N; Yang, LJ; Zhou, HY","Assessment Methods and Intervention Strategies for Cleft-Related Lateral Misarticulation in Chinese-Speaking Children","JOURNAL OF CRANIOFACIAL SURGERY","","1049-2275","10.1097/SCS.0000000000010349","","The aim of this study was to analyze the characteristics and error speech features of cleft-related lateral misarticulation and provide a basis for clinical evaluation and rational intervention. Participants who were diagnosed with lateral misarticulation after cleft palate repairment were 126 children aged 4, 6 to 16, and 11, and they had complete palatopharyngeal closure, no abnormalities in their speech organs and occlusion, and no hearing or intellectual impairments. The Chinese standard pronunciation clarity word list, the American KAY CSL4500, the Beijing Yangchen YF-16 computer speech analysis workstation, soundproof rooms, Wechsler scales of intelligence-fourth edition, and audiometers were used to evaluate the cleft-related lateral misarticulation. Statistical analysis was performed on the age, gender, error rate, corner of the mouth deviation direction, comorbidity, duration of intervention, period of treatment, and therapeutic effect of concentrated or normal intervention group in different patients. Our results showed that 2 to 3 straight stripes were visible at the onset of consonants /ti:/ /t'i:/, and 3 clear straight lines were visible in /t(sic)/, indicating that the lateralized sound had 2 or 3 bursts and lasted for 1 to 2 ms. The onset age of lateralized sound was mostly below 12 years old. Chinese lateralized sound mainly occurred in vowel /i:/, and the occurrence rate of consonants with tongue surface /t(sic)]/ /t(sic)'/ /(sic)/ was the highest. In addition, the corner of the mouth deviation was also an indicator of lateralization sound, and other types of speech disorders mostly accompanied it. There was a significant difference in the improvement of speech clarity between the concentrated intervention group and the normal group before and after treatment. The 2 groups' average duration and course of treatment were not significantly different. Still, the period of concentrated intervention was shortened considerably, and the speech clarity of both groups of children after treatment exceeded 96%, reaching a normal level.","2024-07","2025-02-26 20:37:04","2025-02-26 20:37:04","","1523-1530","","5","35","","","","","","","","","","English","","","","WOS:001261492000021","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","ARTICULATION; Cleft-related lateral misarticulation; DISORDERS; evaluate; intervention; LANGUAGE; OUTCOMES; SPEECH; treatment modes","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M8NWBL52","journalArticle","2021","Amini, S; Zhang, LF; Hao, BR; Gupta, A; Song, MT; Karjadi, C; Lin, HH; Kolachalama, VB; Au, R; Paschalidis, IC","An Artificial Intelligence-Assisted Method for Dementia Detection Using Images from the Clock Drawing Test","JOURNAL OF ALZHEIMERS DISEASE","","1387-2877","10.3233/JAD-210299","","Background: Widespread dementia detection could increase clinical trial candidates and enable appropriate interventions. Since the Clock Drawing Test (CDT) can be potentially used for diagnosing dementia-related disorders, it can be leveraged to develop a computer-aided screening tool. Objective: To evaluate if a machine learning model that uses images from the CDT can predict mild cognitive impairment or dementia. Methods: Images of an analog clock drawn by 3,263 cognitively intact and 160 impaired subjects were collected during inperson dementia evaluations by the Framingham Heart Study. We processed the CDT images, participant's age, and education level using a deep learning algorithm to predict dementia status. Results: When only the CDT images were used, the deep learning model predicted dementia status with an area under the receiver operating characteristic curve (AUC) of 81.3% +/- 4.3%. A composite logistic regression model using age, level of education, and the predictions from the CDT-only model, yielded an average AUC and average F1 score of 91.9% +/- 1.1% and 94.6% +/- 0.4%, respectively. Conclusion: Our modeling framework establishes a proof-of-principle that deep learning can be applied on images derived from the CDT to predict dementia status. When fully validated, this approach can offer a cost-effective and easily deployable mechanism for detecting cognitive impairment.","2021","2025-02-26 20:37:04","2025-02-26 20:37:04","","581-589","","2","83","","","","","","","","","","English","","","","WOS:000696383200010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Alzheimer's disease; artificial intelligence; CLASSIFICATION; clock test; deep learning; dementia; DISEASE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YCGSTCIM","journalArticle","2022","Lu, C; Tang, CG; Zhang, JC; Zong, Y","Progressively Discriminative Transfer Network for Cross-Corpus Speech Emotion Recognition","ENTROPY","","1099-4300","10.3390/e24081046","","Cross-corpus speech emotion recognition (SER) is a challenging task, and its difficulty lies in the mismatch between the feature distributions of the training (source domain) and testing (target domain) data, leading to the performance degradation when the model deals with new domain data. Previous works explore utilizing domain adaptation (DA) to eliminate the domain shift between the source and target domains and have achieved the promising performance in SER. However, these methods mainly treat cross-corpus tasks simply as the DA problem, directly aligning the distributions across domains in a common feature space. In this case, excessively narrowing the domain distance will impair the emotion discrimination of speech features since it is difficult to maintain the completeness of the emotion space only by an emotion classifier. To overcome this issue, we propose a progressively discriminative transfer network (PDTN) for cross-corpus SER in this paper, which can enhance the emotion discrimination ability of speech features while eliminating the mismatch between the source and target corpora. In detail, we design two special losses in the feature layers of PDTN, i.e., emotion discriminant loss Ld and distribution alignment loss La. By incorporating prior knowledge of speech emotion into feature learning (i.e., high and low valence speech emotion features have their respective cluster centers), we integrate a valence-aware center loss Lv and an emotion-aware center loss Lc as the Ld to guarantee the discriminative learning of speech emotions except an emotion classifier. Furthermore, a multi-layer distribution alignment loss La is adopted to more precisely eliminate the discrepancy of feature distributions between the source and target domains. Finally, through the optimization of PDTN by combining three losses, i.e., cross-entropy loss Le, Ld, and La, we can gradually eliminate the domain mismatch between the source and target corpora while maintaining the emotion discrimination of speech features. Extensive experimental results of six cross-corpus tasks on three datasets, i.e., Emo-DB, eNTERFACE, and CASIA, reveal that our proposed PDTN outperforms the state-of-the-art methods.","2022-08","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","8","24","","","","","","","","","","English","","","","WOS:000845963700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","cross-corpus speech emotion recognition; discriminative feature learning; distribution alignment; domain adaptation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5JIZJSN3","journalArticle","2024","Xue, YH; Chen, N; Luo, YX; Zhu, HQ; Zhu, ZY","CLESSR-VC: Contrastive learning enhanced self-supervised representations for one-shot voice conversion","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2024.103139","","One-shot voice conversion (VC) has attracted more and more attention due to its broad prospects for practical application. In this task, the representation ability of speech features and the model's generalization are the focus of attention. This paper proposes a model called CLESSR-VC, which enhances pre-trained self-supervised learning (SSL) representations through contrastive learning for one-shot VC. First, SSL features from the 23rd and 9th layers of the pre-trained WavLM are adopted to extract content embedding and SSL speaker embedding, respectively, to ensure the model's generalization. Then, the conventional acoustic feature mel-spectrograms and contrastive learning are introduced to enhance the representation ability of speech features. Specifically, contrastive learning combined with the pitch-shift augmentation method is applied to disentangle content information from SSL features accurately. Mel-spectrograms are adopted to extract mel speaker embedding. The AM-Softmax and cross-architecture contrastive learning are applied between SSL and mel speaker embeddings to obtain the fused speaker embedding that helps improve speech quality and speaker similarity. Both objective and subjective evaluation results on the VCTK corpus confirm that the proposed VC model has outstanding performance and few trainable parameters.","2024-11","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","165","","","","","","","","","","English","","","","WOS:001315576000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Contrastive learning; One-shot; Self-supervised learning; Voice conversion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3IRP6E5H","journalArticle","2024","Cucevic, IN; Jurisic, MM","SENTENCE NEGATION IN THE LOCAL DIALECTS OF THE CABAR AREA","HRVATSKI DIJALEKTOLOSKI ZBORNIK","","0439-691X","10.21857/94kl4c1d4m","","Syntactic negation is divided into sentence negation and partial negation. Sentence negation through a negated predicate negates the sentence content completely, while partial negation negates the content of a non-predicate member of the sentence structure. The paper analyzes the means of sentence negation in the local dialects of the & Ccaron;abar area, morphological or syntactic, and their position in relation to the verb form in the predicate. Intensifiers of negative meaning and negative concord are also analyzed. The analysis is based on the material collected by directed field research, which, in addition to recording spontaneous speech, includes the dialect versions of standard language templates; the analysis also refers to examples from dialectological literature and sources.","2024-12","2025-02-26 20:37:04","2025-02-26 20:37:04","","207-236","","28","","","","","","","","","","","English","","","","WOS:001394140700006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","& Ccaron; abar local dialects; Kajkavian group of dialects; sentence negation; syntactic negation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SUKZDJVK","journalArticle","2021","Yuan, JH; Cai, XY; Bian, YC; Ye, Z; Church, K","Pauses for Detection of Alzheimer's Disease","FRONTIERS IN COMPUTER SCIENCE","","2624-9898","10.3389/fcomp.2020.624488","","Pauses, disfluencies and language problems in Alzheimer's disease can be naturally modeled by fine-tuning Transformer-based pre-trained language models such as BERT and ERNIE. Using this method with pause-encoded transcripts, we achieved 89.6% accuracy on the test set of the ADReSS (Alzheimer's Dementia Recognition through Spontaneous Speech) Challenge. The best accuracy was obtained with ERNIE, plus an encoding of pauses. Robustness is a challenge for large models and small training sets. Ensemble over many runs of BERT/ERNIE fine-tuning reduced variance and improved accuracy. We found that um was used much less frequently in Alzheimer's speech, compared to uh. We discussed this interesting finding from linguistic and cognitive perspectives.","2021-01-29","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","2","","","","","","","","","","English","","","","WOS:000705504200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Alzheiemer's disease; BERT; COMPLEXITY; ensemble; ERNIE; LENGTH; MARKERS; pause; PROSODY; TIME; UH; UM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XWNXDJ53","journalArticle","2024","Li Destri, E","On documenting language change as it happens: the periphrastic construction ""motion verb","ISOGLOSS OPEN JOURNAL OF ROMANCE LINGUISTICS","","2385-4138","10.5565/rev/isogloss.418","","This study examines the grammaticalization of motion verbs in Italian within the periphrastic construction ""motion verb + a + infinitive"". Verbs such as andare 'to go', venire 'to come' and tornare 'to return' develop functional uses and express aspectual meanings, such as culminative, inchoative-imminential and iterative. The research employs corpus analysis to investigate the distribution of these constructions across formal and informal varieties of Italian. Analysis of both spoken (KIParla) and written (CORIS) corpora indicates diaphasic and diamesic variation. Formal written varieties exhibit higher percentages of aspectual values, while spontaneous speech shows lower percentages. Additionally, the corpus investigation reveals differences in the frequency of aspectual values, with the inchoative-imminential value being more prevalent in spoken language compared to written texts.","2024","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","7","10","","","","","","","","","","English","","","","WOS:001401955400010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;87</p>","","","corpora; diaphasic variation; grammaticalization; Italian; motion verbs periphrases","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X3I36BBT","journalArticle","2025","Yun, WW; Jia, SS; Li, PL; Gao, P; Jiang, Y; Zhang, CL","A new GRN variant in logopenic variant primary progressive aphasia: a case report and literature review","NEUROCASE","","1355-4794","10.1080/13554794.2024.2436215","","The majority of genetic Primary progressive aphasia (PPA) patients harbor mutations in the granulin (GRN) gene. The present case showed impaired performances in single-word retrieval in spontaneous speech and naming, and repetition. Head MRI revealed marked lateral atrophy in the left parietal cortex. A diagnosis of logopenic variant PPA (lvPPA) was established. Genetic analysis showed a heterozygous 10-bp frameshift deletion in exon 4 of the GRN gene (NM_002087.4), leading to transformation of cysteine into alanine at amino acid 92 and creation of a premature stop codon at position 161. This patient represented a rare case of GRN-associated lvPPA. A new mutation site was detected in exon 4 of GRN gene.","2025-01-02","2025-02-26 20:37:04","2025-02-26 20:37:04","","11-16","","1","31","","","","","","","","","","English","","","","WOS:001372610000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","Cys92Alafs; FRONTOTEMPORAL DEMENTIA; GRN; lateral atrophy; LvPPA; mutation; MUTATIONS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4GWXYYUY","journalArticle","2023","Wong, ATY; Reeves, GK; Floud, S","Total sleep duration and daytime napping in relation to dementia detection risk: Results from the Million Women Study","ALZHEIMERS & DEMENTIA","","1552-5260","10.1002/alz.13009","","IntroductionThere is inconsistent evidence on the associations of sleep duration and daytime napping with dementia risk. MethodsIn the Million Women Study, a total of 830,716 women (mean age, 60 years) were asked about sleep duration (<7, 7-8, >8 hours) and daytime napping (rarely/never, sometimes, usually) in median year 2001, and were followed for the first hospital record with any mention of dementia. Cox regression estimated dementia detection risk ratios (RRs) during 17-year follow-up in 5-year intervals. ResultsWith 34,576 dementia cases, there was strong attenuation over follow-up in the RRs related to long sleep duration (>8 vs 7-8 hours) and usually napping (vs rarely/never). Short sleep duration was modestly, positively associated with dementia in the long term (RR = 1.08, 95% confidence interval [CI] 1.04-1.12). DiscussionThere was little evidence to suggest that long sleep duration and regular napping are associated with long-term dementia risk. Short sleep duration was modestly associated with dementia risk, but residual confounding cannot be excluded. HighlightsLong sleep duration was not associated with long-term dementia risk.Daytime napping was not associated with long-term dementia risk.There is some evidence for a small higher risk of dementia related to short sleep.","2023-11","2025-02-26 20:37:04","2025-02-26 20:37:04","","4978-4986","","11","19","","","","","","","","","","English","","","","WOS:000972838000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","ASSOCIATION; daytime napping; dementia; DISTURBANCE; INCIDENT DEMENTIA; prospective; sleep duration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XJDVYLF9","journalArticle","2025","Zhou, JL; Zhao, HS; Lin, SY; Si, HM; Li, BH","Fault diagnosis of high-voltage circuit breaker based on open-set theory fusion model","IET ELECTRIC POWER APPLICATIONS","","1751-8660","10.1049/elp2.12539","","Fault diagnosis of high voltage circuit breaker is an important aspect of electrical equipment intelligence. To effectively identify unknown faults, this paper proposes a high-voltage circuit breaker fault diagnosis method based on open set fusion model (OSFM). Firstly, the current data and vibration data are processed using sequential variational mode decomposition and Fourier transform, respectively, to extract data features, thereby constructing the original feature set of the current-vibration signal, which is then input into the Transformer model for further feature extraction. Secondly, the open-set discriminant model based on the extreme value theory is proposed, and the data output by transformer is input into classifier to realise open-set fault diagnosis. Finally, the tree-structured parzen estimator is used to optimise the selection of transformer model parameters and discriminator acceptance probability. The efficacy of the OSFM was evaluated through experimentation on experimental platform. The results demonstrated that the OSFM method can effectively recognise previously unidentified class faults while maintaining accurate recognition of known classes. Compared with other open-set classification techniques, OSFM can improve the recognition accuracy by up to 38.36%.","2025-01","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","1","19","","","","","","","","","","English","","","","WOS:001401999800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","fault diagnosis; feature extraction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q3ATKNKZ","journalArticle","2023","Khachaturyan, M","From copula to focus, vice versa, or neither? Information structure and non-verbal predication in Mano","MANDENKAN-BULLETIN SEMESTRIEL D ETUDES LINGUISTIQUES MANDE","","0752-5443","10.4000/mandenkan.3070","","This paper studies the system of non-verbal predication of Mano, a South Mande language, based on primary data, including elicited utterances and a corpus of spontaneous speech. The main analytical question that I address concerns the relationship between non-verbal predication and focus marking. I argue that in Mano, the focus meaning arises as a pragmatic interpretation of identifying or presentative constructions with non-verbal predicators under particular contextual conditions. As a result, focus markers may not need to be distinguished as a syntactic and semantic class separate from non-verbal predicators. This discussion aims to shed light on the origin and interactional function of focus marking in Mande.","2023","2025-02-26 20:37:04","2025-02-26 20:37:04","","87-120","","69","","","","","","","","","","","English","","","","WOS:001089357300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","focus; interaction; Mano; non-verbal predication; pragmatic cooptation; predicative demonstratives","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4UK4HGTB","journalArticle","2023","Korkmaz, Y; Boyaci, A","Hybrid voice activity detection system based on LSTM and auditory speech features","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2022.104408","","Voice Activity Detection (VAD), sometimes called as Speech Activity Detection, is the process of extracting speech regions in audio recordings including many type of sounds. Because undesired data causes both computational complexity and time wasting, most of speech based applications consider only speech part (region of interest) and ignore the rest. This is the main reason that makes usage of the VAD stands a preliminary stage in applications like automatic speech recognition (ASR), speaker identification/verification, speech enhancement, speaker diarization etc. In this study, a successful semi-supervised VAD system, which we named as ""hybrid-VAD "", was proposed especially for the environment with high signal-to-noise ratio (SNR) with the manner of two-stage. At first, VAD decision was obtained from a relatively simple Long-Short Term Memory (LSTM) network trained by auditory speech features like energy, zero crossing rate (ZCR) and 13rd order-Mel Frequency Cepstral Coefficients (MFCC). After we applied a reasonable thresholding strategy to the same features to have second VAD decision, we combined both decisions with logical operators. The result was surprisingly showed that final VAD decision have low FEC and OVER errors, which are specifically critical for any speaker diarization system, mostly in the environments with high SNR.","2023-02","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","80","","","","","","","","","","English","","","","WOS:000891441500006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","LSTM; MFCC; RECOGNITION; Voice Activity Detection; Zero Crossing Rate","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GR46Q9PT","journalArticle","2025","Liu, C; Feng, XF; Li, F; Xian, QL; Jia, ZH; Wang, YH; Du, ZD","Deep reinforcement learning combined with transformer to solve the traveling salesman problem","JOURNAL OF SUPERCOMPUTING","","0920-8542","10.1007/s11227-024-06691-9","","The Transformer model is widely employed to address the traveling salesman problem due to its robust global information acquisition, learning, and generalization capabilities. However, its high computational complexity and limited accuracy require further refinement. To overcome these shortcomings, a novel model is proposed, integrating a lightweight CNN embedding layer with a Transformer model enhanced by an efficient Pyramid Compressed Attention (PSA) mechanism. The introduction of the lightweight CNN embedding layer significantly reduces the number of parameters and computational complexity, allowing for the flexible extraction of local spatial features between neighboring nodes, while maintaining the ability to handle larger-scale datasets. The PSA mechanism, on one hand, improves solution accuracy by accounting for both local neighborhood relations and global dependencies. On the other hand, its multi-scale nature enables the model to adapt to problems of varying scales, ensuring strong performance for both small- and large-scale problems. Extensive experiments conducted on random datasets as well as the public TSPLIB dataset have demonstrated that the proposed model surpasses other deep reinforcement learning algorithms in terms of solution quality and generalization ability.","2025-01","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","1","81","","","","","","","","","","English","","","","WOS:001353361700003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","Combinatorial optimization problem; Deep reinforcement learning; Transformer; Traveling salesman problem","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CLBSSQLJ","journalArticle","2024","Wang, SL; Wang, W; Zhao, GZ","A novel deep learning rainfall-runoff model based on Transformer combined with base flow separation","HYDROLOGY RESEARCH","","1998-9563","10.2166/nh.2024.035","","Precise long-term runoff prediction holds crucial significance in water resource management. Although the long short-term memory (LSTM) model is widely adopted for long-term runoff prediction, they encounter challenges such as error accumulation and low computational efficiency. To address these challenges, we utilized a novel method to predict runoff based on a Transformer and the base flow separation approach (BS-Former) in the Ningxia section of the Yellow River Basin. To evaluate the effectiveness of the Transformer model and its responsiveness to the base flow separation technique, we constructed LSTM and artificial neural network (ANN) models as benchmarks for comparison. The results show that Transformer outperforms the other models in terms of predictive performance and that base flow separation significantly improves the performance of the Transformer model. Specifically, the performance of BS-Former in predicting runoff 7 days in advance is comparable to that of the BS-LSTM and BS-ANN models with lead times of 4 and 2 days, respectively. In general, the BS-Former model is a promising tool for long-term runoff prediction.","2024-05","2025-02-26 20:37:04","2025-02-26 20:37:04","","576-594","","5","55","","","","","","","","","","English","","","","WOS:001215184600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","ARTIFICIAL NEURAL-NETWORKS; attention mechanism; coupled model; daily runoff prediction; LSTM; SIMULATION; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GILPNRZX","journalArticle","2023","Zhao, H; Li, LX; Zha, XP; Wang, YJ; Xie, ZX; Zhang, ZX","ACG-EmoCluster: A Novel Framework to Capture Spatial and Temporal Information from Emotional Speech Enhanced by DeepCluster","SENSORS","","1424-8220","10.3390/s23104777","","Speech emotion recognition (SER) is a task that tailors a matching function between the speech features and the emotion labels. Speech data have higher information saturation than images and stronger temporal coherence than text. This makes entirely and effectively learning speech features challenging when using feature extractors designed for images or texts. In this paper, we propose a novel semi-supervised framework for extracting spatial and temporal features from speech, called the ACG-EmoCluster. This framework is equipped with a feature extractor for simultaneously extracting the spatial and temporal features, as well as a clustering classifier for enhancing the speech representations through unsupervised learning. Specifically, the feature extractor combines an Attn-Convolution neural network and a Bidirectional Gated Recurrent Unit (BiGRU). The Attn-Convolution network enjoys a global spatial receptive field and can be generalized to the convolution block of any neural networks according to the data scale. The BiGRU is conducive to learning temporal information on a small-scale dataset, thereby alleviating data dependence. The experimental results on the MSP-Podcast demonstrate that our ACG-EmoCluster can capture effective speech representation and outperform all baselines in both supervised and semi-supervised SER tasks.","2023-05-16","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","10","23","","","","","","","","","","English","","","","WOS:000996693500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Attn-Convolution neural network; Bidirectional Gated Recurrent Unit (BiGRU); RECOGNITION; semi-supervised learning (SSL); speech emotion recognition (SER)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MZBNPUGK","journalArticle","2024","Li, ZR; Hong, B; Nolte, G; Engel, AK; Zhang, D","Speaker-listener neural coupling correlates with semantic and acoustic features of naturalistic speech","SOCIAL COGNITIVE AND AFFECTIVE NEUROSCIENCE","","1749-5016","10.1093/scan/nsae051","","Recent research has extensively reported the phenomenon of inter-brain neural coupling between speakers and listeners during speech communication. Yet, the specific speech processes underlying this neural coupling remain elusive. To bridge this gap, this study estimated the correlation between the temporal dynamics of speaker-listener neural coupling with speech features, utilizing two inter-brain datasets accounting for different noise levels and listener's language experiences (native vs. non-native). We first derived time-varying speaker-listener neural coupling, extracted acoustic feature (envelope) and semantic features (entropy and surprisal) from speech, and then explored their correlational relationship. Our findings reveal that in clear conditions, speaker-listener neural coupling correlates with semantic features. However, as noise increases, this correlation is only significant for native listeners. For non-native listeners, neural coupling correlates predominantly with acoustic feature rather than semantic features. These results revealed how speaker-listener neural coupling is associated with the acoustic and semantic features under various scenarios, enriching our understanding of the inter-brain neural mechanisms during natural speech communication. We therefore advocate for more attention on the dynamic nature of speaker-listener neural coupling and its modeling with multilevel speech features.","2024-08-02","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","1","19","","","","","","","","","","English","","","","WOS:001282492100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","acoustic feature; functional near-infrared spectroscopy (fNIRS); LANGUAGE PRODUCTION; naturalistic speech; NOISE; NONNATIVE LISTENERS; PERCEPTION; PREDICTIONS; semantic feature; speaker-listener neural coupling; SYNCHRONIZATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R4K8GCDR","journalArticle","2023","Simfukwe, C; Youn, YC; Jeong, HT","A machine-learning algorithm for predicting brain age using Rey-Osterrieth complex figure tests of healthy participants","APPLIED NEUROPSYCHOLOGY-ADULT","","2327-9095","10.1080/23279095.2022.2164198","","Objective: Neuropsychologists widely use the Rey-Osterrieth complex figure test (RCFT) as part of neuropsychological test batteries to evaluate cognitive function and assess constructional ability, with age being the most significant factor. Our study investigated a supervised machine learning (ML) algorithm to predict brain age gap using RCFT drawings from the healthy elderly community for early dementia detection. Participants and Methods: RCFT drawings from 1,970 healthy subjects (ages 45-90 years) were collected from the Korean elderly community. We recorded subject demographic information including: age, gender, and education level. We trained the ML model with RCFT copies, immediate recall, delayed recall, and education level of the healthy subjects using CNN regression algorithm from Keras (https://keras.io/) with the Tensorflow library. Results: The performance was evaluated by the mean absolute error (MAE) and root mean squared error (RMSE) between the predicted age and the chronological age based on a test dataset of 300 healthy subjects. The CNN regression model achieved an MAE of 7.2 years in predicting the brain age gap of the subjects, with an RMSE of 8.9 years. Conclusion: The MAE and RMSE accuracies of the CNN regression model predicting the brain age gap showed the model could be a potential biomarker for individual brain aging and a cost-effective method for early dementia detection.","2023-01-11","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","","","","","","","","","","","English","","","","WOS:000913428700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Asians; machine learning; neuropsychological tests; PERFORMANCE; regression analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VM9YLPKW","journalArticle","2023","Liu, XL; Ning, CY; de Villiers, J; Lee, WY; Rolfhus, E; Hutchings, T; Jiang, F; Zhang, YW","The characteristics of spontaneous language in young children identified as language delayed in Mandarin","INTERNATIONAL JOURNAL OF LANGUAGE & COMMUNICATION DISORDERS","","1368-2822","10.1111/1460-6984.12831","","BackgroundLittle is known about the spontaneous speech characteristics of young children with language delay in Mandarin, relative to their peers. Until the recent development of standardized language assessments normed in China on Mandarin-speaking children, it was difficult to independently identify atypically developing children to study their spontaneous speech, and only case studies have been available. AimTo investigate which aspects of spontaneous speech might be distinctive for atypical development in a short play session. Methods & ProceduresA total of 86 Mandarin-speaking children, boys and girls aged 2;6-4;6, were tested using the new standardized assessment for Mandarin, Diagnostic Receptive Expressive Assessment of Mandarin-Comprehensive (DREAM-C), at a major urban hospital in China. Of the children, 39 were identified by DREAM-C as atypically developing in language development (Total Standard score M = 72, SD = 8.9), and 47 scored in the typical range (Total Standard score M = 103, SD = 10.8), using the four scales of Receptive, Expressive Semantics and Syntax. All children then took part in a 15-min semi-structured play session during which their spontaneous speech was recorded by professionals. A variety of games and pictures were used in an attempt to elicit spontaneous questions, negatives and descriptions. Their recorded speech samples were then coded by linguists directly into a database in FilemakerPro for different aspects of vocabulary, sentence variety and grammatical morphemes/structures heard. Outcomes & ResultsThe results describe the characteristics of the speech samples for the typical and atypical groups for age groups 2;6-3.5 (N = 52) and 3;6-4.6 (N = 34). Vocabulary diversity was indicated on an ordinal scale ranging from simple communicative signals including headshakes and words such as 'hi' to 'a rich variety of different content words'. Grammatical diversity similarly ranged from 'only yes/no answers', through to the appearance of multi-clause sentences. Morphosyntax was coded in terms of which morphemes were observed at all in the session, such as aspect markers (LE, ZAI, GUO), and nominal morphemes (DE, GE), and also whether function words such as pronouns, Wh-questions and classifiers were singular or varied in the session. There is considerable optionality in morpheme expression in Mandarin, so measurements such as the percentage supplied in obligatory contexts, though useful for languages such as English, are harder to compute. Nevertheless, the data show change over age in all these aspects of language, and reveal what a typically developing child might be expected to produce in a 15-min sample in such a session. For example, it was rare for the typically developing children by age 3.5 not to have at least simple sentences with some function words, and to use adjectives, nouns and verbs, unlike the children with atypical scores. The morphemes DE, LE and GUO showed significant differences in likelihood across groups for both ages, but BA and ZAI were significantly different only for the older age group. In contrast, GE was common in all groups. The atypical group has markedly lower frequency in several grammatical aspects such as the use of diverse questions, classifiers and pronouns, with much less change across age groups, implying slower growth. The results provide useful information on the relative likelihood of observing different varieties of words, sentence types and morphemes in a short speech sample, which are substantially different in the typical versus atypical groups in both age bands, and change over age. Conclusions & ImplicationsThese data validate the DREAM-C classifications, but the details can also be used to inform the choice of targets for intervention for young children who experience delays in Mandarin language acquisition. WHAT THIS PAPER ADDSWhat is already known on the subjectSpontaneous language samples have been used as a means of studying language in China. However, because of the amount of training and time required to transcribe and analyse spontaneous language samples, there is not yet a sufficient basis for identifying language differences between children with and without language disorder in mainland China. What does this paper add to existing knowledgeAfter using DREAM-C to provide an objective measurement of children with and without language disorders, an easy-to-administer spontaneous language assessment protocol and scoring record form allowed the comparison of the spontaneous language of 39 children with atypically developing language with 47 children who scored in the typical range to observe language differences between those with and without typical language development. What are the potential or actual clinical implications of this work?The study documents differences in vocabulary and sentence variety, and use of different morphemes such as classifiers, passives and aspect markers to aid in choosing targets for intervention by demonstrating the path of development. In addition, the spontaneous language assessment protocol and scoring record form holds promise for allowing clinicians and researchers to more easily study the language of individual children to personalize intervention, but also of groups of children to understand the emergence of basic Mandarin linguistic features.","2023-11","2025-02-26 20:37:04","2025-02-26 20:37:04","","1856-1874","","6","58","","","","","","","","","","English","","","","WOS:000900040800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","ACQUISITION; atypical development; CLASSIFIERS; DREAM-C; ENGLISH; language delay; Mandarin children; MARKING; NOUN BIAS; preschool; SAMPLE; SPEAKING CHILDREN; spontaneous speech; VALIDITY; VOCABULARY DEVELOPMENT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HHYWVK97","journalArticle","2024","Wu, YX; Zhao, GS; Li, MD; Zhang, ZC; Qian, XM","Reason Generation for Point of Interest Recommendation Via a Hierarchical Attention-Based Transformer Model","IEEE TRANSACTIONS ON MULTIMEDIA","","1520-9210","10.1109/TMM.2023.3335886","","Existing point-of-interest (POI) recommendation methods only show the direct recommendation results and lack the proper reasons for recommendation. In recent years, explainable recommendation has become an increasingly important subfield in recommendation systems. The aim of explainable recommendation is to provide a reason why an item is recommended to a user. In this way, it helps to improve the transparency, persuasiveness and user satisfaction of recommendation systems. The explainable recommendation should indicate users' preferences for POIs, such as the category and the price. In addition, to increase the diversity of the results, we take emotional intensity into account in our model to generate more vivid reasons. To this end, we propose a hierarchical attention-based transformer model to generate reasons with specific topics and different emotions. With a hierarchical attention mechanism, we can capture the word-level and attribute-level preferences of users. In addition, we also learn the latent representation of the emotion score to generate diverse recommendation reasons. We evaluate the proposed model on a new real-world dataset collected from three travel service websites. The experimental results demonstrate that our method outperforms the related approaches for reason generation.","2024","2025-02-26 20:37:04","2025-02-26 20:37:04","","5511-5522","","","26","","","","","","","","","","English","","","","WOS:001189435600007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Explainable recommendation; MECHANISMS; natural language generation; personalization; recommender system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3HEHP3WH","journalArticle","2024","Lehouel, K; Saber, C; Bouziani, M; Yaagoubi, R","Remote Sensing Crop Water Stress Determination Using CNN-ViT Architecture","AI","","2673-2688","10.3390/ai5020033","","Efficiently determining crop water stress is vital for optimising irrigation practices and enhancing agricultural productivity. In this realm, the synergy of deep learning with remote sensing technologies offers a significant opportunity. This study introduces an innovative end-to-end deep learning pipeline for within-field crop water determination. This involves the following: (1) creating an annotated dataset for crop water stress using Landsat 8 imagery, (2) deploying a standalone vision transformer model ViT, and (3) the implementation of a proposed CNN-ViT model. This approach allows for a comparative analysis between the two architectures, ViT and CNN-ViT, in accurately determining crop water stress. The results of our study demonstrate the effectiveness of the CNN-ViT framework compared to the standalone vision transformer model. The CNN-ViT approach exhibits superior performance, highlighting its enhanced accuracy and generalisation capabilities. The findings underscore the significance of an integrated deep learning pipeline combined with remote sensing data in the determination of crop water stress, providing a reliable and scalable tool for real-time monitoring and resource management contributing to sustainable agricultural practices.","2024-06","2025-02-26 20:37:04","2025-02-26 20:37:04","","618-634","","2","5","","","","","","","","","","English","","","","WOS:001254503900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","CNN-ViT; crop water stress; deep learning; remote sensing; visual transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F2GSQLAW","journalArticle","2021","Zhang, L; Han, C; Wang, YH; Li, Y; Long, T","Polarimetric HRRP recognition based on feature-guided Transformer model","ELECTRONICS LETTERS","","0013-5194","10.1049/ell2.12225","","Polarimetric high-resolution range profile (HRRP) holds great potential for radar automatic target recognition (RATR) owing to its capability of providing both polarimetric and spatial scattering information. In recent years, deep learning (DL) has obtained state-of-the-art results in many classification tasks and has drawn great attention in the RATR field. However, as one of the most challenging tasks in RATR, small training sample case will restrict the application of DL because its superior performance generally depends on a large number of training samples. A feature-guided deep model based on Transformer framework is proposed for polarimetric HRRP recognition with limited training samples. In the proposed model, artificial features are introduced to the attention module to guide the model focus on the range cells of HRRP with more target scattering information so as to reduce the dependence of the model on the number of training samples. Several different approaches are also studied to measure the similarity between artificial features and HRRP data to further improve the learning capacity of the model. Experimental results demonstrate that the proposed feature-guided Transformer model modifying by Cosine similarity measure is able to achieve a better performance for polarimetric HRRP recognition with limited training samples.","2021-08","2025-02-26 20:37:04","2025-02-26 20:37:04","","705-707","","18","57","","","","","","","","","","English","","","","WOS:000653201200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;12</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AK6LPTZK","journalArticle","2024","Pizurica, M; Zheng, YN; Carrillo-Perez, F; Noor, H; Yao, W; Wohlfart, C; Vladimirova, A; Marchal, K; Gevaert, O","Digital profiling of gene expression from histology images with linearized attention","NATURE COMMUNICATIONS","","2041-1723","10.1038/s41467-024-54182-5","","Cancer is a heterogeneous disease requiring costly genetic profiling for better understanding and management. Recent advances in deep learning have enabled cost-effective predictions of genetic alterations from whole slide images (WSIs). While transformers have driven significant progress in non-medical domains, their application to WSIs lags behind due to high model complexity and limited dataset sizes. Here, we introduce SEQUOIA, a linearized transformer model that predicts cancer transcriptomic profiles from WSIs. SEQUOIA is developed using 7584 tumor samples across 16 cancer types, with its generalization capacity validated on two independent cohorts comprising 1368 tumors. Accurately predicted genes are associated with key cancer processes, including inflammatory response, cell cycles and metabolism. Further, we demonstrate the value of SEQUOIA in stratifying the risk of breast cancer recurrence and in resolving spatial gene expression at loco-regional levels. SEQUOIA hence deciphers clinically relevant information from WSIs, opening avenues for personalized cancer management. Predicting gene alterations and expression from whole-slide images (WSIs) can be a cost-efficient solution for cancer profiling. Here, the authors develop SEQUOIA, a transformer model with linearised attention to predict gene expression from WSIs, and validate its performance and clinical utility across multiple pan-cancer datasets.","2024-11-14","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","1","15","","","","","","","","","","English","","","","WOS:001355878600017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","PROTEOGENOMIC CHARACTERIZATION; REVEALS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"24V2QR22","journalArticle","2021","Li, JC; Liu, P; Dinavahi, V","Space-Time-Parallel 3-D Finite Element Transformer Model With Adaptive TLM and Parareal Techniques for Electromagnetic Transient Analysis","IEEE OPEN JOURNAL OF INDUSTRY APPLICATIONS","","2644-1241","10.1109/OJIA.2021.3091557","","In this paper, a novel massively space-time parallel finite element (FE) transformer model is proposed for power system electromagnetic transient simulations. The method utilizes the reduced magnetic vector potential (RMVP) formulation to solve the electromagnetic field in the transformer, and the 3-D tetrahedral edge element is applied to discretize the RMVP formulation. The discretized nonlinear system is solved by adaptive transmission line modeling (TLM) and matrix-free conjugate gradient iterator, which allows parallelism at the elemental-level and eliminates the need for Newton-Raphson (NR) iterations over the large-scale global matrix. The paper also integrates the parallel-in-time method with the finite element solver to further parallelize the model at space-time level, and the GPU implementation of the model realized a speedup of over 55 and high accuracy, compared with a commercial FE software.","2021","2025-02-26 20:37:04","2025-02-26 20:37:04","","143-153","","","2","","","","","","","","","","English","","","","WOS:001102733100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","3-D edge element; Computational modeling; Domain decomposition; eddy current field; field-circuit coupling; Finite element analysis; finite element method; graphics processors; Integrated circuit modeling; nonlinear behavior; Oil insulation; parallel processing; Parallel processing; parareal; reduced magnetic vector potential; Solid modeling; SOLVERS; STEADY-STATE; Transmission line matrix methods","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FUTHNA9G","journalArticle","2024","Suo, YF; Ding, ZN; Zhang, T","The Mamba Model: A Novel Approach for Predicting Ship Trajectories","JOURNAL OF MARINE SCIENCE AND ENGINEERING","","2077-1312","10.3390/jmse12081321","","To address the complexity of ship trajectory prediction, this study explored the efficacy of the Mamba model, a relatively new deep-learning framework. In order to evaluate the performance of the Mamba model relative to traditional models, which often struggle to cope with the dynamic and nonlinear nature of maritime navigation data, we analyzed a dataset consisting of intricate ship trajectory data. The prediction accuracy and inference speed of the model were evaluated using metrics such as the mean absolute error (MAE) and root mean square error (RMSE). The Mamba model not only excelled in terms of the computational efficiency, with inference times of 0.1759 s per batch-approximately 7.84 times faster than the widely used Transformer model-it also processed 3.9052 samples per second, which is higher than the Transformer model's 0.7246 samples per second. Additionally, it demonstrated high prediction accuracy and the lowest loss among the evaluated models. The Mamba model provides a new tool for ship trajectory prediction, which represents an advancement in addressing the challenges of maritime trajectory analysis when compared to existing deep-learning methods.","2024-08","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","8","12","","","","","","","","","","English","","","","WOS:001304865400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","AIS; AIS DATA; mamba; ship trajectory prediction; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LFEBUYTM","journalArticle","2024","Tao, YY; Xu, B; Zhang, YZ","Refined Self-Attention Transformer Model for ECG-Based Arrhythmia Detection","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2024.3400302","","As the length of electrocardiogram (ECG) sequences increases, most current transformer models demand substantial computational resources for ECG arrhythmia detection. Additionally, conventional single-scale tokens encounter difficulties in accommodating various patterns of arrhythmia. Thus, in this study, a refined-attention transformer model for arrhythmia detection was proposed. Our model introduces two refined attention mechanisms, namely, refined diag- and gated linear (GAL) attentions, effectively alleviating computational burdens associated with unnecessary correlations between heartbeats. To address rhythmic and beat-pattern arrhythmias, we used two refined transformer models with a collaborative block, leveraging coarse- and fine-grained tokens to capture inter and intraheartbeat correlations. The collaborative block between two models facilitates the exchange of rhythm information, thereby improving the accuracy of beat detection. On the MIT-BIH dataset, our refined attentions yield over a 65% reduction in computational efforts compared with conventional self-attention. Notably, our refined transformer models achieve 96% accuracy for rhythmic detection and rank within the top two performers for all types of heartbeat detection. Moreover, the collaborative block enhances the recall by 8.8% and precision by 3.4% for atrial premature detection.","2024","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","73","","","","","","","","","","English","","","","WOS:001231633200013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Arrhythmia detection; BUNDLE-BRANCH BLOCK; CLASSIFICATION; collaboration; computational efforts; electrocardiogram (ECG); gated linear (GAL) attention; refined self-attention; SIGNALS; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SY6UWUPD","journalArticle","2022","Lee, S; Jung, YJ","Hint-Based Image Colorization Based on Hierarchical Vision Transformer","SENSORS","","1424-8220","10.3390/s22197419","","Hint-based image colorization is an image-to-image translation task that aims at creating a full-color image from an input luminance image when a small set of color values for some pixels are given as hints. Though traditional deep-learning-based methods have been proposed in the literature, they are based on convolution neural networks (CNNs) that have strong spatial locality due to the convolution operations. This often causes non-trivial visual artifacts in the colorization results, such as false color and color bleeding artifacts. To overcome this limitation, this study proposes a vision transformer-based colorization network. The proposed hint-based colorization network has a hierarchical vision transformer architecture in the form of an encoder-decoder structure based on transformer blocks. As the proposed method uses the transformer blocks that can learn rich long-range dependency, it can achieve visually plausible colorization results, even with a small number of color hints. Through the verification experiments, the results reveal that the proposed transformer model outperforms the conventional CNN-based models. In addition, we qualitatively analyze the effect of the long-range dependency of the transformer model on hint-based image colorization.","2022-10","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","19","22","","","","","","","","","","English","","","","WOS:000867281200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","attention map; deep learning; image colorization; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZDEZBBTI","journalArticle","2022","Ok, C; Lee, G; Lee, K","Informative Language Encoding by Variational Autoencoders Using Transformer","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app12167968","","In natural language processing (NLP), Transformer is widely used and has reached the state-of-the-art level in numerous NLP tasks such as language modeling, summarization, and classification. Moreover, a variational autoencoder (VAE) is an efficient generative model in representation learning, combining deep learning with statistical inference in encoded representations. However, the use of VAE in natural language processing often brings forth practical difficulties such as a posterior collapse, also known as Kullback-Leibler (KL) vanishing. To mitigate this problem, while taking advantage of the parallelization of language data processing, we propose a new language representation model as the integration of two seemingly different deep learning models, which is a Transformer model solely coupled with a variational autoencoder. We compare the proposed model with previous works, such as a VAE connected with a recurrent neural network (RNN). Our experiments with four real-life datasets show that implementation with KL annealing mitigates posterior collapses. The results also show that the proposed Transformer model outperforms RNN-based models in reconstruction and representation learning, and that the encoded representations of the proposed model are more informative than other tested models.","2022-08","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","16","12","","","","","","","","","","English","","","","WOS:000846319500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","natural language processing; text mining; transformer; variational autoencoder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4STPK9TX","journalArticle","2024","Das, S; Deb, N; Cortesi, A; Chaki, N","Extracting goal models from natural language requirement specifications","JOURNAL OF SYSTEMS AND SOFTWARE","","0164-1212","10.1016/j.jss.2024.111981","","Unstructured (or, semi-structured) natural language is mostly used to capture the requirement specifications both for legacy software systems and for modern day software systems. The adoption of a formal approach to the specification of the requirements, using goal models, enables rigorous and formal inspections while analyzing the requirements for satisfiability, consistency, completeness, conflicts and ambiguities. However, such a formal approach is often considered burdening for the analysts' activity as it requires additional skills, and is therefore, discarded a priori. This works aims to bridge the gap between natural language requirement specifications and efficient goal model analysis techniques. We propose a framework that uses extensive natural language processing techniques to transform a set of unstructured natural language requirement specifications to the corresponding goal model. We combine techniques such as parts-of-speech tagging, dependency parsing, contextual and synonymy vector generation with the FiBER transformer model. An extensive unbiased crowdsourced evaluation of the proposed framework has been performed, showing an acceptability rate (total and partial combined) of 95%. Time and space analyses of our framework also demonstrate the scalability of the proposed solution.","2024-05","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","211","","","","","","","","","","English","","","","WOS:001176594500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","Contextual vector; Entity type recognition; Natural language processing; Natural language requirements; Synonymy vector; TOOL; Transformer model; UML MODELS; USER STORIES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZNFVX8WB","journalArticle","2023","Wang, B; Han, GQ; Lu, X; Ma, H; Zhu, ZY; Liang, XY","The integrated geosciences and engineering production prediction in tight reservoir based on deep learning","GEOENERGY SCIENCE AND ENGINEERING","","2949-8929","10.1016/j.geoen.2023.211571","","The production prediction method of volume-fractured wells in tight reservoirs is studied. Different from the traditional fracture modeling description and the fracture seepage capacity description with analytical or semi -analytical methods, this study combines the concept of integrated geosciences and engineering, uses the simplified static data composed of wellbore data and dimensionality reduced formation data, with the daily data collected during the production process. The time series prediction models based on deep learning are adopted, and human interference such as well shut-in in the production process is considered, thereby increasing the accuracy of the calculation results and reducing the impacts of human factors in the time series prediction. Using time series prediction algorithms such as the Transformer model, the liquid production data of 56 wells in tight reservoirs in 4 formations were predicted, and the MSE reached 0.01957, indicating that the production pre-diction accuracy reached 98.043%, which is instructive to the production prediction in the actual production process.","2023-04","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","223","","","","","","","","","","English","","","","WOS:000958654400003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","ANALYTICAL-MODEL; Deep learning; FRACTURED-HORIZONTAL-WELL; Integrated geosciences and engineering; PERFORMANCE; PERMEABILITY; STRESS; The Transformer model; Time series production prediction; Volume-fractured tight reservoir","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KSK3CE22","journalArticle","2025","Hossen, ME; Mahim, SM; Al Hasan, S; Islam, MK; Islam, MS; Khan, S; Alibakhshikenari, M; Parand, P; Miah, MS","Boosting Cervical Cancer Prediction Leveraging a Hybrid FT-Transformer Model","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2025.3538566","","Cervical Cancer (CC) remains a significant threat to women's health, despite being largely preventable, and is a leading cause of mortality worldwide. Early and accurate prediction is crucial for timely treatment and improved survival rates, particularly given the diverse risk factors contributing to CC development. To address this critical clinical need, we propose an innovative Hybrid FT-Transformer model that synergistically integrates a Feature Tokenization (FT) Transformer with Depthwise convolutional neural networks and Long Short-Term Memory (LSTM) networks for precise CC prediction. Explainable Artificial Intelligence (XAI) tools, including Local Interpretable Model-agnostic Explanations (LIME) and Shapley Additive Explanations (SHAP), provide insights into the model's decision-making process, aiding in validation by clinicians. Trained on a UCI repository dataset focusing on Hinselmann, Biopsy, and Schiller outcomes, our proposed model achieved outstanding accuracies: 99.09% for Hinselmann, 98.90% for Biopsy, and 98.75% for Schiller, using 10-fold cross-validation. These results highlight the model's superiority over current state-of-the-art approaches, with significant potential to enhance CC screening and early diagnosis, ultimately improving patient outcomes.","2025","2025-02-26 20:37:04","2025-02-26 20:37:04","","26876-26896","","","13","","","","","","","","","","English","","","","WOS:001422034400044","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","artificial intelligence; Cervical cancer; deep learning; FT-transformer; HUMAN-PAPILLOMAVIRUS; hybrid model; PREVENTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B3T8CL3F","journalArticle","2024","Maldonado-Correa, J; Torres-Cabrera, J; Martín-Martínez, S; Artigao, E; Gómez-Lázaro, E","Wind turbine fault detection based on the transformer model using SCADA data","ENGINEERING FAILURE ANALYSIS","","1350-6307","10.1016/j.engfailanal.2024.108354","","The growth of installed wind power worldwide and its significant contribution to the energy market is mainly due to the evolution of wind turbines (WTs) and their ability to withstand a wide range of dynamic loads. WT failures can be costly and lead to extended downtime. Early detection of such failures is critical in reducing the costs associated with operation and maintenance (O&M) tasks and unscheduled shutdowns of WTs. This paper applies two Deep Learning (DL) models based on the Transformer model to predict failures in the IGBT module of WTs at an onshore wind farm in Ecuador. To this end, SCADA (Supervisory Control and Data Acquisition) operational and alarm data are used, together with the maintenance record (MR). These data are analyzed and processed, applying different feature selection methods. The results show that the two proposed models perform well, with high accuracy and an approximate prediction of 4.25 months before failure occurrence. The results are promising due to the possibility of using SCADA data for early and accurate identification of faults in different components of WTs.","2024-08","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","162","","","","","","","","","","English","","","","WOS:001325538100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;79</p>","","","ANOMALY DETECTION; Converter; DIAGNOSIS; Faults prediction; NETWORKS; SCADA data; SPATIOTEMPORAL FUSION; Transformers model; Wind turbines","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QGH8H3SX","journalArticle","2024","Geng, J; Yang, HY; Li, Y; Zhang, X; Wang, YH","Influence of electromagnetic transient physical models considering characterization characteristics on capacitive voltage transformers","ARCHIVES OF ELECTRICAL ENGINEERING","","1427-4221","10.24425/aee.2024.149927","","The equivalent circuit of traditional capacitive voltage transformers often faces the problem of complex data calculation and difficulty in grasping the internal nonlinear characteristics of transformers when constructing broadband models, resulting in poor power accuracy and stability. Therefore, with the help of electromagnetic transient physical models, the admittance sub model and nonlinear model are established by considering the frequency and saturation characteristics of the transformer. Based on the characteristics of capacitive voltage transformers, the model is processed in parallel to obtain a broadband coupling transformer model. The results showed that the error between the simulated current peak amplitude and voltage results of the model and the measured values was less than 2% and 1%, respectively. In the fault results, the harmonic error of the load voltage of the improved transformer was relatively small, far less than the error result of 2.73% of the traditional transformer. The proposed transformer model can better characterize its characteristics and has good transient response ability, providing reference tools and value for the operation and state detection of power systems.","2024","2025-02-26 20:37:04","2025-02-26 20:37:04","","467-480","","2","73","","","","","","","","","","English","","","","WOS:001258061200012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","broadband admittance parameters; capacitive voltage transformer; electromagnetic transient model; excitation deviation; saturation characteristic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2MUBAVTE","journalArticle","2024","Liu, Y; Wang, YZ; Liu, XM; Wang, XZ; Ren, ZH; Wu, SL","Research on Runoff Prediction Based on Time2Vec-TCN-Transformer Driven by Multi-Source Data","ELECTRONICS","","2079-9292","10.3390/electronics13142681","","Due to the frequent occurrence of extreme weather in recent years, accurate runoff prediction is crucial for the rational planning and management of water resources. Addressing the high uncertainty and multiple influencing factors in runoff prediction, this paper proposes a runoff prediction method driven by multi-source data. Based on multivariate observed data of runoff, water level, temperature, and precipitation, a Time2Vec-TCN-Transformer model is proposed for runoff prediction research and compared with LSTM, TCN, and TCN-Transformer models. The results show that the Time2Vec-TCN-Transformer model outperforms other models in metrics including MAE, RRMSE, MAPE, and NSE, demonstrating higher prediction accuracy and reliability. By effectively combining Time2Vec, TCN, and Transformer, the proposed model improves the MAPE for forecasting 1-4 days in the future by approximately 7% compared to the traditional LSTM model and 4% compared to the standalone TCN model, while maintaining NSE consistently between 0.9 and 1. This model can better capture the periodicity, long-term scale information, and relationships among multiple variables of runoff data, providing reliable predictive support for flood forecasting and water resources management.","2024-07","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","14","13","","","","","","","","","","English","","","","WOS:001277050700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","multi-source data; runoff prediction; SIMULATION; TCN; Time2Vec; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EEHKV95Y","journalArticle","2024","Zhao, WJ; Ding, W; Zhang, SJ; Zhang, Z","Enhancing lithium-ion battery lifespan early prediction using a multi-branch vision transformer model","ENERGY","","0360-5442","10.1016/j.energy.2024.131816","","Accurately predicting the lifespan of lithium-ion batteries is crucial for effective battery management systems, particularly for ensuring the safe operation and proactive maintenance of electric vehicles. However, existing methods encounter challenges due to the early weak capacity aging trend in batteries. This study a novel approach using a multibranch vision transformer model to address early stage lifespan prediction issues. The proposed model leverages a multi-input data structure by considering various battery parameters during the charging and discharging phases. By employing distinct branch structures for different inputs, the model can separately extract features from individual input variables. Each vision transformer network was meticulously designed to extract high-dimensional global hidden features from the inputs and integrated to predict the battery lifespan. Comparative analyses against advanced baseline models and existing methods consistently demonstrate the superior performance and robustness of the proposed model. Compared with traditional vision transformer, the proposed model demonstrated a notable reduction in root mean square errors of 13.17 % and 6.32 % on the two public datasets, respectively, indicating the efficacy and reliability of our approach for accurately predicting the lifespan of LIBs during the early stages of capacity decline.","2024-09-01","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","302","","","","","","","","","","English","","","","WOS:001247066300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","REMAINING USEFUL LIFE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"STWQXKKY","journalArticle","2024","Liu, X; Huang, HH; Chang, WJ; Cao, YQ; Wang, YH","Enhanced Wavelet Transform Dynamic Attention Transformer Model for Recycled Lithium-Ion Battery Anomaly Detection","ENERGIES","","1996-1073","10.3390/en17205139","","Rapid advancements in electric vehicle (EV) technology have highlighted the importance of lithium-ion (Li) batteries. These batteries are essential for safety and reliability. Battery data show non-stationarity and complex dynamics, presenting challenges for current monitoring and prediction methods. These methods often fail to manage the variability seen in real-world environments. To address these challenges, we propose a Transformer model with a wavelet transform dynamic attention mechanism (WADT). The dynamic attention mechanism uses wavelet transform. It focuses adaptively on the most informative parts of the battery data to enhance the anomaly detection accuracy. We also developed a deep learning model with an improved Transformer architecture. This architecture is tailored for the complex dynamics of battery data time series. The model accounts for temporal dependencies and adapts to non-stationary behavior. Experiments on public battery datasets show our approach's effectiveness. Our model significantly outperforms existing technologies with an accuracy of 0.89 and an AUC score of 0.88. These results validate our method's innovation and effectiveness.","2024-10","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","20","17","","","","","","","","","","English","","","","WOS:001341369800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","complex dynamics; electric vehicle technology; FAULT-DIAGNOSIS; lithium-ion batteries; non-stationarity; PACKS; Transformer; wavelet transform","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QESZXDLI","journalArticle","2022","Liu, ZF; Ding, F; Lu, JY; Zhou, Y; Chu, HT","COMPARISON OF BLSTM-ATTENTION AND BLSTM-TRANSFORMER MODELS FOR WIND SPEED PREDICTION","COMPTES RENDUS DE L ACADEMIE BULGARE DES SCIENCES","","1310-1331","10.7546/CRABS.2022.01.10","","Accurate estimation of wind speed is essential for many meteorological applications. A novel short-term wind speed prediction method of Bi-directional LSTM and Transformer Network (BLSTM-TRA) model is proposed by combining the Transformer model and LSTM model, and a hybrid model of Bidirectional Long Short-term Memory and Attention Network (BLSTM-ATT) is proposed based on Attention mechanism and LSTM model. The proposed BLSTM-ATT and BLSTM-TRA model are used for predicting the wind speed of seven meteorological stations in Qingdao. In combination with historical observation data, the proposed models outperform the Numerical Weather Prediction (NWP) system of European Centre for Medium-Range Weather Forecasts (ECMWF). By comparing the results of BLSTM-ATT, BLSTM-TRA and ECMWF forecast model, RMSE and MAE of BLSTM-ATT are reduced by 44.7% and 50.3% on average, respectively, as well as an average decrease of 43.0% in the RMSE, an average decrease of 47.4% in the MAE of the BLSTM-TRA model. This demonstrates that the BLSTM-ATT model and the BLSTM-TRA model are more accurate than the ECMWF model in wind speed prediction.","2022","2025-02-26 20:37:04","2025-02-26 20:37:04","","80-89","","1","75","","","","","","","","","","English","","","","WOS:000754853800010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","attention mechanism; DECOMPOSITION; LSTM; NEURAL-NETWORK; SINGULAR SPECTRUM ANALYSIS; transformer model; wind speed forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3DDY6LFV","journalArticle","2024","Xu, ZY; Lei, XJ; Ma, M; Pan, Y","Molecular Generation and Optimization of Molecular Properties Using a Transformer Model","BIG DATA MINING AND ANALYTICS","","2096-0654","10.26599/BDMA.2023.9020009","","Generating novel molecules to satisfy specific properties is a challenging task in modern drug discovery, which requires the optimization of a specific objective based on satisfying chemical rules. Herein, we aim to optimize the properties of a specific molecule to satisfy the specific properties of the generated molecule. The Matched Molecular Pairs (MMPs), which contain the source and target molecules, are used herein, and logD and solubility are selected as the optimization properties. The main innovative work lies in the calculation related to a specific transformer from the perspective of a matrix dimension. Threshold intervals and state changes are then used to encode logD and solubility for subsequent tests. During the experiments, we screen the data based on the proportion of heavy atoms to all atoms in the groups and select 12 365, 1503, and 1570 MMPs as the training, validation, and test sets, respectively. Transformer models are compared with the baseline models with respect to their abilities to generate molecules with specific properties. Results show that the transformer model can accurately optimize the source molecules to satisfy specific properties.","2024-03","2025-02-26 20:37:04","2025-02-26 20:37:04","","142-155","","1","7","","","","","","","","","","English","","","","WOS:001243719700010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","logD; Matched Molecular Pairs (MMPs); molecular optimization; solubility; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z93M3HFI","journalArticle","2023","Lan, XY; Yang, XC","Retrieving land surface temperatures from IASI hyperspectral thermal infrared data using an AFNO-transformer model","OPTICS EXPRESS","","1094-4087","10.1364/OE.504907","","An adaptive Fourier neural operator (AFNO)-transformer model was developed to retrieve land surface temperature (LST) data from infrared atmospheric sounding interferometer (IASI) observations. A weight selection scheme based on linearization of the radiative transfer equation was proposed to solve the hyperspectral data channel redundancy problem. The IASI brightness temperatures and Advanced Very High Resolution Radiometer onboard MetOp (AVHRR/MetOp) LST product were selected to construct the training and test datasets. The AFNO-transformer performed effective token mixing through self-attention and effectively solved the global convolution problem in the Fourier domain, which can better learn complex nonlinear equations and achieve time-series forecasting. The root mean square error indicated that the LST in Eastern Spain and North Africa could be retrieved with an error of less than 2.5 K compared with the AVHRR/MetOp LST product. Moreover, the validation results from other time period data showed that the retrieval accuracy of this model can be less than 3 K. The proposed model provides a novel approach for hyperspectral LST retrieval. (c) 2023 Optica Publishing Group under the terms of the Optica Open Access Publishing Agreement","2023-11-20","2025-02-26 20:37:04","2025-02-26 20:37:04","","40249-40260","","24","31","","","","","","","","","","English","","","","WOS:001124438500006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","ALGORITHM; EMISSIVITY; FLUXES; PARAMETERS; PHYSICAL RETRIEVAL; PRODUCTS; SENSOR; WATER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WFJCTMSG","journalArticle","2024","Luo, JW; Zhang, ZH; Ma, XL; Yan, CK; Luo, HM","GTasm: a genome assembly method using graph transformers and HiFi reads","FRONTIERS IN GENETICS","","1664-8021","10.3389/fgene.2024.1495657","","Motivation: Genome assembly aims to reconstruct the whole chromosome-scale genome sequence. Obtaining accurate and complete chromosome-scale genome sequence serve as an indispensable foundation for downstream genomics analyses. Due to the complex repeat regions contained in genome sequence, the assembly results commonly are fragmented. Long reads with high accuracy rate can greatly enhance the integrity of genome assembly results. Results: Here we introduce GTasm, an assembly method that uses graph transformer network to find optimal assembly results based on assembly graphs. Based on assembly graph, GTasm first extracts features about vertices and edges. Then, GTasm scores the edges by graph transformer model, and adopt a heuristic algorithm to find optimal paths in the assembly graph, each path corresponding to a contig. The graph transformer model is trained using simulated HiFi reads from CHM13, and GTasm is compared with other assembly methods using real HIFI read set. Through experimental result, GTasm can produce well assembly results, and achieve good performance on NA50 and NGA50 evaluation indicators. Applying deep learning models to genome assembly can improve the continuity and accuracy of assembly results. The code is available from https://github.com/chu-xuezhe/GTasm.","2024-10-25","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","15","","","","","","","","","","English","","","","WOS:001350878000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","deep learning; genome assembly; graph transformer; HiFi read; SEQUENCE; sequencing technique","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QTQ4PGEI","journalArticle","2024","Song, Y; Li, DJ","Application of a Novel Data-Driven Framework in Anomaly Detection of Industrial Data","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3420878","","In recent years, deep learning algorithms represented by the Transformer model have gained widespread recognition in the application of time series anomaly detection. Based on the Boosting algorithm, this paper proposes a novel data-driven improved Saxformer framework for multivariate time series anomaly detection. This framework enhances the Transformer model's ability to capture local feature information and improves both the robustness to noise and the flexibility in practical applications. A method using Boosting classifiers for fine control is designed to improve the Transformer output layer. By outputting text letter by letter, the method aims to balance the model's creativity and conservatism, suppressing significant fluctuations in predictions and thereby enhancing detection accuracy. Experimental results show that the proposed model outperforms existing mainstream algorithms on multiple evaluation metrics. The F1 score, Precision, and Recall reach 0.882, 0.946, and 0.825, respectively. Compared with the best-performing baseline model, the F1 score is enhanced by 1.4%, demonstrating high accuracy in time series anomaly detection tasks.","2024","2025-02-26 20:37:04","2025-02-26 20:37:04","","102798-102812","","","12","","","","","","","","","","English","","","","WOS:001283799500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","1-d convolution; Anomaly detection; boosting; Boosting; Feature extraction; Long short term memory; Predictive models; Time series analysis; time series data; TIME-SERIES; Transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y9QZL83I","journalArticle","2025","Yu, KY; Sarkar, A; Rimbach-Russ, M; Ishihara, R; Feld, S","Transformer models for quantum gate set tomography","QUANTUM MACHINE INTELLIGENCE","","2524-4906","10.1007/s42484-025-00237-9","","Quantum computation represents a promising frontier in the domain of high-performance computing, blending quantum information theory with practical applications to overcome the limitations of classical computation. This study investigates the challenges of manufacturing high-fidelity and scalable quantum processors. Quantum gate set tomography (QGST) is a critical method for characterizing quantum processors and understanding their operational capabilities and limitations. This paper introduces Ml4Qgst as a novel approach to QGST by integrating machine learning techniques, specifically utilizing a transformer neural network model. Adapting the transformer model for QGST addresses the computational complexity of modeling quantum systems. Advanced training strategies, including data grouping and curriculum learning, are employed to enhance model performance, demonstrating significant congruence with ground-truth values. We benchmark this training pipeline on the constructed learning model, to successfully perform QGST for 2 and 3 gates on single-qubit and two-qubit systems, with over-rotation error and depolarizing noise estimation with comparable accuracy to pyGSTi. This research marks a pioneering step in applying deep neural networks to the complex problem of quantum gate set tomography, showcasing the potential of machine learning to tackle nonlinear tomography challenges in quantum computing.","2025-06","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","1","7","","","","","","","","","","English","","","","WOS:001401201800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Device characterization; Gate set tomography; Machine learning; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2JUP8RVN","journalArticle","2023","Bakare, AM; Anbananthen, KSM; Muthaiyah, S; Krishnan, J; Kannan, S","Punctuation Restoration with Transformer Model on Social Media Data","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13031685","","Several key challenges are faced during sentiment analysis. One major problem is determining the sentiment of complex sentences, paragraphs, and text documents. A paragraph with multiple parts might have multiple sentiment values. Predicting the overall sentiment value for this paragraph will not produce all the information necessary for businesses and brands. Therefore, a paragraph with multiple sentences should be separated into simple sentences. With a simple sentence, it will be effective to extract all the possible sentiments. Therefore, to split a paragraph, that paragraph must be properly punctuated. Most social media texts are improperly punctuated, so separating the sentences may be challenging. This study proposes a punctuation-restoration algorithm using the transformer model approach. We evaluated different Bidirectional Encoder Representations from Transformers (BERT) models for our transformer encoding, in addition to the neural network used for evaluation. Based on our evaluation, the RobertaLarge with the bidirectional long short-term memory (LSTM) provided the best accuracy of 97% and 90% for restoring the punctuation on Amazon and Telekom data, respectively. Other evaluation criteria like precision, recall, and F1-score are also used.","2023-02","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","3","13","","","","","","","","","","English","","","","WOS:000929462100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Bidirectional Encoder Representations from Transformers (BERT); long short-term memory (LSTM); punctuation restoration; transformers models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LZR3EAE4","journalArticle","2022","Gong, Z; Liu, CX; Yao, LZ","Multi-timescale simulator of nonlinear electrical elements by interfacing shifted equivalent phasors and electromagnetic transient simulation","ELECTRIC POWER SYSTEMS RESEARCH","","0378-7796","10.1016/j.epsr.2022.107856","","This paper proposes a multi-timescale transient branch companion model for electrical elements with strong nonlinearity, which is suitable for electromagnetic transient simulation for a wide range of time-scales. A shifted equivalent phasor (SEP) method for signals with wide frequency range is adopted combined with envelope signals and equivalent phasor-shift operator, and a saturable SEP based transformer model is established. A method of piecewise linearization based on Newton-Raphson is used to simulate excitation current under different simulation time step sizes in order to illustrate the overshoot phenomenon of piecewise linearization under large step sizes. Reducing the step size can effectively suppress the overshoot, but simulation efficiency will be sacrificed. This problem can be avoided in SEP model even if large time step is adopted and integrated simulation of both instantaneous and envelope (with larger timescale) waveforms can be efficiently tracked within one simulation run based on the determination of two parameters setting: shifting equivalent phasor and time step size. Finally, the transformer model and voltage source converter (VSC) are established and validated in MATLAB and PSCAD to prove its correctness and efficiency.","2022-07","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","208","","","","","","","","","","English","","","","WOS:000794210200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","EMTP; POWER; SYSTEMS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KIEWY8SN","journalArticle","2024","Sun, YZ; Pang, SC; Zhang, YG","Application of Adaboost-Transformer Algorithm for Lithology Identification Based on Well Logging Data","IEEE GEOSCIENCE AND REMOTE SENSING LETTERS","","1545-598X","10.1109/LGRS.2024.3372513","","In the field of oil and gas exploration, accurately predicting lithology during well logging is crucial. This research introduces a novel approach, the Adaboost-Transformer method, which utilizes data mining techniques to enhance logging lithology prediction. The first step involves applying the Adaboost algorithm for selecting features, which develops a strong classifier by focusing on weighted observations and particularly challenging samples. This approach not only boosts accuracy and durability but also lessens the likelihood of overfitting. Following this, we implement the Transformer as the principal classifier in creating the Adaboost-Transformer model. The Transformer is specifically designed for sequential data and is highly efficient in modeling sequences, especially in capturing temporal links within well logging data. When tested on two separate well logging datasets, this innovative model exhibited superior lithology identification capabilities, achieving accuracy rates of 95.20% and 95.50%. These figures notably surpass those of the standalone Transformer model, which scored 91.50% and 91.10% in accuracy. In comparison, the random forest (RF) model displayed more limited performance with accuracy rates of 88.80% and 87.10%.","2024","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","21","","","","","","","","","","English","","","","WOS:001193080000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;14</p>","","","Adaboost-Transformer method; data mining techniques; LOGS; oil and gas exploration; well logging sequential data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SJLJG7ZD","journalArticle","2024","Xie, Y; Hu, FC; Zhu, Y","Novel deep-learning model for chemical process fault detection based on DCW transformer","CANADIAN JOURNAL OF CHEMICAL ENGINEERING","","0008-4034","10.1002/cjce.25507","","In this study, a double-channel convolutional neural network and weighted (DCW) transformer model is proposed to address the problem of insufficient extraction of local information and no attention to channel-step information in the traditional transformer model. First, a double-channel information extraction method is proposed, so both the channel-step and time-step information achieve attention; second, the local information in the time and channel dimension of the data is extracted from deep and multiple scales, improving the feature extraction capability for local information; third, the long distance dependency relationship of the data is preserved by the attention mechanism, hence, the global correlation of the data is extracted effectively; finally, using the Gumbel-SoftMax function, the weights of the time-step and channel-step feature information are assigned, so the extracted feature information has been optimized. The proposed method was applied for the penicillin fermentation process to verify its efficacy. Experimental results show that the proposed method achieved a better fault detection accuracy, outperforming the existing models. Further ablation experiments were conducted to demonstrate the effectiveness of each component of the proposed model.","2024-09-22","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","","","","","","","","","","","English","","","","WOS:001318386700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","attention mechanism; DCW transformer; feature extraction; local and global information; NEURAL-NETWORKS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4ZRLQ2L2","journalArticle","2024","Farea, A; Tripathi, S; Glazko, G; Emmert-Streib, F","Investigating the optimal number of topics by advanced text-mining techniques: Sustainable energy research","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2024.108877","","In recent years, there has been a growing interest in analyzing text data from different scientific fields. The significant advancement of Artificial Intelligence in Natural Language Processing enables a systematic categorization of the wealth of scientific papers into fundamental thematic clusters. In this context, topic modeling is playing a crucial role. Unfortunately, the comparative analysis between traditional and advanced topic modeling methods, including well-established techniques like Latent Dirichlet Allocation (LDA) and newer approaches like BERTopic, remains significantly underexplored. This study addresses this gap by conducting a comprehensive analysis of extensive text data focused on sustainable energy research. To achieve this, we compile a unique dataset consisting of thousands of abstracts sourced from PubMed, Scopus, and Web of Science. Our analysis involves a comparison between LDA and the transformer model BERTopic. Importantly, we introduce a novel approach to determine the optimal number of topics, achieved through the maximization of combined semantic scores, and show that the number of topics is considerably lower than from previous approaches. Overall, our study not only contributes methodologically but also enhances our understanding of the principal topics in sustainable energy research.","2024-10","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","136","","","","","","","","","","English","","","","WOS:001267811700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;102</p>","","","Latent Dirichlet Allocation; MODEL; Natural language processing; Sustainable energy; Topic modeling; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KLG2UXP2","journalArticle","2024","Qian, K; Pan, YC; Xu, H; Tian, L","Transformer model incorporating local graph semantic attention for image caption","VISUAL COMPUTER","","0178-2789","10.1007/s00371-023-03180-7","","Aiming at the problem of isolating semantic information of existing transformer-based models in the image captioning tasks, a transformer model incorporating local graph semantic attention (TLGSA) is proposed. TLGSA consists of a multi-layer image convolutional encoder, a multi-label semantic recognizer, and a multi-layer natural language generation decoder. The image convolutional feature encoder outputs the spatial feature self-attention information, and the multi-label semantic recognizer combines the global corpus with the current image feature to output image semantic graph node encoding features using a graph convolutional neural network (GCN). The natural language decoder incorporates the input semantic self-attention, graph node encoding features, and spatial feature self-attention to form a local semantic multi-head attention, and finally generates a natural language caption of the image. Experimental results show that the proposed method has higher accuracy with meaningful semantic information than the existing SOTA methods, achieving 23%/23.2%/31.57% of Bleu-4 on the widely used test datasets Flickr8K, Flickr30K, and MS COCO, respectively, without reinforcement optimization stage.","2024-09","2025-02-26 20:37:04","2025-02-26 20:37:04","","6533-6544","","9","40","","","","","","","","","","English","","","","WOS:001115674200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","GENERATION; Graph convolutional neural network; Image caption; Multi-head attention; Multi-label semantic; REPRESENTATION; Transformer-based","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J2J4RW8G","journalArticle","2024","Lu, YR; Chang, SF; Liou, HH","Combining the AD8 and MMSE for community-based dementia screening","EXPERIMENTAL GERONTOLOGY","","0531-5565","10.1016/j.exger.2024.112482","","Background: This study aimed to determine whether a cognitive test the Mini-Mental State Examination (MMSE) and the Ascertain Dementia 8 (AD8) instrument applied in combination could improve the accuracy of dementia detection in a community setting. Methods: Study participants were recruited from a community-based integrated screening program in Tainan, Taiwan. Participants completed the AD8 and were administered the Chinese version of the MMSE by psychologists. In addition, the presence of dementia was determined by neurologists based on the 2011 National Institute on Aging-Alzheimer's Association guidelines. Logistic regression analysis determined whether the combination of these two tests provided any additional information for dementia detection than either test alone. Receiver operating characteristic (ROC) curve analyses were conducted to explore the performances of different screening modalities in detecting dementia. Result: In total, 282 participants with an average age of 69.31 +/- 10.27 years were enrolled. The prevalence of dementia among participants aged >= 65 years was 9.29 %. The sensitivity and specificity of the AD8 applied alone for detecting dementia were 64.71 % and 87.89 %, respectively, and of the MMSE applied alone, after adjusting for education level, were 41.18 % and 84.50 %, respectively. Using a cutoff score of 21 for the MMSE resulted in sensitivity of 77.78 % and specificity of 73.58 %. The AD8 and MMSE when combined in parallel yielded 88.89 % sensitivity and 70.16 % specificity. The serial use of the AD8 followed by the MMSE yielded 50 % sensitivity and 93.02 % specificity. Except for when an MMSE cutoff value of 26 was applied, the sensitivity of all examined modalities was poor and specificity was moderate for detecting mild cognitive impairment. ROC curve analysis revealed that the parallel application of the MMSE and AD8 (area under the ROC curve [AUC]: 82.3 % [75.1 %-89.4 %]) resulted in better dementia detection accuracy than the AD8 alone (AUC: 73.3 % [60.7 %-85.9 %]), the MMSE alone (AUC: 77.4 % [67.6 %-87.3 %]), or serial test administration (AUC: 67.6 % [53.4 %-81.8 %]). Conclusion: This study successfully demonstrated that the MMSE and AD8 combination for dementia screening could improve detection accuracy in a community setting.","2024-09","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","194","","","","","","","","","","English","","","","WOS:001258855500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","ACCURACY; ALZHEIMERS ASSOCIATION WORKGROUPS; Ascertain dementia 8 (AD8); Dementia screening; DIAGNOSTIC GUIDELINES; DISEASE; INFORMANT INTERVIEW; MILD COGNITIVE IMPAIRMENT; Mini -mental state examination (MMSE); MINI-MENTAL-STATE; NATIONAL INSTITUTE; POPULATION; RECOMMENDATIONS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KASNV7TB","journalArticle","2025","Cai, CY; Chen, H; Liu, YX; Chen, DQ; Zhou, XZ; Lin, YG","Graph-Based Feature Crossing to Enhance Recommender Systems","MATHEMATICS","","2227-7390","10.3390/math13020302","","In recommendation tasks, most existing models that learn users' preferences from user-item interactions ignore the relationships between items. Additionally, ensuring that the crossed features capture both global graph structures and local context is non-trivial, requiring innovative techniques for multi-scale representation learning. To overcome these difficulties, we develop a novel neural network, CoGraph, which uses a graph to build the relations between items. The item co-occurrence pattern assumes that certain items consistently appear in pairs in users' viewing or consumption logs. First, to learn relationships between items, a graph whose distance is measured by Normalised Point-Wise Mutual Information (NPMI) is applied to link items for the co-occurrence pattern. Then, to learn as many useful features as possible for higher recommendation quality, a Convolutional Neural Network (CNN) and the Transformer model are used to parallelly learn local and global feature interactions. Finally, a series of comprehensive experiments were conducted on several public data sets to show the performance of our model. It provides valuable insights into the capability of our model in recommendation tasks and offers a viable pathway for the public data operation.","2025-01","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","2","13","","","","","","","","","","English","","","","WOS:001404299400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","co-occurrence pattern; convolutional neural network; graph neural network; recommender systems; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6RP3AP3M","journalArticle","2023","Wang, YF; Liu, JP; Wang, J; Wang, XF; Wang, M; Chu, XT","FE-TCM: Filter-Enhanced Transformer Click Model for Web Search","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3259462","","Constructing click models and extracting implicit relevance feedback information from interaction between users and search engines are very important for improving the ranking of search results. Neural networks are effective for modeling users' click behavior, and we propose a novel Filter-Enhanced Transformer Click Model (FE-TCM) for web search. The model uses the powerful Transformer model as the backbone network for feature extraction and innovatively add a filter layer. Firstly, in order to reduce the influence of noise on user behavior data, we use the learnable filters to filter the log noise. Secondly, following the examination hypothesis, we model the attraction estimator and examination predictor respectively to output attractiveness scores and examination probabilities. A novel transformer model is used to learn the deeper representation among different features. Finally, we apply the different combination functions to integrate attractiveness scores and examination probabilities into the click prediction. From our experiments on two real-world session datasets, it is proved that FE-TCM outperforms the existing click models for the click prediction.","2023","2025-02-26 20:37:04","2025-02-26 20:37:04","","28680-28687","","","11","","","","","","","","","","English","","","","WOS:000966497100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Behavioral sciences; Click model; click prediction; Data models; Discrete Fourier transforms; Information filters; Predictive models; Search engines; transformer; Transformers; web search","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I6SM6XVI","journalArticle","2024","Torjmen, R; Haddar, K","Translation from Tunisian Dialect to Modern Standard Arabic: Exploring Finite-State Transducers and Sequence-to-Sequence Transformer Approaches","ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING","","2375-4699","10.1145/3681788","","Translation from the mother tongue, including the Tunisian dialect, to modern standard Arabic is a highly significant field in natural language processing due to its wide range of applications and associated benefits. Recently, researchers have shown increased interest in the Tunisian dialect, primarily driven by the massive volume of content generated spontaneously by Tunisians on social media following the revolution. This article presents two distinct translators for converting the Tunisian dialect into Modern Standard Arabic. The first translator utilizes a rule-based approach, employing a collection of finite state transducers and a bilingual dictionary derived from the study corpus. On the other hand, the second translator relies on deep learning models, specifically the sequence-to-sequence transformer model and a parallel corpus. To assess, evaluate, and compare the performance of the two translators, we conducted tests using a parallel corpus comprising 8,599 words. The results achieved by both translators are noteworthy. The translator based on finite state transducers achieved a BLEU score of 56.65, while the transformer model-based translator achieved a higher score of 66.07.","2024-10","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","10","23","","","","","","","","","","English","","","","WOS:001365838100004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","finite-state transducer; machine translation; sequence-to-sequence tranrformer; Tunisian dialect","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NSJ5MCS4","journalArticle","2023","Martínez-Nicolás, I; Martínez-Sánchez, F; Ivanova, O; Meilán, JJG","Reading and lexical-semantic retrieval tasks outperforms single task speech analysis in the screening of mild cognitive impairment and Alzheimer's disease","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-023-36804-y","","Age-related cognitive impairment have increased dramatically in recent years, which has risen the interes in developing screening tools for mild cognitive impairment and Alzheimer's disease. Speech analysis allows to exploit the behavioral consequences of cognitive deficits on the patient's vocal performance so that it is possible to identify pathologies affecting speech production such as dementia. Previous studies have further shown that the speech task used determines how the speech parameters are altered. We aim to combine the impairments in several speech production tasks in order to improve the accuracy of screening through speech analysis. The sample consists of 72 participants divided into three equal groups of healthy older adults, people with mild cognitive impairment, or Alzheimer's disease, matched by age and education. A complete neuropsychological assessment and two voice recordings were performed. The tasks required the participants to read a text, and complete a sentence with semantic information. A stepwise linear discriminant analysis was performed to select speech parameters with discriminative power. The discriminative functions obtained an accuracy of 83.3% in simultaneous classifications of several levels of cognitive impairment. It would therefore be a promising screening tool for dementia.","2023-06-15","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","1","13","","","","","","","","","","English","","","","WOS:001012136600065","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","APRAXIA; DEMENTIA; LANGUAGE; MANAGEMENT; PARAMETERS; PROSODY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W3B379RQ","journalArticle","2022","Zhao, HL; Jiang, YY; Wang, SH; He, F; Ren, FZ; Zhang, ZH; Yang, X; Zhu, C; Yue, JR; Li, Y; Liu, YP","Dysphagia diagnosis system with integrated speech analysis from throat vibration","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2022.117496","","Dysphagia is a widespread swallowing disorder. One of the most widely used clinical assessments is the bedside swallowing disorder screening, including the water swallow test. This method can only diagnose the disease according to the choking situation of the liquid, and the aspiration may appear during the drinking water test. In this paper, an automatic diagnostic system is designed according to the patient's performance in pronunciation. To diagnose dysphagia, we treat it as a binary classification task. We use a throat vibrator to collect the vibration signals of the subjects during pronunciation for clear speech signals. Feature engineering techniques, including feature extraction, data balancing and dimensionality reduction are implemented to extract the features for classification. Three popular classifiers are integrated to make the final predictions. Experimental results show that the integrated classifier performs better with accuracy = 72.09%, sensitivity = 63.64% and specificity = 80.95% respectively. Different from the traditional clinical ways, a new machine learning based swallowing disorders detection system is proposed with vibration signals of throat acquired for high-quality speech analysis. It may help to realize a portal and low-cost telemedicine device for dysphagia diagnosis at home.","2022-10-15","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","204","","","","","","","","","","English","","","","WOS:000819313900012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Biomedical monitoring; Machine learning; Medical expert systems; OROPHARYNGEAL DYSPHAGIA; PARKINSONS-DISEASE; PERFORMANCE; PREVALENCE; RISK-FACTOR; Speech analysis; STROKE; SURVIVAL; SWALLOW; Telemedicine","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VZKLPJZZ","journalArticle","2025","Paiva, PVV; Ramos, JJG; Gavrilova, M; de Carvalho, MAG","SkelETT-Skeleton-to-Emotion Transfer Transformer","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2025.3534145","","Emotion recognition plays an essential role in human-computer interaction, spanning diverse domains from human-robot communication and virtual reality to mental health assessment and affective computing. Traditionally, this field has heavily relied on visual and auditory cues, such as facial expressions and speech analysis. However, these modalities alone may not comprehensively capture the full spectrum of human emotion and suffer limitations due to noise or occlusion. Human skeletons, derived from depth sensors or pose estimation algorithms, offer an alternative for facial expression, including valuable spatial and temporal cues. In this paper, we introduce a novel approach to emotion recognition by pre-training a transformer model on a large dataset of unsupervised human skeleton representations and subsequently fine-tuning it for emotion classification. By exposing the model to an extensive corpus of unlabeled human skeleton data, we can effectively learn to represent complex spatial and temporal dependencies inherent in body movements. Following this foundational knowledge acquisition, the model undergoes fine-tuning on a smaller, labeled dataset tailored for emotion classification tasks. We introduce SkelETT, an encoder-only transformer architecture for body emotion recognition. Comprising a series of encoder layers, SkelETT patches 2D body pose representations, it also includes multi-head self-attention mechanisms and position-wise feed-forward networks, providing a powerful framework for extracting hierarchical features from sequential body pose data. We propose and evaluate the impact of different fine-tuning strategies on pose data using the MPOSE action recognition dataset as a pre-training source. Transfer performance is measured on the BoLD body emotion recognition dataset. Compared to the state-of-the-art, we report significant gains in accuracy (approximate to 34% higher), training time (approximate to 50% less), and model complexity reduction (approximate to 80% less trainable parameters).","2025","2025-02-26 20:37:04","2025-02-26 20:37:04","","23344-23358","","","13","","","","","","","","","","English","","","","WOS:001420293500041","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Accuracy; Adaptation models; affective computing; Attention-based design; body emotion recognition; Computational modeling; Data models; Emotion recognition; gait analysis; masked autoencoder; Skeleton; Solid modeling; Training; Transfer learning; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X5F4Y8HN","journalArticle","2024","Shankar, BM; Ramkumar, M; Saravanan, V","Design of Low Power Area Efficient 2D FIR Filter Using Optimized Multiplier and Adder for Speech Signal Analysis","CIRCUITS SYSTEMS AND SIGNAL PROCESSING","","0278-081X","10.1007/s00034-024-02870-4","","In signal analysis, various filters, devices, or algorithms are utilized to process signals, selectively permitting or blocking frequencies to induce desired changes in signal properties. Speech analysis faces challenges dealing with accent, dialect, pitch, and non-stationary features. Filters are crucial in modifying frequency components, reducing noise impact, enhancing robustness, and improving efficiency in speech analyses. To tackle speech analysis challenges, a proposed solution involves a low power, area efficient 2D Finite Impulse Response (FIR) filter, utilizing optimized multipliers and adders. The design integrates the Hybrid Mountaineering Team Bowerbird Optimization Algorithm (HMTBOA) to optimize filter coefficients, minimizing switching activities while considering ripple contents, transition width parameters, and power requirements. Additionally, High Speed Approximate Parallel Prefix Adders (HSAPPA) and the adaptive banyan tree growth optimization algorithm aim to reduce path delay, enhance area efficiency, and lower design complexity and power consumption in approximate adder design and error efficient posit logarithm approximate multiplier. The suggested method achieves outstanding results, with a 3.05ns delay, 0.101mW power consumption, and a 26.36dB signal-to-noise ratio, highlighting its robustness and effectiveness in addressing signal analysis challenges.","2024-09-28","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","","","","","","","","","","","English","","","","WOS:001320988400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Banyan tree growth optimization; Energy efficiency; Finite impulse response filters; Signal-to-noise ratio; Speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WSX2L7ND","journalArticle","2023","Adam, H","Morphosyntactic aspects of agrammatism in Palestinian Arabic: Findings from a Semitic language","REVISTA DE INVESTIGACION EN LOGOPEDIA","","2174-5218","10.5209/rlog.85225","","The present study uses a spontaneous speech task to investigate the production of morphosyntactic elements in Palestinian Arabic agrammatism (PA). Eight Palestinian-Arabic-speaking individuals with agrammatism (6 males and 2 females), diagnosed with mild to severe Broca's aphasia, and 8 age-and gender-matched healthy speakers participated in the study. A speech sample of 100 words from each participant was transcribed and analyzed. Findings showed that substitutions, omissions, simplified sentence structure, and tense inflection errors mostly characterized Palestinian Arabic agrammatism. As for tense and agreement, the speakers with agrammatism showed more tense inflection impairments than agreement inflections. The results suggest that the individuals of PA with agrammatism had marked dissociations in producing certain types of specific morphosyntactic structures, confirming previous findings, mainly from Hebrew and Jordanian Arabic.","2023","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","2","13","","","","","","","","","","English","","","","WOS:001025512000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Agrammatism; AGREEMENT; Morphosyntax; Palestinian Arabic; Semitic languages; TENSE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JPC6GVTE","journalArticle","2024","Viszket, A; Kárpáti, E; Kleiber, J","Narrowing or in Kálmán's writings Investigating the usage of vagy 'or' in Hungarian","ACTA LINGUISTICA ACADEMICA","","2559-8201","10.1556/2062.2024.00675","","The paper investigates the usage of the Hungarian connective vagy ' or ' . Our starting point is Ariel & Mauri's ' s (2018, 2019) and Ariel's ' s (2020) papers about the use of or, where they argue that its core meaning is ' alternativity ' . Our goal is to describe Hungarian vagy ' or ' by analyzing various corpus data, and compare the results. We examined the personal subcorpus of the Hungarian National Corpus (MNSZ2), and the Hungarian Spontaneous Speech Database (BEA). In this paper, as a tribute to the memory of L & aacute;szl & oacute; K & aacute;lm & aacute;n, we investigated a third corpus that is constructed from K & aacute;lm & aacute;n's ' s very popular informative texts on Qubit.","2024-06","2025-02-26 20:37:04","2025-02-26 20:37:04","","171-189","","1-2","71","","","","","","","","","","English","","","","WOS:001319538900007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","alternativity; corpus; K & aacute; L & aacute; lm & aacute; n; or; pragmasemantics; szl & oacute","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2R2FFJPB","journalArticle","2023","Meer, P; Fuchs, R; Deuber, D; Lacoste, V; Hänsel, EC","Prosodic variation of English in Dominica, Grenada, and Trinidad","WORLD ENGLISHES","","0883-2919","10.1111/weng.12615","","Varieties of English in the Caribbean have been claimed to have characteristic pitch patterns. However, there is little empirical research on prosodic aspects of English in the region. This paper provides a comparative phonetic analysis of several pitch parameters (pitch level, range, dynamism, rate of change, variability in rate of change, and tone rate) in English language data from Dominica, Grenada, and Trinidad that comprises read and spontaneous speech from 243 speakers. The results show that a wide pitch range and a high degree of variability in pitch, as mentioned in previous works, are not necessarily characteristic of English in the Caribbean overall, but that there are considerable cross-territorial prosodic differences, with English in Trinidad showing more variability than in Dominica and Grenada, particularly among female speakers. Socioprosodic variation, largely specific to Trinidad, was also identified.","2023-03","2025-02-26 20:37:04","2025-02-26 20:37:04","","48-72","","1","42","","","","","","","","","","English","","","","WOS:000888091400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","FUNDAMENTAL-FREQUENCY; LANGUAGE; STUDENTS ATTITUDES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EPJ5KGDJ","journalArticle","2023","Lan, CF; Wang, YQ; Zhang, L; Yu, ZL; Liu, CD; Guo, XX","Speech Enhancement Algorithm Combining Cochlear Features and Deep Neural Network with Skip Connections","JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO TECHNOLOGY","","1939-8018","10.1007/s11265-023-01891-7","","To solve the problem of the poor enhancement effect of traditional deep learning-based speech enhancement algorithms in low signal-to-noise ratio (SNR) scenarios, this paper proposes a method combining front-end processing Multi-Resolution Cochleagram(FP-MRCG) and skip connections deep neural network (Skip-DNN). This method uses FP-MRCG speech features to train Skip-DNN, and estimates the ideal ratio mask, filters out the background noise of the noisy speech to obtain the enhanced speech features, and obtains enhanced speech by phase reconstruction. The result shows that when the SNR is 0dB, using FP-MRCG as Skip-DNN's input, the average perceptual evaluation of speech quality (PESQ) of enhanced speech is 2.5283, and the average short-term objective intelligibility (STOI) is 0.8825, which is 3 % and 1.7% higher than MRCG, respectively. Besides, when using FP-MRCG as the input of DNN, Skip-DNN and convolutional neural network (CNN), Skip-DNN has a higher evaluation score in a low SNR environment, and CNN has a higher evaluation score in a high SNR environment. However, the training time for the CNN is twice as long as that for the Skip-DNN. Hence, it can be concluded that Skip-DNN performs better in speech enhancement than the other two networks.","2023-08","2025-02-26 20:37:04","2025-02-26 20:37:04","","979-989","","8","95","","","","","","","","","","English","","","","WOS:001057862900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","CANCELLATION; DNN; Low SNR; MASKING; MRCG; NOISE; Skip connections; Speech enhancement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RKNL5IC9","journalArticle","2021","Petinou, K; Taxitari, L; Phinikettos, I; Theodorou, E","Dynamic Linguistic Interconnectedness and Variability in Toddlers","JOURNAL OF PSYCHOLINGUISTIC RESEARCH","","0090-6905","10.1007/s10936-020-09747-y","","This investigation examined the existence of interconnectedness between developing linguistic subsystems. Spontaneous speech samples were collected from 31 typically-developing Greek-speaking toddlers across two age levels, at 28 and 36 months. Correlational analyses were performed synchronically and predictively, revealing significant positive relationships among all language skills within ages. Phonetic and grammatical skills also showed predictive value for later skills. In addition, a cluster analysis on the basis of performance on each individual skill revealed variable linguistic profiles: Low performers showed multiple interactions within and across ages, while High performers showed minimal such interactions. The current results revealed complex interdependencies among the different language skills with children exhibiting variable linguistic profiles, as supported by dynamic systems theory approaches to language acquisition.","2021-08","2025-02-26 20:37:04","2025-02-26 20:37:04","","797-814","","4","50","","","","","","","","","","English","","","","WOS:000604799000004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","4-YEAR-OLDS; ACQUISITION; CHILDREN; Dynamic systems theory; GREEK; Language development; LANGUAGE IMPAIRMENT SLI; LENGTH; Linguistic interconnectedness; PATTERNS; SKILLS; SPEECH; VOCABULARY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PFP9A9PZ","journalArticle","2023","Valerii, LM; Yu, BE; Elizabeth, VM; Kaiser, B","Invective transformations in modernmass media communication","FILOLOGICHESKIE NAUKI-NAUCHNYE DOKLADY VYSSHEI SHKOLY-PHILOLOGICAL SCIENCES-SCIENTIFIC ESSAYS OF HIGHER EDUCATION","","2310-4287","10.20339/PhS.3-23.031","","This material is devoted to the use of trash writing and the use of profanity in the era of digitalization, the reasons for its appearance are identified, and the negative consequences of its use in everyday life are analyzed. Invective vocabulary is unprintable swearing, obscene language, profanity, which came from the lower strata ofthe language. Foul language, invective vocabulary and phraseology are often ex-pressed as in a spontaneous speech reaction to an unexpected and unpleasant situation, and intention-ally as a trash-writing tool. The purpose ofthe article is to analyze the use of profanity in modern media, to identify the reasons for its appearance, about the alleged benefits ofits use. The main task is to consider the features ofthe invective linguistic transformation ofglobal communication in new media.","2023-05","2025-02-26 20:37:04","2025-02-26 20:37:04","","31-40","","3","","","","","","","","","","","English","","","","WOS:001053187700005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;4</p>","","","Internet; literary norm of language; literate speech; mass media; obscene language; speech communication; trash-writing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4LU7P7SN","journalArticle","2023","Schölderle, T; Haas, E; Ziegler, W","Speech Naturalness in the Assessment of Childhood Dysarthria","AMERICAN JOURNAL OF SPEECH-LANGUAGE PATHOLOGY","","1058-0360","10.1044/2023_AJSLP-23-00023","","Purpose: This study investigated perceived speech naturalness estimated by adult listeners in typically developing children and children with dysarthria. We aimed to identify predictors of naturalness among auditory-perceptual parameters and to evaluate the concept of naturalness as a clinical marker of childhood dysarthria. Method: In a listening experiment, naive adult listeners rated speech naturalness of 144 typically developing children (3-9 years old) and 28 children with neurological conditions (5-9 years old) on a visual analog scale. Speech samples were recorded using the materials of the Bogenhausen Dysarthria Scales- Childhood Dysarthria, which also provides for auditory-perceptual judgments covering all speech subsystems. Results: Children with dysarthria obtained significantly lower naturalness ratings compared to typically developing children. However, there was a substantial age effect observable in the typically developing children; that is, younger typically developing children were also perceived as somewhat unnatural. The ratings of the typically developing children were influenced by the occurrence of developmental speech features; for the children with neurological conditions, specific symptoms of dysarthria had an additional effect. In both groups, the perception of naturalness was predominantly determined by the children's articulation and intelligibility. Conclusions: Both symptoms of childhood dysarthria and developmental speech features (e.g., regarding articulation and intelligibility) were associated to some extent with unnatural speech by the listeners. Thus, perceived speech naturalness appears less suitable as a marker of dysarthria in children than in adults.","2023-07","2025-02-26 20:37:04","2025-02-26 20:37:04","","1633-1643","","4","32","","","","","","","","","","English","","","","WOS:001043938100016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","ACCEPTABILITY; CHILDREN; INTELLIGIBILITY; RATINGS; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D7JM4LZF","journalArticle","2023","Sukhavasi, V; Dondeti, V","Effective Automated Transformer Model based Sarcasm Detection Using Multilingual Data","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-023-17302-9","","Sarcasm detection is crucial for social media users to understand more about the underlying facts. However, determining the sarcasm only from text is not appropriate for recently updated social networks. It can be overcome by analyzing both the emoji and text data. Therefore, bilingual data in Hindi and English with emojis are offered as input to the proposed model. Traditionally, different transformer models were developed for efficient sarcasm detection, but such models haven't reached a satisfactory position in the performance enhancement chart. Therefore, in this proposed model, the attention based transformer model is developed, which shows effective performance in analyzing both the emoji and text data. Using raw data in the transformer model will reduce the accuracy rate, therefore, to overcome such an issue, the pre-processing steps like stop word removal, case folding, filtering, lemmatization, stemming, and tokenization are initially performed over the input data. After pre-processing, the Average based Term Frequency-Inverse Document Frequency (ATF-IDF) approach is used to extract the textual features. The Gated Temporal Bidirectional Convolution Network (GT-BiCNet) is used to create the text model. The emoji-to-vector model (E-VM) is used to construct the Emoji model and express the features as vectors. The produced models obtained TexMoJ features concatenated using a deep feature fusion method. The resultant vectors are used to classify the feature vectors using the deep learning model Attention LSTM based on Amended Bidirectional Encoder Representation from Transformers (ALABerT). The network model's losses are reduced by using the Enhanced Pelican Optimization Algorithm (EpoA). The softmax layer efficiently separates the data into sarcasm and non-sarcasm. The proposed method is compared to many current methodologies regarding various performances. The English Twitter dataset has attained 99.1% accuracy, 99.2% precision, 99.1% recall, 99.1% F-measure, an execution time of 56.66 s, and an average threshold of 12364.365 s. The accuracy, recall, precision, and F-measure of the Hindi Twitter dataset are 98.1%, 98.41%, 98.2%, and 69.6%, respectively.","2023-10-27","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","","","","","","","","","","","English","","","","WOS:001088502300013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Average based Term Frequency; Deep Neural Network; Emoji; Emoji to vector model; Feature concatenation; Feature extraction; IDENTIFICATION; Sarcasm identification; Text","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PRVRJWT5","journalArticle","2025","Radhika, S; Prasanth, A; Sowndarya, KKD","A Reliable speech emotion recognition framework for multi-regional languages using optimized light gradient boosting machine classifier","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2025.107636","","In today's world, the interpretation of emotions from human speech has prompted a lot of research attention in signal processing applications. Many speech recognition approaches have been introduced to detect the psychological states of individuals for public datasets. However, identifying the different emotions in the Indian regional language is one of the most demanding promises. As a consequence of inappropriate feature selection techniques, existing machine learning classifiers produce more misclassification errors for Indian regional datasets. Therefore, this work proposes a novel machine learning TEL (TF-EPOA + LGBM) classifier for accurately predicting human emotions. In the first stage, the pre-processing of the speech samples can be carried out to eradicate the artifacts. To express personal emotions in speech, the threshold-based feature selection technique is utilized to select the appropriate speech features. The optimal speech features are fed into the Light Gradient Boosting Machine (LGBM) classifier to significantly determine the emotions. The hyperparameters of the LGBM classifier are properly tuned with the aid of a Hybrid optimization where the Tangent Flight Operator (TF) is incorporated with the Exponential Pelican Optimization Algorithm (EPOA). This effective tuning facilitates the proposed classifier to achieve a superior classification accuracy of 99.27 %, 98.4 %, and 96.7 % for the Tamil, Malayalam, and English language datasets, respectively.","2025-07","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","105","","","","","","","","","","English","","","","WOS:001420320400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Feature Selection; Indian regional language; Machine Learning; Signal Processing; Speech Emotion Recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L3LMW2WN","journalArticle","2023","Guan, JJ; Peng, C; Shang, JY; Tang, XB; Sun, YN","PhaGenus: genus-level classification of bacteriophages using a Transformer model","BRIEFINGS IN BIOINFORMATICS","","1467-5463","10.1093/bib/bbad408","","Motivation: Bacteriophages (phages for short), which prey on and replicate within bacterial cells, have a significant role in modulating microbial communities and hold potential applications in treating antibiotic resistance. The advancement of high-throughput sequencing technology contributes to the discovery of phages tremendously. However, the taxonomic classification of assembled phage contigs still faces several challenges, including high genetic diversity, lack of a stable taxonomy system and limited knowledge of phage annotations. Despite extensive efforts, existing tools have not yet achieved an optimal balance between prediction rate and accuracy. Results: In this work, we develop a learning-based model named PhaGenus, which conducts genus-level taxonomic classification for phage contigs. PhaGenus utilizes a powerful Transformer model to learn the association between protein clusters and support the classification of up to 508 genera. We tested PhaGenus on four datasets in different scenarios. The experimental results show that PhaGenus outperforms state-of-the-art methods in predicting low-similarity datasets, achieving an improvement of at least 13.7%. Additionally, PhaGenus is highly effective at identifying previously uncharacterized genera that are not represented in reference databases, with an improvement of 8.52%. The analysis of the infants' gut and GOV2.0 dataset demonstrates that PhaGenus can be used to classify more contigs with higher accuracy.","2023-09-22","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","6","24","","","","","","","","","","English","","","","WOS:001136371500072","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","genus level; phage classification; protein cluster-based tokens; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SY92IBSW","journalArticle","2024","Jin, FY; Liu, K; Liu, CH; Cheng, TT; Zhang, H; Lee, VCS","A Cooperative Vehicle Localization and Trajectory Prediction Framework Based on Belief Propagation and Transformer Model","IEEE TRANSACTIONS ON CONSUMER ELECTRONICS","","0098-3063","10.1109/TCE.2024.3364052","","The advancement of sensing, transmission, and computation technologies has transformed modern vehicles into ubiquitous consumer electronics. This paper presents a cooperative vehicle localization and trajectory prediction framework for enabling Intelligent Transportation Systems (ITS) applications. Specifically, the proposed framework consists of a Belief Propagation based Location Approximation (BPLA) algorithm for cooperative vehicle localization and a Transformer-based Vehicle trajectory prediction model called VFormer. The BPLA algorithm first establishes a factor graph based on the sensor measurements transmitted by vehicles, and then adopts a modified belief propagation procedure to approximate the posterior distribution of vehicles. On this basis, VFormer extracts the hidden features from historical positions estimated by BPLA and vehicle motion data to model long-term and short-term motion patterns of vehicles. Moreover, the multi-head attention layer in the VFormer is utilized to learn the spatial-temporal dependencies between the target vehicle and its surrounding vehicles at different timestamps to improve prediction accuracy. A comprehensive performance evaluation has been conducted based on the public vehicle trajectory dataset and the real-world system prototype. Experiment results demonstrate the superiority of the proposed framework on improving vehicle localization and trajectory prediction performance.","2024-02","2025-02-26 20:37:04","2025-02-26 20:37:04","","2746-2758","","1","70","","","","","","","","","","English","","","","WOS:001245866100130","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","belief propagation; Belief propagation; Consumer electronics; Global navigation satellite system; Internet of Vehicles; Location awareness; Prediction algorithms; Predictive models; Trajectory; trajectory prediction; transformer model; Vehicle localization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5KCRCCEY","journalArticle","2022","Bose, A; Dutta, M; Dash, NS; Nandi, R; Dutt, A; Ahmed, S","Importance of Task Selection for Connected Speech Analysis in Patients with Alzheimer's Disease from an Ethnically Diverse Sample","JOURNAL OF ALZHEIMERS DISEASE","","1387-2877","10.3233/JAD-220166","","Features of linguistic impairment in Alzheimer's disease (AD) are primarily derived from English-speaking patients. Little is known regarding such deficits in linguistically diverse speakers with AD. We aimed to detail linguistic profiles (speech rate, dysfluencies, syntactic, lexical, morphological, semantics) from two connected speech tasks-Frog Story and picture description-in Bengali-speaking AD patients. The Frog Story detected group differences on all six linguistic levels, compared to only three with picture description. Critically, Frog Story captured the language-specific differences between the groups. Careful consideration should be given to the choice of connected speech tasks for dementia diagnosis in linguistically diverse populations.","2022","2025-02-26 20:37:04","2025-02-26 20:37:04","","1475-1481","","4","87","","","","","","","","","","English","","","","WOS:000812971000006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Alzheimer's disease; Bengali; connected speech; DEMENTIA; MORPHOLOGY; NEUROPSYCHOLOGY; picture description; semantic; speech analysis; story narration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AFZU5BFY","journalArticle","2024","Ding, F; Yuan, YQ; Lv, LZ; Zhang, R; Zhou, WB","Transformer-Enhanced DQN Approach for Energy and Cost-Efficient Large-Scale Dynamic Workflow Scheduling in Heterogeneous Environment","IEEE INTERNET OF THINGS JOURNAL","","2327-4662","10.1109/JIOT.2024.3442997","","In a heterogeneous workflow environment, the uncertainty of task execution times, dynamic resource changes, and task dependencies' evolution pose significant scheduling challenges. This article investigates how to make intelligent and adaptive scheduling decisions in a constantly changing heterogeneous cloud environment. We propose a novel scheduling approach, transformer-enhanced DQN (T-DQN) that combines the strengths of reinforcement learning (RL) and the Transformer model into a hybrid strategy. This method leverages the ability of RL to handle uncertainty and dynamics in the decision-making process while integrating the advantages of the Transformer model in dealing with long sequences and complex relationships. Our experimental evaluation shows that the T-DQN algorithm outperforms existing algorithms consistently in real-world workflow, dynamic scenarios, and high-load environments. T-DQN reduces makespan by up to 13.66%, improves energy by about 16.65%, and improves cost by 44.72% compared to the six other approaches. This performance is particularly significant in high-load environments, where T-DQN's adaptability and scalability minimize failure rates and optimize resource management, affirming its suitability as a robust solution to complex cloud computing challenges.","2024-11-15","2025-02-26 20:37:04","2025-02-26 20:37:04","","37351-37367","","22","11","","","","","","","","","","English","","","","WOS:001351916500095","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Cost; Costs; deep reinforcement learning (DRL); Dynamic scheduling; dynamic workflow scheduling; energy; Heuristic algorithms; Processor scheduling; Scheduling; Task analysis; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9EP2SU4U","journalArticle","2024","Wang, F; Xin, XJ; Lei, ZW; Zhang, Q; Yao, HP; Wang, XL; Tian, QH; Tian, F","Transformer-Based Spatio-Temporal Traffic Prediction for Access and Metro Networks","JOURNAL OF LIGHTWAVE TECHNOLOGY","","0733-8724","10.1109/JLT.2024.3393709","","Predicting the traffic in metro and access networks has a significant influence on expanding and upgrading the network. However, the intricate temporal and spatial correlations in such networks are affected by the users' behaviour and geographic characteristics. Consequently, predicting network traffic in metro or access networks faces significant challenges. To enhance the accuracy of this prediction, this paper explores a spatio-temporal approach to predicting traffic, based on a transformer model. This model effectively captures the temporal correlations in the traffic through a multi-head attention mechanism, learning long-term correlations resulting from the behaviour of the users of the individual nodes. Additionally, it acquires the spatial correlations of the traffic through a graph convolutional layer to capture short-term bursty correlations between users. Unlike previous single-point predictions, we optimize the model to make collaborative predictions for all the network nodes. Through parameter optimization, the improved model accurately predicts network traffic in small-scale regions. We implemented simulations using OMNET++ and predicted the traffic in various scenarios. Concurrently, we validated the proposed method with real network traffic based on operator measurements, achieving a prediction accuracy of 98.49%.","2024-08-01","2025-02-26 20:37:04","2025-02-26 20:37:04","","5204-5213","","15","42","","","","","","","","","","English","","","","WOS:001273934200040","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Bandwidth; Correlation; Feature extraction; Graph convolution network; LEARNING-BASED PREDICTION; machine learning; metro-access networks; Optical network units; OPTICAL NETWORKS; Optical switches; Predictive models; traffic prediction; transformer model; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UJW3W7TL","journalArticle","2022","Kim, DK; Kim, K","A Convolutional Transformer Model for Multivariate Time Series Prediction","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3203416","","This paper presents a multivariate time series prediction framework based on a transformer model consisting of convolutional neural networks (CNNs). The proposed model has a structure that extracts temporal features of input data through CNN and interprets correlations between variables through an attention mechanism. This framework solves the problem of the inability to simultaneously analyze the temporal features of the input data and the correlation between variables, which is a limitation of the forecasting models presented in existing studies. We designed a forecasting experiment using several time series datasets with various data characteristics to precisely evaluate the proposed model. In addition, comparative experiments were performed between the proposed model and several predictive models proposed in recent studies. Furthermore, we conducted ablation studies on the extent to which the proposed CNN structure in the prediction model affects the forecasting results by substituting a specific layer of the model. The results of the experiments showed that the proposed predictive model exhibited good performance in predicting time series data with a clear cycle and high correlation between variables, and improved the accuracy by approximately 3% to 5% compared with that of previous studies' time series prediction models.","2022","2025-02-26 20:37:04","2025-02-26 20:37:04","","101319-101329","","","10","","","","","","","","","","English","","","","WOS:000862340800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Artificial neural networks; ATTENTION; Convolutional neural networks; Data models; Feature extraction; Forecasting; predictive models; Predictive models; Time series analysis; time series prediction; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RFBU7238","journalArticle","2022","Liu, YL; Chen, JL; Chang, YH; He, SL; Zhou, ZT","A novel integration framework for degradation-state prediction via transformer model with autonomous optimizing mechanism","JOURNAL OF MANUFACTURING SYSTEMS","","0278-6125","10.1016/j.jmsy.2022.07.004","","Accurate degradation-state prediction has been a prerequisite for formulating equipment maintenance strategies. Meanwhile, as the increasing timeliness requirement of the maintenance, long-sequence prediction is of great significance. However, accurate long-sequence prediction is still challenging for existing methods. To address the problem, this paper proposed a data-driven framework for state prediction of the degradation process. The framework consists of a multi-output encoder, a health indicator (HI) constructor, and a state predictor. Firstly, with the deployment of multiple activation functions, the encoder can extract multiple non-linear features simultaneously. Meanwhile, due to the limited prior knowledge under practical conditions, the encoder is designed to extract features from high-dimension space directly. Then, based on the auto-encoder mechanism, the extracted features are fused into a HI, which can indicate the degradation state of the object. Finally, a novel autonomous optimizing Transformer (AOT) combining the recurrent mechanism and the position embedding algorithm is proposed to predict the HI using the extracted feature sequences. The effectiveness of the proposed framework is verified through two whole-lifetime bearing datasets. Compared with some state-of-the-art degradation-state prediction approaches, the proposed method performs higher prediction accuracy.","2022-07","2025-02-26 20:37:04","2025-02-26 20:37:04","","288-302","","","64","","","","","","","","","","English","","","","WOS:000828123400006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Degradation-state prediction; HEALTH; INDEX; Long feature sequences processing; PROGNOSIS; Rolling bearing; Transformer model; USEFUL LIFE PREDICTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2HFEUBDA","journalArticle","2024","Joshua, SR; Yeon, AN; Park, S; Kwon, K","A Hybrid Machine Learning Approach: Analyzing Energy Potential and Designing Solar Fault Detection for an AIoT-Based Solar-Hydrogen System in a University Setting","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14188573","","This research aims to optimize the solar-hydrogen energy system at Kangwon National University's Samcheok campus by leveraging the integration of artificial intelligence (AI), the Internet of Things (IoT), and machine learning. The primary objective is to enhance the efficiency and reliability of the renewable energy system through predictive modeling and advanced fault detection techniques. Key elements of the methodology include data collection from solar energy production and fault detection systems, energy potential analysis using Transformer models, and fault identification in solar panels using CNN and ResNet-50 architectures. The Transformer model was evaluated using metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), and an additional variation of MAE (MAE2). Known for its ability to detect intricate time series patterns, the Transformer model exhibited solid predictive performance, with the MAE and MAE2 results reflecting consistent average errors, while the MSE pointed to areas with larger deviations requiring improvement. In fault detection, the ResNet-50 model outperformed VGG-16, achieving 85% accuracy and a 42% loss, as opposed to VGG-16's 80% accuracy and 78% loss. This indicates that ResNet-50 is more adept at detecting and classifying complex faults in solar panels, although further refinement is needed to reduce error rates. This study demonstrates the potential for AI and IoT integration in renewable energy systems, particularly within academic institutions, to improve energy management and system reliability. Results suggest that the ResNet-50 model enhances fault detection accuracy, while the Transformer model provides valuable insights for strategic energy output forecasting. Future research could focus on incorporating real-time environmental data to improve prediction accuracy and developing automated AIoT-based monitoring systems to reduce the need for human intervention. This study provides critical insights into advancing the efficiency and sustainability of solar-hydrogen systems, supporting the growth of AI-driven renewable energy solutions in university settings.","2024-09","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","18","14","","","","","","","","","","English","","","","WOS:001323286700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;107</p>","","","artificial intelligence (AI); fault detection; Internet of Things (IoT); machine learning; solar-hydrogen storage system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HVQGET27","journalArticle","2022","Sabiha, NA; Alkhammash, HI; Lehtonen, M","High frequency modeling and experimental verification of distribution transformers using transfer function approach","ELECTRIC POWER SYSTEMS RESEARCH","","0378-7796","10.1016/j.epsr.2021.107671","","High frequency transformer model represents a mandatory requirement to study transient performance of distribution systems under lightning strokes. In Finland, the distribution systems are frequently subjected to these strokes. In this paper, an accurate and simple model is introduced for the distribution transformers concerning two-port network implemented using transfer functions. Compromising between simplicity and accuracy facilitates the high frequency modeling of transformer for complicated networks. The study is done using two distribution transformers used in Finland, DYN5 (100 kVA) and DYN11 (500 kVA). The proposed model parameters of the two-port network are experimentally extracted for each transformer under the impulse tests. System identification of the impedance parameter is done using the denoised experimental signals for primary and secondary voltages and currents. The model is verified using experimental results under unloaded and loaded conditions. The evaluation is accomplished concerning time domain and frequency responses. Also, the proposed model is compared with published accurate model for loaded, unloaded, and medium voltage spark-gap (MVSG) operation of the first transformer, 100 kVA. The proposed model achieves simple implementation and accurate results for unloaded and loaded transformers as well as under MVSG operation. The simulated results are carried out using the MATLAB and ATPDraw programs.","2022-03","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","204","","","","","","","","","","English","","","","WOS:000794151300011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","Denoised signal; High frequency transformer model; Medium voltage spark-gap; System identification; Two-port network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X36D75ZG","journalArticle","2025","Wang, SP; Pan, N; Gu, SQ; Wang, Y; Huang, YY","Transformer algorithm for pile-up correction in synchrotron radiation spectroscopic detection experiments","NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT","","0168-9002","10.1016/j.nima.2025.170215","","In this study, a Transformer-based algorithm is proposed for pulse pile-up correction in synchrotron radiation spectroscopy detection experiments. The Transformer model, employed as a deep learning framework, is evaluated in conjunction with Gaussian and trapezoidal filter shaping. Through systematic optimization of the model architecture and hyperparameters, its impact on recognition accuracy, loss rate, and generalization performance is analyzed. Additionally, the influence of varying the number of sublayers within the Transformer is investigated, showing that an increased number of sublayers enhances the model's capacity to process complex signals and improves generalization ability. Test experimental results indicate that trapezoidal filter shaping outperforms Gaussian filtering, demonstrating faster convergence and higher recognition accuracy, particularly when addressing pile-up signals. Spectroscopic experiments on iron, cobalt, and copper further demonstrate that the Transformer model consistently maintains energy resolution within the 125-136 eV range, even under high count rate conditions, supporting its applicability to high-throughput synchrotron environments. These findings highlight the potential of the Transformer algorithm to enhance real-time pulse pile-up corrections and improve energy resolution in challenging experimental contexts, providing a solid foundation for future refinements and broader applications.","2025-03","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","1072","","","","","","","","","","English","","","","WOS:001406844100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","COUNT; Filter shaping (trapezoidal; Gaussian); HPGe; Pile-up correction; PULSE-SHAPE DISCRIMINATION; SDD; Synchrotron radiation; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ACUTYPTP","journalArticle","2024","Wu, ZH; Dong, Z; Yang, K; Liu, QJ; Wang, W","Floodwater Extraction from UAV Orthoimagery Based on a Transformer Model","REMOTE SENSING","","2072-4292","10.3390/rs16214052","","In recent years, remote sensing has experienced a significant transformation due to rapid advancements in deep learning technology, which have greatly outpaced traditional methodologies. This integration has attracted substantial interest within the academic community. To address the complex challenges of extracting data on intricate water bodies during disaster scenarios, this study developed a post-disaster floodwater body dataset and an enhanced multi-scale transformer model architecture. Through end-to-end training, the precision of the model in extracting floodwater contours has been significantly improved. Additionally, by utilizing the vast amounts of unannotated data in remote sensing through an unsupervised pre-training task, the model's backbone network has been fortified, greatly enhancing its performance in remote sensing applications. Experimental analyses have shown that the multi-scale transformer-based algorithm for floodwater contour extraction proposed in this study is not only widely applicable but also excels in delivering precise segmentation results in complex environments. This refined approach ensures that the model adeptly handles the intricacies of floodwater body delineation, providing a robust solution for accurate extraction, even in disaster-stricken areas. This innovation represents a substantial leap forward in remote sensing, offering valuable insights and tools for disaster management and environmental monitoring.","2024-11","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","21","16","","","","","","","","","","English","","","","WOS:001351993200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","deep learning; disaster prevention and mitigation; disaster remote sensing; flood disaster; floodwater body dataset; IMAGERY; Segformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S6LX7897","journalArticle","2024","Kotteeswari, C; Chandrasekaran, V; Anitha, S","A novel approach to macular edema detection: DeepLabv3+segmentation and VGG with vision transformer classification","AUTOMATIKA","","0005-1144","10.1080/00051144.2024.2352313","","The domain of deep learning has seen significant advancements, particularly in the context of detecting macular edema from images of the retina, in recent times. This study introduces an innovative model for identifying macular edema, employing two deep learning models: Deeplabv3 + and VGG with a vision transformer. The Deeplabv3 + model is used to segment the macula region in the retinal images. The segmented macula region is then fed into the VGG for feature extraction with a vision transformer model for detection. This approach leverages the strengths of both models in detecting accurately and efficiently. The Deeplabv3 + model can accurately segment the macula region, which is crucial for accurate detection. The VGG combined with a vision transformer model proves highly efficient in detecting even subtle changes in the macular region, signifying the existence of macular edema. The results of our experiments with the dataset show that the proposed method outperforms current cutting-edge techniques. With an outstanding precision rate of 99.53%, the suggested approach firmly solidifies its superiority. The results highlight the effectiveness of the proposed technique in precisely and effectively detecting pathological fluid accumulation in retina images. This ability can have a substantial influence on the early detection and management of eye disorders.","2024-07-02","2025-02-26 20:37:04","2025-02-26 20:37:04","","1177-1190","","3","65","","","","","","","","","","English","","","","WOS:001222800000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","AUTOMATIC DETECTION; deep learning; DeepLabv3+; Macular edema; segmentation; SEGMENTATION; VGG; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3KPQBPPM","journalArticle","2024","Feng, L; Sinchai, A","Transfer learning model for cash-instrument prediction adopting a Transformer derivative","JOURNAL OF KING SAUD UNIVERSITY-COMPUTER AND INFORMATION SCIENCES","","1319-1578","10.1016/j.jksuci.2024.102000","","Investors aiming for high market returns must accurately predict the prices of various cash instruments. However, making accurate predictions is challenging due to the complex cyclic and trending characteristic of markets, characterized by high volatility and unpredictable fluctuations. Furthermore, many studies overlook how interactions between different markets affect price movements. To address these problems, this research introduces a deep transfer -learning approach derived from the Transformer model, named the rotary -positional encoding autocorrelation Transformer (RAT). Unlike traditional methods, the RAT employs autocorrelation instead of self -attention to more effectively capture periodic features, while rotary -positional encoding preserves both the absolute and relative positioning within sequences to enhance trend understanding. Through transfer learning, the RAT model extracts deep features from a source domain and applies them to a target domain, demonstrating superior performance over LSTM, CNN-LSTM, gated recurrent units (GRUs), and Transformer models in multi -day predictions across 12 cash -instrument datasets. It achieved a substantial increase in accuracy, with a 35.83% reduction in mean squared error (MSE), a 23.95% reduction in mean absolute error (MAE), and a 32.63% increase in the coefficient of determination (R2). This study validates the RAT model's effectiveness in predicting financial instrument prices.","2024-03","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","3","36","","","","","","","","","","English","","","","WOS:001203912600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Autocorrelation; Deep Learning; GRAPH NEURAL-NETWORK; PATTERN-RECOGNITION; Price Prediction; SHIFT; Transfer Learning; Transformer Model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LCWC7FEB","journalArticle","2023","Ben Letaifa, L; Rouas, JL","Variable Scale Pruning for Transformer Model Compression in End-to-End Speech Recognition","ALGORITHMS","","1999-4893","10.3390/a16090398","","Transformer models are being increasingly used in end-to-end speech recognition systems for their performance. However, their substantial size poses challenges for deploying them in real-world applications. These models heavily rely on attention and feedforward layers, with the latter containing a vast number of parameters that significantly contribute to the model's memory footprint. Consequently, it becomes pertinent to consider pruning these layers to reduce the model's size. In this article, our primary focus is on the feedforward layers. We conduct a comprehensive analysis of their parameter count and distribution. Specifically, we examine the weight distribution within each layer and observe how the weight values progress across the transformer model's blocks. Our findings demonstrate a correlation between the depth of the feedforward layers and the magnitude of their weights. Consequently, layers with higher weight values require less pruning. Building upon this insight, we propose a novel pruning algorithm based on variable rates. This approach sets the pruning rate according to the significance and location of each feedforward layer within the network. To evaluate our new pruning method, we conduct experiments on various datasets. The results reveal its superiority over conventional pruning techniques, such as local pruning and global pruning.","2023-09","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","9","16","","","","","","","","","","English","","","","WOS:001073332700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","end-to-end speech recognition; model compression; transformer architecture; variable scale pruning; weight magnitude","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6FDB5THC","journalArticle","2024","Feng, JR; Song, HR; Province, M; Li, GF; Payne, PRO; Chen, YX; Li, FH","PathFinder: a novel graph transformer model to infer multi-cell intra- and inter-cellular signaling pathways and communications","FRONTIERS IN CELLULAR NEUROSCIENCE","","1662-5102","10.3389/fncel.2024.1369242","","Recently, large-scale scRNA-seq datasets have been generated to understand the complex signaling mechanisms within the microenvironment of Alzheimer's Disease (AD), which are critical for identifying novel therapeutic targets and precision medicine. However, the background signaling networks are highly complex and interactive. It remains challenging to infer the core intra- and inter-multi-cell signaling communication networks using scRNA-seq data. In this study, we introduced a novel graph transformer model, PathFinder, to infer multi-cell intra- and inter-cellular signaling pathways and communications among multi-cell types. Compared with existing models, the novel and unique design of PathFinder is based on the divide-and-conquer strategy. This model divides complex signaling networks into signaling paths, which are then scored and ranked using a novel graph transformer architecture to infer intra- and inter-cell signaling communications. We evaluated the performance of PathFinder using two scRNA-seq data cohorts. The first cohort is an APOE4 genotype-specific AD, and the second is a human cirrhosis cohort. The evaluation confirms the promising potential of using PathFinder as a general signaling network inference model.","2024-05-23","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","18","","","","","","","","","","English","","","","WOS:001262452400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Alzheimer's disease; ALZHEIMERS-DISEASE; AUTOPHAGY; BIOLOGY; cell cell signaling communications; graph neural network; INFLAMMATION; microenvironment; OLIGOMERS; RECEPTOR; signaling pathways; TARGET","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ML4EPJK4","journalArticle","2024","Jiang, Y; Liu, ZY; Liao, GL; Ma, B","A Novel Chip-on-Board Defect Detection Approach Combining Infrared Thermal Evolution and Self-Supervised Transformer","IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS","","1551-3203","10.1109/TII.2024.3366251","","The chip on printed circuit board assembly (PCBA) is developing toward miniaturization and high density, which makes it increasingly challenging to detect micro solder bump defects hidden inside the package. Here, we propose a chip-on-board defect detection method that leverages infrared thermal evolution with an improved transformer model, achieving highly efficient and accurate industrial chip-on-board defect detection. A periodic read-and-write is implemented in the chip work process and temporal infrared sequences are utilized to analyze the temperature evolution with the purpose of comparing the temperature variations between the reference chip and the defective chip. Subsequently, we develop an enhanced transformer-based classification model incorporating adaptive pooling and batch normalization, resulting in superior performance when compared to existing state-of-the-art models. Extensive experiments are conducted to assess the generalization and robustness of the proposed approach. The compelling results confirm that the performance of self-supervised representation learning exceeds that of a fully supervised method in accuracy and robustness, albeit with access to limited data. Our method indicates effectiveness in the classification of near-distributed datasets and exhibits a promising prospect for microelectronic packaging reliability analysis on industrial high-density PCBA.","2024-05","2025-02-26 20:37:04","2025-02-26 20:37:04","","8044-8054","","5","20","","","","","","","","","","English","","","","WOS:001181517100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","Chip-on-board defect detection; improved transformer model; infrared thermal evolution; microelectronics packaging; self-supervised learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WX9LR42K","journalArticle","2024","Zhao, K; Xiong, W","Exploring region features in remote sensing image captioning","INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION","","1569-8432","10.1016/j.jag.2024.103672","","Remote sensing image captioning (RSIC), an emerging field of cross -modal tasks, has become a popular research topic in recent years. Feature extraction underlies all RSIC tasks, with current tasks using grid features. Compared with grid features, region features provide object -level location -related information; however, these features have not been considered in the RSIC tasks. Therefore, this study examined the performance of region features on RSIC tasks. We generated region annotations based on published RSIC datasets to address the need for region -related datasets. We extracted region features according to the labeled data and proposed a Region Attention Transformer model. To solve the information loss problem owing to the region of interest pooling during region feature extraction, we proposed region -grid features and used geometry relationships for estimating correlations between different region features. We compared the performances of the models using grid and region features. The results showed that region features performed well in RSIC tasks, and region features forced the model to pay more attention to object regions when generating object -related words. This study describes a novel method of using features in RSIC tasks. Our region annotations are available at https://github.com/zk-1019/exploring.","2024-03","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","127","","","","","","","","","","English","","","","WOS:001181895700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Image processing; Model training; Remote sensing image captioning; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IPQUDKD7","journalArticle","2024","Zhu, WW; Zhang, X; Hu, C; Zhao, BX; Niu, YX","Passenger Comfort Quantification for Automated Vehicle Based on Stacking of Psychophysics Mechanism and Encoder-Transformer Model","IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS","","1524-9050","10.1109/TITS.2023.3337775","","Passenger comfort is a crucial aspect that influences humans' acceptance of automated vehicles. The passenger comfort score (PCS) is closely related to the passengers' psychological states, however, comfort quantification methods based on the passengers' psychophysics mechanism are rare. This research pioneers a passenger comfort quantification model (PCQM) specifically designed for automated vehicles, demonstrating the model's ability to accurately quantify subjective PCS under urban LCS. Three significant contributions form the basis of this study: 1) A dataset dedicated to comfort quantification is collected. A novel PCQM based on ensemble learning of psychophysics mechanism based sub-model and encoder-transformer based sub-model is proposed. The psychophysics mechanism model is derived from Stevens' power law. 2) As a subjective indicator, the self-reported score (SRS), which is the indicator of PCS contains considerable noise. The PCQM addresses the issue of substantial noise prevalent in the subjective SRS by incorporating a semi-supervised learning strategy, which enhances data consistency and suppresses noise. 3) The efficacy of the proposed PCQM is corroborated via deployment on an automated vehicle, where the model's real-time predictions strongly align with SRS from onboard passengers.","2024-06","2025-02-26 20:37:04","2025-02-26 20:37:04","","5211-5224","","6","25","","","","","","","","","","English","","","","WOS:001125537700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Automated vehicle; encoder-transformer model; passenger comfort quantification; psychophysics mechanism; SCALE; semi-supervised learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZHQBV2NW","journalArticle","2024","Sajina, R; Tankovic, N; Ipsic, I","Multi-task peer-to-peer learning using an encoder-only transformer model","FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE","","0167-739X","10.1016/j.future.2023.11.006","","Peer-to-peer (P2P) learning is a decentralized approach to organizing the collaboration between end devices known as agents. Agents contain heterogeneous data, and that heterogeneity is disrupting the convergence and accuracy of the collectively learned models. A common technique to mitigate the negative impact of heterogeneous data is to arrange the learning process in a multi-task setting where each task, although it has the same learning objective, is learned separately. However, the multi-task technique can also be applied to solve distinct learning tasks. This paper presents and evaluates a novel approach that utilizes an encoder-only transformer model to enable collaboration between agents learning two distinct Natural Language Processing (NLP) tasks. The evaluation of the approach studied revealed that collaboration among agents, even when working towards separate objectives, can result in mutual benefits, mainly when the connections between agents are carefully considered. The multi-task collaboration led to a statistically significant increase of 11.6% in the mean relative accuracy compared to the baseline results for individual tasks. To our knowledge, this is the first study demonstrating a successful and beneficial collaboration between two distinct NLP tasks in a peer-to-peer setting.","2024-03","2025-02-26 20:37:04","2025-02-26 20:37:04","","170-178","","","152","","","","","","","","","","English","","","","WOS:001111745200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","BERT; Decentralized learning; Gossip averaging; NLP; Peer-to-peer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YN3SRGWW","journalArticle","2023","Wang, X; Zhang, SQ; Zhang, H; Wang, D; Bai, MY; Li, WL; Li, SD; Sun, TG; Wang, Y","Prediction of landslide susceptibility in Wenchuan County based on pixel-level samples","BULLETIN OF ENGINEERING GEOLOGY AND THE ENVIRONMENT","","1435-9529","10.1007/s10064-023-03230-3","","The essence of landslide susceptibility assessment is to conduct a probability assessment of landslide occurrences in a specific area based on historical landslide data. The majority of the results of landslide susceptibility evaluation depend on the fineness of the samples. Traditional sample production methods utilize statistical methods for quantification of dependent variables, and statistical formulas lead to a loss of information on the precise locations of landslides. This leads to uncertainty in the final prediction results. In this work, a new form of pixel-level sample production is proposed to preserve the landslide's boundary location information as much as possible. Three machine learning models, namely, a logistic regression model, a deep neural network model, and a transformer model, are combined with the sample production method proposed in this paper. The accuracy was verified using receiver operating characteristic curves. The three models' areas under the curves were 0.935, 0.963, and 0.980, respectively. The results of the susceptibility zoning showed that the TR model achieves a much finer classification of very high-landslide susceptibility areas, which makes it convenient to conserve human and material resources and focus on high-landslide-occurrence areas.","2023-06","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","6","82","","","","","","","","","","English","","","","WOS:000985913200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;80</p>","","","Deep neural network model; EARTHQUAKE; FUZZY-LOGIC; GIS; HAZARD; ISLAND; Landslide susceptibility prediction; Landslides; Logistic regression model; MODELS; MULTIVARIATE; NEURAL-NETWORKS; PROVINCE; SCALE; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M36TW8V7","journalArticle","2023","Xia, WS; Han, DZ; Li, D; Wu, ZD; Han, B; Wang, JX","An ensemble learning integration of multiple CNN with improved vision transformer models for pest classification","ANNALS OF APPLIED BIOLOGY","","0003-4746","10.1111/aab.12804","","Pests are the main threats to crop growth, and the precision classification of pests is conducive to formulating effective prevention and governance strategies. In response to the problems of low efficiency and inadaptability to the large-scale environment of existing pest classification methods, this paper proposes a new pest classification method based on a convolutional neural network (CNN) and an improved Vision Transformer model. First, the MMAlNet is designed to extract the characteristics of the identification object from different scales and finer granularity. Then, a classification model called DenseNet Vision Transformer (DNVT) combining a CNN and an improved vision transformer model is proposed. The proposed DNVT captures both long distance dependencies and local characteristic modelling capabilities, which can effectively improve pest classification accuracy. Finally, the ensemble learning algorithm is used to learn MMAlNet and DNVT classification forecasts for soft voting, further enhancing the classification accuracy of pests. The simulation experiment results on the D0 and IP102 datasets show that the proposed method attained a maximum classification of 99.89 and 74.20%, respectively, which is better than other state-of-the-art methods and has a high practical application value.","2023-03","2025-02-26 20:37:04","2025-02-26 20:37:04","","144-158","","2","182","","","","","","","","","","English","","","","WOS:000864290400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","AUTOMATIC CLASSIFICATION; convolutional neural networks; ensemble learning; insect classification; RECOGNITION; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VUC5X3E7","journalArticle","2022","Zirka, SE; Albert, D; Moroz, YI; Renner, H","Further Improvements in Topological Transformer Model Covering Core Saturation","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3183279","","This paper is devoted to improvements of the low-frequency topological model of a three-legged stacked-core transformer. It is shown that B hysteresis loops employed in the transformer model and Psi - i curves measured at transformer terminals are quite different in shape. Adistinction is made between transformer modeling at moderate and deep saturations, separated conditionally by the level of technical saturation (near 2 Tesla) typical for grain-oriented steels. In the former case, in addition to the magnetic coupling of different phase windings through the core, an important part is played by air gaps at core joints. It is found that the effective gap length depends on the instantaneous magnetic flux and this dependence is proposed to implement by a variable inductance. It is shown that regardless of the core saturation depth, an important role in the transformer modeling belongs to the distribution of the zero-sequence path between all three phases. In addition to accurate replications of the special purpose saturation test, the modeled results are in a close agreement with positive- and zero sequence data measured on a 50 kVA transformer, as well as with the measured inrush currents.","2022","2025-02-26 20:37:04","2025-02-26 20:37:04","","64018-64027","","","10","","","","","","","","","","English","","","","WOS:000814597400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","3-PHASE TRANSFORMERS; core gap; Saturation; SENSITIVITY; three-legged transformer; topological model; transients; TRANSIENTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C5U5PPVA","journalArticle","2021","Mombello, EE; Flórez, GAD","An improved high frequency white-box lossy transformer model for the calculation of power systems electromagnetic transients","ELECTRIC POWER SYSTEMS RESEARCH","","0378-7796","10.1016/j.epsr.2020.106838","","The recent changes in power systems give rise to new scenarios in which power transformers must continue to perform satisfactorily. Resonant transient phenomena caused by the interaction of the power grid and the transformer have recently led to serious failures. It is therefore essential to carry out network transient studies in order to evaluate potentially dangerous events of this type. This requires high frequency transformer models having an adequate representation of the damping. In this work, a white-box transformer model is presented together with a new and robust procedure for determining its parameters that enforces the stability of the model. In this way, substantial improvements are proposed with respect to models currently available in the literature in the methodological aspects needed for successful practical implementation. The methodology for determining basic impedance data, obtained using the Finite Element Method is first described and then a new methodology for the subsequent processing of these data to obtain the parameters of a stable and robust model is presented, using Vector Fitting in combination with Particle Swarm Optimization. The model has been successfully validated using a large power transformer as a case study within the scope of the JWG CIGRE A2/C4.52.","2021-01","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","190","","","","","","","","","","English","","","","WOS:000594666800005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","COMPUTATION; Damping modeling; Power system transients; Transformers; White-box models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NM6VHBZX","journalArticle","2025","Gao, SW; Qin, Y; Zhu, RX; Zhao, ZR; Zhou, H; Zhu, ZH","SGSAFormer: Spike Gated Self-Attention Transformer and Temporal Attention","ELECTRONICS","","2079-9292","10.3390/electronics14010043","","Spiking neural networks (SNNs), a neural network model structure inspired by the human brain, have emerged as a more energy-efficient deep learning paradigm due to their unique spike-based transmission and event-driven characteristics. Combining SNNs with the Transformer model significantly enhances SNNs' performance while maintaining good energy efficiency. The gating mechanism, which dynamically adjusts input data and controls information flow, plays an important role in artificial neural networks (ANNs). Here, we introduce this gating mechanism into SNNs and propose a novel spike Transformer model, called SGSAFormer, based on the Spikformer network architecture. We introduce the Spike Gated Linear Unit (SGLU) module to improve the Multi-layer perceptron (MLP) module in SNNs by adding a gating mechanism to enhance the model's expressive power. We also incorporate Spike Gated Self-Attention (SGSA) to strengthen the network's attention mechanism, improving its ability to capture temporal information and dynamic processing. Additionally, we propose a Temporal Attention (TA) module, which selects new filters for the input data along the temporal dimension and can substantially reduce energy consumption with only a slight decrease in accuracy. To validate the effectiveness of our approach, we conducted extensive experiments on several neuromorphic datasets. Our model outperforms other state-of-the-art models in terms of performance.","2025-01","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","1","14","","","","","","","","","","English","","","","WOS:001393555900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","attention; gating mechanism; NEURAL-NETWORKS; spiking neural networks; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R83LGETN","journalArticle","2025","Zhou, JQ; Wang, Z; Liu, JX; Luo, XL; Chen, MY","Modeling and Evaluation of Attention Mechanism Neural Network Based on Industrial Time Series Data","PROCESSES","","2227-9717","10.3390/pr13010184","","Chemical process control systems are complex, and modeling the controlled object is the first task in automatic control and optimal design. Most chemical process modeling experiments require test signals to be applied to the process, which may lead to production interruptions or cause safety accidents. Therefore, this paper proposes an improved transformer model based on a self-attention mechanism for modeling industrial processes. Then, an evaluation mechanism based on root mean square error (RMSE) and Kullback-Leibler divergence (KLD) metrics is designed to obtain more appropriate model parameters. The Variational Auto-Encoder (VAE) network is used to compute the associated KLD. Finally, a real nonlinear dynamic process in the petrochemical industry is modeled and evaluated using the proposed methodology to predict the time series data of the process. This study demonstrates the validity of the proposed transformer model and illustrates the versatility of using an integrated modeling, evaluation, and prediction scheme for nonlinear dynamic processes in process industries. The scheme is of great importance for the field of industrial soft measurements as well as for deep learning-based time series prediction. In addition, the issue of a suitable time domain for the prediction is discussed.","2025-01","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","1","13","","","","","","","","","","English","","","","WOS:001403874500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","chemical process modeling; deep learning; DISTRIBUTIONS; evaluation mechanism; KULLBACK-LEIBLER DIVERGENCE; MEAN-SQUARE ERROR; modified transformer; nonlinear dynamic modeling; PREDICTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G2576CVD","journalArticle","2024","Zeng, QL; Wang, LH; Zhu, H; Liu, SZ; Wang, CF; Chen, LF; Tao, JH","Estimating Daily Concentrations of Near-Surface CO, NO2, and O3 Simultaneously Over China Based on Spatiotemporal Multi-Task Transformer Model","ATMOSPHERIC ENVIRONMENT","","1352-2310","10.1016/j.atmosenv.2023.120193","","Accurate and efficient estimation of near-surface air pollutant concentrations holds significant practical importance. Current models for estimating near-surface concentrations (NSC) primarily rely on shallow methods and focus on estimating a single pollutant. However, these models face challenges in capturing the complex spatiotemporal patterns of NSC and demonstrate inefficiency. To overcome these limitations, we propose a spatiotemporal multi-task Transformer model (stmtTransformer) to simultaneously estimate the NSC of carbon monoxide (CO), nitrogen dioxide (NO2), and ozone (O3). Estimation experiments conducted in China from 2021 to 2022 demonstrate that stmtTransformer achieves optimal performance by effectively capturing the spatiotemporal variations of NSC. Based on sample-based validation, the R2 values are 0.643 (CO), 0.781 (NO2), and 0.902 (O3), and the RMSE values are 0.194 mg/m3 (CO), 5.613 mu g/m3 (NO2), and 13.330 mu g/m3 (O3), respectively. In terms of efficiency, stmtTransformer significantly improved the training efficiency by 185.21 % and the estimation efficiency by 129.44 % compared to the single-task model. Finally, when plotting the daily and seasonal maps of NSC for 2022, it is evident that the estimates exhibit a consistent spatial distribution.","2024-01-01","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","316","","","","","","","","","","English","","","","WOS:001112793000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","Air quality; AIR-POLLUTION; Deep learning; Near-surface concentrations; OZONE; PREDICTION; S5P-TROPOMI; Transformer neural network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FAPLN8HQ","journalArticle","2022","Hakeem, H; Feng, W; Chen, ZB; Choong, J; Brodie, MJ; Fong, SL; Lim, KS; Wu, JH; Wang, XF; Lawn, N; Ni, GZ; Gao, X; Luo, MJ; Chen, ZY; Ge, ZY; Kwan, P","Development and Validation of a Deep Learning Model for Predicting Treatment Response in Patients With Newly Diagnosed Epilepsy","JAMA NEUROLOGY","","2168-6149","10.1001/jamaneurol.2022.2514","","IMPORTANCE Selection of antiseizure medications (ASMs) for epilepsy remains largely a trial-and-error approach. Under this approach, many patients have to endure sequential trials of ineffective treatments until the ""right drugs"" are prescribed. OBJECTIVE To develop and validate a deep learning model using readily available clinical information to predict treatment success with the first ASM for individual patients. DESIGN, SETTING, AND PARTICIPANTS This cohort study developed and validated a prognostic model. Patients were treated between 1982 and 2020. All patients were followed up for a minimum of 1 year or until failure of the first ASM. A total of 2404 adults with epilepsy newly treated at specialist clinics in Scotland, Malaysia, Australia, and China between 1982 and 2020 were considered for inclusion, of whom 606 (2S.2%) were excluded from the final cohort because of missing information in 1 or more variables. EXPOSURES One of 7 antiseizure medications. MAIN OUTCOMES AND MEASURES With the use of the transformer model architecture on 16 clinical factors and ASM information, this cohort study first pooled all cohorts for model training and testing. The model was trained again using the largest cohort and externally validated on the other 4 cohorts. The area under the receiver operating characteristic curve (AUROC), weighted balanced accuracy, sensitivity, and specificity of the model were all assessed for predicting treatment success based on the optimal probability cutoff. Treatment success was defined as complete seizure freedom for the first year of treatment while taking the first ASM. Performance of the transformer model was compared with other machine learning models. RESULTS The final pooled cohort included 1798 adults (54.5% female; median age, 34 years [IQR, 24-50 years)). The transformer model that was trained using the pooled cohort had an AUROC of 0.65 (95% CI, 0.63-0.67) and a weighted balanced accuracy of 0.62 (95% CI, 0.60-0.64) on the test set. The model that was trained using the largest cohort only had AUROCs ranging from 0.52 to 0.60 and a weighted balanced accuracy ranging from 0.51 to 0.62 in the external validation cohorts. Number of pretreatment seizures, presence of psychiatric disorders, electroencephalography, and brain imaging findings were the most important clinical variables for predicted outcomes in both models. The transformer model that was developed using the pooled cohort outperformed 2 of the 5 other models tested in terms of AUROC. CONCLUSIONS AND RELEVANCE In this cohort study, a deep learning model showed the feasibility of personalized prediction of response to ASMs based on clinical information. With improvement of performance, such as by incorporating genetic and imaging data, this model may potentially assist clinicians in selecting the right drug at the first trial.","2022-10","2025-02-26 20:37:04","2025-02-26 20:37:04","","986-996","","10","79","","","","","","","","","","English","","","","WOS:000848899800003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;39<br/>Total Times Cited:&nbsp;&nbsp;39<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","DEFINITION; ILAE COMMISSION; IMPACT; LAMOTRIGINE; SANAD; TOPIRAMATE; TREATMENT CHOICE; UNCLASSIFIABLE EPILEPSY; VALPROATE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZH939RWU","journalArticle","2024","Javaid, A; Sajid, M; Uddin, E; Waqas, A; Ayaz, Y","Sustainable urban energy solutions: Forecasting energy production for hybrid solar-wind systems","ENERGY CONVERSION AND MANAGEMENT","","0196-8904","10.1016/j.enconman.2024.118120","","In recent years, hybrid Solar-Wind energy system has emerged as a viable solution to achieve sustainable energy generation and alleviate the burden on the power grid. However, enhancing the system configuration to balance energy production and consumption remains a challenging task. In this study, we propose an energy forecasting methodology that leverages transformers as an AI tool to predict energy production from a hybrid PhotovoltaicWind system in an urban environment. The methodology involves pre-processing data, training the transformer model, and generating energy forecasts. The research utilized a one -year dataset, collecting data at 10 -minute intervals, encompassing various parameters like wind speed, wind direction, global horizontal irradiance, direct normal irradiance, and diffuse horizontal irradiance, all for the purpose of wind and solar energy prediction. The study additionally examined how the model's performance is impacted by fine-tuning hyperparameters and revealed that this dependency is inversely proportional to characteristics such as training data, horizon, and learning rate. Hyperparameters such as look back and epoch, on the other hand, were observed to have a direct link with the model's dependency. Multiple simulations have been conducted to fine -tune the hyperparameters of the machine learning model to improve its efficiency. The outcomes exhibited the energy forecasting methodology's effectiveness in predicting energy production for a hybrid Photovoltaic-Wind system in an urban environment. The forecasting accuracy for solar energy and wind speed reached impressive levels, with 90.7% and 90.4% respectively, across various horizons. The time resolution used for forecasting was 10 min, and the data was split into training, testing, and validation sets with ratios of 60-20-20% and 70-15-15%. Leveraging a transformer model for energy forecasting with an accuracy up to 90% holds the promise of streamlining the planning and management of hybrid PV-Wind-Battery storage systems. This, in turn, can play a critical role in advancing the adoption of sustainable and efficient energy solutions for both residential and commercial structures. The code for timeseries data forecasting is available at https://www.kaggle.com/code/ alijavaid43/transformer-model.","2024-02-15","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","302","","","","","","","","","","English","","","","WOS:001171250200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","Artificial intelligence; BUILDINGS; FOSSIL-FUELS; Hybrid system; Islamabad; MANAGEMENT; OPTIMIZATION; Prediction; RENEWABLE ENERGY; Renewable sources; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8KHJ9A6G","journalArticle","2023","Liu, B; Yu, AZ; Zuo, XB; Wang, RR; Qiu, CP; Yu, XC","Deep hierarchical transformer for change detection in high-resolution remote sensing images","EUROPEAN JOURNAL OF REMOTE SENSING","","2279-7254","10.1080/22797254.2023.2196641","","Deep learning instantiated by convolutional neural networks has achieved great success in high-resolution remote-sensing image change detection. However, such networks have a limited receptive field, being unable to extract long-range dependencies in a scene. As the transformer model with self-attention can better describe long-range dependencies, we introduce a hierarchical transformer model to improve the precision of change detection in high-resolution remote sensing images. First, the hierarchical transformer extracts abstract features from multitemporal remote sensing images. To effectively minimize the model's complexity and enhance the feature representation, we limit the self-attention calculation of each transformer layer to local windows with different sizes. Then, we combine the features extracted by the hierarchical transformer and input them into a nested U-Net to obtain the change detection results. Furthermore, a simple but effective model fusion strategy is adopted to improve the change detection accuracy. Extensive experiments are carried out on two large-scale data sets for change detection, LEVIR-CD and SYSU-CD. The quantitative and qualitative experimental results suggest that the proposed method outperforms the advanced methods in terms of detection performance.","2023-12-31","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","1","56","","","","","","","","","","English","","","","WOS:000963374900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","change detection; deep learning; FEATURE-EXTRACTION; hierarchical transformer; model fusion; nested U-Net; NETWORK; Remote sensing image; UNSUPERVISED CHANGE DETECTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VSZ5QCVG","journalArticle","2022","Choi, WH; Choi, YS","Effective Pre-Training Method and Its Compositional Intelligence for Image Captioning","SENSORS","","1424-8220","10.3390/s22093433","","With the increase in the performance of deep learning models, the model parameter has increased exponentially. An increase in model parameters leads to an increase in computation and training time, i.e., an increase in training cost. To reduce the training cost, we propose Compositional Intelligence (CI). This is a reuse method that combines pre-trained models for different tasks. Since the CI uses a well-trained model, good performance and small training cost can be expected in the target task. We applied the CI to the Image Captioning task. Compared to using a trained feature extractor, the caption generator is usually trained from scratch. On the other hand, we pre-trained the Transformer model as a caption generator and applied CI, i.e., we used a pre-trained feature extractor and a pre-trained caption generator. To compare the training cost of the From Scratch model and the CI model, early stopping was applied during fine-tuning of the image captioning task. On the MS-COCO dataset, the vanilla image captioning model reduced training cost by 13.8% and improved performance by up to 3.2%, and the Object Relation Transformer model reduced training cost by 21.3%.","2022-05","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","9","22","","","","","","","","","","English","","","","WOS:000794464900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","compositional intelligence; feature mapping layer; image captioning; pre-training method; transfer learning; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TWQEYMMK","journalArticle","2024","Zhou, X; Zhang, YC; Ren, ZH; Mi, TC; Jiang, ZY; Yu, TZ; Zhou, SH","A Unet-inspired spatial-attention transformer model for segmenting gear tooth surface defects","ADVANCED ENGINEERING INFORMATICS","","1474-0346","10.1016/j.aei.2024.102933","","Automated vision defect detection is a crucial step in monitoring product quality in industrial production. Despite the widespread utilization of deep learning methods for surface defect identification, several challenges persist in the context of gear applications. Firstly, there is a lack of dedicated defect detection methods specifically tailored for gear tooth surfaces. As surface defects vary in size, the regular single-scale attention computation at each transformer layer tends to compromise spatial information. To address these challenges, we first propose a novel U-shaped spatial-attention transformer model for tooth surface detection. A shunted- window method is introduced to create a pyramid receptive field within a single self-attention layer. This method captures fine-grained features with a small window while preserving coarse-grained features with a larger window. Consequently, this technique enables effective multi-scale information fusion, accommodating objects of different sizes. We curate a dataset of defective samples collected under various working conditions using the CL-100 gear wear machine. Experimental results demonstrate that the proposed model outperforms the state-of-the-art (SOTA) U-shaped SwinUnet by +8.74% AP and +4.40% Sm, while surpassing the excellent defect detection method of ResT-UperNet by +0.63% AP and +4.69% Sm.","2024-10","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","","62","","","","","","","","","","English","","","","WOS:001358747200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Gear surface wear; NETWORK; Shunted windows; Tooth surface defect detection; Unet","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XVT7FSLK","journalArticle","2024","Xia, CX; Tao, ZP; Wang, W; Zhao, WJ; Ge, B; Gao, XJ; Li, KC; Zhang, Y","CTA-Net: A Gaze Estimation network based on Dual Feature Aggregation and Attention Cross Fusion","COMPUTER SCIENCE AND INFORMATION SYSTEMS","","1820-0214","10.2298/CSIS231116020X","","Recent work has demonstrated the Transformer model is effective for computer vision tasks. However, the global self-attention mechanism utilized in Transformer models does not adequately consider the local structure and details of images, which may result in the loss of information and local details, causing decreased estimation accuracy in gaze estimation tasks when compared to convolution or sequential stacking methods. To address this issue, we propose a parallel CNNs-Transformer aggregation network (CTA-Net) for gaze estimation, which fully leverages the advantages of the Transformer model in modeling global context while the convolutional neural networks (CNNs) model in retaining local details. Specifically, Transformer and ResNet are deployed to extract facial and eye information, respectively. Additionally, an attention cross fusion (ACFusion) Block is embedded with CNN branch, which decomposes features in space and channels to supplement lost features, suppress noise, and help extract eye features more effectively. Finally, a dual-feature aggregation (DFA) module is proposed to effectively fuse the output features of both branches with the help feature a selection mechanism and a residual structure. Experimental results on the MPIIGaze and Gaze360 datasets demonstrate that our CTA-Net achieves state-of-the-art results.","2024-06","2025-02-26 20:37:04","2025-02-26 20:37:04","","831-850","","3","21","","","","","","","","","","English","","","","WOS:001278590500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Appearance-based gaze estimation; Deep neural networks; Dilated con- volution; Fusion; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DPH2LRNJ","journalArticle","2024","Moon, J","A Multi-Step-Ahead Photovoltaic Power Forecasting Approach Using One-Dimensional Convolutional Neural Networks and Transformer","ELECTRONICS","","2079-9292","10.3390/electronics13112007","","Due to environmental concerns about the use of fossil fuels, renewable energy, especially solar energy, is increasingly sought after for its ease of installation, cost-effectiveness, and versatile capacity. However, the variability in environmental factors poses a significant challenge to photovoltaic (PV) power generation forecasting, which is crucial for maintaining power system stability and economic efficiency. In this paper, a novel muti-step-ahead PV power generation forecasting model by integrating single-step and multi-step forecasts from various time resolutions was developed. One-dimensional convolutional neural network (CNN) layers were used for single-step forecasting to capture specific temporal patterns, with the transformer model improving multi-step forecasting by leveraging the combined outputs of the CNN. This combination can provide accurate and immediate forecasts as well as the ability to identify longer-term generation trends. Using the DKASC-ASA-1A and 1B datasets for empirical validation, several preprocessing methods were applied and a series of experiments were conducted to compare the performance of the model with other widely used deep learning models. The framework proved to be capable of accurately predicting multi-step-ahead PV power generation at multiple time resolutions.","2024-06","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","11","13","","","","","","","","","","English","","","","WOS:001245658400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","IMPACT; multi-time resolution forecasting; one-dimensional convolutional neural network; OUTPUT; photovoltaic power generation; PREDICTION; renewable energy; time-series forecasting; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GY8V2IBX","journalArticle","2023","Wang, H; Zhou, QJ; Wei, S; Xue, XY; Zhou, XH; Zhang, XB","Research on Seabed Sediment Classification Based on the MSC-Transformer and Sub-Bottom Profiler","JOURNAL OF MARINE SCIENCE AND ENGINEERING","","2077-1312","10.3390/jmse11051074","","This paper proposed an MSC-Transformer model based on the Transformer's neural network, which was applied to seabed sediment classification. The data came from about 2900 km(2) of seabed area on the northern slope of the South China Sea. Using the submarine backscattering intensity and depth data obtained by the sub-bottom profiler, combined with latitude and longitude information, a seabed dataset of the slope area of the South China Sea was constructed. Moreover, using the MSC-Transformer, the accurate identification and judgment of sediment types such as calcareous bio-silt, calcareous bio-clay silt, silty sand, medium sand and gravel sand were realized. Compared with the conventional deep neural network CNN, RNN, etc., the model shows advantages when applied to the sediment dataset of the shallow sea slope region of the South China Sea. This confirms the feasibility and validity of the model and provides a reliable and accurate tool for seabed sediment classification in the field of marine science. The completeness and accuracy of the dataset and the good performance of the model provide a solid foundation for the scientificalness and practicability of the study.","2023-05-18","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","5","11","","","","","","","","","","English","","","","WOS:000997470700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","BACKSCATTER; deep learning; machine learning; seabed sediment classification; SONAR DATA; sub-bottom profiler; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WDLPVX36","journalArticle","2024","Komeiji, S; Mitsuhashi, T; Iimura, Y; Suzuki, H; Sugano, H; Shinoda, K; Tanaka, T","Feasibility of decoding covert speech in ECoG with a Transformer trained on overt speech","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-62230-9","","Several attempts for speech brain-computer interfacing (BCI) have been made to decode phonemes, sub-words, words, or sentences using invasive measurements, such as the electrocorticogram (ECoG), during auditory speech perception, overt speech, or imagined (covert) speech. Decoding sentences from covert speech is a challenging task. Sixteen epilepsy patients with intracranially implanted electrodes participated in this study, and ECoGs were recorded during overt speech and covert speech of eight Japanese sentences, each consisting of three tokens. In particular, Transformer neural network model was applied to decode text sentences from covert speech, which was trained using ECoGs obtained during overt speech. We first examined the proposed Transformer model using the same task for training and testing, and then evaluated the model's performance when trained with overt task for decoding covert speech. The Transformer model trained on covert speech achieved an average token error rate (TER) of 46.6% for decoding covert speech, whereas the model trained on overt speech achieved a TER of 46.3% (p>0.05;d=0.07) . Therefore, the challenge of collecting training data for covert speech can be addressed using overt speech. The performance of covert speech can improve by employing several overt speeches.","2024-05-20","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","1","14","","","","","","","","","","English","","","","WOS:001228252900021","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","AM-241 ALPHA-PARTICLES; BIODOSIMETRY; CANCER; CELLS; CHROMOSOME-ABERRATIONS; DNA-DAMAGE; EXPOSURES; MIXED BEAM; SPACE RADIATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5DJ4RIBZ","journalArticle","2024","Sun, Y; Zhang, J; Zhang, Y","Swin Transformer based fluid classification using Gram angle field-converted well logging data: A novel approach","PHYSICS OF FLUIDS","","1070-6631","10.1063/5.0187614","","Fluid prediction is important in exploration work, helping to determine the location of exploration targets and the reserve potential of the estimated area. Machine learning methods can better adapt to different data distributions and nonlinear relationships through model training, resulting in better learning of these complex relationships. We first use the Gram angle field (GAF) to convert one-dimensional logging data into two-dimensional images. GAF can better capture the nonlinear structure and patterns in time series data by using trigonometric transformation. After that, we used the Swin Transformer model to classify the converted images. It captures the locality and timing of the image by moving the window. Swin Transformer uses a staged attention mechanism that allows the model to efficiently capture feature information at different scales. This allows the model to capture both local and global information in the image, contributing to a better understanding of the image content. The multi-scale feature capture capability of the Swin Transformer enables it to effectively capture different scales and spatial relationships in fluid prediction tasks. Tested in real data from Tarim Oilfield, the GAF-Swin Transformer model has better performance than other machine learning models. This study provides a new perspective in the field of fluid prediction.","2024-01","2025-02-26 20:37:04","2025-02-26 20:37:04","","","","1","36","","","","","","","","","","English","","","","WOS:001145847500004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZH2YMCTK","journalArticle","2021","Ohri, A; Schmah, T","Machine Translation of Mathematical Text","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2021.3063715","","We have implemented a machine translation system, the PolyMath Translator, for LaTeX documents containing mathematical text. The current implementation translates English LaTeX to French LaTeX, attaining a BLEU score of 53.6 on a held-out test corpus of mathematical sentences. It produces LaTeX documents that can be compiled to PDF without further editing. The system first converts the body of an input LaTeX document into English sentences containing math tokens, using the pandoc universal document converter to parse LaTeX input. We have trained a Transformer-based translator model, using OpenNMT, on a combined corpus containing a small proportion of domain-specific sentences. Our full system uses this Transformer model and also Google Translate with a custom glossary, the latter being used as a backup to better handle linguistic features that do not appear in our training dataset. Google Translate is used when the Transformer model does not have confidence in its translation, as determined by a high perplexity score. Ablation testing demonstrates that the tokenization of symbolic expressions is essential to the high quality of translations produced by our system. We have published our test corpus of mathematical text. The PolyMath Translator is available as a web service at http://www.polymathtrans.ai.","2021","2025-02-26 20:37:04","2025-02-26 20:37:04","","38078-38086","","","9","","","","","","","","","","English","","","","WOS:000628905000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Electronic publishing; Encyclopedias; Internet; LaTeX; Machine translation; multi-layer neural network; natural language processing; Terminology; Training; Vocabulary","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8DV3B9XU","journalArticle","2024","Xia, LL; Wang, RQ; Ye, HM; Jiang, BC; Li, G; Ma, C; Gao, ZK","Hybrid LSTM-Transformer Model for the Prediction of Epileptic Seizure Using Scalp EEG","IEEE SENSORS JOURNAL","","1530-437X","10.1109/JSEN.2024.3401771","","Epilepsy is a recurrent neurological disorder, and nearly 30% of patients with epilepsy continue to experience symptoms despite taking anti-epileptic drugs. Predicting epileptic seizures enables patients to proactively take preventive measures against potential harm. Higher accuracy (ACC) of seizure prediction would lead to a reduced incidence rate and decreased labor and resource consumption. In this study, we propose a hybrid long short-term memory (LSTM)-Transformer model for predicting epileptic seizures using scalp electroencephalogram (EEG) data. Time-frequency features are extracted through the short-time Fourier transform (STFT) applied to EEG signals, which are then inputted into the model to distinguish the interictal state and the preictal state. Our approach combines the long-distance dependence capability of the Transformer with the advantages of LSTM in processing variable-length information, resulting in more robust and informative feature extraction. We evaluate our proposed method on the Children's Hospital Boston-MIT (CHB-MIT) dataset and conduct quantitative comparisons with recent methods. The results demonstrate that our method achieves a sensitivity of 99.75%, a false prediction rate (FPR) of 0/h, and an area under the curve (AUC) of 99.39%. This novel approach provides valuable insights for epilepsy prediction.","2024-07-01","2025-02-26 20:37:05","2025-02-26 20:37:05","","21123-21131","","13","24","","","","","","","","","","English","","","","WOS:001280328400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","CONVOLUTIONAL NEURAL-NETWORKS; Deep learning; electroencephalogram (EEG); long short-term memory (LSTM)-Transformer; seizure prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BVGCG3KP","journalArticle","2023","Li, D; Tan, Y; Zhang, YH; Miao, SW; He, S","Probabilistic forecasting method for mid-term hourly load time series based on an improved temporal fusion transformer model","INTERNATIONAL JOURNAL OF ELECTRICAL POWER & ENERGY SYSTEMS","","0142-0615","10.1016/j.ijepes.2022.108743","","The growth of distributed renewable energy and demand-side responsiveness has increased the difficulty of midterm hourly load time-series forecasting. This study presents a probabilistic forecasting method for hourly load time series based on an improved temporal fusion transformer (ITFT) model to achieve more accurate and thorough forecasting results. The raw univariate time series of the hourly load was reconstructed into multiple day-to-day load time series at different hour-points to reconcile the contradiction between learning the temporal dependence on a long prediction horizon and reducing model complexity. The corresponding hour point was used as a static covariable input to distinguish the differences. Based on the original temporal fusion transformer (TFT) model, the ITFT model replaces the long short-term memory (LSTM) with a gated recurrent unit (GRU) to learn long-term dependence more efficiently. Furthermore, quantile constraints and prediction interval (PI) penalty terms were incorporated into the original quantile loss function to prevent quantile crossover and construct more compact prediction intervals (PIs). The results of two actual examples show that the proposed method is explanatory and can significantly improve the reliability and compactness of probabilistic load forecasting (PLF) results compared with other popular methods.","2023-03","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","146","","","","","","","","","","English","","","","WOS:000918661300003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;30<br/>Total Times Cited:&nbsp;&nbsp;30<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Mid-term load forecasting; NETWORK; Probabilistic forecasting; Quantile prediction; QUANTILE REGRESSION; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3MRP64I3","journalArticle","2024","Honarjoo, A; Darvishan, E; Rezazadeh, H; Kosarieh, AH","Damage detection and localization of structural cracks based on dynamic attention based transformer","INTERNATIONAL JOURNAL OF BUILDING PATHOLOGY AND ADAPTATION","","2398-4708","10.1108/IJBPA-06-2024-0128","","PurposeThis article addresses the need for a comprehensive model for structural crack detection in the context of structural health monitoring. The main innovation of this research is the introduction of a dynamic attention-based transformer model that significantly enhances the accuracy and efficiency of detecting and localizing cracks in structures. This study seeks to overcome previous limitations and contribute to advancements in structural health monitoring practices.Design/methodology/approachThe research focuses on three primary computer vision tasks: classification, object detection and semantic segmentation applied to crack detection in concrete, brick and asphalt structures. The proposed approach employs transformer encoders with dynamic attention mechanisms to assess the severity and extent of damage accurately.FindingsIn this study, we propose a dynamic attention-based transformer model for structural crack detection, achieving a remarkable accuracy of 99.38% and an impressive F1 score. Our method demonstrates superior performance compared to existing techniques, such as the fusion features-based broad learning system and deep convolutional neural networks, while also significantly reducing execution time, highlighting its efficiency and potential for practical applications in structural health monitoring.Originality/valueThis research introduces a novel framework for crack detection, leveraging recent advancements in deep learning technology, with significant implications for the field of civil engineering and maintenance.","2024-12-20","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","","","","","","","","","","","English","","","","WOS:001380501100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Attentive vision transformer; Damage detection; Deep learning; Structural cracks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CK5DCV28","journalArticle","2023","Jiang, WJ; Zhang, DQ; Hu, G; Wu, TT; Liu, LB; Xiao, YQ; Duan, ZD","Transformer-based tropical cyclone track and intensity forecasting","JOURNAL OF WIND ENGINEERING AND INDUSTRIAL AERODYNAMICS","","0167-6105","10.1016/j.jweia.2023.105440","","Tropical cyclone (TC) is one of the most destructive natural disasters, and hence it is very crucial to predict attributes of TC accurately. In this paper, a transformer-based method for short-term prediction of the track and intensity of TCs, including the central latitude, the central longitude, the minimum sea level pressure and the maximum sustained wind speed, in the Northwest Pacific Basin is proposed. The data set used in this study ranging from 1980 to 2021 was released by China Meteorological Administration (CMA). A data preprocessing step including feature augmentation is adopted, which can make full use of the historical information of TCs. The transformer networks can model the complex dynamic relationships between the time series data and dig the relationship between different attributes based on the multi-head self-attention mechanism. The transformer-based method proposed in this study exhibits excellent performance in the prediction task. Meanwhile, compared to the traditional recurrent neural network models including gated recurrent units model and long short-term memory model, the transformer model has a better performance in predicting all attributes. This method provides a practical guidance of using advanced AI-based approaches to predict TC attributes.","2023-07","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","238","","","","","","","","","","English","","","","WOS:001002559400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;21<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","AI-based approaches; MODEL; PREDICTION; Short-term prediction; Track and intensity; Transformer model; Tropical cyclone","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T2K9YXXR","journalArticle","2024","Chen, N; Liu, Z; Le, DX; Lai, QR; Jiang, BN; Li, B; Wu, J; Song, YF; Liu, YD","Detection of jelly orange granulation disease using a dual-input Resnet-Transformer model (DresT) based on acoustic vibration images and a novel acoustic vibration device","JOURNAL OF FOOD COMPOSITION AND ANALYSIS","","0889-1575","10.1016/j.jfca.2024.106337","","Granulation is a common internal disease in citrus fruits, and it is difficult to distinguish fruits with granulation disease from their appearance. In this study, a novel acoustic vibration device based on a micro-LDV, a microphone and a resonance speaker was employed to collect acoustic vibration response signals of ""Aiyuan 38"" jelly orange. The one-dimensional acoustic vibration response signal was converted into acoustic vibration images, and a double-input Resnet-Transformer network (DresT) was constructed for extracting deep features in acoustic vibration images for identifying jelly-orange granulation disease. Firstly, train Drest and Resnet50 models using acoustic vibration images and compare the performance of Drest with that of Resnet50 (based on CNN). Then PLS-DA and SVM models are trained using acoustic vibration image texture features or acoustic vibration spectral features, and the performance is compared with the DresT model. The results showed that the DresT model trained using acoustic vibration images can accurately identify jelly orange granulation disease with a detection accuracy of 99.31 %. The F1 of the model is 99.5 %, the accuracy is 99.01 %, and the recall is 100 %.","2024-08","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","132","","","","","","","","","","English","","","","WOS:001325505800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Acoustic vibration; Dual-input Resnet-Transformer model; FAULT-DIAGNOSIS; Granulation; IDENTIFICATION; Non-destructive detection; Orange","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FG7QT7YU","journalArticle","2024","Song, R; Xu, RS; Festag, A; Ma, JQ; Knoll, A","FedBEVT: Federated Learning Birds Eye View Perception Transformer in Road Traffic Systems","IEEE TRANSACTIONS ON INTELLIGENT VEHICLES","","2379-8858","10.1109/TIV.2023.3310674","","Bird's eye view (BEV) perception is becoming increasingly important in the field of autonomous driving. It uses multi-view camera data to learn a transformer model that directly projects the perception of the road environment onto the BEV perspective. However, training a transformer model often requires a large amount of data, and as camera data for road traffic are often private, they are typically not shared. Federated learning offers a solution that enables clients to collaborate and train models without exchanging data butmodel parameters. In this article, we introduce FedBEVT, a federated transformer learning approach for BEV perception. In order to address two common data heterogeneity issues in FedBEVT: (i) diverse sensor poses, and (ii) varying sensor numbers in perception systems, we propose two approaches - Federated Learning with Camera-Attentive Personalization (FedCaP) and Adaptive Multi-Camera Masking (AMCM), respectively. To evaluate our method in real-world settings, we create a dataset consisting of four typical federated use cases. Our findings suggest that FedBEVT outperforms the baseline approaches in all four use cases, demonstrating the potential of our approach for improving BEV perception in autonomous driving.","2024-01","2025-02-26 20:37:05","2025-02-26 20:37:05","","958-969","","1","9","","","","","","","","","","English","","","","WOS:001173317800086","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","bird's eye view; BLOCKCHAIN; Cameras; cooperative intelligent transportation systems; Data models; Federated learning; road environmental perception; Road traffic; Task analysis; Training; Transformers; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4FJRP5TR","journalArticle","2023","Chen, YL; Yi, HA; Liao, C; Lu, LL; Niu, YL","Roughness classification detection of Swin-Transformer model based on the multi-angle and convertible image environment","NONDESTRUCTIVE TESTING AND EVALUATION","","1058-9759","10.1080/10589759.2023.2178651","","Current machine vision methods for surface measurement rely excessively on feature design to quantify surface morphology and build predictive models, but metric design suffers from human intervention, and data acquisition is heavily dependent on light source environment and shooting angle. This paper uses the Swin-Transformer model to evaluate and classify roughness directly on colour images of milled samples acquired in a convertible image environment. The images used in the experiment are taken in a completely dark environment and in an environment disturbed by light sources, such as LED energy-saving lamps during the day. By using two kinds of lenses and combining custom light sources and ordinary light sources, respectively, and for different angles, it deeply simulates the environment of online inspection of industrial production. The roughness classification results prove that the method has very good robustness to light source environment and shooting angle, avoiding the artificial design and extraction of image features. The accuracy of the validation set of samples can reach 98.94%, while the accuracy of the test set can reach 97.54%. To wrap it up, the method provides an optimised strategy for visual roughness measurement in industrial production.","2023-05-04","2025-02-26 20:37:05","2025-02-26 20:37:05","","394-411","","3","38","","","","","","","","","","English","","","","WOS:000935791100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","Classification; Imaging environment; Online Inspection; Roughness; SURFACE-ROUGHNESS; Swin-transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"36MVNP7A","journalArticle","2024","Peng, XH; Xu, CC; Zhang, P; Fu, DD; Chen, Y; Hu, ZG","Computer vision classification detection of chicken parts based on optimized Swin-Transformer","CYTA-JOURNAL OF FOOD","","1947-6337","10.1080/19476337.2024.2347480","","In order to achieve real-time classification and detection of various chicken parts, this study introduces an optimized Swin-Transformer method for the classification and detection of multiple chicken parts. It initially leverages the Transformer's self-attention structure to capture more comprehensive high-level visual semantic information from chicken part images. The image enhancement technique was applied to the image in the preprocessing stage to enhance the feature information of the image, and the migration learning method was used to train and optimize the Swin-Transformer model on the enhanced chicken parts dataset for classification and detection of chicken parts. Furthermore, this model was compared to four commonly used models in object target detection tasks: YOLOV3-Darknet53, YOLOV3-MobileNetv3, SSD-MobileNetv3, and SSD-VGG16. The results indicated that the Swin-Transformer model outperforms these models with a higher mAP value by 1.62%, 2.13%, 5.26%, and 4.48%, accompanied by a reduction in detection time by 16.18 ms, 5.08 ms, 9.38 ms, and 23.48 ms, respectively. The method of this study fulfills the production line requirements while exhibiting superior performance and greater robustness compared to existing conventional methods.","2024-12-31","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","1","22","","","","","","","","","","English","","","","WOS:001217451200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Chicken parts; classification detection; comparison test; deep learning; Swin-Transformer; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3X9ZGTZV","journalArticle","2024","Wang, XT; Wang, Y; Guo, ZC; Wang, D; Dai, Y; Zhao, DY","Sawing Model and Optimization of Single Pass Crosscut Parameters for Pinus kesiya Based on the Transformer Model","FORESTS","","1999-4907","10.3390/f15122144","","The optimization of the sawing process for Pinus kesiya Royle ex Gordon, an important timber used in construction and furniture, especially through the adjustment of parameters such as wood moisture content, cutting speed, and feed speed, not only helps reduce energy consumption and noise but also improves surface processing quality, thereby promoting green and environmentally friendly production. Therefore, this study selects the wood moisture content, cutting speed, and feed speed during the Single Pass Crosscut process of Pinus kesiya as the preliminary experimental parameters. Based on the Transformer model, a cutting prediction model for Pinus kesiya is established to predict three cutting performance indicators: cutting power consumption, surface roughness, and cutting noise. Meanwhile, Bayesian optimization was used to search for the optimal parameter combination within the specified cutting process parameter ranges that minimizes the objective function for these cutting performance indicators. Finally, experimental verification based on the optimal parameter combination shows that the average coefficient of determination for the cutting performance indicators is 0.937, the average mean squared error is 0.076, and the average mean absolute error is 0.186, indicating good agreement between the predicted and measured values.","2024-12","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","12","15","","","","","","","","","","English","","","","WOS:001384343800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","CUTTING CONDITIONS; MOISTURE-CONTENT; Pinus kesiya; power consumption; QUALITY; sawing noise; sawing parameters; surface roughness; transformer neural network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HHRES94L","journalArticle","2025","Shi, T; Shide, K","A comparative analysis of LSTM, GRU, and Transformer models for construction cost prediction with multidimensional feature integration","JOURNAL OF ASIAN ARCHITECTURE AND BUILDING ENGINEERING","","1346-7581","10.1080/13467581.2025.2455034","","Construction cost prediction remains a complex challenge due to the multidimensional nature of construction data and external factors. The objective of this study is to identify the most effective deep learning model for accurately predicting construction costs by comparing the performance of LSTM, GRU, and Transformer models. Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), and Transformer are advanced machine learning regression models widely utilized for data prediction tasks. This study investigates these models' performance for construction cost prediction using a multidimensional feature framework. Through comprehensive evaluation and comparison, the Transformer model demonstrated superior performance, particularly excelling in handling complex feature interactions and long-sequence data. The LSTM model, while effective in capturing temporal dependencies, shows reliable performance but lags behind the Transformer in accuracy. The GRU model, although faster in training, proved less accurate and is less effective in handling outliers. Key features such as Total Area (TA), Site Area (SA), and Number of Floors (NF) were identified as significant predictors across all models, with the Transformer model proving particularly adept at capturing complex interactions. By integrating these features, this study contributes to improved cost management, thereby enhancing prediction accuracy and reliability.","2025-01-20","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","","","","","","","","","","","English","","","","WOS:001398984500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","Construction cost; cost management; cost prediction; deep learning; multidimensional feature integration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9FSLQ42X","journalArticle","2024","Liu, YZ; Han, LM; Yao, B; Li, Q","STA-Former: enhancing medical image segmentation with Shrinkage Triplet Attention in a hybrid CNN-Transformer model","SIGNAL IMAGE AND VIDEO PROCESSING","","1863-1703","10.1007/s11760-023-02893-5","","Convolutional neural networks (CNNs) have found extensive use in medical image segmentation tasks. However, they encounter limitations in capturing long-range semantic interactions. Conversely, Transformers excel at handling long-range dependencies but struggle to preserve local semantic details. To address this challenge, we propose STA-Former, a hybrid CNN-Transformer model for medical image segmentation. Our approach is founded on three fundamental principles: (1) We propose the Shrinkage Triplet Attention (STA) module to enhance feature fusion within the decoder. It focuses on spatial and channel interactions in the feature map, computes thresholds across dimensions, and suppresses irrelevant information through soft-thresholding. (2) We present a redesigned hierarchical hybrid CNN-Transformer encoder that connects CNN and Transformer blocks at multiple scales, enabling the capture of both long-range and short-range dependencies across various scales of feature maps. (3) Unlike traditional decoders that apply the attention mechanism exclusively to low-level features, our approach utilizes a multiscale attention hierarchical decoder, leveraging feature map correlations at different scales for effective feature fusion. Our method exhibits superior performance compared to the state-of-the-art methods on three datasets: Synapse multiorgan CT, ACDC cardiac MRI scans, and breast ultrasound image.","2024-03","2025-02-26 20:37:05","2025-02-26 20:37:05","","1901-1910","","2","18","","","","","","","","","","English","","","","WOS:001122645800004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","CONVOLUTION; Convolutional neural networks; Hybrid CNN-Transformer models; Medical image segmentation; Multiscale features fusion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MQY58DIM","journalArticle","2024","Hu, YK; Lyu, L; Wang, N; Zhou, XL; Fang, M","Long-term prediction of multiple river water quality indexes based on hybrid deep learning models","MEASUREMENT SCIENCE AND TECHNOLOGY","","0957-0233","10.1088/1361-6501/ad774e","","Rivers are an important part of the natural water cycle, but they are facing serious pollution problems due to a variety of human activities. Long-term prediction of river water quality indexes (WQI) is important for the protection of river water environment. Currently, data-driven deep learning models are effective in the task of long-term prediction of WQI, especially the transformer structure-based models have achieved advanced prediction results on a variety of water quality datasets. However, the high computational complexity of transformer models and their insensitivity to anomalous data have limited the application of the models. In this study, we propose a channel independent linear transformer model that has higher prediction accuracy and computational efficiency than the transformer model. We conducted long-term predictions of two WQI, dissolved oxygen and chlorophyll concentration, in the Liaohe River Basin and compared them with a variety of different advanced models. The experimental results show that our model has the best prediction results among all comparative models, and the proposed method for long-term prediction of river WQI provides effective technical support for the establishment of a river water environment monitoring system.","2024-12-01","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","12","35","","","","","","","","","","English","","","","WOS:001311895300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","AQUACULTURE; long-term prediction; time series forecasting; transformer; TRANSFORMER; water quality indexes","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K3UQSME8","journalArticle","2024","Tseng, SM; Wang, YQ; Wang, YC","Multi-Class Intrusion Detection Based on Transformer for IoT Networks Using CIC-IoT-2023 Dataset","FUTURE INTERNET","","1999-5903","10.3390/fi16080284","","This study uses deep learning methods to explore the Internet of Things (IoT) network intrusion detection method based on the CIC-IoT-2023 dataset. This dataset contains extensive data on real-life IoT environments. Based on this, this study proposes an effective intrusion detection method. Apply seven deep learning models, including Transformer, to analyze network traffic characteristics and identify abnormal behavior and potential intrusions through binary and multivariate classifications. Compared with other papers, we not only use a Transformer model, but we also consider the model's performance in the multi-class classification. Although the accuracy of the Transformer model used in the binary classification is lower than that of DNN and CNN + LSTM hybrid models, it achieves better results in the multi-class classification. The accuracy of binary classification of our model is 0.74% higher than that of papers that also use Transformer on TON-IOT. In the multi-class classification, our best-performing model combination is Transformer, which reaches 99.40% accuracy. Its accuracy is 3.8%, 0.65%, and 0.29% higher than the 95.60%, 98.75%, and 99.11% figures recorded in papers using the same dataset, respectively.","2024-08","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","8","16","","","","","","","","","","English","","","","WOS:001305196600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;17</p>","","","CIC-IoT-202; deep learning; Internet of Things; intrusion detection; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V9JFHCXH","journalArticle","2022","Vural, E; Hanci-Azizoglu, EB","A Linguistic Analysis Study for Teaching American-English Pronunciation: A Case Study Research","JOURNAL OF LANGUAGE AND CULTURAL EDUCATION","","1339-4045","10.2478/jolace-2022-0007","","This linguistic case study research investigates the process stages of a language learner's pronunciation errors through speech analysis detection techniques. The purpose of this study is to detect and analyze the pronunciation errors for internalizing the unique and individual pronunciation error patterns that vary from one individual to the next. A speech analysis technique, a method of applied linguistics, is used in combination with the case study method reveals a thorough evaluation map for the language learner's pronunciation error characteristics. In this case study, the participant of the study is a native Chinese speaker. Within the scope of this research study, both the theoretical literature review and the data collection process uncover that pronunciation, unlike other domains of language teaching areas, requires specific and individualized attention for effective teaching and learning strategies. The data collected in this research study is analyzed in terms of phonetic linguistic features, and a personalized pronunciation improvement plan is proposed based on the linguistic features and characteristics of the research participant's errors. A larger scale research study can be conducted for future research by verifying the findings of this research study with more language-specific research participants in order to develop individualized and learning-style focused pronunciation lesson plans for larger learning groups.","2022-07-01","2025-02-26 20:37:05","2025-02-26 20:37:05","","1-19","","2","10","","","","","","","","","","English","","","","WOS:000941614700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","English language pronunciation; individualized pronunciation education; INSTRUCTION; Phonetic linguistic features; Pronunciation errors; Speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A2VEKSPK","journalArticle","2023","Shao, QQ; Fan, SH","Parameter measurement of cable lead sealing using an eddy current system","INSIGHT","","1354-2575","10.1784/insi.2023.65.6.306","","Lead sealing is one of the key accessories for high-voltage cables and its quality directly affects the security and stability of such cables. In order to reduce the accident rate in power processing caused by lead sealing issues, it is necessary to carry out non-destructive testing and evaluation. Due to the bending surface of lead sealings, it is difficult to detect their conductivity and thickness accurately using existing eddy current (EC) testing methods. In this paper, measurements of conductivity and thickness for curved specimens are analysed and an accurate method is subsequently proposed. Firstly, the measurement methods of conductivity and thickness are established based on the transformer model. It is found that the conductivity and thickness can be detected using phase signature at high and low frequencies, respectively. Secondly, the influence of curvature on the phase signature is analysed and the conductivity and thickness measurements of lead sealing are corrected using curvature correction coefficients. Finally, an EC system is built and experiments are carried out to evaluate the novel methods. The results show that the methods achieve a good level of accuracy in detecting the conductivity and thickness of curved lead sealings.","2023-06","2025-02-26 20:37:05","2025-02-26 20:37:05","","306-312","","6","65","","","","","","","","","","English","","","","WOS:001021727300005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","cable lead sealing; conductivity; curvature; detecting system; eddy current; PROBE; thickness; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5LR6EGSE","journalArticle","2022","Xiao, SG; Fu, WP","Optimizing Continuous Prompts for Visual Relationship Detection by Affix-Tuning","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3187263","","Visual relationship detection is crucial for understanding visual scenes and is widely used in many areas, including visual navigation, visual question answering, and machine trouble detection. Traditional detection methods often fuse multiple region modules, which takes considerable time and resources to train every module with extensive samples. As every module is independent, the computation process has difficulty achieving unity and lacks a higher level of logical reasonability. In response to the above problems, we propose a novel method of affix-tuning transformers for visual relationship detection tasks, which keeps transformer model parameters frozen and optimizes a small continuous task-specific vector. It not only makes the model unified and reduces the training cost but also maintains the common-sense reasonability without multiscale training. In addition, we design a vision-and-language sentence expression prompt template and train a few transformer model parameters for downstream tasks. Our method, Prompt Template and Affix-Tuning Transformers (PTAT), is evaluated on visual relationship detection and Visual Genome datasets. Finally, the results of the proposed method are close to or even higher than those of the state-of-the-art methods on some evaluation metrics.","2022","2025-02-26 20:37:05","2025-02-26 20:37:05","","70104-70112","","","10","","","","","","","","","","English","","","","WOS:000838446900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","affix-tuning transformers; Licenses; prompt template; Semantics; Task analysis; Training; Training data; Transformers; Visual relationship detection; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X4JJ79UJ","journalArticle","2023","Bhushan, P; Raj, K; Hota, S; Mishra, D; Raut, A; Mohanty, AK","A Study on Speech Analysis in Acquired Maxillary Defect Patients Treated with Maxillary Obturator","JOURNAL OF PHARMACY AND BIOALLIED SCIENCES","","0976-4879","10.4103/jpbs.jpbs_642_22","","Aim: The aim of the present study was to assess the speech analysis in acquired maxillary defect patients treated with maxillary obturator. Materials and Methods: Total of 16 patients were considered in the study. The age group of these patients ranged from 40 to 75 years with a mean age of 59.5 years, irrespective of their gender. The surgical obturator was fabricated using self-cure acrylic. The surgical obturator was delivered immediately after surgery. After a healing period of about 2 weeks, the surgical obturator was replaced by an interim prosthesis. This was processed with the help of heat-cure polymethylmethacrylate. The total number of patients was divided into two groups, namely, (A) Definitive obturator group and (B) Interim obturator group. The speech intelligibility (SI), was analyzed. Results: The mean scores for SI before prosthesis in definitive and interim groups were 19.13 +/- 3.22 and 19.87 +/- 1.72, respectively. This was increased after prosthesis insertion to 24.38 +/- 1.30 and 22.37 +/- 1.18, which further increased after adaptation period of 2 months to 28.75 +/- 1.28 and 24.62 +/- 1.59 in two groups. Conclusion: The present study concluded that speech was severely affected by maxillary resection and that rehabilitation with maxillary obturator was successful in restoring these aspects of speech.","2023-07","2025-02-26 20:37:05","2025-02-26 20:37:05","","S467-S470","","","15","","","","","","","","","","English","","","","WOS:001043189100098","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;10</p>","","","INTELLIGIBILITY; MAXILLECTOMY; Nasalance; obturator; PROSTHETIC OBTURATION; speech analysis; speech intelligibility","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QSJ8VHZA","journalArticle","2021","Marini, M; Vanello, N; Fanucci, L","Optimising Speaker-Dependent Feature Extraction Parameters to Improve Automatic Speech Recognition Performance for People with Dysarthria","SENSORS","","1424-8220","10.3390/s21196460","","Within the field of Automatic Speech Recognition (ASR) systems, facing impaired speech is a big challenge because standard approaches are ineffective in the presence of dysarthria. The first aim of our work is to confirm the effectiveness of a new speech analysis technique for speakers with dysarthria. This new approach exploits the fine-tuning of the size and shift parameters of the spectral analysis window used to compute the initial short-time Fourier transform, to improve the performance of a speaker-dependent ASR system. The second aim is to define if there exists a correlation among the speaker's voice features and the optimal window and shift parameters that minimises the error of an ASR system, for that specific speaker. For our experiments, we used both impaired and unimpaired Italian speech. Specifically, we used 30 speakers with dysarthria from the IDEA database and 10 professional speakers from the CLIPS database. Both databases are freely available. The results confirm that, if a standard ASR system performs poorly with a speaker with dysarthria, it can be improved by using the new speech analysis. Otherwise, the new approach is ineffective in cases of unimpaired and low impaired speech. Furthermore, there exists a correlation between some speaker's voice features and their optimal parameters.","2021-10","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","19","21","","","","","","","","","","English","","","","WOS:000708043600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","automatic speech recognition; dysarthria; genetic algorithm; kaldi; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3ZYNP9MJ","journalArticle","2024","Wong, M; Choi, K; Barak, L; Lapidow, E; Austin, J; Shafto, P; Bonawitz, E","Young Children's Directed Question Asking in Preschool Classrooms","BEHAVIORAL SCIENCES","","2076-328X","10.3390/bs14090754","","Question asking is a prevalent aspect of children's speech, providing a means by which young learners can rapidly gain information about the world. Previous research has demonstrated that children exhibit sensitivity to the knowledge state of potential informants in laboratory settings. However, it remains unclear whether and how young children are inclined to direct questions that support learning deeper content to more knowledgeable informants in naturalistic classroom contexts. In this study, we examined children's question-asking targets (adults, other preschoolers, self-talk) during an open-play period in a US preschool classroom and assessed how the cognitive and linguistic characteristics of questions varied as a function of the intended recipient. Further, we examined how these patterns changed with age. We recorded the spontaneous speech of individual children between the ages of 3 and 6 years (N = 30, totaling 2875 utterances) in 40-min open-period sessions in their preschool day, noting whether the speech was directed toward an adult, another child, or was stated to self. We publish this fully transcribed database with contextual and linguistic details coded as open access to all future researchers. We found that questions accounted for a greater proportion of preschoolers' adult-directed speech than of their child-directed and self-directed speech, with a particular increase in questions that supported broader learning goals when directed to an adult. Younger children directed a higher proportion of learning questions to adults than themselves, whereas older children asked similar proportions of questions to both, suggesting a difference in younger and older children's question-asking strategies. Although children used greater lexical diversity in questions than in other utterances, their question formulation in terms of length and diversity remained consistent across age and recipient types, reflecting their general linguistic abilities. Our findings reveal that children discriminately choose ""what"" and ""whom"" to ask in daily spontaneous conversations. Even in less-structured school contexts, preschoolers direct questions to the informant most likely to be able to provide an adequate answer.","2024-09","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","9","14","","","","","","","","","","English","","","","WOS:001323458600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","classroom observation; EXPLANATIONS; IGNORANT; INFORMATION; KNOWLEDGE; MECHANISM; MONITOR; preschoolers; question asking; social environments; spontaneous speech; TRUST","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9SVQD2B5","journalArticle","2022","Golub, G; Zoric, AV","FILLER WORDS IN MEDIA SPEECH","FLUMINENSIA","","0353-4642","10.31820/f.34.2.5","","In most of the grammar books filler words have a marginal position. Nevertheless, they are an important source of information for many aspects of linguistic performance. The purpose of this paper was to investigate some of these aspects in more detail, i.e., the use of filler words depending on the speech style in the media, on gender, as well as to get a better insight into speech planning during speech production. The investigation includes the analysis of the frequency of filler words in spontaneous speech in Croatian in formal and entertaining TV shows. In addition, the analysis includes the position of filler words in the utterance, their lexical category, and their distribution according to sex. The analysed speech corpus consists of oneminute recordings of 40 speakers in live broadcasts of public television, which are equalized according to gender and type of show. The results show that some filler words are used by all speakers, although their frequency varies significantly between speakers. Furthermore, filler words are much more often used in entertaining shows than in formal shows, which can be explained by the different communication strategies of the speakers in these two types of shows. In addition, filler words are significantly more frequent at the beginning of the utterance as compared to the middle and the end of the utterance, which supports the thesis that the beginning of the utterance is the place with the highest cognitive load in speech production. There is no difference in the total number of filler words between the sexes, but men use filler words at the end of the utterance more often than women. As far as parts of speech are concerned, filler words are most frequently verbs, followed by adverbs and pronouns. The most frequent filler words in the analysed corpus are Croatian expressions: ono (that), pa (well), ovaj (this), zapravo (actually) and dakle (so), and besides these collective filler words, speakers also use individual fillers, typical for individuals or smaller social groups.","2022","2025-02-26 20:37:05","2025-02-26 20:37:05","","367-396","","2","34","","","","","","","","","","English","","","","WOS:000974872600005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","AGE; disfluencies; filler words; HESITATION; media speech; speech production; spontaneous speech; UH; UM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZNTXYHWI","journalArticle","2022","Lofgren, M; Hinzen, W","Breaking the flow of thought: Increase of empty pauses in the connected speech of people with mild and moderate Alzheimer's disease","JOURNAL OF COMMUNICATION DISORDERS","","0021-9924","10.1016/j.jcomdis.2022.106214","","Introduction: The profile of spontaneous speech in Alzheimer's disease (AD) includes increased pausing as a window into cognitive decline. We here aimed to further characterize the pausing profile of AD by linking pauses to the syntactic positions in which they appear and disease progression. Methods: Speech was obtained through a picture description task, thus minimizing demands on episodic memory (EM), from a group of mild (N = 21) and moderate AD (N = 19), and healthy elderly controls (N = 40). Pauses were sub-indexed according to whether they occurred within-clauses, clause-initially, or utterance-initially, and whether they preceded nouns, verbs, or adjectives/adverbs, when occurring within-clauses. Additionally, relations to verbal fluency (VF) measures at the single-word level were explored. Results: Pause rate but not duration distinguished controls from both AD groups, while fillers did not distinguish any groups. The analysis by syntactic position revealed a highly differentiated picture, with largest effect sizes of significant group differences seen in the utterance-initial pause rate. The two AD groups patterned differently when compared to controls, while none of the measures differentiated the AD groups. Specifically, moderate but not mild AD differed from controls in clause-initial pauses, while mild but not moderate AD differed from controls in within-clause positions. At the within-clause level, the effect dividing controls from mild-AD was specifically driven by pauses ahead of nouns. A significant negative correlation emerged between pausing rate in spontaneous speech and VF measures in the mild-AD group only. Conclusions: Increased empty (non-filled) pauses in AD are not confined to pauses in within-clause positions, which are most directly related to problems in the retrieval of words. Even in early disease stages, where these within-clause pause effects are seen, they are confined to nouns, revealing a grammatically specific problem possibly related to the referencing of objects. At all disease stages, pauses increase in utterance-sized units of structure, indicating progressive problems in the creative configuration of complete thoughts.","2022-05","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","97","","","","","","","","","","English","","","","WOS:000819917100005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","DEMENTIA; EMBEDDED CLAUSES; MEMORY IMPAIRMENT; SYNTACTIC COMPLEXITY; VERBAL FLUENCY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C8Y6XHED","journalArticle","2021","Nasreen, S; Rohanian, M; Hough, J; Purver, M","Alzheimer's Dementia Recognition From Spontaneous Speech Using Disfluency and Interactional Features","FRONTIERS IN COMPUTER SCIENCE","","2624-9898","10.3389/fcomp.2021.640669","","Alzheimer's disease (AD) is a progressive, neurodegenerative disorder mainly characterized by memory loss with deficits in other cognitive domains, including language, visuospatial abilities, and changes in behavior. Detecting diagnostic biomarkers that are noninvasive and cost-effective is of great value not only for clinical assessments and diagnostics but also for research purposes. Several previous studies have investigated AD diagnosis via the acoustic, lexical, syntactic, and semantic aspects of speech and language. Other studies include approaches from conversation analysis that look at more interactional aspects, showing that disfluencies such as fillers and repairs, and purely nonverbal features such as inter-speaker silence, can be key features of AD conversations. These kinds of features, if useful for diagnosis, may have many advantages: They are simple to extract and relatively language-, topic-, and task-independent. This study aims to quantify the role and contribution of these features of interaction structure in predicting whether a dialogue participant has AD. We used a subset of the Carolinas Conversation Collection dataset of patients with AD at moderate stage within the age range 60-89 and similar-aged non-AD patients with other health conditions. Our feature analysis comprised two sets: disfluency features, including indicators such as self-repairs and fillers, and interactional features, including overlaps, turn-taking behavior, and distributions of different types of silence both within patient speech and between patient and interviewer speech. Statistical analysis showed significant differences between AD and non-AD groups for several disfluency features (edit terms, verbatim repeats, and substitutions) and interactional features (lapses, gaps, attributable silences, turn switches per minute, standardized phonation time, and turn length). For the classification of AD patient conversations vs. non-AD patient conversations, we achieved 83% accuracy with disfluency features, 83% accuracy with interactional features, and an overall accuracy of 90% when combining both feature sets using support vector machine classifiers. The discriminative power of these features, perhaps combined with more conventional linguistic features, therefore shows potential for integration into noninvasive clinical assessments for AD at advanced stages.","2021-06-18","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","3","","","","","","","","","","English","","","","WOS:000671435600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","Alzheimer's disease; DIAGNOSIS; DISEASE; disfluency; FLUENCY; interaction; mental health monitoring; MILD COGNITIVE IMPAIRMENT; natural language processing; ORGANIZATION; REPAIR; spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AVE5UKJI","journalArticle","2021","Repiso-Puigdelliura, G","Empty onset repairs in the semi-spontaneous speech of Spanish child and adult heritage speakers","INTERNATIONAL JOURNAL OF BILINGUALISM","","1367-0069","10.1177/13670069211016547","","Aims: In this study I investigate whether child and adult Spanish heritage speakers (HS) use English-like strategies to repair word-external empty onsets preceded by consonants (e.g., el.#o.so 'the (male) bear'). That is, I examine whether HS produce glottal phonation at /C#V/ junctures. I also examine whether stress predicts the use of glottal phonation to repair word-external empty onsets. Design: Semi-spontaneous speech was elicited from a group of child HS (10 females (F), six males (M), mean age = 9.44 years, standard deviation (SD) = 0.69), adult HS (13 F, two M, mean age = 20.6 years, SD = 1.12), adult Spanish speakers in Mexico (six F, four M, mean age = 22.88 years, SD = 1.64), and long-term Mexican immigrants (seven F, two M, mean age = 45.16 years, SD = 9.49, mean age of arrival = 25.33 years, SD = 9.89). Data and analysis: Type of phonation (i.e., glottal or modal) was categorically coded and compared across groups and stress types. Acoustic measures, such as amplitude difference between the first two harmonic (H1*-H2*) and harmonics-to-noise ratio (HNR), were also analyzed to examine gradient group differences. Findings/conclusions: My findings show that child HS and adult HS present higher rates of glottal phonation than Spanish speakers in Mexico. The child HS, but not the adult HS, show higher rates of glottalization than those of long-term immigrants. Lastly, stressed syllables are more often glottalized than unstressed syllables. Originality: In this research I explore connected speech (i.e., word-external empty onsets), an understudied area in heritage language phonology. More specifically, this is the first study that examines empty onset repair strategies in both child and adult HS and analyzes the role of prosodic prominence. Significance and implications: I provide evidence for a greater pressure of the majority language during childhood than during adulthood. My results also show that divergent attainment in heritage language production is conditioned by quality of input.","2021-10","2025-02-26 20:37:05","2025-02-26 20:37:05","","1311-1326","","5","25","","","","","","","","","","English","","","","WOS:000654559400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;83</p>","","","empty onsets; ENGLISH-SPEAKING; GLOTTALIZATION; heritage language phonology; Heritage speakers; INCOMPLETE ACQUISITION; LANGUAGE; PHONOLOGICAL ACQUISITION; resyllabification; Spanish-English bilinguals; VOICE QUALITY; VOWELS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KBDX7WJB","journalArticle","2021","Frankenberg, C; Weiner, J; Knebel, M; Abulimiti, A; Toro, P; Herold, CJ; Schultz, T; Schröder, J","Verbal fl uency in normal aging and cognitive decline: Results of a longitudinal study","COMPUTER SPEECH AND LANGUAGE","","0885-2308","10.1016/j.csl.2021.101195","","Verbal fluency -i.e. the ability to name as many words of a given category as possible in a defined time interval -is an integral part of neuropsychological test batteries for the diagnosis of dementia. Verbal fluency can be easily administered and thus may also be implemented in computerized dementia screening tests. In the present study we sought to investigate the capability of phonemic verbal fluency as a potential predictor of cognitive decline and its associations with acoustic and lexical features directly inferred from recordings of spoken language. Data from 246 ILSE participants born in the years 1930 to 1932 were included. Subjects were investigated three times (t1-t3) over a period of more than 10 years by two board certified geriatric psychiatrists: the mean age of the sample was 62.77 at t1, 66.36 at t2, and 74.22 at t3. To evaluate the sensitivity of phonemic fluency performance on cognitive impairment, scores obtained at t1 and t2 were compared with repeated measures ANOVA between subjects who were cognitively intact and those who were diagnosed with mild cognitive impairment (MCI) or Alzheimer's dementia (AD) at t3. In addition, acoustic and lexical features of spoken language were extracted with automatic speech recognition from semi-structured autobiographical interviews recorded at baseline. Scores were correlated with verbal fluency performance at t1. In all analyzes education was considered as a covariate. Regarding verbal fluency obtained at t1 and t2, repeated measures ANOVA revealed significantly higher scores between subjects who were cognitively intact (HC) at t3 compared with those diagnosed with MCI or AD at t3. At baseline verbal fluency was significantly correlated with important acoustic features of spontaneous speech: word rate, phoneme rate, speech-duration and silence-to-word-ratio. Verbal fluency deficits were proven already in young old age and precede marked cognitive decline years before in a large group recruited from the general population. Verbal fluency is associated with acoustic rather than lexical features of spoken language which can directly be inferred from spontaneous speech. (c) 2021 Elsevier Ltd. All rights reserved.","2021-07","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","68","","","","","","","","","","English","","","","WOS:000633221700009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;20<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","ALZHEIMERS-DISEASE; CERAD; Cognitive reserve; DEMENTIA; FLUENCY; HEALTH; IMPAIRMENT; Language changes; Mild cognitive impairments; PERFORMANCE; SPEECH; Verbal fluency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V99ULRZD","journalArticle","2022","Song, XK; Lee, C; So, WC","Examining Phenotypical Heterogeneity in Language Abilities in Chinese-Speaking Children with Autism: A Naturalistic Sampling Approach","JOURNAL OF AUTISM AND DEVELOPMENTAL DISORDERS","","0162-3257","10.1007/s10803-021-05104-7","","Phenotypical heterogeneity in language abilities is a hallmark of autism but remains poorly understood. The present study collected naturalistic language samples from parent-child interactions. We quantified verbal abilities (mean length of utterance, tokens, types) of 50 Chinese-speaking children (M = 5; 6) and stratified subgroups based on their autism traits, IQ, and language abilities. Using hierarchical cluster analysis, four groups were identified. Group 1, the least affected group, had mild autism, the highest IQ, and the strongest verbal abilities. Group 2, the severely affected group, had the lowest IQ, most severe autism symptoms, and weakest verbal abilities. Group 3 and Group 4 displayed average levels of verbal abilities and IQ. These findings may characterize the heterogeneous profiles of verbal abilities in Chinese-speaking children.","2022-05","2025-02-26 20:37:05","2025-02-26 20:37:05","","1908-1919","","5","52","","","","","","","","","","English","","","","WOS:000654169900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","Cluster analysis; COMMUNICATION; EXPRESSIVE LANGUAGE; Heterogeneity; LENGTH; Naturalistic sampling approach; PREVALENCE; SKILLS; SPECTRUM DISORDER; SPONTANEOUS SPEECH; SUBGROUPS; SUBTYPES; YOUNG-CHILDREN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CBHZYGXU","journalArticle","2023","Rinke, E; Lago, S; Gattei, CA","Diachronic change and variation in use: Judgments of clitic doubling in Peninsular vs. Rioplatense Spanish","ISOGLOSS OPEN JOURNAL OF ROMANCE LINGUISTICS","","2385-4138","10.5565/rev/isogloss.293","","Previous studies have demonstrated that in spontaneous speech, Rioplatense Spanish speakers - in contrast to speakers of Peninsular Spanish - sometimes produce cliticdoubled accusative nominal objects. If this contrast between varieties reflects different grammatical systems, it would be expected to also affect the acceptability of clitic doubling across varieties. We tested this hypothesis in a judgment study that compared the acceptability of dative and accusative clitic-doubled objects between Rioplatense and Peninsular Spanish speakers. Speakers of both varieties showed similar preferences with dative clitic doubling, consistent with previous work. By contrast, accusative clitic doubling was highly acceptable in Rioplatense Spanish, but not in Peninsular Spanish. Based on accounts of the diachronic development of clitic doubling, we argue that the Rioplatense speakers exhibit a diachronically advanced behavior compared to Peninsular Spanish speakers.","2023","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","1","9","","","","","","","","","","English","","","","WOS:001223257400005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","acceptability judgments; clitic doubling; diachronic change; Peninsular Spanish; Rioplatense Spanish","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4ERCMWVK","journalArticle","2024","Dowding, S; Gutwin, C; Cockburn, A","User speech rates and preferences for system speech rates","INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES","","1071-5819","10.1016/j.ijhcs.2024.103222","","Prior studies of human communication have demonstrated that prosocial outcomes occur when facets of communication converge between interlocutors-for example, social likeability and perceived competence increase when people adapt their pitch or rate of speech towards one another. Inspired by these findings, we examined whether user preference for fast or slow system speech rate covaries with user speech rate. Experimental participants uploaded samples of their reading speech and spontaneous speech, and then listened to fast and slow system speech before choosing their preferred system speech rate. Results aligned with our hypothesis that fast speakers prefer faster system speech and that slow speakers prefer slow. Design implications are discussed, as well as plans for future studies that explore the potential for systems to automatically measure the user's speech rate and converge towards it.","2024-04","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","184","","","","","","","","","","English","","","","WOS:001162649900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","Adaption; ARTICULATION RATE; Convergence; CONVERGENCE; READ; SPEAKING; Speech rate; User preferences","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CIHDQ9Q6","journalArticle","2022","Fingerhuth, M; Breuer, LM","Language production experiments as tools for corpus construction: A contrastive study of complementizer agreement","CORPUS LINGUISTICS AND LINGUISTIC THEORY","","1613-7027","10.1515/cllt-2019-0075","","The investigation of linguistic phenomena in corpora of spontaneous speech is sometimes hindered by corpus size or by the complexity of the factors influencing their occurrence. Language Production Experiments (LPEs) can specifically elicit such phenomena and can therefore be used to build corpora that allow for their investigation. Yet experiments are a wide category that covers very different tasks, and there is little empirical research that compares speakers' response behavior to different task types. In this paper, we compare the responses of a group of 22 speakers to a translation task and a completion task, both of which target the syntactic phenomena complementizer agreement (CA). The results indicate that both experimental methods offer legitimate ways to investigate the phenomenon with specific advantages and disadvantages. However, a comparison of results from both tasks allows for insights that a single task could not have provided.","2022-05-25","2025-02-26 20:37:05","2025-02-26 20:37:05","","237-262","","2","18","","","","","","","","","","English","","","","WOS:000869185100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","complementizer agreement; corpus construction; DYNAMICS; language production experiments; syntax; SYNTAX","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YYVPFQFS","journalArticle","2024","Mikros, G; Boumparis, D","Cross-linguistic authorship attribution and gender profiling. Machine translation as a method for bridging the language gap","DIGITAL SCHOLARSHIP IN THE HUMANITIES","","2055-7671","10.1093/llc/fqae028","","This study explores the feasibility of cross-linguistic authorship attribution and the author's gender identification using Machine Translation (MT). Computational stylistics experiments were conducted on a Greek blog corpus translated into English using Google's Neural MT. A Random Forest algorithm was employed for authorship and gender profiling, using different feature groups [Author's Multilevel N-gram Profiles, quantitative linguistics (QL), and cross-lingual word embeddings (CLWE)] in both original and translated texts. Results indicate that MT is a viable method for converting a multilingual corpus into one language for authorship attribution and gender profiling research, with considerable accuracy when training and testing datasets use identical language. In the pure cross-linguistic scenario, higher accuracies than the baselines were obtained using CLWE and QL features.","2024-06-05","2025-02-26 20:37:05","2025-02-26 20:37:05","","954-967","","3","39","","","","","","","","","","English","","","","WOS:001241829300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;92</p>","","","author profiling; Authors'; authorship attribution; CLASSIFICATION; DIVERSITY; EMBEDDINGS; INDEX; lexical diversity; LEXICAL RICHNESS; Machine Translation; Multilevel N-gram Profiles; multilingual word embeddings; SPONTANEOUS SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9PNGKVF3","journalArticle","2022","Kawahara, S; Kato, M; Idemaru, K","Speaking rate normalization across different talkers in the perception of Japanese stop and vowel length contrasts","JASA EXPRESS LETTERS","","2691-1191","10.1121/10.0009793","","Perception of duration is critically influenced by the speaking rate of the surrounding context. However, to what extent this speaking rate normalization is talker-specific is understudied. This experiment investigated whether Japanese listeners' perception of temporally contrastive phonemes is influenced by the speaking rate of the surrounding context, and more importantly, whether the effect of the contextual speaking rate persists across different talkers for different types of contrasts: a singleton-geminate stop contrast and short-long vowel contrast in Japanese. The results suggest that listeners generalized their rate-based adjustments to different talkers' speech regardless of whether the target contrasts depended on silent closure duration or vowel duration. Our results thus support the view that speaking rate normalization is an obligatory process that happens in the early phase of perception. (C) 2022 Author(s).","2022-03","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","3","2","","","","","","","","","","English","","","","WOS:000778996900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","ARTICULATORY-RATE; SPONTANEOUS SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SF39E9X6","journalArticle","2024","Wu, CH","Workplace intelligibility: form-focused pronunciation instruction on ESL spontaneous speech","ENGLISH TEACHING AND LEARNING","","1023-7267","10.1007/s42321-023-00141-0","","This study examined the development of global intelligibility in one's spontaneous workplace spoken ESL in response to form-focused instruction (FFI) through the analyses of comments from both the learner and tutor and subjective listeners' impressionistic judgments. The feedback from individuals who worked with Malcolm showed perceived improvement in Malcolm's intelligibility, while no statistically significant change in Malcolm's speech intelligibility was measured in the one-way repeated ANOVA. The findings were explained through the analyses of the instructional treatment, time factor, listeners' characteristics, fast speech speed, and first language transfer. This study uncovered how an adult ESL learner responded to instruction in reality after having lived in the USA for 19 years. The participant's age, amount of second language (L2) experience, and need for spontaneous workplace intelligibility contribute to the significance of the study.","2024-09","2025-02-26 20:37:05","2025-02-26 20:37:05","","387-415","","3","48","","","","","","","","","","English","","","","WOS:000948862800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","ACQUISITION; COMPREHENSIBILITY; FLUENCY; FOREIGN ACCENT; Form-focused; LEARNERS; LISTENER; Pronunciation instruction; Spontaneous intelligibility; Workplace","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9R8UU5IR","journalArticle","2025","Cajiao, AA","The Unstressed Vowel Reduction of Galician","LANGUAGES","","2226-471X","10.3390/languages10010016","","This study investigates the unstressed reduction process of Galician. In particular, we wondered about: (1) the specific mechanisms involved, (2) whether there are different degrees of reduction, depending on the word-stress position, or whether reduction applies categorically to all unstressed vowels, (3) whether it depends on the duration, and (4) whether it is a mechanical process. In order to answer those questions, an experimental acoustic study with semi-spontaneous speech from six young Galician-native women was conducted. The results were analyzed by applying individual linear mixed-effects models for each vowel. The results show that two different mechanisms are involved in the reduction process, namely raising and centralization, and conclude that, in Galician, this process does not depend on the duration of the segment, and, thus, it is controlled by the grammar of the language.","2025-01","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","1","10","","","","","","","","","","English","","","","WOS:001405973000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","DIALECTS; Galician vowel system; SPOKEN; STRESS; vowel duration; vowel reduction process","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UYICS6PI","journalArticle","2022","Tymbay, A","Prominence and Melody Mistakes in the Spontaneous Speech of Czech Learners of English","SKASE JOURNAL OF THEORETICAL LINGUISTICS","","1336-782X","","","The differences in English and Czech melody, accentuation, and rhythm patterns are viewed in the article as most likely causes of the Czech learners' intonation mistakes. The article aims at identifying these mistakes to help Czech students achieve better intelligibility of their spontaneous English speech. The results of the auditory and acoustic analyses, including the British native speakers' perceptual assessment of the Czech accent, are employed to identify the problematic areas of L2 intonation acquisition. An attempt is made to link these areas, namely the insufficient expression of prominence, differences in speech segmentation, and the choice of melody patterns, with L1 intonation transfer. The article concludes that although these mistakes do not pose a severe obstruction to communication, focused classroom instruction aimed at overcoming the Czech language interference will significantly facilitate English intonation acquisition and improve the general intelligibility of students' speech.","2022","2025-02-26 20:37:05","2025-02-26 20:37:05","","2-17","","2","19","","","","","","","","","","English","","","","WOS:000926444500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","comfortable intelligibility; intonation; L1 transfer; melody; prominence; PROSODY; SALIENCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LQB9CX2I","journalArticle","2023","Mithun, M","ELICITATION AND DOCUMENTATION OF VALENCY-CHANGING CONSTRUCTIONS AND PROCESSES","LANGUAGE DOCUMENTATION & CONSERVATION","","1934-5275","","","Documentation work can be more effective when we approach it knowing about the kinds of categories and patterns that occur cross-linguistically on the one hand, and appreciate the difference between structures one can elicit with reliable results and those whose value emerges more fully from spontaneous speech on the other. The discussion here centers around five sets of topics pertaining to valency, that is, the number of core arguments in a clause. The first are basic clause structures: the core/oblique distinction, transitivity, and common core patterns (nominative/accusative, ergative/absolutive, agent/patient, active/stative, hierarchical, indirective, secundative, and mixed systems). Second are core argument status and differential argument marking. Third are major constructions affecting argument structure: causatives, applicatives, reflexives, middles, reciprocals, passives, and antipassives. Fourth are some discourse functions of valency-changing constructions. Finally, fifth are some of the syntactic functions that argument-structure alternatives serve in various languages.","2023","2025-02-26 20:37:05","2025-02-26 20:37:05","","243-292","","","26","","","","","","","","","","English","","","","WOS:001022084400006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;13</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GCI4MHJY","journalArticle","2024","Hinds, H","Memory and time in early Quakerism","MEMORY STUDIES","","1750-6980","10.1177/17506980231184580","","This article explores the ambiguous place of memory - its absences and presences, its strategic mobilisation and theological redundancy - in the practices and writings of the early Quaker movement. Quakers' commitment to unprogrammed, largely silent, worship and to spontaneous speech meant that memory had no place in their Meetings for Worship. Nevertheless, the movement was actively intent on conserving the memory of its early years, ensuring that its writings, published and unpublished, were preserved, by developing systems of copying and archiving key documents. Memory is thus central to the ambitions and practices of the early movement and yet also rendered redundant by aspects of its theology. The article investigates traces of memory in the composition of the Journal of George Fox, the movement's first leader, and finds its strategic rhetorical mobilisation of memory to be rooted in Quakers' distinctive understandings of human and divine time.","2024-12","2025-02-26 20:37:05","2025-02-26 20:37:05","","1501-1518","","6","17","","","","","","","","","","English","","","","WOS:001034228200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","early Quakerism; Fox's epistles; Fox's Journal; George Fox; memory; time","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UMPUA2NU","journalArticle","2022","Brown, AC; Childers, E; Bowen, EFW; Zuckerberg, GA; Granger, R","Phonemes in continuous speech are better recognized in context than in isolation","FRONTIERS IN COMMUNICATION","","2297-900X","10.3389/fcomm.2022.865587","","The contribution of context to phoneme perception is a subject of extensive study. In recent years, while the perception of phonemes in and out of context has become characterized as well-understood, new studies have emerged to challenge prevailing wisdom. Findings derived from rigorously controlled stimuli have failed to hold up when tested against continuous or more naturalistic speech, and vowels produced in isolation have been shown to possess different frequencies than vowels in spontaneous speech. In the present study, we examine the effect of context on vowel recognition, via stimuli taken directly from natural continuous speech in an audiobook. All tested vowel sounds, except /EH/, were better recognized with surrounding context than in isolation, affirming the resilience of findings from past studies.","2022-08-31","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","7","","","","","","","","","","English","","","","WOS:000853911000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","consonantal context; continuous speech; FUNDAMENTAL-FREQUENCY; IDENTIFICATION; INFORMATION; PERCEPTION; phoneme identification; speech perception; SPOKEN; vowel; vowel recognition; VOWELS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WAXLZB99","journalArticle","2021","Biron, T; Baum, D; Freche, D; Matalon, N; Ehrmann, N; Weinreb, E; Biron, D; Moses, E","Automatic detection of prosodic boundaries in spontaneous speech","PLOS ONE","","1932-6203","10.1371/journal.pone.0250969","","Automatic speech recognition (ASR) and natural language processing (NLP) are expected to benefit from an effective, simple, and reliable method to automatically parse conversational speech. The ability to parse conversational speech depends crucially on the ability to identify boundaries between prosodic phrases. This is done naturally by the human ear, yet has proved surprisingly difficult to achieve reliably and simply in an automatic manner. Efforts to date have focused on detecting phrase boundaries using a variety of linguistic and acoustic cues. We propose a method which does not require model training and utilizes two prosodic cues that are based on ASR output. Boundaries are identified using discontinuities in speech rate (pre-boundary lengthening and phrase-initial acceleration) and silent pauses. The resulting phrases preserve syntactic validity, exhibit pitch reset, and compare well with manual tagging of prosodic boundaries. Collectively, our findings support the notion of prosodic phrases that represent coherent patterns across textual and acoustic parameters.","2021-05-03","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","5","16","","","","","","","","","","English","","","","WOS:000646400800049","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;85</p>","","","DISCOURSE; SENTENCES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DTGG6679","journalArticle","2022","Saavedra, CF; Cañas, VG; Cabrera, GJ; Sáez, CG","Acoustic characteristics of speech in adolescents with suicidal attempt. Voice, speech and suicidal behaviour","MEDICINA BALEAR","","1579-5853","10.3306/AJHS.2022.37.05.64","","Introduction: Suicide represents the second leading cause of death among adolescents. There are studies that link voice to suicidal risk. Methods: The research was conducted through a cross-sectional study, and the sample was selected through non-probability sampling, which included 40 adolescents between 16 and 19 years old from the city of Temuco. After the identification of suicidal attempts, the participants underwent voice and speech acoustic evaluation. Results: A parameter that showed differences was Jitter (p<0,05). As to the spontaneous speech tasks assessment, it was possible to observe differences in the formants concerning the vast majority of the vowels measured (p<0,05). Some voice and speech indicators differ depending on the group and the task requested. Conclusion: Therefore, these indicators might provide useful information for assessing suicidal behaviour.","2022-09","2025-02-26 20:37:05","2025-02-26 20:37:05","","64-73","","5","37","","","","","","","","","","English","","","","WOS:000859999100010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","DEPRESSION; NOMENCLATURE; PREVALENCE; PREVENTION; RISK-ASSESSMENT; SAMPLE; SEVERITY; suicidal attempt; suicide; TOWER-OF-BABEL; Voice","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QLWE8M22","journalArticle","2023","Cox, C; Dideriksen, C; Keren-Portnoy, T; Roepstorff, A; Christiansen, MH; Fusaroli, R","Infant-directed speech does not always involve exaggerated vowel distinctions: Evidence from Danish","CHILD DEVELOPMENT","","0009-3920","10.1111/cdev.13950","","This study compared the acoustic properties of 26 (100% female, 100% monolingual) Danish caregivers' spontaneous speech addressed to their 11- to 24-month-old infants (infant-directed speech, IDS) and an adult experimenter (adult-directed speech, ADS). The data were collected between 2016 and 2018 in Aarhus, Denmark. Prosodic properties of Danish IDS conformed to cross-linguistic patterns, with a higher pitch, greater pitch variability, and slower articulation rate than ADS. However, an acoustic analysis of vocalic properties revealed that Danish IDS had a reduced or similar vowel space, higher within-vowel variability, raised formants, and lower degree of vowel discriminability compared to ADS. None of the measures, except articulation rate, showed age-related differences. These results push for future research to conduct theory-driven comparisons across languages with distinct phonological systems.","2023-11","2025-02-26 20:37:05","2025-02-26 20:37:05","","1672-1696","","6","94","","","","","","","","","","English","","","","WOS:001007039300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;171</p>","","","CLEAR SPEECH; CONVERSATIONAL SPEECH; CROSS-LANGUAGE; FUNDAMENTAL-FREQUENCY; INTELLIGIBILITY; MOTHERS SPEECH; PREFERENCES; SELECTIVE ATTENTION; SOCIAL FEEDBACK; SPACE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3JEZUKL9","journalArticle","2021","Etxebarria, A; Eguskiza, N; Iglesias, A","THE PROSODIC COMPETENCE OF YOUNG BASQUE BILINGUALS IN STORYTELLING: TONAL PEAKS AND BOUNDARY TONES","RLA-REVISTA DE LINGUISTICA TEORICA Y APLICADA","","0718-4883","10.29393/RLA59-14CPAN30014","","In the study of the prosody of the Basque language, we have mainly worked with isolated sentences or read texts, but not with spontaneous narrative texts. This is mainly due to the fact that it is not a standardised language and the accent, depending on the diatopic variety to which it belongs, is not always placed on the same syllable. This work, based on the theory of prosodic hierarchy and using autosegmental metrical notation, aims to specify the tonal peaks and boundary tones of the prosodic groups used in the spontaneous narration of a traditional tale. Enunciative sentences with prosodic group between 5 and 10 syllables were analysed. The main conclusion of this work is that in most of the structures analysed the tonal summit is located in the second sentence of the prosodic group, and the border tone tends to be ascending, but it cannot be generalised.","2021-12","2025-02-26 20:37:05","2025-02-26 20:37:05","","133-151","","2","59","","","","","","","","","","English","","","","WOS:000743484800007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","prosody; spontaneous speech; tonal peaks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FEBVKIM8","journalArticle","2022","Meister, E; Meister, L","Estonian Elderly Speech Corpus - Design, Collection and Preliminary Acoustic Analysis","BALTIC JOURNAL OF MODERN COMPUTING","","2255-8942","10.22364/bjmc.2022.10.3.09","","Elderly speech has been found challenging for automatic speech recognition systems due to the lack of suitable training data and due to age-related physiological changes affecting the acoustic characteristics of voice. The paper introduces the collection of the speech corpus of Estonian elderly speakers aged over 60 years and reports preliminary results of acoustic analysis of some prosodic characteristics. The corpus contains the recordings of spontaneous speech by 100 men and 100 women, on average 29 minutes of speech from each speaker with transcriptions. Acoustic analysis of elderly speech revealed that with age (1) F0 increases significantly in males and slightly decreases in females, (2) speech and articulation rates decrease in females, but not in males, (3) utterances are getting shorter, and (4) pauses are getting longer in females and shorter in males.","2022","2025-02-26 20:37:05","2025-02-26 20:37:05","","360-371","","3","10","","","","","","","","","","English","","","","WOS:000867549800010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","acoustic analysis; AGE-RELATED-CHANGES; elderly speech; fundamental frequency; speaking rate; speech corpus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JN8RWCHL","journalArticle","2022","Sim, JH; Post, B","Variation in quality of maternal input and development of coda stops in English-speaking children in Singapore","JOURNAL OF CHILD LANGUAGE","","0305-0009","10.1017/S0305000921000593","","This study examines the effects of input quality on early phonological acquisition by investigating whether interadult variation in specific phonetic properties in the input is reflected in the production of their children. We analysed the English coda stop release patterns in the spontaneous speech of fourteen mothers and compared them with the spontaneous production of their preschool children. The analysis revealed a very strong positive input-production relationship; mothers who released coda stops to a lesser degree also had children who tended to not release their stops, and the same was true for mothers who released their stops to a higher degree. The findings suggest that young children are sensitive to acoustic properties that are subphonemic, and these properties are also reflected in their production, showing the importance of considering input quality when investigating child production.","2022-11","2025-02-26 20:37:05","2025-02-26 20:37:05","","1147-1172","","6","49","","","","","","","","","","English","","","","WOS:000771234400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","ACQUISITION; CAREGIVER; L1 USE; LANGUAGE DOMINANCE; LEARNERS; PHONETICS; PHONOLOGICAL DEVELOPMENT; PRONUNCIATION; SPANISH; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LXVL85IN","journalArticle","2024","Paul, JS; Raghavan, S; Kesavadas, C; Raj, TA","Comparative analysis of quantitative susceptibility mapping in preclinical dementia detection","EUROPEAN JOURNAL OF RADIOLOGY","","0720-048X","10.1016/j.ejrad.2024.111598","","Purpose: This review aims to explore the role of Quantitative Susceptibility Mapping (QSM) in the early detection of neurodegenerative diseases, particularly Alzheimer's disease (AD) and Lewy body dementia (LBD). By examining QSM's ability to map brain iron deposition, we seek to highlight its potential as a diagnostic tool for preclinical dementia. Methodology: QSM techniques involve the advanced processing of MRI phase images to reconstruct tissue susceptibility, employing methods such as spherical mean value filtering and Tikhonov regularization for accurate background field removal. This review discusses how these methodologies enable the precise quantification of iron and other elements within the brain. Results: QSM has demonstrated effectiveness in identifying early pathological changes in key brain regions, including the hippocampus, basal ganglia, and substantia nigra. These regions are significantly impacted in the early stages of AD and LBD. Studies reviewed indicate that QSM can detect subtle neurodegenerative changes, providing valuable insights into disease progression. However, challenges remain in standardizing QSM processing algorithms to ensure consistent results across different studies. Conclusion: QSM emerges as a promising tool for early dementia detection, offering precise measurements of brain iron deposition and other critical biomarkers. The review underscores the importance of refining QSM methodologies and integrating them with other imaging modalities to improve early diagnosis and management of neurodegenerative diseases. Future research should focus on standardizing QSM techniques and exploring their synergistic use with other neuroimaging methods to enhance its clinical utility.","2024-09","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","178","","","","","","","","","","English","","","","WOS:001267359500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","Alzheimer's disease; Brain iron Levels; Fronto temporal dementia (FTD); Lewis body dementia (LBD); Microstructural changes; Pre-clinical dementia; QSM; Quantitative susceptibility mapping (QSM)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HIN3M9XN","journalArticle","2024","Xie, XP; Li, C; Tian, D; Shen, RF; Ding, F","New research on monaural speech segregation based on quality assessment","COMPUTER SPEECH AND LANGUAGE","","0885-2308","10.1016/j.csl.2023.101601","","Speech enhancement (SE) is a pivotal technology in enhancing the quality and intelligibility of speech signals. Nevertheless, when processing speech signals under conditions of high signal-tonoise ratio (SNR), conventional SE techniques may inadvertently lead to a diminution in the perceptual evaluation of speech quality (PESQ) and short-time objective intelligibility (STOI). This article introduces the innovative incorporation of the Non-Intrusive Speech Quality Assessment (NISQA) algorithm into SE systems. Through the comparison of pre and postenhancement speech quality scores, it discerns whether the speech signal under consideration warrants enhancement processing, thereby mitigating potential deterioration in PESQ and STOI. Furthermore, this study delves into the ramifications of five prevalent speech features, namely, Mel Frequency Cepstral Coefficients (MFCC), Gammatone Frequency Cepstral Coefficients (GFCC), Relative Spectral Trans-formed Perceptual Linear Prediction coefficients (RASTA-PLP), Amplitude Modulation Spectrogram (AMS), and Multi-Resolution Cochleagram (MRCG), on PESQ and STOI under varying noise conditions. Experimental outcomes underscore that MRCG consistently emerges as the optimal and most stable feature for STOI, while the feature yielding the highest PESQ score exhibits intricate correlations with the background noise type, SNR level, and noise compatibility with the speech signal. Consequently, we propose an SE methodology founded on quality assessment and feature selection, facilitating the adaptive selection of optimal features tailored to distinct background noise scenarios, thereby always maintain the highest caliber enhancement effect with regard to PESQ metrics.","2024-04","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","85","","","","","","","","","","English","","","","WOS:001139857800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Deep learning; FEATURES; MFCC; NOISE; Quality assessment; RECOGNITION; Selective speech enhancement; Single -channel speech enhancement; Speech features","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QA75836A","journalArticle","2022","Vaishnavi, V; Dhanaselvam, PS","Neonatal cry signal prediction and classification via dense convolution neural network","JOURNAL OF INTELLIGENT & FUZZY SYSTEMS","","1064-1246","10.3233/JIFS-212473","","The study of neonatal cry signals is always an interesting topic and still researcher works interminably to develop some module to predict the actual reason for the baby cry. It is really hard to predict the reason for their cry. The main focus of this paper is to develop a Dense Convolution Neural network (DCNN) to predict the cry. The target cry signal is categorized into five class based on their sound as ""Eair"", ""Eh"", ""Neh"", ""Heh"" and ""Owh"". Prediction of these signals helps in the detection of infant cry reason. The audio and speech features (AS Features) were exacted using Mel-Bark frequency cepstral coefficient from the spectrogram cry signal and fed into DCNN network. The systematic DCNN architecture is modelled with modified activation layer to classify the cry signal. The cry signal is collected in different growth phase of the infants and tested in proposed DCNN architecture. The performance of the system is calculated through parameters accuracy, specificity and sensitivity are calculated. The output of proposed system yielded a balanced accuracy of 92.31%. The highest accuracy level 95.31%, highest specificity level 94.58% and highest sensitivity level 93% attain through proposed technique. From this study, it is concluded that the proposed technique is more efficient in detecting cry signal compared to the existing techniques.","2022","2025-02-26 20:37:05","2025-02-26 20:37:05","","6103-6116","","6","42","","","","","","","","","","English","","","","WOS:000790690300089","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","audio and speech features; CNN; dense convolution neural network; Infant cry signal; mel-bark frequency cepstral domain; spectrogram images; SVM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6N2P2DTY","journalArticle","2025","Maji, PK; Acharya, S; Paul, P; Chakraborty, S; Basu, S","Deep learning inspired game-based cognitive assessment for early dementia detection","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2024.109901","","This paper introduces a gaming approach inspired by deep learning for the early detection of dementia. This research employs a convolutional neural network (CNN) model to analyze health metrics and facial images via a cognitive assessment gaming application. We have collected 1000 samples of health metric data from Apollo Diagnostic Center and hospitals, labeled ""demented"" or ""nondemented,"" to train a modified 1-dimensional convolutional neural network (MOD-1D-CNN) for game level 1. Additionally, a dataset of 1800 facial images, also labeled ""demented"" or ""non-demented,"" is collected in our work to train a modified 2-dimensional convolutional neural network (MOD-2D-CNN) for game level 2. The MOD-1D-CNN has achieved a loss of 0.2692 and an accuracy of 70.50% in identifying dementia traits via health metric data; in comparison, the MOD-2D-CNN has achieved a loss of 0.1755 and an accuracy of 95.72% in distinguishing dementia from facial images. A rule-based linear weightage method combines these models and provides a final decision. In addition, a better fusion neural network strategy is also explored in the results analysis with an ablation study. The proposed models are computationally efficient alternatives with significantly fewer parameters than other state-of-the-art models. The performance and parameter counts of these models are compared with those of existing deep learning models, emphasizing the role of AI in enhancing early dementia.","2025-02-15","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","142","","","","","","","","","","English","","","","WOS:001399945500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;80</p>","","","ALZHEIMERS-DISEASE; Artificial intelligence; CLASSIFICATION; Cognitive assessment; Convolutional neural networks; Deep learning; Dementia detection; DIAGNOSIS; FACIAL EXPRESSION RECOGNITION; Game playing; INTELLIGENCE; MODEL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GZXXECNM","journalArticle","2024","Bingöl, G; Porcu, S; Floris, A; Atzori, L","WebRTC-QoE: A dataset of QoE assessment of subjective scores, network impairments, and facial & speech features","COMPUTER NETWORKS","","1389-1286","10.1016/j.comnet.2024.110356","","In the realm of real-time communications, WebRTC-based multimedia applications are increasingly prevalent as these can be smoothly integrated within Web browsing sessions. The browsing experience is then significantly improved with respect to scenarios where browser add-ons and/or plug-ins are used; still, the end user's Quality of Experience (QoE) in WebRTC sessions may be affected by network impairments, such as delays and losses. Due to the variability in user perceptions under different communications scenarios, comprehending and enhancing the resulting service quality is a complex endeavor. To address this, we present a dataset that provides a comprehensive perspective on the conversational quality of a two-party WebRTC-based audiovisual telemeeting service. This dataset was gathered through subjective evaluations involving 20 subjects across 15 different test conditions (TCs). A specialized system was developed to induce controlled network disruptions such as delay, jitter, and packet loss rate, which adversely affected the communication between the parties. This methodology offered an insight into user perceptions under various network impairments. The dataset encompasses a blend of objective and subjective data including ACR (Absolute Category Rating) subjective scores, WebRTC-internals parameters, facial expressions features, and speech features. Consequently, it serves as a substantial contribution to the improvement of WebRTC-based video call systems, offering practical and real-world data that can drive the development of more robust and efficient multimedia communication systems, thereby enhancing the user's experience.","2024-05","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","244","","","","","","","","","","English","","","","WOS:001217752500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;6</p>","","","Facial expressions; Network impairments; Quality of experience; Speech; WebRTC; WebRTC-internals","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9HYB7CFS","journalArticle","2023","Geng, SY; Zhu, ZN; Wang, ZD; Dan, YP; Li, HY","LW-ViT: The Lightweight Vision Transformer Model Applied in Offline Handwritten Chinese Character Recognition","ELECTRONICS","","2079-9292","10.3390/electronics12071693","","In recent years, the transformer model has been widely used in computer-vision tasks and has achieved impressive results. Unfortunately, these transformer-based models have the common drawback of having many parameters and a large memory footprint, causing them to be difficult to deploy on mobiles as lightweight convolutional neural networks. To address these issues, a Vision Transformer (ViT) model, named the lightweight Vision Transformer (LW-ViT) model, is proposed to reduce the complexity of the transformer-based model. The model is applied to offline handwritten Chinese character recognition. The design of the LW-ViT model is inspired by MobileViT. The lightweight ViT model reduces the number of parameters and FLOPs by reducing the number of transformer blocks and the MV2 layer based on the overall framework of the MobileViT model. The number of parameters and FLOPs for the LW-ViT model was 0.48 million and 0.22 G, respectively, and it ultimately achieved a high recognition accuracy of 95.8% on the dataset. Furthermore, compared to the MobileViT model, the number of parameters was reduced by 53.8%, and the FLOPs were reduced by 18.5%. The experimental results show that the LW-ViT model has a low number of parameters, proving the correctness and feasibility of the proposed model.","2023-04","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","7","12","","","","","","","","","","English","","","","WOS:000971040800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","CONVOLUTIONAL NEURAL-NETWORK; lightweight vision transformer (LW-ViT); MV2 layer; offline handwritten Chinese character recognition; ONLINE; transformer-based models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RBT4RX2N","journalArticle","2023","Strydom, S; Dreyer, AM; Merwe, BV","Automatic assignment of diagnosis codes to free-form text medical note","JOURNAL OF UNIVERSAL COMPUTER SCIENCE","","0948-695X","10.3897/jucs.89923","","International Classification of Disease (ICD) coding plays a significant role in classify-ing morbidity and mortality rates. Currently, ICD codes are assigned to a patient's medical record by hand by medical practitioners or specialist clinical coders. This practice is prone to errors, and training skilled clinical coders requires time and human resources. Automatic prediction of ICD codes can help alleviate this burden. In this paper, we propose a transformer-based architecture with label-wise attention for predicting ICD codes on a medical dataset. The transformer model is first pre-trained from scratch on a medical dataset. Once this is done, the pre-trained model is used to generate representations of the tokens in the clinical documents, which are fed into the label-wise attention layer. Finally, the outputs from the label-wise attention layer are fed into a feed-forward neural network to predict appropriate ICD codes for the input document. We evaluate our model using hospital discharge summaries and their corresponding ICD-9 codes from the MIMIC-III dataset. Our experimental results show that our transformer model outperforms all previous models in terms of micro-F1 for the full label set from the MIMIC-III dataset. This is also the first successful application of a pre-trained transformer architecture to the auto-coding problem on the full MIMIC-III dataset.","2023","2025-02-26 20:37:05","2025-02-26 20:37:05","","349-373","","4","29","","","","","","","","","","English","","","","WOS:000991529200004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Prediction of ICD codes; transformer architecture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6RK5ZUXU","journalArticle","2025","Cao, YZ; Liao, YL; Liu, ZR; Ma, X; Liu, XG","SWAformer: A novel shifted window attention Transformer model for accurate power distribution prediction","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.126058","","In recent years, deep learning models have been increasingly applied to power distribution prediction due to the success of time series prediction methods. These models extract features from the data and capture the overall trend, leading to more accurate predictions than traditional approaches. Global information refers to the overall trend or pattern across the entire dataset, while local information pertains to specific variations or changes within smaller regions of the data. However, focusing solely on global information while neglecting these local variations can reduce prediction accuracy and increase model complexity. To address these challenges, we propose a novel Shifted Window Attention Transformer model that enhances local information learning by iteratively computing self-attention within regions of varying window sizes. Additionally, patch relative position encoding is incorporated to better preserve spatiotemporal information. The model operates in a bottom-up manner, where the cascaded input data progressively extract features from local to global levels. This approach efficiently integrates both global and local information, resulting in improved performance. The effectiveness of our model was demonstrated on widely used public datasets, where it achieved superior prediction results for power distribution tasks. By optimizing grid operators' decisions, our approach enhances the accuracy and efficiency of power distribution and supports the advancement and modernization of power systems.","2025-03-15","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","265","","","","","","","","","","English","","","","WOS:001382050300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","CONSUMPTION; Deep learning; ENERGY; Long sequence time-series forecasting; NETWORKS; Power distribution prediction; TERM; Window attention Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6VUJUYU4","journalArticle","2024","Nobel, SMN; Swapno, SMMR; Islam, MB; Azad, AKM; Alyami, SA; Alamin, M; Liò, P; Moni, MA","A Novel Mixed Convolution Transformer Model for the Fast and Accurate Diagnosis of Glioma Subtypes","ADVANCED INTELLIGENT SYSTEMS","","2640-4567","10.1002/aisy.202400566","","Glioblastoma is the most common adult brain tumor, significantly impacts disability and mortality. Early and accurate diagnosis of glioma subtypes is essential, but manual categorization is challenging due to their complexity, prompting the need for automated solutions. We developed an innovative mixed convolution-transformer model to classify glioma subtypes, including astrocytoma, glioblastoma, oligodendroglioma, and normal brain tissue, using whole slide images. The novelty of this model lies in its remarkable efficiency and precise results. Multiple advanced and complex layers are incorporated during its development to enhance its performance, ensuring that it delivers fast and accurate classification results for glioma. This proposed model obtains an overall training accuracy of 97.41%, peaking at 98.12% for validation and 97.35% for testing. Next, our model architecture is independently evaluated by comparing its training performances on the CIFAR-10 and CIFAR-100 datasets with the vision transformer and compact convolutional transformer models. Results across various datasets demonstrate that the model consistently outperforms existing models. This performance underscores the effectiveness of our proposed approach in classifying glioma subtypes accurately and efficiently, highlighting its potential impact on healthcare and disability. This system enhances the classification of glioma subtypes and facilitates swift identification, ensuring appropriate and timely treatment.","2024-11-28","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","","","","","","","","","","","English","","","","WOS:001365529900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","ALGORITHM; brain tumor; CLASSIFICATION; computer vision; deep learning; disability Researches; GENETICS; glioma diagnosis; GRADE GLIOMA; MUTATIONS; PREDICTION; vision transformers; whole slide images","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FXHUQXLF","journalArticle","2024","Öztürk, E; Mesut, AS; Fidan, ÖA","A Character Based Steganography Using Masked Language Modeling","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3354710","","In this study, a steganography method based on BERT transformer model is proposed for hiding text data in cover text. The aim is to hide information by replacing specific words within the text using BERT's masked language modeling (MLM) feature. In this study, two models, fine-tuned for English and Turkish, are utilized to perform steganography on texts belonging to these languages. Furthermore, the proposed method can work with any transformer model that supports masked language modeling. While traditionally the hidden information in text is often limited, the proposed method allows for a significant amount of data to be hidden in the text without distorting its meaning. In this study, the proposed method is tested by hiding stego texts of varying lengths in cover text of different lengths in two different language scenarios. The test results are analyzed in terms of perplexity, KL divergence and semantic similarity. Upon examining the results, the proposed method has achieved the best results compared to other methods found in the literature, with KL divergence of 7.93 and semantic similarity of 0.99. It can be observed that the proposed method has low detectability and demonstrates success in the data hiding process.","2024","2025-02-26 20:37:05","2025-02-26 20:37:05","","14248-14259","","","12","","","","","","","","","","English","","","","WOS:001157958300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","BERT; Bit error rate; Data models; Hash functions; Indexes; LINGUISTIC STEGANOGRAPHY; masked language modeling; Media; Natural language processing; Predictive models; steganography; Steganography; SYNONYM SUBSTITUTION; TEXT STEGANOGRAPHY; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZFB8DAZH","journalArticle","2022","Cheng, Y; Saukh, O; Thiele, L","SensorFormer: Efficient Many-to-Many Sensor Calibration With Learnable Input Subsampling","IEEE INTERNET OF THINGS JOURNAL","","2327-4662","10.1109/JIOT.2022.3177948","","Accurate calibration of low-cost environmental sensors is a prerequisite for their successful use in many monitoring applications. State-of-the-art calibration methods vary from simple linear regression to sophisticated deep models based on LSTMs and GRUs. The latter take past measurements to improve calibration accuracy. In this article, we argue that both recent past and close future measurements help to achieve accurate calibration, whereas accuracy improvements beyond the past come with a delay introduced by the occurrence of the future. We propose a generalized many-to-many calibration scheme called SensorFormer based on the successful Transformer model which takes both past and future raw measurements into account. We show that the proposed approach: 1) outperforms other methods by improving calibration accuracy by 16.5%-20.4% on public data sets and own field data and 2) can efficiently run on low-power microcontrollers with very limited computational and storage capabilities. The latter is achieved by a novel optimization technique based on learnable input subsampling taking advantage of the properties of typical sensor data. We manage to reduce the model size by 20%-33% and minimize the overall floating point operations per second (FLOPs) by 65% while maintaining superior accuracy than state-of-the-art methods.","2022-10-15","2025-02-26 20:37:05","2025-02-26 20:37:05","","20577-20589","","20","9","","","","","","","","","","English","","","","WOS:000865097300081","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Air quality; Calibration; Computational modeling; efficient transformer model; Gain measurement; Internet of Things; Pollution measurement; sensor calibration; Time measurement; TRANSFORMER; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PRW4X43X","journalArticle","2023","Zhang, X; Sun, JK; Wang, JX; Jin, YL; Wang, L; Liu, ZW","PAOLTransformer: Pruning-adaptive optimal lightweight Transformer model for aero-engine remaining useful life prediction","RELIABILITY ENGINEERING & SYSTEM SAFETY","","0951-8320","10.1016/j.ress.2023.109605","","Aero-engines are core equipment in aerospace field, and their remaining useful life (RUL) prediction is a critical aspect in spacecraft monitoring and maintenance. Transformer model demonstrates remarkable performance in this domain, but its construction heavily relies on a sizeable number of parameters and the excessive model redundancy may adversely affect its prediction performance. To address this issue, a pruning-adaptive optimal lightweight Transformer (PAOLTransformer) is proposed. The method employs norm information to evaluate the contribution of each element within the model to the outputs and subsequently utilizes structured pruning to eliminate unimportant redundant elements. The pruning procedure is executed automatically by seeking out the optimal compression rate via reinforcement learning with a reward score combining the accuracy and efficiency of RUL prediction. Experimental analysis on the C-MAPSS aero-engine dataset shows that PAOLTransformer significantly improves the performance metrics, including a 7% reduction in prediction error and a 33% reduction in computational complexity compared to the standard Transformer. It follows that the proposed model can achieve an optimal equilibrium between model performance and pruning rate. Furthermore, PAOLTransformer outperforms several advanced models in predicting long and complex time series. Therefore, this study holds significant implications for the implementation of preventive maintenance strategies for aeroengines.","2023-12","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","240","","","","","","","","","","English","","","","WOS:001074867200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;18<br/>Total Times Cited:&nbsp;&nbsp;18<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Adaptive structured pruning; Aero-engine; Lightweight deep learning model; Reinforcement learning; Remaining useful life prediction; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4WZ8TJ34","journalArticle","2024","Wang, Y; Zha, YY","Comparison of transformer, LSTM and coupled algorithms for soil moisture prediction in shallow-groundwater-level areas with interpretability analysis","AGRICULTURAL WATER MANAGEMENT","","0378-3774","10.1016/j.agwat.2024.109120","","Accurate quantification of soil moisture is essential for understanding water and energy exchanges between the atmosphere and the Earth's surface, as well as for agricultural applications. Predicting soil moisture content is vital for efficient water management, irrigation scheduling, and drought monitoring. Traditional forecasting methods, such as numerical regression models, often struggle due to various influencing factors and poor observation data quality. In contrast, deep learning algorithms, particularly recurrent and convolutional neural networks, show promise in predicting nonlinear data like soil moisture. This study focuses on shallow groundwater regions, using groundwater levels and meteorological data as features while coupling the Transformer model with other neural network structures. We investigate the potential of attention-based neural networks for soil moisture time series prediction. Our findings demonstrate that the Transformer model achieves an average R2 of 0.523 across different time lags, outperforming the LSTM model with an R2 of 0.485. The introduction of LSTM enhances the Transformer's stability in handling temporal changes. Additionally, we verified the importance of groundwater for soil moisture prediction. This study introduces new methods for soil moisture prediction and offers new insights and recommendations for the development of artificial intelligence technology for soil moisture prediction.","2024-12-01","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","305","","","","","","","","","","English","","","","WOS:001345949700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Deep learning; EVAPOTRANSPIRATION; HETAO IRRIGATION DISTRICT; Interpretability analysis; PRODUCT; Shallow groundwater level; Soil moisture; Time series prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5L6E48W8","journalArticle","2024","Zhang, SC; Zhu, CS; Guo, XT","Wind-Speed Multi-Step Forecasting Based on Variational Mode Decomposition, Temporal Convolutional Network, and Transformer Model","ENERGIES","","1996-1073","10.3390/en17091996","","Reliable and accurate wind-speed forecasts significantly impact the efficiency of wind power utilization and the safety of power systems. In addressing the performance enhancement of transformer models in short-term wind-speed forecasting, a multi-step prediction model based on variational mode decomposition (VMD), temporal convolutional network (TCN), and a transformer is proposed. Initially, the Dung Beetle Optimizer (DBO) is utilized to optimize VMD for decomposing non-stationary wind-speed series data. Subsequently, the TCN is used to extract features from the input sequences. Finally, the processed data are fed into the transformer model for prediction. The effectiveness of this model is validated by comparison with six other prediction models across three datasets, demonstrating its superior accuracy in short-term wind-speed forecasting. Experimental findings from three distinct datasets reveal that the developed model achieves an average improvement of 52.1% for R2. To the best of our knowledge, this places our model at the leading edge of wind-speed prediction for 8 h and 12 h forecasts, demonstrating MSEs of 1.003 and 0.895, MAEs of 0.754 and 0.665, and RMSEs of 1.001 and 0.946, respectively. Therefore, this research offers significant contributions through a new framework and demonstrates the utility of the transformer in effectively predicting short-term wind speed.","2024-05","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","9","17","","","","","","","","","","English","","","","WOS:001219889200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","multi-step forecasting; OPTIMIZATION ALGORITHM; temporal convolutional network; transformer; variational mode decomposition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BM4E2JCC","journalArticle","2024","Lu, W; Chen, XJ","Short-term load forecasting for power systems with high-penetration renewables based on multivariate data slicing transformer neural network","FRONTIERS IN ENERGY RESEARCH","","2296-598X","10.3389/fenrg.2024.1355222","","Introduction: The characteristics of intermittency and volatility brought by a high proportion of renewable energy impose higher requirements on load forecasting in modern power system. Currently, load forecasting methods mainly include statistical models and machine learning methods, but they exhibit relative rigidity in handling the uncertainty, volatility, and nonlinear relationships of new energy, making it difficult to adapt to instantaneous load changes and the complex impact of meteorological factors. The Transformer model, as an algorithm used in natural language processing, with its self-attention mechanism and powerful nonlinear modeling capability, can help address the aforementioned issues.Methods: However, its current performance in time series processing is suboptimal. Therefore, this paper improves the Transformer model through two steps, namely, Data-Slicing and Channel-independence, enhancing its adaptability in load forecasting.Results: By using load data from Northern Ireland as an example, we compared GRU, CNN, and traditional Transformer models. We validated the effectiveness of this algorithm in short-term load forecasting using MAPE and MSE as indicators.Discussion: The results indicate that, in short-term load forecasting, the MDS method, compared to GRU, CNN, and traditional Transformer methods, has generally reduced the MSE by over 48%, and achieved a reduction of over 47.6% in MAPE, demonstrating excellent performance.","2024-01-31","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","12","","","","","","","","","","English","","","","WOS:001161121300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","data slicing; deep learning; load forecasting; renewable energy; transformer neural network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XT9DNADT","journalArticle","2024","Namoune, A; Benzidane, MR; Taleb, R; Boukortt, A; Benbouzid, Z; Benyamina, M","Design and Simulation of a High-Efficiency Micro-Transformer for Photovoltaic Application","ELECTRIC POWER COMPONENTS AND SYSTEMS","","1532-5008","10.1080/15325008.2024.2310784","","This paper presents the design and analysis of a micro-transformer model aimed at achieving high efficiency in photovoltaic applications. The proposed micro-transformer structure consists of two circular planar coils made of copper mounted on PCB (FR4) and Si substrates. The Mohan formula is employed to calculate the micro-transformer's geometric parameters, ensuring alignment with flyback converter specifications. Consequently, the inductance, quality factors, and coupling factor variation parameters versus frequency, and the impact of the gap between the coils (500, 750, and 1000 mu m) on them were analyzed. The simulation findings unequivocally demonstrated that a judicious reduction in gap thickness to 500 mu m resulted in a remarkable enhancement of the coupling factor by an impressive 91%. Moreover, finite element-based software was used to analyze the thermal, magnetic, and electric performance of the micro-transformer across varying gap sizes. The investigation led to the determination of the optimal gap thickness that achieves adequate temperature, current, and magnetic flux distribution in the micro-transformer. Finally, the simulation circuit of a photovoltaic system that incorporates a flyback converter including the proposed micro-transformer was performed. Overall, the results revealed that the proposed micro-transformer model with its circular planar coil design offers high efficiency in PV applications.","2024-01-25","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","","","","","","","","","","","English","","","","WOS:001155433100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","DC-DC converter; flyback converter; high-efficiency; integration; Micro-transformer; photovoltaic","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7MC3LXK2","journalArticle","2023","Ge, YL","A Study on the Evaluation Model of In-depth Learning for Oral English Learning in Online Education","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","The trend of globalization in the world is becoming increasingly frequent, and people from different regions are communicating more closely. Therefore, the demand for a second language is constantly expanding, accelerating the development of the field of English oral evaluation and also accelerating the development of online education. The study proposes a text priori based oral evaluation model, which is based on the Transformer model and uses target phonemes as input to the Decoder. The model successfully predicts the relationship between actual pronunciation and error labels. At the same time, a self-supervised oral evaluation model with accent is constructed, which simulates the training process of misreading data by calculating semantic distance. The experimental results show that when the training set ratio reaches its maximum in the Speed Ocean dataset and the L2 Arctic dataset, the F1 values of the proposed method are 0.612 and 0.596, respectively; the length of the target phoneme has a smaller impact on this model compared to other models. Experiments have shown that the proposed deep learning method can alleviate deployment difficulties, directly optimize the effectiveness of oral evaluation, provide more accurate feedback, and also provide users with a better learning experience. This has practical significance for the development of the field of oral evaluation.","2023-05","2025-02-26 20:37:05","2025-02-26 20:37:05","","783-792","","5","14","","","","","","","","","","English","","","","WOS:001015055900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","deep learning; evaluation model; online education; SPEECH RECOGNITION; Spoken English; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YF92EKGE","journalArticle","2024","Mohanrajan, SN; Loganathan, A; Manoharan, P; Alenizi, FA","Fuzzy Swin transformer for Land Use/ Land Cover change detection using LISS-III Satellite data","EARTH SCIENCE INFORMATICS","","1865-0473","10.1007/s12145-023-01208-z","","Land Use/ Land Cover change detection is an inspiring, interesting task to be performed worldwide. The real-time satellite data of the earth's surface and its different findings can be studied with the assistance of Remote Sensing and Geographic Information Systems. This work builds the novel Fuzzy Swin Transformer-based LU/LC classification model using the LISS-III satellite data of Yelagiri Hills. In the proposed work, the LU/LC features extracted from fuzzy clustering were used as the input training patches when executing the Swin Transformer model. The training patches assist the transformer in finding the LU/LC classification map with good computational complexity and accuracy. The Simple Random, Cluster, Systematic, and Stratified Random sampling methods were used to validate the accuracy of the acquired LU/LC classification map. The proposed Fuzzy Swin Transformer model attains good results with an average classification accuracy of 98.43% using Simple Random Sampling, 97.45% using Stratified Random Sampling, 97.36% using Systematic Sampling, and 96.97% using Cluster Sampling. The LU/LC change detected in this work was considered an important source of information to support the concerned land resource planners in taking necessary action to preserve the land cover, exclusively for the forest-covered areas of the hill stations.","2024-04","2025-02-26 20:37:05","2025-02-26 20:37:05","","1745-1764","","2","17","","","","","","","","","","English","","","","WOS:001141987400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;92</p>","","","ALGORITHMS; AREAS; DYNAMICS; FOREST COVER; Fuzzy-swin transformer; Geographic information system; IMAGES; IMPACT; Land use / Land cover; Remote sensing; Sampling strategies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TRIC22PV","journalArticle","2022","Tang, AF; Deléger, L; Bossy, R; Zweigenbaum, P; Nédellec, C","Do syntactic trees enhance Bidirectional Encoder Representations from Transformers (BERT) models for chemical-drug relation extraction?","DATABASE-THE JOURNAL OF BIOLOGICAL DATABASES AND CURATION","","1758-0463","10.1093/database/baac070","","Collecting relations between chemicals and drugs is crucial in biomedical research. The pre-trained transformer model, e.g. Bidirectional Encoder Representations from Transformers (BERT), is shown to have limitations on biomedical texts; more specifically, the lack of annotated data makes relation extraction (RE) from biomedical texts very challenging. In this paper, we hypothesize that enriching a pre-trained transformer model with syntactic information may help improve its performance on chemical-drug RE tasks. For this purpose, we propose three syntax-enhanced models based on the domain-specific BioBERT model: Chunking-Enhanced-BioBERT and Constituency-Tree-BioBERT in which constituency information is integrated and a Multi-Task-Learning framework Multi-Task-Syntactic (MTS)-BioBERT in which syntactic information is injected implicitly by adding syntax-related tasks as training objectives. Besides, we test an existing model Late-Fusion which is enhanced by syntactic dependency information and build ensemble systems combining syntax-enhanced models and non-syntax-enhanced models. Experiments are conducted on the BioCreative VII DrugProt corpus, a manually annotated corpus for the development and evaluation of RE systems. Our results reveal that syntax-enhanced models in general degrade the performance of BioBERT in the scenario of biomedical RE but improve the performance when the subject-object distance of candidate semantic relation is long. We also explore the impact of quality of dependency parses.","2022-08-25","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","2022","","","","","","","","","","English","","","","WOS:000844279700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WC2XPGRY","journalArticle","2022","Reza, S; Ferreira, MC; Machado, JJM; Tavares, JMRS","A multi-head attention-based transformer model for traffic flow forecasting with a comparative analysis to recurrent neural networks","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2022.117275","","Traffic flow forecasting is an essential component of an intelligent transportation system to mitigate congestion. Recurrent neural networks, particularly gated recurrent units and long short-term memory, have been the stateof-the-art traffic flow forecasting models for the last few years. However, a more sophisticated and resilient model is necessary to effectively acquire long-range correlations in the time-series data sequence under analysis. The dominant performance of transformers by overcoming the drawbacks of recurrent neural networks in natural language processing might tackle this need and lead to successful time-series forecasting. This article presents a multi-head attention based transformer model for traffic flow forecasting with a comparative analysis between a gated recurrent unit and a long-short term memory-based model on PeMS dataset in this context. The model uses 5 heads with 5 identical layers of encoder and decoder and relies on Square Subsequent Masking techniques. The results demonstrate the promising performance of the transform-based model in predicting long-term traffic flow patterns effectively after feeding it with substantial amount of data. It also demonstrates its worthiness by increasing the mean squared errors and mean absolute percentage errors by (1.25 - 47.8)% and (32.4 - 83.8)%, respectively, concerning the current baselines.","2022-09-15","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","202","","","","","","","","","","English","","","","WOS:000804927600007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;121<br/>Total Times Cited:&nbsp;&nbsp;125<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Deep learning; Gated recurrent unit; Intelligent transportation system; Long short-term memory; PeMS; PREDICTION; Time-series forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3LNW59EX","journalArticle","2024","Muduli, K; Ghosh, I","Prediction of Vehicular Yielding Intention While Approaching a Pedestrian Crosswalk","TRANSPORTATION RESEARCH RECORD","","0361-1981","10.1177/03611981241252835","","This study proposes a novel approach for predicting vehicular yielding intention at pedestrian crosswalks, leveraging transformer-based deep-learning and multilayer perceptron for time-series data representation and classification, respectively. The model was trained using parameters obtained from real-world video feeds, which encompassed vehicle dynamics, pedestrian factors, and traffic context. The study compared the transformer-multilayer perceptron model with other models, such as recurrent neural network, long short-term memory, and gated recurrent unit, in predicting vehicular yielding intention. The transformer model achieved a superior performance with an accuracy of 94.47% compared with other models. This result was statistically validated using the Friedman test. The study used a 2-s prediction horizon, which improved its practical usefulness by giving pedestrians enough time to react to avoid dangerous situations. The study utilized attention scores from the transformer model to identify significant factors influencing yielding decisions. The analysis revealed that the number of visible pedestrians, time remaining to reach the crosswalk, and the behaviors of the preceding vehicle were key determinants of yielding decisions. This model has potential applications in developing advanced warning systems, integrating vehicle-to-pedestrian technology, and providing insights for traffic management policies and road infrastructure design. Future research could explore the integration of human factors and demographic information into the current model.","2024-12","2025-02-26 20:37:05","2025-02-26 20:37:05","","1751-1766","","12","2678","","","","","","","","","","English","","","","WOS:001250750900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","BEHAVIOR; data and data science; driver behavior; human factors; intelligent transportation systems; machine learning (artificial intelligence); pedestrians; safety; SAFETY; SPEED","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WHBXXL4V","journalArticle","2024","Chen, JT; Fu, XY; Zhang, LL; Shen, HY; Wu, JB","A novel offshore wind power prediction model based on TCN-DANet-sparse transformer and considering spatio-temporal coupling in multiple wind farms","ENERGY","","0360-5442","10.1016/j.energy.2024.132899","","Offshore wind power capacity is growing, leading to larger clustered farms. Accurately predicting offshore wind power capacity is crucial for power system stability; however, current studies often overlook neighbouring installations. To address this, this study presents the Temporal Convolutional Network-Dual Attention NetworkSparse Transformer (TCN-DANet-Sparse Transformer) model, which considers the spatiotemporal coupling of multiple wind farms. Before detailing our model, we review the existing prediction methods, noting their limitations in capturing interconnected adjacent wind farms. Our model integrates spatial information from nearby farms to enhance prediction reliability. Through Pearson Correlation Coefficient analysis, we explore the temporal and spatial coupling features. Using overlapping sliding windows, we partition farms into subsequences, processed with TCN-DANet for efficient spatio-temporal feature extraction. These features are then input into the Sparse Transformer to improve the computational efficiency. Validated using a dataset from Ka<spacing diaeresis>chele et al., our model outperforms the baseline on the London Wind Farm. In spring, for Case 1, the mean square error (MSE) of the main model decreased by 43.19 % compared to that of the TCN-DANet-transformer model. Similarly, for Case 2, the MSE of the main model is reduced by 41.69 %.","2024-11-01","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","308","","","","","","","","","","English","","","","WOS:001308636400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Dual attention network; NETWORK; Offshore wind power prediction; Sparse transformer; Spatio-temporal coupling; SPEED; SUPPORT VECTOR REGRESSION; Temporal convolutional network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T63YWBIX","journalArticle","2025","Cui, JH; Chen, YX; Wu, Z; Wu, HW; Wu, WH","A Driver Behavior Detection Model for Human-Machine Co-Driving Systems Based on an Improved Swin Transformer","WORLD ELECTRIC VEHICLE JOURNAL","","2032-6653","10.3390/wevj16010007","","Human-machine co-driving is an important stage in the development of automatic driving, and accurate recognition of driver behavior is the basis for realizing human-machine co-driving. However, traditional detection methods exhibit limitations in driver behavior detection, including low accuracy and slow processing efficiency. Aiming at these challenges, this paper proposes a driver behavior detection method that improves the Swin transformer model. First, the efficient channel attention (ECA) module is added after the self-attention mechanism of the Swin transformer model so that the channel features can be dynamically adjusted according to their importance, thus enhancing the model's attention to the important channel features. Then, the image preprocessing of the public State Farm dataset and expansion of the original image dataset is carried out. Then, the parameters of the model are tuned. Finally, through the comparison test with other models, an ablation test is performed to verify the performance of the proposed model. The results show that the proposed model algorithm has a better performance in 10 classifications of driver behavior detection, with an accuracy of 99.42%, which is improved by 3.8% and 1.68% compared to Vgg16 and MobileNetV2, respectively. It can provide a theoretical reference for the development of an intelligent automobile human-machine co-driving system.","2025-01","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","1","16","","","","","","","","","","English","","","","WOS:001404785000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","attention mechanism; deep learning; driver behavior detection; image processing; network training; RECOGNITION; shared autonomy; Swin transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"REA987RP","journalArticle","2024","Ben Hamida, S; Ben Hamida, S; Snoun, A; Jemai, O; Jemai, A","The influence of dropout and residual connection against membership inference attacks on transformer model: a neuro generative disease case study","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-023-16126-x","","Alzheimer's patients necessitate consistent support from caregivers or family members, highlighting the urgency for advanced technologies to aid in their daily lives through early disease detection. Consequently, there has been substantial research and development of machine learning-based systems aimed at assisting Alzheimer's patients. However, ensuring the protection of the sensitive and personal data utilized in these systems remains a critical concern. In this context, Membership Inference Attack poses a severe threat to the privacy of targeted models. This research focuses on enhancing the preservation of data privacy during the training phase. We conducted vulnerability testing on a Transformer deep-learning model against Membership Inference Attack and developed a defense strategy to mitigate its impact. To achieve this objective, we evaluated the studied attack on Transformer model using two datasets: DemCare and Oasis. These datasets contain sensitive and personal information, underscoring the need for their utmost protection. Subsequently, we proposed a defense strategy based on dropout and residual connections. Through comparative experiments, our proposed strategy demonstrated significant improvements (i.e. 20.97% and 18.43%) over the previous model, providing efficient results. Thus, we can confidently conclude that our defense approach enhances data privacy and effectively mitigates the impact of the analyzed attack.","2024-02","2025-02-26 20:37:05","2025-02-26 20:37:05","","16231-16253","","6","83","","","","","","","","","","English","","","","WOS:001027492600010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Alzheimer; Dropout; MIA; ML; Residual connection; Security and privacy; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9ZQ9R5FX","journalArticle","2022","Xie, P; Zhao, MY; Hu, XH","PiSLTRc: Position-Informed Sign Language Transformer With Content-Aware Convolution","IEEE TRANSACTIONS ON MULTIMEDIA","","1520-9210","10.1109/TMM.2021.3109665","","Since the superiority of Transformer in learning long-term dependency, the sign language Transformer model achieves remarkable progress in Sign Language Recognition (SLR) and Translation (SLT). However, there are several issues with the Transformer that prevent it from better sign language understanding. The first issue is that the self-attention mechanism learns sign video representation in a frame-wise manner, neglecting the temporal semantic structure of sign gestures. Secondly, the attention mechanism with absolute position encoding is direction and distance unaware, thus limiting its ability. To address these issues, we propose a new model architecture, namely PiSLTRc, with two distinctive characteristics: (i) content-aware and position-aware convolution layers. Specifically, we explicitly select relevant features using a novel content-aware neighborhood gathering method. Then we aggregate these features with position-informed temporal convolution layers, thus generating robust neighborhood-enhanced sign representation. (ii) injecting the relative position information to the attention mechanism in the encoder, decoder, and even encoder-decoder cross attention. Compared with the vanilla Transformer model, our model performs consistently better on three large-scale sign language benchmarks: PHOENIX-2014, PHOENIX-2014-T and CSL. Furthermore, extensive experiments demonstrate that the proposed method achieves state-of-the-art performance on translation quality with +1.6 BLEU improvements.","2022","2025-02-26 20:37:05","2025-02-26 20:37:05","","3908-3919","","","24","","","","","","","","","","English","","","","WOS:000838704400017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;23<br/>Total Times Cited:&nbsp;&nbsp;25<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","content-aware neighborhood gathering; FRAMEWORK; NETWORK; position-informed convolution; RECOGNITION; relative position encoding; Sign language recognition; sign language translation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AF3LU3Y7","journalArticle","2025","Zhang, JM; Zhang, FZ; Wei, HT","PSSS-EEG: A Probabilistic-masking Self-Supervised Swin-transformer model for EEG-based drowsiness recognition","PATTERN RECOGNITION","","0031-3203","10.1016/j.patcog.2024.111005","","Drowsiness recognition based on Electroencephalography (EEG) signals is a critical task with wide-ranging applications in areas such as transportation safety. However, existing methods for EEG-based drowsiness recognition have demonstrated limited performance in data-limited scenarios and struggle with capturing the diverse patterns among different subjects. In this paper, we propose a novel approach, the Probabilistic- masking Self-Supervised Swin-transformer model (PSSS-EEG), for accurate and robust EEG-based drowsiness recognition. The PSSS-EEG model integrates data augmentation and self-supervised learning techniques to improve the recognition accuracy and generalization ability of drowsiness recognition. Specifically, we introduce the incomplete probabilistic-masking operation to the data augmentation. Moreover, the swintransformer architecture is employed as the backbone of the self-supervised network to capture long-range dependencies at different scales in EEG data. The retention weights are introduced into the loss function as a linkage between data augmentation and self-supervised network. Experimental results demonstrate that our model outperforms existing methods in EEG-based drowsiness recognition accuracy, achieving an accuracy exceeding 80%. In addition, this work highlights the importance of advanced data augmentation techniques and self-supervised learning models. It also contributes to filling a crucial gap in the existing literature about the integration of data augmentation and self-supervised learning, providing a more effective and adaptable solution for EEG-based recognition.","2025-02","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","158","","","","","","","","","","English","","","","WOS:001320123500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Data augmentation; Drowsiness recognition; Electroencephalography (EEG); Self-supervised learning; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2799SWKA","journalArticle","2024","Abed, M; Imteaz, MA; Huang, YF; Ahmed, AN","Self-attention transformer model for pan evaporation prediction: a case study in Australia","JOURNAL OF HYDROINFORMATICS","","1464-7141","10.2166/hydro.2024.104","","In drought-prone regions like Australia, accurately assessing evaporation rates is essential for effectively managing and maximising the use of precious water resources and reservoirs. Current estimates show that evaporation reduces Australia's open water lake capacity by about 40% annually. With climate change, this water loss is expected to become an even greater concern. This study investigates a transformer-based neural network (TNN) to estimate monthly evaporation in three Australian locations. The models were trained and tested using monthly weather data spanning from 2009 to 2022. Input parameters were chosen based on Pearson's correlation coefficient values to identify the most impactful combinations. The developed TNN model was compared with two widely used empirical methods, namely Thornthwaite and Stephens and Stewart. The TNN model's impressive accuracy in evaporation prediction, attributed to its unique self-attention mechanism, suggests its promising potential for future use in evaporation forecasting. Additionally, the study revealed an intriguing result: Despite using the same input datasets, the TNN model surpassed traditional methods, achieving an average improvement of 18% in prediction accuracy. The TNN prediction model accurately predicts water loss (average R-2 = 0.970), supports irrigation management and agricultural planning and offers financial benefits to farming and related industries.","2024-10","2025-02-26 20:37:05","2025-02-26 20:37:05","","2538-2556","","10","26","","","","","","","","","","English","","","","WOS:001300339400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","CLASSIFICATION; evaporation; EVAPOTRANSPIRATION; NEURAL-NETWORKS; self-attention; Stephens and Stewart model; TEMPERATURE; Thornthwaite model; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HUVXN8XM","journalArticle","2024","Dong, HG; Tang, PW; He, B; Chen, L; Zhang, ZZ; Jia, CQ","Multi-step solar radiation prediction using transformer: A case study from solar radiation data in Tokyo","JOURNAL OF BUILDING PHYSICS","","1744-2591","10.1177/17442591231218831","","The widespread advancement of computer technology resulted in the increasing usage of deep learning models for predicting solar radiation. Numerous studies have been conducted to explore their research potential. Nevertheless, the application of deep learning models in optimizing building energy systems, particularly in a multi-step solar radiation prediction model for model predictive control (MPC), remains a challenging task. This is mainly due to the intricacy of the time series and the possibility of accumulating errors in multistep forecasts. In this study, we propose the development of a transformer-based attention model for predicting multi-step solar irradiation at least 24 h in advance. The model is trained and tested using measured solar irradiation data and temperature forecast data obtained from the Tokyo Meteorological Agency. The findings indicate that the transformer model has the capability to effectively mitigate the issue of error accumulation. Additionally, the generative model exhibits a significant improvement in accuracy, with a 62.35% increase when compared to the conventional regression LSTM model. Additionally, the transformer model has been shown to attain superior prediction stability, mitigate the effects of error accumulation in multi-step forecasting, and circumvent training challenges stemming from gradient propagation issues that can occur with recurrent neural networks.","2024-01","2025-02-26 20:37:05","2025-02-26 20:37:05","","421-438","","4","47","","","","","","","","","","English","","","","WOS:001139657200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","deep learning; ENERGY; interpretable deep learning; multi-step prediction; Solar radiation; time series data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C7WIMMGJ","journalArticle","2025","Uhe, P; Lucas, C; Hawker, L; Brine, M; Wilkinson, H; Cooper, A; Saoulis, AA; Savage, J; Sampson, C","FathomDEM: an improved global terrain map using a hybrid vision transformer model","ENVIRONMENTAL RESEARCH LETTERS","","1748-9326","10.1088/1748-9326/ada972","","The Earth's terrain is linked to many physical processes, and gaining the most accurate representation is key to work in many sectors from engineering to natural hazards modeling and ecology. Existing global digital elevation models (DEMs) are widely used, however often suffer from systematic biases caused by trees, buildings and instrumentation error, ultimately limiting their effectiveness. We present here, FathomDEM, a new global 30 m DEM produced using a novel application of a hybrid vision transformer model. This model removes surface artifacts from a global radar DEM, Copernicus DEM, aligning it more closely with true topography. In addition to improving on other global DEMs, FathomDEM also has reduced error compared to coastal-focussed DEMs such as the recent DeltaDTM. This demonstrates its impressive capacity to perform for specific landscapes, while being trained globally to model a wide range of terrain types. FathomDEM has been tested on the downstream task of flood modeling, showing increased accuracy compared to those run with the previous best global DEM, FABDEM, approaching the performance of LiDAR based flood modeling. This improvement is attributed to FathomDEM's smaller error and substantial reduction in artifacts. This shows the suitability of FathomDEM for applied tasks and strengthens our evaluation compared to one based on vertical error alone.","2025-03-01","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","3","20","","","","","","","","","","English","","","","WOS:001418107900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","digital elevation model; LAND; machine learning; PRODUCT; remote sensing; SRTM; terrain; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FABSYBMF","journalArticle","2024","Jarraya, SK; Masmoudi, M","Hybrid 3D Convolutional-Transformer Model for Detecting Stereotypical Motor Movements in Autistic Children During Pre-Meltdown Crisis","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app142311458","","Computer vision using deep learning algorithms has served numerous human activity identification applications, particularly those linked to safety and security. However, even though autistic children are frequently exposed to danger as a result of their activities, many computer vision experts have shown little interest in their safety. Several autistic children show severe challenging behaviors such as the Meltdown Crisis which is characterized by hostile behaviors and loss of control. This study aims to introduce a monitoring system capable of predicting the Meltdown Crisis condition early and alerting the children's parents or caregivers before entering more difficult settings. For this endeavor, the suggested system was constructed using a combination of a pre-trained Vision Transformer (ViT) model (Swin-3D-b) and a Residual Network (ResNet) architecture to extract robust features from video sequences to extract and learn the spatial and temporal features of the Stereotyped Motor Movements (SMMs) made by autistic children at the beginning of the Meltdown Crisis state, which is referred to as the Pre-Meltdown Crisis state. The evaluation was conducted using the MeltdownCrisis dataset, which contains realistic scenarios of autistic children's behaviors in the Pre-Meltdown Crisis state, with data from the Normal state serving as the negative class. Our proposed model achieved great classification accuracy, at 92%.","2024-12","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","23","14","","","","","","","","","","English","","","","WOS:001376313100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","autism; deep learning approaches; hybrid 3D convolutional-transformer model; pre-meltdown crisis; stereotypical motor movements","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZQ26DP8L","journalArticle","2024","Ji, Y; Luo, YX; Lu, AX; Xia, DY; Yang, LX; Liew, AWC","Galformer: a transformer with generative decoding and a hybrid loss function for multi-step stock market index prediction","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-72045-3","","The prediction of stock market fluctuations is crucial for decision-making in various financial fields. Deep learning algorithms have demonstrated outstanding performance in stock market index prediction. Recent research has also highlighted the potential of the Transformer model in enhancing prediction accuracy. However, the Transformer faces challenges in multi-step stock market forecasting, including limitations in inference speed for long sequence prediction and the inadequacy of traditional loss functions to capture the characteristics of noisy, nonlinear stock history data. To address these issues, we introduce an innovative transformer-based model with generative decoding and a hybrid loss function, named ""Galformer,"" tailored for the multi-step prediction of stock market indices. Galformer possesses two distinctive characteristics: (1) a novel generative style decoder that predicts long time-series sequences in a single forward operation, significantly boosting the speed of predicting long sequences; (2) a novel loss function that combines quantitative error and trend accuracy of the predicted results, providing feedback and optimizing the transformer-based model. Experimental results on four typical stock market indices, namely the CSI 300 Index, S&P 500 Index, Dow Jones Industrial Average Index (DJI), and Nasdaq Composite Index (IXIC), affirm that Galformer outperforms other classical methods, effectively optimizing the Transformer model for stock market prediction.","2024-10-10","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","1","14","","","","","","","","","","English","","","","WOS:001337092300049","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Deep learning; Galformer; Stock index prediction; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PXV3B5KX","journalArticle","2024","Zhang, HZ; Shafiq, MO","Survey of transformers and towards ensemble learning using transformers for natural language processing","JOURNAL OF BIG DATA","","2196-1115","10.1186/s40537-023-00842-0","","The transformer model is a famous natural language processing model proposed by Google in 2017. Now, with the extensive development of deep learning, many natural language processing tasks can be solved by deep learning methods. After the BERT model was proposed, many pre-trained models such as the XLNet model, the RoBERTa model, and the ALBERT model were also proposed in the research community. These models perform very well in various natural language processing tasks. In this paper, we describe and compare these well-known models. In addition, we also apply several types of existing and well-known models which are the BERT model, the XLNet model, the RoBERTa model, the GPT2 model, and the ALBERT model to different existing and well-known natural language processing tasks, and analyze each model based on their performance. There are a few papers that comprehensively compare various transformer models. In our paper, we use six types of well-known tasks, such as sentiment analysis, question answering, text generation, text summarization, name entity recognition, and topic modeling tasks to compare the performance of various transformer models. In addition, using the existing models, we also propose ensemble learning models for the different natural language processing tasks. The results show that our ensemble learning models perform better than a single classifier on specific tasks.","2024-02-04","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","1","11","","","","","","","","","","English","","","","WOS:001156909400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Ensemble learning; Natural language tasks; Transformer model; Transformer-based model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CLACH7W2","journalArticle","2024","Le, TD; Macabiau, C; Albert, K; Jouvet, P; Noumeir, R","A Novel Transformer-Based Self-Supervised Learning Method to Enhance Photoplethysmogram Signal Artifact Detection","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3488595","","Recent research has revealed that traditional machine learning methods, such as semi-supervised label propagation and K-nearest neighbors, outperform Transformer-based models in artifact detection from photoplethysmogram (PPG) signals, mainly when data is limited. This study addresses the underutilization of abundant unlabeled data by employing self-supervised learning (SSL) to extract latent features from these data, followed by fine-tuning on labeled data. Our experiments demonstrate that SSL significantly enhances the Transformer model's ability to learn representations, improving its robustness in artifact classification tasks. Among various SSL techniques-including masking, contrastive learning, and DINO (self-distillation with no labels)-contrastive learning exhibited the most stable and superior performance in small PPG datasets. Further, we delve into optimizing contrastive loss functions, which are crucial for contrastive SSL. Inspired by InfoNCE, we introduce a novel contrastive loss function that facilitates smoother training and better convergence, thereby enhancing performance in artifact classification. In summary, this study establishes the efficacy of SSL in leveraging unlabeled data, particularly in enhancing the capabilities of the Transformer model in PPG artifact detection. This approach holds promise for broader applications in PICU environments, where annotated data is often limited.","2024","2025-02-26 20:37:05","2025-02-26 20:37:05","","159860-159874","","","12","","","","","","","","","","English","","","","WOS:001349771100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Accuracy; ALGORITHM; artifact detection; BLOOD-PRESSURE; Circuit faults; Clinical diagnosis; Clinical PPG signals; contrastive learning; Contrastive learning; Data models; Feature extraction; Filtering; HEART-RATE; imbalanced classes; Monitoring; MOTION; Motion artifacts; self-supervised; Standards; Training; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8AIKEQG6","journalArticle","2024","Li, PC; Wang, HQ; Wang, Z; Wang, K; Wang, C","Swin Routiformer: Moss Classification Algorithm Based on Swin Transformer With Bi-Level Routing Attention","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3387541","","Accurate classification of moss species is essential for progress in ecology and biology. However, traditional methods for classifying moss require significant expertise, and current deep learning techniques struggle due to limited dataset diversity and poor performance in multi-class classification tasks. To overcome these challenges, we proposed the Swin Routiformer, a new algorithm for moss image classification that enhances the Swin Transformer with bi-level routing attention. Addressing the issue of limited data, we constructed a dataset with images of 110 different moss types. Additionally, we propose the Crop-Similar data augmentation algorithm, specifically designed for moss images, to reduce background noise interference and prevent information loss due to feature scaling. Adopting the Swin Transformer model with its multi-level hierarchical architecture for visual feature extraction, we introduce the Swin Routiformer Block, which enhances the network's feature interaction capabilities, reduces computational complexity, and improves classification accuracy and image processing speed for moss species. Our experimental results show that the Swin Routiformer achieves a top-1 accuracy of 82.19% and an f1-score of 82.79% on the test set, outperforming most mainstream models by 4.53% and 1.81% respectively compared to the baseline Swin Transformer model. These findings establish the Swin Routiformer as a valuable tool for the precise identification of moss species, offering significant contributions to the related fields.","2024","2025-02-26 20:37:05","2025-02-26 20:37:05","","53396-53407","","","12","","","","","","","","","","English","","","","WOS:001205766400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","attention mechanism; deep learning; image classification; Moss classification; swin transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DTX3GE8F","journalArticle","2023","Wu, GP; Wang, CY; Gao, LN; Xue, JN","Hybrid Swin Transformer-Based Classification of Gaze Target Regions","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3335249","","Inferring gaze targeting or gaze following is an effective approach for comprehending human behavior and intentions. This paper employs a non-intrusive appearance-based tracking technique, utilizing a binocular stereo vision camera to capture the face image and head pose to address errors caused by problems such as the disappearance of the eye image and head deflection occlusion in image capture. Each gaze direction is determined based on a single image frame. To improve the classification and detection of the gaze target region by effectively handling head motion and view direction, this paper proposes a hybrid structure for the Swin Transformer gaze target region classification method. The facial image features are extracted using both the ResNet50 model and the Swin Transformer model, followed by fusing head pose features to categorise the gaze target area. The study also compares the classification effects of various structural models. The analysis of the results demonstrates that the hybrid Swin Transformer model outperforms in classifying and detecting the gaze target region, achieving an accuracy rate of 90%. Finally, the research examines the gaze of flight trainees during flight missions by using a heatmap, which lays the groundwork for future analyses of pilot attention and operational intentions during flights.","2023","2025-02-26 20:37:05","2025-02-26 20:37:05","","132055-132067","","","11","","","","","","","","","","English","","","","WOS:001121804900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Classification algorithms; computer vision; Computer vision; Estimation; EYE GAZE; Feature extraction; Gaze estimation; Gaze tracking; Head; region classification; swin transformer; Target tracking; Transformers; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VB9RNC3K","journalArticle","2022","Zhang, K; Li, X; Su, J","Variable Support Segment-Based Short-Term Wind Speed Forecasting","ENERGIES","","1996-1073","10.3390/en15114067","","Accurate short-term wind speed forecasting plays an important role in the development of wind energy. However, the inertia of airflow means that wind speed has the properties of time variance and inertia, which pose a challenge in the task of wind speed forecasting. We employ the variable support segment method to describe these two properties. We then propose a variable support segment-based short-term wind speed forecasting model to improve wind speed forecasting accuracy. The core idea is to adaptively determine the variable support segment of the future wind speed by a self-attention mechanism. Historical wind speed series are first decomposed into several components by variational mode decomposition (VMD). Then, the future values of each component are forecast using a modified Transformer model. Finally, the forecasting values of these components are summed to obtain the future wind speed forecasting values. Wind speed data collected from a wind farm were employed to validate the performance of the proposed model. The mean absolute error of the proposed model in spring, summer, autumn, and winter is 0.25, 0.33, 0.31, and 0.29, respectively. Experimental results show that the proposed model achieves significant accuracy and that the modified Transformer model has good performance.","2022-06","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","11","15","","","","","","","","","","English","","","","WOS:000809057900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","attention mechanism; EMPIRICAL MODE DECOMPOSITION; ENSEMBLE; MULTISTEP; NEURAL-NETWORK; OPTIMIZATION; STRATEGY; TIME-SERIES; Transformer; variable support segment; VMD; wind speed forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZUZA6XT9","journalArticle","2024","Chen, LW; Liu, ZB; Yu, QQ; Jiang, X; Zhang, HH; Lin, X","Prediction and analysis of relative error in electric vehicle charging stations based on an improved ConvFormer model","HELIYON","","2405-8440","10.1016/j.heliyon.2024.e35840","","In order to address the issue of metering inaccuracies in charging stations that directly affect the development of electric vehicles, a prediction method for the relative error of charging stations based on the ConvFormer model is proposed. The model combines Convolutional Neural Networks (CNN) with Transformer models in parallel, significantly improving the prediction accuracy. First, charging station data is preprocessed using forward interpolation and normalization methods, and the dataset is transformed into a dataset of input relative errors. Then, a neural network with an improved unidirectional convolutional and attention combination for time-series forecasting is constructed, and common regression performance evaluation metrics, MAE (Mean Absolute Error) and MSE (Mean Squared Error), are selected for evaluation. Finally, based on seven days of charging station data, the relative error of charging stations for the next 24 h is predicted, and compared to traditional Transformer and LSTM (Long Short-Term Memory) timeseries models. The results show that the improved model yields the lowest values for both MAE and MSE, with a 47.30 % reduction in MAE compared to the Transformer model and a 38.06 % reduction compared to LSTM, and a 66.94 % reduction in MSE compared to the Transformer model and approximately 62.32 % reduction compared to LSTM.","2024-08-30","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","16","10","","","","","","","","","","English","","","","WOS:001298223900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","Artificial intelligence; ConvFormer; Neural network; Relative errorr of charging stations; Time series forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AVJNSN3W","journalArticle","2023","Pillay, MT; Minakawa, N; Kim, Y; Kgalane, N; Ratnam, JV; Behera, SK; Hashizume, M; Sweijd, N","Utilizing a novel high-resolution malaria dataset for climate-informed predictions with a deep learning transformer model","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-023-50176-3","","Climatic factors influence malaria transmission via the effect on the Anopheles vector and Plasmodium parasite. Modelling and understanding the complex effects that climate has on malaria incidence can enable important early warning capabilities. Deep learning applications across fields are proving valuable, however the field of epidemiological forecasting is still in its infancy with a lack of applied deep learning studies for malaria in southern Africa which leverage quality datasets. Using a novel high resolution malaria incidence dataset containing 23 years of daily data from 1998 to 2021, a statistical model and XGBOOST machine learning model were compared to a deep learning Transformer model by assessing the accuracy of their numerical predictions. A novel loss function, used to account for the variable nature of the data yielded performance around + 20% compared to the standard MSE loss. When numerical predictions were converted to alert thresholds to mimic use in a real-world setting, the Transformer's performance of 80% according to AUROC was 20-40% higher than the statistical and XGBOOST models and it had the highest overall accuracy of 98%. The Transformer performed consistently with increased accuracy as more climate variables were used, indicating further potential for this prediction framework to predict malaria incidence at a daily level using climate data for southern Africa.","2023-12-28","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","1","13","","","","","","","","","","English","","","","WOS:001134102400009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","RAINFALL; TEMPERATURE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WJ9663BQ","journalArticle","2023","Karatay, B; Bestepe, D; Sailunaz, K; Özyer, T; Alhajj, R","CNN-Transformer based emotion classification from facial expressions and body gestures","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-023-16342-5","","Classifying the correct emotion from different data sources such as text, images, videos, and speech has been an inspiring research area for researchers from various disciplines. Automatic emotion detection from videos and images is one of the most challenging tasks that have been analyzed using supervised and unsupervised machine learning methods. Deep learning has been also employed where the model has been trained by facial and body features using pose and landmark detectors and trackers. In this paper, facial and body features extracted by the OpenPose tool have been used for detecting basic 6, 7 and 9 emotions from videos and images by a novel deep neural network framework which combines the Gaussian mixture model with CNN, LSTM and Transformer to generate the CNN-LSTM model and CNN-Transformer model with and without Gaussian centers. The experiments which were conducted using two benchmark datasets, namely FABO and CK+, showed that the proposed transformer model with 9 and 12 Gaussian centers with video generation approach was able to achieve close to 100% classification accuracy for the FABO dataset which outperforms the other DNN frameworks for emotion detection. It reported over 90% accuracy for most combinations of features for both datasets leading to a comparable framework for video emotion classification.","2023-08-12","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","","","","","","","","","","","English","","","","WOS:001046958100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","Body gesture; CNN; DATABASES; DEEP; Emotion classification; Emotion detection; Gaussian mixture model; LSTM; MODEL; RECOGNITION; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WNQFZ7QT","journalArticle","2022","Tian, NN; Liu, Y; Sun, ZR; Liu, XB","Clustering- and Transformer-Based Networks for the Style Analysis of Logo Images","COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE","","1687-5265","10.1155/2022/2090712","","In the design field, designers need to investigate and collect logo materials before designing logos and search a large number of design materials on well-known logo websites to find logos with similar styles as reference images. However, manual work is time-consuming and labor-intensive. To solve this problem, we propose a clustering method that uses K-Means clustering and visual transformer model to group the styles of the logo database. Specifically, we use the visual transformer model as a feature extractor to convert logo images into feature vectors and perform K-Means clustering, use the clustering results as pseudo-labels to further train the feature extractor, and continue to iterate the above process to finally obtain reliable clustering results. We validate our approach by creating the logo image dataset JN Logo, a proposed database for image quality and style attributes, containing 14922 logo design images. Our proposed deep transformer-based cluster (DTCluster) automatic style grouping method is used in JN Logo; the DBI reaches 0.904, and the DI reaches 0.189, which are better than those of other K-Means clustering methods and other clustering algorithms. We perform a subjective analysis of five features of the clustering results to obtain a semantic description of the clusters. Finally, we provide six styles and five semantic descriptions for the logo database.","2022-05-09","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","2022","","","","","","","","","","English","","","","WOS:000805436800004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","FEATURES; RECOGNITION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XFCCE32T","journalArticle","2024","Megalingam, RK; Menon, GG; Binoj, S; Sai, DA; Kunnambath, AR; Manoharan, SK","Cowpea leaf disease identification using deep learning","SMART AGRICULTURAL TECHNOLOGY","","2772-3755","10.1016/j.atech.2024.100662","","The identification of plant/crop diseases is of great interest to agriculture and in turn, the growth of nations. A systematic way of grouping different plant and crop diseases is essential for identifying and cataloguing the extensive information collected about the many different known plant diseases. There has been no significant research on classifying diseases in cowpea plants. This research employs Vision transformer model to classify the diseases found in the Cowpea plant, a native plant found in Kerala. Classifying diseases affecting cowpea leaves is a vital aspect of crop management and protection. Understanding the specific types of diseases present in a crop facilitates early detection and helps implement control measures. Accurate disease classification provides valuable insights into the impact of the disease on the crop. Along with this, for each classified disease, a Possible Treatments and Prevention Methods suggestion is proposed. Six deep learning models-InceptionV3, VGG16, VGG19, Ensemble model, CNN and Vision Transformer (ViT) models were compared for the prediction of diseases in cowpea plants using a dataset of 5100 images of diseases of cowpea plant leaves. ViT outperformed other models with accuracy of 96%. Disease classification helps monitor the disease's spread and evolution, leading to a better understanding of its impact on cowpea production and the development of more effective control methods for researchers, farmers, and agronomists.","2024-12","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","9","","","","","","","","","","English","","","","WOS:001370840600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Cowpea plants; Deep learning; Plant disease classification; Treatment and prevention methods; Vision transformer model (ViT)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T2CM52D3","journalArticle","2024","Bei, TY; Xiao, JM; Wang, XH","Transient Stability Assessment of Power Systems Based on the Transformer and Neighborhood Rough Set","ELECTRONICS","","2079-9292","10.3390/electronics13020270","","Modern power systems are large in size and complex in features; the data collected by Phasor Measurement Units (PMUs) are often noisy and contaminated; and the machine learning models that have been applied to the transient stability assessment (TSA) of power systems are not sufficiently capable of capturing long-distance dependencies. All these issues make it difficult for data mining-based power system TSA methods to have sufficient accuracy, timeliness, and robustness. To solve this problem, this paper proposes a power system TSA model based on the transformer and neighborhood rough set. The model first uses the neighborhood rough set to deal with the redundant features of the power system trend data and then uses the transformer model to train the TSA model, in which various normalization methods such as Batch Normalization and Layer Normalization are introduced in the process to obtain better evaluation performance and speed up the convergence rate of the model. Finally, the model is evaluated by two evaluation indicators, F1-measure and accuracy, with values of 99.61% for accuracy and 0.9972 for F1-measure, as soon as the tests on noise contamination and missing data test results on the IEEE39 system show that the NRS-Transformer model proposed in this paper is superior in terms of prediction accuracy, training speed, and robustness.","2024-01","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","2","13","","","","","","","","","","English","","","","WOS:001149329400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","neighborhood rough set; normalization methods; power system transient stability assessment; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VUJP3W4U","journalArticle","2022","Bi, CG; Hu, N; Zou, YQ; Zhang, S; Xu, SZ; Yu, HL","Development of Deep Learning Methodology for Maize Seed Variety Recognition Based on Improved Swin Transformer","AGRONOMY-BASEL","","2073-4395","10.3390/agronomy12081843","","In order to solve the problems of high subjectivity, frequent error occurrence and easy damage of traditional corn seed identification methods, this paper combines deep learning with machine vision and the utilization of the basis of the Swin Transformer to improve maize seed recognition. The study was focused on feature attention and multi-scale feature fusion learning. Firstly, input the seed image into the network to obtain shallow features and deep features; secondly, a feature attention layer was introduced to give weights to different stages of features to strengthen and suppress; and finally, the shallow features and deep features were fused to construct multi-scale fusion features of corn seed images, and the seed images are divided into 19 varieties through a classifier. The experimental results showed that the average precision, recall and F1 values of the MFSwin Transformer model on the test set were 96.53%, 96.46%, and 96.47%, respectively, and the parameter memory is 12.83 M. Compared to other models, the MFSwin Transformer model achieved the highest classification accuracy results. Therefore, the neural network proposed in this paper can classify corn seeds accurately and efficiently, could meet the high-precision classification requirements of corn seed images, and provide a reference tool for seed identification.","2022-08","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","8","12","","","","","","","","","","English","","","","WOS:000846410900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;33<br/>Total Times Cited:&nbsp;&nbsp;35<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","CLASSIFICATION; CONVOLUTIONAL NEURAL-NETWORKS; corn seeds; deep learning; IDENTIFICATION; image identification; machine vision; multi-scale feature fusion; SSR MARKERS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AJN668V9","journalArticle","2025","Zhao, J; Yao, W; Gao, HL; Kuang, ZJ; Shi, LJ; Wang, H; Dang, ZZ","Degenerative Disease Diagnosis and Analysis Based on Tissue Specificity of DNA Methylation","INTERNATIONAL JOURNAL OF MOLECULAR SCIENCES","","1661-6596","10.3390/ijms26020452","","The tissue specificity of DNA methylation refers to the significant differences in DNA methylation patterns in different tissues. This specificity regulates gene expression, thereby supporting the specific functions of each tissue and the maintenance of normal physiological activities. Abnormal tissue-specific patterns of DNA methylation are closely related to age-related diseases. This abnormal methylation pattern affects the regulation of gene expression, which may lead to changes in cell function and promote the occurrence of pathological conditions. By analyzing the differences in these methylation patterns, key CpG sites for disease diagnosis can be effectively screened. The main goal of this paper is to use the characteristics associated with tissue-specific abnormal expression and disease to construct an age-related disease diagnosis model. First, we combined chi-square tests and logistic regression to identify tissue-specific and disease-specific CpG sites, laying the foundation for accurate medical diagnosis, and verified the biological relevance of these CpG sites through enrichment analysis. Then we used the Transformer model to fit these CpG sites and realized the automatic diagnosis of age-related diseases. Our work proves that the tissue specificity of DNA methylation has the potential to diagnose age-related diseases, and proves the scientific nature of our proposed diagnostic method from a biological perspective.","2025-01","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","2","26","","","","","","","","","","English","","","","WOS:001404316800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","chi-square analysis; CpG site; disease specificity; DNA methylation; logistic regression; tissue specificity; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FV9SZNX4","journalArticle","2023","Shintani, J; Ogoshi, Y","Detection of Neural Fatigue State by Speech Analysis Using Chaos Theory","SENSORS AND MATERIALS","","0914-4935","10.18494/SAM4334","","Fatigue is a state of reduced physical activity with a distinctive feeling of discomfort and desire for rest caused by excessive physical and mental activity or illness. Until now, fatigue has been detected by listening to subjective fatigue levels or by measuring reactive oxygen species in the blood, but there is a need for a method that can immediately and easily measure fatigue. In this study, a fatigue task was created on a tablet device and administered continuously for 120 min to induce a temporary neurological state. We recorded the study participants' voices before and after the fatigue task and examined whether their neural fatigue could be detected using an analysis method based on chaos theory. The analysis showed that cerebral exponent macro (CEM) values, which indicate brain arousal, decreased significantly after the task, except in cases in which concentration on the task seemed to be insufficient.","2023","2025-02-26 20:37:05","2025-02-26 20:37:05","","2205-2213","","7","35","","","","","","","","","","English","","","","WOS:001031765800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","brain arousal level; chaos theory; fatigue state; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K2PL9DFI","journalArticle","2025","Chen, KT; Bandara, DSV; Arata, J","A real-time approach for surgical activity recognition and prediction based on transformer models in robot-assisted surgery","INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY","","1861-6410","10.1007/s11548-024-03306-9","","PurposeThis paper presents a deep learning approach to recognize and predict surgical activity in robot-assisted minimally invasive surgery (RAMIS). Our primary objective is to deploy the developed model for implementing a real-time surgical risk monitoring system within the realm of RAMIS.MethodsWe propose a modified Transformer model with the architecture comprising no positional encoding, 5 fully connected layers, 1 encoder, and 3 decoders. This model is specifically designed to address 3 primary tasks in surgical robotics: gesture recognition, prediction, and end-effector trajectory prediction. Notably, it operates solely on kinematic data obtained from the joints of robotic arm.ResultsThe model's performance was evaluated on JHU-ISI Gesture and Skill Assessment Working Set dataset, achieving highest accuracy of 94.4% for gesture recognition, 84.82% for gesture prediction, and significantly low distance error of 1.34 mm with a prediction of 1 s in advance. Notably, the computational time per iteration was minimal recorded at only 4.2 ms.ConclusionThe results demonstrated the excellence of our proposed model compared to previous studies highlighting its potential for integration in real-time systems. We firmly believe that our model could significantly elevate realms of surgical activity recognition and prediction within RAS and make a substantial and meaningful contribution to the healthcare sector.","2025-01-12","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","","","","","","","","","","","English","","","","WOS:001394829200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Deep learning; Robot-assisted surgery; Surgical activity recognition; Trajectory prediction; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G4NFHYII","journalArticle","2024","Alberts, M; Laino, T; Vaucher, AC","Leveraging infrared spectroscopy for automated structure elucidation","COMMUNICATIONS CHEMISTRY","","2399-3669","10.1038/s42004-024-01341-w","","The application of machine learning models in chemistry has made remarkable strides in recent years. While analytical chemistry has received considerable interest from machine learning practitioners, its adoption into everyday use remains limited. Among the available analytical methods, Infrared (IR) spectroscopy stands out in terms of affordability, simplicity, and accessibility. However, its use has been limited to the identification of a selected few functional groups, as most peaks lie beyond human interpretation. We present a transformer model that enables chemists to leverage the complete information contained within an IR spectrum to directly predict the molecular structure. To cover a large chemical space, we pretrain the model using 634,585 simulated IR spectra and fine-tune it on 3,453 experimental spectra. Our approach achieves a top-1 accuracy of 44.4% and top-10 accuracy of 69.8% on compounds containing 6 to 13 heavy atoms. When solely predicting scaffolds, the model accurately predicts the top-1 scaffold in 84.5% and among the top-10 in 93.0% of cases. Infrared spectroscopy stands out as an analytical tool for its affordability, simplicity, and accessibility, however, its use has been limited to the identification of a select few functional groups, as most peaks lie beyond human interpretation. Here, the authors use a transformer model that enables chemists to leverage all information contained within an IR spectrum to directly predict the molecular structure.","2024-11-16","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","1","7","","","","","","","","","","English","","","","WOS:001355653200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","IDENTIFICATION; LIBRARY; PREDICTION; SMILES; SPECTRA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZD75EI36","journalArticle","2023","Yu, ZH; Lee, FF; Chen, Q","HCT-net: hybrid CNN-transformer model based on a neural architecture search network for medical image segmentation","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-023-04570-z","","Considering that many manually designed convolutional neural networks (CNNs) for different tasks that require considerable time, labor, and domain knowledge have been designed in the medical image segmentation domain and that most CNN networks only consider local feature information while ignoring the global receptive field due to the convolution limitation, there is still much room for performance improvement. Therefore, designing a new method that can fully capture feature information and save considerable time and human energy with less GPU memory consumption and complexity is necessary. In this paper, we propose a novel hybrid CNN-transformer model based on a neural architecture search network (HCT-Net), which designs a hybrid U-shaped CNN with a key-sampling Transformer backbone that considers contextual and long-range pixel information in the search space and uses a single-path neural architecture search that contains a flexible search space and an efficient search strategy to simultaneously find the optimal subnetwork including three types of cells during SuperNet. Compared with various types of medical image segmentation methods, our framework can achieve competitive precision and efficiency on various datasets, and we also validate the generalization on unseen datasets in extended experiments. In this way, we can verify that our method is competitive and robust. The code for the method is available at .","2023-09","2025-02-26 20:37:05","2025-02-26 20:37:05","","19990-20006","","17","53","","","","","","","","","","English","","","","WOS:000956204200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Convolutional neural network (CNN); Medical image segmentation; Neural architecture search (NAS); Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JW3454DE","journalArticle","2024","Zheng, HX; Hou, HF; Qin, ZY","Research on a Non-Stationary Groundwater Level Prediction Model Based on VMD-iTransformer and Its Application in Sustainable Water Resource Management of Ecological Reserves","SUSTAINABILITY","","2071-1050","10.3390/su16219185","","The precise forecasting of groundwater levels significantly influences plant growth and the sustainable management of ecosystems. Nonetheless, the non-stationary characteristics of groundwater level data often hinder the current deep learning algorithms from precisely capturing variations in groundwater levels. We used Variational Mode Decomposition (VMD) and an enhanced Transformer model to address this issue. Our objective was to develop a deep learning model called VMD-iTransformer, which aims to forecast variations in the groundwater level. This research used nine groundwater level monitoring stations located in Hangjinqi Ecological Reserve in Kubuqi Desert, China, as case studies to forecast the groundwater level over four months. To enhance the predictive performance of VMD-iTransformer, we introduced a novel approach to model the fluctuations in groundwater levels in the Kubuqi Desert region. This technique aims to achieve precise predictions of the non-stationary groundwater level conditions. Compared with the classic Transformer model, our deep learning model more effectively captured the non-stationarity of groundwater level variations and enhanced the prediction accuracy by 70% in the test set. The novelty of this deep learning model lies in its initial decomposition of multimodal signals using an adaptive approach, followed by the reconfiguration of the conventional Transformer model's structure (via self-attention and inversion of a feed-forward neural network (FNN)) to effectively address the challenge of multivariate time prediction. Through the evaluation of the prediction results, we determined that the method had a mean absolute error (MAE) of 0.0251, a root mean square error (RMSE) of 0.0262, a mean absolute percentage error (MAPE) of 1.2811%, and a coefficient of determination (R2) of 0.9287. This study validated VMD and the iTransformer deep learning model, offering a novel modeling approach for precisely predicting fluctuations in groundwater levels in a non-stationary context, thereby aiding sustainable water resource management in ecological reserves. The VMD-iTransformer model enhances projections of the water level, facilitating the reasonable distribution of water resources and the long-term preservation of ecosystems, providing technical assistance for ecosystems' vitality and sustainable regional development.","2024-11","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","21","16","","","","","","","","","","English","","","","WOS:001352067800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","groundwater level; Kubuqi Desert; non-stationarity; REGRESSION; sustainable; TABLE; VMD-iTransformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5Y36CK7T","journalArticle","2025","Liu, SQ; Liu, ZS; Chen, DL; Dai, WC; Zhou, L; Liu, Z; Cheung, RCC; Koç, ÇK","MLFormer: a high performance MPC linear inference framework for transformers","JOURNAL OF CRYPTOGRAPHIC ENGINEERING","","2190-8508","10.1007/s13389-024-00365-1","","Transformer-based models are widely used in natural language processing tasks, and their application has been further extended to computer vision as well. In their usage, data security has become a crucial concern when deploying deep learning services on cloud platforms. To address these security concerns, Multi-party computation (MPC) is employed to prevent data and model leakage during the inference process. However, Transformer model introduces several challenges for MPC computation, including the time overhead of the Softmax (normalized exponential) function, the accuracy issue caused by the ""dynamic range"" of approximated division and exponential, and the high memory overhead when processing long sequences. To overcome these challenges, we propose MLformer, an MPC-based inference framework for transformer models based on Crypten Knott et al. (Adv Neural Inf Process Syst 34: 4961-4973, 2021), a secure machine learning framework suggested by Facebook AI Research group, in the semi-honest adversary model. In this framework, we replace the softmax attention with linear attention, which has linear time and memory complexity with input length. The modification eliminates the softmax function entirely, resulting in lower time and memory overhead. To ensure the accuracy of linear attention, we propose the scaled linear attention to address the dynamic range issue caused by the MPC division used and a new approximate division function is proposed to reduce the computational time of the attention block. Furthermore, to improve the efficiency and accuracy of MPC exponential and reciprocal which are commonly used in transformer model, we propose a novel MPC exponential protocol and first integrate the efficient reciprocal protocol Bar-Ilan and Beaver (in Proceedings of the 8th annual ACM symposium on principles of distributed computing, pp. 201-209, 1989) to our framework. Additionally, we optimize the computation of causal linear attention, which is utilized in private inference of auto-regression tasks, using our novel CUDA kernel functions. All the proceeding optimizations contribute to the construction of a more accurate and efficient framework. The experimental results demonstrate that our framework achieves comparable accuracy with reduced inference time and GPU memory overhead compared to the original transformer model. The speedup reaches 78.79% compared to traditional private transformer with input length of 1024 patches.","2025-04","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","1","15","","","","","","","","","","English","","","","WOS:001358922700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","GPU; Linear transformer; Multi-party computation; Parallel processing; Private inference","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QMJP3AY9","journalArticle","2024","Schwartz, E; Arbelle, A; Karlinsky, L; Harary, S; Scheidegger, F; Doveh, S; Giryes, R","MAEDAY: MAE for few- and zero-shot AnomalY-Detection","COMPUTER VISION AND IMAGE UNDERSTANDING","","1077-3142","10.1016/j.cviu.2024.103958","","We propose using Masked Auto -Encoder (MAE), a transformer model self-supervisedly trained on image inpainting, for anomaly detection (AD). Assuming anomalous regions are harder to reconstruct compared with normal regions. MAEDAY is the first image-reconstruction-based anomaly detection method that utilizes a pre-trained model, enabling its use for Few-Shot Anomaly Detection (FSAD). We also show the same method works surprisingly well for the novel tasks of Zero-Shot AD (ZSAD) and Zero-Shot Foreign Object Detection (ZSFOD), where no normal samples are available.","2024-04","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","241","","","","","","","","","","English","","","","WOS:001200560200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Anomaly-detection; Foreign object detection; Masked autoencoder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"72MZC899","journalArticle","2024","Sun, HF; Chen, LT; Li, J; Yang, Z; Zhu, JR; Wang, ZF; Ren, G; Cai, J; Zhao, L","Synthesis of pseudo-PET/CT fusion images in radiotherapy based on a new transformer model","MEDICAL PHYSICS","","0094-2405","10.1002/mp.17512","","BackgroundPET/CT and planning CT are commonly used medical images in radiotherapy for esophageal and nasopharyngeal cancer. However, repeated scans will expose patients to additional radiation doses and also introduce registration errors. This multimodal treatment approach is expected to be further improved.PurposeA new Transformer model is proposed to obtain pseudo-PET/CT fusion images for esophageal and nasopharyngeal cancer radiotherapy.MethodsThe data of 129 cases of esophageal cancer and 141 cases of nasopharyngeal cancer were retrospectively selected for training, validation, and testing. PET and CT images are used as input. Based on the Transformer model with a ""focus-disperse"" attention mechanism and multi-consistency loss constraints, the feature information in two images is effectively captured. This ultimately results in the synthesis of pseudo-PET/CT fusion images with enhanced tumor region imaging. During the testing phase, the accuracy of pseudo-PET/CT fusion images was verified in anatomy and dosimetry, and two prospective cases were selected for further dose verification.ResultsIn terms of anatomical verification, the PET/CT fusion image obtained using the wavelet fusion algorithm was used as the ground truth image after correction by clinicians. The evaluation metrics, including peak signal-to-noise ratio, structural similarity index, mean absolute error, and normalized root mean square error, between the pseudo-fused images obtained based on the proposed model and ground truth, are represented by means (standard deviation). They are 37.82 (1.57), 95.23 (2.60), 29.70 (2.49), and 9.48 (0.32), respectively. These numerical values outperform those of the state-of-the-art deep learning comparative models. In terms of dosimetry validation, based on a 3%/2 mm gamma analysis, the average passing rates of global and tumor regions between the pseudo-fused images (with a PET/CT weight ratio of 2:8) and the planning CT images are 97.2% and 95.5%, respectively. These numerical outcomes are superior to those of pseudo-PET/CT fusion images with other weight ratios.ConclusionsThis pseudo-PET/CT fusion images obtained based on the proposed model hold promise as a new modality in the radiotherapy for esophageal and nasopharyngeal cancer.","2024-11-21","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","","","","","","","","","","","English","","","","WOS:001393203700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","FRAMEWORK; pseudo-PET/CT; radiotherapy; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MYQLUDLS","journalArticle","2024","Wang, YX; Qu, ZY; Yang, W; Chen, X; Qiao, T","Inversion of Soil Salinity in the Irrigated Region along the Southern Bank of the Yellow River Using UAV Multispectral Remote Sensing","AGRONOMY-BASEL","","2073-4395","10.3390/agronomy14030523","","Soil salinization is a global issue confronting humanity, imposing significant constraints on agricultural production in the irrigated regions along the southern bank of the Yellow River. This, in turn, leads to the degradation of the ecological environment and inadequate grain yields. Hence, it is essential to explore the magnitude and spatial patterns of soil salinization to promote efficient and sustainable agricultural development. This study carried out a two-year surface soil sampling experiment encompassing the periods before spring irrigation and the budding, flowering, and maturity stages of sunflower fields in the irrigated area along the southern bank of the Yellow River. It employed deep learning in conjunction with multispectral remote sensing conducted by UAV to estimate soil salinity levels in the sunflower fields. Following the identification of sensitive spectral variables through correlation analysis, we proceeded to model and compare the accuracy and stability of various models, including the deep learning Transformer model, traditional machine learning BP neural network (BPNN), random forest model (RF), and partial least squares regression model (PLSR). The findings indicate that the precision of soil salinity content (SSC) retrieval in saline-alkali land can be significantly enhanced by incorporating the RE band of UAV data. Four SSC inversion models were developed using the most suitable spectral variables, resulting in precise soil salinity inversion. The model order based on accuracy and stability was Transformer > BPNN > RF > PLSR. Notably, the Transformer model achieved a prediction accuracy exceeding 0.8 for both the training and test datasets, as indicated by R-2 values. The precision order of the soil salinity inversion model in each period is as follows: before spring irrigation > budding period > maturity period > flowering stages. Additionally, the accuracy is higher in the bare soil stage compared to the crop cover stage. The Transformer model exhibited RMSE and R-2 values of 2.41 g kg(-1) and 0.84 on the test datasets, with the salt inversion results aligning closely with field-measured data. The results showed that the Transformer deep learning model integrated with RE band data significantly enhances the precision and efficiency of soil salinity inversion within the irrigated regions along the south bank of the Yellow River.","2024-03","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","3","14","","","","","","","","","","English","","","","WOS:001192039700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","MODEL; salt inversion; soil salinization; transformer; UAV multispectral remote sensing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EHNHKQFE","journalArticle","2023","Alemu, Y; Chen, H; Duan, CH; Caulley, D; Arriaga, RI; Sezgin, E","Detecting Clinically Relevant Emotional Distress and Functional Impairment in Children and Adolescents: Protocol for an Automated Speech Analysis Algorithm Development Study","JMIR RESEARCH PROTOCOLS","","1929-0748","10.2196/46970","","Background: Even before the onset of the COVID-19 pandemic, children and adolescents were experiencing a mental health crisis, partly due to a lack of quality mental health services. The rate of suicide for Black youth has increased by 80%. By 2025, the health care system will be short of 225,000 therapists, further exacerbating the current crisis. Therefore, it is of utmost importance for providers, schools, youth mental health, and pediatric medical providers to integrate innovation in digital mental health to identify problems proactively and rapidly for effective collaboration with other health care providers. Such approaches can help identify robust, reproducible, and generalizable predictors and digital biomarkers of treatment response in psychiatry. Among the multitude of digital innovations to identify a biomarker for psychiatric diseases currently, as part of the macrolevel digital health transformation, speech stands out as an attractive candidate with features such as affordability, noninvasive, and nonintrusive.Objective: The protocol aims to develop speech-emotion recognition algorithms leveraging artificial intelligence/machine learning, which can establish a link between trauma, stress, and voice types, including disrupting speech-based characteristics, and detect clinically relevant emotional distress and functional impairments in children and adolescents.Methods: Informed by theoretical foundations (the Theory of Psychological Trauma Biomarkers and Archetypal Voice Categories), we developed our methodology to focus on 5 emotions: anger, happiness, fear, neutral, and sadness. Participants will be recruited from 2 local mental health centers that serve urban youths. Speech samples, along with responses to the Symptom and Functioning Severity Scale, Patient Health Questionnaire 9, and Adverse Childhood Experiences scales, will be collected using an Android mobile app. Our model development pipeline is informed by Gaussian mixture model (GMM), recurrent neural network, and long short-term memory.Results: We tested our model with a public data set. The GMM with 128 clusters showed an evenly distributed accuracy across all 5 emotions. Using utterance-level features, GMM achieved an accuracy of 79.15% overall, while frame selection increased accuracy to 85.35%. This demonstrates that GMM is a robust model for emotion classification of all 5 emotions and that emotion frame selection enhances accuracy, which is significant for scientific evaluation. Recruitment and data collection for the study were initiated in August 2021 and are currently underway. The study results are likely to be available and published in 2024.Conclusions: This study contributes to the literature as it addresses the need for speech-focused digital health tools to detect clinically relevant emotional distress and functional impairments in children and adolescents. The preliminary results show that our algorithm has the potential to improve outcomes. The findings will contribute to the broader digital health transformation. International Registered Report Identifier (IRRID): DERR1-10.2196/46970","2023","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","12","","","","","","","","","","English","","","","WOS:001026644900007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","adverse childhood experiences; artificial intelligence; at-risk youth; machine learning; mental health; pediatrics; predictive modeling; social determinants of health; speech biomarker; speech-recognition; STATES; trauma and emotional distress; voice marker","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TMJDGW2K","journalArticle","2023","Vekkot, S; Prakash, NNVS; Reddy, TSE; Sripathi, SR; Lalitha, S; Gupta, D; Zakariah, M; Alotaibi, YA","Dementia Speech Dataset Creation and Analysis in Indic Languages-A Pilot Study","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3334790","","The paper describes the creation, analysis and validation of a multilingual Dementia Speech dataset for Indic languages. Three popular Indian languages viz. Telugu, Tamil and Hindi are considered for the pilot study. Dementia and associated Alzheimers disease affect a large section of Asian population. Though there are promising studies in dementia detection focussed on Western ethnicity, the absence of a clinical dementia dataset for Indian languages forms the primary motivation for this study. This pilot study aims to overcome the challenges associated with data collection and validation in a clinical setting and deal with situations wherein clinical data is not readily available. The Indic dementia dataset is an enacted non-clinical dataset created from the manual translations of the benchmark clinical English DementiaBank dataset. The dataset created is validated using features extracted from the benchmark. The feature evaluation revealed a similarity of 92.6% for silences, 92% for mean pitch (Hz), 84.7% for jitter and 90.3% for shimmer. Subjective evaluation was also conducted based on clarity and similarity of utterances with DementiaBank data. An average MOS of 3.9 for clarity of speech and 3.76 for similarity with respect to DementiaBank was obtained across all three languages. A baseline classification using state-of-art deep network architecture gave a maximum of 78% accuracy in dementia detection using the Indic dementia dataset. The pilot experimentation in this work gives promising insights into the development of a multilingual dataset for analysis of clinical speech patterns in early dementia in the Indian population.","2023","2025-02-26 20:37:05","2025-02-26 20:37:05","","130697-130718","","","11","","","","","","","","","","English","","","","WOS:001118695800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","Alzheimer's disease; ALZHEIMERS-DISEASE; cosine similarity; Dementia; Feature extraction; FRAMEWORK; Indic speech; jitter; Jitter; Older adults; Pearson correlation; pitch; Recording; Sensitivity; shimmer; silences; Sociology; Speech processing; Statistics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7HQAB87A","journalArticle","2023","Anwar, U; Arslan, T; Hussain, A; Russ, TC; Lomax, P","Design and Evaluation of Wearable Multimodal RF Sensing System for Vascular Dementia Detection","IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS","","1932-4545","10.1109/TBCAS.2023.3282350","","Vascular dementia is the second most common form of dementia and a leading cause of death. Brain stroke and brain atrophy are the major degenerative pathologies associated with vascular dementia. Timely detection of these progressive pathologies is critical to avoid brain damage. Brain imaging is an important diagnostic tool and determines future treatment options available to the patient. Traditional medical technologies are expensive, require extensive supervision and are not easily accessible. This article presents a novel concept of low- complexity wearable sensing system for the detection of brain stroke and brain atrophy using RF sensors. This multimodal RF sensing system provides a first-of-its-kind RF sensing solution for the detection of cerebral blood density variations and blood clots at an initial stage of neurodegeneration. A customized microwave imaging algorithm is presented for the reconstruction of images in affected areas of the brain. Designs are validated using software simulations and hardware modeling. Fabricated sensors are experimentally validated and can effectively detect blood density variation (1050 +/- 50 Kg/m(3)), artificial stroke targets with a volume of 27 mm(3) and density of 1025-1050 Kg/m(3), and brain atrophy with a cavity of 58 mm(3) within a realistic brain phantom. The safety of the proposed wearable RF sensing system is studied through the evaluation of the Specific Absorption Rate (SAR < 1.4 W/Kg, 100 mW) and thermal conductivity of the brain (<0.152 C-degrees). The results indicate that the device is viable as an efficient, portable, and low-cost substitute for vascular dementia detection.","2023-10","2025-02-26 20:37:05","2025-02-26 20:37:05","","928-940","","5","17","","","","","","","","","","English","","","","WOS:001122543600010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Atrophy; Brain imaging; CT; Dementia; FLEXIBLE ELECTROMAGNETIC CAP; Image sensors; medical imaging; MICROWAVE; microwave sensing system; multimodal sensing; non-invasive sensors; Radio frequency; radio frequency sensors; Sensor systems; Sensors; Temperature sensors; ultra-wideband; vascular dementia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EU9IVJMJ","journalArticle","2023","Dublin, S; Greenwood-Hickman, MA; Karliner, L; Hsu, C; Coley, RY; Colemon, L; Carrasco, A; King, D; Grace, A; Lee, SJ; Walsh, JME; Barrett, T; Broussard, J; Singh, U; Idu, A; Yaffe, K; Boustani, M; Barnes, DE","The electronic health record Risk of Alzheimer's and Dementia Assessment Rule (eRADAR) Brain Health Trial: Protocol for an embedded, pragmatic clinical trial of a low-cost dementia detection algorithm","CONTEMPORARY CLINICAL TRIALS","","1551-7144","10.1016/j.cct.2023.107356","","Background: About half of people living with dementia have not received a diagnosis, delaying access to treatment, education, and support. We previously developed a tool, eRADAR, which uses information in the electronic health record (EHR) to identify patients who may have undiagnosed dementia. This paper provides the protocol for an embedded, pragmatic clinical trial (ePCT) implementing eRADAR in two healthcare systems to determine whether an intervention using eRADAR increases dementia diagnosis rates and to examine the benefits and harms experienced by patients and other stakeholders. Methods: We will conduct an ePCT within an integrated healthcare system and replicate it in an urban academic medical center. At primary care clinics serving about 27,000 patients age 65 and above, we will randomize primary care providers (PCPs) to have their patients with high eRADAR scores receive targeted outreach (intervention) or usual care. Intervention patients will be offered a ""brain health"" assessment visit with a clinical research interventionist mirroring existing roles within the healthcare systems. The interventionist will make follow-up recommendations to PCPs and offer support to newly-diagnosed patients. Patients with high eRADAR scores in both study arms will be followed to identify new diagnoses of dementia in the EHR (primary outcome). Secondary outcomes include healthcare utilization from the EHR and patient, family member and clinician satisfaction assessed through surveys and interviews. Conclusion: If this pragmatic trial is successful, the eRADAR tool and intervention could be adopted by other healthcare systems, potentially improving dementia detection, patient care and quality of life.","2023-12","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","135","","","","","","","","","","English","","","","WOS:001102431300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Alzheimer's disease; BRIEF INFORMANT INTERVIEW; Dementia; DIAGNOSIS; Early detection; Electronic health records; IMPAIRMENT; INSTRUMENTAL ACTIVITIES; LONGITUDINAL DATA; MONTREAL COGNITIVE ASSESSMENT; Pragmatic trial; PREVALENCE; PRIMARY-CARE; Screening; UTILITY; VALIDITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"II9CIVJD","journalArticle","2023","Zadgaonkar, A; Keskar, R; Kakde, O","Towards a Machine Learning Model for Detection of Dementia Using Lifestyle Parameters","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app131910630","","Featured Application Given the challenges of mobility and geriatric issues in old age, this study proposes a simple method, based on lifestyle parameters, to assess dementia trends. Geared towards individuals aged 60+ and caregivers, the approach could be widely adopted as a mobile app using the proposed machine learning model for gauging dementia risk.Abstract The study focuses on Alzheimer's and dementia detection using machine learning, acknowledging their impact on cognitive health beyond normal aging. Data markers, rather than biomarkers, are preferred for diagnosis, allowing machine learning to play a role. The objective is to design and test a model for early dementia detection using lifestyle data from the National Health and Ageing Trends Study (NHATS). This could aid in flagging high-risk individuals and understanding aging-related parameter changes. Using NHATS data from 5000 individuals aged 60+, encompassing 1288 parameters over a decade, the study shortlists parameters relevant to dementia. Artificial neural networks and random forest techniques are employed to build a model that identifies key dementia-related parameters. Temporal analysis reveals features that exhibit declining social interactions, quality of life, and increased depression as individuals age. Results show the random forest model achieving an accuracy of 80% for dementia risk prediction, with precision, recall, and F1-score values of 0.76, 1, and 0.86, respectively. Temporal analysis offers insights into aging trends and elderly citizens' lifestyles, using daily activities as parameters. The study concludes that NHATS data analysed using machine learning techniques aids in understanding aging trends and that machine learning models based on identified parameters can non-intrusively assist in clinical dementia diagnosis and trend-based detection.","2023-10","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","19","13","","","","","","","","","","English","","","","WOS:001081169500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Alzheimer's; dementia; machine learning algorithms; NATIONAL-HEALTH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QZHJPWU9","journalArticle","2022","Zhao, XH; Hu, RF; Wen, HX; Xu, GH; Pang, T; He, XD; Zhang, YP; Zhang, J; Chen, CSP; Wu, XF; Xu, X","A voice recognition-based digital cognitive screener for dementia detection in the community: Development and validation study","FRONTIERS IN PSYCHIATRY","","1664-0640","10.3389/fpsyt.2022.899729","","IntroductionTo facilitate community-based dementia screening, we developed a voice recognition-based digital cognitive screener (digital cognitive screener, DCS). This proof-of-concept study aimed to investigate the reliability, validity as well as the feasibility of the DCS among community-dwelling older adults in China. MethodsEligible participants completed demographic, clinical, and the DCS. Diagnosis of mild cognitive impairment (MCI) and dementia was made based on the Montreal Cognitive Assessment (MoCA) (MCI: MoCA < 23, dementia: MoCA < 14). Time and venue for test administration were recorded and reported. Internal consistency, test-retest reliability and inter-rater reliability were examined. Receiver operating characteristic (ROC) analyses were conducted to examine the discriminate validity of the DCS in detecting MCI and dementia. ResultsA total of 103 participants completed all investigations and were included in the analysis. Administration time of the DCS was between 5.1-7.3 min. No significant difference (p > 0.05) in test scores or administration time was found between 2 assessment settings (polyclinic or community center). The DCS showed good internal consistency (Cronbach's alpha = 0.73), test-retest reliability (Pearson r = 0.69, p < 0.001) and inter-rater reliability (ICC = 0.84). Area under the curves (AUCs) of the DCS were 0.95 (0.90, 0.99) and 0.77 (0.67, 086) for dementia and MCI detection, respectively. At the optimal cut-off (7/8), the DCS showed excellent sensitivity (100%) and good specificity (80%) for dementia detection. ConclusionThe DCS is a feasible, reliable and valid digital dementia screening tool for older adults. The applicability of the DCS in a larger-scale community-based screening stratified by age and education levels warrants further investigation.","2022-07-22","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","13","","","","","","","","","","English","","","","WOS:000837077300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","ALZHEIMERS-DISEASE; CARE; DECLINE; dementia; digital cognitive screening; IMPAIRMENT; MCI; MoCA; OLDER-ADULTS; reliability; TELEPHONE INTERVIEW; validity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MWUEV9IW","journalArticle","2023","Nazir, F; Majeed, MN; Ghazanfar, MA; Maqsood, M","A computer-aided speech analytics approach for pronunciation feedback using deep feature clustering","MULTIMEDIA SYSTEMS","","0942-4962","10.1007/s00530-021-00822-5","","Nowadays, the demand for language learning is increasing because people need to communicate with other people belonging to different regions for their business deals, study, etc. During language learning, a lot of pronunciation mistakes occur due to unfamiliarity with a new language and differences in accent. In this paper, we perform speech mistakes analysis using deep feature-based clustering. We proposed two novel methods for speech analysis, one to deal with phonemic errors (confusing phonemes) and the other to deal with the prosodic errors (partially changed pronunciation variation of phones). For accurate and efficient language learning, it is important to learn both phonemic as well as prosodic error corrections. In our first method, we perform speech analysis by combining deep CNN features and clustering algorithm to detect the phonemic errors. We classify the phonemes using K-nearest neighbor, Naive Bayes, and support vector machine (SVM). We perform experiments on the six most frequently mispronounced confusing pairs of Arabic to handle phonemic errors and achieve an accuracy of 94%. In our second method, we proposed the unsupervised phone variation model (PVM) to detect prosodic errors. In PVM, each phone is extended to represent the different types of pronunciation variation of that phone with different proficiency levels. We use an Arabic dataset of 28 individual phones for speech analysis and provide feedback based on the variation of each phone and achieves an accuracy of 97%.","2023-06","2025-02-26 20:37:05","2025-02-26 20:37:05","","1699-1715","","3","29","","","","","","","","","","English","","","","WOS:000674216400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","CLASSIFICATION; CONFIDENCE MEASURES; Deep clustering; Deep convolutional neural network; MISPRONUNCIATION DETECTION SYSTEM; MODEL; Multimedia tools; Phone variation model; Speech analytics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BS5LBRWD","journalArticle","2023","Xue, JX; Zhou, H; Song, HW; Wu, B; Shi, L","Cross-modal information fusion for voice spoofing detection","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2023.01.001","","In recent years, speaker verification systems have been used in many production scenarios. Unfortunately, they are still very vulnerable to different kinds of spoofing attacks, such as speech synthesis attacks, replay attacks, etc. Researchers have proposed many methods to defend against these attacks, but in the existing methods, researchers just focus on speech features. In recent studies, researchers have found that speech contains a large amount of face information. In fact, we can determine the speaker's gender, age, mouth shape, and other information by voice. These information can help us distinguish spoofing attacks. Inspired by this phenomenon, we propose a generalized framework named GACMNet. To cope with different attack scenarios, we instantiated two different models. Our framework is mainly divided into data pre-processing phase, feature extraction phase, feature fusion phase, and classification phase. Specifically, our framework consists of two branches. On the one hand, we extract face features in speech by a convolutional neural network. On the other hand, we use a densely connected network to extract speech features. For the more, we designed a global attention-based information fusion mechanism to distinguish the importance of each part of the features. Our solution was proven to be effective in two large scenarios. Compared to the existing methods, our model improves the tandem decision cost function (t-DCF) and equal error rate (EER) scores by 9% and 11% in the logical access scenario, respectively, our model improves the EER score by 10% in the physical access scenario.","2023-02","2025-02-26 20:37:05","2025-02-26 20:37:05","","41-50","","","147","","","","","","","","","","English","","","","WOS:000926203600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Face feature; FEATURES; RECOGNITION; Speech feature; Spoofing attacks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LA3HIAJB","journalArticle","2023","Mamieva, D; Abdusalomov, AB; Kutlimuratov, A; Muminov, B; Whangbo, TK","Multimodal Emotion Detection via Attention-Based Fusion of Extracted Facial and Speech Features","SENSORS","","1424-8220","10.3390/s23125475","","Methods for detecting emotions that employ many modalities at the same time have been found to be more accurate and resilient than those that rely on a single sense. This is due to the fact that sentiments may be conveyed in a wide range of modalities, each of which offers a different and complementary window into the thoughts and emotions of the speaker. In this way, a more complete picture of a person's emotional state may emerge through the fusion and analysis of data from several modalities. The research suggests a new attention-based approach to multimodal emotion recognition. This technique integrates facial and speech features that have been extracted by independent encoders in order to pick the aspects that are the most informative. It increases the system's accuracy by processing speech and facial features of various sizes and focuses on the most useful bits of input. A more comprehensive representation of facial expressions is extracted by the use of both low- and high-level facial features. These modalities are combined using a fusion network to create a multimodal feature vector which is then fed to a classification layer for emotion recognition. The developed system is evaluated on two datasets, IEMOCAP and CMU-MOSEI, and shows superior performance compared to existing models, achieving a weighted accuracy WA of 74.6% and an F1 score of 66.1% on the IEMOCAP dataset and a WA of 80.7% and F1 score of 73.7% on the CMU-MOSEI dataset.","2023-06","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","12","23","","","","","","","","","","English","","","","WOS:001015551000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;21<br/>Total Times Cited:&nbsp;&nbsp;22<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","attention mechanism; CNN; facial feature; multimodal emotion recognition; SENTIMENT ANALYSIS; speech feature","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X4ZQNK49","journalArticle","2024","König, A; Köhler, S; Tröger, J; Düzel, E; Glanz, W; Butryn, M; Mallick, E; Priller, J; Altenstein, S; Spottke, A; Kimmich, O; Falkenburger, B; Osterrath, A; Wiltfang, J; Bartels, C; Kilimann, I; Laske, C; Munk, MH; Roeske, S; Frommann, I; Hoffmann, DC; Jessen, F; Wagner, M; Linz, N; Teipel, S","Automated remote speech-based testing of individuals with cognitive decline: Bayesian agreement of transcription accuracy","ALZHEIMER'S & DEMENTIA: DIAGNOSIS, ASSESSMENT & DISEASE MONITORING","","2352-8729","10.1002/dad2.70011","","IntroductionWe investigated the agreement between automated and gold-standard manual transcriptions of telephone chatbot-based semantic verbal fluency testing.MethodsWe examined 78 cases from the Screening over Speech in Unselected Populations for Clinical Trials in AD (PROSPECT-AD) study, including cognitively normal individuals and individuals with subjective cognitive decline, mild cognitive impairment, and dementia. We used Bayesian Bland-Altman analysis of word count and the qualitative features of semantic cluster size, cluster switches, and word frequencies.ResultsWe found high levels of agreement for word count, with a 93% probability of a newly observed difference being below the minimally important difference. The qualitative features had fair levels of agreement. Word count reached high levels of discrimination between cognitively impaired and unimpaired individuals, regardless of transcription mode.DiscussionOur results support the use of automated speech recognition particularly for the assessment of quantitative speech features, even when using data from telephone calls with cognitively impaired individuals in their homes.Highlights High levels of agreement were found between automated and gold-standard manual transcriptions of telephone chatbot-based semantic verbal fluency testing, particularly for word count. The qualitative features had fair levels of agreement. Word count reached high levels of discrimination between cognitively impaired and unimpaired individuals, regardless of transcription mode. Automated speech recognition for the assessment of quantitative and qualitative speech features, even when using data from telephone calls with cognitively impaired individuals in their homes, seems feasible and reliable.","2024-10","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","4","16","","","","","","","","","","English","","","","WOS:001326780100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","ALZHEIMERS ASSOCIATION WORKGROUPS; automated speech recognition; Bland-Altman analysis; dementia; DEMENTIA; DIAGNOSTIC GUIDELINES; DISEASE; IMPAIRMENT; NATIONAL INSTITUTE; RECOMMENDATIONS; reliability; remote cognitive testing; semantic verbal fluency; VERBAL FLUENCY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QUILSSR9","journalArticle","2022","Zhang, QY; Bai, J; Xu, FJ","A retrieval method for encrypted speech based on improved power normalized cepstrum coefficients and perceptual hashing","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-022-12560-5","","In order to improve the impact of noise on the robustness and discrimination of the speech perceptual hashing scheme, improve retrieval efficiency and retrieval accuracy, and protect the privacy of the cloud speech data, a retrieval method for encrypted speech based on improved power normalized cepstrum coefficients (PNCC) and perceptual hashing was proposed in the paper. Firstly, the original speech was encrypted by Henon chaotic map inter-frame scrambling encryption algorithm before uploading to the encrypted speech library in cloud server. Secondly, the discrete wavelet transform (DWT) and first-order difference coefficient were used to improve the PNCC feature extraction algorithm to extract speech features, and the principal component analysis (PCA) was used to reduce high-dimensional audio features to one dimension to form frame features that can represent the speech segment. Finally, the frame features are constructed as binary hashing sequences using hash functions and upload it to the system hashing index table in the cloud. When the user retrieves, the hashing sequence of query speech is extracted and matched with the encrypted speech features by normalized hamming distance in the cloud system hashing index table to obtain the retrieval result. Experimental results show that compared with the existing methods, the proposed method has good robustness and discrimination, and improves retrieval efficiency and retrieval accuracy, the security of cloud speech data is improved. In addition, the proposed method has good recognition ability under simulated real noise environment.","2022-05","2025-02-26 20:37:05","2025-02-26 20:37:05","","15127-15151","","11","81","","","","","","","","","","English","","","","WOS:000769532100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","ALGORITHM; Encrypted speech retrieval; Henon chaotic mapping; Perceptual hashing; Power normalized cepstrum coefficients (PNCC); Speech feature extraction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QK6JSLE3","journalArticle","2022","Shahrebabaki, AS; Salvi, G; Svendsen, T; Siniscalchi, SM","Acoustic-to-Articulatory Mapping With Joint Optimization of Deep Speech Enhancement and Articulatory Inversion Models","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2021.3133218","","We investigate the problem of speaker independent acoustic-to-articulatory inversion (AAI) in noisy conditions within the deep neural network (DNN) framework. In contrast with recent results in the literature, we argue that a DNN vector-to-vector regression front-end for speech enhancement (DNN-SE) can play a key role in AAI when used to enhance spectral features prior to AAI back-end processing. We experimented with single- and multi-task training strategies for the DNN-SE block finding the latter to be beneficial to AAI. Furthermore, we show that coupling DNN-SE producing enhanced speech features with an AAI trained on clean speech outperforms a multi-condition AAI (AAI-MC) when tested on noisy speech. We observe a 15% relative improvement in the Pearson's correlation coefficient (PCC) between our system and AAI-MC at 0 dB signal-to-noise ratio on the Haskins corpus. Our approach also compares favourably against using a conventional DSP approach to speech enhancement (MMSE with IMCRA) in the front-end. Finally, we demonstrate the utility of articulatory inversion in a downstream speech application. We report significant WER improvements on an automatic speech recognition task in mismatched conditions based on the Wall Street Journal corpus (WSJ) when leveraging articulatory information estimated by AAI-MC system over spectral-alone speech features.","2022","2025-02-26 20:37:05","2025-02-26 20:37:05","","135-147","","","30","","","","","","","","","","English","","","","WOS:000735507400007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","acoustic-to-articulatory inversion; ALGORITHM; Deep learning; Deep neural network; FEATURES; Hidden Markov models; INFORMATION; Mel frequency cepstral coefficient; MOVEMENTS; multi-task training; NEURAL-NETWORKS; Noise measurement; speaker independent models; speech enhancement; Speech enhancement; Task analysis; Training","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TPENB6JI","journalArticle","2021","Tsai, TH; Hao, PC; Wang, CL","Self-Defined Text-Dependent Wake-Up-Words Speaker Recognition System","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2021.3117602","","In recent years, wake-up-words (WUW) technology is highly developed in some speaker recognition system. It is the progress of verifying a person's claimed identity from their voice characteristics, and can be efficiently deployed in some consumer applications. In this paper, we proposed a self-defined text-dependent wake-up-words (WUW) speaker recognition system and its implementation. The whole system is divided into two phases: training phase and testing phase. In the training phase, a wake-up word by language is recorded, and the voice segment is cut out by using Voice Activity Detection (VAD). Then we use the Mel-Frequency Cepstral Coefficients (MFCC) as the pre-processing to extract the speech features. After obtaining the speech features, we use Gaussian Mixture Model (GMM) and Hidden Markov Model (HMM) simultaneously for training. In the testing phase, we build GMM and HMM continuously and use the Levenshtein Distance (LD) to calculate the differences of the state sequences between the dataset and the unknown speech input. If the unknown speech input passes the threshold, then it means a wake-up event is derived. The experimental results show that the average accuracy is 93.31 %, 82.42% and 3.38 % in 10dB, 5dB and 0dB of Signal Noise Ratio (SNR) respectively. The CPU and memory usage of entire system is around 757 MIPS and 40MB respectively.","2021","2025-02-26 20:37:05","2025-02-26 20:37:05","","138668-138676","","","9","","","","","","","","","","English","","","","WOS:000707436400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","customized wake-up word; Feature extraction; Gaussian mixture model; hidden Markov model; Hidden Markov models; Mel frequency cepstral coefficient; mel-frequency cepstral coefficients; real-time operation; Speaker recognition; Testing; Training; Voice activity detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZDMWWQK8","journalArticle","2025","Amato, F; Cesarini, V; Olmo, G; Saggio, G; Costantini, G","Beyond breathalyzers: AI-powered speech analysis for alcohol intoxication detection","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.125656","","Detecting potential alcohol inebriation or intoxication status holds paramount significance for social prevention and security. Beyond its association with long-term health effects, alcohol consumption can lead to immediate consequences, including reduced control over one's actions, with traffic fatalities representing one of the most tragic outcomes. This study leveraged the Alcohol Language corpus, involving 162 subjects recorded both in sober and inebriated states. Participants provided 60 speech samples while sober and 30 when intoxicated, all within a realistic car setting using head-mounted microphones. Our research endeavors encompassed comprehensive stratified statistical tests to examine the impact of alcohol consumption on speech production while uncovering the influence of covariates such as age, gender, and drinking habits. Additionally, we introduced a speaker-neutral machine learning algorithm, based on the Domain-Adversarial Neural Network architecture. This approach aimed to overcome challenges posed by individual differences that often complicate intoxicated speech analysis. Notably, our findings highlighted the effectiveness of features like the RASTA-filtered auditory spectrum. Nevertheless, the results from statistical tests emphasized the need for techniques that minimize inter-subject variability. As for the automatic classification, the proposed architecture exhibited promising results, yielding a classification accuracy slightly exceeding 70% on an independent test set. Although preliminary, our research demonstrates the potential for detecting alcohol-induced speech changes, benefiting societal well-being and security. It also underscores the importance of developing strategies that account for individual differences while harnessing the power of automatic models to effectively distinguish between sober and intoxicated individuals.","2025-03-01","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","262","","","","","","","","","","English","","","","WOS:001356269800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Acoustic features; Alcohol intoxication; CONSUMPTION; INJURY; Machine learning; RISK; Speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7USU4D47","journalArticle","2021","Li, Q; Liu, CL; Dong, PY; Zhang, YM; Li, T; Lin, S; Yang, MD; Qiao, F; Wang, YZ; Luo, L; Yang, HZ","NS-FDN: Near-Sensor Processing Architecture of Feature-Configurable Distributed Network for Beyond-Real-Time Always-on Keyword Spotting","IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS","","1549-8328","10.1109/TCSI.2021.3059649","","Always-on keyword spotting (KWS) that detects wake-up words has been the indispensable module in the voice interaction system. However, the ultra-low-power embedded devices put forward strict requirements on energy consumption, latency, and recognition accuracy of KWS. In this work, we propose a near-sensor processing architecture of feature-configurable distributed network (NS-FDN) for always-on KWS applications. The proposed distributed network adapts to the flexible keywords demands in the actual scene by splitting the conventional single network into distributed sub-networks. We design a channel-independent training framework to improve the recognition accuracy of distributed networks. The speech features are evaluated and the redundancy is reduced in NS-FDN, which can also configure the speech features to further reduce the computing complexity and improve processing speed. For deeper optimization, we implement a 65nm-process prototype chip with near-sensor mixed-signal processing architecture avoiding energy-consuming analog-to-digital converter. By improving the system, algorithm, and hardware designs of the KWS, our co-optimized architecture eliminates the energy consumption bottleneck long-standing in conventional KWS systems and achieves state-of-the-art system performance. The experiment results show that NS-FDN achieves 31.6% energy consumption savings, 1.6 times memory savings, 57 times speedup, and 3.4% higher recognition accuracy compared with the state of the art.","2021-05","2025-02-26 20:37:05","2025-02-26 20:37:05","","1892-1905","","5","68","","","","","","","","","","English","","","","WOS:000641972300011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;20<br/>Total Times Cited:&nbsp;&nbsp;22<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Artificial neural networks; configurable feature; distributed network; Energy consumption; Feature extraction; Hardware; Keyword spotting; lightweight GRU; Microphones; near-sensor processing architecture; Power demand; Speech recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T5QRW2BF","journalArticle","2024","Rastegarparnah, A; Asif, ME; Stolkin, R","Hybrid Neural Networks for Enhanced Predictions of Remaining Useful Life in Lithium-Ion Batteries","BATTERIES-BASEL","","2313-0105","10.3390/batteries10030106","","With the proliferation of electric vehicles (EVs) and the consequential increase in EV battery circulation, the need for accurate assessments of battery health and remaining useful life (RUL) is paramount, driven by environmentally friendly and sustainable goals. This study addresses this pressing concern by employing data-driven methods, specifically harnessing deep learning techniques to enhance RUL estimation for lithium-ion batteries (LIB). Leveraging the Toyota Research Institute Dataset, consisting of 124 lithium-ion batteries cycled to failure and encompassing key metrics such as capacity, temperature, resistance, and discharge time, our analysis substantially improves RUL prediction accuracy. Notably, the convolutional long short-term memory deep neural network (CLDNN) model and the transformer LSTM (temporal transformer) model have emerged as standout remaining useful life (RUL) predictors. The CLDNN model, in particular, achieved a remarkable mean absolute error (MAE) of 84.012 and a mean absolute percentage error (MAPE) of 25.676. Similarly, the temporal transformer model exhibited a notable performance, with an MAE of 85.134 and a MAPE of 28.7932. These impressive results were achieved by applying Bayesian hyperparameter optimization, further enhancing the accuracy of predictive methods. These models were bench-marked against existing approaches, demonstrating superior results with an improvement in MAPE ranging from 4.01% to 7.12%.","2024-03","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","3","10","","","","","","","","","","English","","","","WOS:001191564600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;80</p>","","","battery degradation; battery management systems; CNN; deep learning; EV battery recycling; FRAMEWORK; HEALTH ESTIMATION; lithium-ion batteries; LSTM; MODEL; OF-CHARGE ESTIMATION; SOC; STATE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KQAKYNFA","journalArticle","2024","Gandhudi, M; Alphonse, PJA; Fiore, U; Gangadharan, GR","Explainable hybrid quantum neural networks for analyzing the influence of tweets on stock price prediction","COMPUTERS & ELECTRICAL ENGINEERING","","0045-7906","10.1016/j.compeleceng.2024.109302","","Stock price prediction is a complex and challenging activity for organizations and investors to predict future returns. While machine learning and deep learning methods are widely used for stock closing price prediction, these methods have some drawbacks, including high scalability, slow convergence, and poor generalization performance. Furthermore, because those models are inherently black -box, it is challenging to comprehend the logic underlying their forecasts. This study presents an explainable hybrid quantum neural network to investigate the influence of tweets on a stock price prediction. The datasets used in this analysis include the stock prices of six different organizations as well as the 4 million+ tweets written on X (previously Twitter). The proposed methodology finds the average sentiment score of daily tweets using a transformer model which is combined with historical stock data. The proposed hybrid genetic algorithm based quantum neural network predicts the future stock closing price more accurately and uses explainable artificial intelligence methods to investigate the influence of average sentiment score of tweets and compute each attribute contribution towards the outcome. The proposed hybrid quantum neural network outperforms the other existing classical machine learning and quantum inspired machine learning algorithms by achieving a model accuracy ( R 2 ) greater than 99% in the prediction of stock prices for the six different organizations. Further, based on the explainability analysis, we observe that the tweets do not influence stock price to a greater extent.","2024-08","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","118","","","","","","","","","","English","","","","WOS:001246530500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Explainable artificial intelligence; Genetic algorithm; Quantum neural networks; Sentiment analysis; Stock price prediction; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PK2KJNWN","journalArticle","2023","Jiang, YH; Jin, ST; Jin, XR; Xiao, XL; Wu, WF; Liu, XR; Zhang, Q; Zeng, XX; Yang, G; Niu, ZM","Pharmacophoric-constrained heterogeneous graph transformer model for molecular property prediction","COMMUNICATIONS CHEMISTRY","","2399-3669","10.1038/s42004-023-00857-x","","Informative molecular representation is a vital prerequisite in artificial intelligence-driven de novo drug discovery, however, mapping the pharmacophoric information is underexploited by the atom-level based molecular graph representation. Here, the authors design a multi-level based Pharmacophoric-constrained heterogeneous graph transformer (PharmHGT) to better capture the pharmacophore structure and chemical information. Informative representation of molecules is a crucial prerequisite in AI-driven drug design and discovery. Pharmacophore information including functional groups and chemical reactions can indicate molecular properties, which have not been fully exploited by prior atom-based molecular graph representation. To obtain a more informative representation of molecules for better molecule property prediction, we propose the Pharmacophoric-constrained Heterogeneous Graph Transformer (PharmHGT). We design a pharmacophoric-constrained multi-views molecular representation graph, enabling PharmHGT to extract vital chemical information from functional substructures and chemical reactions. With a carefully designed pharmacophoric-constrained multi-view molecular representation graph, PharmHGT can learn more chemical information from molecular functional substructures and chemical reaction information. Extensive downstream experiments prove that PharmHGT achieves remarkably superior performance over the state-of-the-art models the performance of our model is up to 1.55% in ROC-AUC and 0.272 in RMSE higher than the best baseline model) on molecular properties prediction. The ablation study and case study show that our proposed molecular graph representation method and heterogeneous graph transformer model can better capture the pharmacophoric structure and chemical information features. Further visualization studies also indicated a better representation capacity achieved by our model.","2023-04-03","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","1","6","","","","","","","","","","English","","","","WOS:000962801000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;30<br/>Total Times Cited:&nbsp;&nbsp;30<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QQU7NDZ3","journalArticle","2022","Pérez, V; Martínez, V; Diez-Itza, E","Late phonological development in Williams syndrome","FRONTIERS IN PSYCHOLOGY","","1664-1078","10.3389/fpsyg.2022.992512","","Williams syndrome is a neurodevelopmental genetic disorder characterized by a unique phenotype, including mild to moderate intellectual disability and an uneven neuropsychological profile of relative strengths and weaknesses. Language structure components (i.e., phonology, morphosyntax, and vocabulary) have been considered an area of specific ability compared to pragmatic language use. However, research on phonological development in Williams syndrome is very scarce, and it suggests atypical patterns. Therefore, the aim of the present study was to explore the profiles of late phonological development in Spanish-speaking children, adolescents, and adults with Williams syndrome, based on the analysis of five classes of processes (Syllable Structure, Substitution, Omission, Assimilation, and Addition) in spontaneous speech. The phonological profiles of seven children (aged 3-8 years), and seven adolescents and young adults (aged 14-25 years) with Williams syndrome were compared with two normative groups of typically developing (TD) children at different stages of late phonological development (aged 3 and 5 years). The frequency of phonological processes in the group of children with Williams syndrome was similar to that of 3-year-old TD children, which suggests that they would be in the first stage of late phonological development (expansion stage). The group of older individuals with Williams syndrome showed a much lower frequency of processes, similar to that of 5-year-old TD children in the last stage of phonological development (resolution stage). However, their phonological processes appeared to be persistent and independent of chronological age. Furthermore, asynchronies in quantitative and qualitative profiles (relative frequency) indicated atypical and complex trajectories in late phonological development, which cannot be described as simply delayed or protracted. Remarkable individual differences were observed, especially in the group of adolescents and adults with Williams syndrome, although the majority of cases conformed to the modal profiles of their groups. A major tendency for Omission, including final consonant deletion, may be considered atypical and specific to Williams syndrome at all ages. The results of the present study raise the need for continued and appropriate phonological assessment and treatment for people with Williams syndrome across the lifespan.","2022-11-16","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","13","","","","","","","","","","English","","","","WOS:000891568200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;97</p>","","","ABILITIES; ACQUISITION; ADOLESCENTS; atypical language development; CHILDREN; EXPRESSIVE LANGUAGE; intellectual disability; KNOWLEDGE; neurodevelopmental genetic disorders; PERCEPTION; phonological development; phonological processes; POPULATION; SHORT-TERM-MEMORY; SPEECH; spontaneous speech assessment; Williams syndrome","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HI72RFWS","journalArticle","2022","Alsulaiman, R; Harris, J; Bamaas, S; Howell, P","Identifying Stuttering in Arabic Speakers Who Stutter: Development of a Non-word Repetition Task and Preliminary Results","FRONTIERS IN PEDIATRICS","","2296-2360","10.3389/fped.2022.750126","","Stuttering and other conditions that affect speech fluency need to be identified at an early age in order that effective interventions can be given before the problems becomes chronic. This applies in countries where several languages are spoken including those in which English and Arabic are both widely used which calls for assessment procedures that work across these languages. The 'universal' non-word repetition task (UNWR) has been established as an effective screening tool for discriminating between children who stutter (CWS) and children with word-finding difficulty for a number of languages. However, the UNWR does not apply to languages such as Arabic and Spanish. The present study aimed to: (1) introduce an Arabic English NWR (AEN_NWR); which was developed based on the same phonologically informed approach used with UNWR; (2) present preliminary non-word repetition data from Arabic-speaking CWS and adults who stutter (AWS). The AEN_NWR items comprises twenty-seven non-words that meet lexical phonology constraints across Arabic and English. The set of items includes non-words of two, three and four syllables in length. Preliminary non-word repetition data were collected from ten CWS between the ages of 6;5 and 16;7 (M-age = 12:1) and fourteen AWS between the ages of 19;2 and 31;0 (M-age = 24). Participants performed the non-word repetition task and provided a sample of spontaneous speech. The spontaneous speech samples were used to estimate %stuttered syllables (%SS). To validate that AEN_NWR performance provides an alternative way of assessing stuttering, a significant correlation was predicted between %SS and AEN_NWR performance. Also, word length should affect repetition accuracy of AEN_NWR. As predicted, there was a significant negative correlation between the AEN_NWR and %SS scores (r (25) = -0.5), p < 0.000). Overall, CWS were less accurate in their repetition than AWS at all syllable lengths. The AEN_NWR provides a new assessment tool for detecting stuttering in speaker of Arabic and English. Future studies would benefit from a larger sample of participants, and by testing a population-based sample. These studies would allow further investigation of the AEN_NWR as a screening measure for stuttering in preschool children.","2022-03-11","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","10","","","","","","","","","","English","","","","WOS:000776997100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","ACQUISITION; Arabic; CHILDREN; diversity; fluency; non-word; NONWORD REPETITION; SAMPLES; screening; SKILLS; SPEECH; speech disfluency; stuttering; VOCABULARY; word-finding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KZDRFHZ5","journalArticle","2023","Li, H; Xu, F; Lin, Z","ET-DM: Text to image via diffusion model with efficient Transformer","DISPLAYS","","0141-9382","10.1016/j.displa.2023.102568","","Text-to-image synthesis is widely used in many applications, such as virtual reality, game development, image editing, etc. It is a challenging task that requires the conversion of natural language descriptions into corresponding images. Text-to-image synthesis techniques based on generative adversarial networks (GANs) have succeeded greatly. However, there are still some challenges in generating high-quality, diverse, and semantically consistent images. To solve these problems. This paper proposes a novel text-to-image synthesis technique (ET-DM) based on a diffusion model and an efficient Transformer. ET-DM technology combines the diffusion model and the high-efficiency Transformer model. On the one hand, the diffusion model is used to simulate the evolution process of pixel values in the image, and the image is generated through repeated iterations. At the same time, it also uses an efficient Transformer model to process text input and generate corresponding images. In image generation, ET-DM technology can control the image at the pixel level to ensure the image's visual consistency and semantic consistency. In addition, it can generate diverse images by controlling random noise. We conduct experiments on multiple datasets and show that ET-DM outperforms existing methods regarding image quality and diversity while being more computationally efficient. ET-DM represents a promising approach to image generation from textual descriptions, which can find applications in fields such as computer vision, natural language processing, and creative artificial intelligence.","2023-12","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","80","","","","","","","","","","English","","","","WOS:001140257300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Deep Learning; Diffusion Model; Efficient Transformer; Image Processing; Image synthesis; NETWORKS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KBEDSAQZ","journalArticle","2023","Khalil, MMY; Wang, QX; Chen, B; Wang, WD","Cross-modality representation learning from transformer for hashtag prediction","JOURNAL OF BIG DATA","","2196-1115","10.1186/s40537-023-00824-2","","Hashtags are the keywords that describe the theme of social media content and have become very popular in influence marketing and trending topics. In recent years, hashtag prediction has become a hot topic in AI research to help users with automatic hashtag recommendations by capturing the theme of the post. Most of the previous work mainly focused only on textual information, but many microblog posts contain not only text but also the corresponding images. This work explores both image-text features of the microblog post. Inspired by the self-attention mechanism of the transformer in natural language processing, the visual-linguistics pre-train model with transfer learning also outperforms many downstream tasks that require image and text inputs. However, most of the existing models for multimodal hashtag recommendation are based on the traditional co-attention mechanism. This paper investigates the cross-modality transformer LXMERT for multimodal hashtag prediction for developing LXMERT4Hashtag, a cross-modality representation learning transformer model for hashtag prediction. It is a large-scale transformer model that consists of three encoders: a language encoder, an object encoder, and a cross-modality encoder. We evaluate the presented approach on dataset InstaNY100K. Experimental results show that our model is competitive and achieves impressive results, including precision of 50.5% vs 46.12%, recall of 44.02% vs 38.93%, and F1-score of 47.04% vs 42.22% compared to the existing state-of-the-art baseline model.","2023-09-28","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","1","10","","","","","","","","","","English","","","","WOS:001072780000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Attention mechanism; Hashtag recommendation; Multimodal data; RECOMMENDATION; Transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8NN3ACV5","journalArticle","2022","Hu, WY; Zhao, SS","Remaining useful life prediction of lithium-ion batteries based on wavelet denoising and transformer neural network","FRONTIERS IN ENERGY RESEARCH","","2296-598X","10.3389/fenrg.2022.969168","","It is imperative to accurately predict the remaining useful life (RUL) of lithium-ion batteries to ensure the reliability and safety of related industries and facilities. In view of the noise sequence embedded in the measured aging data of lithium-ion batteries and the strong nonlinear characteristics of the aging process, this study proposes a method for predicting lithium-ion batteries' RUL based on the wavelet threshold denoising and transformer model. To specify, firstly, the wavelet threshold denoising method is adopted to preprocess the measured discharging capacity data of lithium-ion batteries to eliminate some noise signals. Second, based on the denoised data, the transformer model output's full connection layer is applied to replace the decoder layer for establishing the RUL prediction model of lithium-ion batteries. Finally, the discharging capacity of each charging-discharging cycle is predicted iteratively, and then the RUL of lithium-ion batteries can be calculated eventually. Two groups of lithium-ion batteries' aging data from the Center for Advanced Life Cycle Engineering (CALCE) at the University of Maryland and the laboratory at Anqing Normal University (AQNU) are employed to verify the proposed method, individually. The experimental results demonstrate that this method can overcome the impacts of data measurement noise, effectively predict the RUL of lithium-ion batteries, and present a sound generalization ability and high accuracy.","2022-08-12","2025-02-26 20:37:05","2025-02-26 20:37:05","","","","","10","","","","","","","","","","English","","","","WOS:000845011400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;25<br/>Total Times Cited:&nbsp;&nbsp;25<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","FILTER; lithium-ion battery; model; MODEL; PROGNOSIS; remaining useful life; RUL prediction; STATE; transformer; VEHICLES; wavelet threshold denoising","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8UEY3VFW","journalArticle","2024","Li, Y; Li, D; Xu, YY; Yuan, XL; Zhu, XW","Human State Recognition Using Ultra Wideband Radar Based on CvT","IEEE INTERNET OF THINGS JOURNAL","","2327-4662","10.1109/JIOT.2024.3379393","","Emotions have a significant impact on an individual's life, and positive emotions can enhance their quality of life. Moreover, emotions play a crucial role in the field of medicine. However, the complexity of human emotions has hindered their rapid development in the medical field. Therefore, it is crucial to rapidly and accurately identify human emotions. In the field of emotion recognition, radar is widely used for monitoring human physiological features due to its strong penetrability and noncontact advantages. In deep learning (DL), the Transformer model has been introduced into radar signal processing due to its excellent global perception ability, offering new possibilities for fast and accurate detection of human emotions. In this article, we propose a human emotion recognition system based on ultrawideband radar, utilizing the convolutional vision transformer (CvT) model as the DL model for emotion classification. The CvT model incorporates convolution into the Vision Transformer architecture, combining the advantages of both in image recognition tasks. Unlike previous works with convolutional networks, CvT fully leverages the benefits of convolution while retaining the characteristics of the Transformer. We pretrained the model on a publicly available radar data set and then conducted experimental validation using our collected data set. The experimental results demonstrate that our network outperforms traditional convolutional approaches, achieving a test accuracy of 86.25%, which is of significant importance for radar-based emotion recognition.","2024-06-15","2025-02-26 20:37:05","2025-02-26 20:37:05","","22066-22080","","12","11","","","","","","","","","","English","","","","WOS:001242362600094","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","CABLE; CLASSIFICATION; Classification of emotions; convolutional vision transformer model (CvT); deep learning (DL); micro-Doppler; ultrawideband radar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HYF9KKYK","journalArticle","2023","Xiong, SF; Tian, WJ; Batra, V; Fan, XB; Xi, L; Liu, HB; Liu, LL","Food safety news events classification via a hierarchical transformer model","HELIYON","","2405-8440","10.1016/j.heliyon.2023.e17806","","In light of the significance of regulatory authorities and the rising demand for information disclosure, a vast amount of information on food safety news reports is readily accessible on the Internet. The extraction of such information for precise classification and provision of appropriate safety alerts based on their respective categories has emerged as a challenging problem for academic research. Given that most food safety-related events in news reports comprise lengthy text, the pre-trained language models currently employed for text analysis are generally limited in their capability to handle long documents. This paper proposes a long-text classification model utilising hierarchical Transformers. We categorise information in long documents into two distinct types: (1) multiple text chunks meeting the length constraint and (2) essential sentences within long documents, such as headings, paragraph start and end sentences, etc. Initially, our proposed model utilises the text chunks as input to the BERT model. Then, it concatenates the output of the BERT model with the important sentences from the document and use them as input to the Transformer model for feature transformation. Finally, we utilise a classifier for food safety news classification. We conducted several comparative experiments with various commonly used text classification models on a dataset constructed from publicly available information on food regulatory websites. Our proposed method outperforms existing methods, establishing itself as the leading approach in terms of performance.","2023-07","2025-02-26 20:37:06","2025-02-26 20:37:06","","","","7","9","","","","","","","","","","English","","","","WOS:001055614700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","BERT; Deep learning; Food safety; Multi-classification; Natural language processing; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GE5ALPBE","journalArticle","2023","Zu, BK; Wang, HY; Li, JQ; He, ZP; Li, YF; Yin, ZX","Weighted residual self-attention graph-based transformer for spectral-spatial hyperspectral image classification","INTERNATIONAL JOURNAL OF REMOTE SENSING","","0143-1161","10.1080/01431161.2023.2171744","","Recently, deep learning for hyperspectral image classification has been successfully applied, and some convolutional neural network (CNN)-based models already achieved attractive classification results. Since hyperspectral data is a spectral-spatial cube data that can generally be considered as sequential data along with the spectral dimension, CNN models perform poorly on such a sequential data. Unlike convolutional neural networks (CNNs) that mainly concern with local relationship models in images, transformer has been shown to be a powerful structure for qualifying sequential data. In the SA (self-attention) module of ViT, each token is updated through aggregating all token's features based on the self-attention graph. Through this, tokens can exchange information sufficiently among each other which provides a powerful representation capability. However, as the layers become deeper, the transformer model suffers from network degradation. Therefore, in order to improve the layer-to-layer information exchange and alleviate the network degradation problem, we propose a Weighted Residual Self-attention Graph-based Transformer (RSAGformer) model for hyperspectral image classification with respect to the self-attention mechanism. It effectively solves the network degradation problem of deep transformer model by fusing the self-attention information between adjacent layers and extracts the information of data effectively. Extensive experiment evaluation with six public hyperspectral datasets shows that the RSAGformer yields competitive results for classification.","2023-02-01","2025-02-26 20:37:06","2025-02-26 20:37:06","","852-877","","3","44","","","","","","","","","","English","","","","WOS:000942197200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","deep learning; FEATURE FUSION; Hyperspectral image classification; NETWORKS; transformer; Weighted Residual Self-attention Graph-based Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JHGIPQ4H","journalArticle","2025","Zhang, W; Xie, R; Li, J; Wang, L; Li, X; Peng, P","Predicting the number of COVID-19 imported cases based on cross-modal transformer: A case study in China","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.125483","","With the global outbreak of COVID-19, an increasing number of countries have made imported epidemic control a priority, imposing restriction measures to prevent the spread of the virus caused by imported cases. To control the imported epidemic, it is necessary to accurately predict the number of imported cases from different source countries. This paper proposes a novel time series prediction approach called PNICA (Prediction on Number of Imported CAses) that uses deep learning to predict the number of COVID-19 imported cases. On the one hand, the proposed PNICA approach adopts a multi-modal learning strategy to fuse three sources of data: flight data, the epidemic data, and the data of historical imported cases. On the other hand, the proposed PNICA approach extends the traditional transformer model with cross-modal attention to learn the interactions between different data modalities to improve prediction accuracy. We use China as the target country and collect the number of imported cases from four source countries-Japan, USA, Russia, and the UK-as well as the epidemic data and flight data from May to November 2020. Experiments on the collected data demonstrate that the proposed PNICA approach outperforms the baseline methods in predicting the number of imported cases. The ablation study shows that both the multi-modal learning strategy and cross-modal attention can significantly improve prediction performance.","2025-01-15","2025-02-26 20:37:06","2025-02-26 20:37:06","","","","","260","","","","","","","","","","English","","","","WOS:001331103700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","COVID-19; Cross-modal attention; IMPACT; Imported case prediction; Multi-modal learning strategy; SARS; SPREAD; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IEUA3YFN","journalArticle","2024","Xu, Y; Hong, Y; Li, XC; Hu, M","MedTrans: Intelligent Computing for Medical Diagnosis Using Multiscale Cross-Attention Vision Transformer","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3450121","","Vision transformer (ViT) has outperformed conventional neural networks (CNNs) on general image classification. Motivated by this, we explore the ViT for Oral Squamous Cell Carcinoma (OSCC) detection from Histopathological Images. Such medical image understanding requires information from multiple spatial resolutions. There, we propose a multiscale transformer to process the information from image patch tokens of variable scales to extract the fine-grained and coarse-grained features. Our transformer model design is based on two branches, a small branch (i.e., small sized patch tokens) and large branch (i.e., large sized patch tokens) where each branch is processed with a separate specialized encoder to represent local and global context information from multiscale image patch tokens, and multi-head cross-attention fusion with lateral connections for information fusion across scales. This information Our ablation shows that MedTrans continuously perform better as patch size becomes smaller and smaller. We present a comprehensive comparison of our model that shows that our model has performed better as compared to different vision transformers and state-of-the-art CNN models on the OSCC dataset. For example, MedTrans-S outperforms the recently proposed CNN-Transformer model named TransPath with Top-1 Acc +3.58% and F1-score +3.91%, and best performing CNN model, EfficientNet, with Top-1 Acc +8.30% and F1-score +7.23%.","2024","2025-02-26 20:37:06","2025-02-26 20:37:06","","146575-146586","","","12","","","","","","","","","","English","","","","WOS:001339053500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","Cancer; CLASSIFICATION; Computer vision; Convolutional neural networks; deep learning; Deep learning; digital health; Feature extraction; histopathology; Histopathology; Image classification; Mouth; Oral cancer; ORAL-CANCER; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3U37V4DM","journalArticle","2024","Liu, XH; Chen, DF; Wang, XB; Xiang, S; Zhou, XW","Rep-MCA-former: An efficient multi-scale convolution attention encoder for text-independent speaker verification","COMPUTER SPEECH AND LANGUAGE","","0885-2308","10.1016/j.csl.2023.101600","","In many speaker verification tasks, the quality of speaker embedding is an important factor in affecting speaker verification systems. Advanced speaker embedding extraction networks aim to capture richer speaker features through the multi-branch network architecture. Recently, speaker verification systems based on transformer encoders have received much attention, and many satisfactory results have been achieved because transformer encoders can efficiently extract the global features of the speaker (e.g., MFA-Conformer). However, the large number of model parameters and computational latency are common problems faced by the above approaches, which make them difficult to apply to resource-constrained edge terminals. To address this issue, this paper proposes an effective, lightweight transformer model (MCA-former) with multi-scale convolutional self-attention (MCA), which can perform multi-scale modeling and channel modeling in the temporal direction of the input with low computational cost. In addition, in the inference phase of the model, we further develop a systematic re-parameterization method to convert the multi-branch network structure into the single-path topology, effectively improving the inference speed. We investigate the performance of the MCA-former for speaker verification under the VoxCeleb1 test set. The results show that the MCA-based transformer model is more advantageous in terms of the number of parameters and inference efficiency. By applying the re-parameterization, the inference speed of the model is increased by about 30%, and the memory consumption is significantly improved.","2024-04","2025-02-26 20:37:06","2025-02-26 20:37:06","","","","","85","","","","","","","","","","English","","","","WOS:001146066300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Multi-scale convolution; Re-parameterization; Speaker verification; Transformer encoder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IRVMGAL3","journalArticle","2023","Leng, JW; Lin, ZS; Zhou, M; Liu, Q; Zheng, P; Liu, ZH; Chen, X","Multi-layer parallel transformer model for detecting product quality issues and locating anomalies based on multiple time-series process data in Industry 4.0","JOURNAL OF MANUFACTURING SYSTEMS","","0278-6125","10.1016/j.jmsy.2023.08.013","","Smart manufacturing systems typically consist of multiple machines with different processing durations. The continuous monitoring of these machines produces multiple time-series process data (MTPD), which have four characteristics: low data value density, diverse data dimensions, transmissible processing states, and complex coupling relationships. Using MTPD for product quality issue detection and rapid anomaly location can help dynamically adjust the control of smart manufacturing systems and improve manufacturing yield. This study proposes a multi-layer parallel transformer (MLPT) model for product quality issue detection and rapid anomaly location in Industry 4.0, based on proper modeling of the MTPD of smart manufacturing systems. The MLPT consists of multiple customized encoder models that correspond to the machines, each using a customized partition strategy to determine the token size. All encoders are integrated in parallel and output to the global multi-layer perceptron layer, which improves the accuracy of product quality issue detection and simultaneously locates anomalies (including key time steps and key sensor parameters) in smart manufacturing systems. An empirical study was conducted on a fan-out, panel-level package (FOPLP) production line. The experimental results show that the MLPT model can detect product quality issues more accurately than other methods. It can also rapidly realize anomalous locations in smart manufacturing systems.","2023-10","2025-02-26 20:37:06","2025-02-26 20:37:06","","501-513","","","70","","","","","","","","","","English","","","","WOS:001076620500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Anomaly location; DATA-DRIVEN APPROACH; DECISION; DIAGNOSIS; EXTRACTION; FAULT-DETECTION; Multi-layer parallel Transformer model; Multiple time -series process data; NEURAL-NETWORKS; Product quality issue detection; Smart manufacturing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WV7ULCSS","journalArticle","2024","Yang, SZ; Jia, RD; Ma, XG; Li, S","TDDAM: transformer based deep domain adaptation methodology for lithium-ion battery prognosis","ENGINEERING RESEARCH EXPRESS","","2631-8695","10.1088/2631-8695/ad62b2","","The status of health (SOH) is a vital indicator to characterize the remaining life of lithium-ion batteries (LIBs), and precise prognosis of the SOH is of great importance for battery management systems. In order to prognosis the SOH of LIBs, this paper proposed a Transformer based deep domain adaptation methodology (TDDAM). This paper applies the transformer model, which is widely used in natural language processing and other fields, to the prediction of LIBs. Meanwhile in order to solve the problem of model matching in different types of batteries or different environments, this paper combines domain adaptation method based on the maximum mean discrepancy. Firstly, we extract the data features of LIBs through position encoding and processing of the encoder structure with the multi-head self-attention mechanism as the core. Then, based on the maximum mean discrepancy index, the target domain data and the source domain data features are aligned, and the decoder part of the original transformer model is replaced with a fully connected layer for the prediction of SOH of LIBs in the target domain. This is the first time that a Transformer has been combined with the maximum mean discrepancy to be applied to LIBs prediction. Comprehensive experiments on two CALCE LIBs data showed that the TDDAM achieved smaller prognostic prediction errors over popular SOH diagnostic methods, indicating its great potential as a generic backbone for LIBs prognosis.","2024-09-01","2025-02-26 20:37:06","2025-02-26 20:37:06","","","","3","6","","","","","","","","","","English","","","","WOS:001284813000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","domain adaptation; HEALTH ESTIMATION; lithium-ion battery; prognosis; STATE; state-of-health; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8KJIZJHF","journalArticle","2024","Sun, W; Chang, LC; Chang, FJ","Deep dive into predictive excellence: Transformer's impact on groundwater level prediction","JOURNAL OF HYDROLOGY","","0022-1694","10.1016/j.jhydrol.2024.131250","","Groundwater, an essential water resource in Taiwan, is closely linked to land subsidence in the Zhuoshui River basin due to excessive exploitation. Therefore, there is a critical need for robust monitoring and predictive tools to facilitate effective management of water resources. Despite the success of Transformer neural networks in natural language processing, their potential in environmental research remains underexplored. This study explores the feasibility of employing a Transformer-based deep neural network to simultaneously predict groundwater levels at eight strategically positioned monitoring stations in the distal fan of the Zhuoshui River basin in central Taiwan. Utilizing a 20-year dataset with 10-day intervals, we compare the Transformer model with benchmarks established separately by the Convolutional Neural Network (CNN), the Long Short-Term Memory neural network (LSTM), and the Feedforward Neural Network (FFNN). Results reveal the Transformer's superior performance in predicting groundwater levels 10 and 20 days in advance. This achievement is attributed to Transformer's self-attention mechanism capable of capturing relationships between factors like rainfall and river flow, enhancing accuracy in predicting trends and peak values. This groundbreaking study underscores the Transformer model's efficacy in groundwater level prediction, emphasizing its significance for sustainable water resource management amid climate change. The findings open new avenues for environmental research and water resource management, not only in Taiwan but also globally.","2024-06","2025-02-26 20:37:06","2025-02-26 20:37:06","","","","","636","","","","","","","","","","English","","","","WOS:001291558500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Convolution Neural Network (CNN); Long Short-Term Memory neural network (LSTM); MEMORY; Regional groundwater level prediction; RESOURCES; Transformer neural network; WATER; Water resource management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TCMMCWEJ","journalArticle","2023","Deng, HJ; Utsuro, T; Kobayashi, A; Nishizaki, H","Comparative Evaluation of Diverse Features in Fluency Evaluation of Spontaneous Speech","IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS","","0916-8532","10.1587/transinf.2022EDP7047","","There have been lots of previous studies on fluency evaluation of spontaneous speech. However, most of them focus on lexical cues, and little emphasis is placed on how diverse acoustic features and deep end-to-end models contribute to improving the performance. In this paper, we describe multi-layer neural network to investigate not only lexical features extracted from transcription, but also consider utterance-level acoustic features from audio data. We also conduct the experiments to investigate the performance of end-to-end approaches with mel-spectrogram in this task. As the speech fluency evaluation task, we evaluate our proposed method in two binary classification tasks of fluent speech detection and disfluent speech detection. Speech data of around 10 seconds duration each with the annotation of the three classes of ""fluent,"" ""neutral,"" and ""disfluent"" is used for evaluation. According to the two way splits of those three classes, the task of fluent speech detection is defined as binary classification of fluent vs. neutral and disfluent, while that of disfluent speech detection is defined as binary classification of fluent and neutral vs. disfluent. We then conduct experiments with the purpose of comparative evaluation of multi-layer neural network with diverse features as well as end-to-end models. For the fluent speech detection, in the comparison of utterance-level disfluency-based, prosodic, and acoustic features with multi-layer neural network, disfluency-based and prosodic features only are better. More specifically, the performance improved a lot when removing all of the acoustic features from the full set of features, while the performance is damaged a lot if fillers related features are removed. Overall, however, the end-to-end Transformer +VGGNet model with mel-spectrogram achieves the best results. For the disfluent speech detection, the multi-layer neural network using disfluency-based, prosodic, and acoustic features without fillers achieves the best results. The end-to-end Transformer +VGGNet architecture also obtains high scores, whereas it is exceeded by the best results with the multi-layer neural network with significant difference. Thus, unlike in the fluent speech detection, disfluency-based and prosodic features other than fillers are still necessary in the disfluent speech detection.","2023-01","2025-02-26 20:37:06","2025-02-26 20:37:06","","36-45","","1","E106D","","","","","","","","","","English","","","","WOS:001071271900006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","acoustic features; disfluency; end-to-end; multilayer neural network; speech fluency evaluation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GC3LK6UM","journalArticle","2024","Westerlund, AM; Koki, SM; Kancharla, S; Tibo, A; Saigiridharan, L; Kabeshov, M; Mercado, R; Genheden, S","Do Chemformers Dream of Organic Matter? Evaluating a Transformer Model for Multistep Retrosynthesis","JOURNAL OF CHEMICAL INFORMATION AND MODELING","","1549-9596","10.1021/acs.jcim.3c01685","","Synthesis planning of new pharmaceutical compounds is a well-known bottleneck in modern drug design. Template-free methods, such as transformers, have recently been proposed as an alternative to template-based methods for single-step retrosynthetic predictions. Here, we trained and evaluated a transformer model, called the Chemformer, for retrosynthesis predictions within drug discovery. The proprietary data set used for training comprised similar to 18 M reactions from literature, patents, and electronic lab notebooks. Chemformer was evaluated for the purpose of both single-step and multistep retrosynthesis. We found that the single-step performance of Chemformer was especially good on reaction classes common in drug discovery, with most reaction classes showing a top-10 round-trip accuracy above 0.97. Moreover, Chemformer reached a higher round-trip accuracy compared to that of a template-based model. By analyzing multistep retrosynthesis experiments, we observed that Chemformer found synthetic routes, leading to commercial starting materials for 95% of the target compounds, an increase of more than 20% compared to the template-based model on a proprietary compound data set. In addition to this, we discovered that Chemformer suggested novel disconnections corresponding to reaction templates, which are not included in the template-based model. These findings were further supported by a publicly available ChEMBL compound data set. The conclusions drawn from this work allow for the design of a synthesis planning tool where template-based and template-free models work in harmony to optimize retrosynthetic recommendations.","2024-04-11","2025-02-26 20:37:06","2025-02-26 20:37:06","","3021-3033","","8","64","","","","","","","","","","English","","","","WOS:001201284600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","CLASSIFICATION; LANGUAGE; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TR5C5V65","journalArticle","2024","Zhao, TRY; Faruqui, N","EconoFormer: A Novel Macroeconomic Policy Analysis and Implementation Planner Using Generative Transformer Model","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3512594","","Macroeconomic policy analysis and implementation planning are critical for economic growth, increasing employment rates, and ensuring price stability. It has become challenging to keep pace with today's fast-evolving, technology-driven economy, as policy analysis is a time-consuming process. This paper proposes a Generative Transformer (GT)-based macroeconomic policy analysis and implementation planner model, EconoFormer, designed with 1 billion parameters and trained on 5358 pages of documents related to macroeconomic policies. It achieved a perplexity score of 12.3, which indicates high prediction confidence. The innovative prompt filtering mechanism incorporated with it blocks irrelevant prompts with 98.22% accuracy. The EconoFormer model is scalable and maintains a linear relationship with the processing time and the number of policy analyses while maintaining a stable accuracy, precision, recall, and F1-score. Moreover, the performance remains stable for wide ranges of macroeconomic policies from different sectors. Most importantly, the policy impact rating similarity test shows that it is as good as macroeconomics policy experts in policy analysis. The EconoFormer has the capability to process real-time data in prompts, establish non-linear relations among 44 different economic indicators, and develop effective and plans for policy implementation. The unique concept, robust capability, and outstanding performance make the EconoFormer a potential framework for rapid macroeconomic policy analysis and implementation plan development.","2024","2025-02-26 20:37:06","2025-02-26 20:37:06","","184714-184725","","","12","","","","","","","","","","English","","","","WOS:001378949400049","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Analytical models; Artificial intelligence; Data models; economic indicators; Economics; generative AI; GROWTH; LLM; macroeconomic policy; Macroeconomics; Predictive models; Real-time systems; Robustness; Stability analysis; Transformer model; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KCWZTCQS","journalArticle","2024","Zhao, XY; Benediktsson, JA; Yang, Y; Chen, KS; Ulfarsson, MÖ","Exploring Transformer-Based Direction-of-Arrival Estimation Over Sea Surface: A BERT Approach With Physics-Based Loss Function","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2024.3440224","","A comprehensive exploration of the transformer and dual-receiver system-based direction-of-arrival (DOA) estimation is presented in the context of sea surface scattering, particularly under varying sea conditions. A bidirectional encoder representation from transformer (BERT) with a physics-based loss function is utilized to process two individual channel radars. The datasets are the radar scattering coefficients of sea surface simulated at C-band for copolarizations and cross-polarizations. Through detailed analysis of simulated datasets and root mean square error (RMSE) evaluations, the model's performance is investigated across different observation modes, namely, the co-polar (CP), co-azimuth (CA), full-bistatic (FB), and Beaufort wind scale from 3 to 5. Our study demonstrates that the bidirectional encoder representation from transformer model, employing a physics-based loss function, outperforms the baseline long short-term memory (LSTM) model, especially under high noise levels and with larger datasets. Significant correlations between wind conditions and DOA accuracy are observed, highlighting the bidirectional encoder representation from transformer model's adaptability to dynamic environmental factors, particularly under increased wind scales. The choice of observation mode, with CP and FB consistently outperforming CA, proves pivotal. Precise simulation of speckle variations and optimized observation mode selection are identified as crucial avenues for enhancing the model's practical utility.","2024","2025-02-26 20:37:06","2025-02-26 20:37:06","","","","","62","","","","","","","","","","English","","","","WOS:001297495600016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Bidirectional encoder representation from transformer (BERT); bistatic radar scattering; CALIBRATION; direction-of-arrival (DOA); Direction-of-arrival estimation; EMISSIVITY; Estimation; MODEL; Receivers; Scattering; SCATTERING; Sea measurements; Sea surface; sea surface scattering; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G23GG2AR","journalArticle","2023","Tragoudaras, A; Antoniadis, C; Massoud, Y","Enhancing DNN Models for EEG/ECoG BCI With a Novel Data-Driven Offline Optimization Method","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3265040","","A better understanding of ElectroEncephaloGraphy (EEG) and ElectroCorticoGram (ECoG) signals would get us closer to comprehending brain functionality, creating new avenues for treating brain abnormalities and developing novel Brain-Computer Interface (BCI)-related applications. Deep Neural Networks (DNN)s have lately been employed with remarkable success to decode EEG/ECoG signals for BCI. However, the optimal architectural/training parameter values in these DNN architectures have yet to receive much attention. In addition, new data-driven optimization methodologies that leverage significant advancements in Machine Learning, such as the Transformer model, have recently been proposed. Because an exhaustive search on all possible architectural/training parameter values of the state-of-the-art DNN model (our baseline model) decoding the motor imagery EEG and finger tension ECoG signals comprising the BCI IV 2a and 4 datasets, respectively, would require prohibitively much time, this paper proposes an offline model-based optimization technique based on the Transformer model for the discovery of the optimal architectural/training parameter values for that model. Our findings indicate that we could pick better values for the baseline model's architectural/training parameters, enhancing the baseline model's performance by up to 14.7% in the BCI IV 2a dataset and by up to 61.0% in the BCI IV 4 dataset.","2023","2025-02-26 20:37:06","2025-02-26 20:37:06","","35888-35900","","","11","","","","","","","","","","English","","","","WOS:000972184900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","BCI; Biological system modeling; Brain modeling; CNN; data-driven optimization; Decoding; deep learning; ECoG; EEG; EEG signals; Electrodes; Electroencephalography; Optimization; Recording; self-attention model; SIGNALS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FXPCHVSV","journalArticle","2022","Shan, JJ; Nishihara, Y; Maeda, A; Yamanishi, R","Question Generation for Reading Comprehension Test Complying with Types of Question","JOURNAL OF INFORMATION SCIENCE AND ENGINEERING","","1016-2364","10.6688/JISE.202205_38(3).0005","","In this paper, we proposed a method to generate two different types of reading comprehension questions complying with types of question for language learning tests with the Transformer model and the seq2seq method. In recent years, many approaches have showed good results by treating question generation as a seq2seq task. These approaches were implemented with a question-answering (QA) dataset; however, few studies have considered a reading comprehension-based dataset. Therefore, this paper proposed a method to generate questions appropriate for reading comprehension tests from articles. Moreover, analysis of reading comprehension test questions revealed two primary types of the question's asking style: the commonly-used question (CM question) and the directly-related question (DR question). The characteristic of the two question types was different and therefore needs to design the generation models complying with the type of questions. We proposed a method to separate the two question types in the dataset and used two models to generate both types, comparing the result with the method that generates the two types of questions together. The positive rate for the proposed method's CM questions was 88% and for its DR questions was 49%, compared to 33% and 24%, respectively, for the comparative method. The evaluation showed that the proposed method could generate the two types of reading comprehension questions more effectively, with a positive rate increased by an average of 40%.","2022-05","2025-02-26 20:37:06","2025-02-26 20:37:06","","571-589","","3","38","","","","","","","","","","English","","","","WOS:000992618900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","attention mechanism; language learning; question generation; reading comprehension tests; Seq2Seq; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A3KHXUCC","journalArticle","2024","Sreekumar, G; Martin, JP; Raghavan, S; Joseph, CT; Raja, SP","Transformer-Based Forecasting for Sustainable Energy Consumption Toward Improving Socioeconomic Living: AI-Enabled Energy Consumption Forecasting","IEEE SYSTEMS MAN AND CYBERNETICS MAGAZINE","","2380-1298","10.1109/MSMC.2023.3334483","","Smart energy management encompasses energy consumption prediction and energy data analytics. Energy consumption prediction or electric load forecasting leverages autoregressive and moving-average models. Recently, there has been a lot of traction in data-driven models for energy consumption prediction. In this article, a self-attention-based Transformer model is proposed. The deep-learning model captures long-term dependencies in the data sequence and can be used for long-term prediction. The proposed model is compared with autoregressive integrated moving average (ARIMA) and long short-term memory network (LSTM) models. The different models were applied to the load consumption data from a house located in Sceaux, Paris, France. The prediction windows of 24, 100, and 200 h were considered. To evaluate the performance, the mean absolute prediction error (MAPE) and root-mean-square error (RMSE) were considered as the metrics. The Transformer and LSTM models performed significantly better than ARIMA. Even though Transformer and LSTM performed on par, the load forecasted using Transformer was closer to the previous data in the dataset, which proves the better efficiency of the model. Since the Transformer model has transfer learning ability, it can be used as a pretrained model for training of other time-series datasets and, hence, the model can be potentially applied in other related prediction scenarios also, where time-series data are involved.","2024-04","2025-02-26 20:37:06","2025-02-26 20:37:06","","52-60","","2","10","","","","","","","","","","English","","","","WOS:001205798800003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Data models; Energy consumption; Load forecasting; MODEL; PREDICTION; Predictive models; Training; Transfer learning; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FXIDJSBP","journalArticle","2024","Faruqui, N; Thatoi, P; Choudhary, R; Roncevic, I; Alqahtani, H; Sarker, IH; Khanam, S","AI-Analyst: An AI-Assisted SDLC Analysis Framework for Business Cost Optimization","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3519423","","Managing the System Development Lifecycle (SDLC) is a complex task because of its involvement in coordinating diverse activities, stakeholders, and resources while ensuring project goals are met efficiently. The complex nature of the SDLC process leaves plenty of scope for human error, which impacts the overall business cost. This paper introduces AI-Analyst, an AI-assisted framework developed using the transformer-based model with more than 150 million parameters to assist with SDLC management. It minimizes manual effort errors, optimizes resource allocation, and improves decision-making processes, resulting in substantial cost savings. The statistical analysis shows that it saves around 53.33% of costs in an experimental project. The transformer model has been trained with a uniquely prepared dataset tailored for SDLC through transfer learning. It achieved impressive results, with an accuracy of 91.5%, precision of 91.9%, recall of 91.3%, and an F1-score of 91.5%, demonstrating its high reliability and performance. The perplexity score of 15 further indicates the model's strong language understanding capabilities to retrieve relations from complex characteristics of Natural Language Processing (NLP). The AI-Analyst framework represents a significant advancement in integrating Large Language Models (LLMs) into SDLC, offering a scalable and cost-effective solution for optimizing business processes.","2024","2025-02-26 20:37:06","2025-02-26 20:37:06","","195188-195203","","","12","","","","","","","","","","English","","","","WOS:001385626400050","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","AI; artificial intelligence; Business; business cost optimization; Costs; large language model; LLM; Mathematical models; Optimization; PMP; project management automation; SDLC; system analyst; system development lifecycle; Systematic literature review; Testing; Training; transfer learning; Transformer model; Transformers; Unified modeling language; Vectors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SWGX9SJH","journalArticle","2022","Qu, K; Si, GQ; Shan, ZH; Kong, XG; Yang, X","Short-term forecasting for multiple wind farms based on transformer model","ENERGY REPORTS","","2352-4847","10.1016/j.egyr.2022.02.184","","With the rapid growth of wind power installed capacity in recent years, the distribution of wind farms will be relatively dense, and there are usually multiple wind farms in the same area. However, due to the complex correlations and dependencies among these wind farms, traditional forecasting models for individual wind power are difficult to apply. Meanwhile, the accurate forecasting of power output of multiple wind farms is very important to the evaluation results of the renewable energy consumption capacity of the grid, and this problem has received extensive attention from many scholars. To improve the accuracy of forecasting, we apply the Transformer model from natural language processing (NLP) to the field of wind power forecasting. The proposed model is capable of capturing longer sequence internal dependencies, as well as capturing the key information of wind data in a comprehensive and multifaceted way. By comparing with the comparison method, case studies show that the model is not only able to accurately extract different levels of correlation between multiple wind farms, but also to give accurate wind power forecasting results. (c) 2022 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). Peer-review under responsibility of the scientific committee of the 2021 The 2nd International Conference on Power Engineering, ICPE, 2021.","2022-08","2025-02-26 20:37:06","2025-02-26 20:37:06","","483-490","","","8","","","","","","","","","","English","","","","WOS:000770818700059","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;35<br/>Total Times Cited:&nbsp;&nbsp;36<br/>Cited Reference Count:&nbsp;&nbsp;16</p>","","","Multiple wind farms; NEURAL-NETWORK; Self-attention; Short-term forecasting; SPEED; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7ZSZXDKP","journalArticle","2025","Lu, BY; Bai, YL; Zhang, J","A Multigranularity Parallel Pyramidal Transformer Model for Ethylene Production Prediction and Energy Efficiency Optimization","PROCESSES","","2227-9717","10.3390/pr13010104","","Ethylene production prediction is crucial for improving energy efficiency and optimizing processes in the petrochemical industry. However, the production process data of ethylene are highly complex, and the interaction relationships between variables vary at different time granularities. Ignoring these feature relationships can affect the accuracy of ethylene prediction. Traditional prediction methods model data at a single time granularity only and fail to effectively extract multigranularity features. Therefore, to address the complex multigranularity time-varying characteristics of ethylene production, a multigranularity parallel pyramidal Transformer (MPPT) model is proposed to capture and integrate features from ethylene production data at multiple time granularities, enabling accurate production prediction and energy efficiency optimization. The MPPT model integrates three key modules: multiscale decomposition (MSD), parallel pyramid Transformer (PPT), and multigranularity fusion (MF). The MSD converts industrial process data into multigranularity formats, while the PPT extracts both local and global interaction features across different time granularities using a parallel pyramid structure. Finally, the MF module fuses these features to establish a mapping for accurate prediction. We conducted comparative prediction experiments on an ethylene industrial production dataset, where the MPPT model achieved the best performance among all compared prediction models, with an MAE and RMSE of 0.006 and 0.1755, respectively. Furthermore, we leveraged the accuracy of MPPT in ethylene production prediction to optimize production inputs, achieving energy efficiency optimization in ethylene production.","2025-01","2025-02-26 20:37:06","2025-02-26 20:37:06","","","","1","13","","","","","","","","","","English","","","","WOS:001403855000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","ALGORITHM; energy saving; ethylene industrial production prediction; multigranularity modeling; NEURAL-NETWORK; parallel pyramidal transformer model; PETROCHEMICAL INDUSTRIES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HDZ8AXY9","journalArticle","2021","Li, YC; Li, JH; Zhang, M","Deep Transformer modeling via grouping skip connection for neural machine translation","KNOWLEDGE-BASED SYSTEMS","","0950-7051","10.1016/j.knosys.2021.107556","","Most of the deep neural machine translation (NMT) models are based on a bottom-up feedforward fashion, in which representations in low layers construct or modulate high layers representations. We conjecture that this unidirectional encoding fashion could be a potential issue in building a deep NMT model. In this paper, we propose to build a deeper Transformer encoder by properly organizing encoder layers into multiple groups, which are connected via a grouping skip connection mechanism. Here, each group is further appropriately fed into subsequent groups to build a deep Transformer encoder. In this way, we successfully build a deep Transformer encoder with up to 48 layers. Moreover, we can share the parameters among groups to extend the encoder (virtual) depth even without introducing additional parameters. Detailed experimentation on the large-scale WMT (workshop on machine translation) 2014 English-to-German, English-to-French translation, WMT 2016 English-to German, and WMT 2017 Chinese-to-English tasks demonstrates that our proposed deep Transformer model significantly outperforms the strong Transformer baseline. Furthermore, we carry out linguistic probing tasks to analyze the problems existing in the original Transformer model and explain how our deep Transformer encoder improves the translation quality. One particularly nice property of our approach is that it is incredibly easy to implement. We make our code available on Github https://github.com/liyc7711/deep-nmt. (C) 2021 Elsevier B.V. All rights reserved.","2021-12-25","2025-02-26 20:37:06","2025-02-26 20:37:06","","","","","234","","","","","","","","","","English","","","","WOS:000712466600016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","Deep NMT; Grouping skip connection; Neural machine translation; PRIMARY VISUAL-CORTEX; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8UAYE8UA","journalArticle","2025","Liu, D; Long, H; Liu, ZB","Channel selection and local attention transformer model for semantic segmentation on UAV remote sensing scene","IET IMAGE PROCESSING","","1751-9659","10.1049/ipr2.13298","","Compared with common urban landscape semantic segmentation, unmanned aerial vehicle (UAV) image semantic segmentation is more challenging because small targets have very low pixel percentages and multi-scale features due to the influence of flight altitude. Yet, the commonly used successive grid downsampling strategy in the current transformer-based methods omits some important features of small targets. Furthermore, due to the complex background interference, it can lead to even worse results. In reaction to this, existing strategies aim to maintain superior resolution. Nevertheless, the application of this method incurs considerable computational costs, which brings challenges for the practical applications of UAVs. So it is significant to design a novel framework to balance retaining more pixels representing small objects during downsampling and reducing computational costs. For this, the Channel Selection and the Local Attention Transformer Model (CSLFormer) are proposed. During the overlap patch embedding process of feature maps, the model allocates half of the important channels to global attention and local attention. These two types of attention focus on different aspects: one learns the relationships and importance among various patches, while the other emphasizes the features of individual patches. The method shows superior performance on two public datasets: AeroScapes and Vaihingen, achieving mean intersection over union (mIoU) of 75.57% and 78.93%, respectively. The proposed CSLFormer has been released on GitHub: .","2025-01","2025-02-26 20:37:06","2025-02-26 20:37:06","","","","1","19","","","","","","","","","","English","","","","WOS:001374010400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","aircraft; CNN; computer vision; convolutional neural nets; feedforward neural nets; image segmentation; NETWORK","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RQ6PJ62S","journalArticle","2022","Radke, MA; Gupta, A; Stock, K; Jones, CB","Disambiguating spatial prepositions: The case of geo-spatial sense detection","TRANSACTIONS IN GIS","","1361-1682","10.1111/tgis.12976","","Spatial relations in natural language are frequently expressed through prepositions. Thus, in the locative expressions ""New York in the United States"" and ""the house on the river"" the prepositions ""in"" and ""on,"" respectively, serve to communicate the relationships in space between the subject and object of the preposition. Automatic detection of the use of prepositions in a spatial and in particular a geo-spatial sense that refers to geographic context is of interest in supporting automated methods for determining the actual geographic location referred to by locative expressions. This work focuses on disambiguation of prepositions in natural language, with the goal of distinguishing whether a preposition is used in a specifically geo-spatial sense. We conduct machine learning experiments that demonstrate the clear benefit for geo-spatial sense detection of using transformer model deep learning methods when compared with a variety of methods, that include Naive Bayes, support vector machine, and random forest classifiers with handcrafted linguistic features, and a bag of words approach with a meta-classifier that adds geo-spatial features. The best performance was obtained with the Bidirectional Encoder Representation from Transformer-based XLNet transformer model, with a best precision of 0.96 and an F1 score of 0.94 when evaluated on a corpus of natural language expressions that were annotated for this task. We also conducted experiments to detect generic spatial sense, in which the best F1 score, of 0.95, was again obtained with XLNet.","2022-09","2025-02-26 20:37:06","2025-02-26 20:37:06","","2621-2650","","6","26","","","","","","","","","","English","","","","WOS:000850559400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","SEARCH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WQJCB8L5","journalArticle","2024","Wang, Q; Xia, RC; Yu, JY; Liu, QH; Tong, SR; Xu, ZL","From Text to Safety: A Novel Framework for Mining Unsafe Aviation Events Using Advanced Neural Network and Feature Network","AEROSPACE","","2226-4310","10.3390/aerospace11100843","","The rapid growth of the aviation industry highlights the need for strong safety management. Analyzing data on unsafe aviation events is crucial for preventing risks. This paper presents a new method that integrates the Transformer network model, clustering analysis, and feature network modeling to analyze Chinese text data on unsafe aviation events. Initially, the Transformer model is used to generate summaries of event texts, and the performance of three pre-trained Chinese models is evaluated and compared. Next, the Jieba tool is applied to segment both summarized and original texts to extract key features of unsafe events and prove the effectiveness of the pre-trained Transformer model in simplifying lengthy and redundant original texts. Then, cluster analysis based on text similarity categorizes the extracted features. By solving the correlation matrix of these features, this paper constructs a feature network for unsafe aviation events. The network's global and individual metrics are calculated and then used to identify key feature nodes, which alert aviation professionals to focus more on the decision-making process for safety management. Based on the established network and these metrics, a data-driven hidden danger warning strategy is proposed and illustrated. Overall, the proposed method can effectively analyze Chinese texts of unsafe aviation events and provide a basis for improving aviation safety management.","2024-10","2025-02-26 20:37:06","2025-02-26 20:37:06","","","","10","11","","","","","","","","","","English","","","","WOS:001340797600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","cluster analysis; feature network analysis; text segmentation; transformer network model; unsafe aviation event","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""