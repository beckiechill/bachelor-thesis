"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"896DPTFY","journalArticle","2022","Wu, BJ; Cai, WJ; Cheng, FY; Chen, HR","Simultaneous-fault diagnosis considering time series with a deep learning transformer architecture for air handling units","ENERGY AND BUILDINGS","","0378-7788","10.1016/j.enbuild.2021.111608","","An advanced deep learning-based method that employs transformer architecture is proposed to diagnose the simultaneous faults with time-series data. This method can be directly applied to transient data while maintaining the accuracy without a steady-state detector so that the fault can be diagnosed in its early stage. The transformer architecture adopts a novel multi-head attention mechanism without involving any convolutional and recurrent layers as in conventional deep learning methods. The model has been verified by an on-site air handling unit with 6 single-fault cases, 7 simultaneous-fault cases, and normal operating conditions with satisfactory performances of test accuracy of 99.87%, Jaccard score of 99.94%, and F1 score of 99.95%. Besides, the attention distribution reveals the correlations between features to the corresponding fault. It is found that the length of the sliding window is key to the model performance, and a trade-off is made for the window length between the model performance and the diagnosis time. Based on the similar idea, another sequence-to-vector model based on the gated recurrent unit (GRU) is proposed and benchmarked with the transformer model. The results show that the transformer model outperforms the GRU model with a better Jaccard score and F1 score in less training time. (C) 2021 Published by Elsevier B.V.","2022-02-15","2025-02-26 20:39:12","2025-02-26 20:39:12","","","","","257","","","","","","","","","","English","","","","WOS:000754679300004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;26<br/>Total Times Cited:&nbsp;&nbsp;27<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","AHU; Air handling unit; Attention mechanism; Deep learning method; Fault diagnosis; MULTIPLE SIMULTANEOUS FAULTS; STRATEGY; SYSTEM; Transformer architecture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZIR6ZJER","journalArticle","2025","Li, TY; Xu, M; Liu, Z; Chen, Y; Li, K","A Deep Transformer-Based Fast CU Partition Approach for Inter-Mode VVC","IEEE TRANSACTIONS ON IMAGE PROCESSING","","1057-7149","10.1109/TIP.2025.3533204","","The latest versatile video coding (VVC) standard proposed by the Joint Video Exploration Team (JVET) has significantly improved coding efficiency compared to that of its predecessor, while introducing an extremely higher computational complexity by 6 similar to 26 times. The quad-tree plus multi-type tree (QTMT)-based coding unit (CU) partition accounts for most of the encoding time in VVC encoding. This paper proposes a data-driven fast CU partition approach based on an efficient Transformer model to accelerate VVC inter-coding. First, we establish a large-scale database for inter-mode VVC, comprising diverse CU partition patterns from more than 800 raw video sequences across various resolutions and contents. Next, we propose a deep neural network model with a Transformer-based temporal topology for predicting the CU partition, named as TCP-Net, which is adaptive to the group of pictures (GOP) hierarchy in VVC. Then, we design a two-stage structured output for TCP-Net, reflecting both the locations of CU edges and the split modes of all possible CUs. Accordingly, we develop a dual-supervised optimization mechanism to train the TCP-Net model with improved accuracy. The experimental results have verified that our approach can reduce the encoding time by 46.89 similar to 55.91 % with negligible rate-distortion (RD) degradation, outperforming other state-of-the-art approaches.","2025","2025-02-26 20:39:12","2025-02-26 20:39:12","","1133-1148","","","34","","","","","","","","","","English","","","","WOS:001422000700004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","coding unit (CU); complexity reduction; Correlation; quad-tree plus multi-type tree (QTMT); transformer model; Versatile video coding (VVC)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SB2RNSBN","journalArticle","2023","Mao, HY; Liu, ZY; Qiu, C; Huang, Y; Tan, JR","Prescriptive maintenance for complex products with digital twin considering production planning and resource constraints","MEASUREMENT SCIENCE AND TECHNOLOGY","","0957-0233","10.1088/1361-6501/aced5f","","Maintenance is a critical aspect of complex products through entire life cycle, often requiring coordination of production planning and available resources, while previous studies appear to have rarely addressed. With this in mind, this paper presents a prescriptive maintenance framework based on digital twins (DTs) for reducing operational risk and maintenance costs of complex equipment clusters. Virtual entities are firstly constructed for each single asset in multiple dimensions, which use real-time or historical sensing data collected from the physical entities to predict the corresponding remaining useful life (RUL). Then such RUL information is incorporated into a stochastic programming model with chance constraints to enable dynamic decision making. In particular, a risk-based optimization model is formulated to take full account of the physical distances between facilities and production gaps. Further, a dual-sense pyramidal transformer model is proposed to sense important details of data in both time and space while capturing temporal dependencies at different scales. Compared to existing data-driven approaches, the proposed DT-based alternative achieves dynamic real-time interaction between physical and virtual units driven by both models and data, while virtual verification based on high-fidelity models ensures high reliability of maintenance decisions, which has also been validated in an aero-engine maintenance case study.","2023-12-01","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","12","34","","","","","","","","","","English","","","","WOS:001054281300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","digital twin; HEALTH MANAGEMENT; MODEL; NEURAL-NETWORK; prescriptive maintenance; PROGNOSTICS; pyramid transformer model; remaining useful life prediction; risk-based stochastic optimization; USEFUL LIFE PREDICTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7LQ5JM94","journalArticle","2024","Lan, YX; Xu, X; Fang, Q; Hao, JY","Sample Efficient Deep Reinforcement Learning With Online State Abstraction and Causal Transformer Model Prediction","IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS","","2162-237X","10.1109/TNNLS.2023.3296642","","Deep reinforcement learning (RL) typically requires a tremendous number of training samples, which are not practical in many applications. State abstraction and world models are two promising approaches for improving sample efficiency in deep RL. However, both state abstraction and world models may degrade the learning performance. In this article, we propose an abstracted model-based policy learning (AMPL) algorithm, which improves the sample efficiency of deep RL. In AMPL, a novel state abstraction method via multistep bisimulation is first developed to learn task-related latent state spaces. Hence, the original Markov decision processes (MDPs) are compressed into abstracted MDPs. Then, a causal transformer model predictor (CTMP) is designed to approximate the abstracted MDPs and generate long-horizon simulated trajectories with a smaller multistep prediction error. Policies are efficiently learned through these trajectories within the abstracted MDPs via a modified multistep soft actor-critic algorithm with a lambda-target. Moreover, theoretical analysis shows that the AMPL algorithm can improve sample efficiency during the training process. On Atari games and the DeepMind Control (DMControl) suite, AMPL surpasses current state-of-the-art deep RL algorithms in terms of sample efficiency. Furthermore, DMControl tasks with moving noises are conducted, and the results demonstrate that AMPL is robust to task-irrelevant observational distractors and significantly outperforms the existing approaches.","2024-11","2025-02-26 20:39:13","2025-02-26 20:39:13","","16574-16588","","11","35","","","","","","","","","","English","","","","WOS:001051250000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Causal transformer; Computational modeling; feature representation; Heuristic algorithms; model-based reinforcement learning (MBRL); Prediction algorithms; Predictive models; state abstraction; Task analysis; Training; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PNCKS93L","journalArticle","2024","Yang, K; Ding, YL; Jiang, HC; Zhang, Y; Zou, ZB","Deep learning-based bridge damage identification approach inspired by internal force redistribution effects","STRUCTURAL HEALTH MONITORING-AN INTERNATIONAL JOURNAL","","1475-9217","10.1177/14759217231176050","","Damage identification has always been one of the core functions of bridge structural health monitoring (SHM) systems. Damage identification techniques based on deep learning (DL) approaches have shown great promise recently. However, DL methods still need to be improved owing to their poor interpretability and generalization performance. The fundamental reason lies in the separation between physics-based mechanical principles and data-driven DL methods. To address this issue, this paper proposes a physics-inspired approach combining the data-driven method and the internal force redistribution effects to perform efficient damage identification. Firstly, the mechanical derivation of internal force redistribution is given based on a simplified three-span continuous bridge. Then, two types of typical damage scenarios including segment stiffness decrease and prestress loss are simulated to formulate the damage dataset with monitored field data noise added. Next, a modified Transformer model with multi-dimensional output is trained to obtain the complex dynamic spatiotemporal mapping among multiple measurement points from the intact structure as a benchmark model. Finally, the relationship between multiple damage patterns and the corresponding output regression residual distribution is studied, based on which the flexible combinations of the sensors are proposed as the test set to characterize the internal force redistribution due to damage. Validation on the extended dataset showed that this approach is effective to realize preliminary identification of damage patterns and resist interference from noise at the monitoring site.","2024-03","2025-02-26 20:39:13","2025-02-26 20:39:13","","714-732","","2","23","","","","","","","","","","English","","","","WOS:001001719200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","damage identification; FRAMEWORK; internal force redistribution; KNOWLEDGE; pattern recognition; PATTERN-RECOGNITION; SHM; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ES2NAKC9","journalArticle","2023","Xi, N; Yang, Q; Sun, YJ; Mei, G","Machine Learning Approaches for Slope Deformation Prediction Based on Monitored Time-Series Displacement Data: A Comparative Investigation","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13084677","","Slope deformation prediction is one of the critical factors in the early warning of slope failure. Establishing an accurate slope deformation prediction model is important. Time-series displacement data of slopes directly reflect the deformation characteristics and stability properties of slopes. The use of existing data analysis approaches, such as statistical methods and machine learning algorithms, to establish a reasonable and accurate prediction model based on the monitored time-series displacement data is a common solution to slope deformation prediction. In this paper, we conduct a comparative investigation of machine learning approaches for slope deformation prediction based on monitored time-series displacement data. First, we established eleven slope deformation prediction models based on the time-series displacement data obtained from seven in situ monitoring points of the Huanglianshu landslide using machine learning approaches. Second, four evaluation metrics were used to comparatively analyze the prediction performance of all models at each monitoring point. The experimental results of the Huanglianshu landslide indicated that the long-short-term memory (LSTM) model with an attention mechanism and the transformer model achieved the highest prediction accuracy. The comparative analysis of model characteristics suggested that the Transformer model is better adapted to predict nonlinear landslide displacements that are affected by multiple factors. The drawn conclusion could help select a suitable slope deformation model for early landslide warnings.","2023-04","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","8","13","","","","","","","","","","English","","","","WOS:000977475600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","LANDSLIDE DISPLACEMENT; long-short-term memory (LSTM); machine learning; MODELS; slope deformation; time-series data; transformer; TRANSFORMER; WIND-SPEED","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BVZQGICT","journalArticle","2023","Niculescu, O","Acoustic Correlates of Filler Particles in Romanian Connected Speech","PHILOLOGICA JASSYENSIA","","1841-5377","10.60133/PJ.2023.2.05","","This paper explores a lesser studied topic in Romanian linguistic research related to the acoustic features (duration, pitch, F1/F2 values) and pragmatic functions of filler particles, often referred to as '' filled pauses '', in spontaneous speech. From a theoretical perspective, we align our analysis with the recent definition proposed by Belz (2023), where '' a phonetic exponent which is segmentally structured, semantically empty, syntactically unconstrained, and does not show an interjectional function is classified as a filler particle ''. Moreover, as a way to reinforce the idea that filler particles are, from a phonetic perspective, extra-pausal phenomena, we classified fillers in terms of their positioning relative to the silent pause (i.e., pre-pausal, post-pausal, inter-pausal and concatenated). Prior to carrying out extensive quantitative analyses of filler particles on Romanian data, in this article we proposed performing an initial qualitative exploration of fillers in connected speech based on the Ro-Phon corpus. Our results reveal that: ( 1) the prototypical filler particle outputs in Romanian are vocalic (/partial derivative,i/), vocalic-nasal (/partial derivative m/) and nasal (/m/), (2) the length of the pause preceding a filler particle is systematically longer than the pause following it, (3) inter-pausal filler particles display the longest average duration while concatenated fillers were the shortest in our data, (4) in terms of formant frequencies, there is a greater degree of movement along the F1 axis compared to the average F2 frequencies extracted from both vocalic and vocalic-nasal tokens, indicative of an acoustic continuum present within the central vowels /i/ and /partial derivative/, (5) all fillers display a low, flat f0 contour, with a similar frequency as that of neighbouring phones, and that (6) filler particles perform various and often cumulative discursive roles, ranging from a cognitive function (indicative of planning processes), marker of a repair (self-initiated, content-based repairs), to a discourse management function used to signal upcoming new (sensitive) information within the narrative sequence. Future studies aim at extending the data and performing in-depth quantitative analyses related to duration, frequency distribution, voice and vowel quality of filler particles in non-pathological native and non-native Romanian speech data.","2023","2025-02-26 20:39:13","2025-02-26 20:39:13","","71-87","","2","19","","","","","","","","","","English","","","","WOS:001182421100006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","filler particle; MARKERS; phonetic exponents; Romanian spontaneous speech; UM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KX4A4GVI","journalArticle","2022","Msigwa, SS; Li, Y; Cheng, XL; Cao, F","Combining electroacupuncture and transcranial direct current stimulation as an adjuvant therapy enhances spontaneous conversation and naming in subacute vascular aphasia: A retrospective analysis","JOURNAL OF INTEGRATIVE MEDICINE-JIM","","2095-4964","10.1016/j.joim.2022.03.002","","Objective: Emerging evidence shows the effectiveness of speech and language therapy (SLT); however, precise therapeutic parameters remain unclear. Evidence for the use of adjunctive transcranial direct current stimulation (tDCS) to treat post-stroke aphasia (PSA) is promising; however, the utility of combining tDCS and electroacupuncture (EA) has not yet been analyzed. This study assessed the therapeutic consequences of EA and tDCS coupled with SLT in subacute PSA patients who were also undergoing hyperbaric oxygen therapy (HBOT). Methods: A retrospective analysis was conducted on subacute (< 6 months) PSA patients who were divided into three groups: patients who received EA plus tDCS (acupuncture group), patients who underwent tDCS (tDCS group), and patients who experienced conventional therapy (HBOT + SLT). All subjects underwent 21 days of treatment and also received conventional treatment. The aphasia battery of Chinese (ABC) was used to score pre- and post-intervention status. Results: The analysis comprised 238 patients. Cerebral infarction was the most frequent stroke type (137 [57.6%]), while motor (66 [27.7%]) and global aphasia (60 [25.2%]) were the most common types of aphasia. After 21 days of intervention, the ABC scores of all patients were improved. The acupuncture group had the highest ABC scores, but only repetition, naming, and spontaneous speech were statistically improved (P < 0.01). Post-hoc tests revealed significant improvement in word retrieval in the acupuncture and tDCS groups (P < 0.01, P = 0.037), while the acupuncture group had additional significant improvement in spontaneous conversation (P < 0.01). Conclusion: Combining acupuncture and tDCS as an adjuvant therapy for subacute PSA led to significant spontaneous speech and word retrieval improvements. Future prospective, multi-ethnic, multi-center trials are warranted. Please cite this article as: Msigwa SS, Li Y, Cheng XL, Cao F. Combining electroacupuncture and transcranial direct current stimulation as an adjuvant therapy enhances spontaneous conversation and naming in subacute vascular aphasia: A retrospective analysis. J Integr Med. 2022; 20(3): 244-251. (c) 2022 Shanghai Yueyang Hospital Affiliated to Shanghai University of Traditional Chinese Medicine. Published by Elsevier B.V. All rights reserved.","2022-05","2025-02-26 20:39:13","2025-02-26 20:39:13","","244-251","","3","20","","","","","","","","","","English","","","","WOS:000911807200008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","Acupuncture; Aphasia; Electroacupuncture; FMRI; GUIDELINES; HEALTHY; HYPERBARIC-OXYGEN; NONINVASIVE BRAIN-STIMULATION; RECOVERY; REHABILITATION; Speech therapy; STROKE; Stroke rehabilitation; TDCS; TONGLI HT 5; Transcranial direct current stimulation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2VSX65HD","journalArticle","2024","Gogoi, P; Sarmah, P; Prasanna, SRM","Cross-linguistic rhythm analysis of Mising and Assamese","ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING","","2375-4699","10.1145/3694785","","The objective of the current study is to explore a quantitative frequency domain technique to evaluate rhythm in spontaneous speech data of 19 native speakers of Mising and Assamese, two low-resourced languages spoken in Assam, North-East India. The concept of analyzing speech rhythm using amplitude modulation (AM) low-frequency (LF) spectrum, also known as rhythm formant analysis (RFA), is initially put forth by Gibbon and Li [17]. We propose three features from rhythm formants of the LF spectrum and also explore discrete cosine transform (DCT)-based characterization of the retrieved LF spectrum. We aim to distinguish the rhythm of Assamese and two Mising dialects, namely Pagro and Delu, with the aid of machine learning techniques fed with the derived features as input. We have observed that the features are efficient in classifying Assamese vs Pagro and Assamese vs Delu with an accuracy of 92.73% and 91.15%, respectively. The experimental analysis further reveals that Assamese is rhythmically closer to Delu than Pagro.","2024-10","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","10","23","","","","","","","","","","English","","","","WOS:001365838100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","assamese; formants; METRICS; mising; Rhythm; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WALVPRI6","journalArticle","2025","Tang, J; Ma, EX; Qu, Y; Gao, WB; Zhang, YC; Gan, L","UAPT: an underwater acoustic target recognition method based on pre-trained Transformer","MULTIMEDIA SYSTEMS","","0942-4962","10.1007/s00530-024-01614-3","","The Convolutional Neural Network (CNN) model in underwater acoustic target recognition (UATR) research reveals limitations arising from its inability to capture long-distance dependencies, impeding its capacity to focus on global information within the underwater acoustic signal. In contrast, the Transformer model has progressively emerged as the optimal choice in various studies, owing to its exclusive dependence on the attention mechanism for extracting global features from input data. Limited research utilizing the Transformer model in UATR has relied on an early ViT model, while in this paper, two refined Transformer models, namely Swin Transformer and Biformer, are adopted as the foundational networks, and a novel Swin Biformer model is proposed by harnessing the strengths of the two. Experimental results demonstrate the consistent superiority of the three models over CNN and ViT in UATR, and the Swin Biformer model remarkably attains the highest recognition accuracy of 94.3% evaluated on a dataset constructed from the Deepship database. At the same time, this paper proposes a UATR method based on pre-trained Transformer, the effectiveness of which is underscored by experimental findings as a recognition accuracy of approximately 97% was achieved on a generalized dataset derived from the Shipsear database. Even with limited data samples and more stringent classification requirements, the method maintains a recognition accuracy of over 90%, all while significantly reducing the training duration.","2025-02","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","1","31","","","","","","","","","","English","","","","WOS:001391651000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Deep learning; MODEL; Pre-train; Transfer learning; Transformer; Underwater acoustic target recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GQZDW35W","journalArticle","2025","Jiang, XF; Xu, LQ; Yu, L; Fang, XJ","MFT: A novel memory flow transformer efficient intrusion detection method","COMPUTERS & SECURITY","","0167-4048","10.1016/j.cose.2024.104174","","Intrusion detection is a critical field in network security research that is devoted to detecting malicious traffic or attacks on networks. Even with the advances in today's Internet environment, a lot of intrusion detection techniques still fail to take into account the long-term characteristics present in network data, which results in a high false alarm rate. Some researchers have tried to address this problem by using the traditional transformer model; however, it is not very effective when dealing with complex relationships and the subtle classification requirements of large amounts of sequential data. This work presents a novel solution called the memory flow transformer (MFT) in response to the limitations of the conventional transformer model. By utilizing a carefully designed memory flow structure, MFT transcends traditional limitations and makes it possible to obtain complex long-term features from network traffic. This innovation enables the model to identify deep connections at a finer level between a wide variety of network traffic data. Extensive experiments were carried out on the complex CICIDS 2017 and NSL-KDD datasets to validate the effectiveness of the MFT model. The results were outstanding, demonstrating MFT's powerful detection abilities. With regard to performance metrics like accuracy, F1 score, false alarm rate, and training time, MFT is superior to current state-of-the-art approaches. Network security is greatly strengthened by MFT, which provides practitioners in the intrusion detection field with novel and effective techniques.","2025-01","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","148","","","","","","","","","","English","","","","WOS:001349852400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","CICIDS 2017; Intrusion detection; memory flow; NSL-KDD; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AQR3P2F9","journalArticle","2024","Lin, B; Guo, YY; Luo, H; Ding, MJ","TITE: A transformer-based deep reinforcement learning approach for traffic engineering in hybrid SDN with dynamic traffic","FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE","","0167-739X","10.1016/j.future.2024.07.006","","Hybrid Software Defined Networks (Hybrid SDNs), with a partial upgrade of legacy routers to SDN switches in traditional distributed networks, currently stand as a prevailing network architecture. Traffic Engineering (TE) in hybrid SDN requires the efficient and timely acquisition of a routing policy to adapt to dynamically changing traffic demands, which has recently become a hot topic. Ignoring the hidden relations of consecutive states and the compact representation of the network environment, previous Deep Reinforcement Learning (DRL)-based studies suffer from the convergence problem by only establishing the direct relationship between individual Traffic Matrix (TM) and routing policy. Therefore, to enhance TE performance in hybrid SDNs under dynamically changing traffic demands, we propose to integrate the Transformer model with DRL to establish the relationship between consecutive states and routing policies. The temporal characteristic among consecutive states can effectively assist DRL in solving the convergence problem. To obtain a compact and accurate description of the network environment, we propose to jointly consider TM, routing action, and reward in designing the state of the network environment. To better capture the temporal relations among consecutive states of the network environment, we design a multi-feature embedding module and achieve positional encodings in the Transformer model. The extensive experiments demonstrate that once the convergence problem is solved, the proposed Transformer-based DRL method can efficiently generate routing policies that adapt well to dynamic network traffic.","2024-12","2025-02-26 20:39:13","2025-02-26 20:39:13","","95-105","","","161","","","","","","","","","","English","","","","WOS:001271547500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","ALGORITHMS; Deep Reinforcement Learning; DEMANDS; Dynamic traffic; Hybrid SDN; ROUTING ROBUST; Traffic Engineering; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F2BAKVVL","journalArticle","2022","Baker, E","iCasi to caistes!: Variation in second person singular preterit forms in Spanish Children","JOURNAL OF CHILD LANGUAGE","","0305-0009","10.1017/S0305000921000507","","The current study investigates Spanish children's variation between the standard and nonstandard forms for second person singular preterit s (caiste caistes). All second person singular preterit forms were extracted from the spontaneous speech of 78 children in Spain and analyzed for the effects of age, language contact setting, and lexical frequency. Results show that children in contact with Galician and Catalan produce more non-standard than children in non-contact areas like Madrid. Meanwhile, low-frequency verbs (e.g., pillaste) are more likely to occur with the non-standard -s than high-frequency verbs (e.g., fuiste). However, age is not a significant predictor of children's 2sg preterit production. These preliminary findings demonstrate that Spanish children do have the non-standard -s in their speech, and that their 2sg preterit forms are significantly conditioned by language contact and lexical frequency.","2022-11","2025-02-26 20:39:13","2025-02-26 20:39:13","","1256-1267","","6","49","","","","","","","","","","English","","","","WOS:000771545900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","ACQUISITION; acquisition of sociolinguistic variation; acquisition of Spanish morphosyntax; developmental sociolinguistics; morphosyntactic variation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FZEIT9M3","journalArticle","2021","Linford, B; Harley, A; Brown, EK","SECOND LANGUAGE ACQUISITION OF/S/-WEAKENING IN A STUDY ABROAD CONTEXT","STUDIES IN SECOND LANGUAGE ACQUISITION","","0272-2631","10.1017/S0272263120000571","","This study examines the second language (L2) development of variable /s/-weakening in the spontaneous speech of L2 learners of Spanish who studied abroad in either Dominican Republic, where /s/-weakening is widespread, or central Spain, where /s/-weakening is much less common. Learners' realizations of /s/ were coded impressionistically and acoustically by measuring voicing, center of gravity, and duration. The results show that regardless of the study abroad location, students did not change the amount of sibilance they produced over time. However, they became more nativelike with respect to /s/-voicing and duration. Additionally, whereas some linguistic factors were found to significantly constrain /s/-weakening across groups, learners did not gain sensitivity to all factors that constrain native-speaker /s/-weakening. Findings suggest that exposure to /s/-weakening during a semester abroad is insufficient for learners to adopt this sociolinguistic variable and other social and cognitive factors likely mitigate its integration into the L2 learners' phonological systems.","2021-05","2025-02-26 20:39:13","2025-02-26 20:39:13","","403-427","","2","43","","","","","","","","","","English","","","","WOS:000671929500008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","CONTACT; DELETION; LEARNERS; SPANISH; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YWJCLB4K","journalArticle","2024","Liang, ZY; Chen, H; Zhu, SH; Liang, ZW","Single image deraining via nonlinear recursive Conv-Transformer","INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS","","1868-8071","10.1007/s13042-024-02510-y","","Image deraining is an important foundation of advanced image processing, aiming to reconstruct high-quality clean images from rainy images. In recent years, image deraining algorithms based on convolutional neural networks have become mainstream, and deep learning models based on Transformer have also made significant progress in the field of image restoration. Compared with convolutional neural networks, the image deraining performance of Transformer is slightly inferior. In addition, although excessive parameterization helps improve the generalization performance of Transformer, it can also lead to the network size to be too large to be trained. To address the aforementioned issues, a lightweight image deraining network called the nonlinear recursive Conv-Transformer network is proposed, which not only outperforms the Transformer model but also the convolutional model in terms of performance. Specifically, a dual-branch based on convolutional and Transformer models is first proposed, which integrates the local features extracted by the convolutional model with the global features extracted by the Transformer model; then, a nonlinear projecting block is proposed to implement the constraint recursion and a channel attention module is utilized to fuse multi-branch residual features, which helps in designing lightweight networks. Experiments on a large number of benchmark datasets have demonstrated that the performance of the proposed method is superior to that of state-of-the-art methods, while the computational complexity and parameter quantity are much lower than those of similar methods based on Transformer.","2024-12-27","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","","","","","","","","","","","English","","","","WOS:001384975500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Channel attention; Convolutional network; Image deraining; Nonlinear mapping; RAIN; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AWN8WMWN","journalArticle","2023","Guo, SL; Wen, YH; Zhang, XQ; Chen, HY","Monthly runoff prediction using the VMD-LSTM-Transformer hybrid model: a case study of the Miyun Reservoir in Beijing","JOURNAL OF WATER AND CLIMATE CHANGE","","2040-2244","10.2166/wcc.2023.257","","Accurate runoff prediction is of great significance for flood prevention and mitigation, agricultural irrigation, and reservoir scheduling in watersheds. To address the strong non-linear and non-stationary characteristics of runoff series, a hybrid model of monthly runoff prediction, VMD-LSTM-Transformer, is proposed. Firstly, VMD is used to decompose the runoff series into multiple modal components, and the sample entropy of each modal component is calculated and divided into high-frequency and low-frequency components. The LSTM model is then used to predict the high-frequency components and the transformer to predict the low-frequency components; finally, the prediction results are summed to obtain the final prediction results. The Mann-Kendall trend test method is used to analyze the runoff characteristics of the Miyun Reservoir, and the constructed VMD-LSTM-Transformer model is used to forecast the runoff of the Miyun Reservoir. The prediction results are compared and evaluated with those of VMD-LSTM, VMD-Transformer, EMD-LSTM-Transformer, and EMD-LSTM models. The results show that the NSE value of this model is 0.976, MAE is 0.206 x 10(7) m(3), MAPE is 0.381%, and RMSE is 0.411 x 10(7) m(3), all of which are better than other models, indicating that the VMD-LSTM-Transformer model has higher prediction accuracy and can be applied to runoff prediction in the actual study area.","2023-09","2025-02-26 20:39:13","2025-02-26 20:39:13","","3221-3236","","9","14","","","","","","","","","","English","","","","WOS:001065660400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","DECOMPOSITION; frequency division prediction; LSTM; runoff prediction; transformer; VMD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UDISPII9","journalArticle","2023","Li, YC; Shan, YX; Liu, ZY; Che, C; Zhong, ZQ","Transformer fast gradient method with relative positional embedding: a mutual translation model between English and Chinese","SOFT COMPUTING","","1432-7643","10.1007/s00500-022-07678-5","","Machine translation uses computers to transform one natural language into another. Text-like neural machine translation tasks cannot fully identify the sequence order of texts or the long-term dependence between words, and they suffer from excessive translation and mistranslation. To improve the naturalness, fluency, and accuracy of translation, this study proposes a new training strategy, the transformer fast gradient method with relative positional embedding (TF-RPE), which includes the fast gradient method (FGM) of adversarial training and relative positional embedding. The input sequence is founded on the transformer model, and after the word embedding matrix converts a word vector in the word embedding layer, the positional encoding can be embedded in it through relative positional embedding, helping the word vector to better save the linguistic information of the word (meaning, semantics). The addition of FGM adversarial training to the multi-head attention encoder mechanism strengthens the training of word vectors and reduces the phenomenon of miss-or-error translation, enabling significant improvement of the overall computational efficiency and accuracy of the model. TF-RPE can also provide satisfactory high-quality translations for the low-resource corpus. Extensive ablation studies and comparative analyses validate the effectiveness of the scheme, and TF-RPE achieves an improvement of average 3+ Bilingual evaluation understudy scores compared with the SOTA methods.","2023-09","2025-02-26 20:39:13","2025-02-26 20:39:13","","13435-13443","","18","27","","","","","","","","","","English","","","","WOS:000892909300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","FGM adversarial training algorithm; Multi-attentional mechanism; Neural machine translation; Relative positional embedding; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AXV5VBBI","journalArticle","2021","Hu, SC; Cai, WJ; Gao, TJ; Zhou, JJ; Wang, MJ","Robust wave-feature adaptive heartbeat classification based on self-attention mechanism using a transformer model","PHYSIOLOGICAL MEASUREMENT","","0967-3334","10.1088/1361-6579/ac3e88","","Objective. Electrocardiography is a common method for screening cardiovascular diseases. Accurate heartbeat classification assists in diagnosis and has attracted great attention. In this paper, we proposed an automatic heartbeat classification method based on a transformer neural network using a self-attention mechanism. Approach. An adaptive heartbeat segmentation method was designed to selectively focus on the time-dependent representation of heartbeats. A one-dimensional convolution layer was used to embed wave characteristics into symbolic representations, and then, a transformer block using multi-head attention was applied to deal with the dependence of wave-embedding. The model was trained and evaluated using the MIT-BIH arrhythmia database (MIT-DB). To improve the model performance, the model pre-trained on MIT-BIH supraventricular arrhythmia database (MIT-SVDB) was used and fine-tuned on MIT-DB. Main results. The proposed method was verified using the MIT-DB for two groups. In the first group, our method attained F1 scores of 0.86 and 0.96 for the supraventricular ectopic beat class and ventricular ectopic beat class, respectively. In the second group, our method achieved an average F1 value of 99.83% and better results than other state-of-the-art methods. Significance. We proposed a novel heartbeat classification method based on a transformer model. This method provides a new solution for real-time electrocardiogram heartbeat classification, which can be applied to wearable devices","2021-12-01","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","12","42","","","","","","","","","","English","","","","WOS:000735627300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","adaptive heartbeat segmentation; ECG CLASSIFICATION; heartbeat classification; NETWORK; transformer; wave-embedding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"295ILJ9F","journalArticle","2025","Yang, B; Jiang, ZH; Pan, D; Yu, HY; Gui, G; Gui, WH","LFDT-Fusion: A latent feature-guided diffusion Transformer model for general image fusion","INFORMATION FUSION","","1566-2535","10.1016/j.inffus.2024.102639","","For image fusion tasks, it is inefficient for the diffusion model to iterate multiple times on the original resolution image for feature mapping. To address this issue, this paper proposes an efficient latent feature-guided diffusion model for general image fusion. The model consists of a pixel space autoencoder and a compact Transformer- based diffusion network. Specifically, the pixel space autoencoder is a novel UNet-based latent diffusion strategy that compresses inputs into a low-resolution latent space through downsampling. Simultaneously, skip connections transfer multiscale intermediate features from the encoder to the decoder for decoding, preserving the high-resolution information of the original input. Compared to the existing VAE-GAN-based latent diffusion strategy, the proposed UNet-based strategy is significantly more stable and generates highly detailed images without adversarial optimization. The Transformer-based diffusion network consists of a denoising network and a fusion head. The former captures long-range diffusion dependencies and learns hierarchical diffusion representations, while the latter facilitates diffusion feature interactions to comprehend complex cross-domain information. Moreover, improvements to the diffusion model in noise level, denoising steps, and sampler selection have yielded superior fusion performance across six image fusion tasks. The proposed method illustrates qualitative and quantitative advantages, as evidenced by experimental results in both public datasets and industrial environments. The code is available at: https://github.com/BOYang-pro/LFDT-Fusion.","2025-01","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","113","","","","","","","","","","English","","","","WOS:001301749300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;87</p>","","","ADVERSARIAL NETWORK; GAN; General image fusion; Latent diffusion model; MFF; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DVXTTQER","journalArticle","2023","He, SM; Deng, T; Chen, BW; Sherratt, RS; Wang, J","Unsupervised Log Anomaly Detection Method Based on Multi-Feature","CMC-COMPUTERS MATERIALS & CONTINUA","","1546-2218","10.32604/cmc.2023.037392","","Log anomaly detection is an important paradigm for system troubleshooting. Existing log anomaly detection based on Long Short-Term Memory (LSTM) networks is time-consuming to handle long sequences. Transformer model is introduced to promote efficiency. However, most existing Transformer-based log anomaly detection methods convert unstructured log messages into structured templates by log parsing, which introduces parsing errors. They only extract simple semantic feature, which ignores other features, and are generally supervised, relying on the amount of labeled data. To overcome the limitations of existing methods, this paper proposes a novel unsupervised log anomaly detection method based on multi-feature (UMFLog). UMFLog includes two sub-models to consider two kinds of features: semantic feature and statistical feature, respectively. UMFLog applies the log original content with detailed parameters instead of templates or template IDs to avoid log parsing errors. In the first sub-model, UMFLog uses Bidirectional Encoder Representations from Transformers (BERT) instead of random initialization to extract effective semantic feature, and an unsupervised hypersphere-based Transformer model to learn compact log sequence representations and obtain anomaly candidates. In the second sub-model, UMFLog exploits a statistical feature-based Variational Autoencoder (VAE) about word occurrence times to identify the final anomaly from anomaly candidates. Extensive experiments and evaluations are conducted on three real public log datasets. The results show that UMFLog significantly improves F1scores compared to the state-of-the-art (SOTA) methods because of the multifeature.","2023","2025-02-26 20:39:13","2025-02-26 20:39:13","","517-541","","1","76","","","","","","","","","","English","","","","WOS:001020942100031","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","anomaly detection; features; semantic features; statistical; System log; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DX92XH8P","journalArticle","2024","Rao, SR; Shi, H","EFFECTS OF PSYCHOLOGICAL STRESS AND ANXIETY ON PERFORMANCE AND COPING STRATEGIES IN ATHLETES","REVISTA INTERNACIONAL DE MEDICINA Y CIENCIAS DE LA ACTIVIDAD FISICA Y DEL DEPORTE","","1577-0354","10.15366/rimcafd2024.94.030","","Competitive sports are social sports activities with the main goal of winning competitions, which require athletes' physical and psychological abilities to be extremely high. Therefore, paying attention to the psychological health of outstanding athletes and improving their comprehensive quality are crucial to improving their sports performance. Traditional measures of psychological stress and anxiety mainly measure subjective stress feelings through stress perception scales, which ignores objective physiological indicators, while electroencephalogram (EEG), as an objective physiological data, has a strong correlation with different psycho -physiological conditions. Traditional feature extraction algorithms combined with machine learning require a large amount of a priori knowledge, while deep learning does not require a priori knowledge to deeply mine the deep features of the data. Therefore, this paper identifies and analyses psychological stress and anxiety in athletes based on deep learning by combining physiological data obtained from EEG signals and subjective data obtained from stress perception scales. Specifically, a stress EEG signal recognition model based on Transformer is proposed, the Transformer model in deep learning is explored, the encoder module in the Transformer model is applied to EEG signal analysis, and adaptive improvements are made and parameter optimization is carried out to be suitable for EEG signal analysis. Then experiments were carried out on two EEG signal public datasets, and the simulation experiment results proved the effectiveness of the proposed method.","2024-01","2025-02-26 20:39:13","2025-02-26 20:39:13","","482-497","","94","24","","","","","","","","","","English","","","","WOS:001174139300010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;14</p>","","","AMERICAN MEDICAL SOCIETY; Coping Strategies; MANAGEMENT; MENTAL-HEALTH ISSUES; Psychological Anxiety; Psychological Stress","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"93LN9IG5","journalArticle","2023","Jin, X; Zhou, J; Rao, Y; Zhang, XD; Zhang, W; Ba, WJ; Zhou, XH; Zhang, T","An innovative approach for integrating two-dimensional conversion of Vis-NIR spectra with the Swin Transformer model to leverage deep learning for predicting soil properties","GEODERMA","","0016-7061","10.1016/j.geoderma.2023.116555","","The application of visual-near-infrared and shortwave-infrared (VNIR-SWIR) diffuse reflectance spectroscopy for soil properties analysis is increasingly gaining popularity due to its rapid, cost-effective, and non-destructive nature. In particular, deep learning models have been found to perform exceptionally well for large spectra libraries. This study proposes a novel approach to enhance the deep learning approach that involves converting one-dimensional spectra into two-dimensional (2D) spectral images. We investigated several methods, such as cutting reshape (CR), Gramian angular difference field (GADF), Gramian angle sum field (GASF), and Markov transition field (MTF). We then combine these converted images with the Swin Transformer model to predict a range of soil properties. Furthermore, we compare our proposed method with existing techniques reported in the literature. The results showed that the root mean square error (RMSE) of predicting soil organic carbon content (OC (g.kg(-1))), nitrogen content (N (g.kg(-1))), cation exchange capacity (CEC (cmol(+).kg(-1))), pH, and sand (%) and clay content (%) using Gram's angular difference field (GADF) and Swin Transformer were 23.25, 1.26, 8.55, 0.54, 15.33, 6.14, and determination coefficients R2 of 0.95, 0.92, 0.79, 0.90, 0.74 and 0.84, respectively. This study introduces a new perspective to enhance deep learning models for soil spectroscopy.","2023-08","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","436","","","","","","","","","","English","","","","WOS:001019623100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Deep learning; Gramian angular difference field; Soil spectroscopy; Spectrograms; SPECTROSCOPY; Swin Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"34VYRHEF","journalArticle","2023","Gu, XY; See, KW; Li, PH; Shan, KH; Wang, YP; Zhao, L; Lim, KC; Zhang, N","A novel state-of-health estimation for the lithium-ion battery using a convolutional neural network and transformer model","ENERGY","","0360-5442","10.1016/j.energy.2022.125501","","State-of-health (SOH) estimation of lithium-ion batteries is crucial for ensuring the reliability and safety of battery operation while keeping maintenance and service costs down in the long run. This study suggests a novel SOH estimation based on data pre-processing methods and a convolutional neural network (CNN)-Transformer framework. In data pre-processing, highly related features are selected by the Pearson correlation coefficient (PCC). Principal correlation analysis (PCA) is also employed to minimize the computational burden of the estimation model by eliminating redundant feature information. Then, all the features are normalized by the min-max feature scaling method, which will speed up the training process to reach the minimum cost function. After pre-processing, all the features are fed into the CNN-Transformer model. The dataset of the battery from the NASA is employed as a training and testing dataset to build the proposed model. The simulations indicate that the proposed performance, proven by absolute estimation errors for each dataset, is within 1%. The estimation performance index is proven by mean absolute error (MAE), mean absolute percentage error (MAPE), and root mean square error (RMSE) are held within 0.55%. These show that the proposed model can estimate the battery SOH with high accuracy and stability.","2023-01-01","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","262","","","","","","","","","","English","","","","WOS:000879215000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;111<br/>Total Times Cited:&nbsp;&nbsp;112<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","CAPACITY ESTIMATION; CHARGE; Convolution neural network (CNN); Lithium -ion battery; Long short-term memory (LSTM); SINGLE-PARTICLE MODEL; State -of -health (SOH); Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"REUMCP4P","journalArticle","2024","Rahman, AU; Alsenani, Y; Zafar, A; Ullah, K; Rabie, K; Shongwe, T","Enhancing heart disease prediction using a self-attention-based transformer model","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-51184-7","","Cardiovascular diseases (CVDs) continue to be the leading cause of more than 17 million mortalities worldwide. The early detection of heart failure with high accuracy is crucial for clinical trials and therapy. Patients will be categorized into various types of heart disease based on characteristics like blood pressure, cholesterol levels, heart rate, and other characteristics. With the use of an automatic system, we can provide early diagnoses for those who are prone to heart failure by analyzing their characteristics. In this work, we deploy a novel self-attention-based transformer model, that combines self-attention mechanisms and transformer networks to predict CVD risk. The self-attention layers capture contextual information and generate representations that effectively model complex patterns in the data. Self-attention mechanisms provide interpretability by giving each component of the input sequence a certain amount of attention weight. This includes adjusting the input and output layers, incorporating more layers, and modifying the attention processes to collect relevant information. This also makes it possible for physicians to comprehend which features of the data contributed to the model's predictions. The proposed model is tested on the Cleveland dataset, a benchmark dataset of the University of California Irvine (UCI) machine learning (ML) repository. Comparing the proposed model to several baseline approaches, we achieved the highest accuracy of 96.51%. Furthermore, the outcomes of our experiments demonstrate that the prediction rate of our model is higher than that of other cutting-edge approaches used for heart disease prediction.","2024-01-04","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","1","14","","","","","","","","","","English","","","","WOS:001136960700086","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","FAILURE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CDU3YM8K","journalArticle","2024","Li, DL; Fu, QW","Deep Learning Model-Based Demand Forecasting for Secondary Water Supply in Residential Communities: A Case Study of Shanghai City, China","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3288817","","To promote intelligent water services and accelerate the water industry's modernization process, accurately predicting regional residents' water demand and reducing energy consumption for secondary water supply is a major challenge for scientific scheduling and efficient management of urban water supply. This paper proposes a deep learning-based approach for demand forecasting in residential communities. The approach first identifies and corrects outliers in raw water supply data, and incorporates additional features such as epidemics and meteorological information. A long and short time Transformer model (LTMFormer) is then proposed, combining the recursive mechanism of the LSTM model and the parallel mechanism of the Transformer to achieve parallel output in the long-time series modeling task, improving both the prediction length and accuracy of the model. We evaluate our model on a metering dataset of 20 cells in Shanghai and compare it to traditional deep-learning models. Our experimental results demonstrate that the proposed model outperforms other deep learning models, achieving MSE, RMSE, and MAE scores of 3.337, 4.536, and 1.848 respectively on the test set. These results provide a theoretical and technical basis for further safeguarding public water health and meeting the growing demand for better urban water management.","2024","2025-02-26 20:39:13","2025-02-26 20:39:13","","38745-38757","","","12","","","","","","","","","","English","","","","WOS:001188380600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","deep learning; Deep learning; Demand forecasting; Energy consumption; Intelligent systems; Job shop scheduling; LSTM model; outlier identification; Predictive models; SEASONAL ARIMA MODELS; transformer model; Transformers; Water demand prediction; Water resources","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JID3H3FZ","journalArticle","2024","Tuli, S; Jha, NK","EdgeTran: Device-Aware Co-Search of Transformers for Efficient Inference on Mobile Edge Platforms","IEEE TRANSACTIONS ON MOBILE COMPUTING","","1536-1233","10.1109/TMC.2023.3328287","","Automated design of efficient transformer models has recently attracted significant attention from industry and academia. However, most works only focus on certain metrics while searching for the best-performing transformer architecture. Furthermore, running traditional, complex, and large transformer models on low-compute edge platforms is a challenging problem. In this work, we propose a framework, called ProTran, to profile the hardware performance measures for a design space of transformer architectures and a diverse set of edge devices. We use this profiler in conjunction with the proposed co-search technique to obtain the best-performing models that have high accuracy on the given task and minimize latency, energy consumption, and peak power draw to enable edge deployment. We refer to our framework for co-optimizing accuracy and hardware performance measures as EdgeTran. It searches for the best transformer model and edge device pair. Finally, we propose GPTran, a multi-stage block-level grow-and-prune post-processing step that further improves accuracy in a hardware-aware manner. The obtained transformer model is 2.8x smaller and has a 0.8% higher GLUE score than the baseline (BERT-Base). Inference with it on the selected edge device enables 15.0% lower latency, 10.0x lower energy, and 10.8x lower peak power draw compared to an off-the-shelf GPU.","2024-06","2025-02-26 20:39:13","2025-02-26 20:39:13","","7012-7029","","6","23","","","","","","","","","","English","","","","WOS:001216462000048","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","Adaptation models; Computational modeling; Computer architecture; Embedded platforms; Energy consumption; Hardware; hardware-software co-design; machine learning; Optimization; transformer design space; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GL9MB9RZ","journalArticle","2023","Tang, L; Shi, KB; Shen, HT; Soh, YC","Application of Transformer Model in Peak Correction of X-Ray Fluorescence Spectra","IEEE TRANSACTIONS ON NUCLEAR SCIENCE","","0018-9499","10.1109/TNS.2023.3320807","","A novel estimation model based on deep learning is proposed for estimating the pulse amplitude of photons incident upon a silicon drift detector in X-ray spectroscopic systems. It is specifically designed for accurate analysis of spectroscopy where amplitude estimation of distorted pulses is an issue. A key step in the training of the estimation model is embedding of positional encoding and the calculation of multihead attention. This model uses the timing information in the input signal by adding positional encoding, improves the learning ability of the model, and realizes the accurate estimation of the amplitude parameters of the nuclear pulse signals. The simulation results show that the Transformer model can not only overcome the shortcomings of the traditional digital shaping methods in the inaccurate estimation of the amplitude of the distorted pulses but also improve the problem of the recurrent neural network (RNN) model's poor ability to capture the remote information and can accurately estimate the amplitude parameters of the pulse with different degrees of distortion. During the experimental verification process, the peak area correction ratio is 93.01% in the region of interest (ROI) of Se, and the peak area correction ratio is 97.74% in the ROI of Sn. The model exhibits higher pulse estimation accuracy than other state-of-the-art pulse estimation methods and corrects the peak area in the ROI of characteristic peak while being much faster to compute.","2023-11","2025-02-26 20:39:13","2025-02-26 20:39:13","","2479-2489","","11","70","","","","","","","","","","English","","","","WOS:001122724000004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Deep learning; NOISE; PILE-UP; positional encoding; spectral peak correction; Spectroscopy; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2WL44QHQ","journalArticle","2022","Zhu, JQ; Ma, YW","Atorvastatin treatment in a patient with post-traumatic hydrocephalus: a case report","BRAIN INJURY","","0269-9052","10.1080/02699052.2022.2109750","","Objectives Clinical treatment of post-traumatic hydrocephalus (PTH) is limited to cerebrospinal fluid (CSF) extracranial shunting, and research on noninvasive treatment is still lacking. In a follow-up study of a patient with PTH, atorvastatin treatment was beneficial in controlling hydrocephalus and promoting neurological recovery. Method A 29-year-old male patient with traumatic brain injury (TBI) was found to have progressive hydrocephalus and presented with symptoms of decreased spontaneous speech and delayed functional recovery. We added oral treatment with 20 mg/day atorvastatin and followed up hydrocephalus with head CT every two months. Results The span of the third ventricle decreased by 21%, Evan's index fell by 16%, and the Fugl-Meyer motor score was up from 17/100 to 56/100. The Montreal Cognitive Assessment score was modified from 15/30 to 23/30. Conclusion The use of atorvastatin in the patient may improve the imaging results and benefit the patient functionally.","2022-07-29","2025-02-26 20:39:13","2025-02-26 20:39:13","","1204-1206","","9","36","","","","","","","","","","English","","","","WOS:000843039200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;10</p>","","","atorvastatin treatment; delayed recovery of neurological function; Evans index; Post-traumatic hydrocephalus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X7I3PMSK","journalArticle","2021","Barker, MS; Knight, JL; Dean, RJ; Mandelstam, S; Richards, LJ; Robinson, GA","Verbal Adynamia and Conceptualization in Partial Rhombencephalosynapsis and Corpus Callosum Dysgenesis","COGNITIVE AND BEHAVIORAL NEUROLOGY","","1543-3633","10.1097/WNN.0000000000000261","","Verbal adynamia is characterized by markedly reduced spontaneous speech that is not attributable to a core language deficit such as impaired naming, reading, repetition, or comprehension. In some cases, verbal adynamia is severe enough to be considered dynamic aphasia. We report the case of a 40-year-old, left-handed, male native English speaker who presented with partial rhombencephalosynapsis, corpus callosum dysgenesis, and a language profile that is consistent with verbal adynamia, or subclinical dynamic aphasia, possibly underpinned by difficulties selecting and generating ideas for expression. This case is only the second investigation of dynamic aphasia in an individual with a congenital brain malformation. It is also the first detailed neuropsychological report of an adult with partial rhombencephalosynapsis and corpus callosum dysgenesis, and the only known case of superior intellectual abilities in this context.","2021-03","2025-02-26 20:39:13","2025-02-26 20:39:13","","38-52","","1","34","","","","","","","","","","English","","","","WOS:000647756900004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;108</p>","","","adynamia; AGENESIS; AUTISM; CEREBELLUM; COGNITIVE-AFFECTIVE SYNDROME; COMPREHENSION; corpus callosum dysgenesis; dynamic aphasia; DYNAMIC APHASIA; LOPEZ-HERNANDEZ SYNDROME; PROGRESSIVE SUPRANUCLEAR PALSY; RESPONSE SELECTION; rhombencephalosynapsis; SPEECH PRODUCTION; spoken language","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"29QP8DFX","journalArticle","2023","Rose, C; McBride, AF","French pronunciation instruction using the PACE model","FOREIGN LANGUAGE ANNALS","","0015-718X","10.1111/flan.12711","","As an overwhelming amount of research has demonstrated that educator preparation programs do not adequately prepare instructors to teach pronunciation, this study aims to help teachers of foreign languages to implement and improve pronunciation instruction (PI) in their classroom by adapting PACE (Presentation, Attention, Co-construction, and Extension), the commonly used model for grammar instruction. The present study explores the efficacy of this model in improving learners' ability (1) to associate target phonemes with the appropriate phonological context and (2) to produce target phonemes distinctly in a spontaneous speech task. Data suggest that a modified PACE model for PI can be effective in both intermediate- and advanced-level courses. The possibility of adapting an existing and well-known method for teaching grammar would allow teachers to implement and/or improve their PI with minimal additional training.","2023-09","2025-02-26 20:39:13","2025-02-26 20:39:13","","532-551","","3","56","","","","","","","","","","English","","","","WOS:001040504500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","2ND-LANGUAGE PRONUNCIATION; all languages; BELIEFS; curriculum and curriculum development; foreign; FORM; in-service and professional development; LEARNERS; phonetics; PHONETICS; phonology; pronunciation; second language teacher preparation; TEACHERS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NXXQ94ZN","journalArticle","2023","Travis, CE; Cacoullos, RT","Form and function covariation: Obligation modals in Australian English","LANGUAGE VARIATION AND CHANGE","","0954-3945","10.1017/S0954394523000200","","Shifts in the frequencies of English modals of obligation have been linked to shifts in modal function and changing interpersonal authority. Interpretation of over 2,000 tokens in spontaneous speech data recorded in Sydney, Australia, in the 1970s and 2010s establishes a replicable classification of obligation meanings, based on source of obligation, with a three-way distinction between Hierarchical authority, General circumstances, and Personal choice. Competing expressions for these obligation types, besides have to, have got to, and older must, include should and, recently, need to. Two sets of regression analyses provide evidence of covariation of form and function: first, the linguistic and social conditioning of forms, with meaning as one of the predictors; and second, the conditioning of function, with modal form as a predictor. Need to rises in real time and so does talk of personal obligation. However, the change in modal function is concomitant with, but independent of, shifting modal forms.","2023-10","2025-02-26 20:39:13","2025-02-26 20:39:13","","351-377","","3","35","","","","","","","","","","English","","","","WOS:001089680800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Australian English; CONVERSATION; EXPRESSION; form-function covariation; modals of obligation; need to; obligation meanings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"66KJAXY6","journalArticle","2025","Mori, H; Nishino, H","End-to-end conversational speech synthesis with controllable emotions in the dimensions of pleasantness and arousal","ACOUSTICAL SCIENCE AND TECHNOLOGY","","1346-3969","10.1250/ast.e24.13","","We propose an end-to-end conversational speech synthesis system that allows for flexible control of emotional states defined over emotion dimensions. We extend the Tacotron 2 and VITS architectures to accept emotion dimensions as input. Initially, the model is pre-trained using a largescale spontaneous speech corpus, followed by fine-tuning using a natural dialogue speech corpus with manually annotated perceived emotion in the form of pleasantness and arousal. Since the pre-training lacks emotion information, we explore two pre-training strategies and demonstrate that applying an emotion dimension estimator before the pre-training enhances emotion controllability. Evaluation of the synthesized speech using VITS yields a mean opinion score of 4 or higher for naturalness. Furthermore, there is a correlation of R = 0.53 for pleasantness and R = 0.89 for arousal between the given and perceived emotional states. These results underscore the effectiveness of our proposed conversational speech synthesis system with emotion control.","2025","2025-02-26 20:39:13","2025-02-26 20:39:13","","70-77","","1","46","","","","","","","","","","English","","","","WOS:001382144300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","Conversational agents; Dialog; Emotion dimensions; TTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5Q6HI2UF","journalArticle","2024","Bill, C; Driemel, I; Yatsushiro, K; Hein, J; Sauerland, U","Kein subjects are hard: Exploring German-speaking children's behavior with negative indefinites","LANGUAGE ACQUISITION","","1048-9223","10.1080/10489223.2024.2354219","","In this article, we present converging results from three studies investigating children's production or comprehension of the negative indefinite kein in German. An elicited production study found that 3- to 6-year-old children and adults exhibit different patterns with respect to the production of kein: children, but not adults, exhibit an asymmetry with respect to the position where they produce negative indefinites, in that they use negative indefinites more frequently in object position than in subject position. A corpus study investigating spontaneous speech replicated this asymmetry for children but this time found it also present for adults. Finally, the asymmetry is corroborated by a comprehension study indicating a processing cost for negative indefinite subjects relative to negative indefinite objects. We argue that these patterns are most straightforwardly captured by an explanation that assumes the decomposition approach to the German negative indefinite kein: rather than a single semantic unit (i.e. negative quantifier), kein is decomposed into a negative part and an indefinite part.","2024-06-16","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","","","","","","","","","","","English","","","","WOS:001248627200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","CONCORD; ENGLISH; MOVEMENT; TIME","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GCVWZUFR","journalArticle","2024","Preeshl, A","Gullah-Geechee Accents in English on Daufuskie and Sapelo Islands","VOICE AND SPEECH REVIEW","","2326-8263","10.1080/23268263.2022.2130294","","In Gullah-Geechee accents in English, centralizing, rounding, backing, and lowering vowels, monophthongizing diphthongs, and simplifying consonant cluster were expected in comparison with the So-Called General American (SCGA) accent. Five Sapelo Island interviewees and three Daufuskie Island interviewees from Gullah-Geechee communities read ""Arthur the Rat"" and told stories about growing up. Centralization, rounding, raising, backing, and monophthongization were realized more often than lowering and unrounding. Several interviewees unrounded vowels in stories about growing up. Devoicing initial and/or final consonants, and substituting plosives for SCGA fricatives or affricates, connected this accent to Gullah creole and Krio. Sapelo interviewees centralized, monophthongized, diminished rhoticity, and sibilant endings, and/or shortened nasal and lateral endings in ""Arthur the Rat,"" adding raising, backing, substituting plosives for affricates, and simplifying consonant cluster in spontaneous speech. Daufuskie interviewees significantly varied realizations. Sapelo interviewees incorporated more Gullah-Geechee features than Daufuskie interviewees in Gullah-Geechee accents in English.","2024-01-02","2025-02-26 20:39:13","2025-02-26 20:39:13","","44-52","","1","18","","","","","","","","","","English","","","","WOS:000865378000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","accents; African Diaspora; climate change; dialects; Gullah-Geechee; Red-lining; sociolinguistics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4EINCKGB","journalArticle","2021","Rao, J; Hu, GJ; Yang, WJ; Yu, JW; Xue, C; Tian, L; Chen, J","Recovery of aphemia with pure word dumbness after treatment with repetitive transcranial magnetic stimulation: A case report","JOURNAL OF NEUROLINGUISTICS","","0911-6044","10.1016/j.jneuroling.2021.100991","","Aphemia with pure word dumbness is a relatively rare clinical syndrome caused by injury to the Broca area of the dominant hemisphere. Patients with this syndrome have significant difficulties in oral expression, whereas other language functions, such as written expression and comprehension, are normal. In this study, a patient without no evidence of structural brain lesions presented with aphemia with pure word dumbness after head trauma of the frontal lobe. Through magnetic resonance imaging (MRI) examinations, functional abnormalities (regional homogeneity, degree centrality, and language network) were found in the patient without structural alterations. After four weeks of treatment with repetitive transcranial magnetic stimulation (rTMS) and cognitive evaluation every week, we found that the patient's linguistic function (i.e., spontaneous speech, speech comprehension, rehearsal, naming, reading, writing and the aphasia quotient) recovered gradually. Therefore, rTMS may be an adjuvant therapy for the recovery of aphemia patients with pure word dumbness.","2021-08","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","59","","","","","","","","","","English","","","","WOS:000656680400012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","Aphemia; Broca&apos; DEPRESSION; Oral express disorder; Pure word dumbness; Repetitive transcranial magnetic stimulation; s area","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I8VGMYF5","journalArticle","2021","Lancien, M; Côté, MH","Hypoarticulation as a tool for assessing addressed to different types of interlocutors","STUDII DE LINGVISTICA","","2248-2547","","","Work within Hyper-Hypoarticulation Theory (H&H) and Communication Accommodation Theory (CAT) is increasingly focused on the adaptation of speech to the identity of the interlocutor (Koppen et al. 2017, Pardo et al. 2012, among others). These studies show a correlation between changes in the rate and spectral characteristics of speech (especially vowels) and the relationship between the speakers. Using the Diapix task (Baker & Hazan 2011), 10 Quebec-French-speaking couples were invited to interact together and with two strangers, one French and one Quebecois. This produced a corpus of 25h of speech and 121000 vowels. Spectral variations (especially hyper- / hypo- articulation), and changes in speech rate depending on the interlocutor, were studied using ((G)LMM) analysis. Our results reveal a correlation between the degree of social distance and speech reduction: the closer the interlocutors are (partners), the more speech is reduced","2021","2025-02-26 20:39:13","2025-02-26 20:39:13","","55-84","","","11","","","","","","","","","","English","","","","WOS:000758090900004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","acoustics; FUNDAMENTAL-FREQUENCY; LANGUAGE; PHONETIC CONVERGENCE; phonostylistics; Quebec French; social distance; sociophonetics; SPONTANEOUS SPEECH; VARIABILITY; VOCAL ACCOMMODATION; vowel variation; VOWELS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2M53CRH3","bookSection","2021","Meltzer-Asscher, A","Resumptive Pronouns in Language Comprehension and Production","ANNUAL REVIEW OF LINGUISTICS, VOL 7","2333-9691","","","","Although the grammatical status of resumptive pronouns varies from one language to the other, these elements occur in spontaneous speech cross-linguistically, giving rise to a long-held intuition that resumption has a processing function, facilitating production and/or comprehension. In this review, I examine the central threads of thought related to resumption and processing and consider the prominent theories and findings that have shaped the discussion on this issue. I review grammatical and grammaticalization-based approaches to resumption and present the evidence suggesting that resumptive pronouns are a production artifact as well as the evidence that speaks in favor of or against the idea that resumptive pronouns aid comprehension. While the theory that resumption aids the producer receives straightforward support, the findings backing the claim that resumption helps the comprehender are much more equivocal, suggesting that in some cases resumption is not helpful and may even be detrimental to comprehension.","2021","2025-02-26 20:39:13","2025-02-26 20:39:13","","177-194","","","7","","","","","","","","","","English","","","","WOS:000614614700011","","","DOI: 10.1146/annurev-linguistics-031320-012726","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;80</p>","","","COMPLEXITY; DEPENDENCIES; filler-gap dependencies; GAP; GRAMMAR; INTERFACE; INTERFERENCE; MEMORY; RELATIVE CLAUSES; resumptive pronouns; sentence comprehension; sentence processing; sentence production; syntactic islands","","Liberman, MY; Partee, BH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SQYWBAV2","journalArticle","2024","Ye, QS; Wang, H; Xu, FD; Zhang, SJ; Zhang, SL; Yang, ZW; Zhang, L","Co-Mutations and Possible Variation Tendency of the Spike RBD and Membrane Protein in SARS-CoV-2 by Machine Learning","INTERNATIONAL JOURNAL OF MOLECULAR SCIENCES","","1661-6596","10.3390/ijms25094662","","Since the onset of the coronavirus disease 2019 (COVID-19) pandemic, SARS-CoV-2 variants capable of breakthrough infections have attracted global attention. These variants have significant mutations in the receptor-binding domain (RBD) of the spike protein and the membrane (M) protein, which may imply an enhanced ability to evade immune responses. In this study, an examination of co-mutations within the spike RBD and their potential correlation with mutations in the M protein was conducted. The EVmutation method was utilized to analyze the distribution of the mutations to elucidate the relationship between the mutations in the spike RBD and the alterations in the M protein. Additionally, the Sequence-to-Sequence Transformer Model (S2STM) was employed to establish mapping between the amino acid sequences of the spike RBD and M proteins, offering a novel and efficient approach for streamlined sequence analysis and the exploration of their interrelationship. Certain mutations in the spike RBD, G339D-S373P-S375F and Q493R-Q498R-Y505, are associated with a heightened propensity for inducing mutations at specific sites within the M protein, especially sites 3 and 19/63. These results shed light on the concept of mutational synergy between the spike RBD and M proteins, illuminating a potential mechanism that could be driving the evolution of SARS-CoV-2.","2024-05","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","9","25","","","","","","","","","","English","","","","WOS:001220038600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","BALANCE; BIOLOGY; co-mutations; CONTACTS; COVID-19; HEMAGGLUTININ; INFLUENZA-A VIRUS; mutational synergy; NEURAMINIDASE; RATES; SARS-CoV-2; sequence analysis; sequence-to-sequence transformer model; TRANSMISSION; VARIANT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z72A7UE8","journalArticle","2024","Sun, YL; Lian, JG; Teng, Z; Wei, ZY; Tang, Y; Yang, L; Gao, YJ; Wang, TF; Li, HF; Xu, M; Lei, BY","COVID-19 diagnosis based on swin transformer model with demographic information fusion and enhanced multi-head attention mechanism","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2023.122805","","Coronavirus disease 2019 (COVID-19) is an acute disease, which can rapidly become severe. Hence, it is of great significance to realize the automatic diagnosis of COVID-19. However, existing models are often inapplicable for fusing patients' demographic information due to its low dimensionality. To address this, we propose a COVID-19 patient diagnosis method with feature fusion and a model based on Swin Transformer. Specifically, two auxiliary tasks are added for fusing computed tomography (CT) images and patients' demographic information, which utilizes the patients' demographic information as the label for the auxiliary tasks. Besides, our approach involves designing a Swin Transformer model with Enhanced Multi-head Self-Attention (EMSA) to capture different features from CT data. Meanwhile, the EMSA module is able to extract and fuse attention information in different representation subspaces, further enhancing the performance of the model. Furthermore, we evaluate our model in COVIDx CT-3 dataset with different tasks to classify Normal Controls (NC), COVID-19 cases and community-acquired pneumonia (CAP) cases and compare the performance of our method with other models, which show the effectiveness of our model. In addition, we have conducted various visualization efforts to demonstrate the interpretability of our model, including principal component analysis, attention heatmaps, etc. Various results indicate that our model is capable of making reasonable diagnosis.","2024-06-01","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","243","","","","","","","","","","English","","","","WOS:001141204500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","COVID-19 diagnosis; Demographic information fusion; Enhanced Multi-head Self-Attention; Swin Transformer; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CTZXHYMW","journalArticle","2022","Regan, B","The social meaning of a merger: The evaluation of an Andalusian Spanish consonant merger (ceceo)","LANGUAGE IN SOCIETY","","0047-4045","10.1017/S0047404521000543","","This study analyzes the social evaluations of the Andalusian Spanish ceceo merger and its split, distincion. A matched-guise experiment was created by digitally manipulating spontaneous speech from twelve Western Andalusian speakers, varying only in syllable-initial [s] and [theta] for < s > and < z, ci, ce >, creating ceceo and distincion guises. Based on 221 listeners from Huelva and Lepe, Spain, mixed effects linear regression models found that speakers with distincion guises were evaluated as being of higher social status, more urban, and more formal than speakers with ceceo guises. Additionally, listeners' comments referred not only to the sounds and graphemes, but also to the merger itself and its social connotations. The implications are two-fold: (i) consonant mergers may be subject to more overt social evaluation than vocalic mergers; and (ii) a merger can acquire social meaning, and this meaning in turn, may promote its split.","2022-06","2025-02-26 20:39:13","2025-02-26 20:39:13","","481-510","","3","51","","","","","","","","","","English","","","","WOS:000780263000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;108</p>","","","Andalusian Spanish; ceceo; CONTACT; dialect levelling; distincion; language attitudes; LISTENER; Mergers; PERCEPTION; S/; sociolinguistic perception; sociophonetics; SPEECH; splits","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ANEA4FSN","journalArticle","2024","Mujadia, V; Mishra, P; Sharma, DM","Disfluency annotated corpora for Indian English in technical domains","LANGUAGE RESOURCES AND EVALUATION","","1574-020X","10.1007/s10579-024-09781-5","","Disfluencies are common in spontaneous speech and can significantly affect the accuracy of automated systems that process spoken input. In this work, we tackled this issue for Indian English by developing a human-annotated disfluency corpus (DASIE (H)) comprising over 240K words for the technical lecture domain. To have a larger disfluency dataset, we introduced a method to generate synthetic disfluency, employing contextual embeddings and shallow linguistic features such as part-of-speech patterns. This algorithm allowed us to generate a synthetic disfluency corpus (DASIE (S)) that exceeds 15.4 million words. We evaluate the efficacy of our disfluency-annotated corpora by developing models for disfluency identification. Our efforts result in achieving the highest F1 score of 0.93 on the Switchboard test set and 0.80 on the DASIE (H) test set with the coarser disfluency identifier. The resulting corpora and model can be utilized to effectively detect and process disfluencies in various speech-interfacing applications.","2024-10-26","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","","","","","","","","","","","English","","","","WOS:001342062200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","Disfluency for Indian English; Disfluency processing; Indian languages; Speech translation; Technical domain","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FTSY9SNQ","journalArticle","2023","Nebot, AC; Navarro, AH","[en] Phonic characterization of (im)politeness in spoken Spanish (Valencia, Spain). A qualitative and quantitative approach","CIRCULO DE LINGUISTICA APLICADA A LA COMUNICACION","","1576-4737","10.5209/clac.82314","","This paper presents the results of a qualitative-quantitative study of the Fonocortesia (Phonopoliteness) database (http:// fonocortesia.es). Fonocortesia, collected thanks a project (FFI2009-07034-FILO) and carried out between 2009 and 2013, includes 278 samples of (im)politeness in spontaneous speech. These (im)polite fragments were selected and later analysed by the research team of the project, and have been now processed with the computational tool Oralstats (<https://github.com/acabedo/oralstats>), which allows to carry out statistical analyses along with a basic exploration of speech databases. Thus, the previous qualitative approach has been completed applying a a factor analysis of mixed data (FAMD) that combines quantitative and qualitative data. Despite the important variation in the data, the general results point to a correlation between a) impoliteness with high values of F0 and ascending tonemes, but also b) politeness with high F0 values.","2023","2025-02-26 20:39:13","2025-02-26 20:39:13","","131-149","","93","","","","","","","","","","","English","","","","WOS:000936935300009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","(im)politeness; MITIGATION; Oralstats; POLITENESS; prosody; SPEECH; statistics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MW929QJ6","journalArticle","2024","Saito, K","Age effects in spoken second language vocabulary attainment beyond the critical period","STUDIES IN SECOND LANGUAGE ACQUISITION","","0272-2631","10.1017/S0272263122000432","","The current study set out to examine to what degree age of acquisition (AOA), defined as a learner's first intensive exposure to a second language (L2) environment, mediates the final state of postpubertal, spoken vocabulary attainment. In Study 1, spontaneous speech samples were elicited from experienced Japanese users of English (n = 41) using storytelling and interview tasks. The samples were analyzed using a range of corpus- and rater-based lexical measures and compared to the speech of inexperienced Japanese speakers (n = 40) and native speakers of English (n = 10). The results showed that most experienced L2 learners tended to demonstrate nativelike proficiency for relatively easy lexical dimensions of speech (i.e., richness), but that AOA appeared to play a key role in predicting the ultimate attainment of relatively difficult lexical dimensions (i.e., appropriateness). In Study 2, the findings were successfully replicated with experienced L1 Polish users of English (n = 50).","2024-03","2025-02-26 20:39:13","2025-02-26 20:39:13","","3-27","","1","46","","","","","","","","","","English","","","","WOS:000883183100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;86</p>","","","2ND LANGUAGE; ACQUISITION; CORPUS; ENGLISH; FLUENCY; FOREIGN ACCENT; LEXICAL SOPHISTICATION; OF-ONSET; SPEAKERS; VERTICAL-BAR","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UE7EXTED","journalArticle","2023","Young, NJ; McGarrah, M","Forced alignment for Nordic languages: Rapidly constructing a high-quality prototype","NORDIC JOURNAL OF LINGUISTICS","","0332-5865","10.1017/S033258652100024X","","We propose a rapid adaptation of FAVE-Align to the Nordic languages, and we offer our own adaptation to Swedish as a template. This study is motivated by the fact that researchers of lesser-studied languages often neither have sufficient speech material nor sufficient time to train a forced aligner. Faced with a similar problem, we made a limited number of surface changes to FAVE-Align so that it - along with its original hidden Markov models for English - could be used on Stockholm Swedish. We tested the performance of this prototype on the three main sociolects of Stockholm Swedish and found that read-aloud alignments met all of the minimal benchmarks set by the literature. Spontaneous-speech alignments met three of the four minimal benchmarks. We conclude that an adaptation such as ours would especially suit laboratory experiments in Nordic phonetics that rely on elicited speech.","2023-05","2025-02-26 20:39:13","2025-02-26 20:39:13","","105-131","","1","46","","","","","","","","","","English","","","","WOS:000753469400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","computational automatic speech recognition tools; forced alignment; Nordic dialectology; sociolinguistics; sociophonetics; SOUND; Swedish varieties","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RKCNDL64","journalArticle","2021","Schaefer, S","Authenticity: an Elusive Aspect of Pronunciation Work","RECHERCHE ET PRATIQUES PEDAGOGIQUES EN LANGUES DE SPECIALITE-CAHIERS DE L APLIUT","","2257-5405","10.4000/apliut.8627","","This paper looks at the concept of authenticity in oral discourse, and at English language models used in the classroom. These increasingly feature spontaneous speech rather than ""careful speech"", a difference largely reflected in stress placement and syllable reduction in English speech rhythm: the suprasegmental structure that has its basis in the acoustic prominence and non-prominence of syllables. The notion of authentic acoustic materials for L2 language models figures officially in the French secondary school syllabus, as reported in a publication by the French Inspection generale (2000). The report calls for a systematic effort to dispel opaqueness in the stream of speech. In order to characterize ""authentic speech material"", we have briefly examined listening strategies in two popular English language workbooks, Bridges 2(e) and New Missions 2(de). We conclude that effective listening involves gradually presenting authentic discourse as a perception model, leading to better assimilation of native or fluent speech.","2021","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","1","40","","","","","","","","","","English","","","","WOS:000615103200007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","acoustic speech decoding; authenticity; intonation; sentence stress; speech rhythm; suprasegmental structure; syllable prominence; vowel reduction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I2XYU8K7","journalArticle","2021","Travis, CE; Ghina, I","Gender, mobility and contact Stability and change in an Acehnese dialect","ASIA-PACIFIC LANGUAGE VARIATION","","2215-1354","10.1075/aplv.20007.tra","","We examine variation in a rural variety of Acehnese spoken in Aceh Province, to better understand the impact of long-term contact with Indonesian and increasing urbanization. The Great Aceh variety is characterized by variable realization of word-final (t) as a dental vs. glottal stop. Analyses of over 2,000 tokens of this variable from a corpus of spontaneous speech from 35 speakers indicate that the variability is relatively stable among men, and among women of high mobility, measured in terms of education, occupation, and time spent outside Great Aceh. Women with low mobility produce the lowest rates of [t & x32a;], and in this group we observe a higher rate of [t & x32a;] by younger than older women, suggesting change over time. We thus find both stability - among those who have long enjoyed high levels of mobility - and change - among those most affected by recent social changes, namely low-mobility women.","2021-10-06","2025-02-26 20:39:13","2025-02-26 20:39:13","","142-167","","2","7","","","","","","","","","","English","","","","WOS:000836814000004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","Acehnese; glottalization; Indonesian; language contact; mobility; sociophonetics; variation and change","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LLLYPTAV","journalArticle","2022","Yang, C; Stanford, JN; Luo, CX; Zhang, NL","Generational differences in the low tones of Black Lahu","LINGUISTICS VANGUARD","","2199-174X","10.1515/lingvan-2021-0099","","We investigate apparent-time variation of the low falling (T21) and low level (T11) tones of the Black Lahu language of Yunnan, China. Linear mixed-effects modeling of spontaneous speech shows that both tones have a higher F0 trajectory among younger speakers and in certain phonetic environments. Since F0 is known to lower with increasing age, for comparison we also analyze variation in the high rising tone (T45) and find no evidence of generational difference. This suggests that the effect of age on low tones is not due to physiological change across the life span. We leave open the question of whether this result reflects a change in progress or a stable sociotonetic difference between older and younger speakers. This study contributes towards two underrepresented areas of sound change research: (1) sociotonetic approaches to tone variation in naturalistic speech styles, and (2) engagement with Indigenous scholars who are cultural insiders in small rural minority language communities.","2022-09-28","2025-02-26 20:39:13","2025-02-26 20:39:13","","759-770","","","8","","","","","","","","","","English","","","","WOS:000811795200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","apparent-time tone variation; carryover effects; Lahu; sociotonetics; tone change in progress","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5A5QDMVM","journalArticle","2024","Alderete, J","Simon Fraser University Speech Error Database (SFUSED) Cantonese: Methods, design, and usage","FRONTIERS IN PSYCHOLOGY","","1664-1078","10.3389/fpsyg.2024.1270433","","The Simon Fraser University Speech Error Database (SFUSED) is a multi-purpose database of speech errors based in audio recordings. The motivation for SFUSED Cantonese, a component of this database, is to create a linguistically rich data set for exploring language production processes in Cantonese, an under-studied language. We describe in detail the methods used to collect, analyze, and explore the database, including details of team workflows, time budgets, data quality, and explicit linguistic and processing assumptions. In addition to showing how to use the database, this account supports future research with a template for investigating additional under-studied languages, and it gives fresh perspective on the benefits and drawbacks of collecting speech error data from spontaneous speech. All of the data and supporting materials are available as open access data sets.","2024-01-25","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","15","","","","","","","","","","English","","","","WOS:001158551300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;77</p>","","","ACTIVATION; Cantonese; data collection; data quality; ecological validity; language production; LEXICAL ACCESS; MANDARIN CHINESE; MODELS; PERCEPTION; REPRESENTATION; SERIAL ORDER; SLIPS; speech errors; TONE; TONGUE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T4ITBD6A","journalArticle","2023","Benítez-Burraco, A; Hoshi, K; Murphy, E","Language deficits in GRIN2A mutations and Landau-Kleffner syndrome as neural dysrhythmias","JOURNAL OF NEUROLINGUISTICS","","0911-6044","10.1016/j.jneuroling.2023.101139","","We review epilepsy-related aphasias in connection with GRIN2A mutations, focusing on acquired childhood epileptic aphasias such as Landau-Kleffner syndrome (LKS). The spontaneous speech of children with LKS exhibits syntactically simplified utterances, severe word finding difficulties, and severe phonological paraphasias. Characterizing LKS as a neural dysrhythmia, we review how EEG abnormalities typically manifested during non-rapid eye movement (NREM) sleep as elec-trical status epilepticus are related to sleeping disorders partly caused by GRIN2A mutations. Expanding on speculations originally put forward by Landau & Kleffner, 1957, we explore how neural processes such as sharp-wave ripples, sleep spindles, slow oscillations, and their cross-frequency couplings are necessary for language-related processes which are perturbed in LKS, accounting in part for the linguistic profile of epileptic aphasias.","2023-08","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","67","","","","","","","","","","English","","","","WOS:000975916900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;144</p>","","","ACQUIRED EPILEPTIC APHASIA; BENIGN CHILDHOOD EPILEPSY; CONTINUOUS SPIKES; CONVULSIVE DISORDER; CSWS; Epileptic aphasia; ESES; GRIN2A mutation; HUMAN BRAIN; Landau-kleffner syndrome; Neural dysrhythmia; NMDA RECEPTOR; PREFRONTAL CORTEX; PYRAMIDAL CELLS; ROLANDIC EPILEPSY; SUBUNIT MESSENGER-RNAS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A9ZZPNCX","journalArticle","2024","Maes, P; Weyland, M; Kissine, M","Structure and acoustics of the speech of verbal autistic preschoolers","JOURNAL OF CHILD LANGUAGE","","0305-0009","10.1017/S0305000923000417","","In this study, we report an extensive investigation of the structural language and acoustical specificities of the spontaneous speech of ten three- to five-year-old verbal autistic children. The autistic children were compared to a group of ten typically developing children matched pairwise on chronological age, nonverbal IQ and socioeconomic status, and groupwise on verbal IQ and gender on various measures of structural language (phonetic inventory, lexical diversity and morpho-syntactic complexity) and a series of acoustical measures of speech (mean and range fundamental frequency, a formant dispersion index, syllable duration, jitter and shimmer). Results showed that, overall, the structure and acoustics of the verbal autistic children's speech were highly similar to those of the TD children. Few remaining atypicalities in the speech of autistic children lay in a restricted use of different vocabulary items, a somewhat diminished morpho-syntactic complexity, and a slightly exaggerated syllable duration.","2024-05","2025-02-26 20:39:13","2025-02-26 20:39:13","","509-525","","3","51","","","","","","","","","","English","","","","WOS:001022092200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","acoustics; autism; CHILDREN; INTONATION; LANGUAGE; naturalistic speech sample; PATTERNS; PROSODY; SPECTRUM DISORDER; structural language; TODDLERS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PYIBRKQ5","journalArticle","2022","Häberl, CG; Kashintseva, K; Loesov, S","Who Killed Osman Xate?","ARAMAIC STUDIES","","1477-8351","10.1163/17455227-bja10033","","The grammar of the village dialects of.uroyo remains poorly described apart from that of Mid.n, and within the documentation there is a dearth of spontaneous conversations. Consequently, much about.uroyo pragmatics and sociolinguistics in general also remains undescribed. We therefore present two short conversations between three residents of Kfarze in Tur Abdin, concerning a significant event in its recent history, together with a translation and a glossary. In addition to their value as oral histories of the Christian-Kurdish relationship in the region, they reveal significant details about the dialect of Kfarze, including 1) the contraction of triphthongs in ii-y verbs; 2) nouns consistently marked with l- when they express the agent of an `ergative' preterite; and 3) the retention of `soft' (unaspirated). in Kurmanji loan vocabulary. The presence of the last feature, and of frequent code-switching between.uroyo and Kurmanji in the spontaneous speech of these villagers, attests to the bilingual situation in Kfarze.","2022-12","2025-02-26 20:39:13","2025-02-26 20:39:13","","213-273","","2","20","","","","","","","","","","English","","","","WOS:000923886500005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;15</p>","","","bilingualism; Kurdish; Neo-Aramaic; oral history; sectarianism","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3CIEWPSM","journalArticle","2022","Unlutabak, B; Aktan-Erciyes, A; Yilmaz, D; Kandemir, S; Goksun, T","Parental input during book reading and toddlers' elicited and spontaneous communicative interactions","JOURNAL OF APPLIED DEVELOPMENTAL PSYCHOLOGY","","0193-3973","10.1016/j.appdev.2022.101436","","This study examined the relation between characteristics of parental input, particularly focusing on questions and pointing gestures directed to toddlers during book reading, and toddlers' elicited and spontaneous communicative interactions. A total of 30 Turkish speaking parents and their toddlers (18 girls, Mage = 18.79 SDage = 1.55) were observed during shared book reading. The communicative interactions were coded for parents' questions and pointing, and toddlers' elicited and spontaneous speech and pointing. The results showed that parents' label questions with pointing were positively associated with toddlers' elicited speech. Similarly, parents' label questions without pointing, and parents' description questions with pointing were positively associated with toddlers' elicited pointing. These findings highlight the importance of parental questions accompanied by pointing when eliciting toddler communicative interactions both in the form of speech and pointing, and provides insight for how to best communicate with toddlers during such interactions.","2022-07","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","81","","","","","","","","","","English","","","","WOS:000809724000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;77</p>","","","ACQUISITION; ELABORATION; Gesture input; INTERVENTION; LANGUAGE; MOTHERS; Parental questions; Pragmatic development; QUANTITY; Shared book reading; SPEECH; Toddlers; VOCABULARY DEVELOPMENT; WH-QUESTIONS; YOUNG-CHILDREN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HB2VFC46","journalArticle","2021","Snyder, W","A parametric approach to the acquisition of syntax","JOURNAL OF CHILD LANGUAGE","","0305-0009","10.1017/S0305000921000465","","Three case-studies, using longitudinal records of children's spontaneous speech, illustrate what happens when a child's syntax changes. The first, examining acquisition of English verb-particle constructions, shows a near-total absence of commission errors. The second, examining acquisition of prepositional questions in English or Spanish, shows that children (i) may go as long as 9 months producing both direct-object questions and declaratives with prepositional phrases, before first attempting a prepositional question; and (ii) at some point, abrubtly begin producing prepositional questions that are correctly formed for the target language. The third case study shows that in children acquiring English, the onset of verb-particle constructions occurs almost exactly when that child begins using novel noun-noun compounds. After a discussion of the implications for the nature of syntactic knowledge, and for the mechanisms by which it is acquired, two examples are presented of as-yet untested acquisitional predictions of parametric proposals in the syntax literature.","2021-09","2025-02-26 20:39:13","2025-02-26 20:39:13","","862-887","","5","48","","","","","","","","","","English","","","","WOS:000696182900004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","language acquisition; Principles and Parameters; syntax","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VHB25UWB","journalArticle","2024","Baird, P","Building languages: Estonian-English two-year-old bilingual's reliance on patterns in code-mixed utterances","NORDIC JOURNAL OF LINGUISTICS","","0332-5865","10.1017/S0332586524000015","","This paper examines patterns in an Estonian-English bilingual child's spontaneous speech, employing a computational application of the traceback method, which is used in usage-based linguistics. Forty-five hours of data were analyzed to check what proportion of patterns from code-mixed utterances are attested in the child's monolingual data and in her input. Pattern overlap between the child's and the caregivers' speech was also examined. Results show that about one-third of code-mixed utterances can be traced back to the child's input and one-third also to her own monolingual data. A little over half of the child's utterances are either chunks or frame-and-slot patterns from the caregivers' speech. These results make it evident that the traceback method can also be applied to language pairs that are genealogically more distant, though limitations exist.","2024-02-16","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","","","","","","","","","","","English","","","","WOS:001163383300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","bilingualism; code-mixing; English; Estonian; GERMAN; language acquisition; SENTENCE; traceback method; usage-based linguistics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UXLX9U63","journalArticle","2021","Cojocaru, V","THE USE OF DISCOURSE MARKERS BY FOREIGN STUDENTS LEARNING ROMANIAN","REVUE ROUMAINE DE LINGUISTIQUE-ROMANIAN REVIEW OF LINGUISTICS","","0035-3957","","","The aim of this study is to investigate the use of discourse markers by students learning Romanian as a foreign language (L2), focusing mainly on the difficulties that occur in their acquisition, so one can provide better strategies to improve their teaching. Discourse markers are recognized as being essential for successful communication, which means that their acquisition should play an important role in the process of learning a language. The class of discourse markers covers a significant number of multifunctional elements, such as textual connectors, attitude markers, opinion markers, etc., that are mostly responsible for coherent and cohesive written texts, on the one hand, and for performing authentic and spontaneous speech, on the other. Our study has shown that foreign students use discourse markers differently from native speakers, in some cases because of the transfer from their mother tongue(s) or from other languages, such as English, and in other cases because of the lack of suitable input material.","2021","2025-02-26 20:39:13","2025-02-26 20:39:13","","335-343","","4","66","","","","","","","","","","English","","","","WOS:000945682200003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","discourse coherence; discourse markers; non-native speakers; pragmatic competence; Romanian as a foreign language","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2LEFKY6L","journalArticle","2023","Henkel, J; Hartmann, C; Niccolai, V; van de Vijver, R; Schnitzler, A; Biermann-Ruben, K","Reduced syntactic recursion in spontaneous speech of Parkinson's disease patients","ACTA PSYCHOLOGICA","","0001-6918","10.1016/j.actpsy.2023.103931","","Although characterized as a movement disorder, Parkinson's disease (PD) affects more than just the motor system. Within the heterogenous non-motor symptoms, language impairment is frequent but poorly understood beyond semantic processing.This study investigates the impact of PD on syntactic subordination in spontaneous language production. Fifteen PD patients in ON levodopa status narrated a short story guided by a set of pictures. Thirteen PD patients were also assessed in OFF levodopa status. Narrations were digitally recorded, subsequently transcribed and annotated, making the produced speech accessible to systematical quantitative analysis.Compared to a healthy matched control group, PD patients showed a significant reduction of subordinating structures while the number of non-embedding sentences remained unaffected. No significant effect comparing ON versus OFF levodopa status emerged. Our results suggest a contribution of the basal ganglia to language processing, such as syntactic composition, which, however, does not seem to be dopamine dependent.","2023-06","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","236","","","","","","","","","","English","","","","WOS:000998718900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","Basal ganglia; BRAIN; DISORDERS; EVOLUTION; LANGUAGE; Parkinson's disease; Recursion; Speech production; Syntax","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EUMC5YYI","journalArticle","2021","de Vargas, MF; Marino, D; Weill-Duflos, A; Cooperstock, JR","Speaking Haptically: From Phonemes to Phrases With a Mobile Haptic Communication System","IEEE TRANSACTIONS ON HAPTICS","","1939-1412","10.1109/TOH.2021.3054812","","In this article, we present three studies involving WhatsHap, a mobile system designed to deliver speech as vibrations on the forearm with minimal hardware demands and practice time. After only 4.2 h of training on a 24-haptic phoneme vocabulary and on how to combine these to form words, participants were able to generalize their phoneme identification skills to the understanding of untrained English words, correctly identifying 65% of words in phrases rendered with a user-controlled interval between words, and up to 59% with a fixed interval. Ultimately, participants were able to complete 88% of simple communicative tasks that elicited spontaneous speech and semi-structured bidirectional conversation using the apparatus. We conclude by providing insights as to how such a system may ultimately be used for communication under more natural conditions.","2021-07","2025-02-26 20:39:13","2025-02-26 20:39:13","","479-490","","3","14","","","","","","","","","","English","","","","WOS:000694697600004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","ACQUISITION; Actuators; Encoding; Haptic interfaces; Hardware; HEARING; Language learning; phonemic coding; SENTENCES; speech-to-haptic; tactile speech communication; Task analysis; Training; Vibrations; VOCABULARY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NVGSLFCN","journalArticle","2022","Baron, B; Kolanska-Pluska, J; Lukaniszyn, M; Spalek, D; Kraszewski, T","Solution of nonlinear stiff differential equations for a three-phase no-load transformer using a Runge-Kutta implicit method","ARCHIVES OF ELECTRICAL ENGINEERING","","1427-4221","10.24425/aee.2022.142126","","The paper presents an approach to differential equation solutions for the stiff problem. The method of using the classic transformer model to study nonlinear steady states and to determine the current pulses appearing when the transformer is turned on is given. Moreover, the stiffness of nonlinear ordinary differential state equations has to be considered. This paper compares Runge-Kutta implicit methods for the solution of this stiff problem.","2022","2025-02-26 20:39:13","2025-02-26 20:39:13","","1081-1106","","4","71","","","","","","","","","","English","","","","WOS:000908030200002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","circuit model of a three-phase transformer; MAGNETIC-FIELD; Runge-Kutta implicit methods; stiff nonlinear ordinary differential equations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NXMRFSC5","journalArticle","2024","Berthault, E; Chen, SP; Falk, S; Morillon, B; Schon, D","Auditory and motor priming of metric structure improves understanding of degraded speech","COGNITION","","0010-0277","10.1016/j.cognition.2024.105793","","Speech comprehension is enhanced when preceded (or accompanied) by a congruent rhythmic prime reflecting the metrical sentence structure. Although these phenomena have been described for auditory and motor primes separately, their respective and synergistic contribution has not been addressed. In this experiment, participants performed a speech comprehension task on degraded speech signals that were preceded by a rhythmic prime that could be auditory, motor or audiomotor. Both auditory and audiomotor rhythmic primes facilitated speech comprehension speed. While the presence of a purely motor prime (unpaced tapping) did not globally benefit speech comprehension, comprehension accuracy scaled with the regularity of motor tapping. In order to investigate inter-individual variability, participants also performed a Spontaneous Speech Synchronization test. The strength of the estimated perception-production coupling correlated positively with overall speech comprehension scores. These findings are discussed in the framework of the dynamic attending and active sensing theories.","2024-07","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","248","","","","","","","","","","English","","","","WOS:001231114000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Audio -motor; Behavior; Coupling; DYNAMICS; Human; INTEGRATION; MUSIC; RHYTHM; Speech; Synchronization; TIME","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T2699DSC","journalArticle","2023","Römmelt, C; Hiddemann, M; Köhler, K; Köhler, F","Verfahren der künstlichen Intelligenz - eine Perspektive für die kardiovaskuläre Telemedizin?","AKTUELLE KARDIOLOGIE","","2193-5203","10.1055/a-2162-4478","","An estimated 150000-200000 patients with chronic heart failure in Germany have been entitled to telemedical care since 2022 as a result of the decision of The Federal Joint Committee. Currently, artificial intelligence based applications are not permitted for standard care in cardiovascular telemedicine. The application of AI might help to improve the predictive accuracy of existing telemedical sensors through pattern recognition involving multiple data sources. Furthermore, new AI-based biomarkers are currently being developed for use in telemedical sensor technology. The approach of AI-based voice analysis to detect pulmonary congestion in heart failure seems very promising. AI-based decision support systems might help in future to optimize the reporting process in the telemedical center. Finally, large-language-models could support doctors to generate medical reports. Research in the field of digital medicine requires a precise framework in order to be able to test new AI-based technologies in healthcare in patient applications.","2023-12","2025-02-26 20:39:13","2025-02-26 20:39:13","","475-481","","06","12","","","","","","","","","","English","","","","WOS:001111918300002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","artificial intelligence; biomarker; heart failure; speech analysis; SPEECH ANALYSIS; telemedicine","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JC9QWN4E","journalArticle","2023","Lih, OS; Jahmunah, V; Palmer, EE; Barua, PD; Dogan, S; Tuncer, T; García, S; Molinari, F; Acharya, UR","EpilepsyNet: Novel automated detection of epilepsy using transformer model with EEG signals from 121 patient population","COMPUTERS IN BIOLOGY AND MEDICINE","","0010-4825","10.1016/j.compbiomed.2023.107312","","Background: Epilepsy is one of the most common neurological conditions globally, and the fourth most common in the United States. Recurrent non-provoked seizures characterize it and have huge impacts on the quality of life and financial impacts for affected individuals. A rapid and accurate diagnosis is essential in order to instigate and monitor optimal treatments. There is also a compelling need for the accurate interpretation of epilepsy due to the current scarcity in neurologist diagnosticians and a global inequity in access and outcomes. Furthermore, the existing clinical and traditional machine learning diagnostic methods exhibit limitations, warranting the need to create an automated system using deep learning model for epilepsy detection and monitoring using a huge database. Method: The EEG signals from 35 channels were used to train the deep learning-based transformer model named (EpilepsyNet). For each training iteration, 1-min-long data were randomly sampled from each participant. Thereafter, each 5-s epoch was mapped to a matrix using the Pearson Correlation Coefficient (PCC), such that the bottom part of the triangle was discarded and only the upper triangle of the matrix was vectorized as input data. PCC is a reliable method used to measure the statistical relationship between two variables. Based on the 5 s of data, single embedding was performed thereafter to generate a 1-dimensional array of signals. In the final stage, a positional encoding with learnable parameters was added to each correlation coefficient's embedding before being fed to the developed EpilepsyNet as input data to epilepsy EEG signals. The ten-fold cross-validation technique was used to generate the model. Results: Our transformer-based model (EpilepsyNet) yielded high classification accuracy, sensitivity, specificity and positive predictive values of 85%, 82%, 87%, and 82%, respectively. Conclusion: The proposed method is both accurate and robust since ten-fold cross-validation was employed to evaluate the performance of the model. Compared to the deep models used in existing studies for epilepsy diagnosis, our proposed method is simple and less computationally intensive. This is the earliest study to have uniquely employed the positional encoding with learnable parameters to each correlation coefficient's embedding together with the deep transformer model, using a huge database of 121 participants for epilepsy detection. With the training and validation of the model using a larger dataset, the same study approach can be extended for the detection of other neurological conditions, with a transformative impact on neurological diagnostics worldwide.","2023-09","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","164","","","","","","","","","","English","","","","WOS:001059382100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;25<br/>Total Times Cited:&nbsp;&nbsp;25<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Automated diagnosis; CLASSIFICATION; DIAGNOSIS; ELECTROENCEPHALOGRAM; Epilepsy; Pearson correlation coefficient; Positional encoding; SEIZURE; Transformer deep model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"472QRHVW","journalArticle","2024","Saeedi, S; Hetjens, S; Grimm, MOW; Latoszek, BBV","Acoustic Speech Analysis in Alzheimer's Disease: A Systematic Review and Meta-Analysis","JPAD-JOURNAL OF PREVENTION OF ALZHEIMERS DISEASE","","2274-5807","10.14283/jpad.2024.132","","BackgroundThe potential of biomarkers in the detection of Alzheimer's disease (AD) is prominent. Acoustics may be useful in this context but the evaluation and weighting for specific acoustic parameters on continuous speech is missing. This meta-analysis aimed to explore the significance of acoustic parameters from acoustic speech analysis on continuous speech, as a diagnostic tool for clinical AD.MethodsApplying PRISMA protocol, a comprehensive search was done in MEDLINE, Scopus, Web of Science, and CENTRAL, from 1960 to January 2024. Cross-sectional studies comparing the acoustic speech analysis between AD patients and healthy controls (HC), were taken into account. The bias risk of the included studies were examined via JBI checklist. Using Review Manager v.5.4.1, the mean differences of acoustic speech parameters among AD and HC were weighted, and the pooled analysis and the heterogeneity statistics were conducted.ResultsIn total, 1112 records (without duplicates) were obtained, and 11 papers with 7 acoustic parameters were included for this study, and 8 from 11 studies were identified with a low level of bias. Five from 7 acoustic parameters revealed significant differences among the two groups (p-values <= 0.01), in which for all rate-related and interruption-related acoustic parameters were the most prominent and less in temporal-related acoustic parameters.ConclusionsAlthough a small number of acoustic parameters on continuous speech could be evaluated in the detection of clinical AD, the greatest potential of acoustic biomarkers for AD appeared to exist in two of three categories. Further contributions of high-quality studies are needed to support evidence for acoustics as biomarkers for AD.","2024-12","2025-02-26 20:39:13","2025-02-26 20:39:13","","1789-1797","","6","11","","","","","","","","","","English","","","","WOS:001289377500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","acoustic; Alzheimer's disease; ARTICULATION RATE; diagnosis; DIAGNOSIS; NATIONAL INSTITUTE; PROTEIN; RHYTHM; signal processing; speech and voice analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FBDA8JKU","journalArticle","2024","Di Cesare, MG; Perpetuini, D; Cardone, D; Merla, A","Machine Learning-Assisted Speech Analysis for Early Detection of Parkinson's Disease: A Study on Speaker Diarization and Classification Techniques","SENSORS","","1424-8220","10.3390/s24051499","","Parkinson's disease (PD) is a neurodegenerative disorder characterized by a range of motor and non-motor symptoms. One of the notable non-motor symptoms of PD is the presence of vocal disorders, attributed to the underlying pathophysiological changes in the neural control of the laryngeal and vocal tract musculature. From this perspective, the integration of machine learning (ML) techniques in the analysis of speech signals has significantly contributed to the detection and diagnosis of PD. Particularly, MEL Frequency Cepstral Coefficients (MFCCs) and Gammatone Frequency Cepstral Coefficients (GTCCs) are both feature extraction techniques commonly used in the field of speech and audio signal processing that could exhibit great potential for vocal disorder identification. This study presents a novel approach to the early detection of PD through ML applied to speech analysis, leveraging both MFCCs and GTCCs. The recordings contained in the Mobile Device Voice Recordings at King's College London (MDVR-KCL) dataset were used. These recordings were collected from healthy individuals and PD patients while they read a passage and during a spontaneous conversation on the phone. Particularly, the speech data regarding the spontaneous dialogue task were processed through speaker diarization, a technique that partitions an audio stream into homogeneous segments according to speaker identity. The ML applied to MFCCS and GTCCs allowed us to classify PD patients with a test accuracy of 92.3%. This research further demonstrates the potential to employ mobile phones as a non-invasive, cost-effective tool for the early detection of PD, significantly improving patient prognosis and quality of life.","2024-03","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","5","24","","","","","","","","","","English","","","","WOS:001182974900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","DYSARTHRIA; machine learning; Parkinson's disease; speaker diarization; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FL8ET3RR","journalArticle","2023","Mai, GT; Wang, WSY","Distinct roles of delta- and theta-band neural tracking for sharpening and predictive coding of multi-level speech features during spoken language processing","HUMAN BRAIN MAPPING","","1065-9471","10.1002/hbm.26503","","The brain tracks and encodes multi-level speech features during spoken language processing. It is evident that this speech tracking is dominant at low frequencies (<8 Hz) including delta and theta bands. Recent research has demonstrated distinctions between delta- and theta-band tracking but has not elucidated how they differentially encode speech across linguistic levels. Here, we hypothesised that delta-band tracking encodes prediction errors (enhanced processing of unexpected features) while theta-band tracking encodes neural sharpening (enhanced processing of expected features) when people perceive speech with different linguistic contents. EEG responses were recorded when normal-hearing participants attended to continuous auditory stimuli that contained different phonological/morphological and semantic contents: (1) real-words, (2) pseudo-words and (3) time-reversed speech. We employed multivariate temporal response functions to measure EEG reconstruction accuracies in response to acoustic (spectrogram), phonetic and phonemic features with the partialling procedure that singles out unique contributions of individual features. We found higher delta-band accuracies for pseudo-words than real-words and time-reversed speech, especially during encoding of phonetic features. Notably, individual time-lag analyses showed that significantly higher accuracies for pseudo-words than real-words started at early processing stages for phonetic encoding (<100 ms post-feature) and later stages for acoustic and phonemic encoding (>200 and 400 ms post-feature, respectively). Theta-band accuracies, on the other hand, were higher when stimuli had richer linguistic content (real-words > pseudo-words > time-reversed speech). Such effects also started at early stages (<100 ms post-feature) during encoding of all individual features or when all features were combined. We argue these results indicate that delta-band tracking may play a role in predictive coding leading to greater tracking of pseudo-words due to the presence of unexpected/unpredicted semantic information, while theta-band tracking encodes sharpened signals caused by more expected phonological/morphological and semantic contents. Early presence of these effects reflects rapid computations of sharpening and prediction errors. Moreover, by measuring changes in EEG alpha power, we did not find evidence that the observed effects can be solitarily explained by attentional demands or listening efforts. Finally, we used directed information analyses to illustrate feedforward and feedback information transfers between prediction errors and sharpening across linguistic levels, showcasing how our results fit with the hierarchical Predictive Coding framework. Together, we suggest the distinct roles of delta and theta neural tracking for sharpening and predictive coding of multi-level speech features during spoken language processing.","2023-12-01","2025-02-26 20:39:13","2025-02-26 20:39:13","","6149-6172","","17","44","","","","","","","","","","English","","","","WOS:001082212200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;82</p>","","","ACTIVATION; COMPREHENSION; CONNECTIVITY; CORTICAL ENTRAINMENT; delta and theta bands; INTEGRATION; KNOWLEDGE; NETWORKS; neural sharpening; neural tracking of speech; OSCILLATIONS; phonological/morphological processing; predictive coding; RECOGNITION; semantic processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QIN65EG7","journalArticle","2024","Hartnagel, LM; Emden, D; Foo, JC; Streit, F; Witt, H; Frank, J; Limberger, MF; Schmitz, SE; Gilles, M; Rietschel, M; Hahn, T; Ebner-Priemer, UW; Sirignano, L","Momentary Depression Severity Prediction in Patients With Acute Depression Who Undergo Sleep Deprivation Therapy: Speech-Based Machine Learning Approach","JMIR MENTAL HEALTH","","2368-7959","10.2196/64578","","Background: Mobile devices for remote monitoring are inevitable tools to support treatment and patient care, especially in recurrent diseases such as major depressive disorder. The aim of this study was to learn if machine learning (ML) models based on longitudinal speech data are helpful in predicting momentary depression severity. Data analyses were based on a dataset including 30 inpatients during an acute depressive episode receiving sleep deprivation therapy in stationary care, an intervention inducing a rapid change in depressive symptoms in a relatively short period of time. Using an ambulatory assessment approach, we captured speech samples and assessed concomitant depression severity via self-report questionnaire over the course of 3 weeks (before, during, and after therapy). We extracted 89 speech features from the speech samples using the Extended Geneva Minimalistic Acoustic Parameter Set from the Open-Source Speech and Music Interpretation by Large-Space Extraction (audEERING) toolkit and the additional parameter speech rate. Objective: We aimed to understand if a multiparameter ML approach would significantly improve the prediction compared to previous statistical analyses, and, in addition, which mechanism for splitting training and test data was most successful, especially focusing on the idea of personalized prediction. Methods: To do so, we trained and evaluated a set of >500 ML pipelines including random forest, linear regression, support vector regression, and Extreme Gradient Boosting regression models and tested them on 5 different train-test split scenarios: a group 5-fold nested cross-validation at the subject level, a leave-one-subject-out approach, a chronological split, an odd-even split, and a random split. Results: In the 5-fold cross-validation, the leave-one-subject-out, and the chronological split approaches, none of the models were statistically different from random chance. The other two approaches produced significant results for at least one of the models tested, with similar performance. In total, the superior model was an Extreme Gradient Boosting in the odd-even split approach (R2=0.339, mean absolute error=0.38; both P <.001), indicating that 33.9% of the variance in depression severity could be predicted by the speech features. Conclusions: Overall, our analyses highlight that ML fails to predict depression scores of unseen patients, but prediction performance increased strongly compared to our previous analyses with multilevel models. We conclude that future personalized ML models might improve prediction performance even more, leading to better patient management and care.","2024","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","11","","","","","","","","","","English","","","","WOS:001390715500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","ambulatory assessment; depression; depressive disorder; digital health; HETEROGENEITY; machine learning; mental health; mHealth; mobile health; mobile phone; openSMILE; remote monitoring; sleep deprivation therapy; speech features","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WN7F8CJJ","journalArticle","2024","Guo, FW; Wang, PX; Tansey, K; Zhang, Y; Li, MQ; Liu, JM; Zhang, SY","A novel transformer-based neural network under model interpretability for improving wheat yield estimation using remotely sensed multi-variables","COMPUTERS AND ELECTRONICS IN AGRICULTURE","","0168-1699","10.1016/j.compag.2024.109111","","Timely and accurate yield prediction before wheat harvest is of great significance for food policy formulation and national economic development. Deep learning method gains importance on crop yield estimation and growth monitoring with the rapid development of deep learning models combined with remotely sensed data. However, the problems of nonlinear parameter optimization and long-term dependence in time series data have restricted the improvement of yield estimation accuracy. Transformer model completely abandons the traditional deep learning architecture and is gradually applied to time series tasks due to the advantage in modeling long-term dependence. This study introduced a novel transformer -based deep learning framework to estimate winter wheat yield in the Guanzhong Plain utilizing remotely sensed multi -variables, namely leaf area index (LAI), fraction of photosynthetically active radiation (FPAR) and vegetation temperature condition index (VTCI). The proposed model, called SSA-LSTM-transformer (SLTF), was developed for dealing with above problems under the automatic optimization capability of the sparrow search algorithm (SSA) and the long-term memory advantage of the long short-term memory (LSTM) structure. The findings demonstrated that the SLTF model achieved better estimation accuracy at the county level (R 2 = 0.72, RMSE = 488.68 kg/ha) compared with the single transformer model (R 2 = 0.61, RMSE = 573.99 kg/ha). The analysis on SLTF model 's performance at sampling sites over different disasters suggested that the model can effectively learn the effects of diseases, lodge and pests on crop yield estimation, which had good generalization ability at all sampling sites (R 2 = 0.45, RMSE = 738.63 kg/ha). The Shapley Additive exPlanations (SHAP) approach was employed to evaluate the relative importance of remotely sensed multi -variables to yield and to understand how each input variable influences the estimated yield for global interpretability and local interpretability of the SLTF model. It was found that FPAR played the largest roles in yield estimation with the highest importance value, and FPAR and LAI from late April to late May and VTCI from late March to mid -April were regarded as important features for the estimated yield with high importance value. In conclusion, our findings indicated the potential of SLTF model for winter wheat yield estimation, which contributes to promoting further application of remotely sensed technology for agricultural production.","2024-08","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","223","","","","","","","","","","English","","","","WOS:001255465200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","DROUGHT; LEAF-AREA INDEX; Model interpretability; Sparrow search algorithm (SSA); TEMPERATURE CONDITION INDEX; Transformer model; UNITED-STATES; Vegetation temperature condition index (VTCI); Yield estimation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RJNMFVS7","journalArticle","2022","Lefter, I; Baird, A; Stappen, L; Schuller, BW","A Cross-Corpus Speech-Based Analysis of Escalating Negative Interactions","FRONTIERS IN COMPUTER SCIENCE","","2624-9898","10.3389/fcomp.2022.749804","","The monitoring of an escalating negative interaction has several benefits, particularly in security, (mental) health, and group management. The speech signal is particularly suited to this, as aspects of escalation, including emotional arousal, are proven to easily be captured by the audio signal. A challenge of applying trained systems in real-life applications is their strong dependence on the training material and limited generalization abilities. For this reason, in this contribution, we perform an extensive analysis of three corpora in the Dutch language. All three corpora are high in escalation behavior content and are annotated on alternative dimensions related to escalation. A process of label mapping resulted in two possible ground truth estimations for the three datasets as low, medium, and high escalation levels. To observe class behavior and inter-corpus differences more closely, we perform acoustic analysis of the audio samples, finding that derived labels perform similarly across each corpus, with escalation interaction increasing in pitch (F0) and intensity (dB). We explore the suitability of different speech features, data augmentation, merging corpora for training, and testing on actor and non-actor speech through our experiments. We find that the extent to which merging corpora is successful depends greatly on the similarities between label definitions before label mapping. Finally, we see that the escalation recognition task can be performed in a cross-corpus setup with hand-crafted speech features, obtaining up to 63.8% unweighted average recall (UAR) at best for a cross-corpus analysis, an increase from the inter-corpus results of 59.4% UAR.","2022-03-07","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","4","","","","","","","","","","English","","","","WOS:000782759200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","ACOUSTIC EMOTION RECOGNITION; affective computing; CONFLICT; conflict escalation; cross-corpora analysis; emotion recognition; negative interactions; speech paralinguistics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FDK2AV6T","journalArticle","2024","Haas, E; Ziegler, W; Schölderle, T","Age Estimation and Gender Attribution in Typically Developing Children and Children With Dysarthria","AMERICAN JOURNAL OF SPEECH-LANGUAGE PATHOLOGY","","1058-0360","10.1044/2023_AJSLP-23-00246","","Purpose: The purposes of this study were (a) to investigate adult listeners' perceptions of age and gender in typically developing children and children with dysarthria and (b) to identify predictors of their estimates among auditoryperceptual parameters and an acoustic measure of vocal pitch (F0). We aimed to evaluate the influence of dysarthria on the listeners' impressions of age and gender against the background of typical developmental processes. Method: In a listening experiment, adult listeners completed age and gender estimates of 144 typically developing children (3-9 years of age) and 25 children with dysarthria (5-9 years of age). The Bogenhausen Dysarthria Scales for Childhood Dysarthria (BoDyS-KiD) were applied to record speech samples and to complete auditory-perceptual judgments covering all speech subsystems. Furthermore, each child's mean F0 was determined from samples of four BoDyS-KiD sentences. Results: Age estimates for the typically developing children showed a regression to the mean, whereas children with dysarthria were systematically underestimated in their age. The estimates of all children were predicted by developmental speech features; for the children with dysarthria, specific dysarthria symptoms had an additional effect. We found a significantly higher accuracy of gender attribution in the typically developing children than in the children with dysarthria. The prediction accuracy of the listeners' gender attribution in the preadolescent children by the included speech characteristics was limited. Conclusions: Children with dysarthria are more difficult to estimate for their age and gender than their typically developing peers. Dysarthria thus alters the auditory-perceptual impression of indexical speech features in children, which must be considered another facet of the communication disorder associated with childhood dysarthria.","2024-05","2025-02-26 20:39:13","2025-02-26 20:39:13","","1236-1253","","3","33","","","","","","","","","","English","","","","WOS:001239450900011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","BOYS; CHILDHOOD; GIRLS; IDENTIFICATION; INTELLIGIBILITY; SYSTEM; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5TH33LG2","journalArticle","2023","Yang, CQ; Zhang, XY; Chen, YX; Li, YE; Yu, S; Zhao, BM; Wang, T; Luo, LZ; Gao, S","Emotion-dependent language featuring depression","JOURNAL OF BEHAVIOR THERAPY AND EXPERIMENTAL PSYCHIATRY","","0005-7916","10.1016/j.jbtep.2023.101883","","Background and objectives: Understanding language features of depression contributes to the detection of the disorder. Considering that depression is characterized by dysfunctions in emotion and individuals with depression often show emotion-dependent cognition, the present study investigated the speech features and word use of emotion-dependent narrations in patients with depression.Methods: Forty depression patients and forty controls were required to narrate self-relevant memories under five basic human emotions (i.e., sad, angry, fearful, neutral, and happy). Recorded speech and transcribed texts were analyzed.Results: Patients with depression, as compared to non-depressed individuals, talked slower and less. They also performed differently in using negative emotion, work, family, sex, biology, health, and assent words regardless of emotion manipulation. Moreover, the use of words such as first person singular pronoun, past tense, causation, achievement, family, death, psychology, impersonal pronoun, quantifier and preposition words displayed emotion-dependent differences between groups. With the involvement of emotion, linguistic indicators associ-ated with depressive symptoms were identified and explained 71.6% variances of depression severity. Limitations: Word use was analyzed based on the dictionary which does not cover all the words spoken in the memory task, resulting in text data loss. Besides, a relatively small number of depression patients were included in the present study and therefore the results need confirmation in future research using big emotion-dependent data of speech and texts.Conclusions: Our findings suggest that consideration of different emotional contexts is an effective means to improve the accuracy of depression detection via the analysis of word use and speech features.","2023-12","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","81","","","","","","","","","","English","","","","WOS:001011481300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","ACOUSTIC MEASURES; Autobiographical memory; AUTOBIOGRAPHICAL MEMORY SPECIFICITY; CONTEXT; Depression; DISORDER; Emotion; NARRATIVES; PERSONALITY; POWER; RECOGNITION; SEVERITY; Speech; SYMPTOMS; Word use","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"44QD7XY8","journalArticle","2021","Yang, L; Xie, K; Wen, C; He, JB","Speech Emotion Analysis of Netizens Based on Bidirectional LSTM and PGCDBN","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2021.3073234","","In recent years, the application of speech emotion recognition (SER) in the supervision of Internet public opinion has received increasing attention. This study proposes a new SER algorithm to analyze the public opinion information of network platforms. Firstly, we extract different spectrum features from speech signals and combine them into frame level speech features. Then, we select conditional deep confidence network (CDBN) which has the ability to learn sequential features as the final classification model. We apply particle swarm optimization (PSO) and genetic algorithm (GA) during the fine-tuning stage of the CDBN to obtain more suitable optimal weights of the whole network, and propose the PSO-GA-CDBN (PGCDBN) model. Compare with the traditional back propagation (BP) algorithm, our training method accelerates the convergence speed of the network and improves the robustness and recognition performance of the network. In our experiment, we used the Chinese Academy of Sciences' Institute of automation (CASIA) Chinese emotional corpus and self-collected Chinese speech datasets, which were collected from Sina Weibo, Tik tok and other online social media platforms. Compare with the popular emotion classifiers such as support vector machine (SVM), deep residual network (ResNet), long short-term memory (LSTM) neural network, DBN, our proposed PGCDBN achieves the best recognition results from both datasets. In addition, we use bidirectional LSTM before PGCDBN to further process the extracted speech features, and the result of bidirectional LSTM has stronger speech signal expression ability. The average recognition accuracy of this new hybrid deep learning model algorithm in two datasets is 98.67%, which can be used for the supervision of netizens' opinions.","2021","2025-02-26 20:39:13","2025-02-26 20:39:13","","59860-59872","","","9","","","","","","","","","","English","","","","WOS:000642755200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","bidirectional LSTM; conditional deep belief network; Emotion recognition; Feature extraction; genetic algorithm; Genetic algorithms; Mel frequency cepstral coefficient; particle swarm optimization; RECURRENT; REPRESENTATIONS; Speech emotion recognition; Speech recognition; Support vector machines; Training","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8S6DPR67","journalArticle","2021","Chen, H; Lin, Y; Li, YM; Wang, W; Wang, P; Lei, Y","Hybrid Feature Embedded Sparse Stacked Autoencoder and Manifold Dimensionality Reduction Ensemble for Mental Health Speech Recognition","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2021.3057382","","Speech feature learning is the key to speech mental health recognition. Deep feature learning can automatically extract the speech features but suffers from the small sample problem. The traditional feature extract method is effective, but cannot find the inter-feature structure to generate the new high-quality features. This paper proposes an embedded hybrid feature deep sparse stacked autoencoder ensemble method to solve this problem. Firstly, the speech features are extracted based on prior knowledge and called original features. Secondly, the original features are embedded into the deep network (Sparse Stacked Autoencoder) to filter the output of the hidden layer, to enhance the complementarity between the deep features and the original features. Thirdly, the L1 regularized feature selection mechanism is designed to reduce the hybrid feature set formed by the combination of deep features and original features. Finally, a manifold projection classifier ensemble is designed to enhance the stability of classification. Besides, this paper for the first time proposes a speech collection scheme for mental health recognition. We construct a large-scale Chinese mental health speech database for verification of the proposed algorithm of mental health. In the experimental section, the proposed algorithm is verified and compared with the representative related algorithms. The experimental results show that the proposed algorithm has better classification accuracy than the other representative algorithms. The proposed method combines the advantages of deep feature learning and traditional feature extraction methods more efficiently to solve the small sample problem.","2021","2025-02-26 20:39:13","2025-02-26 20:39:13","","28729-28741","","","9","","","","","","","","","","English","","","","WOS:000621384600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Classification algorithms; Depression; Embedded hybrid feature sparse stacked autoencoder; ensemble learning; Feature extraction; feature fusion; L1 regularization; Mental health; speech mental health recognition; Speech recognition; Support vector machines; Task analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KGMEBGJY","journalArticle","2022","Mobram, S; Vali, M","Depression detection based on linear and nonlinear speech features in I-vector/SVDA framework","COMPUTERS IN BIOLOGY AND MEDICINE","","0010-4825","10.1016/j.compbiomed.2022.105926","","This study proposes depression detection systems based on the i-vector framework for classifying speakers as depressed or healthy and predicting depression levels according to the Beck Depression Inventory-II (BDI-II). Linear and non-linear speech features are investigated as front-end features to i-vectors. To take advantage of the complementary effects of features, i-vector systems based on linear and non-linear features are combined through the decision-level fusion. Variability compensation techniques, such as Linear Discriminant Analysis (LDA) and Within-Class Covariance Normalization (WCCN), are widely used to reduce unwanted variabilities. A more generalizable technique than the LDA is required when limited training data are available. We employ a support vector discriminant analysis (SVDA) technique that uses the boundary of classes to find discriminatory directions to address this problem. Experiments conducted on the 2014 Audio-Visual Emotion Challenge and Workshop (AVEC 2014) depression database indicate that the best accuracy improvement obtained using SVDA is about 15.15% compared to the uncompensated i-vectors. In all cases, experimental results confirm that the decision -level fusion of i-vector systems based on three feature sets, TEO-CB-Auto-Env+delta, Glottal+delta, and MFCC+delta+delta delta, achieves the best results. This fusion significantly improves classifying results, yielding an ac-curacy of 90%. The combination of SVDA-transformed BDI-II score prediction systems based on these three feature sets achieved RMSE and MAE of 8.899 and 6.991, respectively, which means 29.18% and 30.34% improvements in RMSE and MAE, respectively, over the baseline system on the test partition. Furthermore, this proposed combination outperforms other audio-based studies available in the literature using the AVEC 2014 database.","2022-10","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","149","","","","","","","","","","English","","","","WOS:000877199500003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","Depression detection; i-vector; Speech feature; SVDA; TEO-CB-Auto-Env","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KBTDEW7P","journalArticle","2024","Sharma, Y; Singh, BK; Dhurandhar, S","Vocal tasks-based EEG and speech signal analysis in children with neurodevelopmental disorders: a multimodal investigation","COGNITIVE NEURODYNAMICS","","1871-4080","10.1007/s11571-024-10096-y","","Neurodevelopmental disorders (NDs) often hamper multiple functional prints of a child brain. Despite several studies on their neural and speech responses, multimodal researches on NDs are extremely rare. The present work examined the electroencephalography (EEG) and speech signals of the ND and control children, who performed ""Hindi language"" vocal tasks (V) of seven different categories, viz. 'vowel', 'consonant', 'one syllable', 'multi-syllable', 'compound', 'complex', and 'sentence' (V1-V7). Statistical testing of EEG parameters showed substantially high beta and gamma band energies in frontal, central, and temporal head sites of NDs for tasks V1-V5 and in parietal too for V6. For the 'sentence' task (V7), the NDs yielded significantly high theta and low alpha energies in the parietal area. These findings imply that even performing a general context-based task exerts a heavy cognitive loading in neurodevelopmental subjects. They also exhibited poor auditory comprehension while executing a long phrasing. Further, the speech signal analysis manifested significantly high amplitude (for V1-V7) and frequency (for V3-V7) perturbations in the voices of ND children. Moreover, the classification of subjects as ND or control was done via EEG and speech features. We attained 100% accuracy, precision, and F-measure using EEG features of all tasks, and using speech features of the 'complex' task. Jointly, the 'complex' task transpired as the best vocal stimuli among V1-V7 for characterizing ND brains. Meanwhile, we also inspected inter-relations between EEG energies and speech attributes of the ND group. Our work, thus, represents a unique multimodal layout to explore the distinctiveness of neuro-impaired children.","2024-10","2025-02-26 20:39:13","2025-02-26 20:39:13","","2387-2403","","5","18","","","","","","","","","","English","","","","WOS:001190038500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","AUTISM; Correlation; DECOMPOSITION; DIAGNOSIS; Electroencephalography (EEG); Neurodevelopmental disorders; Signal analysis; Speech; Vocal task","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9W7GC8XV","journalArticle","2022","Kaur, B; Rathi, S; Agrawal, RK","Enhanced depression detection from speech using Quantum Whale Optimization Algorithm for feature selection","COMPUTERS IN BIOLOGY AND MEDICINE","","0010-4825","10.1016/j.compbiomed.2022.106122","","There is an urgent need to detect depression using a non-intrusive approach that is reliable and accurate. In this paper, a simple and efficient unimodal depression detection approach based on speech is proposed, which is non -invasive, cost-effective and computationally inexpensive. A set of spectral, temporal and spectro-temporal fea-tures is derived from the speech signal of healthy and depressed subjects. To select a minimal subset of the relevant and non-redundant speech features to detect depression, a two-phase approach based on the nature-inspired wrapper-based feature selection Quantum-based Whale Optimization Algorithm (QWOA) is proposed. Experiments are performed on the publicly available Distress Analysis Interview Corpus Wizard-of-Oz (DAIC-WOZ) dataset and compared with three established univariate filtering techniques for feature selection and four well-known evolutionary algorithms. The proposed model outperforms all the univariate filter feature selection techniques and the evolutionary algorithms. It has low computational complexity in comparison to traditional wrapper-based evolutionary methods. The performance of the proposed approach is superior in comparison to existing unimodal and multimodal automated depression detection models. The combination of spectral, tem-poral and spectro-temporal speech features gave the best result with the LDA classifier. The performance ach-ieved with the proposed approach, in terms of F1-score for the depressed class and the non-depressed class and error is 0.846, 0.932 and 0.094 respectively. Statistical tests demonstrate that the acoustic features selected using the proposed approach are non-redundant and discriminatory. Statistical tests also establish that the performance of the proposed approach is significantly better than that of the traditional wrapper-based evolutionary methods.","2022-11","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","150","","","","","","","","","","English","","","","WOS:000864036200004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;89</p>","","","CUES; Depression; EVOLUTIONARY; EXPRESSION; Feature extraction; Feature selection; FREQUENCY; INDICATORS; Quantum-based Whale Optimization Algorithm; RECOGNITION; SEVERITY; Speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ME548WK4","journalArticle","2023","Zhang, Y; Wang, FP","HandFormer: A Dynamic Hand Gesture Recognition Method Based on Attention Mechanism","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13074558","","The application of dynamic gestures is extensive in the field of automated intelligent manufacturing. Due to the temporal and spatial complexity of dynamic gesture data, traditional machine learning algorithms struggle to extract accurate gesture features. Existing dynamic gesture recognition algorithms have complex network designs, high parameter counts, and inadequate gesture feature extraction. In order to solve the problems of low accuracy and high computational complexity in current dynamic gesture recognition, a network model based on the MetaFormer architecture and an attention mechanism was designed. The proposed network fuses a CNN (convolutional neural network) and Transformer model by embedding spatial attention convolution and temporal attention convolution into the Transformer model. Specifically, the token mixer in the MetaFormer block is replaced by the Spatial Attention Convolution Block and Temporal Attention Convolution Block to obtain the Spatial Attention Former Block and Temporal Attention Former Block. Firstly, each frame of the input image is quickly down-sampled by the PoolFormer block and then input to the Spatial Attention Former Block to learn spatial feature information. Then, the spatial feature maps learned from each frame are concatenated along the channel dimension and input to the Temporal Attention Former Block to learn the temporal feature information of the gesture action. Finally, the learned overall feature information is classified to obtain the category of dynamic gestures. The model achieves an average recognition accuracy of 96.72% and 92.16% on two publicly available datasets, Jester and NVGesture, respectively.","2023-04","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","7","13","","","","","","","","","","English","","","","WOS:000971908200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","attention mechanism; CNN (convolutional neural network); DATASET; dynamic hand gesture recognition; fusion network; MetaFormer; temporal feature","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DLI66JSP","journalArticle","2025","Zhang, JY; Guo, L; Wang, GL; Yu, J; Zheng, X; Mei, YS; Han, BY","A dual-level graph attention network and transformer for enhanced trajectory prediction under road network constraints","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.125510","","Predicting vehicle future trajectories enables various Location-Based Services (LBS), including traffic flow monitoring, vehicle route planning, etc. Vehicles are constrained to predefined road networks. Their traveling behaviors are influenced by both their own attributes and road network characteristics hidden in other vehicles' travel histories. Most of the existing methods fail to sufficiently leverage such collaborative trajectory data under road network constraints. This paper proposes a novel model, called HGT-RN (Hierarchical Graph Attention Network and Transformer Networks for Enhanced Trajectory Prediction under Road Network Constraints), which exploits all vehicles' trajectories and integrates road network constraints. Specifically, HGTRN creates a dual-level Graph Attention Network (GAT) based on global traffic flow and local individual trajectory graph to learn trajectory embeddings: (i) Weighted-directional global traffic flow graph and Weighted- Directional GAT to learn the global-level trajectory embedding by aggregating the neighbors' embeddings based on the spatial transitional relationships among road intersections over all vehicles' trajectories, considering the preference of current trajectory; and (ii) Local individual trajectory graph attention network to learn the local-level trajectory embedding by modeling the transitions within the current trajectory at each intersection. When incorporating the trajectory embeddings into a transformer model for future trajectory prediction, a road network topology-aware loss function is designed to improve accuracy. Extensive experiments conducted on three city-scale real-world taxi trajectory datasets demonstrate that HGT-RN significantly outperforms existing baseline models. The code is available at https://github.com/zjy9826/HGT-RN.","2025-02-01","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","261","","","","","","","","","","English","","","","WOS:001339557400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","Graph attention networks; MODEL; Road network constraints; Trajectory prediction; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9WE3N8FS","journalArticle","2023","Cai, ML; Zhao, L; Hou, GJ; Zhang, YN; Wu, W; Jia, LY; Zhao, JJ; Wang, L; Qiang, Y","FDTrans: Frequency Domain Transformer Model for predicting subtypes of lung cancer using multimodal data","COMPUTERS IN BIOLOGY AND MEDICINE","","0010-4825","10.1016/j.compbiomed.2023.106812","","Background and purpose: Accurate identification of lung cancer subtypes in medical images is of great significance for the diagnosis and treatment of lung cancer. Despite substantial progress in existing methods, they remain challenging due to limited annotated datasets, large intra-class differences, and high inter-class similarities. Methods: To address these challenges, we propose a Frequency Domain Transformer Model (FDTrans) to identify patients' lung cancer subtypes using the TCGA lung cancer dataset. We add a pre-processing process to transfer histopathological images to the frequency domain using a block-based discrete cosine transform and design a coordinate Coordinate-Spatial Attention Module (CSAM) to obtain critical detail information by reassigning weights to the location information and channel information of different frequency vectors. Then, a Cross-Domain Transformer Block (CDTB) is designed for Y, Cb, and Cr channel features, capturing the long-term dependencies and global contextual connections between different component features. At the same time, feature extraction is performed on the genomic data to obtain specific features. Finally, the image branch and the gene branch are fused, and the classification result is output through the fully connected layer. Results: In 10-fold cross-validation, the method achieves an AUC of 93.16% and overall accuracy of 92.33%, which is better than similar current lung cancer subtypes classification detection methods. Conclusion: This method can help physicians diagnose the subtypes classification of lung cancer in patients and can benefit from both spatial and frequency domain information.","2023-05","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","158","","","","","","","","","","English","","","","WOS:000971196500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Deep learning; Frequency domain; FUSION; Histopathological; Lung cancer subtypes; Multimodal learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2WJSZTNR","journalArticle","2024","Kartal, Y; Akdeniz, EK; Özkan, K","Automating modern code review processes with code similarity measurement","INFORMATION AND SOFTWARE TECHNOLOGY","","0950-5849","10.1016/j.infsof.2024.107490","","Context: Modern code review is a critical component in software development processes, as it ensures security, detects errors early and improves code quality. However, manual reviews can be time-consuming and unreliable. Automated code review can address these issues. Although deep -learning methods have been used to recommend code review comments, they are expensive to train and employ. Instead, information retrieval (IR) -based methods for automatic code review are showing promising results in efficiency, effectiveness, and flexibility. Objective: Our main objective is to determine the optimal combination of the vectorization method and similarity to measure what gives the best results in an automatic code review, thereby improving the performance of IR -based methods. Method: Specifically, we investigate different vectorization methods (Word2Vec, Doc2Vec, Code2Vec, and Transformer) that differ from previous research (TF-IDF and Bag -of -Words), and similarity measures (Cosine, Euclidean, and Manhattan) to capture the semantic similarities between code texts. We evaluate the performance of these methods using standard metrics, such as Blue, Meteor, and Rouge -L, and include the run-time of the models in our results. Results: Our results demonstrate that the Transformer model outperforms the state-of-the-art method in all standard metrics and similarity measurements, achieving a 19.1% improvement in providing exact matches and a 6.2% improvement in recommending reviews closer to human reviews. Conclusion: Our findings suggest that the Transformer model is a highly effective and efficient approach for recommending code review comments that closely resemble those written by humans, providing valuable insight for developing more efficient and effective automated code review systems.","2024-09","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","173","","","","","","","","","","English","","","","WOS:001245336700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Code similarity; Information retrieval; Modern code review; Vectorization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W9LTIPC6","journalArticle","2024","Hu, YR","Design and Research of Cross-Border E-Commerce Short Video Recommendation System Based on Multi-Modal Fusion Transformer Model","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","This study designed a cross-border e-commerce short video recommendation system based on Transformer's multimodal analysis model. When mining associations, the model not only focuses on the relationships between modalities, but also improves semantic context by addressing contextual correlations within and between modalities. At the same time, the model uses a cross modal multi head attention mechanism for multi-level association mining, and constructs an association network interwoven with latitude and longitude. In the process of exploring the essential correlation between patterns and subjective emotional fluctuations, the potential context between patterns has been realized. Fully explore correlations and then more accurately identify the truth contained in the original data. In addition, this study proposes a self supervised single modal label generation method. When multimodal labels are known, it does not require complex deep networks and only relies on the mapping relationship between multimodal representations and labels to generate a single modal label. Modal labeling can achieve phased automatic labeling of single modal labels, and quantify the mapping relationship between modal representations and labels from the representation space to generate weak single modal labels. The study also achieved multimodal collaborative learning in the context of limited differential information acquisition due to incomplete labeling, fully utilizing multimodal information. The experimental results on classic datasets in the field of multimodal analysis show that it outperforms the baseline model in terms of accuracy and F1 score, reaching 98.76% and 97.89%, respectively.","2024-08","2025-02-26 20:39:13","2025-02-26 20:39:13","","410-419","","8","15","","","","","","","","","","English","","","","WOS:001313102300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","cross border e -commerce; Multimodal fusion; short video recommendation system; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YZ6A6KEN","journalArticle","2022","Orosz, T","FEM-Based Power Transformer Model for Superconducting and Conventional Power Transformer Optimization","ENERGIES","","1996-1073","10.3390/en15176177","","There were many promising superconducting materials discovered in the last decades that can significantly increase the efficiency of large power transformers. However, these large machines are generally custom-made and tailored to the given application. During the design process the most economical design should be selected from thousands of applicable solutions in a short design period. Due to the nonlinearity of the task, the cost-optimal transformer design, which has the smallest costs during the transformers' planned lifetime, is usually not the design with the highest efficiency. Due to the topic's importance, many simplified transformer models were published in the literature to resolve this problem. However, only a few papers considered this preliminary design optimization problem in the case of superconducting transformers and none of them made a comparison with a validated conventional transformer optimization model. This paper proposes a novel FEM-based two-winding transformer model, which can be used to calculate the main dimension of conventional and superconducting transformer designs. The models are stored in a unified JSON-file format, which can be easily integrated into an evolutionary or genetic algorithm-based optimization. The paper shows the used methods and their accuracy on conventional 10 MVA and superconducting 1.2 MVA transformer designs. Moreover, a simple cost optimization with the 10 MVA transformer was performed for two realistic economic scenarios. The results show that in some cases the cheaper, but less efficient, transformer can be the more economic.","2022-09","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","17","15","","","","","","","","","","English","","","","WOS:000852525300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","AC LOSSES; DESIGN OPTIMIZATION; evolutionary algorithms; finite element analysis; HYSTERESIS LOSS; IMPACT; KV; optimization; power transformers; superconductors; TAPES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZTPH9HRG","journalArticle","2024","Hirosawa, T; Shimizu, T","Enhancing English Presentation Skills with Generative Artificial Intelligence: A Guide for Non-native Researchers","MEDICAL SCIENCE EDUCATOR","","2156-8650","10.1007/s40670-024-02078-w","","This commentary explores the utilization of generative artificial intelligence (AI), particularly Google Gemini (previously Bard), in enhancing English presentation skills among non-native researchers. We present a step-by-step methodology for using Google Gemini's Speech-to-Text and Text-to-Speech features. Our findings suggest that Google Gemini effectively aids in draft presentations, pronunciation practice, and content verification, tapping into an area often unexplored-using AI for presentation skills in scientific research. Despite its potential, users must exercise caution due to the experimental nature of this AI technology. Adapting to such technologies is timely and beneficial for the global scientific community.","2024-10","2025-02-26 20:39:13","2025-02-26 20:39:13","","1179-1184","","5","34","","","","","","","","","","English","","","","WOS:001234209500003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","Artificial intelligence; Communication; Learning; Natural language processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5LN3X3QQ","journalArticle","2023","Umejiaku, AP; Dhakal, P; Sheng, VS","Detecting COVID-19 Effectively with Transformers and CNN-Based Deep Learning Mechanisms","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13064050","","The COVID-19 pandemic has been a major global concern in the field of respiratory diseases, with healthcare institutions and partners investing significant resources to improve the detection and severity assessment of the virus. In an effort to further enhance the detection of COVID-19, researchers have investigated the performance of current detection methodologies and proposed new approaches that leverage deep learning techniques. In this article, the authors propose a two-step transformer model for the multi-class classification of COVID-19 images in a patient-aware manner. This model is implemented using transfer learning, which allows for the efficient use of pre-trained models to accelerate the training of the proposed model. The authors compare the performance of their proposed model to other CNN models commonly used in the detection of COVID-19. The experimental results of the study show that CNN-based deep learning networks obtained an accuracy in the range of 0.76-0.92. However, the proposed two-step transformer model implemented with transfer learning achieved a significantly higher accuracy of 0.9735 +/- 0.0051. This result indicates that the proposed model is a promising approach to improving the detection of COVID-19. Overall, the findings of this study highlight the potential of deep learning techniques, particularly the use of transfer learning and transformer models, to enhance the detection of COVID-19. These approaches can help healthcare institutions and partners to reduce the time and difficulty in detecting the virus, ultimately leading to more effective and timely treatment for patients.","2023-03","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","6","13","","","","","","","","","","English","","","","WOS:000954155500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","CNN; COVID-19; transfer learning; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LQURNM3B","journalArticle","2023","Ayas, S","Multiclass skin lesion classification in dermoscopic images using swin transformer model","NEURAL COMPUTING & APPLICATIONS","","0941-0643","10.1007/s00521-022-08053-z","","Automatic skin lesion classification in dermoscopic images is a very challenging task due to the huge intraclass variation, the high degree of interclass visual similarity, low contrast between skin lesion and surrounding normal skin, and the existence of extraneous and intrinsic artifacts. However, existing algorithms for skin lesion classification are developed by leveraging convolutional neural networks (CNNs), and the effectiveness of these algorithms is mostly validated for binary classification of skin lesions. In addition, the relatively low diagnostic sensitivity achieved by these studies demonstrates the uncertainty involved in skin lesion classification. In order to overcome these difficulties, a swin transformer model for multiclass skin lesion classification is proposed by taking advantage of both transformer and CNNs that are based on end-to-end mapping and do not require prior knowledge. Furthermore, the problem of class imbalance is addressed through a weighted cross entropy loss. Moreover, key components of the proposed approach are explored in detail in order to ensure efficient and effective learning process with multiclass data in the skin lesion classification. The proposed method is extensively evaluated on International Skin Imaging Collaboration (ISIC) 2019 Skin Lesion Analysis Towards Melanoma Detection Challenge dataset and achieves a sensitivity, specificity, accuracy, and balanced accuracy value of 82.3%, 97.9%, 97.2%, and 82.3%, respectively. Experimental results demonstrate that the proposed method has the highest balanced accuracy value and outperforms most of the other state-of-the-art methods in multiclass skin lesion classification.","2023-03","2025-02-26 20:39:13","2025-02-26 20:39:13","","6713-6722","","9","35","","","","","","","","","","English","","","","WOS:000889402900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;23<br/>Total Times Cited:&nbsp;&nbsp;24<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Dermoscopy image analysis; DIAGNOSIS; Multiclass classification; SEGMENTATION; Skin lesion diagnosis; Swin transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MNB9Z7A3","journalArticle","2024","Ishfaq, M; Saadia, A; Alserhani, FM; Gul, A","Enhancing Security: Infused Hybrid Vision Transformer for Signature Verification","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3447083","","Handwritten signature verification is challenging because there is a huge variation between the orientation thickness and appearance of handwritten signatures. A strong signature verification system is essential to refine the accuracy of confirming user authentication. This investigation introduces an inclusive framework for training and evaluating hybrid vision transformer models on diverse signature datasets, aiming to refine the accuracy in confirming user authentication. In previous studies, transformer & MobileNet were used for computer vision classification and signature verification separately. Drawing inspiration from the Convolutional Neural Network (CNN), the hybrid model is proposed as a deep-learning model (ResNet-18 & MobileNetV2) with the Vision Transformer model (proposed method 1 & proposed method 2).To bring originality to this study, we excluded the final layer of the feature extractor and smoothly integrated it with the initial layer of the vision transformer. In the scope of this research, we introduced a unique hybrid vision transformer model. Furthermore, we incorporated swish and tangent hyperbolic (tanh) activation functions into the validation model to enhance its performance. Experimental results showcase the effectiveness of the proposed hybrid model, achieving notable accuracies on various datasets, including 92.33% accuracy on Bhsig-Bengali, 99.89% accuracy on Bhsig-Hindi, 99.96% accuracy on Cedar, and 74.09% accuracy on UTsig-Persian datasets, respectively. The practical implications of this research extend to real-time signature verification for secure and efficient user authentication, particularly in mobile applications. This advancement in signature verification technology presents new possibilities for practical use in diverse scenarios beyond academia.","2024","2025-02-26 20:39:13","2025-02-26 20:39:13","","137504-137521","","","12","","","","","","","","","","English","","","","WOS:001327325200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","FEATURES; handwritten character verification; handwritten signature verification; hybrid vision transformer; MobileNetV2; signature verification; UTsig-Persian; Vision transformer ResNet-18","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TSFWHKSJ","journalArticle","2023","Akbari, M; Rezaei-Zare, A","Thermal Analysis of Power Transformers Under Geomagnetically Induced Current","IEEE TRANSACTIONS ON POWER DELIVERY","","0885-8977","10.1109/TPWRD.2023.3303106","","Temperature distribution in the power transformers is investigated in this study under Geomagnetically Induced Current (GIC) conditions. Thermal stress can significantly reduce the insulation life, and in the case of excessive hot spot temperature (HST), catastrophic failure of transformers is likely, as happened in the past Geomagnetic Disturbance (GMD) events. Although a few reports emphasize the impact of GIC on the local heating within the transformers, especially in the structural parts, the effect of GIC on the thermal condition of transformers has not been investigated profoundly. This article studies the power transformer HST during the GIC. Since finding stray losses under GIC conditions is challenging, a hybrid approach, including a topological transformer model and 3D finite element method (FEM), is implemented. The detailed topological transformer model is utilized in the EMTP time-domain simulations to determine the harmonic currents at different GIC levels. Additionally, FEM is employed to calculate the temperature distribution within the transformer. The simulation results reveal that the structural parts are saturated with low GIC magnitudes, resulting in high stray losses and local hot spot heating in those areas. Furthermore, the tank can reach high temperatures at mid-GIC levels. These results clearly show that the transformer structural parts are highly vulnerable under severe GIC situations.","2023-12","2025-02-26 20:39:13","2025-02-26 20:39:13","","4114-4121","","6","38","","","","","","","","","","English","","","","WOS:001116067200062","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Circuit faults; Computational fluid dynamics; Computational fluid dynamics (CFD); Finite element analysis; finite element method; FLOW; geomagnetic disturbance (GMD); Geomagnetic storms; geomagnetically induced current (GIC); HEAT-TRANSFER; hot-spot temperature; MODEL; Oil insulation; PERFORMANCE; Power transformer insulation; PREDICTION; RADIATORS; SIMULATION; SINGLE-PHASE; transformer thermal modeling; VALIDATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CFMBJFV3","journalArticle","2023","Zhang, X; Li, P","Transfer Learning in the Transformer Model for Thermal Comfort Prediction: A Case of Limited Data","ENERGIES","","1996-1073","10.3390/en16207137","","The HVAC (Heating, Ventilation, and Air Conditioning) system is an important component of a building's energy consumption, and its primary function is to provide a comfortable thermal environment for occupants. Accurate prediction of occupant thermal comfort is essential for improving building energy utilization as well as health and work efficiency. Therefore, the development of accurate thermal comfort prediction models is of great value. Deep learning based on data-driven techniques has excellent potential for predicting thermal comfort due to the development of artificial intelligence. However, the inability to obtain large quantities of detailed thermal comfort labeling data from residents presents a substantial challenge to the modeling endeavor. This paper proposes a building-to-building transfer learning framework to make deep learning models applicable in data-limited interior building environments, thereby resolving the issue and enhancing model predictive performance. The transfer learning method (TL) is applied to a novel technology dubbed the Transformer model, which has demonstrated outstanding performance in data trend prediction. The model exploits the spatiotemporal relationship of data regarding thermal comfort. Experiments are conducted using the source dataset (Scales project dataset and ASHRAE RP-884 dataset) and the target dataset (Medium US office dataset), and the results show that the proposed TL-Transformer achieves 62.6% accuracy, 57% precision, and a 59% F1 score, and the prediction performance is better than other existing methods. The model is useful for predicting indoor thermal comfort in buildings with limited data, and its validity is verified by experimental results.","2023-10","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","20","16","","","","","","","","","","English","","","","WOS:001092558100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","buildings; deep learning; energy efficiency; HVAC; INDOOR; OFFICE; thermal comfort; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QV7NUDEX","journalArticle","2024","Paderno, A; Rau, A; Bedi, N; Bossi, P; Mercante, G; Piazza, C; Holsinger, FC","Computer Vision Foundation Models in Endoscopy: Proof of Concept in Oropharyngeal Cancer","LARYNGOSCOPE","","0023-852X","10.1002/lary.31534","","ObjectivesTo evaluate the performance of vision transformer-derived image embeddings for distinguishing between normal and neoplastic tissues in the oropharynx and to investigate the potential of computer vision (CV) foundation models in medical imaging.MethodsComputational study using endoscopic frames with a focus on the application of a self-supervised vision transformer model (DINOv2) for tissue classification. High-definition endoscopic images were used to extract image patches that were then normalized and processed using the DINOv2 model to obtain embeddings. These embeddings served as input for a standard support vector machine (SVM) to classify the tissues as neoplastic or normal. The model's discriminative performance was validated using an 80-20 train-validation split.ResultsFrom 38 endoscopic NBI videos, 327 image patches were analyzed. The classification results in the validation cohort demonstrated high accuracy (92%) and precision (89%), with a perfect recall (100%) and an F1-score of 94%. The receiver operating characteristic (ROC) curve yielded an area under the curve (AUC) of 0.96.ConclusionThe use of large vision model-derived embeddings effectively differentiated between neoplastic and normal oropharyngeal tissues. This study supports the feasibility of employing CV foundation models like DINOv2 in the endoscopic evaluation of mucosal lesions, potentially augmenting diagnostic precision in Otorhinolaryngology.Level of Evidence4 Laryngoscope, 2024 A computational study using endoscopic frames with a focus on the application of a trained self-supervised vision transformer model for tissue classification. This study supports the feasibility of employing vision foundation models in the endoscopic evaluation of mucosal lesions. image","2024-11","2025-02-26 20:39:13","2025-02-26 20:39:13","","4535-4541","","11","134","","","","","","","","","","English","","","","WOS:001240555600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","artificial intelligence; CLASSIFICATION; computer vision; endoscopy; foundation models; oropharyngeal cancer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F4TUE6KA","journalArticle","2024","Fang, ZQ; Hu, Y; Tan, ZH; Li, ZK; Yan, Z; He, YT; Luo, ST; Cao, Y","Regularized spatial-spectral transformer for domain adaptation in hyperspectral image classification","JOURNAL OF APPLIED REMOTE SENSING","","1931-3195","10.1117/1.JRS.18.042610","","Unsupervised domain adaptation (UDA) is an effective approach for cross-scene hyperspectral image (HSI) classification. Notably, deep learning-based UDA methods have shown potential by leveraging their powerful capability of feature extraction. Most of these methods rely on traditional convolutional neural networks (CNNs), which typically emphasize local feature extraction but lack the capacity to capture global features, thereby limiting their ability to process complex HSI data. Given the ability of capturing long-range dependencies, the transformer demonstrates superior performance than CNNs in many fields, making its employment in UDA a promising approach. However, the original transformer has only spatial attention, which is inadequate for HSI data with spatial and spectral dimensions. Moreover, the limited available labeled HSI data cannot offer the optimization of the transformer model and constrains its capacity. To address these problems, a regularized spatial-spectral transformer for domain adaptation (RSTDA) is proposed. To effectively extract features from HSI data, a spatial-spectral transformer network is designed for HSI data specifically, which contains spatial-spectral attention modules to facilitate the extraction of spatial-spectral features. Also, convolutional layers are introduced at different stages of the transformer as a regulation technique, making it possible to train the transformer model on limited HSI data. Finally, a smooth adversarial training strategy is adopted to decrease the domain discrepancy and improve the generalization of the transformer, thus enhancing the accuracy of the crossscene HSI classification. Experimental results on three datasets demonstrate that RSTDA surpasses the existing state-of-the-art UDA methods for HSI classification.","2024-10","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","4","18","","","","","","","","","","English","","","","WOS:001410544700010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","classification; hyperspectral image; regularization; transformer; unsupervised domain adaptation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PQTFDBGF","journalArticle","2024","Zhang, TY; Liu, J; Wu, F; Wang, K; Huang, SB; Zhang, YK","Artifact suppression for sparse view CT via transformer-based generative adversarial network","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2024.106297","","Sparse view CT images are often severely degraded by streak artifacts. Numerous studies have confirmed the remarkable progress made by deep learning (DL) in sparse view CT imaging scenarios. However, the mainstream CNN-based methods are inefficient when capturing feature information in large regions. In this paper, a transformer based generative adversarial network (SVT-GAN), which is designed to efficiently suppress artifacts in sparse view CT images, is proposed. We leverage the advantages of transformer networks and adversarial learning into a framework to improve the quality of sparse view CT image restoration results. The generator is primarily composed of an encoder-decoder structure that relies on the transformer model to learn multiscale local-global representations and leverage contextual information derived from distant artifacts. Moreover, in contrast with the standard transformer model, we utilize the multi-Dconv head-transposed attention (MDTA) module to enhance the ability of the proposed approach to extract both local and nonlocal information and produce impressive structure and detail restoration results. To suppress the transformation of artifact features, the gated-Dconv feedforward network (GDFN) is utilized. Within the GAN learning framework, we employ a simple nine-layer network as the discriminator to enhance the ability of the generator to suppress artifacts and retain features. Compared with the recently developed state-of-the-art methods, the proposed model significantly reduces serious noise artifacts while preserving details on the AAPM and Real CT datasets. Qualitative and quantitative assessments demonstrate the competitive performance of the SVT-GAN.","2024-09","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","95","","","","","","","","","","English","","","","WOS:001232393800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","COMPUTED-TOMOGRAPHY; CT; Deep learning; DUAL-DOMAIN; Generate adversarial networks; RECONSTRUCTION; Sparse view; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CY5YZMXV","journalArticle","2024","Lu, YT; Wang, SZ; Wang, BL; Zhang, X; Wang, XX; Zhao, YQ","Enhanced Window-Based Self-Attention with Global and Multi-Scale Representations for Remote Sensing Image Super-Resolution","REMOTE SENSING","","2072-4292","10.3390/rs16152837","","Transformers have recently gained significant attention in low-level vision tasks, particularly for remote sensing image super-resolution (RSISR). The vanilla vision transformer aims to establish long-range dependencies between image patches. However, its global receptive field leads to a quadratic increase in computational complexity with respect to spatial size, rendering it inefficient for addressing RSISR tasks that involve processing large-sized images. In an effort to mitigate computational costs, recent studies have explored the utilization of local attention mechanisms, inspired by convolutional neural networks (CNNs), focusing on interactions between patches within small windows. Nevertheless, these approaches are naturally influenced by smaller participating receptive fields, and the utilization of fixed window sizes hinders their ability to perceive multi-scale information, consequently limiting model performance. To address these challenges, we propose a hierarchical transformer model named the Multi-Scale and Global Representation Enhancement-based Transformer (MSGFormer). We propose an efficient attention mechanism, Dual Window-based Self-Attention (DWSA), combining distributed and concentrated attention to balance computational complexity and the receptive field range. Additionally, we incorporated the Multi-scale Depth-wise Convolution Attention (MDCA) module, which is effective in capturing multi-scale features through multi-branch convolution. Furthermore, we developed a new Tracing-Back Structure (TBS), offering tracing-back mechanisms for both proposed attention modules to enhance their feature representation capability. Extensive experiments demonstrate that MSGFormer outperforms state-of-the-art methods on multiple public RSISR datasets by up to 0.11-0.55 dB.","2024-08","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","15","16","","","","","","","","","","English","","","","WOS:001286982100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","global receptive field; multi-scale representation; NETWORK; remote sensing image super-resolution; transformer model; window-based self-attention","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2N74L3JQ","journalArticle","2023","Kadri, M; Hamouda, A; Sayah, S","Efficient method for transformer models implementation in distribution load flow matrix","ELECTRICAL ENGINEERING & ELECTROMECHANICS","","2074-272X","10.20998/2074-272X.2023.3.11","","Introduction. Most distribution networks are unbalanced and therefore require a specific solution for load flow. There are many works on the subject in the literature, but they mainly focus on simple network configurations. Among the methods dedicated to this problem, one can refer to the load flow method based on the bus injection to branch current and branch current to bus voltage matrices. Problem. Although this method is regarded as simple and complete, its drawback is the difficulty in supporting the transformer model as well as its winding connection types. Nevertheless, the method requires the system per unit to derive the load flow solution. Goal. In the present paper, our concern is the implementation of distribution transformers in the modeling and calculation of load flow in unbalanced networks. Methodology. Unlike previous method, distribution transformer model is introduced in the topology matrices without simplifying assumptions. Particularly, topology matrices were modified to take into account all winding types of both primary and secondary sides of transformer that conserve the equivalent scheme of an ideal transformer in series with an impedance. In addition, the adopted transformer models overcome the singularity problem that can be encountered when switching from the primary to the secondary side of transformer and inversely. Practical value. The proposed approach was applied to various distribution networks such as IEEE 4-nodes, IEEE 13-nodes and IEEE 37-nodes. The obtained results validate the method and show its effectiveness. References 24, tables 4, figures 9.","2023","2025-02-26 20:39:13","2025-02-26 20:39:13","","76-82","","3","","","","","","","","","","","English","","","","WOS:000989080500011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","DISTRIBUTION NETWORKS; distribution systems; distribution transformer models; POWER-FLOW; topology network matrix; unbalanced load flow","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GTL7M4YC","journalArticle","2022","Stankevicius, L; Lukosevicius, M; Kapociute-Dzikiene, J; Briediene, M; Krilavicius, T","Correcting Diacritics and Typos with a ByT5 Transformer Model","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app12052636","","Due to the fast pace of life and online communications and the prevalence of English and the QWERTY keyboard, people tend to forgo using diacritics, make typographical errors (typos) when typing in other languages. Restoring diacritics and correcting spelling is important for proper language use and the disambiguation of texts for both humans and downstream algorithms. However, both of these problems are typically addressed separately: the state-of-the-art diacritics restoration methods do not tolerate other typos, but classical spellcheckers also cannot deal adequately with all the diacritics missing.In this work, we tackle both problems at once by employing the newly-developed universal ByT5 byte-level seq2seq transformer model that requires no language-specific model structures. For a comparison, we perform diacritics restoration on benchmark datasets of 12 languages, with the addition of Lithuanian. The experimental investigation proves that our approach is able to achieve results (>98%) comparable to the previous state-of-the-art, despite being trained less and on fewer data. Our approach is also able to restore diacritics in words not seen during training with >76% accuracy. Our simultaneous diacritics restoration and typos correction approach reaches >94% alpha-word accuracy on the 13 languages. It has no direct competitors and strongly outperforms classical spell-checking or dictionary-based approaches. We also demonstrate all the accuracies to further improve with more training. Taken together, this shows the great real-world application potential of our suggested methods to more data, languages, and error classes.","2022-03","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","5","12","","","","","","","","","","English","","","","WOS:000771041000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;118</p>","","","ByT5; diacritics restoration; natural language processing; QWERTY; RESTORATION; SPELLING CORRECTION; transformer models; typo correction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EKBLJKS5","journalArticle","2024","Lee, MY; Huang, YS; Chang, CJ; Yang, JY; Liu, CW; Lin, TC; Lin, YB","Transmission Line Fault Classification Using Conformer Convolution-Augmented Transformer Model","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14104031","","Ensuring a consistently reliable power supply is paramount in power systems. Researchers are engaged in the pursuit of categorizing transmission line failures to design countermeasures for mitigating the associated financial losses. Our study employs a machine learning-based methodology, specifically the Conformer Convolution-Augmented Transformer model, to classify transmission line fault types. This model processes time series input data directly, eliminating the need for expert feature extraction. The training and validation datasets are generated through simulations conducted on a two-terminal transmission line, while testing is conducted on historical data consisting of 108 events that occurred in the Taiwan power system. Due to the limited availability of historical data, they are utilized solely for inference purposes. Our simulations are meticulously designed to encompass potential faults based on an analysis of historical data. A significant aspect of our investigation focuses on the impact of the sampling rate on input data, establishing that a rate of four samples per cycle is sufficient. This suggests that, for our specific classification tasks, relying on lower frequency data might be adequate, thereby challenging the conventional emphasis on high-frequency analysis. Eventually, our methodology achieves a validation accuracy of 100%, although the testing accuracy is lower at 88.88%. The discrepancy in testing accuracy can be attributed to the limited information and the small number of historical events, which pose challenges in bridging the gap between simulated data and real-world measurements. Furthermore, we benchmarked our method against the ELM model proposed in 2023, demonstrating significant improvements in testing accuracy.","2024-05","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","10","14","","","","","","","","","","English","","","","WOS:001233118300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","conformer model; machine learning; sampling rate; transmission line fault classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P6PQ86WX","journalArticle","2024","Parri, S; Teeparthi, K","SVMD-TF-QS: An efficient and novel hybrid methodology for the wind speed prediction","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.123516","","Wind power is gaining significant attention as a renewable and environmentally friendly energy source. However, accurate forecasting of wind speed poses challenges due to its inherent variability and stochastic nature. To address this issue, a novel hybrid model (SVMD-TF-QS) for wind speed prediction (WSP) is proposed in this study. The model combines successive variational mode decomposition (SVMD) with a Transformer (TF) based model that incorporates a novel query selection (QS) mechanism. The SVMD component of the hybrid model offers several improvements, including enhanced mode extraction, adaptive mode determination, robustness against initial values of center frequencies, and improved computational efficiency. By decomposing the wind speed data using SVMD, the transformed data is then fed into the TF-QS model. The proposed approach effectively combines the benefits of the QS mechanism and the Transformer model to accurately predict wind speed while minimizing computational load. This is achieved by introducing a deterministic algorithm within the QS mechanism, which computes a sparse approximation of the attention matrix used in the Transformer model. This further enhances the predictive capabilities of the hybrid model. To evaluate its performance and generalization capability, extensive assessments are conducted using data from two wind farms located in Leicester and Portland. The assessments cover various time periods, including 5 min, 10 min, 15 min, 30 min, 1 h, and 2 h WSP intervals. The results of this study provide robust evidence supporting the effectiveness of the proposed hybrid model in WSP for the diverse wind farms and scenarios.","2024-09-01","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","249","","","","","","","","","","English","","","","WOS:001198402600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","DECOMPOSITION; Efficiency; MODEL; Predictions; Query; Svmd; Wind speed","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QUYDQK6A","journalArticle","2025","Yin, KX; Chen, CJ; Shen, Q; Deng, J","A lightweight and rapidly converging transformer based on separable linear self-attention for fault diagnosis","MEASUREMENT SCIENCE AND TECHNOLOGY","","0957-0233","10.1088/1361-6501/ad9f89","","Reaching reliable decisions on equipment maintenance is facilitated by the implementation of intelligent fault diagnosis techniques for rotating machineries. Recently, the Transformer model has demonstrated exceptional capabilities in global feature modeling for fault diagnosis tasks, garnering significant attention from the academic community. However, it lacks sufficient prior knowledge regarding rotation invariance, scale, and shift, necessitating pre-training on extensive datasets. In comparison, contemporary convolutional neural networks exhibit greater ease of optimization. This limitation becomes particularly evident when applying the Transformer model in fault diagnosis scenarios with limited data availability. Moreover, the increasing the number of parameters and FLOPs. Pose a challenge to its suitability for mobile services due to the limited computational resources available on edge devices. To mitigate these issues, this paper introduces a novel lightweight Transformer (SepFormer) based on separable linear self-attention (LSA) for fault diagnosis task. The SepFormer performs a novel sequence-level feature embedding to better leverage the inductive bias inherent in the convolutional layers. Furthermore, it integrate a novel separable LSA mechanism into the Transformer architecture, effectively mitigating the computational burden concerns and significantly enhancing the training convergence speed. Extensive experiments are conducted extensively on a bearing fault dataset and gear fault dataset. The experimental results demonstrate that the SepFormer achieves a top-1 accuracy exceeding state-of-the-art approaches by more than 5%, while utilizing the fewest FLOPs. Moreover, the optimizability of SepFormer surpasses that of CNN, ensuring its superior preservation of inductive bias.","2025-01-31","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","1","36","","","","","","","","","","English","","","","WOS:001390449400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","fault diagnosis; FUSION; inductive bias; lightweight; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IRIEBUNQ","journalArticle","2025","Liu, CZ; Zhu, ZY; Hao, WM; Sun, GC","Heterogeneous multivariate time series imputation by transformer model with missing position encoding","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2025.126435","","Time series imputation has become a hot research topic. With Transformer-based methods becoming the mainstream approach in the field of artificial intelligence, leveraging Transformer-based techniques to enhance time series imputation has become the primary consensus among scholars. However, due to the unique nature of numerical representations in time series and the difficulty in aligning representations of missing values in multivariate time series with token representations, Transformer-based solutions often struggle to achieve satisfactory results directly. This paper presents a time series imputation method based on an Encoder-Only Transformer model. This approach tokenizes time series with missing values and employs a Transformer to establish an end-to-end reconstruction and prediction loss function, effectively completing the time series. The model incorporates token embeddings for missing positions to specifically indicate missing locations within the time series. Additionally, heterogeneous token node embeddings are used to represent the variable types each token belongs to within a multivariate time series. The model also integrates absolute, relative, and learnable position encodings to maintain the position invariance of time series tokens. We demonstrate that for heterogeneous multivariate time series modeling, multi-addition position embedding trick also works. This method effectively addresses the issue of missing data in time series, providing a novel approach and tool for time series analysis. Empirical evaluations on synthetic datasets and KDD competition datasets demonstrate that the proposed heterogeneous multivariate time series imputation method achieves a significant advancement (about 5% similar to 10%) compared with existing method.","2025-05-01","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","271","","","","","","","","","","English","","","","WOS:001420459600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","Heterogeneous time series; Missing position encoding; Transformer-based imputation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PTPUL3L2","journalArticle","2023","Skondras, P; Zervas, P; Tzimas, G","Generating Synthetic Resume Data with Large Language Models for Enhanced Job Description Classification","FUTURE INTERNET","","1999-5903","10.3390/fi15110363","","In this article, we investigate the potential of synthetic resumes as a means for the rapid generation of training data and their effectiveness in data augmentation, especially in categories marked by sparse samples. The widespread implementation of machine learning algorithms in natural language processing (NLP) has notably streamlined the resume classification process, delivering time and cost efficiencies for hiring organizations. However, the performance of these algorithms depends on the abundance of training data. While selecting the right model architecture is essential, it is also crucial to ensure the availability of a robust, well-curated dataset. For many categories in the job market, data sparsity remains a challenge. To deal with this challenge, we employed the OpenAI API to generate both structured and unstructured resumes tailored to specific criteria. These synthetically generated resumes were cleaned, preprocessed and then utilized to train two distinct models: a transformer model (BERT) and a feedforward neural network (FFNN) that incorporated Universal Sentence Encoder 4 (USE4) embeddings. While both models were evaluated on the multiclass classification task of resumes, when trained on an augmented dataset containing 60 percent real data (from Indeed website) and 40 percent synthetic data from ChatGPT, the transformer model presented exceptional accuracy. The FFNN, albeit predictably, achieved lower accuracy. These findings highlight the value of augmented real-world data with ChatGPT-generated synthetic resumes, especially in the context of limited training data. The suitability of the BERT model for such classification tasks further reinforces this narrative.","2023-11","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","11","15","","","","","","","","","","English","","","","WOS:001107875100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","big data; ChatGPT; CV; deep learning; embeddings; labor market analysis; large language models; metadata extraction; multiclass classification; resumes","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UXSJCLFB","journalArticle","2023","Jahromi, AN; Pourjafari, E; Karimipour, H; Satpathy, A; Hodge, L","CRL+: A Novel Semi-Supervised Deep Active Contrastive Representation Learning-Based Text Classification Model for Insurance Data","JOURNAL OF ADVANCES IN INFORMATION TECHNOLOGY","","1798-2340","10.12720/jait.14.5.1056-1062","","Financial sector and especially the insurance industry collect vast volumes of text on a daily basis and through multiple channels (their agents, customer care centers, emails, social networks, and web in general). The information collected includes policies, expert and health reports, claims and complaints, results of surveys, and relevant social media posts. It is difficult to effectively extract labels, classify, and interpret the essential information from such varied and unstructured material. Therefore, the Insurance Industry is among the ones that can benefit from applying technologies for the intelligent analysis of free text through Natural Language Processing (NLP). In this paper, CRL+, a novel text classification model combining Contrastive Representation Learning (CRL) and Active Learning is proposed to handle the challenge of using semi-supervised learning for text classification. In this method, supervised (CRL) is used to train a RoBERTa transformer model to encode the textual data into a contrastive representation space and then classify using a classification layer. This CRL-based transformer model is used as the base model in the proposed Active Learning mechanism to classify all the data in an iterative manner. The proposed model is evaluated using unstructured obituary data with objective to determine the cause of the death from the data. This model is compared with the CRL model and an Active Learning model with the RoBERTa base model. The experiment shows that the proposed method can outperform both methods for this specific task.","2023","2025-02-26 20:39:13","2025-02-26 20:39:13","","1056-1062","","5","14","","","","","","","","","","English","","","","WOS:001100488200021","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","active learning; contrastive representation learning; CRL+; natural language processing; text classification; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S2U9A7BM","journalArticle","2022","Yang, C; Lu, TL; Yan, SY; Zhang, JL; Yu, XZ","N-Trans: Parallel Detection Algorithm for DGA Domain Names","FUTURE INTERNET","","1999-5903","10.3390/fi14070209","","Domain name generation algorithms are widely used in malware, such as botnet binaries, to generate large sequences of domain names of which some are registered by cybercriminals. Accurate detection of malicious domains can effectively defend against cyber attacks. The detection of such malicious domain names by the use of traditional machine learning algorithms has been explored by many researchers, but still is not perfect. To further improve on this, we propose a novel parallel detection model named N-Trans that is based on the N-gram algorithm with the Transformer model. First, we add flag bits to the first and last positions of the domain name for the parallel combination of the N-gram algorithm and Transformer framework to detect a domain name. The model can effectively extract the letter combination features and capture the position features of letters in the domain name. It can capture features such as the first and last letters in the domain name and the position relationship between letters. In addition, it can accurately distinguish between legitimate and malicious domain names. In the experiment, the dataset is the legal domain name of Alexa and the malicious domain name collected by the 360 Security Lab. The experimental results show that the parallel detection model based on N-gram and Transformer achieves 96.97% accuracy for DGA malicious domain name detection. It can effectively and accurately identify malicious domain names and outperforms the mainstream malicious domain name detection algorithms.","2022-07","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","7","14","","","","","","","","","","English","","","","WOS:000831624000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","DGA; malicious domain name; N-gram; N-Trans; parallel detection model; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5ADCB9SU","journalArticle","2024","Qiu, J; Zhang, Y; Fu, CQ; Yang, YC; Ye, YJ; Wang, RB; Tang, B","Study on photofluorescent uranium ore sorting based on deep learning","MINERALS ENGINEERING","","0892-6875","10.1016/j.mineng.2023.108523","","Uranium ore stands as a vital source of energy, and the process of ore sorting serves to segregate valuable uranium ore from its less valuable counterparts. This not only enhances the intrinsic ore grade but also mitigates the challenges associated with subsequent refining processes, thus leading to substantial resource cost savings. Consequently, the necessity of pre-sorting uranium ore becomes evident. While prevailing X-ray-based ore sorting technology remains at the forefront, the quest for a more efficacious method to sort uranium ore remains ongoing. This study harnesses the inherent photofluorescence properties of uranium ore by subjecting it to ultraviolet light, inducing the emission of a vibrant green fluorescence. Consequently, we propose a novel sorting technique founded on photofluorescence, augmented by deep learning to enhance the precision and categorization of uranium ore images. Two distinct models, the Convolutional Neural Network (CNN) model and the Transformer model, are developed in tandem. Empirical findings underscore the superiority of the Swin Transformer model, with training accuracy, validation accuracy, and classification rate registering at 0.9780, 0.9719, and 96.4 ms/it, respectively, surpassing the performance of alternative models like Alex Net and Res Net 34. Furthermore, the study employs visual aids, including channel visualization diagrams, confusion matrices, and Grad-CAM diagrams, to elucidate the operational intricacies of the model in the sorting of photofluorescent uranium ore images. This allows for an insightful analysis of the characteristics that influence classification weights. The potential applications of this method are indeed substantial, opening new avenues for uranium ore exploration and utilization.","2024-01","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","206","","","","","","","","","","English","","","","WOS:001139962000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","COAL; Deep learning; Photofluorescence; Swin Transformer; Uranium ore sorting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NUSL5A89","journalArticle","2023","Ferdous, GJ; Sathi, KA; Hossain, MA; Hoque, MM; Dewan, MAA","LCDEiT: A Linear Complexity Data-Efficient Image Transformer for MRI Brain Tumor Classification","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3244228","","Current deep learning-assisted brain tumor classification models sustain inductive bias and parameter dependency problems for extracting texture-based image information. Thereby concerning these problems, the recent development of the vision transformer model has substituted the DL model for classification tasks. However, the high performance of the vision transformer model depends on a large-scale dataset as well as self-attention calculations between the number of image patches which result in a quadratic computational complexity. To address these problems, the vision transformer must be data-efficient to be well-trained with a limited amount of data, and the computational complexity must be linear with the number of image patches. Consequently, this paper presents a novel linear-complexity data-efficient image transformer called LCDEiT for training with small-size datasets by using a teacher-student strategy and linear computational complexity concerning the number of patches using an external attention mechanism. The teacher model comprised a custom gated-pooled convolutional neural network to provide knowledge to the transformer-based student model for the classification of MRI brain tumors. The average classification accuracy and F1-score for two benchmark datasets including Figshare and BraTS-21 are found 98.11% and 97.86% and 93.69% and 93.68% respectively. The results indicate that the proposed model could have a great impact on medical imaging-based diagnosis where data availability and faster computations are the main concern.","2023","2025-02-26 20:39:13","2025-02-26 20:39:13","","20337-20350","","","11","","","","","","","","","","English","","","","WOS:000946237700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","BASE; Brain modeling; Brain tumor; classification; Computational modeling; Data models; external attention; Feature extraction; Image classification; MRI; MULTI-CLASSIFICATION; transformer; Transformers; Tumors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B4T4AS8Q","journalArticle","2023","Fan, F; Ke, WC; Dai, XH; Shi, L; Liu, YY; Lin, YS; Cheng, ZQ; Zhang, Y; Chen, H; Deng, ZH","Semi-supervised automatic dental age and sex estimation using a hybrid transformer model","INTERNATIONAL JOURNAL OF LEGAL MEDICINE","","0937-9827","10.1007/s00414-023-02956-9","","Teeth-based age and sex estimation is an important task in mass disasters, criminal scenes, and archeology. Although various methods have been proposed, most of them are subjective and influenced by observers' experiences. In this study, we aimed to develop a deep learning model for automatic dental age and sex estimation from orthopantomograms (OPGs) and compare to manual methods. A large dataset of 15,195 OPGs (age range, 16 similar to 50 years; mean age, 29.65 years +/- 9.36 [SD]; 10,218 females) was used to train and test a hybrid deep learning model which is a combination of convolutional neural network and transformer model. The final performance of this model was evaluated on additional independent 100 OPGs and compared to the manual method for external validation. In the test of 1413 OPGs, the mean absolute error (MAE) of age estimation was 2.61 years by this model. The accuracy and the area under the receiver operating characteristic curve (AUC) of sex estimation were 95.54% and 0.984. The heatmap indicated that the crown and pulp chamber of premolars and molars contain the most age-related information. In the additional independent 100 OPGs, this model achieved an MAE of 3.28 years for males and 3.79 years for females. The accuracy of this model was much higher than that of the manual models. Therefore, this model has the potential to assist radiologists in automated age and sex estimation.","2023-05","2025-02-26 20:39:13","2025-02-26 20:39:13","","721-731","","3","137","","","","","","","","","","English","","","","WOS:000923647500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Age determination by teeth; Convolutional neural network; Deep learning; Orthopantomograms; Sex estimation; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W3PY33GY","journalArticle","2021","Zhu, JB; Shi, XJ; Zhang, SH","Machine Learning-Based Grammar Error Detection Method in English Composition","SCIENTIFIC PROGRAMMING","","1058-9244","10.1155/2021/4213791","","The detection of grammatical errors in English composition is an important task in the field of NLP. The main purpose of this task is to check out grammatical errors in English sentences and correct them. Grammatical error detection and correction are important applications in the automatic proofreading of English texts and in the field of English learning aids. With the increasing influence of English on a global scale, a huge breakthrough has been made in the task of detecting English grammatical errors. Based on machine learning, this paper designs a new method for detecting grammatical errors in English composition. First, this paper implements a grammatical error detection model based on Seq2Seq. Second, this paper implements a grammatical error detection and correction scheme based on the Transformer model. The Transformer model performs better than most grammar models. Third, this paper realizes the application of the BERT model in grammar error detection and error correction tasks, and the generalization ability of the model has been significantly enhanced. This solves the problem that the forward and backward cannot be merged when the Transformer trains the language model. Fourth, this paper proposes a method of grammatical error detection and correction in English composition based on a hybrid model. According to specific application scenarios, the corresponding neural network model is used for grammatical error correction. Combine the Seq2Seq structure to encode the input sequence and automate feature engineering. Through the combination of traditional model and deep model, the advantages are complemented to realize grammatical error detection and automatic correction.","2021-12-18","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","2021","","","","","","","","","","English","","","","WOS:000737289300003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","ELEMENTARY-SCHOOL STUDENTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LKSYMM9J","journalArticle","2024","Zhang, XT; Liu, YS; Gong, C; Nie, Y; Rodriguez, J","Electric Motor Bearing Fault Noise Detection via Mel-Spectrum-Based Contrastive Self-Supervised Transformer Model","IEEE TRANSACTIONS ON INDUSTRY APPLICATIONS","","0093-9994","10.1109/TIA.2024.3451414","","Bearings are vital components of motor drive systems and are widely used in various industrial applications. Bearing failures can lead to system collapse and pose a risk to human safety. Therefore, real-time monitoring and diagnosis of multi-fault bearings are crucial. This paper proposes a Mel-spectrum-based contrastive self-supervised Transformer (Mel-CSST) model to efficiently detect multiple bearing faults in electric motors through vibration noise signals. Among them, the contrastive self-supervised Transformer model (CSST) can be pre-trained without the need for labeled data, significantly improving the fault detection accuracy of the target bearing after transfer learning using the parameter-frozen domain-adversarial (PFDA) method. Mel-spectrums are converted from a mass of sub-signals generated by the random-masked sliding window (RMSW) method, providing training data sample pairs for the CSST model. Mel-spectrums can analyze significant vibration noise signals at lower frequencies in more detail, revealing the fault features missed by the standard fast Fourier transform. Furthermore, the encoder part of Mel-CSST uses a modified Transformer network to ensure the feature extraction effectiveness of CSST. The proposed method can be easily transferred to be used on target bearings without expensive labelling data in practical applications. Experiments using two real bearing datasets measured from two test rigs, along with comparison experiments with other existing methods, validate the effectiveness of the proposed method.","2024-11","2025-02-26 20:39:13","2025-02-26 20:39:13","","8755-8765","","6","60","","","","","","","","","","English","","","","WOS:001355796100041","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","ADAPTATION; Bearing; Data models; DIAGNOSIS; electric motor; fault detection; Feature extraction; Mathematical models; Motor drives; neural network; Noise; Transformers; vibration noise; Vibrations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XGNQCMNG","journalArticle","2023","Du, JS; Jiang, JZ; Zheng, J; Zhang, HB; Huang, D; Lu, YT","Improving Computation and Memory Efficiency for Real-world Transformer Inference on GPUs","ACM TRANSACTIONS ON ARCHITECTURE AND CODE OPTIMIZATION","","1544-3566","10.1145/3617689","","Transformer models have emerged as a leading approach in the field of natural language processing (NLP) and are increasingly being deployed in production environments. Graphic processing units (GPUs) have become a popular choice for the transformer deployment and often rely on the batch processing technique to ensure high hardware performance. Nonetheless, the current practice for transformer inference encounters computational and memory redundancy due to the heavy-tailed distribution of sequence lengths in NLP scenarios, resulting in low practical performance. In this article, we propose a unified solution for improving both computation and memory efficiency of the real-world transformer inference on GPUs. The solution eliminates the redundant computation and memory footprint across a transformer model. At first, a GPU-oriented computation approach is proposed to process the self-attention module in a fine-grained manner, eliminating its redundant computation. Next, the multi-layer perceptron module continues to use the word-accumulation approach to eliminate its redundant computation. Then, to better unify the fine-grained approach and the word-accumulation approach, it organizes the data layout of the self-attention module in block granularity. Since aforementioned approaches make the required memory size largely reduce and constantly fluctuate, we propose the chunk-based approach to enable a better balance between memory footprint and allocation/free efficiency. Our experimental results show that our unified solution achieves a decrease of average latency by 28% on the entire transformer model, 63.8% on the self-attention module, and reduces memory footprint of intermediate results by 7.8x, compared with prevailing frameworks.","2023-12","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","4","20","","","","","","","","","","English","","","","WOS:001153375300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","graphics processing unit; natural language processing; Parallel computing; transformer inference","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YKGM583E","journalArticle","2023","Ai, Z; Zhang, YJ; Lu, MY","A Domain Knowledge Transformer Model for Occupation Profiling","INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS","","1875-6891","10.1007/s44196-023-00386-4","","Occupation profiling is a subtask of authorship profiling that is broadly defined as an analysis of individuals' writing styles. Although the problem has been widely explored, no previous studies have attempted to identify Chinese classical poetry. Inspired by Trudgill's seminal work on stylistic variation as a function of occupation, we present a novel Domain-Knowledge Transformer model to predict a poet's occupation through their poems' writing styles. Different from other Indo-European languages, Chinese has rarely used characters and two types of writing forms: traditional Chinese and simplified Chinese. To tackle these problems, we use the language-related component to standardize our input. We also use alphabetization to satisfy the restrictions on rhyming rules and tonal styles. As a special literal form, traditional domain knowledge, for example, named entities, themes, ages and the official career path, is valuable for poet occupation profiling. However, due to the lack of appropriate annotation datasets, it is difficult to recognize these features. Therefore, we proposed the domain knowledge component employing the latent Dirichletal location model to capture the extra theme information and establish named entity dictionaries to recognize the named entity of the datasets in this study. Finally, in the deep learning component, we combine Transformer with a convolutional neural network (CNN) model to perform occupation profiling. The experimental results suggest that our model is effective in this task. Moreover, the results demonstrate an account of other social attribution features of poetry style that are predictive of occupation in this domain.","2023-12-21","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","1","16","","","","","","","","","","English","","","","WOS:001127205300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","AUTHOR; Authorship profiling; Chinese classical poem; LDA; Occupation profiling; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LATSZBCJ","journalArticle","2022","Niu, C; Wang, G","Unsupervised contrastive learning based transformer for lung nodule detection","PHYSICS IN MEDICINE AND BIOLOGY","","0031-9155","10.1088/1361-6560/ac92ba","","Objective. Early detection of lung nodules with computed tomography (CT) is critical for the longer survival of lung cancer patients and better quality of life. Computer-aided detection/diagnosis (CAD) is proven valuable as a second or concurrent reader in this context. However, accurate detection of lung nodules remains a challenge for such CAD systems and even radiologists due to not only the variability in size, location, and appearance of lung nodules but also the complexity of lung structures. This leads to a high false-positive rate with CAD, compromising its clinical efficacy. Approach. Motivated by recent computer vision techniques, here we present a self-supervised region-based 3D transformer model to identify lung nodules among a set of candidate regions. Specifically, a 3D vision transformer is developed that divides a CT volume into a sequence of non-overlap cubes, extracts embedding features from each cube with an embedding layer, and analyzes all embedding features with a self-attention mechanism for the prediction. To effectively train the transformer model on a relatively small dataset, the region-based contrastive learning method is used to boost the performance by pre-training the 3D transformer with public CT images. Results. Our experiments show that the proposed method can significantly improve the performance of lung nodule screening in comparison with the commonly used 3D convolutional neural networks. Significance. This study demonstrates a promising direction to improve the performance of current CAD systems for lung nodule detection.","2022-10-21","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","20","67","","","","","","","","","","English","","","","WOS:000864899800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;21<br/>Total Times Cited:&nbsp;&nbsp;22<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","CAD; CLASSIFICATION; CNNS; CT SCANS; deep learning; GUIDELINES; lung nodule detection; MANAGEMENT; PULMONARY NODULES; transformer; unsupervised pretraining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4JM2LD7X","journalArticle","2024","He, ZP; Zhu, QL; Xia, KW; Ghamisi, P; Zu, BK","Semi-supervised hierarchical Transformer for hyperspectral Image classification","INTERNATIONAL JOURNAL OF REMOTE SENSING","","0143-1161","10.1080/01431161.2023.2290996","","Transformer has achieved outstanding performance in many fields such as computer vision benefiting from its powerful and efficient modelling ability and long-range feature extraction capability complementary to convolution. However, on the one hand, the lack of CNN's innate inductive biases, such as translation invariance and local sensitivity, makes Transformer require more data for learning. On the other hand, labelled hyperspectral samples are scarce due to the time-consuming and costly annotation task. To this end, we propose a semi-supervised hierarchical Transformer model for HSI classification to improve the classification performance of the Transformer with limited labelled samples. In order to perturb the samples more fully and extensively to improve the model performance, two different data augmentation methods are used to perturb the unlabelled samples, and two sets of augmented samples are obtained respectively. The pseudo-label obtained on the original unlabelled sample is used to simultaneously supervise the augmented sample obtained on this unlabelled sample. Among them, only the pseudo-labels above the threshold are retained. To further improve the model stability and classification accuracy, hierarchical patch embedding is proposed to eliminate the mutual interference between pixels. Extensive experiments on three well-known hyperspectral datasets validate the effectiveness of the proposed semi-supervised Transformer model. The experiments show that the model achieves excellent classification accuracy even when there are only 10 labelled samples in each category, which can effectively improve the classification performance of Transformer under small-scale labelled samples.","2024-01-02","2025-02-26 20:39:13","2025-02-26 20:39:13","","21-50","","1","45","","","","","","","","","","English","","","","WOS:001133415100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","GRAPH CONVOLUTIONAL NETWORKS; Hierarchical patch embedding; hyperspectral image classification; semi-supervised learning; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WUGQ8T6F","journalArticle","2024","Yang, H","Optimized English Translation System Using Multi-Level Semantic Extraction and Text Matching","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3426652","","The domain of machine text translation and matching is undergoing substantial transformations amidst the perpetual evolution of deep learning methodologies. By amalgamating the contemporary realm of generative models and networks with the multi-faceted attentiveness of multiple heads, there has been a pronounced enhancement in the efficacy of existing text translation and matching endeavors. Consequently, this manuscript endeavors to elucidate the intricacies of the text-matching conundrum within the ambit of English translation. It posits a novel MA-Transformer text-matching framework that seamlessly integrates multi-tiered semantic feature extraction methodologies to actualize the text-matching task in the English translation process. The framework initiates its journey by employing Continuous Bag of Words (CBOW) for word vector embedding, thereby accomplishing the generation and embedding of word vectors. Subsequently, it expeditiously conducts the multilevel amalgamation of data features through the expeditious execution of the multi-head Transformer model. Following the culmination of feature fusion, a judicious sequence of data downgrading and feature screening ensues, ultimately culminating in the attainment of high-precision text matching. The experimental results show that the constructed MA Transformer model performs well in public and actual data testing, with an average precision of 0.867 and 0.722, respectively, on the two types of datasets. The accuracy of the text-matching is higher than that of the current common method frameworks, which provide technical support and references for the future construction of English translation systems.","2024","2025-02-26 20:39:13","2025-02-26 20:39:13","","96527-96536","","","12","","","","","","","","","","English","","","","WOS:001273024300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Context modeling; Data models; Encoding; English translation; Feature extraction; machine translation; Multi-level semantic feature extraction; Neural networks; Semantics; text matching; Text processing; Vectors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WP6NY8ZR","journalArticle","2023","Saleem, N; Gunawan, TS; Kartiwi, M; Nugroho, BS; Wijayanto, I","NSE-CATNet: Deep Neural Speech Enhancement Using Convolutional Attention Transformer Network","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3290908","","Speech enhancement (SE) is a critical aspect of various speech-processing applications. Recent research in this field focuses on identifying effective ways to capture the long-term contextual dependencies of speech signals to enhance performance. Deep convolutional networks (DCN) using self-attention and the Transformer model have demonstrated competitive results in SE. Transformer models with convolution layers can capture short and long-term temporal sequences by leveraging multi-head self-attention, which allows the model to attend the entire sequence. This study proposes a neural speech enhancement (NSE) using the convolutional encoder-decoder (CED) and convolutional attention Transformer (CAT), named the NSE-CATNet. To effectively process the time-frequency (T-F) distribution of spectral components in speech signals, a T-F attention module is incorporated into the convolutional Transformer model. This module enables the model to explicitly leverage position information and generate a two-dimensional attention map for the time-frequency speech distribution. The performance of the proposed SE is evaluated using objective speech quality and intelligibility metrics on two different datasets, the VoiceBank-DEMAND Corpus and the LibriSpeech dataset. The experimental results indicate that the proposed SE outperformed the competitive baselines in terms of speech enhancement performance at -5dB, 0dB, and 5dB. This suggests that the model is effective at improving the overall quality by 0.704 with VoiceBank-DEMAND and by 0.692 with LibriSpeech. Further, the intelligibility with VoiceBank-DEMAND and LibriSpeech is improved by 11.325% and 11.75% over the noisy speech signals.","2023","2025-02-26 20:39:13","2025-02-26 20:39:13","","66979-66994","","","11","","","","","","","","","","English","","","","WOS:001028877600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","convolutional attention transformer; convolutional encoder-decoder; FUSION; MASKING; Neural speech enhancement; NOISE; RECURRENT NETWORKS; T-F attention; T-F masking","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WK7WCP8R","journalArticle","2023","Li, XH; Zhang, X; Zhang, LW; Chen, X; Zhou, P","A Transformer-Based Multi-Task Learning Framework for Myoelectric Pattern Recognition Supporting Muscle Force Estimation","IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING","","1534-4320","10.1109/TNSRE.2023.3298797","","Simultaneous implementation of myoelectric pattern recognition and muscle force estimation is highly demanded in building natural gestural interfaces but a challenging task due to the gesture classification accuracy degradation under varying muscle strengths. To address this problem, a novel method using transformer-based multi-task learning (MTL-Transformer) for the prediction of both myoelectric patterns and corresponding muscle strengths was proposed to describe the inherent characteristics of an individual gesture pattern under different force conditions, thereby improving the accuracy of myoelectric pattern recognition. In addition, the transformer model enabled the characterization of long-term temporal correlations to ensure precise and smooth estimation of the muscle force. The performance of the proposed MTL-Transformer framework was evaluated via experiments of classifying eleven hand gestures and estimating the corresponding muscle force simultaneously, using high-density surface electromyogram (HD-sEMG) recordings from forearm flexor muscles of eleven intact-limbed subjects. The MTL-Transformer framework yielded high classification accuracy (98.70 +/- 1.21%) and low root mean square deviation (12.59 +/- 2.76%), and outperformed other two common temporally modelling methods significantly (p< 0.05) in terms of both improved gesture recognition accuracies and reduced muscle force estimation errors. The MTL-Transformer framework is demonstrated as an effective solution for simultaneous implementation of myoelectric pattern recognition and muscle force estimation. This study promotes the development of robust and smooth myoelectric control systems, with wide applications in gestural interfaces, prosthetic and orthotic control.","2023","2025-02-26 20:39:13","2025-02-26 20:39:13","","3255-3264","","","31","","","","","","","","","","English","","","","WOS:001051704500002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","CLASSIFICATION SCHEME; HAND; multi-task learning; muscle force estimation; Myoelectric pattern recognition; SURFACE; transformer model; varying muscle strengths","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DK2XTBPU","journalArticle","2021","Hu, X; Li, T; Zhou, T; Liu, Y; Peng, YX","Contrastive Learning Based on Transformer for Hyperspectral Image Classification","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app11188670","","Recently, deep learning has achieved breakthroughs in hyperspectral image (HSI) classification. Deep-learning-based classifiers require a large number of labeled samples for training to provide excellent performance. However, the availability of labeled data is limited due to the significant human resources and time costs of labeling hyperspectral data. Unsupervised learning for hyperspectral image classification has thus received increasing attention. In this paper, we propose a novel unsupervised framework based on a contrastive learning method and a transformer model for hyperspectral image classification. The experimental results prove that our model can efficiently extract hyperspectral image features in unsupervised situations.","2021-09","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","18","11","","","","","","","","","","English","","","","WOS:000699188200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;39<br/>Total Times Cited:&nbsp;&nbsp;40<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","contrastive learning; deep learning; transformer; unsupervised hyperspectral image classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BHQWIBYN","journalArticle","2021","Al-Nafjan, A; Alghamdi, N; Almudhi, A","Virtual Reality Technology and Speech Analysis for People Who Stutter","EMITTER-INTERNATIONAL JOURNAL OF ENGINEERING TECHNOLOGY","","2355-391X","10.24003/emitter.v9i2.649","","Virtual reality (VR) technology provides an interactive computer-generated experience that artificially simulates real-life situations by creating a virtual environment that looks real and stimulates the user's feelings. During the past few years, the use of VR technology in clinical interventions for assessment, rehabilitation and treatment have received increased attention. Accordingly, many clinical studies and applications have been proposed in the field of mental health, including anxiety disorders. Stuttering is a speech disorder in which affected individuals have a problem with the flow of speech. This can manifest in the repetition and prolongation of words or phrases, as well as in involuntary silent pauses or blocks during which the individual is unable to produce sounds. Stuttering is often accompanied by a social anxiety disorder as a secondary symptom, which requires separate treatment. In this study, we evaluated the effectiveness of using a VR environment as a medium for presenting speech training tasks. In addition, we evaluated the accuracy of a speech analyzer module in detecting stuttering events.","2021-12","2025-02-26 20:39:13","2025-02-26 20:39:13","","326-338","","2","9","","","","","","","","","","English","","","","WOS:000744154800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","ENVIRONMENTS; rehabilitation; speech analysis; stutter; virtual reality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CYV7N3JT","journalArticle","2021","Sisman, B; Yamagishi, J; King, S; Li, HZ","An Overview of Voice Conversion and Its Challenges: From Statistical Modeling to Deep Learning","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2020.3038524","","Speaker identity is one of the important characteristics of human speech. In voice conversion, we change the speaker identity from one to another, while keeping the linguistic content unchanged. Voice conversion involves multiple speech processing techniques, such as speech analysis, spectral conversion, prosody conversion, speaker characterization, and vocoding. With the recent advances in theory and practice, we are now able to produce human-like voice quality with high speaker similarity. In this article, we provide a comprehensive overview of the state-of-the-art of voice conversion techniques and their performance evaluation methods from the statistical approaches to deep learning, and discuss their promise and limitations. We will also report the recent Voice Conversion Challenges (VCC), the performance of the current state of technology, and provide a summary of the available resources for voice conversion research.","2021","2025-02-26 20:39:13","2025-02-26 20:39:13","","132-157","","","29","","","","","","","","","","English","","","","WOS:000597160600011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;160<br/>Total Times Cited:&nbsp;&nbsp;175<br/>Cited Reference Count:&nbsp;&nbsp;301</p>","","","ABSOLUTE ERROR MAE; Deep learning; GAUSSIAN MIXTURE MODEL; GENERATIVE ADVERSARIAL NETWORKS; MAXIMUM-LIKELIHOOD-ESTIMATION; NEURAL-NETWORKS; Pipelines; PROCESSING TECHNIQUES; SPARSE REPRESENTATION; speaker characterization; SPEAKER VERIFICATION; speech analysis; Speech analysis; Speech synthesis; TEXT-TO-SPEECH; Training; Training data; Vocoders; vocoding; Voice conversion; voice conversion challenges; voice conversion evaluation; WAVENET VOCODER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7ZPIDXTU","journalArticle","2024","O'Shaughnessy, D","Review of Methods for Automatic Speaker Verification","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2023.3346293","","A review of techniques to identify speakers from their voices is presented, noting strengths and weaknesses of various methods. Similar acoustic analysis has been often used for both speech and speaker recognition, despite the two tasks being quite different. Speaker biometrics from voice is far more indirect and subtle than the estimation of phoneme sequences for automatic speech recognition from periodic evaluations of the spectral envelope of the vocal tract output. Speech signals are discussed from the point of view of how to recognize their textual content versus estimating other aspects of speakers. Common speech analysis methods such as filter banks, linear prediction, and mel-frequency cepstrum are examined. Approaches such as hidden Markov models, i-vectors, and artificial neural networks are shown to be useful for multiple speech applications. Focus is on how various types of networks can accomplish automatic speaker verification (ASV). Suggestions to improve these methods are made.","2024","2025-02-26 20:39:13","2025-02-26 20:39:13","","1776-1789","","","32","","","","","","","","","","English","","","","WOS:001188287400004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;105</p>","","","Acoustic measurements; Acoustics; Artificial neural networks; automatic speaker verification; Behavioral sciences; Frequency measurement; IDENTIFICATION; intonation; KERNEL; LINEAR PREDICTION; pattern recognition; SCORE NORMALIZATION; SOFTMAX; spectral analysis; SPEECH; speech analysis; Speech recognition; STATISTICAL PATTERN-RECOGNITION; Task analysis; Training; TUTORIAL; VARIABILITY; WORD RECOGNITION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7KXR8PEC","journalArticle","2021","Williams, K; Myers, JS; Hu, JX; Manson, A; Maliski, SL","Psycholinguistic Screening for Cognitive Decline in Cancer Survivors: A Feasibility Study","ONCOLOGY NURSING FORUM","","0190-535X","10.1188/21.ONF.474-480","","OBJECTIVES: To test the feasibility of using psycholinguistic speech analysis as a proxy for cognitive function in men undergoing treatment for prostate cancer. SAMPLE & SETTING: Audio-recorded speech samples were collected from 13 men enrolled in a parent study at the University of Kansas Cancer Center in Kansas City. METHODS & VARIABLES: Audio-recorded speech samples, collected from clinical interviews and in response to a prompt question during the parent study at two time points, were evaluated to determine feasibility relationships between neurocognitive and psycholinguistic measures. RESULTS: Correlations between neurocognitive and psycholinguistic measures were identified for prompted speech, but the strength of relationships varied between time points. No relationships were identified in clinical interview speech samples. IMPLICATIONS FOR NURSING: Feasibility was demonstrated for recording, transcribing, and analyzing speech from clinical interviews, and results suggest relationships between neurocognitive and psycholinguistic measures in prompted speech. If validated, psycholinguistic assessments may be used to assess cognitive function in cancer survivors. Advances in natural language processing may provide opportunities for automated speech analyses for cancer treatment-related cognitive decline.","2021-09","2025-02-26 20:39:13","2025-02-26 20:39:13","","474-480","","5","48","","","","","","","","","","English","","","","WOS:000686560100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","cancer treatment; cognition; cognitive decline; LANGUAGE; psycholinguistic screening; speech analysis; THERAPY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QHC4GINY","journalArticle","2024","Sravani, K; RaviSankar, V","Intelligent Differentiation Framework for Lewy Body Dementia and Alzheimer's disease using Adaptive Multi-Cascaded ResNet-Autoencoder-LSTM Network","INTERNATIONAL JOURNAL OF IMAGE AND GRAPHICS","","0219-4678","10.1142/S0219467825500664","","In recent years, most of the patients with dementia have acquired healthcare systems within the primary care system and they also have some challenging psychiatric and medical issues. Here, dementia-based symptoms are not identified in the primary care center, because they are affected by various factors like psychological symptoms, clinically relevant behavior, numerous psychotropic medications, and multiple chronic medical conditions. To enhance the healthcare-related applications, the primary healthcare system with additional resources like coordination with interdisciplinary dementia specialists, feasible diagnosis, and screening process need to be improved. Therefore, the differentiation between Alzheimer's Disease (AD) and Lewy Body Dementia (LBD) has been acquired to provide the best clinical support to the patients. In this research work, the deep structure depending on AD and LBD systems has been implemented with the help of an adaptive algorithm to provide promising outcomes over dementia detection. Initially, the input images are collected from online sources. Thus, the collected images are forwarded to the newly designed Multi-Cascaded Deep Learning (MSDL), where the ResNet, Autoencoder, and weighted Long-Short Term Memory (LSTM) networks are serially cascaded to provide effective classification results. Then, the fully connected layer of ResNet is given to the Autoencoder structure. Here, the output from the encoder phase is optimized by using the Adaptive Water Wave Cuttlefish Optimization (AWWCO), which is derived from the Water Wave Optimization (WWO) and Cuttlefish Algorithm (CA), and the resultant selected output is fed to the weight-optimized LSTM network. Further, the parameters in the MSDL network are optimized by using the same AWWCO algorithm. Finally, the performance comparison over different heuristic algorithms and conventional dementia detection approaches is done for the validation of the overall effectiveness of the suggested model in terms of various estimation measures.","2024-04-09","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","","","","","","","","","","","English","","","","WOS:001198655800004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","adaptive water wave cuttlefish optimization; Alzheimer's disease; autoencoder; CA1; Disease differentiation framework; HIPPOCAMPAL; Lewy body dementia; multi-cascaded deep learning; NEURAL-NETWORKS; ResNet; VOLUME; weighted long-short term memory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZLU8FKN7","journalArticle","2024","Nikolaev, AS","Recognition of the Psychoneurological State of Children with Autism Spectrum Disorders Based on Speech Signals: Acoustic and Perceptual Characteristics","ACOUSTICAL PHYSICS","","1063-7710","10.1134/S1063771024602085","","Recognition by adults of the psychoneurological state of children with autism spectrum disorders (ASD), n = 35, and typically developing (TD) children, n = 47, aged 5-14 years, was studied. A perceptual analysis was carried out, in which adult native Russian speakers (auditors) took part, n = 206. For perceptual analysis, test sequences (audio tests) were created containing words and phrases of children with ASD and TD children, selected from spontaneous speech recordings. The auditors were faced with the problem of determining the psychoneurological state of a child based on auditory perception: typical-atypical development. A spectrographic analysis of the speech material of children with ASD and TD children was carried out. The phrases of children with ASD are characterized by a lower speech rate compared to the phrases of TD children, as well as fewer words, longer duration of stressed and unstressed vowels in words, higher values of the frequency of the fundamental tone in the phrase, word, and stressed and unstressed vowels.","2024-06","2025-02-26 20:39:13","2025-02-26 20:39:13","","586-591","","3","70","","","","","","","","","","English","","","","WOS:001315805600002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","acoustic analysis; autism spectrum disorder; child speech; CLASSIFICATION; LANGUAGE; PATTERNS; perceptual analysis; PROSODY; speech recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NM3B82FF","journalArticle","2024","Diachek, E; Brown-Schmidt, S","Linguistic features of spontaneous speech predict conversational recall","PSYCHONOMIC BULLETIN & REVIEW","","1069-9384","10.3758/s13423-023-02440-w","","Empirical studies of conversational recall show that the amount of conversation that can be recalled after a delay is limited and biased in favor of one's own contributions. What aspects of a conversational interaction shape what will and will not be recalled? This study aims to predict the contents of conversation that will be recalled based on linguistic features of what was said. Across 59 conversational dyads, we observed that two linguistic features that are hallmarks of interactive language use-disfluency (um/uh) and backchannelling (ok, yeah)-promoted recall. Two other features-disagreements between the interlocutors and use of ""like""-were not predictive of recall. While self-generated material was better remembered overall, both hearing and producing disfluency and backchannels improved memory for the associated utterances. Finally, the disfluency-related memory boost was similar regardless of the number of disfluencies in the utterance. Overall, we conclude that interactional linguistic features of conversation are predictive of what is and is not recalled following conversation.","2024-08","2025-02-26 20:39:13","2025-02-26 20:39:13","","1638-1649","","4","31","","","","","","","","","","English","","","","WOS:001141861300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;80</p>","","","AGE; Backchanneling; Conversation; DISCOURSE; Disfluency; Free recall; HESITATIONS; MEMORY EXPECTANCIES; MODE; PAUSES; R PACKAGE; REMEMBRANCES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4QBWBZ8A","journalArticle","2023","Moisio, A; Porjazovski, D; Rouhe, A; Getman, Y; Virkkunen, A; AlGhezi, R; Lennes, M; Grósz, T; Lindén, K; Kurimo, M","Lahjoita puhetta: a large-scale corpus of spoken Finnish with some benchmarks","LANGUAGE RESOURCES AND EVALUATION","","1574-020X","10.1007/s10579-022-09606-3","","The Donate Speech campaign has so far succeeded in gathering approximately 3600 h of ordinary, colloquial Finnish speech into the Lahjoita puhetta (Donate Speech) corpus. The corpus includes over twenty thousand speakers from all the regions of Finland and from all age brackets. The primary goals of the collection were to create a representative, large-scale resource to study spontaneous spoken Finnish and to accelerate the development of language technology and speech-based services. In this paper, we present the collection process and the collected corpus, and showcase its versatility through multiple use cases. The evaluated use cases include: automatic speech recognition of spontaneous speech, detection of age, gender, dialect and topic and metadata analysis. We provide benchmarks for the use cases, as well downloadable, trained baseline systems with open-source code for reproducibility. One further use case is to verify the metadata and transcripts given in this corpus itself, and to suggest artificial metadata and transcripts for the part of the corpus where it is missing.","2023-09","2025-02-26 20:39:13","2025-02-26 20:39:13","","1295-1327","","3","57","","","","","","","","","","English","","","","WOS:000839256500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","age; Automatic speech recognition; dialect and topic recognition; Gender; Speech collection; SPEECH RECOGNITION; Spoken colloquial language","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6EP55S4U","journalArticle","2025","Sirpa, P; Paula, S; Terhi, A; Niemitalo-Haapola, E; Anneli, Y; Leena, R","A Randomized Controlled Trial With Female Teachers: Are there Differences Between and Within the Outcomes in Voice Therapy Groups With and Without Carryover Strategies?","JOURNAL OF VOICE","","0892-1997","10.1016/j.jvoice.2022.06.029","","Purpose. We investigated if outcomes differ between voice therapy groups systematically using carryover strategies (attempts to generalize new vocal skills outside the clinic) and voice therapy with no emphasis on any generalizing process (here referred to as traditional voice therapy). Method. A randomized controlled trial was conducted. Participants (53 female teachers with voice disorders) were randomly allocated into three groups: Carryover (a group receiving voice therapy using carryover strategies), Trad (a group receiving voice therapy with no emphasis on any generalizing process), Controls (a group on an eight-week non-therapy period). Prior to the trial a direct laryngoscopy was performed with a videolaryngostroboscopy system and/or nasofaryngofiberoscope with stroboscopy. Before and after therapy and at follow-up a voice evaluation protocol was implemented consisting of subjective assessments (Questionnaire on Voice Symptoms, and the Voice Activity and Participation Profile; VAPP), and objective measurements (voice sample recordings, acoustic analysis [SPL, sound pressure level; f0, fundamental frequency; alpha-ratio, tilt of the sound spectrum slope]). Results. No differences were found between the groups. Several significant changes occurred within the groups between initial phase vs. post-therapy and initial phase vs. follow-up. In the Carryover group text reading the alpha-ratio became lower (P = 0.011) and spontaneous speech f0 increased (P = 0.024) after the therapy and [a:] SPL increased (P = 0.042) at follow-up. In the Trad group post-therapy [a:] alpha-ratio became lower (P = 0.012) and spontaneous speech f0 decreased (P = 0.034). After therapy VAPP scores showed improvement in voice- related quality of life in both therapy groups (Carryover P = 0.003; Trad P = 0.01) but only in Carryover at follow-up (P = 0.000). Voice symptoms decreased in the Carryover group post-therapy (P = 0.001) and at follow-up (P = 0.000) and after Controls' eight-week non-therapy period (P = 0.003). Conclusion. The results showed that carryover strategies give no additional advantages in voice therapy. However, the decreasing trend in the Carryover group's voice complaints at follow-up would suggest that carryover strategies may have long-lasting effects. The results also confirm that voice therapy is efficient in improving voice-related quality of life","2025-01","2025-02-26 20:39:13","2025-02-26 20:39:13","","158-171","","1","39","","","","","","","","","","English","","","","WOS:001414349400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","Carryover; DISORDERS; DYSPHONIA; EFFICACY; Follow-up studyI; NOISE; PARAMETERS; QUALITY-OF-LIFE; SPEECH; Subjective assessment; Teacher voice symptoms; Voice quality; Voice therapy outcome; WORK","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PZGQ2BSK","journalArticle","2023","Szagun, G; Stumper, B","The role of infinitival clauses in the dialogues of German-speaking children and adults","JOURNAL OF CHILD LANGUAGE","","0305-0009","10.1017/S0305000922000496","","The present study aims at analysing the role of infinitival clauses (INFCs) in German child-adult dialogue. In German subject-less INFCs are a grammatical sentence pattern. Extensive corpora of spontaneous speech between 6 children aged 1;5 to 2;10 and adults were analysed applying structural and contextual analyses. We extended Freudenthal, Pine and Gobet's (2010) model of lexically specific learning to include INFCs in adult input. Results show that frequencies of adult INFC and MOD+INF clauses are related to child INFCs. We interpret these results as reflecting shared verb vocabulary and, regarding INFCs, as an adaptation of adult CDS to child grammatical structure. While most child INFCs have modal meaning, some occur in non-modal contexts. The majority of child INFCs are subject-less clauses with final infinitives and therefore grammatical. Results are discussed in terms of the pragmatic function of child and adult INFCs and the role of adult INFCs in German CDS.","2023-11","2025-02-26 20:39:13","2025-02-26 20:39:13","","1411-1435","","6","50","","","","","","","","","","English","","","","WOS:000870522100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","ACQUISITION; child-adult dialogue; contextual analysis; DUTCH; ENGLISH; ERRORS; German; Infinitival clauses; LANGUAGE; MARKING; ROOT INFINITIVES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MTNAA7J2","journalArticle","2023","Zhang, H; Parola, A; Zhou, Y; Wang, HL; Bliksted, V; Fusaroli, R; Hinzen, W","Linguistic markers of psychosis in Mandarin Chinese: Relations to theory of mind","PSYCHIATRY RESEARCH","","0165-1781","10.1016/j.psychres.2023.115253","","Disorganized and impoverished language is a key feature of schizophrenia (Sz), but whether and which linguistic changes previously observed in Indo-European languages generalize to other languages remains unclear. Targeting Mandarin Chinese, we aimed to profile aspects of grammatical complexity that we hypothesized would be reduced in schizophrenia in a task of verbalizing social events. 51 individuals with Sz and 39 controls participated in the animated triangles task, a standardized measure of theory of mind (ToM), in which participants describe triangles moving in either a random or an 'intentional' condition. Results revealed that clauses embedded as arguments in other clauses were reduced in Sz, and that both groups produced such clauses and grammatical aspect more frequently in the intentional condition. ToM scores specifically correlated with production of embedded argument clauses. These results document grammatical impoverishment in Sz in Chinese across several structural domains, which in some of its specific aspects relate to mentalizing performance.","2023-07","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","325","","","","","","","","","","English","","","","WOS:001012586800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","ABILITIES; CLINICAL HIGH-RISK; INTENTIONAL MOVEMENT; LANGUAGE; Language complexity; Mandarin Chinese; Schizophrenia; SCHIZOPHRENIA; SPEECH; Spontaneous speech; Theory of mind; THOUGHT-DISORDER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QI6WQ8FM","journalArticle","2021","Johns, MA; Rodrigo, L; Tamargo, REG; Winneg, A; Dussias, PE","Priming and persistence in bilinguals: What codeswitching tells us about lexical priming in sentential contexts*","BILINGUALISM-LANGUAGE AND COGNITION","","1366-7289","10.1017/S1366728921000080","","Most studies on lexical priming have examined single words presented in isolation, despite language users rarely encountering words in such cases. The present study builds upon this by examining both within-language identity priming and across-language translation priming in sentential contexts. Highly proficient Spanish-English bilinguals read sentence-question pairs, where the sentence contained the prime and the question contained the target. At earlier stages of processing, we find evidence only of within-language identity priming; at later stages of processing, however, across-language translation priming surfaces, and becomes as strong as within-language identity priming. Increasing the time between the prime sentence and target question results in strengthened priming at the latest stages of processing. These results replicate previous findings at the single-word level but do so within sentential contexts, which has implications both for accounts of priming via automatic spreading activation as well as for accounts of persistence attested in spontaneous speech corpora.","2021-08","2025-02-26 20:39:13","2025-02-26 20:39:13","","681-693","","4","24","","","","","","","","","","English","","","","WOS:000669500800008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","2 LANGUAGES; ACCESS; codeswitching; EYE-MOVEMENTS; eye-tracking; FREQUENCY; identity priming; L2; MODEL; PREDICTABILITY; reading; TIME-COURSE; TRANSLATION; translation priming; VISUAL WORD RECOGNITION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U7JBTHPW","journalArticle","2023","Dhanjal, AS; Singh, W","A comprehensive survey on automatic speech recognition using neural networks","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-023-16438-y","","The continuous development in Automatic Speech Recognition has grown and demonstrated its enormous potential in Human Interaction Communication systems. It is quite a challenging task to achieve high accuracy due to several parameters such as different dialects, spontaneous speech, speaker's enrolment, computation power, dataset, and noisy environment that decrease the performance of the speech recognition system. It has motivated various researchers to make innovative contributions to the development of a robust speech recognition system. The study presents a systematic analysis of current state-of-the-art research work done in this field during 2015-2021. The prime focus of the study is to highlight the neural network-based speech recognition techniques, datasets, toolkits, and evaluation metrics utilized in the past seven years. It also synthesizes the evidence from past studies to provide empirical solutions for accuracy improvement. This study highlights the current status of speech recognition systems using neural networks and provides a brief knowledge to the new researchers.","2023-08-15","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","","","","","","","","","","","English","","","","WOS:001048111200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;119</p>","","","ARABIC SPEECH; ARCHITECTURES; Dataset; Deep learning; HMM; Neural network; NOISE; PRIMER; SEGMENTATION; Speech recognition; SYSTEM; Tools","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3JYBY9NV","journalArticle","2024","Strand, BMS","Playing With Fire Compounds: The Tonal Accents of Compounds in (North) Norwegian Preschoolers' Role-Play Register","LANGUAGE AND SPEECH","","0023-8309","10.1177/00238309231161289","","Prosodic features are some of the most salient features of dialect variation in Norway. It is therefore no wonder that the switch in prosodic systems is what is first recognized by caretakers and scholars when Norwegian children code-switch to something resembling the dialect of the capital (henceforth Urban East Norwegian, UEN) in role-play. With a focus on the system of lexical tonal accents, this paper investigates the spontaneous speech of North Norwegian children engaging in peer social role-play. By investigating F0 contours extracted from a corpus of spontaneous peer play, and comparing them with elicited baseline reference contours, this paper makes the case that children fail to apply the target tonal accent consistent with UEN in compounds in role-play, although the production of tonal accents otherwise seems to be phonetically target like UEN. Put in other words, they perform in accordance with UEN phonetics, but not UEN morpho-phonology.","2024-03","2025-02-26 20:39:13","2025-02-26 20:39:13","","113-139","","1","67","","","","","","","","","","English","","","","WOS:000983381200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;112</p>","","","child language; FEATURES; FUNCTIONAL DATA-ANALYSIS; GAMES; LEXICAL PITCH-ACCENT; PAST TENSE; PERCEPTION; phonetics; Phonology; play; READING PROSODY; registers; SPEECH; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HVQ84N3N","journalArticle","2022","Pálvölgyi, KB","Tonal peaks in the spontaneous speech of vantage level Hungarian learners of Spanish","ACTA LINGUISTICA ACADEMICA","","2559-8201","10.1556/2062.2021.00436","","This paper reports on a two-part research project, conducted in order to see how Hungarian learners with at least vantage level of Spanish realize melodic peaks in their Spanish utterances. First, we are focusing on the tonal and distributional characteristics of melodic peaks, taking into consideration the proportion of the rise in f0 with respect to the previous syllable and examining if the affected syllable is lexically stressed. Second, the range of the tonal rise until the first peak of the utterance is analyzed. The method applied in both cases is Cantero Serena's Prosodic Analysis of Speech (2019), which represents intonation by objectively comparable standardized melodic curves. The differences found in the speech of Hungarian learners as compared to native Spanish speakers have not proved to be significant in the aspects analyzed here. The main finding of the research is that native Spanish speakers tend to realize the first peak of their declarative sentences as the highest f0 point of the utterance, whereas this is less typical in the oral production of Hungarian learners of Spanish.","2022-03","2025-02-26 20:39:13","2025-02-26 20:39:13","","59-73","","1","69","","","","","","","","","","English","","","","WOS:000774411800005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","anacrusis; intonation; melodic peaks; standardization; stress","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9VFLFA5F","journalArticle","2021","Torregrossa, J; Andreou, M; Bongartz, C; Tsimpli, IM","Bilingual acquisition of reference: The role of language experience, executive functions and cross-linguistic effects","BILINGUALISM-LANGUAGE AND COGNITION","","1366-7289","10.1017/S1366728920000826","","The present study aims to understand which factors contribute to different patterns of use of referring expressions by bilingual children, by considering the triangulation between language experience and proficiency, executive functions and cross-linguistic effects. We analyze reference use in Greek in the context of a narrative elicitation task as performed by 125 children of different language combinations, including Greek-Albanian, Greek-English and Greek-German. We calculate, for each child, an index of language experience that combines a proficiency measure with background questionnaire information. After identifying the occurrences of underinformative (underspecified) and overinformative (overspecified) referring expressions in the production of each child, we investigate to what extent each pattern of reference use is affected by language experience, cross-linguistic effects and executive functions. The study aims to shed some new light on the nature of overspecification and underspecification in bilingual reference production and, more in general, to model variation in reference use among bilingual children.","2021-08","2025-02-26 20:39:13","2025-02-26 20:39:13","","694-706","","4","24","","","","","","","","","","English","","","","WOS:000669500800009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;30<br/>Total Times Cited:&nbsp;&nbsp;30<br/>Cited Reference Count:&nbsp;&nbsp;93</p>","","","bilingual reference production; cross-linguistic effects; ENGLISH; executive functions; EXPOSURE; INDIVIDUAL-DIFFERENCES; language dominance; over- and underspecification; REALIZATION; SPANISH; SPEAKERS; SPONTANEOUS SPEECH; SYNTAX; VOCABULARY; WORKING-MEMORY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P2NKQ89X","journalArticle","2024","Martinez, JO","'Until' constructions and expletive negation in Huasteca Nahuatl","STUDIES IN LANGUAGE","","0378-4177","10.1075/sl.22064.olg","","A number of works have explored expletive negation in clause-linkage constructions. Most of them have shown that this type of negative marker can be omitted from the adverbial clause without affecting the interpretation holding between clauses. The study shows, based on the analysis of natural discourse data, that expletive negation has developed an intriguing discourse function in three types of 'until' constructions in Huasteca Nahuatl: 'not & mldr;until' constructions, scalar additive 'until' constructions, and beginning-to-end constructions. When the negative marker amo appears in the 'until' clause, the proposition should be characterized as expressing surprise. When it is absent from the 'until' clause, the proposition does not express surprise. This function of the expletive negative marker amo does not appear in elicited sentences, but only in spontaneous speech. It is proposed that Huasteca Nahuatl developed expletive negation in 'not & mldr;until' constructions due to contact with Spanish. However, the development of expletive negation in scalar additive 'until' constructions and beginning-to-end constructions is an internally motivated development in Huasteca Nahuatl that cannot be attributed to Spanish.","2024-01-03","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","","","","","","","","","","","English","","","","WOS:001296207500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","'Until' clauses; clause combining; expletive negation; linguistic typology; scalar additive operators","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"64L8AXIK","journalArticle","2022","Wang, SF","The interaction between predictability and pre-boundary lengthening on syllable duration in Taiwan Southern Min","PHONETICA","","0031-8388","10.1515/phon-2022-0009","","This study investigated how predictability and prosodic phrasing interact in accounting for the variability of syllable duration in Taiwan Southern Min. Speech data were extracted from 8 hours of spontaneous speech. Three predictability measurements were examined: bigram surprisal, bigram informativity, and lexical frequency. Results showed that higher informativity and surprisal led to longer syllables. As for the interaction with prosodic positions, there was a general weakening of predictability effects for syllables closer to the boundary, especially in the pre-boundary position, where pre-boundary lengthening was the strongest. However, the effect of word informativity appeared to be least modulated by this effect of boundary marking. These findings are consistent with a hypothesis that prosodic structure modulates the predictability effects on phonetic variability. The robustness of informativity in predicting syllable duration also suggests a possibility of stored phonetic variants associated with a word's usual contextual predictability.","2022-08-26","2025-02-26 20:39:13","2025-02-26 20:39:13","","315-352","","4","79","","","","","","","","","","English","","","","WOS:000878299800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;96</p>","","","ACOUSTIC REDUCTION; CONTEXTUAL PREDICTABILITY; duration; FRENCH; FREQUENCY; informativity; INFORMATIVITY; lexical frequency; NEIGHBORHOOD DENSITY; predictability; prosodic boundaries; REDUNDANCY; SIMILARITY; SPOKEN WORD RECOGNITION; surprisal; VOWEL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RTYSC34M","journalArticle","2021","Coro, G; Massoli, FV; Origlia, A; Cutugno, F","Psycho-acoustics inspired automatic speech recognition","COMPUTERS & ELECTRICAL ENGINEERING","","0045-7906","10.1016/j.compeleceng.2021.107238","","Understanding the human spoken language recognition process is still a far scientific goal. Nowadays, commercial automatic speech recognisers (ASRs) achieve high performance at recognising clean speech, but their approaches are poorly related to human speech recognition. They commonly process the phonetic structure of speech while neglecting supra-segmental and syllabic tracts integral to human speech recognition. As a result, these ASRs achieve low performance on spontaneous speech and require enormous costs to build up phonetic and pronunciation models and catch the large variability of human speech. This paper presents a novel ASR that addresses these issues and questions conventional ASR approaches. It uses alternative acoustic models and an exhaustive decoding algorithm to process speech at a syllabic temporal scale (100-250 ms) through a multi-temporal approach inspired by psycho-acoustic studies. Performance comparison on the recognition of spoken Italian numbers (from 0 to 1 million) demonstrates that our approach is cost-effective, outperforms standard phonetic models, and reaches state-of-the-art performance.","2021-07","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","","93","","","","","","","","","","English","","","","WOS:000687736100033","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;148</p>","","","Automatic speech recognition; Convolutional neural networks; CONVOLUTIONAL NEURAL-NETWORKS; Deep learning; Factorial hidden Markov models; Hidden Markov models; Long short term memory; MODEL; PERCEPTION; Psycho-acoustics; SHORTLIST; Speech; Syllables","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7FU9DDE6","journalArticle","2024","Perry, SJ; Kelley, MC; Tucker, BV","Documenting and modeling the acoustic variability of intervocalic alveolar taps in conversational Peninsular Spanish","JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA","","0001-4966","10.1121/10.0024345","","This study constitutes an investigation into the acoustic variability of intervocalic alveolar taps in a corpus of spontaneous speech from Madrid, Spain. Substantial variability was documented in this segment, with highly reduced variants constituting roughly half of all tokens during spectrographic inspection. In addition to qualitative documentation, the intensity difference between the tap and surrounding vowels was measured. Changes in this intensity difference were statistically modeled using Bayesian finite mixture models containing lexical and phonetic predictors. Model comparisons indicate predictive performance is improved when we assume two latent categories, interpreted as two pronunciation variants for the Spanish tap. In interpreting the model, predictors were more often related to categorical changes in which pronunciation variant was produced than to gradient intensity changes within each tap type. Variability in tap production was found according to lexical frequency, speech rate, and phonetic environment. These results underscore the importance of evaluating model fit to the data as well as what researchers modeling phonetic variability can gain in moving past linear models when they do not adequately fit the observed data.","2024-01","2025-02-26 20:39:13","2025-02-26 20:39:13","","294-305","","1","155","","","","","","","","","","English","","","","WOS:001144141400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","CONTEXTUAL PREDICTABILITY; DURATION; FREQUENCY; LENITION; PROBABILITY; REDUCTION; REDUNDANCY; WORD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WBGKBZUR","journalArticle","2024","Dash, D; Ferrari, P; Wang, J","Neural Decoding of Spontaneous Overt and Intended Speech","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2024_JSLHR-24-00046","","Purpose: The aim of this study was to decode intended and overt speech from neuromagnetic signals while the participants performed spontaneous overt speech tasks without cues or prompts (stimuli). Method: Magnetoencephalography (MEG), a noninvasive neuroimaging technique, was used to collect neural signals from seven healthy adult English speakers performing spontaneous, overt speech tasks. The participants randomly spoke the words yes or no at a self-paced rate without cues. Two machine learning models, namely, linear discriminant analysis (LDA) and onedimensional convolutional neural network (1D CNN), were employed to classify the two words from the recorded MEG signals. Results: LDA and 1D CNN achieved average decoding accuracies of 79.02% and 90.40%, respectively, in decoding overt speech, significantly surpassing the chance level (50%). The accuracy for decoding intended speech was 67.19% using 1D CNN. Conclusions: This study showcases the possibility of decoding spontaneous overt and intended speech directly from neural signals in the absence of perceptual interference. We believe that these findings make a steady step toward the future spontaneous speech-based brain-computer interface.","2024-11","2025-02-26 20:39:13","2025-02-26 20:39:13","","4216-4225","","11","67","","","","","","","","","","English","","","","WOS:001355394400006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","COMMUNICATION; LOCKED-IN SYNDROME; MAGNETOENCEPHALOGRAPHY; TASK","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2SNQGDAS","journalArticle","2025","Yang, J; Davis, BL","A longitudinal study of tone and segment accuracy in Mandarin-speaking children","SPEECH LANGUAGE AND HEARING","","2050-571X","10.1080/2050571X.2025.2455267","","Mandarin Chinese uses both tonal and segmental properties to code word meanings. Previous research has not achieved consensus on whether tones are acquired chronologically earlier than segments. The present study investigated the relationship between production accuracy for tones and segments in spontaneous speech samples collected from four monolingual Mandarin-speaking children longitudinally between twelve and twenty-four months. Recognizable words were perceptually transcribed. Position-weighted tone accuracy and whole-word segment accuracy were calculated and compared across tone types and chronological age. Results showed that tone accuracy was highest in Tone 4 and lowest in Tone 3 words. Tone accuracy was higher than segment accuracy in Tone 4 words. Segment accuracy was higher than tone accuracy in Tone 3 words. The differences between tone and segment accuracy decreased with chronological age. In conclusion, prior to age two, tone accuracy is not always higher than segment accuracy nor vice versa. The relationship between tone and segment accuracy is influenced by both complexity of tone type and children' developmental age.","2025-01-02","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","1","28","","","","","","","","","","English","","","","WOS:001415494800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","ACQUISITION; age; CANTONESE; children; longitudinal; Mandarin Chinese; MAXIMUM SPEED; segment accuracy; speech production; tone accuracy; tone complexity; WORDS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B9N7W2LC","journalArticle","2023","Sergidou, EK; Scheijen, N; Leegwater, J; Cambier-Langeveld, T; Bosma, W","Frequent-words analysis for forensic speaker comparison","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2023.03.010","","While many authorship analysis techniques could be applied to any type of linguistic data, there is very limited research on their application on transcriptions of spontaneous speech to help identify the speaker. In authorship analyses, frequency analysis of function words has been quite a successful feature since, when writing a text, people tend to use different function words in different frequencies. Thus, this feature is sensitive to author style while it remains relatively insensitive to the topic of the text. In this paper, we make the cross-over to speech samples and test whether frequency analysis of the most common words in speech, which are mostly function words, has potential as a speaker discriminant. We propose a method within the likelihood ratio framework for court applicability. Our approach takes into account both the similarity and typicality of word frequencies by employing a method using percentile-rank for feature extraction. We apply our method on the forensically relevant dataset FRIDA, achieving good results even when a limited amount of data is available.","2023-05","2025-02-26 20:39:13","2025-02-26 20:39:13","","1-8","","","150","","","","","","","","","","English","","","","WOS:000988977600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","AUTHORSHIP ATTRIBUTION; Forensic linguistics; Forensic speaker comparison; IDENTIFICATION; Likelihood ratio; LIKELIHOOD RATIO; Percentile-rank; SIMILARITY; Similarity and typicality; SYSTEMS; VERIFICATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MBQVSNCW","journalArticle","2022","Faes, J; Gillis, S","Intraword Variability in Children With Auditory Brainstem Implants: A Longitudinal Comparison With Children With Cochlear Implants","AMERICAN JOURNAL OF SPEECH-LANGUAGE PATHOLOGY","","1058-0360","10.1044/2022_AJSLP-21-00312","","Purpose: Intraword variability designates the phenomenon that a particular target word is produced variably by a child at one point in the child's development. In this study, the amount of intraword variability is studied longitudinally in children with auditory brainstem implants (ABIs). Auditory brainstem implantation is a relative recent technique in pediatric hearing restoration. Therefore, little is known about the phonological development of these children's speech. Method: The intraword variability is investigated in three children with ABI, in comparison to children with cochlear implants, matched on lexical development. Intraword variability is measured using relative entropy in order to take into account the frequency distribution in children's productions. Result: Results showed considerable variation between the three children with ABI. Still, all children had higher levels of intraword variability in their spontaneous speech productions as compared to children with cochlear implants. Conclusion: It seems that children with ABI are lagging behind their phonological development in reference to children with cochlear implants.","2022-07","2025-02-26 20:39:13","2025-02-26 20:39:13","","1787-1800","","4","31","","","","","","","","","","English","","","","WOS:000852775300017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","ACCURACY; DEVELOPMENTAL APRAXIA; HEARING; LANGUAGE; OUTCOMES; PERCEPTION; PRESCHOOL-CHILDREN; SPEAKING CHILDREN; SPEECH; WORD PHONOLOGICAL VARIABILITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RPCEB4NI","journalArticle","2021","Umbal, P","FILIPINOS FRONT TOO! A SOCIOPHONETIC ANALYSIS OF TORONTO ENGLISH /u/-FRONTING","AMERICAN SPEECH","","0003-1283","10.1215/00031283-9116273","","The fronting of the back vowel /u/ is an ongoing sound change in many varieties of English. While /u/-fronting is argued to be primarily phonetically constrained, many studies report the significant role of various social factors, including ethnicity. This article investigates the linguistic and social conditioning of /u/-fronting in Toronto English. A sociophonetic analysis of /u/, extracted from spontaneous speech data of second-generation Filipinos and age-matched Anglos, was conducted to determine whether Filipinos exhibit/u/-fronting and to what extent coarticulatory and social factors affect degree of fronting. Results of a multivariate analysis show that male and female Filipinos produce fronted realizations of /u/ as often as their Anglo peers. However, Filipinos exhibit greater fronting than Anglos in coronal and palatal contexts, which may be explained by cross-language influence from Tagalog. Taken together, this study suggests that, although Filipinos join other Torontonians in /u/-fronting, they nonetheless exhibit finer-grained differences when phonetic conditioning is taken into account.","2021-11-01","2025-02-26 20:39:13","2025-02-26 20:39:13","","397-423","","4","96","","","","","","","","","","English","","","","WOS:000721169700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;95</p>","","","1ST-LANGUAGE; AMERICAN; BILINGUALS; Canadian English; coarticulation; CONTEXT; cross-language influence; ethnolect; FRENCH; LANGUAGE; PATTERNS; SOUTHERN BRITISH; Tagalog; VERTICAL-BAR; VOWEL COARTICULATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IFQP2J9I","journalArticle","2022","Maessen, B; Rombouts, E; Maes, B; Zink, I","The relation between gestures and stuttering in individuals with Down syndrome","JOURNAL OF APPLIED RESEARCH IN INTELLECTUAL DISABILITIES","","1360-2322","10.1111/jar.12980","","Background Evidence shows that neurotypical individuals who stutter use fewer gestures than those who do not stutter. Presently, no research exists about the interaction of stuttering and gestures in individuals with Down syndrome. Method Twenty-nine individuals with Down syndrome (7-19 years) of whom 16 stuttered and 13 spoke fluently and 20 neurotypical children (3-10 years) of whom 8 stuttered and 12 spoke fluently participated in this study. In spontaneous speech transcriptions, stuttering events and gestures were coded. Results Comparisons of gesture frequency during stuttered and fluent speech inside the Down syndrome and neurotypical group show that the Down syndrome group uses significantly more gestures during stuttered than during fluent speech while no significant difference is seen in the neurotypical group. Conclusions There is some preliminary evidence that individuals with Down syndrome try to compensate for their stuttering events, however, analyses on word level are necessary to confirm a successful compensation.","2022-05","2025-02-26 20:39:13","2025-02-26 20:39:13","","761-776","","3","35","","","","","","","","","","English","","","","WOS:000745904500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;97</p>","","","ACQUISITION; ADOLESCENTS; COMMUNICATION; DISFLUENCIES; Down syndrome; gesture-speech relationship; gestures; HAND GESTURES; LANGUAGE; NAMING TASK; SPECIALIZATION; SPEECH; stuttering; YOUNG-CHILDREN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5Q583HXQ","journalArticle","2022","Sanfelici, E; Gallina, C","The timing of production: on the acquisition of Italian prepositions","ISOGLOSS OPEN JOURNAL OF ROMANCE LINGUISTICS","","2385-4138","10.5565/rev/isogloss.137","","This paper inves tigates the acquisition of Italian prepositions looking at children's early spontaneous speech. With a longitudinal study on the production of fifteen Italianspeaking children aged 1;4 to 3;4, we sought to determine the timing in which different prepositi onal items emerged in children's speech. Following much acquisition research, the order of emergence is assumed to reveal how syntax develops during acquisition (Rizzi, 1993/1994; P & eacute;rez-Leroux & al., 2012; Friedmann, Belletti, & Rizzi, 2020). Our analysis shows that children produced different prepositional items at different stages following the geometry of the syntactic tree proposed in the cartographic literature (Svenonius, 2008, 2010): KP prepositions are acquired before p P prepositions which in turn appear earlier than AxPartP prepositions. Our results are in line with the previous findings on French and Spanish (Morgenstern & Sekali, 2009; Stewart, 2015) but diverge from those reported for English (Littlefield, 2009). In this respect, the development of prepositions matches the acquisition of other functional morphemes that differentiates morphologically rich languages from those with a poorer functional inventory.","2022","2025-02-26 20:39:13","2025-02-26 20:39:13","","","","2","8","","","","","","","","","","English","","","","WOS:001223636400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","acquisition; CHILDREN; emergence; ENGLISH; functional morphemes; Italian; preposition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P7J58N3H","journalArticle","2025","Kavé, G; Goral, M; Mirelman, A; Shiner, T; Bregman, N","Does Parkinson's disease affect verb production in picture descriptions?","JOURNAL OF NEUROLINGUISTICS","","0911-6044","10.1016/j.jneuroling.2024.101230","","Research on Parkinson's disease (PD) has documented significant deficits in verb production, with more robust results in single word retrieval tasks than in connected speech, yet the underlying causes of these deficits are disputable, especially concerning connected speech production. We analyzed picture descriptions provided by 48 individuals with PD and 48 age-matched healthy controls, and examined the percent of nouns and verbs of all words, the number of described events, verbs denoting activity, verbs in active morpho-syntactic patterns, and transitive verbs. Individuals with PD produced a lower percent of verbs than did control participants, but the groups differed in no other variable. Scores on a cognitive screening task associated with the percent of verbs and the number of events. We suggest that verb retrieval in connected speech in PD reflects no specific difficulty with action semantics, but rather the spread of PD pathology into more diffuse verb-specific neural networks.","2025-02","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","73","","","","","","","","","","English","","","","WOS:001317951600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","ABILITIES; Actionality; ALZHEIMERS-DISEASE; Connected speech; DISCOURSE; Embodied cognition; FLUENCY; IMPAIRMENT; LANGUAGE; MOVEMENT; PROGRESSION; SPONTANEOUS SPEECH; Transitivity; Word retrieval; WORD RETRIEVAL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HG4RIFGN","journalArticle","2022","Suarez-Rivera, C; Linn, E; Tamis-LeMonda, CS","From Play to Language: Infants' Actions on Objects Cascade to Word Learning","LANGUAGE LEARNING","","0023-8333","10.1111/lang.12512","","Infants build knowledge by acting on the world. We conducted an ecologically grounded test of an embodied learning hypothesis: that infants' active engagement with objects in the home environment elicits caregiver naming and cascades to learning object names. Our home-based study extends laboratory-based theories to identify real-world processes that support infant word learning. Frame-by-frame coding of 2-hr video recordings of 32 mothers and their 18- to 23-month-old infants focused on infant manipulation and mother and infant naming of 245 unique objects. Objects manipulated by infants and/or named by mothers were more likely to appear in infants' vocabularies and spontaneous speech relative to nonmanipulated objects and objects that mothers did not name. Furthermore, the vocabularies of 5,520 infants hosted on Wordbank revealed an early age of acquisition of words for objects that mothers named and infants manipulated. Infants actively build object-word mappings from everyday engagements with objects in the context of social interactions.","2022-12","2025-02-26 20:39:14","2025-02-26 20:39:14","","1092-1127","","4","72","","","","","","","","","","English","","","","WOS:000826174800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;22<br/>Total Times Cited:&nbsp;&nbsp;25<br/>Cited Reference Count:&nbsp;&nbsp;78</p>","","","ACQUISITION; ATTENTION; CHILDREN; DYNAMICS; embodied learning; EXPLORATION; INPUT; MANIPULATION; naturalistic interaction; object play; parent responsiveness; TODDLERS; VIEW; word learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DM49N8M7","journalArticle","2021","Rodríguez-Ordóñez, I","The role of social meaning in contact-induced variation among new speakers of Basque","JOURNAL OF SOCIOLINGUISTICS","","1360-6441","10.1111/josl.12477","","This study examines the variable use and the social meaning of a contact-induced phenomenon in Basque, Differential Object Marking, to explain the emergence of new variation in a minoritized language situation. The spontaneous speech of 77 Basque-Spanish bilinguals was analyzed and compared to the perception results obtained from a matched-guise experiment. I situate this analysis using emergent participant self-identification categories that lie along a continuum of Basque speaker authenticity. Production results show that DOM use increases according to a speaker's self-ascribed authenticity, but the matched-guise analyses indicate that some DOM uses may undermine the speaker's perceived authenticity. I discuss the ideological multiplicity of DOM within its semiotic landscape and consider practice-based approaches to variation in explaining this paradox. The evidence lends support for social meaning-based accounts of variation that also consider speakerhood as an agentive process, and it additionally challenges models that directly correlate language use to acts of identity.","2021-09","2025-02-26 20:39:14","2025-02-26 20:39:14","","533-556","","4","25","","","","","","","","","","English","","","","WOS:000639361600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;18<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","ACCENT; based identity; Basque; Differential Object Marking; new speakers; practiced‐; SCOTTISH GAELIC SPEAKERS; social meaning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AX9C5SYP","journalArticle","2024","Yam, EED; Pfeiler, BB","The evidential BIN in the children's environment of engagement: Reporting, evaluating, and engaging knowledge in Yucatec Maya","FIRST LANGUAGE","","0142-7237","10.1177/01427237241272541","","This article explores the role of the reportative BIN in Yucatec Maya language acquisition and socialization among children aged 4 years and above, focusing on their interactions during pretend play. Building upon prior research on caregivers' strategic use of BIN, the study aims to elucidate the nuanced meanings and functions of the reportative in children's language. Through a theoretical framework rooted in the theory of engagement, the article posits that BIN serves not only as a linguistic form but also as an interactive device conveying contextual and imaginative speech. Divided into six sections, the article progresses from theoretical underpinnings to interpreting children's language in pretend play. By analyzing spontaneous speech data, the study uncovers novel insights into the dynamic nature of reportatives, emphasizing the creative ways children employ BIN to engage in games. The findings contribute to a broader understanding of reportatives and underscore the dynamic nature of children's language usage and development.","2024-12","2025-02-26 20:39:14","2025-02-26 20:39:14","","686-707","","6","44","","","","","","","","","","English","","","","WOS:001322137500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","engagement; evidentiality; evidentials; GRAMMAR; pragmatics; pretend play; reportatives; socialization; SPEECH; Yucatec Maya children","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V49HHKHU","journalArticle","2023","Michalsky, J","Questioning questions - the perception of f0 scaling in German questions between categorical function and continuous attitude","PHONETICA","","0031-8388","10.1515/phon-2023-2002","","In previous studies comparing the intonation of questions and statements in German, greater f0 excursions of phrase-final rises have been associated with questions in both read speech and spontaneous speech. This holds for production studies as well as perception studies. However, a major question remains whether these differences are perceived categorically or continuously. Furthermore, we ask whether the differences in f0 scaling correspond to categorical linguistic functions or rather an attitudinal continuum. We conducted three different perception experiments: a classical categorical perception task, an imitation task, and a semantic evaluation task. The results suggest that f0 scaling in phrase-final rises is perceived as a phonetic continuum rather than in phonological categories. Furthermore, the gradual increase of the final rise is associated with a gradual increase in perceived questioning. Lastly, the phonetic cues to this degree of questioning are distinct from those to the other investigated meanings surprise and uncertainty. Accordingly, this study supports the assumption that questioning constitutes an attitudinal meaning in its own right.","2023-10-26","2025-02-26 20:39:14","2025-02-26 20:39:14","","357-392","","5","80","","","","","","","","","","English","","","","WOS:001042101800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","categorical perception; DISCRIMINATION; f0 scaling; interrogativity; PITCH; pitch perception; question intonation; questioning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EX98KIAL","journalArticle","2024","Kang, BO; Jeon, HB; Lee, YK","AI-based language tutoring systems with end-to-end automatic speech recognition and proficiency evaluation","ETRI JOURNAL","","1225-6463","10.4218/etrij.2023-0322","","This paper presents the development of language tutoring systems for non-native speakers by leveraging advanced end-to-end automatic speech recognition (ASR) and proficiency evaluation. Given the frequent errors in non-native speech, high-performance spontaneous speech recognition must be applied. Our systems accurately evaluate pronunciation and speaking fluency and provide feedback on errors by relying on precise transcriptions. End-to-end ASR is implemented and enhanced by using diverse non-native speaker speech data for model training. For performance enhancement, we combine semisupervised and transfer learning techniques using labeled and unlabeled speech data. Automatic proficiency evaluation is performed by a model trained to maximize the statistical correlation between the fluency score manually determined by a human expert and a calculated fluency score. We developed an English tutoring system for Korean elementary students called EBS AI PengTalk and a Korean tutoring system for foreigners called KSI Korean AI Tutor. Both systems were deployed by South Korean government agencies.","2024-02","2025-02-26 20:39:14","2025-02-26 20:39:14","","48-58","","1","46","","","","","","","","","","English","","","","WOS:001153318900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","automatic speech recognition; computer-assisted language learning; end-to-end recognition; language tutoring; spoken proficiency evaluation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ACPM26W6","journalArticle","2021","Friesner, M; Kastronic, L; Lamontagne, J","DYNAMICS OF SHORT-A IN MONTREAL AND QUEBEC CITY ENGLISH","AMERICAN SPEECH","","0003-1283","10.1215/00031283-8791781","","This study compares the effects of city and ethnicity with respect to Quebec English speakers' participation in two ongoing changes affecting /ae/ in Canadian English: retraction as part of the Canadian Vowel Shift and tensing in prenasal environments. Quebec English speakers might be expected to differ in their behavior with regard to these two phenomena as compared to other Canadian English speakers. Based on an analysis of Euclidean distances and a mixed-effects model using spontaneous speech, the authors find that Quebec English speakers are less advanced with respect to the Canadian Shift, especially speakers from Quebec City. For tensing, British-origin speakers from Montreal and Quebec City are found to pattern similarly, participating in the more widespread patterning, while Jewish and Italian speakers are moving in the opposite direction. The authors argue that this move away from characteristically Canadian patterns is an artifact of the interplay between the two phenomena under study, reflective of differential replication of the Canadian Shift in the two environments.","2021-11-01","2025-02-26 20:39:14","2025-02-26 20:39:14","","450-480","","4","96","","","","","","","","","","English","","","","WOS:000721169700003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;79</p>","","","Canadian Shift; CANADIAN SHIFT; ethnicity; FRENCH; LANGUAGE; minority English; prenasal tensing; REGION; sociophonetic variation; VOWEL SHIFT EVIDENCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L69E469E","journalArticle","2024","Sun, H; Saito, K; Dewaele, JM","Cognitive and Sociopsychological Individual Differences, Experience, and Naturalistic Second Language Speech Learning: A Longitudinal Study","LANGUAGE LEARNING","","0023-8333","10.1111/lang.12561","","This study longitudinally examined the effects of cognitive and sociopsychological individual differences (aptitude, motivation, personality) and the quantity and quality of second language (L2) experience on L2 speech gains in naturalistic settings. We elicited L2 spontaneous speech from 50 Chinese learners of English at the beginning and the end of their first 4 months of study abroad. Then, we linked the participants' gains in comprehensibility (ease of understanding) and accentedness (linguistic nativelikeness) to their individual difference and experience profiles. The participants' gains in comprehensibility were associated mainly with the amount of their interaction with fluent English speakers during immersion and secondarily with certain cognitive (grammatical inferencing) and sociopsychological (extraversion) individual differences. Furthermore, the amount of interactive L2 use mediated the effect of sociopsychological individual differences (extraversion and potentially ideal L2 self). In contrast, gains in accentedness tended to be less subject to experience effects but could be affected by certain pronunciation-related cognitive individual differences (phonemic coding).","2024-03","2025-02-26 20:39:14","2025-02-26 20:39:14","","5-40","","1","74","","","","","","","","","","English","","","","WOS:000943116600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;88</p>","","","aptitude; ENGLISH; experience; EXPLICIT; FOREIGN; IMPLICIT; L2 PHONOLOGY; LANGUAGE APTITUDE; LEARNERS; motivation; MOTIVATION; MULTICULTURAL PERSONALITY QUESTIONNAIRE; personality; pronunciation; second language speech; SELF; study abroad","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ETNEMXLN","journalArticle","2021","Maffia, M; De Micco, R; Pettorino, M; Siciliano, M; Tessitore, A; De Meo, A","Speech Rhythm Variation in Early-Stage Parkinson's Disease: A Study on Different Speaking Tasks","FRONTIERS IN PSYCHOLOGY","","1664-1078","10.3389/fpsyg.2021.668291","","Patients with Parkinson's disease (PD) usually reveal speech disorders and, among other symptoms, the alteration of speech rhythm. The purpose of this study is twofold: (1) to test the validity of two acoustic parameters-%V, vowel percentage and VtoV, the mean interval between two consecutive vowel onset points-for the identification of rhythm variation in early-stage PD speech and (2) to analyze the effect of PD on speech rhythm in two different speaking tasks: reading passage and monolog. A group of 20 patients with early-stage PD was involved in this study and compared with 20 age- and sex-matched healthy controls (HCs). The results of the acoustic analysis confirmed that %V is a useful cue for early-stage PD speech characterization, having significantly higher values in the production of patients with PD than the values in HC speech. A simple speaking task, such as the reading task, was found to be more effective than spontaneous speech in the detection of rhythmic variations.","2021-06-14","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","12","","","","","","","","","","English","","","","WOS:000667199200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;16<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","acoustic analysis; DYSARTHRIA; DYSFUNCTION; early-stage; INDIVIDUALS; Parkinson's disease; PERCEPTION; PROGRESSION; speaking tasks; speech rhythm; VOWEL ARTICULATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CNBP6LEE","journalArticle","2021","Bloom, PP; Robin, J; Xu, MD; Arvind, A; Daidone, M; Gupta, AS; Chung, RDT","Hepatic Encephalopathy is Associated With Slow Speech on Objective Assessment","AMERICAN JOURNAL OF GASTROENTEROLOGY","","0002-9270","10.14309/ajg.0000000000001351","","Introduction:There are no available low-burden, point-of-care tests to diagnose, grade, and predict hepatic encephalopathy (HE). Methods:We evaluated speech as a biomarker of HE in 76 English-speaking adults with cirrhosis. Results:Three speech features significantly correlated with the following neuropsychiatric scores: speech rate, word duration, and use of particles. Patients with low neuropsychiatric scores had slower speech (22 words/min, P = 0.01), longer word duration (0.09 seconds/word, P = 0.01), and used fewer particles (0.85% fewer, P = 0.01). Patients with a history of overt HE had slower speech (23 words/min, P = 0.005) and longer word duration (0.09 seconds/word, P = 0.005). Discussion:HE is associated with slower speech. [GRAPHICS] .","2021-09","2025-02-26 20:39:14","2025-02-26 20:39:14","","1950-1953","","9","116","","","","","","","","","","English","","","","WOS:000711687600026","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;14</p>","","","DIAGNOSIS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M7684GGY","journalArticle","2024","Arif, M; Ameer, I; Bölücü, N; Sidorov, G; Gelbukh, A; Elangovan, V","Mental Illness Classification on Social Media Texts Using Deep Learning and Transfer Learning","COMPUTACION Y SISTEMAS","","1405-5546","10.13053/CyS-28-2-4873","","Given the current social distance restrictions across the world, most individuals now use social media as their major medium of communication. Due to this, millions of people suffering from mental diseases have been isolated, and they are unable to get help in person. They have become more reliant on online venues to express themselves and seek advice on dealing with their mental disorders. According to the World Health Organization (WHO), approximately 450 million people are affected. Mental illnesses, such as depression, anxiety, etc., are immensely common and have affected an individual's physical health. Recently, Artificial Intelligence (AI) methods have been presented to help mental health providers, including psychiatrists and psychologists, in decision -making based on patients' authentic information (e.g., medical records, behavioral data, social media utilization, etc.). AI innovations have demonstrated predominant execution in numerous real -world applications, broadening from computer vision to healthcare. This study analyzed unstructured user data on the Reddit platform and classified five common mental illnesses: depression, anxiety, bipolar disorder, ADHD, and PTSD. In this paper, we proposed a Transformer model with late fusion methods to combine the two texts (title and post) of the dataset into the model to detect the mental disorders of individuals. We compared the proposed models with traditional machine learning, deep learning, and transfer learning multi -class models. Our proposed Transformer model with the late fusion method outperformed (F1 score = 89.65) the state-of-the-art performance (F1 score = 89 [35]). This effort will benefit the public health system by automating the detection process and informing the appropriate authorities about people who need emergency assistance.","2024","2025-02-26 20:39:14","2025-02-26 20:39:14","","451-464","","2","28","","","","","","","","","","English","","","","WOS:001260827000010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","deep learning; FEATURES; FUSION; HEALTH; late fusion; machine learning; Mental illnesses classification; RECOGNITION; Reddit; transfer learning; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WGBX9YWT","journalArticle","2025","Xu, J; Huang, K; Zhong, LZ; Gao, Y; Sun, K; Liu, W; Zhou, YJ; Guo, WC; Guo, Y; Zou, YQ; Duan, YP; Lu, L; Wang, Y; Chen, X; Zhao, S","RemixFormer plus plus : A Multi-Modal Transformer Model for Precision Skin Tumor Differential Diagnosis With Memory-Efficient Attention","IEEE TRANSACTIONS ON MEDICAL IMAGING","","0278-0062","10.1109/TMI.2024.3441012","","Diagnosing malignant skin tumors accurately at an early stage can be challenging due to ambiguous and even confusing visual characteristics displayed by various categories of skin tumors. To improve diagnosis precision, all available clinical data from multiple sources, particularly clinical images, dermoscopy images, and medical history, could be considered. Aligning with clinical practice, we propose a novel Transformer model, named RemixFormer++ that consists of a clinical image branch, a dermoscopy image branch, and a metadata branch. Given the unique characteristics inherent in clinical and dermoscopy images, specialized attention strategies are adopted for each type. Clinical images are processed through a top-down architecture, capturing both localized lesion details and global contextual information. Conversely, dermoscopy images undergo a bottom-up processing with two-level hierarchical encoders, designed to pinpoint fine-grained structural and textural features. A dedicated metadata branch seamlessly integrates non-visual information by encoding relevant patient data. Fusing features from three branches substantially boosts disease classification accuracy. RemixFormer++ demonstrates exceptional performance on four single-modality datasets (PAD-UFES-20, ISIC 2017/2018/2019). Compared with the previous best method using a public multi-modal Derm7pt dataset, we achieved an absolute 5.3% increase in averaged F1 and 1.2% in accuracy for the classification of five skin tumors. Furthermore, using a large-scale in-house dataset of 10,351 patients with the twelve most common skin tumors, our method obtained an overall classification accuracy of 92.6%. These promising results, on par or better with the performance of 191 dermatologists through a comprehensive reader study, evidently imply the potential clinical usability of our method.","2025-01","2025-02-26 20:39:14","2025-02-26 20:39:14","","320-337","","1","44","","","","","","","","","","English","","","","WOS:001389746700029","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","ALGORITHMS; CANCER; CLASSIFICATION; CNN; DERMATOLOGISTS; dermoscopy; differential diagnosis; Feature extraction; Image recognition; Imaging; Lesions; metadata; Metadata; multi-modality fusion; NEURAL-NETWORK; Skin; Skin tumor diagnosis; Tumors; WORKING","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EMPIK3CK","journalArticle","2024","Mohamed, EA; Koura, A; Kayed, M","Speech Emotion Recognition in Multimodal Environments with Transformer: Arabic and English Audio Datasets","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","Speech Emotion Recognition (SER) is a fastdeveloping area of study with a primary goal of automatically identifying and analyzing the emotional states expressed in speech. Emotions are crucial in human communication as they impact the effectiveness and meaning of linguistic expressions. SER aims to create computational approaches and models to detect and interpret emotions from speech signals. One of the primary applications of SER is evident in the field of Human-Computer Interaction (HCI), where it can be used to develop interactive systems that adapt to the user's emotional state based on their voice. This paper investigates the use of speech data for speech emotion recognition. Additionally, we applied a transformation process to convert the speech data into 2D images. Subsequently, we compared the outcomes of this transformation with the original speech data, aligning the comparison with a dataset containing labeled speech samples in both Arabic and English. Our experiments compare three methods: a transformer-based model, a Vision Transformer (ViT) based model, and a wave2vec-based model. The transformer model is trained from scratch on two significant audio datasets: the Arabic Natural Audio Dataset (ANAD) and the Toronto Emotional Speech Set (TESS), while the vision transformer is evaluated alongside wave2vec as part of transfer learning. The results are impressive. The transformer model achieved remarkable accuracies of 94% and 99% on ANAD and TESS datasets, respectively. Additionally, ViT demonstrates strong capabilities, achieving accuracies of 88% and 98% on the ANAD and TESS datasets, respectively. To assess the transfer learning potential, we also explore the Wave2Vector model with fine-tuning. However, the findings suggest limited success, achieving only a 56% accuracy rate on the ANAD dataset.","2024-03","2025-02-26 20:39:14","2025-02-26 20:39:14","","581-592","","3","15","","","","","","","","","","English","","","","WOS:001317462700058","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","fine-tuning; multimodal emotion recognition; Speech emotion recognition; transformer encoder; wav2vec","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4K95HGQM","journalArticle","2023","Sarraf, S; Kabia, M","Optimal Topology of Vision Transformer for Real-Time Video Action Recognition in an End-To-End Cloud Solution","MACHINE LEARNING AND KNOWLEDGE EXTRACTION","","2504-4990","10.3390/make5040067","","This study introduces an optimal topology of vision transformers for real-time video action recognition in a cloud-based solution. Although model performance is a key criterion for real-time video analysis use cases, inference latency plays a more crucial role in adopting such technology in real-world scenarios. Our objective is to reduce the inference latency of the solution while admissibly maintaining the vision transformer's performance. Thus, we employed the optimal cloud components as the foundation of our machine learning pipeline and optimized the topology of vision transformers. We utilized UCF101, including more than one million action recognition video clips. The modeling pipeline consists of a preprocessing module to extract frames from video clips, training two-dimensional (2D) vision transformer models, and deep learning baselines. The pipeline also includes a postprocessing step to aggregate the frame-level predictions to generate the video-level predictions at inference. The results demonstrate that our optimal vision transformer model with an input dimension of 56 x 56 x 3 with eight attention heads produces an F1 score of 91.497% for the testing set. The optimized vision transformer reduces the inference latency by 40.70%, measured through a batch-processing approach, with a 55.63% faster training time than the baseline. Lastly, we developed an enhanced skip-frame approach to improve the inference latency by finding an optimal ratio of frames for prediction at inference, where we could further reduce the inference latency by 57.15%. This study reveals that the vision transformer model is highly optimizable for inference latency while maintaining the model performance.","2023-12","2025-02-26 20:39:14","2025-02-26 20:39:14","","1320-1339","","4","5","","","","","","","","","","English","","","","WOS:001136031800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","action recognition; ATTENTION; cloud solution; DEEP; INFERENCE; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RJQYZ27M","journalArticle","2023","Li, WJ; Liu, XP; An, K; Qin, CJ; Cheng, YH","Table Tennis Track Detection Based on Temporal Feature Multiplexing Network","SENSORS","","1424-8220","10.3390/s23031726","","Recording the trajectory of table tennis balls in real-time enables the analysis of the opponent's attacking characteristics and weaknesses. The current analysis of the ball paths mainly relied on human viewing, which lacked certain theoretical data support. In order to solve the problem of the lack of objective data analysis in the research of table tennis competition, a target detection algorithm-based table tennis trajectory extraction network was proposed to record the trajectory of the table tennis movement in video. The network improved the feature reuse rate in order to achieve a lightweight network and enhance the detection accuracy. The core of the network was the ""feature store & return"" module, which could store the output of the current network layer and pass the features to the input of the network layer at the next moment to achieve efficient reuse of the features. In this module, the Transformer model was used to secondarily process the features, build the global association information, and enhance the feature richness of the feature map. According to the designed experiments, the detection accuracy of the network was 96.8% for table tennis and 89.1% for target localization. Moreover, the parameter size of the model was only 7.68 MB, and the detection frame rate could reach 634.19 FPS using the hardware for the tests. In summary, the network designed in this paper has the characteristics of both lightweight and high precision in table tennis detection, and the performance of the proposed model significantly outperforms that of the existing models.","2023-02","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","3","23","","","","","","","","","","English","","","","WOS:000930911900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;95</p>","","","CLASSIFICATION; deep learning; feature reuse; lightweight network; motion trajectory; object detection; PREDICTION; SPORTS; TARGET; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NFGLJPRK","journalArticle","2024","Mineo, R; Salanitri, FP; Bellitto, G; Kavasidis, I; De Filippo, O; Millesimo, M; De Ferrari, GM; Aldinucci, M; Giordano, D; Palazzo, S; D'Ascenzo, F; Spampinato, C","A Convolutional-Transformer Model for FFR and iFR Assessment From Coronary Angiography","IEEE TRANSACTIONS ON MEDICAL IMAGING","","0278-0062","10.1109/TMI.2024.3383283","","The quantification of stenosis severity from X-ray catheter angiography is a challenging task. Indeed, this requires to fully understand the lesion's geometry by analyzing dynamics of the contrast material, only relying on visual observation by clinicians. To support decision making for cardiac intervention, we propose a hybrid CNN-Transformer model for the assessment of angiography-based non-invasive fractional flow-reserve (FFR) and instantaneous wave-free ratio (iFR) of intermediate coronary stenosis. Our approach predicts whether a coronary artery stenosis is hemodynamically significant and provides direct FFR and iFR estimates. This is achieved through a combination of regression and classification branches that forces the model to focus on the cut-off region of FFR (around 0.8 FFR value), which is highly critical for decision-making. We also propose a spatio-temporal factorization mechanisms that redesigns the transformer's self-attention mechanism to capture both local spatial and temporal interactions between vessel geometry, blood flow dynamics, and lesion morphology. The proposed method achieves state-of-the-art performance on a dataset of 778 exams from 389 patients. Unlike existing methods, our approach employs a single angiography view and does not require knowledge of the key frame; supervision at training time is provided by a classification loss (based on a threshold of the FFR/iFR values) and a regression loss for direct estimation. Finally, the analysis of model interpretability and calibration shows that, in spite of the complexity of angiographic imaging data, our method can robustly identify the location of the stenosis and correlate prediction uncertainty to the provided output scores.","2024-08","2025-02-26 20:39:14","2025-02-26 20:39:14","","2866-2877","","8","43","","","","","","","","","","English","","","","WOS:001285367200024","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","Analytical models; Angiography; ATTENTION; Attention methods; coronary angiography; coronary stenosis quantification; Feature extraction; FRACTIONAL FLOW RESERVE; QUANTIFICATION; Solid modeling; STENOSIS; Three-dimensional displays; Transformers; Visualization; WAVE-FREE RATIO","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9WJQ4AK8","journalArticle","2023","Ehab, M; Tawfik, MA; Munir, MU; Ahmed, A; Park, JH","ISM-Band Frequency Transformer Modeling for Isolated High-Power Conversions","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2023.3261921","","In the last few years, the switching frequency of power electronic converters have been extended to the several MHz range. Industrial, scientific, and medical (ISM) frequency bands are specified in this range for power electronic applications. Most converter circuits, such as resonance and soft-switching circuits, require an accurate modeling of the circuit components, such as high-frequency inductors and transformers. This article focuses on the evaluation of a practically simple but accurate high-frequency transformer model. At first, a three-capacitor lumped model is chosen due to its simplicity, as well as the physics-oriented concept. Furthermore, the extraction of the parameters is straightforward. It is found that splitting the leakage inductances into two halves based on the winding capacitance would make the model more accurate for modeling high-frequency characteristics. The article analyzes the model and provides a closed-form transfer function for the input impedance and the voltage gain. To verify the model, different kinds of transformer hardware are fabricated, and their input impedances are measured from 1 to 30 MHz, which includes three ISM bands. The measurements are then compared with the impedance function developed from the model. The model is shown matching well with the measurement as compared to the conventional models. Finally, the model is validated experimentally by designing an isolated 13.56 MHz Class-E power conversion circuit, which includes a transformer with soft switching. The soft switching is designed based on the conventional, three-capacitor model and the proposed model, respectively. The proposed model provides a more accurate design for the inverter, assuring soft switching and optimum performance of the circuit.","2023","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","72","","","","","","","","","","English","","","","WOS:000965103200024","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","Analytical models; Capacitance; CIRCUIT; High-frequency transformer model; Inductance; industrial; input impedance; Integrated circuit modeling; isolated Class-E resonant inverter; Mathematical models; medical (ISM) bands; scientific; Transformers; voltage gain; Windings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IGX9783S","journalArticle","2024","Liu, YX; Su, QQ","PPTIF: Privacy-Preserving Transformer Inference Framework for Language Translation","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3384268","","The Transformer model has emerged as a prominent machine learning tool within the field of natural language processing. Nevertheless, running the Transformer model on resource-constrained devices presents a notable challenge that needs to be addressed. Although outsourcing services can significantly reduce the computational overhead associated with using the model, it also incurs privacy risks to the provider's proprietary model and the client's sensitive data. In this paper, we propose an efficient privacy-preserving Transformer inference framework (PPTIF) for language translation tasks based on three-party replicated secret-sharing techniques. PPTIF offers a secure approach for users to leverage Transformer-based applications, such as language translation, while maintaining the confidentiality of their original input and inference results, thereby preventing any disclosure to the cloud server. Meanwhile, PPTIF ensures robust protection for the model parameters, guaranteeing their integrity and confidentiality. In PPTIF, we design a series of interaction protocols to implement the secure computation of Transformer components, namely secure Encoder and secure Decoder. To improve the efficiency of PPTIF, we optimize the computation of the Scaled Dot-Product Attention (Transformer's core operation) under secret sharing, effectively reducing its computation and communication overhead. Compared with Privformer, the optimized Masked Multi-Head Attention achieves about 1.7x lower runtime and 2.3x lower communication. In total, PPTIF achieve about 1.3x lower runtime and 1.2x lower communication. The effectiveness and security of PPTIF have been rigorously evaluated through comprehensive theoretical analysis and experimental validation.","2024","2025-02-26 20:39:14","2025-02-26 20:39:14","","48881-48897","","","12","","","","","","","","","","English","","","","WOS:001199956200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Computational modeling; Cryptography; Data models; Homomorphic encryption; Neural networks; NEURAL-NETWORK INFERENCE; Outsourcing; Privacy; Privacy-preserving; Protocols; replicated secret-sharing; secure multi-party computation; secure outsourcing; SYSTEM; Task analysis; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HY3WFLWW","journalArticle","2024","Hu, HX; Hu, Q; Tan, GP; Zhang, Y; Lin, ZZ","A Multi-Layer Model Based on Transformer and Deep Learning for Traffic Flow Prediction","IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS","","1524-9050","10.1109/TITS.2023.3311397","","Using traffic data to accurately predict the traffic flow at a certain time in the future can alleviate problems such as traffic congestion, which plays an important role in the healthy transportation and economic development of cities. However, current traffic flow prediction models rely on human experience and only consider the advantages of single machine learning model. Therefore, in this work, we propose a multi-layer model based on transformer and deep learning for traffic flow prediction (MTDLTFP). The MTDLTFP model first draws on the idea of transformer model, which uses multiple encoders and decoders to perform feature extraction on the initial traffic data without human experience. In addition, in the prediction stage, the MTDLTFP model using deep learning technology, which input the hidden features into the convolutional neural network (CNN) and multi-layer feedforward neural network (MFNN) to obtain the prediction score respectively. The CNN model can captures the correlation information between the hidden features, and the MFNN can captures the nonlinear relationship between the features. Finally, we use a linear model to combine the two prediction scores, which can make the final prediction value take into account the common advantages of both models. Multiple experimental results on two real datasets demonstrate the effectiveness of the MTDLTFP model. The experimental results on the WorkDay dataset are as follows, with the RMSE value of 0.191, MAE value of 0.165. The experimental results on the HoliDay dataset are as follows, with RMSE value of 0.227, MAE value of 0.192.","2024-01","2025-02-26 20:39:14","2025-02-26 20:39:14","","443-451","","1","25","","","","","","","","","","English","","","","WOS:001078397500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Computational modeling; convolutional neural network; Data models; deep learning; Deep learning; Feature extraction; Mathematical models; multi-layer model; Predictive models; Traffic flow prediction; transformer model; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D42V2B2K","journalArticle","2023","Li, CJ; Shi, ZH; Zhou, L; Zhang, ZJ; Wu, CW; Ren, XY; Hei, XH; Zhao, MH; Zhang, YT; Liu, HQ; You, ZZ; He, LF","TFFormer: A Time-Frequency Information Fusion-Based CNN-Transformer Model for OSA Detection With Single-Lead ECG","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2023.3312472","","Accurate detection of obstructive sleep apnea (OSA) with a single-lead electrocardiogram (ECG) signal is highly desirable for the timely treating of OSA patients. However, due to the variance of apneas in appearance and size in ECG signals, it is still a very challenging task to obtain an accurate OSA apnea detection. To address this problem, this article presents a time-frequency information fusion-based CNN-Transformer model (TFFormer) for OSA detection with single-lead ECG, in which a module consisting of a deep residual shrinkage module, a multiscale convolutional attention (MSCA) module, and a multilayer convolution module is developed for time-frequency feature extraction. The purpose of this operation is to extract rich features from a short length of ECG signal sequences with a low computation cost. For time-frequency information fusion, to reduce its computation cost, a gated self-attention-based adaptive pruning time-frequency information fusion attention module is developed to prune the redundant tokens. With the attention-based adaptive pruning time-frequency information fusion module, the TFFormer is constructed for data-parallel processing and long-distance modeling. Compared with the best model in the comparative method, the accuracy of the proposed method was improved by 0.18% in the segmented case, and the mean absolute error was reduced by 0.25 per-recorded case, which demonstrates that the TFFormer model has better OSA detection performance and could provide a convenient and accurate solution for clinical OSA detection.","2023","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","72","","","","","","","","","","English","","","","WOS:001070721800005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Adaptive pruning time-frequency information fusion attention module; electrocardiogram (ECG); multiscale convolutional attention (MSCA) module; obstructive sleep apnea (OSA); SLEEP-APNEA DETECTION; time-frequency information fusion-based CNNTransformer (TFFormer) model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WKXMP6RG","journalArticle","2023","Bommidi, BS; Teeparthi, K; Kosana, V","Hybrid wind speed forecasting using ICEEMDAN and transformer model with novel loss function","ENERGY","","0360-5442","10.1016/j.energy.2022.126383","","Wind energy technologies have been investigated extensively due to worldwide environmental challenges and rising energy demand. Therefore, accurate and reliable wind speed forecasts are essential for large scale wind power integration. But seasonal and stochastic winds make forecasting difficult. Hence, this study proposes a novel loss function-based hybrid deep learning architecture for the wind speed forecasting (WSF). The proposed hybrid model is developed using the improved complete ensemble empirical mode decomposition with adaptive noise (ICEEMDAN) decomposition method for the denoising wind speed data, and transformer network (TRA) with a novel Kernel MSE loss function (NLF) for the WSF (NLF-ICEEMDAN-TRA). As the MSE loss function is sensitive to outliers and fails to identify the non-linear characteristics in wind speed data, a novel kernel MSE loss function has been used for the training of the transformer network. Wind speed data from two wind farms located in Block Island and the Gulf Coast have been used to validate the effectiveness of the proposed hybrid model. Because current WSF methods performance declines as the time ahead rises, the proposed hybrid model is verified using eight time horizons: 5 min, 10 min, 15 min, 30 min, 1 h, 2 h, 24 h and 48 h ahead WSF. To investigate the performance of proposed hybrid model in WSF, six individual WSF models, six hybrid WSF models, and six NLF based hybrid WSF models are employed for comparative analysis. The experimental results demonstrated that the proposed hybrid model achieved the best results for all eight time horizon WSF for both wind farm sites, with a significant improvement.","2023-02-15","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","265","","","","","","","","","","English","","","","WOS:000906752100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;71<br/>Total Times Cited:&nbsp;&nbsp;72<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Decomposition; DECOMPOSITION; ENSEMBLE; Forecasting; FRAMEWORK; Kernel loss function; LSTM; PREDICTION; RECURRENT NEURAL-NETWORKS; SPECTRUM; TERM-MEMORY NETWORK; Transformer model; Wind speed","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IDY5X4DT","journalArticle","2024","Wang, T; Li, JW; Sun, CY","DeHi: A Decoupled Hierarchical Architecture for Unaligned Ground-to-Aerial Geo-Localization","IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY","","1051-8215","10.1109/TCSVT.2023.3293514","","Ground-to-aerial (G2A) geo-localization remains extremely challenging due to the drastic appearance and geometry differences between ground and aerial views, especially when their relative orientation is unknown. In this paper, we focus on the challenging problem of unaligned G2A geo-localization, where the query ground-level image is not perfectly orientation-aligned with respect to reference aerial imagery. We cast this problem as a metric embedding task and propose a decoupled hierarchical (DeHi) architecture to progressively learn meaningful multi-grained features. Specifically, DeHi first leverages CNN to extract high-level semantic features, and then introduces a novel orthogonally factorized transformer model consisting of part-level and global transformer encoders to learn part-level and global feature descriptors sequentially. For the purpose of enhancing representation power, cross-level connections are introduced to enrich part-level and global descriptors by CNN features, and the pooled part-level descriptor is combined with the global descriptor to construct the final query representation. Furthermore, such a decoupled hierarchical architecture allows for incorporating multi-level deep supervision. We introduce two part-level losses combined with one cross-level loss to complement the widely used global retrieval loss. Extensive experiments on standard benchmark datasets show significant boosting in recall rates compared with the previous state-of-the-art. Remarkably, DeHi improves the recall rate @top-1 from 78.59% to 82.38% (+3.79%) and from 72.91% to 77.94% (+5.03%) on CVUSA and CVACT datasets, respectively, under random orientation misalignments. Besides, DeHi maintains competitive inference efficiency with less parameters compared to existing transformer-based methods.","2024-03","2025-02-26 20:39:14","2025-02-26 20:39:14","","1927-1940","","3","34","","","","","","","","","","English","","","","WOS:001179365000010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Computational modeling; Computer architecture; Convolutional neural networks; decoupled hierarchical architecture; factorized transformer model; Feature extraction; multi-level deep supervision; Sun; Task analysis; Transformers; Unaligned cross-view geo-localization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SVVFU7JL","journalArticle","2023","Cao, ZL; Magar, R; Wang, YY; Farimani, AB","MOFormer: Self-Supervised Transformer Model for Metal-Organic Framework Property Prediction","JOURNAL OF THE AMERICAN CHEMICAL SOCIETY","","0002-7863","10.1021/jacs.2c11420","","Metal-organic frameworks (MOFs) are materials with a high degree of porosity that can be used for many applications. However, the chemical space of MOFs is enormous due to the large variety of possible combinations of building blocks and topology. Discovering the optimal MOFs for specific applications requires an efficient and accurate search over countless potential candidates. Previous high-throughput screening methods using computational simulations like DFT can be time-consuming. Such methods also require the 3D atomic structures of MOFs, which adds one extra step when evaluating hypothetical MOFs. In this work, we propose a structure-agnostic deep learning method based on the Transformer model, named as MOFormer, for property predictions of MOFs. MOFormer takes a text string representation of MOF (MOFid) as input, thus circumventing the need of obtaining the 3D structure of a hypothetical MOF and accelerating the screening process. By comparing to other descriptors such as Stoichiometric-120 and revised autocorrelations, we demonstrate that MOFormer can achieve state-of-the-art structure-agnostic prediction accuracy on all benchmarks. Furthermore, we introduce a self-supervised learning framework that pretrains the MOFormer via maximizing the cross-correlation between its structure-agnostic representations and structure-based representations of the crystal graph convolutional neural network (CGCNN) on >400k publicly available MOF data. Benchmarks show that pretraining improves the prediction accuracy of both models on various downstream prediction tasks. Furthermore, we revealed that MOFormer can be more data-efficient on quantum-chemical property prediction than structure-based CGCNN when training data is limited. Overall, MOFormer provides a novel perspective on efficient MOF property prediction using deep learning.","2023-01-27","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","","","","","","","","","","","English","","","","WOS:000924951900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;63<br/>Total Times Cited:&nbsp;&nbsp;63<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","ADSORPTION; DISCOVERY; LANGUAGE; SOFTWARE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A5WJ2G5J","journalArticle","2021","Ferreira, RSD; Picher, P; Ezzaidi, H; Fofana, I","Frequency Response Analysis Interpretation Using Numerical Indices and Machine Learning: A Case Study Based on a Laboratory Model","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2021.3076154","","Frequency response analysis is a powerful tool for mechanical fault diagnostics in power transformers. However, interpretation schemes still today depend on expert analyses, mainly because of the complex structure of power transformers. One of the fundamental shortcomings of experimental investigations is that mechanical deformations cannot be managed on real transformers to obtain data for different scenarios because they are too destructive. To address this issue in a systematic way, the current research used a specially designed laboratory transformer model that allows mechanical defects to be introduced so its frequency response can be evaluated under different conditions. The key feature of this model is the non-destructive interchangeability of its winding sections, allowing reproducibility and repeatability of frequency response measurements. Numerical indices were compared over key performance indicators (linearity, sensitivity and monotonicity). The analysis indicated that comparative standard deviation offered promising results for evaluation of mechanical deformations on the laboratory winding model given its monotonic behaviour, sensitivity and linear increase with fault severity. Additionally, support vector machine learning, radial basis function neural network and the statistical k-nearest neighbour method were used for fault classification with different strategies and configurations. While limited data from different transformers are used in the available literature, the approach discussed here considers 371 measurements from the same transformer model. The test results are supportive and demonstrate great accuracy when machine learning is used for winding fault classification.","2021","2025-02-26 20:39:14","2025-02-26 20:39:14","","67051-67063","","","9","","","","","","","","","","English","","","","WOS:000648327800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Condition monitoring; Current measurement; Frequency measurement; Frequency response; frequency response analysis interpretation; Indexes; machine learning; numerical indices; Numerical models; Power transformer insulation; power transformers; radial basis function; STATE; support vector machines; TRANSFORMER FRA RESPONSES; Windings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W5GFZTR3","journalArticle","2024","Lee, DG; Ahn, KH","Improving medium-range streamflow forecasts over South Korea with a dual-encoder transformer model","JOURNAL OF ENVIRONMENTAL MANAGEMENT","","0301-4797","10.1016/j.jenvman.2024.122114","","Accurate and reliable hydrological forecasts play a pivotal role in ensuring water security, facilitating flood preparedness, and supporting agriculture activities. This study investigates the potential of hydrological forecasting in South Korea, focusing on medium-range lead times ranging from 1 to 10 days. The methodology involves leveraging a Transformer neural network, a model entirely based on attention mechanisms. Specifically, our study introduces the Dualformer, a dual-encoder-based transformer model capable of accommodating two distinct datasets: historical and forecast meteorological data. The performance of this proposed model, along with its variants designed to test specific structural aspects, is evaluated in predicting daily streamflow across 473 grid cells covering extensive regions within the study area. Furthermore, the proposed model is assessed against the performance of a recently developed approach aiming for the same objective. These models are trained using historical meteorological variables and geographic characteristics, alongside the Global Ensemble Forecast System, version 12 (GEFSv12) reforecasts, in addition to historical runoff. The results indicate that our proposed model performs competitively, especially for relatively short lead times while effectively managing information from two distinct data sources. For instance, the mean Nash-Sutcliffe efficiency for 473 grids is 0.664 for the first one-day lead when using the Dualformer, whereas the benchmark model achieves a score of 0.535. Additionally, we observe an additional enhancement in Dualformer's performance when utilizing a larger dataset. Finally, we conclude this paper with a discussion regarding potential improvements to the forecast model through the incorporation of additional input and modeling structures.","2024-09","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","368","","","","","","","","","","English","","","","WOS:001292613400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","BASIN; CLIMATE; Dualformer; DYNAMICAL CORE; FUTURE; Hydrological forecasting; IMPACTS; MANAGEMENT; Medium-range forecasing; PREDICTION; RAINFALL; SKILL; Transformer neural network; UNCERTAINTY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HAEFUXU2","journalArticle","2024","Özbay, E","Gastrointestinal Tract Disease Classification Using Residual-Inception Transformer With Wireless Capsule Endoscopy Images Segmentation","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3522009","","One of the leading causes of cancer-related mortality in affluent nations is Colorectal Cancer (CRC). Gastrointestinal (GI) disorders pose a severe hazard to human health and are frequently managed through invasive operations. Accurately and early CRC diagnosis is crucial for the course of treatment. Experts can determine characteristics in the human GI tract using an endoscope to look for infections or even potential CRC indications. However, in the research done so far, the desired accuracy value could not be attained. In this study, the approach of segmenting GI tract regions in Wireless Capsule Endoscopy (WCE) scans was used together with a long-range transformer model. In order to produce local information with surrounding pixels and patches in the architecture, embedding a split token method is applied to the transformer block. To diversity model training effectiveness and capture intricate anatomical details of the GI tract, feature learning with a cross-channel technique was used along with the Residual block and Inception module. The proposed framework was tested with experiments on the WCE Curated Colon Disease (WCECCD) dataset, which contains a total of 4 classes of images, including 3 different GI tract diseases and normal. The proposed model reached 99.50% accuracy performance. The proposed approach outperformed current state-of-the-art techniques, according to experimental results. This transformer model, developed together with GI tract image segmentation, is making significant progress in the field and become a more precise and effective tool for experts.","2024","2025-02-26 20:39:14","2025-02-26 20:39:14","","197988-197998","","","12","","","","","","","","","","English","","","","WOS:001386558700033","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Accuracy; ALGORITHM; DIAGNOSIS; Diseases; Endoscopes; Endoscopy; Esophagus; Feature extraction; FEATURES; gastrointestinal disorders; Gastrointestinal tract; Image segmentation; residual-inception; SCALE; segmentation; Training; Transformers; Ulcerative colitis; vision transformer; WCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FGDEKSTQ","journalArticle","2024","Zaman, K; Samiul, IJAM; Sah, M; Direkoglu, C; Okada, S; Unoki, M","Hybrid Transformer Architectures With Diverse Audio Features for Deepfake Speech Classification","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3478731","","The rise of synthetic speech technologies has triggered growing concerns about the increasing difficulty in distinguishing between real and fake voices. In this context, we propose novel hybrid transformer-based models together with different audio feature analysis techniques and achieved the state-of-the-art results. To the best of our knowledge, none of the existing methods have considered combining various hybrid transformer models together with different audio features for fake speech classification, which forms the main novelty of our work. In our work, transformer models are compared with hybrid transformer architectures including Convolutional Neural Network (CNN)-Transformer (i.e., ResNet34- Transformer and VGG16-Transformer models), Bi-directional Long Short-Term Memory (Bi-LSTM)- Transformer, and Transformer with Support Vector Machine (SVM) using different audio feature extraction techniques. In our approach, we utilize three audio attribute extraction techniques: Mel spectrogram (Mel), Mel Frequency Cepstral Coefficient (MFCC), and Short-Time Fourier Transform (STFT) as input representations. The results of our evaluation with instances of real and fake speech using the ASVspoof LA dataset with hybrid transformer models across various audio features indicate that the STFT feature performs best with the ResNet34-Transformer model, achieving a state-of-the-art performance with a development set equal error rate (EER) of 0.0% and evaluation set EER of 3.22%, surpassing all other methods. In terms of accuracy, the STFT feature also performed best with the VGG16-Transformer model, achieving a development set accuracy of 99.55% and an evaluation set accuracy of 94.04%. These results indicate that the proposed study achieved better performance compared to the baseline and state-of-the-art methods.","2024","2025-02-26 20:39:14","2025-02-26 20:39:14","","149221-149237","","","12","","","","","","","","","","English","","","","WOS:001339071900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","CNN-Transformer; features; fusion models; ResNet-Transformer; Transformer; Transformer- SVM; VGG16-Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YX4HBJAH","journalArticle","2023","Gao, K; Li, XH; Chen, B; Hu, L; Liu, J; Du, RH; Li, YF","Dual Transformer Based Prediction for Lane Change Intentions and Trajectories in Mixed Traffic Environment","IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS","","1524-9050","10.1109/TITS.2023.3248842","","In a mixed traffic environment of human and autonomous driving, it is crucial for an autonomous vehicle to predict the lane change intentions and trajectories of vehicles that pose a risk to it. However, due to the uncertainty of human intentions, accurately predicting lane change intentions and trajectories is a great challenge. Therefore, this paper aims to establish the connection between intentions and trajectories and propose a dual Transformer model for the target vehicle. The dual Transformer model contains a lane change intention prediction model and a trajectory prediction model. The lane change intention prediction model is able to extract social correlations in terms of vehicle states and outputs an intention probability vector. The trajectory prediction model fuses the intention probability vector, which enables it to obtain prior knowledge. For the intention prediction model, the accuracy can be improved by designing the multi-head attention. For the trajectory prediction model, the performance can be optimized by incorporating intention probability vectors and adding the LSTM. Verified on NGSIM and highD datasets, the experimental results show that this model has encouraging accuracy. Compared with the model without intention probability vectors, the impact of the model on NGSIM dataset and highD dataset in RMSE is improved by 57.27% and 58.70% respectively. Compared with two existed models, evaluation metrics of the intention prediction can be improved by 7.40-10.09% on NGSIM dataset and 2.17-2.69% on highD dataset within advanced prediction time 1s. This method provides the insights for designing advanced perceptual systems for autonomous vehicles.","2023-06","2025-02-26 20:39:14","2025-02-26 20:39:14","","6203-6216","","6","24","","","","","","","","","","English","","","","WOS:000947767400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;37<br/>Total Times Cited:&nbsp;&nbsp;41<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Adaptation models; Atmospheric modeling; Autonomous vehicles; Feature extraction; highD; intention prediction; Mixed traffic environment; NGSIM; Predictive models; Trajectory; trajectory prediction; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YBULJNTA","journalArticle","2024","Li, JJ; Han, J; Niu, DP; Jiang, XZ","Fast and accurate gas turbine emission prediction based on a light and enhanced Transformer model","FUEL","","0016-2361","10.1016/j.fuel.2024.132750","","Gas turbine emissions, such as nitrogen oxides (NOx) NO x ) and carbon monoxide (CO) can cause serious environmental problems. Fast and accurate prediction of NOx x and CO is of great significance to mitigate emissions. In this study, a light and enhanced Transformer model was proposed to predict CO and NOx x emissions from gas turbines. The model adopted the backbone of the encoder from a Transformer network and improved the encoder by incorporating a causal convolutional module. The incorporation of the causal convolution module allows the encoder to extract global and deep features from rich contextual information and guarantees an accurate prediction of the gas turbine emissions. A regularization term was introduced in the prediction module to prevent the network from overfitting. Deactivation operations which randomly drop out data from every individual hidden layer were implemented to accelerate the convergence of data and to increase the generalization ability of the model. The mean absolute error (MAE) and root-mean-square-error (RMSE) of the NOx x emission predicted by the present model are 1.3748 and 1.9948, respectively; the MAE and RMSE of the CO emission predicted by the present model are 0.3954 and 0.6379, respectively. Such evaluation metrics are lower than those predicted by previous models, showcasing the superior predicting performance of the present model. The proposed model also outstands in the execution time, in comparison with the long short-term memory network and convolutional neural network (two widely used neural networks). This study provides a brand-new way to construct network for emission prediction.","2024-11-15","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","376","","","","","","","","","","English","","","","WOS:001294878300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Causal convolution module; Encoder module; Gas turbine emissions; INTERNET; K-nearest neighbor; MACHINE; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5KLNAEP2","journalArticle","2024","Moroto, Y; Maeda, K; Togo, R; Ogawa, T; Haseyama, M","Multimodal Transformer Model Using Time-Series Data to Classify Winter Road Surface Conditions","SENSORS","","1424-8220","10.3390/s24113440","","This paper proposes a multimodal Transformer model that uses time-series data to detect and predict winter road surface conditions. For detecting or predicting road surface conditions, the previous approach focuses on the cooperative use of multiple modalities as inputs, e.g., images captured by fixed-point cameras (road surface images) and auxiliary data related to road surface conditions under simple modality integration. Although such an approach achieves performance improvement compared to the method using only images or auxiliary data, there is a demand for further consideration of the way to integrate heterogeneous modalities. The proposed method realizes a more effective modality integration using a cross-attention mechanism and time-series processing. Concretely, when integrating multiple modalities, feature compensation through mutual complementation between modalities is realized through a feature integration technique based on a cross-attention mechanism, and the representational ability of the integrated features is enhanced. In addition, by introducing time-series processing for the input data across several timesteps, it is possible to consider the temporal changes in the road surface conditions. Experiments are conducted for both detection and prediction tasks using data corresponding to the current winter condition and data corresponding to a few hours after the current winter condition, respectively. The experimental results verify the effectiveness of the proposed method for both tasks. In addition to the construction of the classification model for winter road surface conditions, we first attempt to visualize the classification results, especially the prediction results, through the image style transfer model as supplemental extended experiments on image generation at the end of the paper.","2024-06","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","11","24","","","","","","","","","","English","","","","WOS:001245739400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","deep learning; GENERATIVE ADVERSARIAL NETWORKS; multimodal analysis; time-series processing; transformer; winter road surface condition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NRLXL5EY","journalArticle","2022","Bai, J; Wen, Z; Xiao, Z; Ye, FW; Zhu, YD; Alazab, M; Jiao, LC","Hyperspectral Image Classification Based on Multibranch Attention Transformer Networks","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2022.3196661","","Deep learning (DL) has become a mainstream method of hyperspectral image (HSI) classification. Many DL-based methods exploit spatial-spectral features to achieve better classification results. However, due to the complex backgrounds in HSIs, existing methods usually show unsatisfactory performance for the class pixels located on the land-cover category boundary area. In large part, this is because the network is susceptible to interference by the irrelevant information around the target pixel in the training stage, resulting in inaccurate feature extraction. In this article, a new multibranch transformer architecture (spectral spatial transformer (SST)-M) that assembles spatial attention and extracts spectral features is proposed to address this problem. The transformer model has a global receptive field and thus can integrate global spatial position information in the HSI cube. Meanwhile, we design a spatial sequence attention model to enhance the useful spatial location features and weaken invalid information. Considering that HSIs contain considerable spectral information, a spectral feature extraction model is designed to extract discriminative spectral features, replacing the widely used principal component analysis (PCA) method and obtaining better classification results than it. Finally, inspired by semantic segmentation, a mask prediction model is designed to classify all of the pixels in the HSI cube; this guides the neural network to learn precise pixel characteristics and spatial distributions. To verify the effectiveness of our algorithm (SST-M), quantitative experiments were conducted in three well-known datasets, namely, Indian Pines (IP), University of Pavia (PU), and Kennedy Space Center (KSC). The experimental results demonstrate that the proposed model achieves better performance than the other state-of-the-art methods.","2022","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","60","","","","","","","","","","English","","","","WOS:000843314100007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;44<br/>Total Times Cited:&nbsp;&nbsp;44<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","CNN; Convolution; Convolutional neural networks; Deep learning (DL); Feature extraction; hyperspectral image classification (HSIC); Hyperspectral imaging; multibranch prediction; REPRESENTATION; self-attention (SA) mechanism; spatial attention; Three-dimensional displays; Training; transformer model; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F4HFAZX3","journalArticle","2025","Dong, QY; Chen, ZW; Li, RP; Yang, ZY; Gao, F; Chen, YH; Xia, F; Zhong, W; Zhao, ZF","Adapted Swin Transformer-based real-time plasma shape detection and control in HL-3","NUCLEAR FUSION","","0029-5515","10.1088/1741-4326/ada2fe","","In the field of magnetic confinement plasma control, the accurate feedback of plasma position and shape primarily relies on calculations derived from magnetic measurements through equilibrium reconstruction or matrix mapping method. However, under harsh conditions like high-energy neutron radiation and elevated temperatures, the installation of magnetic probes within the device becomes challenging. Relying solely on external magnetic probes can compromise the precision of EFIT in determining the plasma shape. To tackle this issue, we introduce a real-time, non-magnetic measurement method on the HL-3 tokamak, which diagnoses the plasma position and shape via imaging. Particularly, we put forward an adapted Swin Transformer model, the Poolformer Swin Transformer (PST), to accurately and fastly interpret the plasma shape from the Charge-Coupled Device Camera images. By adopting multi-task learning and knowledge distillation techniques, the model is capable of robustly detecting six shape parameters under visual interference conditions such as bright light from the divertor and gas injection, thereby avoiding cumbersome manual labeling. Specifically, the well-trained PST model capably infers R and Z within the mean average error below 1.1 cm and 1.8 cm, respectively, while requiring less than 2 ms for end-to-end feedback, an 80% improvement over the smallest Swin Transformer model, laying the foundation for real-time control. Finally, we deploy the PST model in the Plasma Control System using TensorRT, and achieve 500 ms stable PID feedback control based on the PST-computed horizontal displacement information. In conclusion, this research opens up new avenues for the practical application of image-computing plasma shape diagnostic methods in the realm of real-time feedback control.","2025-02-01","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","2","65","","","","","","","","","","English","","","","WOS:001391204600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","HL-3 tokamak; real-time; RECONSTRUCTION; shape detection and control; Swin Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H647T4Y6","journalArticle","2024","Tougui, I; Zakroum, M; Karrakchou, O; Ghogho, M","Transformer-based transfer learning on self-reported voice recordings for Parkinson's disease diagnosis","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-81824-x","","Deep learning (DL) techniques are becoming more popular for diagnosing Parkinson's disease (PD) because they offer non-invasive and easily accessible tools. By using advanced data analysis, these methods improve early detection and diagnosis, which is crucial for managing the disease effectively. This study explores end-to-end DL architectures, such as convolutional neural networks and transformers, for diagnosing PD using self-reported voice data collected via smartphones in everyday settings. Transfer learning was applied by starting with models pre-trained on large datasets from the image and the audio domains and then fine-tuning them on the mPower voice data. The Transformer model pre-trained on the voice data performed the best, achieving an average AUC of \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$95.89\%$$\end{document} and an average AUPRC of \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$87.11\%$$\end{document}, outperforming models trained from scratch. To the best of our knowledge, this is the first use of a Transformer model for audio data in PD diagnosis, using this dataset. We achieved better results than previous studies, whether they focused solely on the voice or incorporated multiple modalities, by relying only on the voice as a biomarker. These results show that using self-reported voice data with state-of-the-art DL architectures can significantly improve PD prediction and diagnosis, potentially leading to better patient outcomes.","2024-12-03","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","1","14","","","","","","","","","","English","","","","WOS:001369783000035","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Deep learning; Fine-tuning; IMPAIRMENT; Parkinson's disease; SPEECH; Transfer learning; Transformers; Voice data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DTKISCW3","journalArticle","2024","Jiang, HW; Mutahira, H; Park, U; Muhammad, MS","Scanning dial: the instantaneous audio classification transformer","DISCOVER APPLIED SCIENCES","","3004-9261","10.1007/s42452-024-05731-6","","A number of remarkable accomplishments have been achieved in the field of audio classification using algorithms based on Transformers in recent years. As addressed in the literature, sound classification commonly involves the analysis of audio recordings that are usually five seconds or longer in duration. This raises a secondary question: Can Transformers effectively classify extremely short audio samples? The main objective of this study is to utilize the Transformer model for sound classification, focusing on extremely brief audio clips, with an average sound duration of 1.24 x 10 - 2 \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$1.24\times 10<^>{-2}$$\end{document} seconds, which is too short for human recognition. In addition, a new filter is developed to obtain an instantaneous audio dataset. This filter is applied individually to the ESC-50, UrbanSound8K, AESDD, ReaLISED and RAVDESS datasets to obtain corresponding instantaneous datasets. Moreover, a new data augmentation technique is introduced with the objective of increasing classification accuracy. A comparative analysis between the proposed scheme and the mainstream data augmentation methods is performed on the instantaneous audio datasets, resulting in accuracy rates of 94.16%, 96.40%, 70.98%, 89.28%, and 53.51%, respectively. This study has the main advantage of being able to classify sounds efficiently for extremely short audio duration. The proposed method filters out the muted part from the audio files, resulting in a new dataset called as instantaneous audio dataset. A novel data augmentation technique and an adapted Transformer model are proposed for the effective classification of short audio. This algorithm can effectively classify sounds within extremely short audio durations, which makes it useful for situations requiring swift decision-making.","2024-02","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","3","6","","","","","","","","","","English","","","","WOS:001178827900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Data augmentation; Instantaneous audio classification; Instantaneous audio dataset; RECOGNITION; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PX32X8HK","journalArticle","2024","Ke, FC; Wang, WQ; Tan, WC; Du, L; Jin, YN; Huang, YJ; Yin, HZ","HiTSKT: A hierarchical transformer model for session-aware knowledge tracing","KNOWLEDGE-BASED SYSTEMS","","0950-7051","10.1016/j.knosys.2023.111300","","Knowledge tracing (KT) aims to leverage students' learning histories to estimate their mastery levels on a set of pre-defined skills, based on which the corresponding future performance can be accurately predicted. In practice, a student's learning history comprises answers to sets of massed questions, each known as a session, rather than merely being a sequence of independent answers. Theoretically, within and across these sessions, students' learning dynamics can be very different. Therefore, how to effectively model the dynamics of students' knowledge states within and across the sessions is crucial for handling the KT problem. Most existing KT models treat student's learning records as a single continuing sequence, without capturing the sessional shift of students' knowledge state. To address the above issue, we propose a novel hierarchical transformer model, named HiTSKT, comprises an interaction(-level) encoder to capture the knowledge a student acquires within a session, and a session(-level) encoder to summarize acquired knowledge across the past sessions. To predict an interaction in the current session, a knowledge retriever integrates the summarized past-session knowledge with the previous interactions' information into proper knowledge representations. These representations are then used to compute the student's current knowledge state. Additionally, to model the student's long-term forgetting behaviour across the sessions, a power-law-decay attention mechanism is designed and deployed in the session encoder, allowing it to emphasize more on the recent sessions. Extensive experiments on four public datasets demonstrate that HiTSKT achieves new state-of-the-art performance on all the datasets compared with seven state-of-the-art KT models.","2024-01-25","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","284","","","","","","","","","","English","","","","WOS:001144496600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Educational data mining; Hierarchical transformer; Knowledge tracing; Learner modelling; MEMORY; RETRIEVAL PRACTICE; User behaviour modelling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5Q35MKSZ","journalArticle","2023","Banerjee, S; Mukherjee, S; Bandyopadhyay, S; Pakray, P","An extract-then-abstract based method to generate disaster-news headlines using a DNN extractor followed by a transformer abstractor","INFORMATION PROCESSING & MANAGEMENT","","0306-4573","10.1016/j.ipm.2023.103291","","Generating news headlines has been one of the predominant problems in Natural Language Processing research. Modern transformer models, if fine-tuned, can present a good headline with attention to all the parts of a disaster-news article. A disaster-news headline generally focuses on the event, its effect, and the major impacts, which a transformer model lacks when generating the headline. The extract-then-abstract based method proposed in this article improves the performance of a state-of-the-art transformer abstractor to generate a good-quality disaster-news headline. In this work, a Deep Neural Network (DNN) based sentence extractor and a transformer-based abstractive summarizer work sequentially to generate a headline. The sentence extraction task is formulated as a binary classification problem where the DNN model is trained to generate two binary labels: one corresponding to the sentence similarity with ground truth headlines and the other corresponding to the presence of disaster and its impact related information in the sentence. The transformer model generates the headline from the sentences extracted by the DNN. ROUGE scores of the headlines generated using the proposed method are found to be better than the scores of the headlines generated directly from the original documents. The highest ROUGE 1, 2, and 3 score improvements are observed in the case of the Text-To-Text Transfer Transformer (T5) model by 17.85%, 38.13%, and 21.01%, respectively. Such improvements suggest that the proposed method can have a high utility for finding effective headlines from disaster related news articles.","2023-05","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","3","60","","","","","","","","","","English","","","","WOS:000927289200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Abstractive summarization; Extractive summarization; Headline generation; T5 transformer; Text summarization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZBEEHIQT","journalArticle","2023","Wang, SZ","A Stock Price Prediction Method Based on BiLSTM and Improved Transformer","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3296308","","How to maximize shareholder returns has always been a focus of research in the financial field. In order to improve the accuracy and stability of stock price prediction, this article proposes a new method, BiLSTM-MTRAN-TCN. Improve the transformer model and introduce TCN (Temporary Revo-lution Network) to construct a new transformer model (MTRAN-TCN), making it suitable for stock price prediction. This method consists of BiLSTM (Bi-directional Long Short-Term Memory) and MTRAN-TCN, which can fully utilize the advantages of the three models: BiLSTM, transformer and TCN. Transformer is good at obtaining full range distance information, but its ability to capture sequence information is weak. BiLSTM can capture bidirectional information in sequences, while TCN can capture sequence dependencies and improve the model's generalization ability. Not only did the improvement effect of the transformer and the effectiveness of introducing the BiLSTM model be verified, but the effectiveness of the method was also verified using 5 index stocks and 14 Shanghai and Shenzhen stocks. Compared with other existing methods in the literature, this method has the best fit on each index stock, and the R-2 of this method is the best in 85.7% of the stock dataset. RMSE decreases by 24.3% to 93.5%, and R-2 increases by 0.3% to 15.6%. In addition, this method has relatively stable prediction performance at different time periods and does not have timeliness issues. The results indicate that the BiLSTM-MTRAN-TCN method performs better in predicting stock prices, with high accuracy and generalization ability.","2023","2025-02-26 20:39:14","2025-02-26 20:39:14","","104211-104223","","","11","","","","","","","","","","English","","","","WOS:001079894300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","BiLSTM; deep learning; hybrid neural network; stock price prediction; TCN; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N6E6UR23","journalArticle","2023","Zhou, SH; Qin, L; Sun, H; Peng, B; Ruan, JJ; Wang, J; Tang, X; Wang, XL; Liu, KP","TransFNN: A Novel Overtemperature Prediction Method for HVDC Converter Valves Based on an Improved Transformer and the F-NN Algorithm","SENSORS","","1424-8220","10.3390/s23084110","","Appropriate cooling of the converter valve in a high-voltage direct current (HVDC) transmission system is highly significant for the safety, stability, and economical operation of a power grid. The proper adjustment of cooling measures is based on the accurate perception of the valve's future overtemperature state, which is characterized by the valve's cooling water temperature. However, very few previous studies have focused on this need, and the existing Transformer model, which excels in time-series predictions, cannot be directly applied to forecast the valve overtemperature state. In this study, we modified the Transformer and present a hybrid Transformer-FCM-NN (TransFNN) model to predict the future overtemperature state of the converter valve. The TransFNN model decouples the forecast process into two stages: (i) The modified Transformer is used to obtain the future values of the independent parameters; (ii) the relation between the valve cooling water temperature and the six independent operating parameters is fit, and the output of the Transformer is used to calculate the future values of the cooling water temperature. The results of the quantitative experiments showed that the proposed TransFNN model outperformed other models with which it was compared; with TransFNN being applied to predict the overtemperature state of the converter valves, the forecast accuracy was 91.81%, which was improved by 6.85% compared with that of the original Transformer model. Our work provides a novel approach to predicting the valve overtemperature state and acts as a data-driven tool for operation and maintenance personnel to use to adjust valve cooling measures punctually, effectively, and economically.","2023-04","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","8","23","","","","","","","","","","English","","","","WOS:000977583100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","clustering algorithm; converter valve; cooling system; HVDC; NETWORKS; time series prediction; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"43YHE65C","journalArticle","2023","Eunice, J; Andrew, J; Sei, Y; Hemanth, DJ","Sign2Pose: A Pose-Based Approach for Gloss Prediction Using a Transformer Model","SENSORS","","1424-8220","10.3390/s23052853","","Word-level sign language recognition (WSLR) is the backbone for continuous sign language recognition (CSLR) that infers glosses from sign videos. Finding the relevant gloss from the sign sequence and detecting explicit boundaries of the glosses from sign videos is a persistent challenge. In this paper, we propose a systematic approach for gloss prediction in WLSR using the Sign2Pose Gloss prediction transformer model. The primary goal of this work is to enhance WLSR's gloss prediction accuracy with reduced time and computational overhead. The proposed approach uses hand-crafted features rather than automated feature extraction, which is computationally expensive and less accurate. A modified key frame extraction technique is proposed that uses histogram difference and Euclidean distance metrics to select and drop redundant frames. To enhance the model's generalization ability, pose vector augmentation using perspective transformation along with joint angle rotation is performed. Further, for normalization, we employed YOLOv3 (You Only Look Once) to detect the signing space and track the hand gestures of the signers in the frames. The proposed model experiments on WLASL datasets achieved the top 1% recognition accuracy of 80.9% in WLASL100 and 64.21% in WLASL300. The performance of the proposed model surpasses state-of-the-art approaches. The integration of key frame extraction, augmentation, and pose estimation improved the performance of the proposed gloss prediction model by increasing the model's precision in locating minor variations in their body posture. We observed that introducing YOLOv3 improved gloss prediction accuracy and helped prevent model overfitting. Overall, the proposed model showed 17% improved performance in the WLASL 100 dataset.","2023-03","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","5","23","","","","","","","","","","English","","","","WOS:000947710400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","ASL-LEX; CNN; DATABASE; deep learning; gloss prediction; MULTISCALE; pose estimation; pose-based approach; sign language recognition; SIGN-LANGUAGE RECOGNITION; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J4E7FIXN","journalArticle","2024","Wang, ZX; He, XR; Bu, TZ; Pang, B; Guo, W; Tu, ZY; Zhang, ZQ; Xiao, XL; Yin, ZP; Huang, J; Wu, H","A Full-Process, Fine-Grained, and Quantitative Rehabilitation Assessment Platform Enabled by On-Skin Sensors and Multi-Task Gait Transformer Model","ADVANCED MATERIALS","","0935-9648","10.1002/adma.202408478","","Rehabilitation of patients with lower limb movement disorders is a gradual process, which requires full-process assessments to guide the implementation of rehabilitation plans. However, the current methods can only complete the assessment in one stage and lack objective and quantitative assessment strategies. Here, a full-process, fine-grained, and quantitative rehabilitation assessments platform (RAP) supported by on-skin sensors and a multi-task gait transformer (MG-former) model for patients with lower limb movement disorders is developed. The signal quality and sensitivity of on-skin sensor is improved by the synthesis of high-performance triboelectric material and structure design. The MG-former model can simultaneously perform multiple tasks including binary classification, multiclassification, and regression, corresponding to assessment of fall risk, walking ability, and rehabilitation progress, covering the whole rehabilitation cycle. The RAP can assess the walking ability of 23 hemiplegic patients, which has highly consistent results with the scores by the experienced physician. Furthermore, the MG-former model outputs fine-grained assessment results when performing regression task to track slight progress of patients that cannot be captured by conventional scales, facilitating adjustment of rehabilitation plans. This work provides an objective and quantitative platform, which is instructive for physicians and patients to implement effective strategy throughout the whole rehabilitation process. This work develops a full-process, fine-grained, and quantitative rehabilitation assessments platform (RAP) supported by on-skin sensors and a multi-task gait transformer model for patients with lower limb movement disorders. The RAP can perform multiple assessments including fall risk, walking ability, and rehabilitation progress, covering the whole process of rehabilitation and realizing objective and quantitative rehabilitation assessment. image","2024-11","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","46","36","","","","","","","","","","English","","","","WOS:001315939600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","full-process rehabilitation assessments; lower limb movement disorders; MG-former model; on-skin sensors; RECOGNITION; STROKE PATIENTS; WALKING","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"27535KEP","journalArticle","2025","Zhou, BF; Yin, Y; Wang, MF; Zhang, RJ; Zhang, Y; Guo, WH","Identification of strong motion record baseline drift based on Bayesian-optimized Transformer network","ACTA GEOPHYSICA","","1895-6572","10.1007/s11600-024-01460-x","","Research in earthquake engineering heavily relies on strong motion observation. The quality of strong motion records directly affects the reliability of earthquake disaster prevention, rapid reporting of seismic magnitude, earthquake early warning, and other areas. Currently, basic mathematical methods, such as zero-line adjustment and filtering, are commonly employed to ensure the quality of strong motion records. However, these methods often rely on subjective judgment based on human experience when dealing with abnormal waveforms in strong motion records, leading to relatively low efficiency. To address this challenge, this paper proposes an innovative Transformer model based on Bayesian optimization to efficiently identify baseline drift anomalies in strong motion records. By partitioning the strong motion record data from the 1999 Chi-Chi earthquake in Taiwan, China, into two categories: high-quality records (with minimal baseline drift) and low-quality records (with significant baseline drift), we extracted data with distinct features and inputted them into the proposed model for training. Data with distinct features were extracted and input into the proposed model for training. Finally, the model was used to predict whether strong motion records exhibited baseline drift abnormalities. The experimental results show that the optimized Transformer model achieves a performance exceeding 85% in key evaluation metrics such as accuracy and F1 scores. It is capable of efficiently identifying a substantial volume of strong motion records with baseline drift within a short period of time. The model effectively performs the baseline drift classification task for strong motion records and can be used for subsequent identification of abnormalities after baseline drift correction, enabling automation in handling abnormal data related to baseline drift.","2025-02","2025-02-26 20:39:14","2025-02-26 20:39:14","","517-525","","1","73","","","","","","","","","","English","","","","WOS:001329084600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Baseline drift; Bayesian optimization; GROUND-MOTION; Sequence classification; Strong motion record; Transformer network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FTBJ6XX5","journalArticle","2021","Jiang, ZC; Dong, ZX; Wang, LY; Jiang, WP","Method for Diagnosis of Acute Lymphoblastic Leukemia Based on ViT-CNN Ensemble Model","COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE","","1687-5265","10.1155/2021/7529893","","Acute lymphocytic leukemia (ALL) is a deadly cancer that not only affects adults but also accounts for about 25% of childhood cancers. Timely and accurate diagnosis of the cancer is an important premise for effective treatment to improve survival rate. Since the image of leukemic B-lymphoblast cells (cancer cells) under the microscope is very similar in morphology to that of normal B-lymphoid precursors (normal cells), it is difficult to distinguish between cancer cells and normal cells. Therefore, we propose the ViT-CNN ensemble model to classify cancer cells images and normal cells images to assist in the diagnosis of acute lymphoblastic leukemia. The ViT-CNN ensemble model is an ensemble model that combines the vision transformer model and convolutional neural network (CNN) model. The vision transformer model is an image classification model based entirely on the transformer structure, which has completely different feature extraction method from the CNN model. The ViT-CNN ensemble model can extract the features of cells images in two completely different ways to achieve better classification results. In addition, the data set used in this article is an unbalanced data set and has a certain amount of noise, and we propose a difference enhancement-random sampling (DERS) data enhancement method, create a new balanced data set, and use the symmetric cross-entropy loss function to reduce the impact of noise in the data set. The classification accuracy of the ViT-CNN ensemble model on the test set has reached 99.03%, and it is proved through experimental comparison that the effect is better than other models. The proposed method can accurately distinguish between cancer cells and normal cells and can be used as an effective method for computer-aided diagnosis of acute lymphoblastic leukemia.","2021-08-23","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","2021","","","","","","","","","","English","","","","WOS:000700350900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;48<br/>Total Times Cited:&nbsp;&nbsp;50<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4JVT4Q98","journalArticle","2025","Xu, K; Xie, Q; Zhu, Y; Cao, WX; Ni, J","Effective Multi-Species weed detection in complex wheat fields using Multi-Modal and Multi-View image fusion","COMPUTERS AND ELECTRONICS IN AGRICULTURE","","0168-1699","10.1016/j.compag.2025.109924","","Rapid and accurate acquisition of weed information in wheat fields is the precondition and key to precision weeding. Weed detection in open and complex wheat fields faces two challenges: 1) detection of grass weeds that have a similar appearance to wheat; and 2) weed detection under leaf occlusion. Dual-modal information, namely, red-green-blue (RGB) images and depth images can be introduced, which fundamentally overcomes limitations of single-modal image features in identifying grass weeds. Then, a dual-path Swin Transformer model was developed for multi-modal feature extraction. An alignment and attention module (AAM) was designed to realize the alignment and fusion of information in different modalities. Finally, multi-view images were introduced to break the limitation of leaf occlusion in natural wheat fields by completing the feature space of objects, and the multi-view information fusion method based on the common underlying principle of view agreement was proposed. The experimental results demonstrate that depth information is a valuable complement to RGB imagery, facilitating the detection of grass weeds and significantly enhancing weed detection accuracy in wheat fields. Compared with Deep Convolutional Neural Network (DCNN) model, dual-path Swin Transformer model and the model containing AAM have resulted in an improvement in weed detection accuracy by 6.6% and 11.03%, respectively. Additionally, incorporating multi-view information has effectively addressed the issue of leaf occlusion in weed detection, resulting in an 85.14% increase in weed detection accuracy. Furthermore, the problem of view divergence in multi-view learning has been resolved, reducing the false detection rate by 23.94% compared to the direct Combination method.","2025-03","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","230","","","","","","","","","","English","","","","WOS:001398493700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","CAMERA; CLASSIFICATION; Complex wheat fields; Deep learning; IDENTIFICATION; INDEXES; Multi-modal image; Multi-view image; SEGMENTATION; VEGETATION; Weed detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A7Z7887M","journalArticle","2024","Xu, TJ; Yuan, D; Wang, P; Yang, GX; Li, BY; Sun, WL","Improved 3-D Representation of GPR Pipelines B-Scan Sequences Using a Neural Network Framework","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2024.3360101","","Ground-penetrating radar (GPR) is an efficient nondestructive testing tool used for detecting and locating buried pipelines. It helps to avoid interference with existing pipelines and determine optimal layouts, resulting in time and cost savings. However, applications in this domain often require the joint observation of sequential images, mapping from 2-D B-scans to 3-D spatial structures. Complex underground environments, equipment orientations, noise, and data deviations can introduce visual distortions, blurriness, and unclear structures in the collected data. Therefore, there is a need for a method to rapidly comprehend and visually analyze the true conditions of underground pipeline structures. GPR data is typically collected and stored in the form of 2-D B-scan sequences. In this article, we propose a network framework that takes sparse original 2-D B-scan sequences as input and outputs a dense 3-D target model. We first employ a transformer model to interpolate the B-scan slice collection, generating dense 3-D B-scan volume data. Subsequently, a from-coarse-to-fine back-projection strategy, based on the transformer model, constructs a 3-D volume data inversion-mapping model to transform 2-D hyperbolic waves into 3-D pipeline information. In addition, we apply a clutter removal mechanism based on conditional generative adversarial networks (CGANs) to declutter and enhance the visualization of the desired hyperbolic wave structures, improving the accuracy of 3-D visual imaging. Experimental results demonstrate that the proposed method is better suited for structural analysis of GPR pipeline data, particularly in complex real-world data experiments, affirming the effectiveness and practicality of the approach presented in this article.","2024","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","62","","","","","","","","","","English","","","","WOS:001173250800038","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Clutter suppression; GROUND-PENETRATING RADAR; ground-penetrating radar (GPR); inverse mapping; neural network; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A2CPWNQH","journalArticle","2021","Wang, ZN; Peng, DW; Shang, YB; Gao, JJ","Autistic Spectrum Disorder Detection and Structural Biomarker Identification Using Self-Attention Model and Individual-Level Morphological Covariance Brain Networks","FRONTIERS IN NEUROSCIENCE","","1662-453X","10.3389/fnins.2021.756868","","Autism spectrum disorder (ASD) is a range of neurodevelopmental disorders, which brings enormous burdens to the families of patients and society. However, due to the lack of representation of variance for diseases and the absence of biomarkers for diagnosis, the early detection and intervention of ASD are remarkably challenging. In this study, we proposed a self-attention deep learning framework based on the transformer model on structural MR images from the ABIDE consortium to classify ASD patients from normal controls and simultaneously identify the structural biomarkers. In our work, the individual structural covariance networks are used to perform ASD/NC classification via a self-attention deep learning framework, instead of the original structural MR data, to take full advantage of the coordination patterns of morphological features between brain regions. The self-attention deep learning framework based on the transformer model can extract both local and global information from the input data, making it more suitable for the brain network data than the CNN- structural model. Meanwhile, the potential diagnosis structural biomarkers are identified by the self-attention coefficients map. The experimental results showed that our proposed method outperforms most of the current methods for classifying ASD patients with the ABIDE data and achieves a classification accuracy of 72.5% across different sites. Furthermore, the potential diagnosis biomarkers were found mainly located in the prefrontal cortex, temporal cortex, and cerebellum, which may be treated as the early biomarkers for the ASD diagnosis. Our study demonstrated that the self-attention deep learning framework is an effective way to diagnose ASD and establish the potential biomarkers for ASD.","2021-10-08","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","15","","","","","","","","","","English","","","","WOS:000713209700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","autism spectrum disorder; biomarker; CLASSIFICATION; CORTICAL THICKNESS; deep learning; individual morphological covariance brain networks; self-attention based neural networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SFZWGRGT","journalArticle","2025","Wu, YC; Yang, Y; Zhang, RM; Chen, ZJ; Jin, MC; Zou, Y; Wang, ZH; Wu, FH","Molecular representation learning based on Transformer with fixed-length padding method","JOURNAL OF MOLECULAR STRUCTURE","","0022-2860","10.1016/j.molstruc.2024.139574","","Effective molecular representation learning plays an important role in molecular modeling process of drug design, protein engineering, material science and so on. Currently, self-supervised learning models based on the Transformer architecture have shown great promise in molecular representation. However, batch training of Transformer model requires input data of consistent length, while the length of each entry's molecular data (SMILES sequence) is inconsistent, which results in the model being unable to process batches directly. Therefore, corresponding strategies should be proposed to enable the model to smoothly process data with inconsistent length in batches. In this work, we adopt a strategy of head-tail padding and tail padding to obtain fixed-length data, which are employed as inputs for the Transformer encoder and decoder respectively, thus overcoming the limitation of the Transformer's inability to batch process input data with inconsistent length. In this way, our Transformer-based model can be used for batch training of molecular data, thereby improving the efficiency, accuracy, and simplicity of molecular representation learning. Subsequently, public datasets are used to evaluate the performance of our molecular representation model in predicting molecular property. In the classification and regression tasks, the average ROC-AUC and RMSE values improves by over 10.3% and 3.3% respectively compared to the baseline models. Furthermore, the specific distributions are found after the compressing molecular representation vectors into two-dimensional or three-dimensional space using PCA dimensionality reduction algorithm, instead of random distributions. Our work highlights the potential of Transformer model in batch training for constructing molecular representation model, thus providing new path for AI technology in molecular modeling.","2025-01-05","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","1319","","","","","","","","","","English","","","","WOS:001297710900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","DATABASE; Fixed-length padding; Molecular property prediction; Molecular representation learning; NOMENCLATURE; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"87KYWII8","journalArticle","2024","Song, KL; Nie, J; Li, Y; Li, JB; Song, PX; Ercisli, S","Regional soil water content monitoring based on time-frequency spectrogram of low-frequency swept acoustic signal","GEODERMA","","0016-7061","10.1016/j.geoderma.2023.116765","","Acoustic waves offer a non-destructive, safe, and cost-effective means of monitoring the environment, with a potential application in soil water content monitoring. However, extracting soil water information from acoustic signals is still challenging. To tackle this issue, we have developed a low -frequency swept acoustic signal detection device and system. We conducted soil penetration testing using low -frequency swept acoustic signals. The swept -frequency acoustic signals passing through the soil were transformed into time-frequency spectrogram. Using the Swin-Transformer model, we established a regression model between the time-frequency spectrogram of the swept frequencies and the soil water content. Predictions were made both on a laboratory test dataset and through field trials using the calibrated model. The results indicate that the RMSE, MAE, and R2 values between the observed and the model's outputs of water content (%) for the test laboratory dataset are 0.191, 0.081, and 0.999, respectively, using the Swin-Transformer model. In the case of the field trials, the RMSE, MAE, and R2 values between the predicted and observed values are 6.715 %, 1.829 %, and 0.711, respectively. These studies demonstrate that this method is highly effective in predicting soil water content, with the best results achieved at a resolution of 20 PPI (Pixels Per Inch) and within the frequency range of 260-360 Hz. It provides an efficient approach for acoustic soil water content detection, effectively resolves the difficulty in building models caused by the single -parameter limitation in traditional acoustic model.","2024-01","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","441","","","","","","","","","","English","","","","WOS:001153992500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","AGRICULTURE; Image regression; Soil water content; Sweep frequency; Swin-Transformer; Time-frequency spectrogram","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I3Z6C555","journalArticle","2024","Nguyen, C; Cheema, AA; Kurnaz, C; Rahimian, A; Brennan, C; Duong, TQ","Deep Learning Models for Time-Series Forecasting of RF-EMF in Wireless Networks","IEEE OPEN JOURNAL OF THE COMMUNICATIONS SOCIETY","","2644-125X","10.1109/OJCOMS.2024.3365708","","Radio-frequency electromagnetic field (RF-EMF) forecasting plays an important role in the evaluation of regulatory compliance, network planning and system optimization. The knowledge of RF-EMF levels is essential to ensure compliance with standards and avoid public health concerns, especially with the arrival of new frequencies and scenarios in fifth-generation (5G) and sixth generation (6G) wireless networks. This work provides a comprehensive study on time series forecasting for RF-EMF measured in frequency from 100 kHz - 3 GHz. The state-of-the-art deep learning model architectures consist of deep neural network (DNN), convolutional neural network (CNN), long-short term memory (LSTM), and transformer are applied for time series forecasting. The prediction performance is evaluated under three different scenarios - namely single-step input single-step output (SISO), multi-step input single-step output (MISO), and multi-step input multi-step output (MIMO). The findings from the simulation demonstrate that SISO forecasting is inadequate in predicting long-term radio-frequency electromagnetic fields (RF-EMF) data as it lacks accuracy while MISO and MIMO forecasting scenarios offer more precise predictions. Specifically, in these two scenarios where the input width and label width are both set to 20 steps, the LSTM and CNN models exhibit superior performance compared to other models. Nonetheless, as the input width and label width in a MIMO scenario increase, the accuracy of both CNN and LSTM models decline considerably, whereas the transformer model consistently maintains good performance. Additionally, the transformer model continues to deliver accurate predictions as the label width and shift length increase, which is not the case for DNN, CNN, and LSTM models.","2024","2025-02-26 20:39:14","2025-02-26 20:39:14","","1399-1414","","","5","","","","","","","","","","English","","","","WOS:001184777000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","5G mobile communication; 6G; 6G mobile communication; CNN; Convolutional neural networks; Data models; deep learning; EMF; EXPOSURE; forecasting; Forecasting; Frequency measurement; LSTM; Predictive models; RF-EMF; time-series; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GFTJRFJF","journalArticle","2022","Lee, YJ; Choe, S; Wy, S; Jang, M; Jeoung, JW; Choi, HJ; Park, KH; Sun, S; Kim, YK","Demographics Prediction and Heatmap Generation From OCT Images of Anterior Segment of the Eye: A Vision Transformer Model Study","TRANSLATIONAL VISION SCIENCE & TECHNOLOGY","","2164-2591","10.1167/tvst.11.11.7","","Purpose: To predict demographic characteristics from anterior segment optical coherence tomography (AS-OCT) images of eyes using a Vision Transformer (ViT) model. Methods: A total of 2970 AS-OCT images were used to train, validate, and test a ViT to predict age and sex, and 2616 images were used for height, weight, and body mass index (BMI). The main outcome measure was the area under the receiver operating characteristic curve (AUC) of the ViT. Results: The ViT achieved the largest AUC (0.910) for differentiating age <75 versus >75 years, followed by age <60 versus 60-75 versus >75 years (AUC, 0.844), and for discriminating sex (AUC, 0.665). The prediction abilities for the other demographic characteristics were lower: an AUC of 0.521 for classifying height <170 versus >170 cm in males and <155 versus >155 cm in females; 0.522 for weight <70 versus >70 kg in males and 0.503 for <55 versus >55 kg in females, and 0.517 for BMI <23 versus 23-25 versus >25 kg/m2. Heatmaps highlighted the area of the iridocorneal angle for its contribution to the prediction of age <75 versus >75 years. Conclusions: Although the ViT demonstrated a good ability to classify age from AS-OCT images, it performed poorly for sex, height, weight, and BMI. The heatmap obtained of the prediction will provide clues to understanding the age-related anterior segment changes in eyes. Translational Relevance: The ViT can determine age-related anterior segment structural changes using AS-OCT images, which will aid clinicians in the management of ocular diseases.","2022-01","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","11","11","","","","","","","","","","English","","","","WOS:000982526100007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","AGE; ANGLE; anterior segment optical coherence tomography; CHAMBER; CONJUNCTIVAL; CORNEAL; deep learning; demographic characteristics; DIAGNOSIS; OPTICAL COHERENCE TOMOGRAPHY; prediction; SEX; THICKNESS; vision transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9JH5PI8Z","journalArticle","2025","Wen, K; Chen, Y; Zhu, ZW; Yang, JZ; Bao, JJ; Fu, DD; Hu, ZG; Peng, XH; Jiao, M","A novel real-time crayfish weight grading method based on improved Swin Transformer","JOURNAL OF FOOD SCIENCE","","0022-1147","10.1111/1750-3841.70008","","This study proposed a novel detection method for crayfish weight classification based on an improved Swin-Transformer model. The model demonstrated a Mean Intersection over Union (MIOU) of 90.36% on the crayfish dataset, outperforming the IC-Net, DeepLabV3, and U-Net models by 17.44%, 5.55%, and 1.01%, respectively. Furthermore, the segmentation accuracy of the Swin-Transformer model reached 99.0%, surpassing the aforementioned models by 1.25%, 1.73%, and 0.46%, respectively. To facilitate weight prediction of crayfish from segmented images, this study also investigated the correlation between the projected area and the weight of each crayfish part, and developed a multiple regression model with a correlation coefficient of 0.983 by comparing the total projected area and the relationship between the projected area and the actual weight of each crayfish part. To validate this model, a test set of 40 samples was employed, with the average prediction accuracy reaching 98.34% based on 10 representative data points. Finally, grading experiments were carried out on the crayfish weight grading system, and the experimental results showed that the grading accuracy could reach more than 86.5%, confirming the system's feasibility. The detection method not only predicts the weight based on the area but also incorporates the proportional relationship of the area of each part to improve the accuracy of the prediction further. This innovation makes up for the limitations of traditional inspection methods and shows higher potential for application. This study has important applications in industrial automation, especially for real-time high-precision weight grading in the aquatic processing industry, which can improve production efficiency and optimize quality control.","2025-02","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","2","90","","","","","","","","","","English","","","","WOS:001412487900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","correlation; crayfish; image segmentation; weight grading","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7U8NSDQJ","journalArticle","2022","Kuang, L; Zhou, C; Yang, XX","Code comment generation based on graph neural network enhanced transformer model for code understanding in open-source software ecosystems","AUTOMATED SOFTWARE ENGINEERING","","0928-8910","10.1007/s10515-022-00341-1","","In open-source software ecosystems, the scale of source code is getting larger and larger, and developers often use various methods (good code comments or method names, etc.) to make the code easier to read and understand. However, high-quality code comments or method names are often unavailable due to tight project schedules or other reasons in open-source software ecosystems such as Github. Therefore, in this work, we try to use deep learning models to generate appropriate code comments or method names to help software development and maintenance, which requires a non-trivial understanding of the code. Therefore, we propose a Graph neural network enhanced Transformer model (GTrans for short) to learn code representation to understand code better. Specifically, GTrans learns code representation from code sequences and graphs. We use a Transformer encoder to capture the global representation from code sequence and a graph neural network (GNN) encoder to focus on the local details in the code graph, and then use a decoder to combine both global and local representations by attention mechanism. We use three public datasets collected from GitHub to evaluate our model. In an extensive evaluation, we show that GTrans outperforms the state-of-the-art models up to 3.8% increase in METEOR metrics on code comment generation and outperforms the state-of-the-art models by margins of 5.8%-9.4% in ROUGE metrics on method name generation after some adjustments on the structure. Empirically, we find the method name generation task depends on more local information than global, and the code comment generation task is in contrast. Our data and code are available at https://github.com/zc-work/GTrans.","2022-11","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","2","29","","","","","","","","","","English","","","","WOS:000811207100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Code representation; Graph neural network; Open-source software ecosystems; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JSNRNRK2","journalArticle","2024","Gao, RQ; Bourlai, T","On Designing a SwinIris Transformer Based Iris Recognition System","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3369035","","In this paper, we discuss our proposed unified approach to iris recognition called the SwinIris. This approach works efficiently when combing a tuned version of the original Swin Transformer with a set of iris recognition processes. While the original Swin Transformer has recently been used on different biometric modalities due to its competitive advantage over other architectures, it has not been used for iris recognition. Thus, in our work, our proposed deep learning architecture is using a pre-trained Swin Transformer model that is fine-tuned with a set of linear layers. This model is a set of algorithmic aspects that achieve competitive iris-matching accuracy when using any of the selected iris databases selected to test our approach. Specifically, our proposed SwinIris Transformer-based iris recognition system is composed of four modules, namely, the eye detection, iris detection, iris segmentation, and iris classification modules. The proposed system commences with a detection process that aims to identify eyes within the camera-captured original iris images. Subsequently, the iris detection process identifies the iris patterns within the detected iris images to ensure that they are present and can be segmented. The third module involves iris segmentation, which extracts iris features utilized by the fourth and final module that matches iris images using the SwinIris-based Transformer model. The performance of the proposed system is evaluated on small- and large-scale iris datasets, including the CASIA-Iris- Thousand, CASIA-Iris-Lamp, CASIA-IntervalV4, and CASIA- IntervalV3. Our proposed model has a competitive iris classification accuracy when compared to various academic state-of-the-art methodologies, resulting in a classification performance ranging from 95.14% to 99.56%.","2024","2025-02-26 20:39:14","2025-02-26 20:39:14","","30723-30737","","","12","","","","","","","","","","English","","","","WOS:001175896600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Biometrics; Biometrics (access control); Classification algorithms; Computational modeling; Computer architecture; deep learning; Deep learning; Feature extraction; human identification; Identification of persons; iris recognition; Iris recognition; Swin Transformer; Task analysis; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7PAI3DBY","journalArticle","2024","Yang, Y; Qu, ZY; Yan, ZF; Gao, ZP; Wang, T","Network Configuration Entity Extraction Method Based on Transformer with Multi-Head Attention Mechanism","CMC-COMPUTERS MATERIALS & CONTINUA","","1546-2218","10.32604/cmc.2023.045807","","Nowadays, ensuring the quality of network services has become increasingly vital. Experts are turning to knowledge graph technology, with a significant emphasis on entity extraction in the identification of device configurations. This research paper presents a novel entity extraction method that leverages a combination of active learning and attention mechanisms. Initially, an improved active learning approach is employed to select the most valuable unlabeled samples, which are subsequently submitted for expert labeling. This approach successfully addresses the problems of isolated points and sample redundancy within the network configuration sample set. Then the labeled samples are utilized to train the model for network configuration entity extraction. Furthermore, the multi-head self-attention of the transformer model is enhanced by introducing the Adaptive Weighting method based on the Laplace mixture distribution. This enhancement enables the transformer model to dynamically adapt its focus to words in various positions, displaying exceptional adaptability to abnormal data and further elevating the accuracy of the proposed model. Through comparisons with Random Sampling (RANDOM), Maximum Normalized LogProbability (MNLP), Least Confidence (LC), Token Entrop (TE), and Entropy Query by Bagging (EQB), the proposed method, Entropy Query by Bagging and Maximum Influence Active Learning (EQBMIAL), achieves comparable performance with only 40% of the samples on both datasets, while other algorithms require 50% of the samples. Furthermore, the entity extraction algorithm with the Adaptive Weighted Multi-head Attention mechanism (AW-MHA) is compared with BILSTM-CRF, Mutil_Attention-Bilstm-Crf, Deep_Neural_Model_NER and BERT_Transformer, achieving precision rates of 75.98% and 98.32% on the two datasets, respectively. Statistical tests demonstrate the statistical significance and effectiveness of the proposed algorithms in this paper.","2024","2025-02-26 20:39:14","2025-02-26 20:39:14","","735-757","","1","78","","","","","","","","","","English","","","","WOS:001186467600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","active learning; Entity extraction; knowledge graph; network configuration; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GBRYVHB9","journalArticle","2024","Prakash, S; Jalal, AS; Pathak, P","TiDEFormer-a heterogenous stacking ensemble approach for time series forecasting of COVID-19 prevalence","INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS","","1868-8071","10.1007/s13042-024-02417-8","","Forecasting time series data over extended periods remains a formidable task in practical scenarios, such as the ongoing COVID-19 epidemic. The current variant of concern, JN.1, has increased transmissibility and reduced susceptibility to vaccinations in comparison to previous strains. As a result, there is an urgent requirement to forecast the daily incidence of COVID-19 in the near future. While deep learning models have demonstrated potential in predicting time series, they lack effectiveness in forecasting over long durations. This study seeks to fill the current gap by implementing a novel ensemble-based approach that incorporates two highly promising deep learning models: Time series Dense Encoder (TiDE) and Self attention-based Transformer model. The TiDEFormer, which combines TiDE and Transformer models using a heterogenous stacking ensemble technique, has exhibited greater accuracy in comparison to other proficient algorithms. The work employs the Blocked Time Series Cross validation technique to build distinct accurate models. In addition, the models are subjected to hyper-parameter tuning using the Grid Search Algorithm. The test results of TiDEFormer on the COVID-19 Dataset show a significant improvement in the Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) by around 22% and 17% respectively, compared to the TiDE model. The percentage improvement with respect to the Transformer model is approximately 9% and 6% respectively. Furthermore, an accurate prediction of the COVID-19 situation on daily basis is available for all countries, spanning a period of 200 days forecasting horizon covering approximately these months (From Dec 2023 to July 2024).","2024-10-22","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","","","","","","","","","","","English","","","","WOS:001337216300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","COVID-19; Ensemble; Time series dense encoder; Time series forecasting; Transformer network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D36ZS2JT","journalArticle","2024","Li, C; Zhao, WY; Zhao, LX; Ju, L; Zhang, HY","Application of fuzzy logic control theory combined with target tracking algorithm in unmanned aerial vehicle target tracking","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-58140-5","","This paper aims to increase the Unmanned Aerial Vehicle's (UAV) capacity for target tracking. First, a control model based on fuzzy logic is created, which modifies the UAV's flight attitude in response to the target's motion status and changes in the surrounding environment. Then, an edge computing-based target tracking framework is created. By deploying edge devices around the UAV, the calculation of target recognition and position prediction is transferred from the central processing unit to the edge nodes. Finally, the latest Vision Transformer model is adopted for target recognition, the image is divided into uniform blocks, and then the attention mechanism is used to capture the relationship between different blocks to realize real-time image analysis. To anticipate the position, the particle filter algorithm is used with historical data and sensor inputs to produce a high-precision estimate of the target position. The experimental results in different scenes show that the average target capture time of the algorithm based on fuzzy logic control is shortened by 20% compared with the traditional proportional-integral-derivative (PID) method, from 5.2 s of the traditional PID to 4.2 s. The average tracking error is reduced by 15%, from 0.8 m of traditional PID to 0.68 m. Meanwhile, in the case of environmental change and target motion change, this algorithm shows better robustness, and the fluctuation range of tracking error is only half of that of traditional PID. This shows that the fuzzy logic control theory is successfully applied to the UAV target tracking field, which proves the effectiveness of this method in improving the target tracking performance.","2024-08-09","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","1","14","","","","","","","","","","English","","","","WOS:001288468500055","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","DRONES TRACKING; Edge computing; Fuzzy logic control; Particle filter algorithm; Unmanned aerial vehicle target tracking; Vision transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4BZQKZIK","journalArticle","2025","Li, XX; Li, D; Ren, WX; Sun, XT","An RFE-aided Transformer-SVM framework for multi-bolt connection loosening identification using wavelet entropy of vibro-acoustic modulation signals","ADVANCES IN STRUCTURAL ENGINEERING","","1369-4332","10.1177/13694332241269233","","To ensure structural safety and integrity, a novel framework is developed for detecting the loosening of multi-bolt connections using wavelet entropy of vibro-acoustic modulation (VAM) signals. Wavelet entropy is employed as the dynamic index to capture the intricate time-frequency characteristics that are indicative of the connection status. Taking the wavelet entropy vectors as input, the proposed framework distinguishes itself by integrating a Transformer model for high-dimensional feature extraction with the recursive feature elimination (RFE) for essential feature selection, followed by a support vector machine (SVM) model for classification. Specifically, the Transformer model with innovative positional encoding capability helps to extract the time-dependent transient features that are sensitive to the bolt loosening. The RFE process reduces the data dimensionality while discerning the diagnostic information for more accurate classification. Through the experiment on a four-bolt joint, the identification results with cross-validation showed high accuracy and robustness of the proposed framework across various loosening cases. It outperformed the traditional SVM, long short-term memory network (LSTM), convolutional neural network (CNN)-SVM models without and with RFE, as well as the Transformer-SVM model without RFE, achieving an accuracy increase of 15.72%, 11.74%, 9.47%, 5.49%, and 5.06%, respectively. The proposed framework was demonstrated to be able to learn the damage-sensitive features more effectively from wavelet entropy data, marking a significant advancement in the health monitoring of engineering structures with high-strength bolt connections.","2025-01","2025-02-26 20:39:14","2025-02-26 20:39:14","","89-103","","1","28","","","","","","","","","","English","","","","WOS:001282520000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","FAULT-DIAGNOSIS; JOINTS; loosening identification; Multi-bolt connections; NEURAL-NETWORKS; recursive feature elimination; transformer-support vector machine; vibro-acoustic modulation; wavelet entropy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CNKQ8UTV","journalArticle","2022","Qing-dao-er-ji, R; Cheng, K; Pang, R","Research on Traditional Mongolian-Chinese Neural Machine Translation Based on Dependency Syntactic Information and Transformer Model","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app121910074","","Neural machine translation (NMT) is a data-driven machine translation approach that has proven its superiority in large corpora, but it still has much room for improvement when the corpus resources are not abundant. This work aims to improve the translation quality of Traditional Mongolian-Chinese (MN-CH). First, the baseline model is constructed based on the Transformer model, and then two different syntax-assisted learning units are added to the encoder and decoder. Finally, the encoder's ability to learn Traditional Mongolian syntax is implicitly strengthened, and the knowledge of Chinese-dependent syntax is taken as prior knowledge to explicitly guide the decoder to learn Chinese syntax. The average BLEU values measured under two experimental conditions showed that the proposed improved model improved by 6.706 (45.141-38.435) and 5.409 (41.930-36.521) compared with the baseline model. The analysis of the experimental results also revealed that the proposed improved model was still deficient in learning Chinese syntax, and then the Primer-EZ method was introduced to ameliorate this problem, leading to faster convergence and better translation quality. The final improved model had an average BLEU value increase of 9.113 (45.634-36.521) compared with the baseline model at experimental conditions of N = 5 and epochs = 35. The experiments showed that both the proposed model architecture and prior knowledge could effectively lead to an increase in BLEU value, and the addition of syntactic-assisted learning units not only corrected the initial association but also alleviated the long-term dependence between words.","2022-10","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","19","12","","","","","","","","","","English","","","","WOS:000866630700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","attention mechanism; convolutional neural networks; dependency parsing; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TZP8MZMV","journalArticle","2022","Zhang, XD; Xuan, JX; Yao, CS; Gao, QJ; Wang, LL; Jin, X; Li, SW","A deep learning approach for orphan gene identification in moso bamboo (Phyllostachys edulis) based on the CNN plus Transformer model","BMC BIOINFORMATICS","","1471-2105","10.1186/s12859-022-04702-1","","Background Orphan gene play an important role in the environmental stresses of many species and their identification is a critical step to understand biological functions. Moso bamboo has high ecological, economic and cultural value. Studies have shown that the growth of moso bamboo is influenced by various stresses. Several traditional methods are time-consuming and inefficient. Hence, the development of efficient and high-accuracy computational methods for predicting orphan genes is of great significance. Results In this paper, we propose a novel deep learning model (CNN + Transformer) for identifying orphan genes in moso bamboo. It uses a convolutional neural network in combination with a transformer neural network to capture k-mer amino acids and features between k-mer amino acids in protein sequences. The experimental results show that the average balance accuracy value of CNN + Transformer on moso bamboo dataset can reach 0.875, and the average Matthews Correlation Coefficient (MCC) value can reach 0.471. For the same testing set, the Balance Accuracy (BA), Geometric Mean (GM), Bookmaker Informedness (BM), and MCC values of the recurrent neural network, long short-term memory, gated recurrent unit, and transformer models are all lower than those of CNN + Transformer, which indicated that the model has the extensive ability for OG identification in moso bamboo. Conclusions CNN + Transformer model is feasible and obtains the credible predictive results. It may also provide valuable references for other related research. As our knowledge, this is the first model to adopt the deep learning techniques for identifying orphan genes in plants.","2022-05-05","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","1","23","","","","","","","","","","English","","","","WOS:000791327400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","ALIGNMENT; CLASSIFICATION; Convolutional neural network; Deep learning; GENOME-WIDE IDENTIFICATION; LINEAGE-SPECIFIC GENES; Moso bamboo; NEURAL-NETWORKS; Orphan genes; PREDICTION; Transformer neural network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JZQS8QS7","journalArticle","2024","Almakayeel, N","Deep learning-based improved transformer model on android malware detection and classification in internet of vehicles","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-74017-z","","With the growing popularity of autonomous vehicles (AVs), confirming their safety has become a significant concern. Vehicle manufacturers have combined the Android operating system into AVs to improve consumer comfort. However, the diversity and weaknesses of the Android operating system pose substantial safety risks to AVs, as these factors can expose them to threats, namely Android malware. The advanced behaviour of multi-data source fusion in autonomous driving models has mitigated recognition accuracy and effectualness for Android malware. To efficiently counter new malware variants, novel techniques distinct from conventional methods must be utilized. Machine learning (ML) techniques cannot detect every new and complex malware variant. The deep learning (DL) model is an efficient tool for detecting various malware variants. This manuscript proposes a Deep Learning-Based Improved Transformer Model on Android Malware Detection (DLBITM-AMD) technique for Internet vehicles (IoVs). The main aim of the presented DLBITM-AMD approach is to detect Android malware effectually and accurately. The DLBITM-AMD method performs a Z-score normalization process to convert the raw data into a standard form. Then, the DLBITM-AMD approach utilizes the binary grey wolf optimization (BGWO) model to select optimum feature subsets. An improved transformer is integrated with the RNN model and softmax to enhance classification for Android malware recognition. Finally, the snake optimizer algorithm (SOA) method is employed to select the optimum parameter for the classification method. An extensive experiment of the DLBITM-AMD method is accomplished on a benchmark dataset. The performance validation of the DLBITM-AMD technique portrayed a superior accuracy value of 99.26% over existing Android malware recognition models.","2024-10-24","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","1","14","","","","","","","","","","English","","","","WOS:001342116100027","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Android malware detection; ANOMALY DETECTION; Deep learning; Internet of vehicles; MACHINE; OPTIMIZATION; Snake optimizer algorithm; Softmax","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U8UFX8JX","journalArticle","2024","Dobberstein, N; Maass, A; Hamaekers, J","Llamol: a dynamic multi-conditional generative transformer for de novo molecular design","JOURNAL OF CHEMINFORMATICS","","1758-2946","10.1186/s13321-024-00863-8","","Generative models have demonstrated substantial promise in Natural Language Processing (NLP) and have found application in designing molecules, as seen in General Pretrained Transformer (GPT) models. In our efforts to develop such a tool for exploring the organic chemical space in search of potentially electro-active compounds, we present Llamol, a single novel generative transformer model based on the Llama 2 architecture, which was trained on a 12.5M superset of organic compounds drawn from diverse public sources. To allow for a maximum flexibility in usage and robustness in view of potentially incomplete data, we introduce Stochastic Context Learning (SCL) as a new training procedure. We demonstrate that the resulting model adeptly handles single- and multi-conditional organic molecule generation with up to four conditions, yet more are possible. The model generates valid molecular structures in SMILES notation while flexibly incorporating three numerical and/or one token sequence into the generative process, just as requested. The generated compounds are very satisfactory in all scenarios tested. In detail, we showcase the model's capability to utilize token sequences for conditioning, either individually or in combination with numerical properties, making Llamol a potent tool for de novo molecule design, easily expandable with new properties. Scientific contribution We developed a novel generative transformer model, Llamol, based on the Llama 2 architecture that was trained on a diverse set of 12.5 M organic compounds. It introduces Stochastic Context Learning (SCL) as a new training procedure, allowing for flexible and robust generation of valid organic molecules with up to multiple conditions that can be combined in various ways, making it a potent tool for de novo molecular design.","2024-06-21","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","1","16","","","","","","","","","","English","","","","WOS:001251548300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","CHEMICAL LANGUAGE; DATABASE; De novo molecular design; DISCOVERY; Machine learning; Molecular generation; PROJECT; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EKBPG45Q","journalArticle","2024","Han, L; Yu, RJ; Wang, CZ; Abdel-Aty, M","Transformer-based modeling of abnormal driving events for freeway crash risk evaluation","TRANSPORTATION RESEARCH PART C-EMERGING TECHNOLOGIES","","0968-090X","10.1016/j.trc.2024.104727","","A crash risk evaluation model aims to estimate crash occurrence possibility by establishing the relationships between traffic flow status and crash occurrence. Based upon which, Proactive Traffic Safety Management (PTSM) systems have been developed and implemented. The current crash risk evaluation models relied on high dense traffic detectors, which limited the applications of PTSM to infrastructures with enough sensing devices. To address such application limitation issue, this study employed the widespread abnormal driving event information that is generated by emerging driving monitoring and vehicle connection techniques to develop the crash risk evaluation model. Specifically, to characterize abnormal driving events, a six-tuple embedding method was proposed to store their space, time and kinetics features. Given their irregular and discrete distributions on roadways, a Transformer model with self-attention mechanism was proposed to extract the spatial distribution characteristics. In addition, a time-decay function was integrated to fit the temporal impacts of abnormal driving events on crash risk. Empirical data from a freeway in China were utilized for the analyses. The results showed that abnormal driving events with lower speed, larger acceleration and duration are more likely to cause crashes. The accumulation of multiple events in the time period of less than 3 min would lead to a sharp increase of crash risk. Besides, compared to the average metrics of the widely adopted Convolutional Neural Network (CNN), XGBoost, and logistic regression models, the proposed model achieved higher accuracy (0.841) and AUC (0.777), with average improvement of 2.5 % and 9.1 % respectively.","2024-08","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","165","","","","","","","","","","English","","","","WOS:001325374100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Abnormal Driving Event; Convolutional Neural Network; Crash Risk Evaluation; SAFETY; Time-decay Function; TRAFFIC FLOW; Transformer Model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MTCVYZVJ","journalArticle","2025","Constantine, J; Lian, KL; He, ZP; Xiao, CY; Fan, YF; Yang, NT","A New Interface for Power Hardware-in-the-Loop Simulation Using Nelder-Mead Algorithm Une nouvelle interface pour la simulation Hardware-in-the-Loop de puissance à l'aide de l'algorithme de Nelder-Mead","IEEE CANADIAN JOURNAL OF ELECTRICAL AND COMPUTER ENGINEERING","","2694-1783","10.1109/ICJECE.2024.3500028","","A cyber-physical system is a system that integrates computation and physical processes. Such a system has found numerous applications in power systems. One such application is power hardware-in-the-loop (PHIL) simulation. In the context of PHIL simulation, a hardware device under test (DUT) is typically linked to a digital real-time simulator (DRTS) via a PHIL interface. Over time, several PHIL interfaces have been proposed and explored. Notably, the ideal transformer model (ITM) stands out due to its popularity, primarily for its ease of implementation. Other PHIL interfaces, such as partial circuit duplication (PCD) and damping impedance, can be viewed as extensions of the ITM concept. These PHIL interfaces necessitate a strict impedance ratio between the physical (i.e., the DUT) and the cyber parts (i.e., the system modeled in DRTS) before embarking on a PHIL implementation. This prerequisite can often prove to be a demanding and complex task. This article introduces a novel PHIL interface for PHIL using Nelder-Mead (NM) algorithm, designed to eliminate such constraints. Notably, the proposed PHIL interface offers an expanded stability region when compared with ITM, thus rendering it suitable for a broader range of PHIL applications. The effectiveness of this proposed method has been confirmed by a practical PHIL setup.","2025","2025-02-26 20:39:14","2025-02-26 20:39:14","","10-18","","1","48","","","","","","","","","","English","","","","WOS:001381453100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","ACCURACY; Circuit stability; Cyber-physical system; Damping; DESIGN; ideal transformer model (ITM); Impedance; IMPROVE; Integrated circuit modeling; Nelder-Mead (NM) algorithm; power hardware-in-the-loop (PHIL); Power system stability; Real-time systems; STABILITY; Stability analysis; Thermal stability; Time-varying systems; Voltage; voltage source converter","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4A9INN6D","journalArticle","2024","Yamada, D; Kojima, F; Otsuka, Y; Kawakami, K; Koishi, N; Oba, K; Bando, T; Matsusako, M; Kurihara, Y","Multimodal modeling with low-dose CT and clinical information for diagnostic artificial intelligence on mediastinal tumors: a preliminary study","BMJ OPEN RESPIRATORY RESEARCH","","2052-4439","10.1136/bmjresp-2023-002249","","Background Diagnosing mediastinal tumours, including incidental lesions, using low-dose CT (LDCT) performed for lung cancer screening, is challenging. It often requires additional invasive and costly tests for proper characterisation and surgical planning. This indicates the need for a more efficient and patient-centred approach, suggesting a gap in the existing diagnostic methods and the potential for artificial intelligence technologies to address this gap. This study aimed to create a multimodal hybrid transformer model using the Vision Transformer that leverages LDCT features and clinical data to improve surgical decision-making for patients with incidentally detected mediastinal tumours.Methods This retrospective study analysed patients with mediastinal tumours between 2010 and 2021. Patients eligible for surgery (n=30) were considered 'positive,' whereas those without tumour enlargement (n=32) were considered 'negative.' We developed a hybrid model combining a convolutional neural network with a transformer to integrate imaging and clinical data. The dataset was split in a 5:3:2 ratio for training, validation and testing. The model's efficacy was evaluated using a receiver operating characteristic (ROC) analysis across 25 iterations of random assignments and compared against conventional radiomics models and models excluding clinical data.Results The multimodal hybrid model demonstrated a mean area under the curve (AUC) of 0.90, significantly outperforming the non-clinical data model (AUC=0.86, p=0.04) and radiomics models (random forest AUC=0.81, p=0.008; logistic regression AUC=0.77, p=0.004).Conclusion Integrating clinical and LDCT data using a hybrid transformer model can improve surgical decision-making for mediastinal tumours, showing superiority over models lacking clinical data integration.","2024-04","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","1","11","","","","","","","","","","English","","","","WOS:001201903100006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Imaging/CT MRI etc; Thoracic Surgery; THYMOMA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CCA8UYST","journalArticle","2025","Chen, D; Chen, MD; Wu, PS; Wu, MT; Zhang, T; Li, CQ","Two-stream spatio-temporal GCN-transformer networks for skeleton-based action recognition","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-025-87752-8","","For the purpose of achieving accurate skeleton-based action recognition, the majority of prior approaches have adopted a serial strategy that combines Graph Convolutional Networks (GCNs) with attention-based methods. However, this approach frequently treats the human skeleton as an isolated and complete structure, neglecting the significance of highly correlated yet indirectly connected skeletal parts, finally hindering recognition accuracy. This study proposes a novel architecture addressing this limitation by implementing a parallel configuration of GCNs and the Transformer model (SA-TDGFormer). This parallel structure integrates the advantages of both the GCN model and the Transformer model, facilitating the extraction of both local and global spatio-temporal features, leading to more accurate motion information encoding and improved recognition performance. The proposed model distinguishes itself through its dual-stream structure: a spatiotemporal GCN stream and a spatiotemporal Transformer stream. The former focuses on capturing the topological structure and motion representations of human skeletons. In contrast, the latter seeks to capture motion representations that consist of global inter-joint relationships. Recognizing the unique feature representations generated by these streams and their limited mutual understanding, the model also incorporates a late fusion strategy to merge the results from the two streams. This fusion allows the spatiotemporal GCN and Transformer streams to complement each other, enriching action features and maximizing information exchange between the two representation types. Empirical validation on three established benchmark datasets, NTU RGB + D 60, NTU RGB + D 120, and Kinetics-Skeleton, substantiates the model's effectiveness. The experimental results indicate that, compared to existing classification frameworks, the method proposed in this paper improves the accuracy of human action recognition by 1-5% (NTU RGB + D 60 dataset). This improvement demonstrates the superior performance of the model in action recognition.","2025-02-10","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","1","15","","","","","","","","","","English","","","","WOS:001418562300045","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","Action recognition; GRAPH CONVOLUTIONAL NETWORK; Graph convolutional networks; NEURAL-NETWORK; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7SMYFR4I","journalArticle","2024","Chen, JH; Dai, H; Wang, S; Liu, CR","Improving Accuracy and Efficiency in Time Series Forecasting with an Optimized Transformer Model","ENGINEERING LETTERS","","1816-093X","","","Time series forecasting (TSF) is a prevalent research task in various fields such as medicine, transportation, environment, network detection, finance, and others. The TSF task aims to identify underlying patterns in data and make relatively accurate estimates of future data based on known values. In recent years, deep learning models have gained popularity for TSF tasks due to their capability to capture internal information effectively. However, traditional deep-learning models encounter difficulties when parallelizing data calculations, leading to error accumulation and reduced forecasting accuracy. Additionally, when dealing with excessively long input data, traditional deep learning models may experience performance degradation despite providing sufficient information and making it arduous to predict future data. Transformer-based models, with Self-Attention as the core, have shown the ability to facilitate global information interaction and enhance prediction efficiency. Nonetheless, they may encounter problems with significant and redundant parameters, causing unnecessary time overhead. To overcome these challenges, we propose a novel model called VarSeg-Trans, which incorporates three key optimizations: the cut-up mechanism, the variables-isolating mechanism, and an improved attention calculation method to enhance the transformer model's performance. Specifically, the cut-up mechanism enables the model to process longer input sequences, the variables-isolating mechanism mitigates overfitting, and the improved attention method leverages sequence information more effectively. Compared to other baseline TSF models and previous Transformer-based models, VarSeg-Trans has achieved an average reduction of 9% in MSE and MAE, along with a 3% increase in the coefficient of determination R2. This trend is substantiated by consistent results across multiple experimental trials.","2024-01-01","2025-02-26 20:39:14","2025-02-26 20:39:14","","1-11","","1","32","","","","","","","","","","English","","","","WOS:001138408200011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Deep learning; NEURAL-NETWORK; PREDICTION; Self-Attention; Time series forecasting; Transformer-based models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"85CYK7UY","journalArticle","2024","Zhang, K; Ning, WZ; Zhu, YD; Li, ZH; Wang, T; Jiang, WK; Zeng, M; Yang, Z","Gaussian-Linearized Transformer with Tranquilized Time-Series Decomposition Methods for Fault Diagnosis and Forecasting of Methane Gas Sensor Arrays","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14010218","","Methane is considered as a clean energy that is widely used in places with high environmental requirements. The increasing demand for methane exploration in polar and deep sea extreme environments has a positive role in carbon neutrality policies. As a result, there will be a gradual increase in exploration activities for deep sea methane resources. Methane sensors require high reliability but are prone to faults, so fault diagnosis and forecasting of gas sensors are of vital practical significance. In this work, a Gaussian-linearized transformer model with a tranquilized time-series decomposition method is proposed for fault diagnosis and forecasting tasks. Since the traditional transformer model requires more computational expense with time complexity of O (N2) and is not applicable to continuous-sequence prediction tasks, two blocks of the transformer are improved. First, a Gaussian-linearized attention block is modified for fault-diagnosis tasks so that its time complexity can be changed to O (N), which can reduce computational resources. Second, a model with proposed attention for fault forecasting replaces the traditional embedding block with a decomposed block, which can input the continuous sequence data to the model completely and preserve the continuity of the methane data. Results show that the Gaussian-linearized transformer improves the accuracy of fault diagnosis to 99% and forecasting with low computational cost, which is superior to that of traditional methods. Moreover, the least mean-square-error loss of fault forecasting is 0.04, which is lower compared with the traditional time series prediction models and other deep learning models, highlighting the great potential of the proposed transformer for fault diagnosis and fault forecasting of gas sensor arrays.","2024-01","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","1","14","","","","","","","","","","English","","","","WOS:001139189600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","deep sea; methane; self-attention; sensor arrays; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RVF64CFZ","journalArticle","2025","Prakash, S; Jalal, AS; Pathak, P","Infectious disease time series modelling using transformer self-attention based network","ENGINEERING RESEARCH EXPRESS","","2631-8695","10.1088/2631-8695/ada66f","","Researchers are focusing on improving time series forecasting methods to address real-world problems like COVID-19. Current methods show decreased accuracy due to unpredictable seasonality, and enhancing models to handle long-term dependencies is crucial for better forecasting accuracy. This paper presents a Transformer self-attention based novel approach for infectious disease time series forecasting, specifically for COVID-19. The proposed method utilizes the Ensemble Empirical Mode Decomposition (EEMD) and Local Outlier Factor (LOF) methods for data pre-processing and to detect outliers. Next, a modified self-attention model based on Transformer neural network is introduced for predicting COVID-19 time series forecasting for the first time. The research specifically investigates the application of encoder/decoder networks with an enhanced Positional Encoding approach. This involves using a novel time encoding technique on the input pattern to achieve more precise intended output. Consequently, the parameters in the Transformer model are adjusted using the Arithmetic Optimization Algorithm (AOA) to enhance the accuracy of the prediction. The model generates more accurate predictions over broader time intervals, with the lowest MAE of 371.92 and RMSE of 674.61, indicating superior predictive accuracy by approximately 30% compared to other state-of-the-art methods. The proposed Transformer model has demonstrated significant improvements in robustness and forecasting accuracy compared to standard approaches such as LSTM, RNN, Exponential Smoothing, AutoARIMA, and TBATS for the COVID-19 time series of India, USA, and Brazil. The suggested model, due to its superior predictive accuracy, is applicable in diverse time series forecasting domains such as stock market trends, sales, and industrial consumption forecasting etc.","2025-03-31","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","1","7","","","","","","","","","","English","","","","WOS:001397509900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","COVID-19; machine learning; self-attention; time series forecasting; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M8S3KC95","journalArticle","2024","Liu, GX; Yu, X; Liu, DY","Predictive Model for Long-Term Lane Occupancy Rate Based on CT-Transformer and Variational Mode Decomposition","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14125346","","Lane occupancy is a crucial indicator of traffic flow and is significant for traffic management and planning. However, predicting lane occupancy is challenging due to numerous influencing factors, such as weather, holidays, and events, which render the data nonsmooth. To enhance lane occupancy prediction accuracy, this study introduces a fusion model that combines the CT-Transformer (CSPNet-Attention and Two-stage Transformer framework) with the Temporal Convolutional Neural Network-Long Short-Term Memory (TCN-LSTM) models alongside the Variational Mode. This includes a long-term lane occupancy prediction model utilizing the Variational Mode Decomposition (VMD) technique. Initially, the Variational Mode Decomposition decomposes the original traffic flow data into multiple smooth subsequences. Subsequently, each subsequence's autocorrelation and partial correlation coefficients ascertain the presence of seasonal characteristics. Based on these characteristics, the CT-Transformer and TCN-LSTM models process each subsequence for long-term lane occupancy rate prediction, respectively. Finally, predictions from both models are integrated using variable modes to derive the ultimate lane occupancy predictions. The core CT-Transformer model, an enhancement of the GBT (Two-stage Transformer) model, comprises two phases: autoregressive and prediction. The autoregressive phase leverages historical data for initial predictions inputted into the prediction phase. Here, the novel CSPNet-Attention mechanism replaces the conventional attention mechanism in the Encoder, reducing memory usage and computational resource loss, thereby enhancing the model's accuracy and robustness. Experiments on the PeMS public dataset demonstrate that the proposed model surpasses existing methods in predicting long-term lane occupancy, offering decent reliability and generalizability.","2024-06","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","12","14","","","","","","","","","","English","","","","WOS:001254685500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","CSPNet-Attention; lane occupancy prediction; TCN-LSTM; time-series prediction; Transformer; Variational Mode Decomposition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XXAVFBNI","journalArticle","2023","Hu, SC; Wang, YN; Liu, J; Yang, CW","Personalized Transfer Learning for Single-Lead ECG-Based Sleep Apnea Detection: Exploring the Label Mapping Length and Transfer Strategy Using Hybrid Transformer Model","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2023.3312698","","Objective: Automatic sleep apnea (SA) detection based on deep learning (DL) and single-lead electrocardiogram (ECG) has been extensively studied. We aim to explore the impact of different DL model structures and label mapping length (LML) on personalized transfer learning (TL), providing personalized TL applicability conditions based on the proposed hybrid transformer model (HTM). Methods: Two DL models, a pure convolutional neural network (CNN)-based model (PCM) and a proposed HTM, are included in the study. Eight different LMLs are considered. Furthermore, various personalized TL strategies are introduced to thoroughly explore the impact. Finally, two-sided t-tests are utilized to evaluate the significance. Results: In the same database, the average accuracy and AUC for the personalized PCM are 0.8412 and 0.9002, respectively, with p < 0.001, while the hybrid transformer-based personalized model achieves an average accuracy of 0.8537 and an average AUC of 0.9147 with p < 0.001. Across databases, the accuracy and AUC of personalized HTM reach 0.8271 and 0.8724, respectively, and p < 0.001. Conclusion: The increase in LML has a beneficial impact on the general model (GM) and personalized model for different model structures. The HTM exhibits better performance in both GM and personalized TL compared to the PCM. Additionally, personalized TL achieves significant improvement when utilizing only positive samples within the same database. However, it is more advantageous to utilize only negative samples when performing cross-database personalized TL. Significance: This article provides guidance for personalized TL in SA detection and provides an HTM-based personalized TL method.","2023","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","72","","","","","","","","","","English","","","","WOS:001071771900003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Electrocardiogram (ECG); EXTRACTION; hybrid transformer; sleep apnea (SA); transfer learning (TL)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4GNY7ABA","journalArticle","2024","Klug, J; Leclerc, G; Dirren, E; Carrera, E","Machine learning for early dynamic prediction of functional outcome after stroke","COMMUNICATIONS MEDICINE","","2730-664X","10.1038/s43856-024-00666-w","","BackgroundPrediction of outcome after stroke is critical for treatment planning and resource allocation but is complicated by fluctuations during the first days after onset. We propose a machine learning model that can provide hourly predictions based on the integration of continuous variables acquired within 72 h of hospital admission.MethodsWe analyzed 2492 admissions for ischemic stroke in the Geneva University Hospital from 01.01.2018 to 31.12.2021, amounting to 2'131'752 unique data points. We developed a transformer model that continuously included clinical, physiological, imaging, and biological data recorded within 72 h of admission. This model was trained to generate hourly predictions of mortality and morbidity. Shapley additive explanations were used to identify the most relevant predictors to explain outcomes for each patient. The MIMIC-III database was used for external validation.ResultsOur transformer model predicts mortality, with an area under the receiver operating characteristic curve of 0.830 (95% CI 0.763-0.885) on admission, reaching 0.893 (95% CI 0.839-0.933) 72 h later for a 3-month outcome. Validated in an independent cohort, it outperforms all static models. Based on their mean explanatory weights, the top predictors included continuous clinical evaluation, baseline patient characteristics, timing from admission to acute treatment, and markers of inflammation and organ dysfunction.ConclusionsThe performance of our transformer model demonstrates the potential of machine learning models integrating clinical, physiological, imaging, and biological variables over time after stroke. The clinical applicability of our model is further strengthened by access to hourly updated predictions along with accompanying explanations. Stroke is the most frequent cause of disability in industrialized countries. To determine the best treatment and allocate resources, an early and accurate prediction of outcome is essential. Although modern stroke units gather a continuous stream of data, existing tools for outcome prediction are rarely used as they are static and fail to adapt to the evolving condition of the patient.We developed a machine learning model, a computer system learning from existing data, to provide real-time predictions of in-hospital mortality and 3-month outcomes. Our model was able to provide accurate hourly prediction of outcome based on regularly updated clinical data obtained from the patient.This study demonstrates the potential of integrating the continuous data stream recorded in the electronic health record after stroke. Similar predictive models could help personalize treatment planning, empower patients and their families through counseling, and facilitate resource allocation. Klug et al. present a machine learning model for continuous monitoring and prediction of functional outcome after acute ischemic stroke. Integrating clinical, physiological, and biological variables over time, the system detects patients at risk as well as potential causes of deterioration.","2024-11-13","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","1","4","","","","","","","","","","English","","","","WOS:001353755700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;89</p>","","","ACUTE ISCHEMIC-STROKE; DECISION-SUPPORT; LENGTH; MODEL; RISK; STAY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AIRK97YX","journalArticle","2024","Bhattacharjee, P; Augustyniak, P","Comparative Evaluation of Neural Network Models for Optimizing ECG Signal in Non-Uniform Sampling Domain","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14198772","","Electrocardiographic signals (ECG) are ubiquitous, which justifies the research of their optimal storage and transmission. However, proposals for non-uniform signal sampling must take into account the priority of diagnostic data accuracy and record integrity, as well as robustness to noise and interference. In this study, two novel methods are introduced, each utilizing a distinct neural network architecture for optimizing non-uniform sampling of ECG signal. A transformer model refines each time point selection through an iterative process using gradient descent optimization, with the goal of minimizing the mean squared error between the original and resampled signals. It adaptively modifies time points, which improves the alignment between both signals. In contrast, the Temporal Convolutional Network model trains on the original signal, and gradient descent optimization is utilized to improve the selection of time points. Evaluation of both strategies' efficacy is performed by calculating signal distances at lower and higher sampling rates. First, a collection of synthetic data points that resembled the P-QRS-T wave was used to train the model. Then, the ECG-ID database for real data analysis was used. Filtering to remove baseline wander followed by evaluation and testing were carried out in the real patient data. The results, in particular MSE = 0.0005, RMSE = 0.0216, and Pearson's CC = 0.9904 for 120 sps in the case of the transformer patient data model, provide viable paths for maintaining the precision and dependability of ECG-based diagnostic systems at much lower sampling rate. Outcomes indicate that both techniques are effective at improving the fidelity between the original and modified ECG signals.","2024-10","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","19","14","","","","","","","","","","English","","","","WOS:001332191200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","electrocardiogram (ECG); neural networks; non-uniform sampling; samples per second (sps); signal fidelity; temporal convolutional network (TCN); transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZPRRA6RK","journalArticle","2023","Iyer, PG; Sachdeva, K; Leggett, CL; Codipilly, DC; Abbas, H; Anderson, K; Kisiel, JB; Asfahan, S; Awasthi, S; Anand, P; Kumar, MP; Singh, SP; Shukla, S; Bade, S; Mahto, C; Singh, N; Yadav, S; Padhye, C","Development of Electronic Health Record-Based Machine Learning Models to Predict Barrett's Esophagus and Esophageal Adenocarcinoma Risk","CLINICAL AND TRANSLATIONAL GASTROENTEROLOGY","","2155-384X","10.14309/ctg.0000000000000637","","INTRODUCTION: Screening for Barrett's esophagus (BE) is suggested in those with risk factors, but remains underutilized. BE/esophageal adenocarcinoma (EAC) risk prediction tools integrating multiple risk factors have been described. However, accuracy remains modest (area under the receiver-operating curve [AUROC] <= 0.7), and clinical implementation has been challenging. We aimed to develop machine learning (ML) BE/EAC risk prediction models from an electronic health record (EHR) database. METHODS: The Clinical Data Analytics Platform, a deidentified EHR database of 6 million Mayo Clinic patients, was used to predict BE and EAC risk. BE and EAC cases and controls were identified using International Classification of Diseases codes and augmented curation (natural language processing) techniques applied to clinical, endoscopy, laboratory, and pathology notes. Cases were propensity score matched to 5 independent randomly selected control groups. An ensemble transformer-based ML model architecture was used to develop predictive models. RESULTS: We identified 8,476 BE cases, 1,539 EAC cases, and 252,276 controls. The BE ML transformer model had an overall sensitivity, specificity, and AUROC of 76%, 76%, and 0.84, respectively. The EAC ML transformer model had an overall sensitivity, specificity, and AUROC of 84%, 70%, and 0.84, respectively. Predictors of BE and EAC included conventional risk factors and additional novel factors, such as coronary artery disease, serum triglycerides, and electrolytes. DISCUSSION: ML models developed on an EHR database can predict incident BE and EAC risk with improved accuracy compared with conventional risk factor-based risk scores. Such a model may enable effective implementation of a minimally invasive screening technology.","2023-10","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","10","14","","","","","","","","","","English","","","","WOS:001158090200007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","algorithm; artificial intelligence; esophageal cancer; prediction; SURVEILLANCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E9ESFT7D","journalArticle","2023","Yu, HL; Su, W; Liu, L; Zhang, J; Cai, C; Xu, CL","Pre-training model for low-resource Chinese-Braille translation","DISPLAYS","","0141-9382","10.1016/j.displa.2023.102506","","The technology for converting Chinese to Braille is of great importance. When paired with a Braille display, it can better meet the educational and daily needs of the visually impaired community, especially children and students. Incorporating visual assistance mechanisms can further enhance the user experience and provide comprehensive support for individuals with visual impairments. In recent years, the use of end-to-end neural machine translation models for Chinese-Braille translation has gained traction. However, this task requires large, high-quality, and domain-specific parallel data to train robust models. Unfortunately, the existing Chinese-Braille parallel data is insufficient to achieve satisfactory results. To address this challenge, this paper puts forward a groundbreaking approach that integrates pre-training models into the Chinese Braille translation task. This represents the first-ever application of such technology in this context and it is different from traditional pre-training methods. While previous pre-training method of natural language processing mainly utilized raw text data, we have identified its limitations in improving Chinese-Braille translation. Therefore, we have proposed three novel forms of pre-training datasets, instead of relying solely on raw text data. By utilizing the Transformer model, our approach achieves the highest BLEU score of 94.53 on a 10k parallel corpus, presenting a new direction for Chinese-Braille translation research. Furthermore, we introduce a new form of data that enables Chinese-Braille translation solely using the encoder framework. Leveraging the MacBERT model, this approach achieves a BLEU score of 98.87 on the test set and demonstrates an inference speed 54 times faster than the Transformer model. These findings have significant implications for the field of Chinese-Braille translation, providing insights for future research endeavors.","2023-09","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","79","","","","","","","","","","English","","","","WOS:001144738800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Chinese-Braille translation; Low-resource translation; Pre-training; Visually assistance mechanisms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"872B2FLY","journalArticle","2023","Saidani, O; Alsafyani, M; Alroobaea, R; Alturki, N; Jahangir, R; Jamel, L","An Efficient Human Activity Recognition Using Hybrid Features and Transformer Model","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3314492","","Human activity recognition is a challenging and active research topic in computer science due to its applications in video surveillance, health monitoring, rehabilitation, human-robot interaction, robotics, gesture and posture analysis, and sports. In the past, various studies have utilized manual features to identify human activities and obtained good accuracy. Nonetheless, the performance of such features degraded in complex situations. Therefore, recent research used deep learning (DL) techniques to capture the local features automatically from given activity instances. Though automatic feature extraction overcomes the problems of manual features, there is still a need to enhance the efficiency and accuracy of existing techniques. The motivation behind this research is to improve the efficiency and accuracy of HAR systems. This research proposed a HAR system, which applies data enhancement techniques before capturing robust and discriminative features set from each activity instance. The captured feature set is given to the transformer model for activities recognition using the PAMAP2, UCI HAR, and WISDM datasets. The achieved results revealed that the proposed HAR model outperformed the baseline methods. Specifically, the proposed HAR achieved 98.2% accuracy for PAMAP2 with all instances in 12 activities, 98.6% accuracy for UCI HAR with all instances in 6 activities, 97.3% for WISDM with all instances in 6 activities. The advantage of the proposed hybrid features is the capability to capture both low-level and high-level information from the sensor data, potentially enhancing the discriminative power of the system. In addition, this study employed a transformer a model due to its ability to capture long-range dependencies, which are beneficial in recognizing complex human activities patterns.","2023","2025-02-26 20:39:14","2025-02-26 20:39:14","","101373-101386","","","11","","","","","","","","","","English","","","","WOS:001071730500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","HAR; Human activity recognition; hybrid features; PAMP2; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GDYEHMK2","journalArticle","2022","Hlaing, ZZ; Thu, YK; Supnithi, T; Netisopakul, P","Improving neural machine translation with POS-tag features for low-resource language pairs","HELIYON","","2405-8440","10.1016/j.heliyon.2022.e10375","","Integrating linguistic features has been widely utilized in statistical machine translation (SMT) systems, resulting in improved translation quality. However, for low-resource languages such as Thai and Myanmar, the integration of linguistic features in neural machine translation (NMT) systems has yet to be implemented. In this study, we propose transformer-based NMT models (transformer, multi-source transformer, and shared-multi-source transformer models) using linguistic features for two-way translation of Thai-to-Myanmar, Myanmar-to-English, and Thai-to-English. Linguistic features such as part-of-speech (POS) tags or universal part-of-speech (UPOS) tags are added to each word on either the source or target side, or both the source and target sides, and the proposed models are conducted. The multi-source transformer and shared-multi-source transformer models take two inputs (i.e., string data and string data with POS tags) and produce string data or string data with POS tags. A transformer model that utilizes only word vectors was used as the first baseline model for comparison with the proposed models. The second baseline model, an Edit-Based Transformer with Repositioning (EDITOR) model, was also used to compare with our proposed models in addition to the baseline transformer model. The findings of the experiments show that adding linguistic features to the transformer-based models enhances the performance of a neural machine translation in low-resource language pairs. Moreover, the best translation results were yielded using shared-multi-source transformer models with linguistic features resulting in more significant Bilingual Evaluation Understudy (BLEU) scores and character n-gram F-score (chrF) scores than the baseline transformer and EDITOR models.","2022-08","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","8","8","","","","","","","","","","English","","","","WOS:000919415700022","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Linguistic features; Neural machine translation; Part-of-speech; Transformer architecture; Universal part -of -speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EPU9VICX","journalArticle","2025","Zhang, YT; Zhou, L; Zhu, SM; Zhou, YN; Wang, ZT; Ma, LA; Yuan, YQ; Xie, YS; Niu, XX; Su, YL; Liu, HQ; Hei, XH; Shi, ZH; Ren, XY; Shi, YW","Deep Learning for Obstructive Sleep Apnea Detection and Severity Assessment: A Multimodal Signals Fusion Multiscale Transformer Model","NATURE AND SCIENCE OF SLEEP","","1179-1608","10.2147/NSS.S492806","","Purpose: To develop a deep learning (DL) model for obstructive sleep apnea (OSA) detection and severity assessment and provide a new approach for convenient, economical, and accurate disease detection. Methods: Considering medical reliability and acquisition simplicity, we used electrocardiogram (ECG) and oxygen saturation (SpO2) signals to develop a multimodal signal fusion multiscale Transformer model for OSA detection and severity assessment. The proposed model comprises signal preprocessing, feature extraction, cross-modal interaction, and classification modules. A total of 510 patients who underwent polysomnography were included in the hospital dataset. The model was tested on hospital and public datasets. The hospital dataset was utilized to demonstrate the applicability and generalizability of the model. Two public datasets, Apnea-ECG dataset (consisting of 8 recordings) and UCD dataset (consisting of 21 recordings), were used to compare the results with those of previous studies. Results: In the hospital dataset, the accuracy (Acc) values of per-segment and per-recording detection were 91.38 and 96.08%, respectively. The Acc values for mild, moderate, and severe OSA were 90.20, 88.24, and 92.16%, respectively. The Bland-Altman plots revealed the consistency of the true apnea-hypopnea index (AHI) and the predicted AHI. In the public datasets, the per-segment detection Acc values of the Apnea-ECG and UCD datasets were 95.04 and 90.56%, respectively. Conclusion: The experiments on hospital and public datasets have demonstrated that the proposed model is more advanced, accurate, and applicable in OSA detection and severity assessment than previous models.","2025","2025-02-26 20:39:14","2025-02-26 20:39:14","","1-15","","","17","","","","","","","","","","English","","","","WOS:001390614100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","CLASSIFICATION; deep learning; detection model; DIAGNOSIS; multimodal signals fusion; obstructive sleep apnea","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WJPIE3IX","journalArticle","2024","Cao, BH; Sun, JX; Fan, MB; Ye, B; Li, C; Zhang, DM","Novel Conductivity Measurement of Thin Metallic Materials Using Crossover Frequency Feature From Triple-Frequency Eddy Current Signals","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2024.3383059","","Non-ferromagnetic thin metallic materials find extensive applications in the fields of electronics, aerospace, and instrumentation, wherein the conductivity of these metal materials serves as a crucial indicator of material quality. However, the established methods are subject to computational burdens like model-based inversion or invariant thickness. In this work, a novel simple but accurate method is proposed to determine the conductivity of thin films using the crossover frequency feature from eddy current impedance. First, the crossover phenomenon of resistance and reactance from swept-frequency eddy current impedance was investigated with a transformer model. It is found that the impedances of only triple frequencies are enough to accurately determine the crossover frequency point. Second, the crossover frequency is found to have an inverse proportionality to the conductivity of metal materials after mathematical manipulations, and it would change accordingly when the liftoff distance and sample thickness change. Afterward, a mathematical map was derived by fitting work between sample thickness and slope rate. In this case, the proposed method is suitable for samples with thickness change without recalibration. Last, a PCB single-coil eddy current sensor was designed to validate the presented method through simulations and experiments. The results demonstrate that the developed crossover feature based method from triple frequency impedances, compared with a reported single frequency method, achieves better accuracy and more stable measurement results, with a maximum relative error of 2.26%. This new method only needs to gauge sample thickness without recalibration work when the thickness of samples changes, and it does not need large computational resource.","2024","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","73","","","","","","","","","","English","","","","WOS:001342545400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Conductivity measurement; crossover frequency; PROBE; THICKNESS; thin metallic materials; transformer model; triple-frequency eddy current","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NAF83YJC","journalArticle","2024","Yang, YM; Cai, ZL; Qiu, SX; Xu, P","A Novel Transformer Model With Multiple Instance Learning for Diabetic Retinopathy Classification","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3351473","","Diabetic retinopathy (DR) is an irreversible fundus retinopathy. A deep learning-based auto-mated DR diagnosis system can save diagnostic time. While Transformer has shown superior performance compared to Convolutional Neural Network (CNN), it typically requires pre-training with large amounts of data. Although Transformer-based DR diagnosis method may alleviate the problem of limited performance on small-scale retinal datasets by loading pre-trained weights, the size of input images is restricted to 224 x 224. The resolution of retinal images captured by fundus cameras is much higher than 224 x 224, reducing resolution in training will result in the loss of valuable information. In order to efficiently utilize high-resolution retinal images, a new Transformer model with multiple instance learning (TMIL) is proposed for DR classification. A multiple instance learning approach is firstly applied on the retinal images to segment these high-resolution images into 224 x 224 image patches. Subsequently, Vision Transformer (ViT) is used to extract features from each patch. Then, Global Instance Computing Block (GICB) is designed to calculate the inter-instance features. After introducing global information from GICB, the features are used to output the classification results. When using high-resolution retinal images, TMIL can load pre-trained weights of Transformer without being affected by weight interpolation on model performance. Experimental results using the APTOS dataset and the Messidor-1 dataset demonstrate that TMIL achieves better classification performance and reduces inference time by 62% compared with that directly inputting high-resolution images into ViT. And TMIL shows highest classification accuracy compared with the current state-of-the-art results.","2024","2025-02-26 20:39:14","2025-02-26 20:39:14","","6768-6776","","","12","","","","","","","","","","English","","","","WOS:001143384600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","diabetic retinopathy; DISEASE; high-resolution fundus retinal images; IMAGES; medical image classification; multiple instance learning; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7VBYGEUE","journalArticle","2021","Shome, D; Kar, T; Mohanty, SN; Tiwari, P; Muhammad, K; AlTameem, A; Zhang, YZ; Saudagar, AKJ","COVID-Transformer: Interpretable COVID-19 Detection Using Vision Transformer for Healthcare","INTERNATIONAL JOURNAL OF ENVIRONMENTAL RESEARCH AND PUBLIC HEALTH","","1660-4601","10.3390/ijerph182111086","","In the recent pandemic, accurate and rapid testing of patients remained a critical task in the diagnosis and control of COVID-19 disease spread in the healthcare industry. Because of the sudden increase in cases, most countries have faced scarcity and a low rate of testing. Chest X-rays have been shown in the literature to be a potential source of testing for COVID-19 patients, but manually checking X-ray reports is time-consuming and error-prone. Considering these limitations and the advancements in data science, we proposed a Vision Transformer-based deep learning pipeline for COVID-19 detection from chest X-ray-based imaging. Due to the lack of large data sets, we collected data from three open-source data sets of chest X-ray images and aggregated them to form a 30 K image data set, which is the largest publicly available collection of chest X-ray images in this domain to our knowledge. Our proposed transformer model effectively differentiates COVID-19 from normal chest X-rays with an accuracy of 98% along with an AUC score of 99% in the binary classification task. It distinguishes COVID-19, normal, and pneumonia patient's X-rays with an accuracy of 92% and AUC score of 98% in the Multi-class classification task. For evaluation on our data set, we fine-tuned some of the widely used models in literature, namely, EfficientNetB0, InceptionV3, Resnet50, MobileNetV3, Xception, and DenseNet-121, as baselines. Our proposed transformer model outperformed them in terms of all metrics. In addition, a Grad-CAM based visualization is created which makes our approach interpretable by radiologists and can be used to monitor the progression of the disease in the affected lungs, assisting healthcare.","2021-11","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","21","18","","","","","","","","","","English","","","","WOS:000718967900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;71<br/>Total Times Cited:&nbsp;&nbsp;75<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","COVID-19; data science; deep learning; grad-CAM; healthcare; interpretability; transfer learning; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q2SZLSD6","journalArticle","2025","Yan, L; Wen, H; Wang, ZP; Jin, YF; Guo, J; Liu, Y; Fan, SX","Prediction and evaluation of key parameters in coalbed methane pre-extraction based on transformer and inversion model","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2024.109661","","Accurate parameter prediction in the coalbed methane (CBM) pre-extraction process is crucial for formulating effective control measures and preventing CBM-related accidents. Traditional prediction methods rely on feature extraction or complex physical model parameter calculations, which require extensive manual intervention and have limited practical applicability. Additionally, simple neural network methods are prone to overfitting and gradient vanishing when handling parameters, and they lack the capability to dynamically monitor gas pressure during extraction, leading to inefficient and blind extraction operations. This study proposes a CBM preextraction parameter and completion time prediction method based on the Transformer model. By integrating autoregressive models and wavelet denoising techniques, the approach effectively captures temporal features and long-term dependencies in CBM data. Experimental results demonstrate that the proposed model outperforms traditional methods in short-, medium-, and long-term predictions, with a median R2 value of 0.99072, and 76% of the training results exceeding 0.9. Furthermore, a CBM pressure inversion model was developed, combining dimensional analysis and physical similarity principles with the Transformer model, enabling the dynamic detection of high- and low-pressure regions in coal seams. In single borehole compliance time predictions, the median compliance time for the first stage is 4 days, with an average of 49 days and a maximum of 277 days, providing adjustment guidance for boreholes with extended compliance times. The proposed model significantly improves prediction accuracy and stability, offering critical support for developing scientifically sustainable pre-extraction plans and advancing intelligent CBM management.","2025-01","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","139","","","","","","","","","","English","","","","WOS:001358834300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","BOREHOLES; CBM PRODUCTION; Coalbed methane; Deep learning; FACE; GAS; Industrial safety; NETWORKS; NUMERICAL-SIMULATION; Sequential models; TECHNOLOGIES; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NIDPGWIE","journalArticle","2024","Zhou, GX; Liu, M; Li, LZ","A Spatiotemporal Fusion Transformer Model for Chlorophyll-a Concentrations Prediction Over Large Areas With Satellite Time Series Data","IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING","","0196-2892","10.1109/TGRS.2024.3451999","","Predicting Chlorophyll-a (Chla) is essential to support the marine environment changes and marine ecosystem health, and provide early warning of algae blooms. The development of learning-based methods has facilitated Chla prediction research. Still, most of the current methods can only predict short-term Chla changes in small areas, which is limited by the ability of the model to exploit spatiotemporal dependencies. Thus, this article proposes a spatiotemporal fusion transformer prediction model (STF_Transformer) to predict relatively long-term Chla changes (15 days ahead). This model utilizes temporal and spatial transformer modules to extract the temporal and spatial correlations of the input spatiotemporal sequences, which are then fused to predict the 15-day Chla. The experimental results show that the proposed model has the optimal performance compared to the existing methods [e.g., convolutional neural network (CNN), long- and short-term memory (LSTM), and convolutional LSTM (ConvLSTM)], with root mean squared error (RMSE), mean absolute error (MAE), and mean absolute percentage error (MAPE) less than 0.61 mg/m3, 0.315 mg/m3, and 22.5%, respectively, for 15 days Chla prediction in a large area (including Bohai, Yellow, and East China Sea). In addition, the temporal and spatial prediction results of the proposed model show that the predicted Chla has consistent temporal and spatial patterns with the observed Chla. This study indicates that the proposed STF_Transformer model can provide a highly accurate prediction of Chla over a large area in the relatively long term (15 days), providing data and technical support for marine ecosystem-related applications.","2024","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","62","","","","","","","","","","English","","","","WOS:001313400800026","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Biological system modeling; Chlorophyll-a (Chla) prediction; Data models; Feature extraction; large areas; OCEAN; Oceans; Predictive models; RESERVOIRS; satellite; spatiotemporal; Spatiotemporal phenomena; transformer; Transformers; WATER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DMFWDINN","journalArticle","2023","Le-Hong, P; Cambria, E","A semantics-aware approach for multilingual natural language inference","LANGUAGE RESOURCES AND EVALUATION","","1574-020X","10.1007/s10579-023-09635-6","","This paper introduces a semantics-aware approach to natural language inference which allows neural network models to perform better on natural language inference benchmarks. We propose to incorporate explicit lexical and concept-level semantics from knowledge bases to improve inference accuracy. We conduct an extensive evaluation of four models using different sentence encoders, including continuous bag-of-words, convolutional neural network, recurrent neural network, and the transformer model. Experimental results demonstrate that semantics-aware neural models give better accuracy than those without semantics information. On average of the three strong models, our semantic-aware approach improves natural language inference in different languages.","2023-06","2025-02-26 20:39:14","2025-02-26 20:39:14","","611-639","","2","57","","","","","","","","","","English","","","","WOS:000933417800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Commonsense; Language inference; Recurrent neural networks; Semantics; Text; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AKBSYHJB","journalArticle","2021","Lee, SS; Faroqi-Shah, Y","Performance of Korean-English bilinguals on an adaptation of the screening bilingual aphasia test","INTERNATIONAL JOURNAL OF LANGUAGE & COMMUNICATION DISORDERS","","1368-2822","10.1111/1460-6984.12623","","Background The use of standardized tests specifically designed for and normed on bilingual groups is crucial for the accurate diagnosis and language profiling of bilingual speakers with aphasia. Currently, there is a dearth of norms and supporting psychometric data for the few available bilingual aphasia assessments. The only available aphasia test for Korean-English (KE) bilinguals is the Korean-English Bilingual Aphasia Test (KE-BAT). The absence of bilingual normative data for the KE-BAT limits its clinical and research utility. Aims (1) To revise the original screening KE-BAT to clarify ambiguities in its instructions and stimuli; and (2) to examine subtest and item performance across the two languages for the revised screening KE-BAT with a local sample of highly proficient KE bilinguals. Methods & Procedures The original screening KE-BAT was first revised to replace unrecognizable drawings, address ambiguities in the instructions and stimuli, and increase the number of items on naming subtests. This revised test is henceforth referred to as the adapted screening KE-BAT (AS KE-BAT). A total of 21 neurologically healthy, highly proficient and college-educated KE bilinguals (19-34 years old) were recruited from a large city in the United States. Participants completed three measures of language proficiency and the AS KE-BAT including the KE translation test (Part C). Total and subtest scores were compared across the two languages, and individual item accuracy was calculated. Incorrect responses of low scoring items were examined. Outcomes & Results Performance was comparable across Korean and English for all subtests, except for the spontaneous speech subtest. The item accuracy of 17 items (7% of total items) in the AS KE-BAT fell to < 80%, and four items (1.6% of total items) had an accuracy < 60%. Incorrect responses of low scoring items were caused by phoneme misperception, lexical substitution and morphosyntactic L2 patterns. Conclusions & Implications The results of the study highlight the importance of empirically examining the performance of neurotypical bilinguals on bilingual aphasia assessments to establish their psychometric properties. Based on the small-sized local bilingual normative sample obtained in this study, appropriate cut-off criteria, recommendations for clinical interpretation and further modifications of the AS KE-BAT are proposed. What this paper adds What is already known on the subject The pair of English and Korean aphasia assessments (e.g., Western Aphasia Battery-Revised; WAB-R) (Kertesz 2012) and Korean Western Aphasia Battery (Kim and Na 2001) cannot be used to assess language impairments in KE bilinguals with aphasia since these tests have not been designed for and normed on the bilingual group. Clinical utility of the Korean-English Bilingual Aphasia Test (KE-BAT), which is the only resource currently available to assess KE bilinguals with aphasia, is greatly compromised by the lack of KE bilingual normative data. What this study adds to existing knowledge This study provides cut-off scores, comparability of test performance and item difficulty metrics and it identifies additional ways in which items and spontaneous speech scoring of the adapted screening KE-BAT (AS KE-BAT) could be modified. Suggested guidelines allow improved interpretations of the linguistic performance of local KE bilinguals with aphasia who have a similar demographic and linguistic background. What are the potential or actual clinical implications of this work? The AS KE-BAT with cut-off criteria of 95% for Part B and 80% for Part C is suitable for the language assessment of highly proficient and young KE bilinguals with a high level of education and it yields comparable performance across the two languages. Clinicians may decide to adjust spontaneous speech scoring criteria if the client's language history is suggestive of code-switching and use the item difficulty data to guide test item selection for this group of bilinguals.","2021-07","2025-02-26 20:39:14","2025-02-26 20:39:14","","719-738","","4","56","","","","","","","","","","English","","","","WOS:000645205100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","aphasia; bilingual; bilingual aphasia; BOSTON NAMING TEST; BRAIN; English bilinguals; Korean–; language assessment; LEXICAL ACCESS; PERCEPTION; psychometric properties; SPANISH-ENGLISH; SPEAKERS; SPEECH; STROKE; VERBAL FLUENCY; VOCABULARY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6BIKYWHS","journalArticle","2024","Shakeel, MA; Khattak, HA; Khurshid, N","Deep Acoustic Modelling for Quranic Recitation - Current Solutions and Future Directions","IPSI BGD TRANSACTIONS ON INTERNET RESEARCH","","1820-4503","","","The Holy Quran has the utmost importance for the Muslim community, and to get full reward, the Quran should be read according the rules mentioned. In the past few years, this field has gained a lot of importance in the eyes researchers who aim to automate the Quranic reading and understanding process with the help of Machine Learning and Deep Learning, knowing it has a lot of challenges. To date, there are a lot research categories explored. However, still, there lacks a few holistic, including one detailed survey of all the categories and methodologies used solve problems. We focused the paper on being one-stop-shop for the people interested so they could find (i) all related information and (ii) future gaps in research. This paper provides a detailed survey on Deep Modeling for Quranic Recitation address these challenges. We discussed possible categories of speech analysis, including the most advanced feature extraction techniques, mispronunciation detection using Tajweed rules, Reciters and speech dialect classification, and implementation of Automatic Speech Recognition (ASR) on Quranic Recitations. We also discussed research challenges in this domain and identified possible future gaps.","2024-07","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","2","20","","","","","","","","","","English","","","","WOS:001301297900005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Automatic Speech Recognition; Deep Learning; Feature Extraction; Mispronunciation Detection; Reciter Classification; Speech Analysis; Tajweed","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HXQMDD5R","journalArticle","2021","Kumar, S","Real-time implementation and performance evaluation of speech classifiers in speech analysis-synthesis","ETRI JOURNAL","","1225-6463","10.4218/etrij.2019-0364","","In this work, six voiced/unvoiced speech classifiers based on the autocorrelation function (ACF), average magnitude difference function (AMDF), cepstrum, weighted ACF (WACF), zero crossing rate and energy of the signal (ZCR-E), and neural networks (NNs) have been simulated and implemented in real time using the TMS320C6713 DSP starter kit. These speech classifiers have been integrated into a linear-predictive-coding-based speech analysis-synthesis system and their performance has been compared in terms of the percentage of the voiced/unvoiced classification accuracy, speech quality, and computation time. The results of the percentage of the voiced/unvoiced classification accuracy and speech quality show that the NN-based speech classifier performs better than the ACF-, AMDF-, cepstrum-, WACF- and ZCR-E-based speech classifiers for both clean and noisy environments. The computation time results show that the AMDF-based speech classifier is computationally simple, and thus its computation time is less than that of other speech classifiers, while that of the NN-based speech classifier is greater compared with other classifiers.","2021-02","2025-02-26 20:39:14","2025-02-26 20:39:14","","82-94","","1","43","","","","","","","","","","English","","","","WOS:000616698600008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","ACF; AMDF; Cepstrum; CLASSIFICATION; E; FEATURES; neural network; PITCH DETECTION; real‐; speech classification; time system; WACF; ZCR‐","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GL9JNNHZ","journalArticle","2022","Iuzzini-Seigel, J; Allison, KM; Stoeckel, R","A Tool for Differential Diagnosis of Childhood Apraxia of Speech and Dysarthria in Children: A Tutorial","LANGUAGE SPEECH AND HEARING SERVICES IN SCHOOLS","","0161-1461","10.1044/2022_LSHSS-21-00164","","Purpose: While there has been mounting research centered on the diagnosis of childhood apraxia of speech (CAS), little has focused on differentiating CAS from pediatric dysarthria. Because CAS and dysarthria share overlapping speech symptoms and some children have both motor speech disorders, differential diagnosis can be challenging. There is a need for clinical tools that facilitate assessment of both CAS and dysarthria symptoms in children. The goals of this tutorial are to (a) determine confidence levels of clinicians in differentially diagnosing dysarthria and CAS and (b) provide a systematic procedure for differentiating CAS and pediatric dysarthria in children. Method: Evidence related to differential diagnosis of CAS and dysarthria is reviewed. Next, a web-based survey of 359 pediatric speech-language pathologists is used to determine clinical confidence levels in diagnosing CAS and dysarthria. Finally, a checklist of pediatric auditory-perceptual motor speech features is presented along with a procedure to identify CAS and dysarthria in children with suspected motor speech impairments. Case studies illustrate application of this protocol, and treatment implications for complex cases are discussed. Results: The majority (60%) of clinician respondents reported low or no confidence in diagnosing dysarthria in children, and 40% reported they tend not to make this diagnosis as a result. Going forward, clinicians can use the feature checklist and protocol in this tutorial to support the differential diagnosis of CAS and dysarthria in clinical practice. Conclusions: Incorporating this diagnostic protocol into clinical practice should help increase confidence and accuracy in diagnosing motor speech disorders in children. Future research should test the sensitivity and specificity of this protocol in a large sample of children with varying speech sound disorders. Graduate programs and continuing education trainings should provide opportunities to practice rating speech features for children with dysarthria and CAS.","2022-10","2025-02-26 20:39:14","2025-02-26 20:39:14","","926-946","","4","53","","","","","","","","","","English","","","","WOS:000928434500002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;30<br/>Total Times Cited:&nbsp;&nbsp;31<br/>Cited Reference Count:&nbsp;&nbsp;94</p>","","","CEREBRAL-PALSY; COARTICULATION; DEVELOPMENTAL APRAXIA; DISORDERS; DOWN-SYNDROME; INTELLIGIBILITY; LANGUAGE; MAXIMUM PERFORMANCE-TASKS; MOTOR CONTROL; THERAPY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N4B9WEJ8","journalArticle","2024","Lim, WS; Chiu, S; Peng, PL; Jang, JSR; Lee, SH; Lin, CH; Kim, HJ","A cross-language speech model for detection of Parkinson's disease","JOURNAL OF NEURAL TRANSMISSION","","0300-9564","10.1007/s00702-024-02874-z","","Speech change is a biometric marker for Parkinson's disease (PD). However, evaluating speech variability across diverse languages is challenging. We aimed to develop a cross-language algorithm differentiating between PD patients and healthy controls using a Taiwanese and Korean speech data set. We recruited 299 healthy controls and 347 patients with PD from Taiwan and Korea. Participants with PD underwent smartphone-based speech recordings during the ""on"" phase. Each Korean participant performed various speech texts, while the Taiwanese participant read a standardized, fixed-length article. Korean short-speech (<= 15 syllables) and long-speech (> 15 syllables) recordings were combined with the Taiwanese speech dataset. The merged dataset was split into a training set (controls vs. early-stage PD) and a validation set (controls vs. advanced-stage PD) to evaluate the model's effectiveness in differentiating PD patients from controls across languages based on speech length. Numerous acoustic and linguistic speech features were extracted and combined with machine learning algorithms to distinguish PD patients from controls. The area under the receiver operating characteristic (AUROC) curve was calculated to assess diagnostic performance. Random forest and AdaBoost classifiers showed an AUROC 0.82 for distinguishing patients with early-stage PD from controls. In the validation cohort, the random forest algorithm maintained this value (0.90) for discriminating advanced-stage PD patients. The model showed superior performance in the combined language cohort (AUROC 0.90) than either the Korean (AUROC 0.87) or Taiwanese (AUROC 0.88) cohorts individually. However, with another merged speech data set of short-speech recordings < 25 characters, the diagnostic performance to identify early-stage PD patients from controls dropped to 0.72 and showed a further limited ability to discriminate advanced-stage patients. Leveraging multifaceted speech features, including both acoustic and linguistic characteristics, could aid in distinguishing PD patients from healthy individuals, even across different languages.","2024-12-30","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","","","","","","","","","","","English","","","","WOS:001385917300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Biomarkers; Deep-learning model; Face; Parkinson's disease; Speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BZA34G3K","journalArticle","2024","Wang, YW; Li, F; Zhang, XH; Wang, P; Li, YM; Zhang, YL","Intra-subject enveloped multilayer fuzzy sample compression for speech diagnosis of Parkinson's disease","MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING","","0140-0118","10.1007/s11517-023-02944-6","","Machine learning-based Parkinson's disease (PD) speech diagnosis is a current research hotspot. However, existing methods use each corpus sample as the base unit for modeling. Since different corpus samples within the same subject have different sensitive speech features, it is difficult to obtain unified and stable sensitive speech features (diagnostic markers) that reflect the pathology of the whole subject. Therefore, this study aims at compressing the corpus samples within the subject to facilitate the search for diagnostic markers with high diagnostic accuracy. A two-step sample compression module (TSCM) can solve the problem above. It includes two major parts: sample pruning module (SPM) and sample fuzzy clustering mechanism (SFCMD). Based on stacking multiple TSCMs, a multilayer sample compression module (MSCM) is formed to obtain multilayer compression samples. After that, simultaneous sample/feature selection mechanism (SS/FSM) is designed for feature selection. Based on the multilayer compression samples processed by MSCM and SS/FSM, a novel ensemble learning algorithm (EMSFE) is designed with sparse fusion ensemble learning mechanism (SFELM). The proposed EMSFE is validated by visualization of extracted features and performance comparison with related algorithms. The experimental results show that the proposed algorithm can effectively extract the stable diagnostic markers by compressing the corpus samples within the subject. Furthermore, based on LOSO cross validation, the proposed algorithm with extreme learning machine (ELM) classifier can achieve the accuracy of 92.5%, 93.75% and 91.67% on three datasets, respectively. The proposed EMSFE can extract unified and stable sensitive features that accurately reflect the overall pathology of the subject, which can better meet the requirements of clinical applications.The code and datasets can be found in:https://github.com/wywwwww/EMSFE-supplementary-material.gitGraphical AbstractMain flowchart of the proposed algorithm","2024-02","2025-02-26 20:39:14","2025-02-26 20:39:14","","371-388","","2","62","","","","","","","","","","English","","","","WOS:001093893700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","CLASSIFICATION; Corpus sample compression; Ensemble learning; Envelope learning; FEATURES; Fuzzy c-means clustering; MACHINE; MULTIPLE TYPES; Parkinson's disease; SELECTION; SPARSE; Speech diagnosis; VOICE RECORDINGS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WCLC736D","journalArticle","2024","Stipancic, KL; Whelan, BM; Laur, L; Zhao, YX; Rohl, A; Choi, I; Kuruvilla-Dugdale, M","Tipping the Scales: Indiscriminate Use of Interval Scales to Rate Diverse Dysarthric Features","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2024_JSLHR-23-00785","","Purpose: Error related to incorrect use of rating scales is problematic in the assessment and treatment of dysarthria. The main purpose of this project was to determine scale fit for cardinal speech features of hypokinetic dysarthria. A secondary aim was to determine rater reliability for the two different scales explored. Method: Forty-three speakers with Parkinson's disease (PD) and 25 neurologically healthy control talkers were recorded reading sentences from the Speech Intelligibility Test. Twenty-two healthy female listeners used both an equal appearing interval (EAI) scale and a direct magnitude estimation (DME) scale to rate five perceptual speech features (i.e., overall speech severity, articulatory imprecision, reduced loudness, short rushes of speech, and monotony) from these recordings. Regression analyses were used to determine the linearity of the relationship between the means of the EAI and DME ratings. Inter- and intrarater reliability was calculated using intraclass correlation coefficients and Spearman's correlation coefficients, respectively, for both EAI and DME ratings. Results: There was a linear relationship between EAI and DME means for monotony, indicating it is a metathetic dimension. Curvilinear relationships were observed between the EAI and DME means for the other four features, indicating prothetic dimensions. Intra- and interrater reliability values were similar for EAI and DME ratings. Discussion: Overall, results of this work suggest that DME is the best fit for scaling several hypokinetic dysarthria features, and not the conventionally used EAI scale. Prothetic dimensions best scaled by DME include overall speech severity, articulatory imprecision, reduced loudness, and short rushes of speech. Monotony was the only feature found to be a metathetic dimension and would be best scaled using EAI or DME. Findings call for rethinking the widespread use of EAI scales for rating perceptual features as part of the assessment and treatment of motor speech disorders.","2024-10","2025-02-26 20:39:14","2025-02-26 20:39:14","","3673-3685","","10","67","","","","","","","","","","English","","","","WOS:001343395000011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","CONSTRUCT-VALIDITY; DIRECT MAGNITUDE ESTIMATION; EQUAL-APPEARING INTERVAL; INTELLIGIBILITY; INTRACLASS CORRELATION-COEFFICIENTS; NATURALNESS; PERCEPTUAL EVALUATION; RELIABILITY; VISUAL ANALOG SCALES; VOICE QUALITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L9RS3TCH","journalArticle","2022","Yan, L; Mu, GX; Wang, QB; He, ZF; Zhu, YF","Time sequence information-based transformer for the judgement on the state of power dispatching","INTERNATIONAL JOURNAL OF COMPUTING SCIENCE AND MATHEMATICS","","1752-5055","10.1504/IJCSM.2022.10051269","","The key to avoiding power system abnormality, which often causes serious safety accidents, is finding abnormal data from massive data. The current abnormal detection model of the power dispatching system has low accuracy and low efficiency. Therefore, this paper proposes a new deep transformer model based on time-sequence features to automatically detect abnormal data. The model eliminates useless features in redundant data through the self-attention mechanism, extracts and analyses time-series features, for accurately detecting the abnormal. We evaluate the proposed model on the local dataset. The average detection accuracy of the model is 87.24% which has reached or even exceeded the accuracy of manual detection.","2022","2025-02-26 20:39:14","2025-02-26 20:39:14","","71-84","","1","16","","","","","","","","","","English","","","","WOS:000883154100007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","deep learning; power dispatching; self-attention mechanism; time-sequence; time-series; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3UTT2AI8","journalArticle","2023","Kang, K; Nunes, AS; Sharma, M; Hall, AJ; Mishra, RK; Casado, J; Cole, R; Derhammer, M; Barchard, G; Najafi, B; Vaziri, A; Wills, AM; Pantelyat, A","Utilizing speech analysis to differentiate progressive supranuclear palsy from Parkinson's disease","PARKINSONISM & RELATED DISORDERS","","1353-8020","10.1016/j.parkreldis.2023.105835","","Introduction: Distinguishing Parkinson's disease (PD) from Progressive supranuclear palsy (PSP) at early disease stages is important for clinical trial enrollment and clinical care/prognostication.Methods: We recruited 21 participants with PSP(n = 11) or PD(n = 10) with reliable caregivers. Standardized passage reading, counting, and sustained phonation were recorded on the BioDigit Home tablet (BioSensics LLC, Newton, MA USA), and speech features from the assessments were analyzed using the BioDigit Speech platform (BioSensics LLC, Newton, MA USA). An independent t-test was performed to compare each speech feature between PSP and PD participants. We also performed Spearman's correlations to evaluate associations between speech measures and clinical scores (e.g., PSP rating scales and MoCA). In addition, the model's performance in classifying PSP and PD was evaluated using Rainbow passage reading analysis.Results: During Rainbow passage reading, PSP participants had a significantly slower articulation rate (2.45(0.49) vs 3.60(0.47) words/minute), lower speech-to-pause ratio (2.33(1.08) vs 3.67(1.18)), intelligibility dynamic time warping (DTW, 0.26(0.19) vs 0.53(0.26)), and similarity DTW (0.43(0.27) vs 0.67(0.13)) compared to PD participants. PSP participants also had longer pause times (17.24(5.47) vs 8.45(3.13) sec) and longer total signal times (52.44(6.67) vs (36.67(6.73) sec) when reading the passage. In terms of the phonation 'a', PSP participants showed a significant higher spectral entropy, spectral centroid, and spectral spread compared to PD participants and no differences were found for phonation 'e'. PD participants had more accurate reverse number counts than PSP participants (14.89(3.86) vs 7.36(4.67)). PSP Rating Scale (PSPRS) dysarthria (r = 0.79, p = 0.004) and bulbar item scores (r = 0.803, p = 0.005) were positively correlated with articulation rate in reverse number counts. Correct reverse number counts were positively correlated with total Montreal Cognitive Assessment scores (r = 0.703, p = 0.016). Machine learning models using passage reading-derived measures obtained an AUC of 0.93, and the sensitivity/specificity in correctly classifying PSP and PD participants were 0.95 and 0.90, respectively.Conclusion: Our study demonstrates the feasibility of differentiating PSP from PD using a digital health technology platform. Further multi-center studies are needed to expand and validate our initial findings.","2023-10","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","115","","","","","","","","","","English","","","","WOS:001074568500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;15</p>","","","DIAGNOSIS; Digital biomarkers; DISORDERS; Machine learning; Parkinsonism; Remote patient monitoring; Speech assessments","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2PDT49CM","journalArticle","2025","Mu, ZY; Liang, AM; Ge, MM; Chen, DS; Fan, DX; Xu, MY","Generalizing morphologies in dam break simulations using transformer model","PHYSICS OF FLUIDS","","1070-6631","10.1063/5.0245680","","The interaction of waves with structural barriers, such as dam breaking, plays a critical role in flood defense and tsunami disasters. In this work, we explore the dynamic changes in wave surfaces impacting various structural shapes-circle, triangle, and square-using deep learning techniques. We introduce the ""DamFormer,"" a novel transformer-based model designed to learn and simulate these complex interactions. Additionally, we conducted zero-shot experiments to evaluate the model's ability to generalize across different domains. This approach enhances our understanding of fluid dynamics in marine engineering and opens new avenues for advancing computational methods in the field. Our findings demonstrate the potential of deep learning models like the DamFormer to provide significant insights and predictive capabilities in ocean engineering and fluid mechanics.","2025-01","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","1","37","","","","","","","","","","English","","","","WOS:001394069900018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","FLOW","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WEKCRA2E","journalArticle","2025","Xiao, GN; Tong, HL; Shu, YQ; Ni, AN","Spatial-temporal load prediction of electric bus charging station based on S2TAT","INTERNATIONAL JOURNAL OF ELECTRICAL POWER & ENERGY SYSTEMS","","0142-0615","10.1016/j.ijepes.2024.110446","","In recent years, electric buses have advanced rapidly due to their green and low-carbon attributes. To address range anxiety and optimize charging strategies, accurately predicting charging load has become essential. This paper introduces a synchronous spatial-temporal attention transformer (S2TAT) model that models temporal and spatial dependencies simultaneously, utilizing operational data from new energy electric buses in Shanghai. To improve charging event prediction, we propose two key improvements: an adaptive adjacency matrix for dynamic spatial dependencies learning and a periodicity extraction mechanism for capturing cyclical patterns. These enhancements significantly boost prediction accuracy over baseline models. An ablation study further verifies the contributions of the model's components.","2025-03","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","164","","","","","","","","","","English","","","","WOS:001398711500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Charging load prediction; Electric bus; Spatial-temporal series; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WDH2RLG6","journalArticle","2021","Li, ZH; Zhang, YJ; Abu-Siada, A; Chen, XX; Li, ZX; Xu, YC; Zhang, L; Tong, Y","Fault Diagnosis of Transformer Windings Based on Decision Tree and Fully Connected Neural Network","ENERGIES","","1996-1073","10.3390/en14061531","","While frequency response analysis (FRA) is a well matured technique widely used by current industry practice to detect the mechanical integrity of power transformers, interpretation of FRA signatures is still challenging, regardless of the research efforts in this area. This paper presents a method for reliable quantitative and qualitative analysis to the transformer FRA signatures based on a decision tree classification model and a fully connected neural network. Several levels of different six fault types are obtained using a lumped parameter-based transformer model. Results show that the proposed model performs well in the training and the validation stages, and is of good generalization ability.","2021-03","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","6","14","","","","","","","","","","English","","","","WOS:000634426700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;26<br/>Total Times Cited:&nbsp;&nbsp;28<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","decision tree; frequency response analysis; fully connected neural network; IMAGE; image processing; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FX4UPWVQ","journalArticle","2022","Teferra, BG; Borwein, S; DeSouza, DD; Rose, J","Screening for Generalized Anxiety Disorder From Acoustic and Linguistic Features of Impromptu Speech: Prediction Model Evaluation Study","JMIR FORMATIVE RESEARCH","","2561-326X","10.2196/39998","","Background: Frequent interaction with mental health professionals is required to screen, diagnose, and track mental health disorders. However, high costs and insufficient access can make frequent interactions difficult. The ability to assess a mental health disorder passively and at frequent intervals could be a useful complement to the conventional treatment. It may be possible to passively assess clinical symptoms with high frequency by characterizing speech alterations collected using personal smartphones or other wearable devices. The association between speech features and mental health disorders can be leveraged as an objective screening tool. Objective: This study aimed to evaluate the performance of a model that predicts the presence of generalized anxiety disorder (GAD) from acoustic and linguistic features of impromptu speech on a larger and more generalizable scale than prior studies did. Methods: A total of 2000 participants were recruited, and they participated in a single web-based session. They completed the Generalized Anxiety Disorder-7 item scale assessment and provided an impromptu speech sample in response to a modified version of the Trier Social Stress Test. We used the linguistic and acoustic features that were found to be associated with anxiety disorders in previous studies along with demographic information to predict whether participants fell above or below the screening threshold for GAD based on the Generalized Anxiety Disorder-7 item scale threshold of 10. Separate models for each sex were also evaluated. We reported the mean area under the receiver operating characteristic (AUROC) from a repeated 5-fold cross-validation to evaluate the performance of the models. Results: A logistic regression model using only acoustic and linguistic speech features achieved a significantly greater prediction accuracy than a random model did (mean AUROC 0.57, SD 0.03; P<.001). When separately assessing samples from female participants, we observed a mean AUROC of 0.55 (SD 0.05; P=.01). The model constructed from the samples from male participants achieved a mean AUROC of 0.57 (SD 0.07; P=.002). The mean AUROC increased to 0.62 (SD 0.03; P<.001) on the all-sample data set when demographic information (age, sex, and income) was included, indicating the importance of demographics when screening for anxiety disorders. The performance also increased for the female sample to a mean of 0.62 (SD 0.04; P<.001) when using demographic information (age and income). An increase in performance was not observed when demographic information was added to the model constructed from the male samples. Conclusions: A logistic regression model using acoustic and linguistic speech features, which have been suggested to be associated with anxiety disorders in prior studies, can achieve above-random accuracy for predicting GAD. Importantly, the addition of basic demographic variables further improves model performance, suggesting a role for speech and demographic information to be used as automated, objective screeners of GAD.","2022-10","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","10","6","","","","","","","","","","English","","","","WOS:001044189700030","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","acoustic features; anxiety prediction; generalized anxiety disorder; impromptu speech; linguistic features; mental health; mobile phone; RESPONSES; STRESS; TRAIT ANXIETY; WORDS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KWZ7NXSV","journalArticle","2024","Shao, B; Yan, JW","A long-context language model for deciphering and generating bacteriophage genomes","NATURE COMMUNICATIONS","","2041-1723","10.1038/s41467-024-53759-4","","Inspired by the success of large language models (LLMs), we develop a long-context generative model for genomes. Our multiscale transformer model, megaDNA, is pre-trained on unannotated bacteriophage genomes with nucleotide-level tokenization. We demonstrate the foundational capabilities of our model including the prediction of essential genes, genetic variant effects, regulatory element activity and taxonomy of unannotated sequences. Furthermore, it generates de novo sequences up to 96 K base pairs, which contain potential regulatory elements and annotated proteins with phage-related functions. MegaDNA, a long-context genomic language model, generates DNA sequences up to 96 K base pairs with annotated proteins and potential regulatory elements. It predicts essential genes, genetic variant effects, and regulatory element activity.","2024-10-30","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","1","15","","","","","","","","","","English","","","","WOS:001346144300015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q4P2SSD8","journalArticle","2023","Tay, Y; Dehghani, M; Bahri, D; Metzler, D","Efficient Transformers: A Survey","ACM COMPUTING SURVEYS","","0360-0300","10.1145/3530811","","Transformer model architectures have garnered immense interest lately due to their effectiveness across a range of domains like language, vision, and reinforcement learning. In the field of natural language processing for example, Transformers have become an indispensable staple in the modern deep learning stack. Recently, a dizzying number of ""X- former"" models have been proposed-Reformer, Linformer, Performer, Longformer, to name a few which improve upon the original Transformer architecture, many of which make improvements around computational and memory efficiency. With the aim of helping the avid researcher navigate this flurry, this article characterizes a large and thoughtful selection of recent efficiency-flavored ""X-former"" models, providing an organized and comprehensive overview of existing work and models across multiple domains.","2023-06","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","6","55","","","","","","","","","","English","","","","WOS:000893245700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;266<br/>Total Times Cited:&nbsp;&nbsp;282<br/>Cited Reference Count:&nbsp;&nbsp;95</p>","","","attention; deep learning; neural networks; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7AHCTF97","journalArticle","2024","Chen, QH; Wang, R; Lyu, M; Zhang, J","Transformer-Based Reinforcement Learning for Multi-Robot Autonomous Exploration","SENSORS","","1424-8220","10.3390/s24165083","","A map of the environment is the basis for the robot's navigation. Multi-robot collaborative autonomous exploration allows for rapidly constructing maps of unknown environments, essential for application areas such as search and rescue missions. Traditional autonomous exploration methods are inefficient due to the repetitive exploration problem. For this reason, we propose a multi-robot autonomous exploration method based on the Transformer model. Our multi-agent deep reinforcement learning method includes a multi-agent learning method to effectively improve exploration efficiency. We conducted experiments comparing our proposed method with existing methods in a simulation environment, and the experimental results showed that our proposed method had a good performance and a specific generalization ability.","2024-08","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","16","24","","","","","","","","","","English","","","","WOS:001305869700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","artificial neural network; DEEP; deep reinforcement learning; GAME; GO; robot exploration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T4ZJV9ZW","journalArticle","2024","Hernandez, M; Ronderos, J; Castilla-Earls, AP","Diagnostic Accuracy of Grammaticality and Utterance Length in Bilingual Children","LANGUAGE SPEECH AND HEARING SERVICES IN SCHOOLS","","0161-1461","10.1044/2024_LSHSS-23-00100","","Purpose: The purpose of this study was to investigate the diagnostic accuracy of two measures derived from spontaneous language samples, mean length of utterance in words (MLUw) and percentage of grammatical utterances (PGU), in identifying developmental language disorder (DLD) in Spanish-English bilingual children. We examined two approaches: best language and total language. Method: The participants in this study included 74 Spanish-English bilingual children with (n = 36) and without (n = 38) DLD. Language samples were elicited through a story retell and story generation task using Frog wordless picture books in English and Spanish. Stories were transcribed and coded using the Systematic Analysis of Language Samples (Miller & Iglesias, 2020) to extract MLUw and PGU in both languages. Results: Logistic regression analyses suggested that a model that included PGU, MLUw, and age achieved the best diagnostic accuracy in predicting group membership. Both approaches, best language and total language, had fair diagnostic accuracy. Conclusions: In combination, PGU and MLUw seem to be useful diagnostic tools to differentiate bilingual children with and without DLD. Clinical implications and usability are discussed.","2024-04","2025-02-26 20:39:14","2025-02-26 20:39:14","","577-597","","2","55","","","","","","","","","","English","","","","WOS:001209430300003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","AGE; IMPAIRMENT; LANGUAGE SAMPLE ANALYSIS; MORPHOLOGY; PRESCHOOL; PREVALENCE; SPANISH-SPEAKING CHILDREN; SPONTANEOUS SPEECH; TENSE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YBJVDKIE","journalArticle","2023","Shafaei-Bajestan, E; Moradipour-Tari, M; Uhrig, P; Baayen, RH","LDL-AURIS: a computational model, grounded in error-driven learning, for the comprehension of single spoken words","LANGUAGE COGNITION AND NEUROSCIENCE","","2327-3798","10.1080/23273798.2021.1954207","","A computational model for the comprehension of single spoken words is presented that builds on an earlier model using discriminative learning. Real-valued features are extracted from the speech signal instead of discrete features. Vectors representing word meanings using one-hot encoding are replaced by real-valued semantic vectors. Instead of incremental learning with Rescorla-Wagner updating, we use linear discriminative learning, which captures incremental learning at the limit of experience. These new design features substantially improve prediction accuracy for unseen words, and provide enhanced temporal granularity, enabling the modelling of cohort-like effects. Visualisation with t-SNE shows that the acoustic form space captures phone-like properties. Trained on 9 h of audio from a broadcast news corpus, the model achieves recognition performance that approximates the lower bound of human accuracy in isolated word recognition tasks. LDL-AURIS thus provides a mathematically-simple yet powerful characterisation of the comprehension of single words as found in English spontaneous speech.","2023-04-21","2025-02-26 20:39:14","2025-02-26 20:39:14","","509-536","","4","38","","","","","","","","","","English","","","","WOS:000675705800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;116</p>","","","ACQUISITION; ACTIVATION; AMBIGUITY; DYNAMICS; error-driven learning; FREQUENCY; INTELLIGIBILITY; linear discriminative learning; naive discriminative learning; RECOGNITION; REPRESENTATIONS; SHORTLIST; SPEECH; Spoken word recognition; Widrow-Hoff learning rule","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PPXFN82J","journalArticle","2021","Pook, H","OBJECT CASE VARIATION OF THE PRONOUN MIS 'WHAT' IN SPONTANEOUS SPOKEN ESTONIAN AND ESTONIAN DIALECTS","EESTI JA SOOME-UGRI KEELETEADUSE AJAKIRI-JOURNAL OF ESTONIAN AND FINNO-UGRIC LINGUISTICS","","1736-8987","10.12697/jeful.2021.12.1.07","","The Estonian language makes a systematic distinction between total and partial objects on the basis of semantic and syntactic features: total objects occur in nominative or genitive, partial objects in partitive. However, in the case of the interrogative-relative pronoun mis 'what', the partitive mida in the expected partial object position can be replaced with the nominative mis. The aim of this paper is to determine which variables significantly affect this object case variation, how the variation differs between contemporary speech and archaic dialects and what might have possibly motivated the development of this variation. This study is based on the data in the Phonetic Corpus of Estonian Spontaneous Speech and the Corpus of Estonian Dialects. The results show that the variation is most affected by verb type, clause type, length of the following word and dialect. It is concluded that there might be multiple motivations behind this variation, mainly language contact (or a lack of it in certain areas), high usage frequency of the pronoun mis and the effect of the standardisation of language.","2021","2025-02-26 20:39:14","2025-02-26 20:39:14","","259-301","","1","12","","","","","","","","","","English","","","","WOS:000693001700008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;86</p>","","","CONSTRUCTIONS; differential object marking; Estonian dialects; interrogative-relative pronouns; spoken language; syntax; TREES; variation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LUBEWZJN","journalArticle","2024","Blom, E; Yazici, G; Boerma, T; van Witteloostuijn, M","A longitudinal study of Turkish-Dutch children's language mixing in single-language settings: Language status, language proficiency, cognitive control and developmental language disorder","COGNITIVE DEVELOPMENT","","0885-2014","10.1016/j.cogdev.2024.101481","","The aim of this study was to investigate the role of language status, language proficiency, cognitive control and Developmental Language Disorder (DLD) in bilingual Turkish-Dutch children's language mixing in single-language settings. We investigated these factors over time following 31 children (20 with typical development, 11 with DLD), from the age of 5 or 6 years until they were 7 or 8 years old. Children more often mix the majority-societal language (Dutch) into the minority-heritage language (Turkish) than the other way around. Higher proficiency in Dutch, lower proficiency in Turkish, and having DLD are linked to more mixing in the Turkish setting. Effects of cognitive control on children's language mixing are limited. Linguistic factors at a child-external and child-internal level impact on children's mixing in single-language settings, and are more important than domain-general cognitive control. Increasing language proficiency in Turkish could explain why children mix less as they grow older.","2024-07","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","71","","","","","","","","","","English","","","","WOS:001265226100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","ABILITY; BILINGUAL-CHILDREN; Bilingualism; Cognitive control; Developmental Language Disorder; IMPAIRMENT; Language mixing; Language proficiency; PREVALENCE; Semi -spontaneous speech; SUSTAINED ATTENTION; VOCABULARY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CL2SE4H4","journalArticle","2021","Baird, A; Cristiano, A; Nagy, N","Apocope in Heritage Italian","LANGUAGES","","2226-471X","10.3390/languages6030120","","Apocope (deletion of word-final vowels) and word-final vowel reduction are hallmarks of southern Italian varieties. To investigate whether heritage speakers reproduce the complex variable patterns of these processes, we analyze spontaneous speech of three generations of heritage Calabrian Italian speakers and a homeland comparator sample. All occurrences (N = 2477) from a list of frequent polysyllabic words are extracted from 25 speakers' interviews and analyzed via mixed effects models. Tested predictors include: vowel identity, phonological context, clausal position, lexical frequency, word length, gender, generation, ethnic orientation and age. Homeland and heritage speakers exhibit similar distributions of full, reduced and deleted forms, but there are inter-generational differences in the constraints governing the variation. Primarily linguistic factors condition the variation. Homeland variation in reduction shows sensitivity to part of speech, while heritage speakers show sensitivity to segmental context and part of speech. Slightly different factors influence apocope, with suprasegmental factors and part of speech significant for homeland speakers, but only part of speech for heritage speakers. Surprisingly, for such a socially marked feature, few social factors are relevant. Factors influencing reduction and apocope are similar, suggesting the processes are related.","2021-09","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","3","6","","","","","","","","","","English","","","","WOS:000702288000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","apocope; Calabrese; CONTACT; DELETION; heritage language; Italian; LANGUAGE; ORGANIZATION; variationist sociolinguistics; vowel centralization; vowel reduction; VOWEL REDUCTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CZCEZPRH","journalArticle","2023","Jachimek, A; Köpcke, KM; Dimroth, C","Anaphoric reference in a German-Polish bilingual child","LINGUISTICS VANGUARD","","2199-174X","10.1515/lingvan-2022-0063","","The study examines the use of referring expressions in anaphoric contexts in a German-Polish bilingual child between age 2;0 to 4;0. The longitudinal corpus consists of 160 video recordings of spontaneous speech in both languages. There are fundamental differences in the way anaphoric reference is expressed in German and Polish. Speakers of German refer to discourse-given referents either with a definite NP, a personal or a demonstrative pronoun. Speakers of Polish - a pro drop language without articles - mostly use bare nouns or null pronouns. Overt pronouns and demonstrative determiners are restricted to specific information structure conditions. We found an overuse of overt pronouns and demonstrative determiners in Polish in comparison to a monolingual Polish child of the same age and also qualitative differences in the use of the relevant expressions. Despite the fact that the earliest child grammar in both languages rather resembles the Polish target (no articles, no pronouns), the reliable markers of discourse-givenness encountered in the German input are rapidly acquired and overextended to Polish, before the more implicit Polish system is in place.","2023-06-30","2025-02-26 20:39:14","2025-02-26 20:39:14","","191-200","","","9","","","","","","","","","","English","","","","WOS:000900743100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","ACQUISITION; anaphoric reference; bilingual language acquisition; cross-linguistic influence; German; Polish; SUBJECT REALIZATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7YY9J2IS","journalArticle","2023","Lubinus, C; Keitel, A; Obleser, J; Poeppel, D; Rimmele, JM","Explaining flexible continuous speech comprehension from individual motor rhythms","PROCEEDINGS OF THE ROYAL SOCIETY B-BIOLOGICAL SCIENCES","","0962-8452","10.1098/rspb.2022.2410","","When speech is too fast, the tracking of the acoustic signal along the auditory pathway deteriorates, leading to suboptimal speech segmentation and decoding of speech information. Thus, speech comprehension is limited by the temporal constraints of the auditory system. Here we ask whether individual differences in auditory-motor coupling strength in part shape these temporal constraints. In two behavioural experiments, we characterize individual differences in the comprehension of naturalistic speech as function of the individual synchronization between the auditory and motor systems and the preferred frequencies of the systems. Obviously, speech comprehension declined at higher speech rates. Importantly, however, both higher auditory-motor synchronization and higher spontaneous speech motor production rates were predictive of better speech-comprehension performance. Furthermore, performance increased with higher working memory capacity (digit span) and higher linguistic, model-based sentence predictability-particularly so at higher speech rates and for individuals with high auditory-motor synchronization. The data provide evidence for a model of speech comprehension in which individual flexibility of not only the motor system but also auditory-motor synchronization may play a modulatory role.","2023-03-08","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","1994","290","","","","","","","","","","English","","","","WOS:000941349200003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;89</p>","","","audiomotor; auditory-motor synchronization; INFORMATION; INTELLIGIBILITY; LANGUAGE COMPREHENSION; OPINION; ORGANIZATION; oscillations; OSCILLATIONS; PATTERNS; PERCEPTION; PREDICTION; speech perception; speech production; TIME-COMPRESSED SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HMLTRL4H","journalArticle","2023","Halpern, BM; Feng, SY; van Son, R; van den Brekel, M; Scharenborg, O","Automatic evaluation of spontaneous oral cancer speech using ratings from naive listeners","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2023.03.008","","In this paper, we build and compare multiple speech systems for the automatic evaluation of the severity of a speech impairment due to oral cancer, based on spontaneous speech. To be able to build and evaluate such systems, we collected a new spontaneous oral cancer speech corpus from YouTube consisting of 124 utterances rated by 100 non-expert listeners and one trained speech-language pathologist, which we made publicly available. We evaluated the systems in two scenarios: a scenario where transcriptions were available (reference-based) and a scenario where transcriptions might not be available (reference-free).The results of extensive experiments showed that (1) when transcriptions were available, the highest correlation with the human severity ratings was obtained using an automatic speech recognition (ASR) retrained with oral cancer speech. (2) When transcriptions were not available, the best results were achieved by a LASSO model using modulation spectrum features. (3) We found that naive listeners' ratings are highly similar to the speech pathologist's ratings for speech severity evaluation. (4) The use of binary labels led to lower correlations of the automatic methods with the human ratings than using severity scores.","2023-04","2025-02-26 20:39:14","2025-02-26 20:39:14","","84-97","","","149","","","","","","","","","","English","","","","WOS:000974261300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Automatic speech evaluation; HEAD; INTELLIGIBILITY ASSESSMENT; NECK-CANCER; Oral cancer; Pathological speech; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9XFTJ7NL","journalArticle","2022","Christou, S; Coloma, CJ; Andreu, L; Guerra, E; Araya, C; Rodriguez-Ferreiro, J; Sanz-Torrent, M","Online Comprehension of Verbal Number Morphology in Children With Developmental Language Disorder: An Eye-Tracking Study","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2022_JSLHR-21-00591","","Purpose: Previous studies have raised the possibility of preserved language comprehension in children with developmental language disorder (DLD) in online tasks and within simple sentence structures. Consequently, we evaluated the capacity of children with DLD to comprehend verbal number agreement in simple sentence structures (i.e., verb-object-subject and verb-subject). Method: Using an eye-tracking methodology, we conducted two psycholinguistic experiments with 96 Spanish- and Catalan-speaking participants. The sample was distributed into four groups: 24 children with DLD (age range: 4;6-12;6 [years;months]; average age = 7;8 [years;months]), 24 children with the same chronological age (4;6-12;2, 7;8), 24 children with the same linguistic level (4;6-9;4, 6;8), and 24 university students as language experts (18-30, 22;5). Results: The experimental data indicate that children with DLD can comprehend verbal number agreement at least under the present experimental conditions. Conclusion: The empirical outcomes suggest that number morphology comprehension by children with DLD might be more typical than what it is generally considered to be.","2022-11","2025-02-26 20:39:14","2025-02-26 20:39:14","","4181-4204","","11","65","","","","","","","","","","English","","","","WOS:000891439000012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;78</p>","","","ENGLISH; GRAMMATICAL MORPHOLOGY; IMPAIRMENT; PREPOSITIONS; PSYCHOLINGUISTIC MARKERS; SENTENCE COMPREHENSION; SLI; SPANISH-SPEAKING CHILDREN; SPONTANEOUS SPEECH; WORKING-MEMORY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J56EK2I6","journalArticle","2022","Shor, L; Reshef, Y; Gonen, E","PRONOMINAL SUBJECT EXPRESSION IN SPOKEN MODERN HEBREW: A DIACHRONIC PERSPECTIVE","JOURNAL OF SEMITIC STUDIES","","0022-4480","10.1093/jss/fgab030","","As a consequence of the sociolinguistic circumstances of its emergence, the morpho-syntactic profile of Modern Hebrew (MH) originates in several sources - classical layers of Hebrew, pre-existing written practices, contact-induced influence of the native languages of the early MH speakers and internal linguistic developments. Adopting a diachronic corpus-based perspective, the present study focuses on one morpho-syntactic feature, the distribution of first and second person free subject pronouns with suffix (qatal) and prefix (yiwol) conjugation verbs. In contrast to the mainly synchronic studies of that feature in MH, the starting point of the present study is data extracted from historical recordings documenting the spontaneous speech of four generations of MH speakers over more than 50 years. Our data indicate two opposite trends: On the one hand, there is a relative stability in the rates of free pronoun usage from the 1960s until the 2010s in two aspects: the near obligatory presence of the free 1sG pronoun ani in the prefix-conjugation, and the relatively low rates of free pronouns in the remaining persons. On the other hand, a significant decrease in the use of the 1sG pronoun ani in the suffix-conjugation was found throughout the years.","2022-02-24","2025-02-26 20:39:14","2025-02-26 20:39:14","","269-288","","1","67","","","","","","","","","","English","","","","WOS:000760971200016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","BILINGUAL ACQUISITION; LANGUAGE; REALIZATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D9KXP9R8","journalArticle","2021","Umbal, P; Nagy, N","Heritage Tagalog Phonology and a Variationist Framework of Language Contact","LANGUAGES","","2226-471X","10.3390/languages6040201","","Heritage language variation and change provides an opportunity to examine the interplay of contact-induced and language-internal effects while extending the variationist framework beyond monolingual speakers and majority languages. Using data from the Heritage Language Variation and Change in Toronto Project, we illustrate this with a case study of Tagalog (r), which varies between tap, trill, and approximant variants. Nearly 3000 tokens of (r)-containing words were extracted from a corpus of spontaneous speech of 23 heritage speakers in Toronto and 9 homeland speakers in Manila. Intergenerational and intergroup analyses were conducted using mixed-effects modeling. Results showed greater use of the approximant among second-generation (GEN2) heritage speakers and those that self-report using English more. In addition, the distributional patterns remain robust and the approximant appears in more contexts. We argue that these patterns reflect an interplay between internal and external processes of change. We situate these findings within a framework for distinguishing sources of variation in heritage languages: internal change, identity marking and transfer from the dominant language.","2021-12","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","4","6","","","","","","","","","","English","","","","WOS:000737649100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;95</p>","","","ACQUISITION; BILINGUALS; ENGLISH; ETHNIC ORIENTATION; FOREIGN-LANGUAGE; heritage language; IDENTITY; internal change; language contact; language transfer; lenition; rhotics; RHOTICS; SPANISH; SPEAKERS; SPEECH; Tagalog; variationist sociolinguistics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2BJZWYTZ","journalArticle","2023","Kaland, C","Contour clustering: A field-data-driven approach for documenting and analysing prototypical f0 contours","JOURNAL OF THE INTERNATIONAL PHONETIC ASSOCIATION","","0025-1003","10.1017/S0025100321000049","","This paper reports an automatic data-driven analysis for describing prototypical intonation patterns, particularly suitable for initial stages of prosodic research and language description. The approach has several advantages over traditional ways to investigate intonation, such as the applicability to spontaneous speech, language- and domain-independency, and the potential of revealing meaningful functions of intonation. These features make the approach particularly useful for language documentation, where the description of prosody is often lacking. The core of this approach is a cluster analysis on a time-series of f0 measurements and consists of two scripts (Praat and R, available from https://constantijnkaland.github.io/contourclustering/). Graphical user interfaces can be used to perform the analyses on collected data ranging from spontaneous to highly controlled speech. There is limited need for manual annotation prior to analysis and speaker variability can be accounted for. After cluster analysis, Praat textgrids can be generated with the cluster number annotated for each individual contour. Although further confirmatory analysis is still required, the outcomes provide useful and unbiased directions for any investigation of prototypical f0 contours based on their acoustic form.","2023-04","2025-02-26 20:39:14","2025-02-26 20:39:14","","159-188","","1","53","","","","","","","","","","English","","","","WOS:000768593000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","WORD STRESS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J2JSI433","journalArticle","2022","Salemme, S; Benuzzi, F; Fiondella, L; Carbone, C; Vinceti, G; Magarelli, S; Molinari, MA; Malagoli, M; Zamboni, G; Chiari, A","Pure word deafness: a case report of an atypical manifestation of Alzheimer's disease","NEUROLOGICAL SCIENCES","","1590-1874","10.1007/s10072-022-06213-6","","Background Auditory agnosia refers to the impairments in sound recognition despite intact hearing and written language abilities. When auditory agnosia is specific to spoken language, it can be indicated as pure word deafness (PWD), which is characterized by the isolated difficulty in understanding spoken language, despite preserved reading comprehension, recognition of nonverbal sounds, and production of written and spoken language. Case A middle-aged man with a high level of education developed a progressive speech disorder initially characterized by isolated phonemic errors during spontaneous speech and later enriched by difficulties in comprehending long sentences. The patient's past medical history was unremarkable except for hypertension. The neuropsychological picture was suggestive of PWD, while cerebrospinal fluid (CSF) analyses lead to a biomarker-based diagnosis of Alzheimer's disease (AD). PWD remained the prevalent cognitive deficit over the subsequent 4 years. Conclusions This case report shows that the presence of isolated auditory agnosia or PWD should prompt consideration of a diagnosis of AD. It also suggests that the spectrum of atypical presentations of early-onset AD may be larger than what we currently think.","2022-09","2025-02-26 20:39:14","2025-02-26 20:39:14","","5275-5279","","9","43","","","","","","","","","","English","","","","WOS:000812007300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;13</p>","","","Alzheimer's disease; CSF; FDG-PET; MRI; PATIENT; Pure word deafness","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J3PME5MF","journalArticle","2021","Seifart, F; Strunk, J; Danielsen, S; Hartmann, I; Pakendorf, B; Wichmann, S; Witzlack-Makarevich, A; Himmelmann, NP; Bickel, B","The extent and degree of utterance-final word lengthening in spontaneous speech from 10 languages","LINGUISTICS VANGUARD","","2199-174X","10.1515/lingvan-2019-0063","","Words in utterance-final positions are often pronounced more slowly than utterance-medial words, as previous studies on individual languages have shown. This paper provides a systematic cross-linguistic comparison of relative durations of final and penultimate words in utterances in terms of the degree to which such words are lengthened. The study uses time-aligned corpora from 10 genealogically, areally, and culturally diverse languages, including eight small, under-resourced, and mostly endangered languages, as well as English and Dutch. Clear effects of lengthening words at the end of utterances are found in all 10 languages, but the degrees of lengthening vary. Languages also differ in the relative durations of words that precede utterance-final words. In languages with on average short words in terms of number of segments, these penultimate words are also lengthened. This suggests that lengthening extends backwards beyond the final word in these languages, but not in languages with on average longer words. Such typological patterns highlight the importance of examining prosodic phenomena in diverse language samples beyond the small set of majority languages most commonly investigated so far.","2021-01-27","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","1","7","","","","","","","","","","English","","","","WOS:000733308700011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","CONTEXTUAL PREDICTABILITY; DURATION; final lengthening; FREQUENCY; language documentation; PHRASE; POSITION; prosodic typology; word duration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WXXK3TGY","journalArticle","2021","Herrera, DA; Rodríguez, S; Niño, D; Pardo-Martínez, M; Giraldo, V","The UAN Colombian co-speech gesture corpus","LANGUAGE RESOURCES AND EVALUATION","","1574-020X","10.1007/s10579-021-09540-w","","A research group from the Universidad Antonio Narino at Bogota, Colombia, collected over four hours of audiovisual interaction between the Dean of the Faculty of Systems Engineering and prospective Colombian students to help answer questions about how to annotate Colombian gesture during spontaneous speech. Out of 10 interviews conducted during two semesters showing dyadic or multiparty interactions and recorded from three angles, the group selected five dyadic interactions from the second semester totaling over an hour and a half to code for gesture and speech behaviors. The group transcribed the speech and coded the behaviors of the Dean using the NEUROGES-ELAN coding system and the ELAN annotation software, adjusted to the group's purposes. The group was able to achieve acceptable inter-rater reliability (around 80%) for all NEUROGES-ELAN modules. From the last Function category tier in NEUROGES-ELAN, which corresponds to conversational gestures, the group further determined lexical entries and assigned lexical affiliates. The results were then used to generate a gesture lexicon based on lexical affiliates. Lessons learned from the gesture/speech corpus will be applied to the recording and annotation of future Colombian gesture corpora with other subjects and in other contexts.","2021-09","2025-02-26 20:39:14","2025-02-26 20:39:14","","833-854","","3","55","","","","","","","","","","English","","","","WOS:000650096700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;94</p>","","","Annotation; BEHAVIOR; Gesture; Multimodal interaction; NEUROGES-ELAN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VMB9YMUQ","journalArticle","2023","Belz, M","Defining Filler Particles: A Phonetic Account of the Terminology, Form, and Grammatical Classification of ""Filled Pauses""","LANGUAGES","","2226-471X","10.3390/languages8010057","","The terms hesitation, planner, filler, and filled pause do not always refer to the same phonetic entities. This terminological conundrum is approached by investigating the observational, explanatory, and descriptive inadequacies of the terms in use. Concomitantly, the term filler particle is motivated and a definition is proposed that identifies its phonetic exponents and describes them within the linguistic category of particles. The definition of filler particles proposed here is grounded both theoretically and empirically and then applied to a corpus of spontaneous dialogues with 32 speakers of German, showing that in addition to the prototypical phonetic forms, there is a substantial amount of non-prototypical forms, i.e., 9.5%, comprising both glottal (e.g., [P]) and vocal forms (e.g., [epsilon Phi], [ j epsilon ve]). The grammatical classification and the results regarding the phonetic forms are discussed with respect to their theoretical relevance in filler particle research and corpus studies. The phonetic approach taken here further suggests a continuum of phonetic forms of filler particles, ranging from singleton segments to multi-syllabic entities.","2023-03","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","1","8","","","","","","","","","","English","","","","WOS:000960588200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;93</p>","","","continuum; corpus study; definition; DISFLUENCIES; ENGLISH; filled pause; filler; filler particle; FLUENCY; hesitation; HESITATION MARKERS; interjection; INTERJECTIONS; phonetic form; SIGNAL; SPEECH; spontaneous speech; UH; UM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M88EXHTV","journalArticle","2024","Cichocki, W; Kaminskaïa, S; Hagar, L","Regional variation in articulation rate in French spoken in Canada","JOURNAL OF THE INTERNATIONAL PHONETIC ASSOCIATION","","0025-1003","10.1017/S0025100323000154","","This study examines articulation rate in three varieties of Canadian French and includes consideration of speaking style (reading vs. spontaneous), speaker's age and gender, and length of inter-pause intervals. The varieties are spoken in different geographic areas of Canada - Quebec City (Quebec), Tracadie (New Brunswick), and Windsor (Ontario) - where there are different degrees of French-English contact. The main research question asks how these different contact situations are related to variation in articulation rate. Results show that in both reading and spontaneous speech articulation rates were faster among Quebec City speakers, where French is in a low-contact setting, and slower among speakers from Tracadie and Windsor, where there are greater degrees of contact. The effects of other factors are the same across the three regions: AR was faster in spontaneous productions than in reading; AR decreased with age in the reading task; AR was faster as the length of the inter-pausal intervals increased. The discussion points to similarities and differences with varieties of French spoken in Europe and underscores the importance of language contact in accounting for variation in articulation rate.","2024-04","2025-02-26 20:39:14","2025-02-26 20:39:14","","126-145","","1","54","","","","","","","","","","English","","","","WOS:001027257400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","AGE; AMERICAN; BETWEEN-SPEAKER; LANGUAGE; SPEECH RATE; WITHIN-SPEAKER VARIATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FFM23GEY","journalArticle","2023","Muhlack, B; Trouvain, J; Jessen, M","Distributional and Acoustic Characteristics of Filler Particles in German with Consideration of Forensic-Phonetic Aspects","LANGUAGES","","2226-471X","10.3390/languages8020100","","In this study, we investigate the use of the filler particles (FPs) uh, um, hm, as well as glottal FPs and tongue clicks of 100 male native German speakers in a corpus of spontaneous speech. For this purpose, the frequency distribution, FP duration, duration of pauses surrounding FPs, voice quality of FPs, and their vowel quality are investigated in two conditions, namely, normal speech and Lombard speech. Speaker-specific patterns are investigated on the basis of twelve sample speakers. Our results show that tongue clicks and glottal FPs are as common as typically described FPs, and should be a part of disfluency research. Moreover, the frequency of uh, um, and hm decreases in the Lombard condition while the opposite is found for tongue clicks. Furthermore, along with the usual F1 increase, a considerable reduction in vowel space is found in the Lombard condition for the vowels in uh and um. A high degree of within- and between-speaker variation is found on the individual speaker level.","2023-06","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","2","8","","","","","","","","","","English","","","","WOS:001015066700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;96</p>","","","ARTICULATION RATE; CLICKS; disfluencies; DISFLUENCY; filled pauses; filler particles; forensic phonetics; FREQUENCY; hesitation; HESITATION; MARKERS; pauses; PAUSES; speaker-specificity; SPEAKING; SPEECH PRODUCTION; VARIABILITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YJX7E883","journalArticle","2022","Paschen, L; Fuchs, S; Seifart, F","Final Lengthening and vowel length in 25 languages","JOURNAL OF PHONETICS","","0095-4470","10.1016/j.wocn.2022.101179","","Lengthening of segments at the end of prosodic domains is commonly considered a universal phenomenon, but language-specific variation has also been reported, specifically in languages with a phonological vowel length con-trast. This cross-linguistic study uses spontaneous speech data from the DoReCo corpus as a testbed to inves-tigate Final Lengthening (FL) in a diverse sample of 25 mostly understudied languages, thirteen of which have a phonological vowel length contrast. The duration of vowels was labeled using an automatic aligner, with addi-tional manual corrections of word boundaries upon which refined segment alignments were created. The study reveals that (i) FL is a widespread process across languages; (ii) FL shows a wide variety of manifestations with respect to the degree and scope of lengthening; (iii) there are several significant interactions between phonological length and positional lengthening. These results lend support to theories assuming a phonological nature of Final Lengthening. CO 2022 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY license (http:// creativecommons.org/licenses/by/4.0/).","2022-09","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","94","","","","","","","","","","English","","","","WOS:000855851800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;148</p>","","","CONTRASTS; Corpus phonetics; CUES; DURATION; Endangered languages; ENGLISH; Final lengthening; Length contrast; Phonological quantity; PHRASE; PROSODIC BOUNDARY; QUANTITY; SCOPE; STRESS; VOICE ONSET TIME","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MRUXT4YP","journalArticle","2021","Zhang, N; Yuan, BK; Yan, J; Cheng, JL; Lu, JF; Wu, JS","Multivariate machine learning-based language mapping in glioma patients based on lesion topography","BRAIN IMAGING AND BEHAVIOR","","1931-7557","10.1007/s11682-021-00457-0","","Diffusive and progressive tumor infiltration within language-related areas of the brain induces functional reorganization. However, the macrostructural basis of subsequent language deficits is less clear. To address this issue, lesion topography data from 137 preoperative patients with left cerebral language-network gliomas (81 low-grade gliomas and 56 high-grade gliomas), were adopted for multivariate machine-learning-based lesion-language mapping analysis. We found that tumor location in the left posterior middle temporal gyrus-a bottleneck where both dorsal and ventral language pathways travel-predicted deficits of spontaneous speech (cluster size = 1356 mm(3), false discovery rate corrected P < 0.05) and naming scores (cluster size = 1491 mm(3), false discovery rate corrected P < 0.05) in the high-grade glioma group. In contrast, no significant lesion-language mapping results were observed in the low-grade glioma group, suggesting a large functional reorganization. These findings suggest that in patients with gliomas, the macrostructural plasticity mechanisms that modulate brain-behavior relationships depend on glioma grade.","2021-10","2025-02-26 20:39:14","2025-02-26 20:39:14","","2552-2562","","5","15","","","","","","","","","","English","","","","WOS:000620480000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;88</p>","","","ARCHITECTURE; ASSOCIATION; BRAIN-STIMULATION; CONVERGING EVIDENCE; FUNCTIONAL CONNECTIVITY; grade glioma; GRADE-II GLIOMAS; High‐; Language; Low‐; Machine learning; NETWORK; RESECTION; Structural MRI; TUMOR; WERNICKES AREA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MXKKARKD","journalArticle","2023","Marques, MA; Aguiar, M","MULTIFUNCTIONALITY OF DISCOURSE MARKER PORTANTO IN BRAGA'S SPEECH","STUDIA UNIVERSITATIS BABES-BOLYAI PHILOLOGIA","","1220-0484","10.24193/subbphilo.2023.4.05","","Multifunctionality of discourse marker portanto in Braga's Speech. This paper explores the multifunctionality and usage patterns of the discourse marker portanto in Braga's speech. Our main goal is to propose a revised description of portanto, while acknowledging the validity of previous research on the topic. The investigation focused on the co-occurrence of functions associated with portanto, emphasizing its pivotal role in speech construction. The frequency distribution of portanto usage was found to be consistent with earlier studies, affirming its most prevalent application as a filler (marker). Our study also highlighted that an excessive use of discourse markers can create the illusion of coherence, rather than genuinely ensuring it, especially in contexts characterized by frequent pauses, verbal hesitations, and syntactic interruptions. Furthermore, this research examined the influence of discourse genre on portanto's usage patterns. Notably, the two predominant uses observed in Braga's speech were linked to specific aspects of sociolinguistic interviews, particularly the recollection of life stories and features of spontaneous speech. The findings enrich our understanding of this discourse marker's multifaceted role in facilitating coherent communication and its significance in various speech contexts.","2023-12","2025-02-26 20:39:14","2025-02-26 20:39:14","","99-119","","4","68","","","","","","","","","","English","","","","WOS:001168459000006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","colloquial register; discourse markers; DONC; European; multifunctionality.; Portuguese","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5KU5LR48","journalArticle","2023","Asllani, B; Mullen, DM","Using personal writings to detect dementia: A text mining approach","HEALTH INFORMATICS JOURNAL","","1460-4582","10.1177/14604582231204409","","A novel text mining pilot for dementia detection using Linguistic Inquiry and Word Count (LIWC) was tested on public figures' writings looking at word choice and affect compared to those with and without dementia. The differences found in this analysis mirror the expected patterns where writings of people with dementia reflect significantly more analytical thinking words, but significantly less authentic and emotional tone. In addition, the analysis found that people with dementia use significantly less functional words, such as grammar, and affections (happiness, sadness, anger, sadness), but tend to use significantly more pronouns in their writings. Written samples of those with dementia also use significantly less time-oriented words that indicate past, present, or future. The analysis of free form text suggests a potential avenue for detecting early changes that correlate with dementia, allowing for early preventative treatment before noticeable cognitive impairment occurs.","2023-10","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","4","29","","","","","","","","","","English","","","","WOS:001159279700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","dementia; LANGUAGE; linguistic inquiry and word count; text-mining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7488IW6T","journalArticle","2025","Erickson, CM; Largent, EA; O'Brien, KS","Paving the way for Alzheimer's disease blood-based biomarkers in primary care","ALZHEIMERS & DEMENTIA","","1552-5260","10.1002/alz.14203","","Blood-based biomarkers (BBBMs) for Alzheimer's disease (AD) have the potential to revolutionize the detection and management of cognitive impairment. AD BBBMs are not currently recommended for use in primary care but may soon be as research demonstrates their clinical utility for differential diagnosis and patient management. To prepare for the incorporation of AD BBBMs into primary care, several practical challenges must be addressed. Here, we describe four immediate challenges: (1) preparing primary care providers to order and disclose AD BBBMs, (2) expanding the dementia-capable workforce, (3) ensuring equitable uptake of AD BBBM testing, and (4) securing access to AD treatment. We conclude by discussing future directions and challenges for use of AD BBBMs in primary care, including screening for preclinical AD and dementia detection algorithms.","2025-01","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","1","21","","","","","","","","","","English","","","","WOS:001386195800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Alzheimer's disease; biomarkers; DEMENTIA; dementia-capable care; DIAGNOSIS; DISPARITIES; PREVALENCE; primary care","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"68B7VAJQ","journalArticle","2021","Salerno, P","Memory and Re-Foundation. Political Identity in Nestor Kirchner's Malvinas Speeches","JOURNAL OF LATIN AMERICAN CULTURAL STUDIES","","1356-9325","10.1080/13569325.2021.1878117","","In this article we will analyse a series of speeches commemorating the Malvinas War, delivered by Nestor Kirchner during his presidency. Using the theoretical framework of Speech Analysis, we will observe how a re-foundational spirit and the construction of a collective memory intersect in these speeches in a special way. In contrast with other pronouncements by the Argentine leader, his attempts to commemorate Malvinas do not lean on generational traits identified with the 1970s and militancy; the intention here is to extol a respect for the institutions of the state while mobilising traditional ideas regarding the correspondence between nation and territory. We will show that from these axes Kirchner delineates a collective identity understood in terms of political belonging to the nation, re-signifying the Malvinas question as a matter of social inclusion. We will also see how the notion of ""internal exile"" links the figure of the Malvinas veteran to a Kirchnerist spirit of national re-foundation. For this analysis we will work with a corpus formed by speeches paying homage to Malvinas war veterans, delivered by Nestor Kirchner every 2 April, during his time in office (2003-2007).","2021-01-02","2025-02-26 20:39:14","2025-02-26 20:39:14","","143-160","","1","30","","","","","","","","","","English","","","","WOS:000657541000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Collective memory; DISCOURSE; Malvinas; national re-foundation; Nestor Kirchner; political identity; speech analysis; WAR","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CVAVFNUD","journalArticle","2024","Narayanrao, PV; Kohirker, K; Preeth, TS; Kumari, PLS","Depression Symptom Identification Through Acoustic Speech Analysis: A Transfer Learning Approach","TRAITEMENT DU SIGNAL","","0765-0019","10.18280/ts.410113","","In the field of mental health diagnostics, the acoustic characteristics of speech have been recognized as potent markers for the identification of depressive symptoms. This study harnesses the power of transfer learning (TL) to discern depression -related sentiments from speech. Acoustic features such as rhythm, pitch, and tone form the core of this analysis. The methodology unfolds in three distinct phases. Initially, a Multi -Layer Perceptron (MLP) network employing stochastic gradient descent is applied to the RAVDESS dataset, yielding an accuracy of 65%. This finding catalyzes the second phase, wherein a comprehensive hyperparameter optimization via grid search (GS) is conducted on the MLP Classifier. This step primarily focuses on detecting emotions commonly associated with depression, including neutrality, sadness, anger, fear, and disgust. The optimized MLP classifier indicates an improved accuracy of 71%. In the final phase, to enhance precision further, the same GS -based model, underpinned by TL principles, is applied to the TASS dataset. This application astonishingly achieves an accuracy of 99.80%, suggesting a high risk of depression. This comparative study establishes the proposed framework as a vanguard in the application of TL for depression prediction, showcasing a significant leap in accuracy over previous methodologies.","2024-02","2025-02-26 20:39:14","2025-02-26 20:39:14","","165-177","","1","41","","","","","","","","","","English","","","","WOS:001181958200024","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","depression transfer learning (TL) grid; Perceptron (MLP) classifier; search (GS) speech analysis Multi-Layer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9JS7CZNL","journalArticle","2022","Chaurasiya, H; Chandra, G","HOTELLING'S T-SQUARE AND BAYESIAN STATISTICS HYBRID AS AN INVESTIGATIVE TOOL","ADVANCES AND APPLICATIONS IN MATHEMATICAL SCIENCES","","0974-6803","10.1080/00224065.2006.11918611","","Spectrogram patch segmentation with noise classification is one of the most challenging and complex tasks in acoustic image (feature) analysis environments, especially in deep learning. Although all convolutional neural networks extract speech features (attributes) from the acoustic spectrogram itself, Hotelling's T-square and Bayesian statistics hybrid is used as an exploratory tool for segmentation and classification with better accuracy. To validate this, the paper expands with an experimental analysis. In this analysis, n-gram ?n ? 2? language model was used for noise modelling and the noise degradation was eliminated with the decision. Frame classification scores of 64.92%, 67.17%, and 69.49% were obtained using this statistical hybrid tool with 10, 20, and 30 frames, respectively. Best performance was achieved with the longest patch.","2022-07","2025-02-26 20:39:14","2025-02-26 20:39:14","","5517-5530","","9","21","","","","","","","","","","English","","","","WOS:000860196200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","Baysian statistics (BS); Convolutional neural network (CNN); Gaussian; Spectrogram patch segmentation (SPS)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q3FEKYHC","journalArticle","2021","Kumala, OU; Zahra, A","Indonesian Speech Emotion Recognition using Cross-Corpus Method with the Combination of MFCC and Teager Energy Features","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","Emotion recognition is one of the widely studied topics in speech technology. Emotions that come from speech can contain useful information for many purposes. The main aspects in speech emotion recognition are speech features, speech corpus, and machine learning algorithms as the classifier method. In this paper, cross-corpus method is used to conduct Indonesian Speech Emotion Recognition (SER) along with the combination of Mel Frequency Cepstral Coefficients (MFCC) and Teager Energy features. Using Support Vector Machine (SVM) as classifier, the experiment result shows that applying cross-corpus method by adding corpora from other languages to the training dataset improves the emotion classification accuracy by 4.16% on MFCC Statistics feature and 2.09% on Teager-MFCC Statistics feature.","2021-04","2025-02-26 20:39:14","2025-02-26 20:39:14","","163-168","","4","12","","","","","","","","","","English","","","","WOS:000648867700023","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","Cross corpus; Indonesian speech emotion recognition; Mel Frequency Cepstral Coefficients; Teager Energy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IQBMBGBG","journalArticle","2022","Martínez-Nicolás, I; Llorente, TE; Martínez-Sánchez, F; Meilán, JJG","Speech biomarkers of risk factors for vascular dementia in people with mild cognitive impairment","FRONTIERS IN HUMAN NEUROSCIENCE","","1662-5161","10.3389/fnhum.2022.1057578","","IntroductionIn this study we intend to use speech analysis to analyze the cognitive impairments caused by pathologies of vascular origin such as diabetes, hypertension, hypercholesterolemia and heart disease, predictors of the development of vascular dementia. MethodsIn this study, 40 participants with mild cognitive impairment were asked to read while being recorded and they were inquired about their history of the aforementioned conditions. Their speech was then analyzed. ResultsWe found that some speech parameters of frequencies and syllabic rhythm vary due to these pathologies. In addition, we conducted a discriminant analysis in which we found that diabetes and hypertension can be predicted with an accuracy over 95% with few speech parameters, and hypercholesterolemia and heart disease with an accuracy over 80%. DiscussionThe predictor parameters found are heterogeneous, including voice quality, amplitude, frequency, and rhythm parameters. This result may lead to investigate why such important qualitative changes occur in the voice of older adults with these pathologies. Rather than trying to find a diagnostic procedure already existing in classical medicine, we expect this finding to contribute to explore the causes and concomitant pathologies of these diseases. We discuss the implications of behavioral traits, such as speech, as digital biomarkers.","2022-12-15","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","16","","","","","","","","","","English","","","","WOS:000904914500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","blood pressure; cholesterol; diabetes; heart disease; mild cognitive impairment; speech analysis; vascular dementia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TF8PZ652","journalArticle","2022","de Boer, MM; Quene, H; Heeren, WFL","Long-term within-speaker consistency of filled pauses in native and non-native speech","JASA EXPRESS LETTERS","","2691-1191","10.1121/10.0009598","","Filled pauses are widely considered as a relatively consistent feature of an individual's speech. However, acoustic consistency has only been observed within single-session recordings. By comparing filled pauses in two recordings made > 2.5 years apart, this study investigates within-speaker consistency of the vowels in the filled pauses uh and um, in both first language (L1) Dutch and second language (L2) English, produced by student speakers who are known to converge in other speech features. Results show that despite minor within-speaker differences between languages, the spectral characteristics of filled pauses in L1 and L2 remained stable over time. (C) 2022 Author(s). All article content, except where otherwise noted, is licensed under a Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).","2022-03","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","3","2","","","","","","","","","","English","","","","WOS:000772909500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","R PACKAGE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4JQERTNB","journalArticle","2024","Xiong, Y; Guo, XY; Xu, JJ","CNN-Transformer: A deep learning method for automatically identifying learning engagement","EDUCATION AND INFORMATION TECHNOLOGIES","","1360-2357","10.1007/s10639-023-12058-z","","Learning engagement is an essential indication to define students' learning pacification in the class, and its automated identification technique is the foundation for exploring how to effectively explain the motive of learning impact modifications and making intelligent teaching choices. Current research have demonstrated that there is a direct link between learning engagement and emotional investment and behavioural investment, and it is appropriate and required to apply artificial intelligence to perform autonomous assessment. Unfortunately, the number of relevant research is limited, and the features of learning engagement in certain contexts have not been thoroughly examined. In this research, we highlight the features of a particular application scenario of learning engagement: the application scenario of learning engagement has to incorporate both the coarse-grained information of human body position and the fine-grained information of facial expressions. On the basis of this analysis, a fine-grained learning participation recognition model that suppresses background clutter information is presented. This model can effectively extract coarse and fine-grained information to improve the recognition of learning participation in real-world teaching situations. Particularly, the CNN-Transformer model suggested in this study employs CNN to extract fine-grained information of facial expressions and Transformer to recover coarse-grained information of human body position. Simultaneously, we gathered and categorised real teaching data based on the features of learning engagement situations and enhanced the data quality via crowdsourcing and expert verification. The experimental findings indicate that the CNN-Transformer model can accurately predict the learning engagement of unknown participants with a 92.9% rate of accuracy. Comparative trials reveal that the model's recognition impact is much greater than that of other sophisticated deep learning approaches. Our research offers a framework for future work on deep learning approaches in learning engagement settings.","2024-06","2025-02-26 20:39:14","2025-02-26 20:39:14","","9989-10008","","8","29","","","","","","","","","","English","","","","WOS:001070382300002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","ACADEMIC-PERFORMANCE; Artificial intelligence; CONTINUANCE INTENTION; Deep learning; EXCESSIVE USE; FACEBOOK USAGE; IMPACT; Learning engagement identification; NEGATIVE CONSEQUENCES; NETWORKING SITES; ONLINE COMMUNITIES; Precision teaching; SOCIAL MEDIA USAGE; TECHNOLOGY OVERLOAD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FHN22FLV","journalArticle","2023","Ren, JL; Wang, AH; Li, HY; Yue, XB; Meng, L","A Transformer-Based Neural Network for Gait Prediction in Lower Limb Exoskeleton Robots Using Plantar Force","SENSORS","","1424-8220","10.3390/s23146547","","Lower limb exoskeleton robots have shown significant research value due to their capabilities of providing assistance to wearers and improving physical motion functions. As a type of robotic technology, wearable robots are directly in contact with the wearer's limbs during operation, necessitating a high level of human-robot collaboration to ensure safety and efficacy. Furthermore, gait prediction for the wearer, which helps to compensate for sensor delays and provide references for controller design, is crucial for improving the the human-robot collaboration capability. For gait prediction, the plantar force intrinsically reflects crucial gait patterns regardless of individual differences. To be exact, the plantar force encompasses a doubled three-axis force, which varies over time concerning the two feet, which also reflects the gait patterns indistinctly. In this paper, we developed a transformer-based neural network (TFSformer) comprising convolution and variational mode decomposition (VMD) to predict bilateral hip and knee joint angles utilizing the plantar pressure. Given the distinct information contained in the temporal and the force-space dimensions of plantar pressure, the encoder uses 1D convolution to obtain the integrated features in the two dimensions. As for the decoder, it utilizes a multi-channel attention mechanism to simultaneously focus on both dimensions and a deep multi-channel attention structure to reduce the computational and memory consumption. Furthermore, VMD is applied to networks to better distinguish the trends and changes in data. The model is trained and tested on a self-constructed dataset that consists of data from 35 volunteers. The experimental results show that FTSformer reduces the mean absolute error (MAE) up to 10.83%, 15.04% and 8.05% and the mean squared error (MSE) by 20.40%, 29.90% and 12.60% compared to the CNN model, the transformer model and the CNN transformer model, respectively.","2023-07","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","14","23","","","","","","","","","","English","","","","WOS:001072772900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","convolutional neural network; gait prediction; plantar pressure; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"79WPT5R8","journalArticle","2024","Yu, SY; Deng, H; Liu, ZK; Chen, J; Xiao, KY; Mao, XC","Identification of Geochemical Anomalies Using an End-to-End Transformer","NATURAL RESOURCES RESEARCH","","1520-7439","10.1007/s11053-024-10334-4","","Deep learning methods have demonstrated remarkable success in recognizing geochemical anomalies for mineral exploration. Typically, these methods identify anomalies by reconstructing the geochemical background, which is marked by long-distance spatial variability, giving rise to long-range spatial dependencies within geochemical signals. However, current deep learning models for geochemical anomaly recognition face limitations in capturing intricate long-range spatial dependencies. Additionally, concerns emerge from the uncertainty associated with preprocessing in existing deep learning models, which involve generating interpolated images and topological graphs to represent the spatial structure of geochemical samples. In this paper, we present a novel end-to-end method for geochemical anomaly extraction based on the Transformer model. Our model utilizes self-attention mechanism to adequately capture both global and local interconnections among geochemical samples from a holistic perspective, enabling the reconstruction of geochemical background. Moreover, the self-attention mechanism allows the Transformer model to directly input free-form geochemical samples, eliminating the uncertainty associated with the employment of prior interpolation or graph generation typically required for geochemical samples. To align geochemical data with Transformer's architecture, we tailor a specialized data organization integrating learnable positional encoding and data masking. This enables the ingestion of entire geochemical data into the Transformer for anomaly recognition. Capitalizing on the flexibility afforded by the attention mechanism, we devise a contrastive loss for training, establishing a self-supervised learning scheme that enhances model generalizability for anomaly recognition. The proposed method is utilized to recognize geochemical anomalies related to Au mineralization in the northwest Jiaodong Peninsula, Eastern China. By comparison with anomalies identified by models of graph attention network and geographically weighted regression, it is demonstrated that the proposed method is more effective and geologically sound in identifying mineralization-associated anomalies. This superior performance in geochemical anomaly recognition is attributed to its ability to capture long-range dependencies within geochemical data.","2024-06","2025-02-26 20:39:14","2025-02-26 20:39:14","","973-994","","3","33","","","","","","","","","","English","","","","WOS:001220460300002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;88</p>","","","AREA; Au deposits; CHINA; Geochemical anomalies; GOLD DEPOSITS; IDENTIFY; JIAODONG PENINSULA; MACHINE; PROSPECTIVITY; RECOGNITION; Self-attention mechanism; SINGULARITIES; Transformer; UNDISCOVERED MINERAL-DEPOSITS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CMHRGQKF","journalArticle","2025","Wang, X; Zhang, M; Li, C; Jia, CY; Yu, XJ; He, H","Performance and efficiency of machine learning models in analyzing capillary serum protein electrophoresis","CLINICA CHIMICA ACTA","","0009-8981","10.1016/j.cca.2025.120165","","Background and Objective: Serum protein electrophoresis (SPEP) plays a critical role in diagnosing diseases associated with M-proteins. However, its clinical application is limited by a heavy reliance on experienced experts. Methods: A dataset comprising 85,026 SPEP outcomes was utilized to develop artificial intelligence diagnostic models for the classification and localization of M-proteins. These models were trained and validated using three data features, and their performance was evaluated using comprehensive metrics, including sensitivity, positive predictive value (PPV), specificity, negative predictive value (NPV), F1 score, accuracy, area under the receiver operating characteristic curve (AUC), Matthews correlation coefficient (MCC), and Intersection over Union (IoU). The best-performing machine learning (ML) and deep learning (DL) models were further tested on a separate dataset of 1,079 samples. The localization ability of the DL model was compared against three clinical experts. Results: Among the four ML models, the extreme gradient boosting (XGB) model achieved the best performance, with MCC, AUC, F1 score, sensitivity, specificity, accuracy, PPV, and NPV of 0.847, 0.903, 0.875, 0.822, 0.985, 0.951, 0.934, and 0.955, respectively. Different feature extraction methods significantly influenced model performance. The DL models outperformed the ML models in comprehensive performance. The U-Net combined with Transformer model demonstrated localization ability comparable to that of clinical experts, achieving sensitivity, specificity, accuracy, PPV, NPV, F1 score, AUC, MCC, and IoU of 0.947, 0.984, 0.976, 0.938, 0.986, 0.942, 0.966, 0.927, and 0.877, respectively. Conclusion: The U-Net combined with the Transformer model demonstrated expert-level performance in M-protein classification and localization, achieving an accuracy of 0.976 and an IoU of 0.877. This exceptional performance highlights the potential of this combined model for automating clinical SPEP workflows.","2025-03-01","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","569","","","","","","","","","","English","","","","WOS:001413217900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","ACCURACY; ALGORITHM; CLASSIFICATION; COMPONENTS; Deep learning; EXPERT-SYSTEM; Extreme Gradient Boosting; FOLLOW-UP; LIMIT; Machine Learning; MULTICENTER; Serum Protein Electrophoresis; U -Net","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ADZ4R6M7","journalArticle","2025","Wu, Y; Wu, ZZ; Ji, CT","Transformer-based partner dance motion generation","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2024.109610","","With the rapid development of information technology, particularly the recent breakthroughs in the field of artificial intelligence, the field of dance education has experienced an unprecedented transformation. Today, an increasing number of dance enthusiasts can experience an efficient and personalized immersive dance learning process via advanced artificial intelligence applications. Compared with the individual practice of solo dance, the learning process of partner dancing is more complex. Partner dancing requires not only a coordinated dance partner but also the abilities of both individuals to accurately follow each other's movements in real time as well as adjust and present the correct dance postures. In this study, we developed an innovative real-time virtual reality dance training framework tailored for interactive entertainment and teaching. Our framework used an enhanced transformer model that could generate partner movement sequences based on user movements. Furthermore, we established a somatosensory virtual reality interaction environment by integrating somatosensory devices to capture user movements in real time. These movement sequences were then fed into a network to produce partner movement sequences by generating virtual characters and creating an interactive dance learning system that can offer real-time feedback from a virtual partner. Our experiments validated the robustness and effectiveness of the proposed sequence generation model. In addition, we incorporated Laban movement analysis to explore the semantic representations of partner dances and devised a comprehensive set of evaluation indicators to assess the quality of the generated partner dance movements. The rigorous testing of each component and actual user testing demonstrated the effectiveness of the system. The system offered users rich interactive feedback and a scientifically grounded approach for learning to dance with a partner. Therefore, this study offers significant prospects for both intelligent dance teaching and human-computer interaction in virtual reality among other applications.","2025-01","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","139","","","","","","","","","","English","","","","WOS:001361134500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Artificial intelligence; Dance movement evaluation; Interactive dance; Transformer model; Virtual dance partner; Virtual reality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y554FSVI","journalArticle","2023","Abeltino, A; Bianchetti, G; Serantoni, C; Riente, A; De Spirito, M; Maulucci, G","Putting the Personalized Metabolic Avatar into Production: A Comparison between Deep-Learning and Statistical Models for Weight Prediction","NUTRIENTS","","2072-6643","10.3390/nu15051199","","Nutrition is a cross-cutting sector in medicine, with a huge impact on health, from cardiovascular disease to cancer. Employment of digital medicine in nutrition relies on digital twins: digital replicas of human physiology representing an emergent solution for prevention and treatment of many diseases. In this context, we have already developed a data-driven model of metabolism, called a ""Personalized Metabolic Avatar"" (PMA), using gated recurrent unit (GRU) neural networks for weight forecasting. However, putting a digital twin into production to make it available for users is a difficult task that as important as model building. Among the principal issues, changes to data sources, models and hyperparameters introduce room for error and overfitting and can lead to abrupt variations in computational time. In this study, we selected the best strategy for deployment in terms of predictive performance and computational time. Several models, such as the Transformer model, recursive neural networks (GRUs and long short-term memory networks) and the statistical SARIMAX model were tested on ten users. PMAs based on GRUs and LSTM showed optimal and stable predictive performances, with the lowest root mean squared errors (0.38 +/- 0.16-0.39 +/- 0.18) and acceptable computational times of the retraining phase (12.7 +/- 1.42 s-13.5 +/- 3.60 s) for a production environment. While the Transformer model did not bring a substantial improvement over RNNs in term of predictive performance, it increased the computational time for both forecasting and retraining by 40%. The SARIMAX model showed the worst performance in term of predictive performance, though it had the best computational time. For all the models considered, the extent of the data source was a negligible factor, and a threshold was established for the number of time points needed for a successful prediction.","2023-03","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","5","15","","","","","","","","","","English","","","","WOS:000947988200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","deep learning; diet plans; digital nutrition; digital twin; forecasting; gated recurrent unit; HEALTH-CARE; long short-term memory; metabolism; SARIMAX; transformer; wearables","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CIKFCETV","journalArticle","2024","Yuan, JX; Li, YC","An APT Attack Detection Method of a New-type Power System Based on STSA-transformer","RECENT ADVANCES IN ELECTRICAL & ELECTRONIC ENGINEERING","","2352-0965","10.2174/2352096516666230428104141","","Background Complex structures such as a high proportion of power electronic equipment has brought new challenges to the safe and stable operation of new-type power system, increasing the possibility of the system being attacked, especially the more complex Advanced Persistent Threat (APT). This kind of attack has a long duration and strong concealment.Objective Traditional detection methods target a relatively single attack mode, and the time span of APT processed is relatively short. None of them can effectively capture the long-term correlation in the attack, and the detection rate is low. These methods can't meet the safety requirements of the new-type power system. In order to solve this problem, this paper proposes an improved transformer model called STSA-transformer algorithm, and applies it to the detection of APT in new-type power systems.Methods In the STSA-transformer model, the network traffic collected from the power system is first converted into a sequence of feature vectors, and the location information and local feature of the sequence, is extracted by combining position encoding with convolutional embedding operations, and then global characteristics of attack sequences is captured using the multi-head self-attention mechanism of the transformer encoder, the higher-frequency features of the attention are extracted through the self-learning threshold operation, combined with the PowerNorm algorithm to standardize the samples, and finally classify the network traffic of the APT.Results After multiple rounds of training on the model, the expected effect can be achieved and applied to the APT detection of a new-type power system.Conclusion The experimental results show that the proposed STSA-transformer algorithm has better detection accuracy and lower detection false-alarm rate than traditional deep learning algorithms and machine learning algorithms.","2024","2025-02-26 20:39:14","2025-02-26 20:39:14","","19-28","","1","17","","","","","","","","","","English","","","","WOS:001143812200003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","advanced persistent threat; false-alarm rate; Network security; new-type power system; self-attention mechanism; STSA-transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7IG8UX2J","journalArticle","2022","Jiang, YJ; Song, L; Zhang, JM; Song, Y; Yan, M","Multi-Category Gesture Recognition Modeling Based on sEMG and IMU Signals","SENSORS","","1424-8220","10.3390/s22155855","","Gesture recognition based on wearable devices is one of the vital components of human-computer interaction systems. Compared with skeleton-based recognition in computer vision, gesture recognition using wearable sensors has attracted wide attention for its robustness and convenience. Recently, many studies have proposed deep learning methods based on surface electromyography (sEMG) signals for gesture classification; however, most of the existing datasets are built for surface EMG signals, and there is a lack of datasets for multi-category gestures. Due to model limitations and inadequate classification data, the recognition accuracy of these methods cannot satisfy multi-gesture interaction scenarios. In this paper, a multi-category dataset containing 20 gestures is recorded with the help of a wearable device that can acquire surface electromyographic and inertial (IMU) signals. Various two-stream deep learning models are established and improved further. The basic convolutional neural network (CNN), recurrent neural network (RNN), and Transformer models are experimented on with our dataset as the classifier. The CNN and the RNN models' test accuracy is over 95%; however, the Transformer model has a lower test accuracy of 71.68%. After further improvements, the CNN model is introduced into the residual network and augmented to the CNN-Res model, achieving 98.24% accuracy; moreover, it has the shortest training and testing time. Then, after combining the RNN model and the CNN-Res model, the long short term memory (LSTM)-Res model and gate recurrent unit (GRU)-Res model achieve the highest classification accuracy of 99.67% and 99.49%, respectively. Finally, the fusion of the Transformer model and the CNN model enables the Transformer-CNN model to be constructed. Such improvement dramatically boosts the performance of the Transformer module, increasing the recognition accuracy from 71.86% to 98.96%.","2022-08","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","15","22","","","","","","","","","","English","","","","WOS:000839833200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;26<br/>Total Times Cited:&nbsp;&nbsp;26<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","convolutional neural network; CONVOLUTIONAL NEURAL-NETWORKS; hand gesture recognition; IMU; recurrent neural network; residual networks; sEMG; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CNNB29YM","journalArticle","2024","Chen, WQ; Liao, DL; Deng, YY; Hu, JZ","Development of a transformer-based deep learning algorithm for diabetic peripheral neuropathy classification using corneal confocal microscopy images","FRONTIERS IN CELL AND DEVELOPMENTAL BIOLOGY","","2296-634X","10.3389/fcell.2024.1484329","","Background Diabetic peripheral neuropathy (DPN) is common and can go unnoticed until it is firmly developed. This study aims to establish a transformer-based deep learning algorithm (DLA) to classify corneal confocal microscopy (CCM) images, identifying DPN in diabetic patients.Methods Our classification model differs from traditional convolutional neural networks (CNNs) using a Swin transformer network with a hierarchical architecture backbone. Participants included those with (DPN+, n = 57) or without (DPN-, n = 37) DPN as determined by the updated Toronto consensus criteria. The CCM image dataset (consisting of 570 DPN+ and 370 DPN- images, with five images selected from each participant's left and right eyes) was randomly divided into training, validation, and test subsets at a 7:1:2 ratio, considering individual participants. The effectiveness of the algorithm was assessed using diagnostic accuracy measures, such as sensitivity, specificity, and accuracy, in conjunction with Grad-CAM visualization techniques to interpret the model's decisions.Results In the DPN + group (n = 12), the transformer model successfully predicted all participants, while in the DPN- group (n = 7), one participant was misclassified as DPN+, with an area under the curve (AUC) of 0.9405 (95% CI 0.8166, 1.0000). Among the DPN + images (n = 120), 117 were correctly classified, and among the DPN- images (n = 70), 49 were correctly classified, with an AUC of 0.8996 (95% CI 0.8502, 0.9491). For single-image predictions, the transformer model achieved a superior AUC relative to the ResNet50 model (0.8761, 95% CI 0.8155, 0.9366), the Inception_v3 model (0.8802, 95% CI 0.8231, 0.9374), and the DenseNet121 model (0.8965, 95% CI 0.8438, 0.9491).Conclusion Transformer-based networks outperform CNN-based networks in rapid binary DPN classification. Transformer-based DLAs have clinical DPN screening potential.","2024-10-14","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","12","","","","","","","","","","English","","","","WOS:001342312100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","ARTIFICIAL-INTELLIGENCE; confocal microscopy; convolutional neural network; deep learning; diabetic neuropathy; DIAGNOSTIC-CRITERIA; POLYNEUROPATHY; PREDICTS; RISK; SEVERITY; SKIN BIOPSY; Swin transformer network; UPDATE; VALIDATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CL7XMRWC","journalArticle","2024","Jiang, XY; Xu, SP; Wu, JY; Zhou, CF; Ji, SC","Boosting Noise Reduction Effect via Unsupervised Fine-Tuning Strategy","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14051742","","Over the last decade, supervised denoising models, trained on extensive datasets, have exhibited remarkable performance in image denoising, owing to their superior denoising effects. However, these models exhibit limited flexibility and manifest varying degrees of degradation in noise reduction capability when applied in practical scenarios, particularly when the noise distribution of a given noisy image deviates from that of the training images. To tackle this problem, we put forward a two-stage denoising model that is actualized by attaching an unsupervised fine-tuning phase after a supervised denoising model processes the input noisy image and secures a denoised image (regarded as a preprocessed image). More specifically, in the first stage we replace the convolution block adopted by the U-shaped network framework (utilized in the deep image prior method) with the Transformer module, and the resultant model is referred to as a U-Transformer. The U-Transformer model is trained to preprocess the input noisy images using noisy images and their labels. As for the second stage, we condense the supervised U-Transformer model into a simplified version, incorporating only one Transformer module with fewer parameters. Additionally, we shift its training mode to unsupervised training, following a similar approach as employed in the deep image prior method. This stage aims to further eliminate minor residual noise and artifacts present in the preprocessed image, resulting in clearer and more realistic output images. Experimental results illustrate that the proposed method achieves significant noise reduction in both synthetic and real images, surpassing state-of-the-art methods. This superiority stems from the supervised model's ability to rapidly process given noisy images, while the unsupervised model leverages its flexibility to generate a fine-tuned network, enhancing noise reduction capability. Moreover, with support from the supervised model providing higher-quality preprocessed images, the proposed unsupervised fine-tuning model requires fewer parameters, facilitating rapid training and convergence, resulting in overall high execution efficiency.","2024-03","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","5","14","","","","","","","","","","English","","","","WOS:001182803300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","boosting denoising effect; data bias; fine-tuning; flexibility; IMAGE; SPARSE; supervised denoising models; unsupervised denoising models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PQZZK8AJ","journalArticle","2023","Sadhukhan, B; Chakraborty, S; Mukherjee, S","Predicting the magnitude of an impending earthquake using deep learning techniques","EARTH SCIENCE INFORMATICS","","1865-0473","10.1007/s12145-022-00916-2","","Earthquakes are one of nature's most devastating disasters. Earthquake prediction is critical in seismology since its success can save lives, property, and infrastructure. Numerous technologies have been proposed to address this issue, including mathematical analysis, artificial intelligence, and machine learning algorithms. Unfortunately, due to earthquakes' dynamic and spontaneous nature, they frequently fail to provide positive results. The study uses deep learning techniques to predict the magnitude of an impending earthquake using eight mathematically calculated seismic indicators derived from Japan, Indonesia, and the Hindu-Kush Karakoram Himalayan (HKKH) region's earthquake catalogs. Three deep learning techniques, including Long Short-Term Memory (LSTM), Bi-directional Long Short-Term Memory (Bi-LSTM), and self-attention-based transformer, have been implemented to model the associations between calculated seismic indicators and potential earthquake incidents. These models have been evaluated with well-known matrices such as the Mean Absolute Error (MAE), Mean Squared Error (MSE), log-cosh loss, and Mean Squared Logarithmic Error (MSLE). The value of these cost functions converges to a small number for all models, indicating that these models effectively predict earthquake magnitudes. When these models were fed with an unknown test dataset from Japan, the LSTM model performed best with the least deviation metrics (MAE = 0.060, MSE = 0.006, log cosh = 0.042 and MSLE = 0.003). Similarly, the Bi-LSTM model delivered the ideal result for the Indonesia earthquake catalog (MAE = 0.073, MSE = 0.009, log cosh = 0.016, and MSLE = 0.009), while the transformer model produced the optimal result for the HKKH region (MAE = 0.062, MSE = 0.006, log cosh = 0.043, and MSLE = 0.003). Predicting earthquake magnitude at various locations using these methodologies produces significant and positive results for magnitudes ranging from 3.5 M to 6.0 M, paving the way for the ultimate robust prediction mechanism, that has not yet been developed.","2023-03","2025-02-26 20:39:14","2025-02-26 20:39:14","","803-823","","1","16","","","","","","","","","","English","","","","WOS:000903448800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Bi-LSTM model; Earthquake prediction; LSTM model; NEURAL-NETWORK; PATTERNS; PRECURSORS; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WG69Y7R9","journalArticle","2024","Song, BF; Raj, DKC; Yang, RY; Li, SB; Zhang, CC; Liang, RG","Classification of Mobile-Based Oral Cancer Images Using the Vision Transformer and the Swin Transformer","CANCERS","","2072-6694","10.3390/cancers16050987","","Simple Summary Transformer models, originally successful in natural language processing, have found application in computer vision, demonstrating promising results in tasks related to cancer image analysis. Despite being one of the prevalent and swiftly spreading cancers globally, there is a pressing need for accurate automated analysis methods for oral cancer. This need is particularly critical for high-risk populations residing in low- and middle-income countries. In this study, we evaluated the performance of the Vision Transformer (ViT) and the Swin Transformer in the classification of mobile-based oral cancer images we collected from high-risk populations. The results showed that the Swin Transformer model achieved higher accuracy than the ViT model, and both transformer models work better than the conventional convolution model VGG19.Abstract Oral cancer, a pervasive and rapidly growing malignant disease, poses a significant global health concern. Early and accurate diagnosis is pivotal for improving patient outcomes. Automatic diagnosis methods based on artificial intelligence have shown promising results in the oral cancer field, but the accuracy still needs to be improved for realistic diagnostic scenarios. Vision Transformers (ViT) have outperformed learning CNN models recently in many computer vision benchmark tasks. This study explores the effectiveness of the Vision Transformer and the Swin Transformer, two cutting-edge variants of the transformer architecture, for the mobile-based oral cancer image classification application. The pre-trained Swin transformer model achieved 88.7% accuracy in the binary classification task, outperforming the ViT model by 2.3%, while the conventional convolutional network model VGG19 and ResNet50 achieved 85.2% and 84.5% accuracy. Our experiments demonstrate that these transformer-based architectures outperform traditional convolutional neural networks in terms of oral cancer image classification, and underscore the potential of the ViT and the Swin Transformer in advancing the state of the art in oral cancer image analysis.","2024-03","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","5","16","","","","","","","","","","English","","","","WOS:001182831400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","artificial intelligence; oral cancer; oral image analysis; Swin Transformer; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9J2SMP27","journalArticle","2023","Zeng, PY; Hu, GL; Zhou, XF; Li, S; Liu, PJ","Seformer: a long sequence time-series forecasting model based on binary position encoding and information transfer regularization","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-022-04263-z","","Long sequence time-series forecasting (LSTF) problems, such as weather forecasting, stock market forecasting, and power resource management, are widespread in the real world. The LSTF problem requires a model with high prediction accuracy. Recent studies have shown that the transformer model architecture is the most promising model structure for LSTF problems compared with other model architectures. The transformer model has the property of permutation equivalence, which leads to the importance of sequence position encoding, an essential process in model training. Currently, the continuous dynamics models constructed for position encoding using the neural differential equations (neural ODEs) method can model sequence position information well. However, we have found that there are some limitations when neural ODEs are applied to the LSTF problem, including the time cost problem, the baseline drift problem, and the information loss problem; thus, neural ODEs cannot be directly applied to the LSTF problem. To address this problem, we design a binary position encoding-based regularization model for long sequence time-series prediction, named Seformer, which has the following structure: 1) The binary position encoding mechanism, including intrablock and interblock position encoding. For intrablock position encoding, we design a simple ODE method by discretizing the continuum dynamics model, which reduces the time cost required to compute neural ODEs while maintaining their dynamics properties to the maximum extent. In interblock position encoding, a chunked recursive form is adopted to alleviate the baseline drift problem caused by eigenvalue explosion. 2) Information transfer regularization mechanism: By regularizing the model intermediate hidden variables as well as the encoder-decoder connection variables, we can reduce information loss during the model training process while ensuring the smoothness of the position information. Extensive experimental results obtained on six large-scale datasets show a consistent improvement in our approach over the baselines.","2023-06","2025-02-26 20:39:14","2025-02-26 20:39:14","","15747-15771","","12","53","","","","","","","","","","English","","","","WOS:000889431400003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Conditional variational autoencoder; Long sequence time-series forecasting; Position encoding; Regularization method; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5KTTWP3F","journalArticle","2024","Liu, CT; Fan, HM; Wang, YX","Gully erosion susceptibility assessment using three machine learning models in the black soil region of Northeast China","CATENA","","0341-8162","10.1016/j.catena.2024.108275","","Gully erosion has significantly increased and severely threatened agricultural production and food security, especially in the black soil region of Northeast China. The present study is set out to select the importance factors in gully erosion occurrence and compare similarities and differences in importance factors among watersheds, validate the applicability of the transformer model, and analyze the spatial distribution characteristic of gully erosion susceptibility maps (GESMs) and relationship between sloping farmland and gully erosion susceptibility area. 25 geo-environmental factors (GEFs) affecting the occurrence of gully erosion were identified through various data resource platforms and Arcgis10.2, and gully inventory maps were generated from remote sensing image interpretation and field survey. The mathematical relationships between GEFs and erosion gullies were established using random forest (RF), convolutional neural network (CNN), and transformer models after multicollinearity test. The 10-fold cross-validation and 8 indicators were used to comprehensively compare the model performances. Results showed that the 10 factors played a key role in gully erosion occurrence in the black soil region of Northeast China which were convergence index (CI), distance from river, rainfall, terrain ruggedness index (TRI), normalized difference vegetation index (NDVI), topographic wetness index (TWI), elevation, distance from road, drainage density, and slope respectively. Except TWI, elevation, and slope, other 7 importance factors are shared among watersheds but with different degrees of importance. The transformer model has better applicability. According to the GESMs, the low susceptibility areas were still dominant and the occurrence of gully erosion was mostly in the very high susceptibility area. Our results demonstrate that the very high susceptibility area was related to the sloping farmland closely and exceeding 75% of very high susceptibility areas were located on sloping farmland.","2024-10","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","245","","","","","","","","","","English","","","","WOS:001291779100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;83</p>","","","CERTAINTY FACTOR; ENVIRONMENTAL-FACTORS; Geo-environmental factors; Gully erosion; IRAN; Machine learning; PERFORMANCE; RANDOM FOREST; REGRESSION; SEMIARID REGION; Sloping farmland; Susceptibility assessment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2763235H","journalArticle","2024","Yang, ZS; Li, HD; Chen, RT","An acoustic emission onset time determination method based on Transformer","STRUCTURAL HEALTH MONITORING-AN INTERNATIONAL JOURNAL","","1475-9217","10.1177/14759217231223078","","Acoustic emission (AE) technology, as the main method of non-destructive testing technology, has been widely used in structural health monitoring (known as SHM) in the fields of machinery and civil engineering. Locating the failure source is an important application of SHM, and accurately identifying the moment when the AE signal first reaches the sensor (which is called onset time) is of vital importance. Deep learning model has been widely used in onset time determination of AE signals in recent years due to its powerful feature extraction ability. However, as one of the most popular models, Transformer has not been further studied in such field and its effectiveness remains to be proven. In this paper, a novel AE onset time determination method based on Transformer is proposed. Firstly, a preprocessing method based on segmentation-concatenation is applied to divide original data into several connected small segments, while the integrating labeling method is applied on small label segments. Secondly, the preprocessed data and labels are substituted into the Transformer model for training. Finally, for the sequence processed by the Transformer model, the first-time index that reaches the maximum value is obtained as the determination result. Based on the Hsu-Nielson source AE data, the feasibility and performance of this method are analyzed and compared with several commonly used methods: Akaike information criterion (AIC), short/long term average combined with AIC (STA/LTA-AIC), floating threshold (FT) and 1D-CNN-AIC method. The results show that the proposed method is significantly better than AIC, STA/LTA-AIC and FT. Moreover, the determination efficiency is greatly improved while the performance of the proposed method is close to that of 1D-CNN-AIC. Meanwhile, the method has robust performance especially in low signal-to-noise ratio scenario. In practical applications with small-scale data, the proposed method is of relatively high reference as well as application value.","2024-09","2025-02-26 20:39:14","2025-02-26 20:39:14","","3174-3194","","5","23","","","","","","","","","","English","","","","WOS:001146926100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","acoustic emission; low SNR; Onset time; PICKING; SIGNALS; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FMH27SA3","journalArticle","2024","Lu, HL; Zhou, T","MCIF-Transformer Mask RCNN: Multi-Branch Cross-Scale Interactive Feature Fusion Transformer Model for PET/CT Lung Tumor Instance Segmentation","CMC-COMPUTERS MATERIALS & CONTINUA","","1546-2218","10.32604/cmc.2024.047827","","The precise detection and segmentation of tumor lesions are very important for lung cancer computer-aided diagnosis. However, in PET/CT (Positron Emission Tomography/Computed Tomography) lung images, the lesion shapes are complex, the edges are blurred, and the sample numbers are unbalanced. To solve these problems, this paper proposes a Multi-branch Cross-scale Interactive Feature fusion Transformer model (MCIF-Transformer Mask RCNN) for PET/CT lung tumor instance segmentation, The main innovative works of this paper are as follows: Firstly, the ResNet-Transformer backbone network is used to extract global feature and local feature in lung images. The pixel dependence relationship is established in local and non-local fields to improve the model perception ability. Secondly, the Cross-scale Interactive Feature Enhancement auxiliary network is designed to provide the shallow features to the deep features, and the cross-scale interactive feature enhancement module (CIFEM) is used to enhance the attention ability of the fine-grained features. Thirdly, the Cross-scale Interactive Feature fusion FPN network (CIF-FPN) is constructed to realize bidirectional interactive fusion between deep features and shallow features, and the low-level features are enhanced in deep semantic features. Finally, 4 ablation experiments, 3 comparison experiments of detection, 3 comparison experiments of segmentation and 6 comparison experiments with two-stage and single-stage instance segmentation networks are done on PET/CT lung medical image datasets. The results showed that APdet, APseg, ARdet and ARseg indexes are improved by 5.5%, 5.15%, 3.11% and 6.79% compared with Mask RCNN (resnet50). Based on the above research, the precise detection and segmentation of the lesion region are realized in this paper. This method has positive significance for the detection of lung tumors.","2024","2025-02-26 20:39:14","2025-02-26 20:39:14","","4371-4393","","3","79","","","","","","","","","","English","","","","WOS:001268119400014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","instance segmentation; interactive fusion; mask RCNN; PET/CT images; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FV4QUCK6","journalArticle","2022","Alzahrani, AIA; Al-Rasheed, A; Ksibi, A; Ayadi, M; Asiri, MM; Zakariah, M","Anomaly Detection in Fog Computing Architectures Using Custom Tab Transformer for Internet of Things","ELECTRONICS","","2079-9292","10.3390/electronics11234017","","Devices which are part of the Internet of Things (IoT) have strong connections; they generate and consume data, which necessitates data transfer among various devices. Smart gadgets collect sensitive information, perform critical tasks, make decisions based on indicator information, and connect and interact with one another quickly. Securing this sensitive data is one of the most vital challenges. A Network Intrusion Detection System (IDS) is often used to identify and eliminate malicious packets before they can enter a network. This operation must be done at the fog node because the Internet of Things devices are naturally low-power and do not require significant computational resources. In this same context, we offer a novel intrusion detection model capable of deployment at the fog nodes to detect the undesired traffic towards the IoT devices by leveraging features from the UNSW-NB15 dataset. Before continuing with the training of the models, correlation-based feature extraction is done to weed out the extra information contained within the data. This helps in the development of a model that has a low overall computational load. The Tab transformer model is proposed to perform well on the existing dataset and outperforms the traditional Machine Learning ML models developed as well as the previous efforts made on the same dataset. The Tab transformer model was designed only to be capable of handling continuous data. As a result, the proposed model obtained a performance of 98.35% when it came to classifying normal traffic data from abnormal traffic data. However, the model's performance for predicting attacks involving multiple classes achieved an accuracy of 97.22%. The problem with imbalanced data appears to cause issues with the performance of the underrepresented classes. However, the evaluation results that were given indicated that the proposed model opened new avenues of research on detecting anomalies in fog nodes.","2022-12","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","23","11","","","","","","","","","","English","","","","WOS:000897553300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","DATASET; deep learning; feature selection; intrusion detection; INTRUSION DETECTION SYSTEM; network security; NETWORKS; STATISTICAL-ANALYSIS; UNSW-NB15 DATA SET","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BERBEGLJ","journalArticle","2024","Zhang, DL; Shi, J","Research on Assessment Method for Cognitive Influence Factors of Nuclear Power Plant Operators Based on Fuzzy Analytic Hierarchy Process and Deep Learning of Electroencephalogram Signals","NUCLEAR SCIENCE AND ENGINEERING","","0029-5639","10.1080/00295639.2024.2397256","","This study explores the factors influencing the cognitive processes of operators in digital nuclear power plants, with a focus on the correlation between these factors and electroencephalogram (EEG) features. Initially, based on expert consultations, seven factors were considered: stress, time, fatigue, procedural complexity, user interface experience, procedural clarity, and efficiency. From these, four were identified as the most crucial for each stage of the cognitive process, highlighting their significant roles in influencing cognitive performance and potentially correlating with distinct EEG characteristics. These were assessed using the fuzzy analytic hierarchy process (FAHP) to determine the weightings of influences across the cognitive stages of monitoring, decision making, and execution.Employing a simulated scenario of a steam generator tube rupture, subjective questionnaires were utilized to gauge participant perceptions of influencer impacts at each stage, calculating human factors fuzzy synthetic values. Concurrently, EEG signals were segmented by operational steps, extracting around 114 features across the time, frequency, and time-frequency domains, which were then dimensionally reduced to 17 principal components via adaptive principal components analysis (APCA). A correlation analysis was performed between the human factors fuzzy synthetic values and the APCA-reduced EEG features of participants. Subsequently, the EEG feature columns of the eight selected participants were used as inputs to construct a transformer-based self-attention network model to evaluate the participants' human factors fuzzy comprehensive values.The findings confirm the transformer model's efficacy in assessing these values, evidencing a significant correlation between the EEG features and human factors fuzzy synthetic values. Integrating FAHP with machine learning methodologies, this model proficiently estimated operators' cognitive states during various cognitive processes, significantly enhancing human-machine interface design and the operational safety and efficiency at nuclear power plants.","2024-09-13","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","","","","","","","","","","","English","","","","WOS:001324055500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Digital nuclear power plant; fuzzy analytic hierarchy process; human factors reliability; HUMAN RELIABILITY-ANALYSIS; steam generator tube rupture; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5ZDMH2G2","journalArticle","2024","Khaliq, A; Khan, A; Awan, SA; Jan, SL; Umair, M; Zuhairi, MF","Integrating Topic-Aware Heterogeneous Graph Neural Network With Transformer Model for Medical Scientific Document Abstractive Summarization","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3443730","","The development of abstractive summarization methods is a crucial task in Natural Language Processing (NLP) that presents challenges, which require the creation of intelligent systems that are capable of extracting the main idea from text effectively and generate coherent summary. Numerous existing abstractive approaches do not take into account the importance of the broader context or fail to capture the global semantics in identifying salient content for summary. Moreover, there is lack of studies that extensively evaluated abstractive summarization models for specific domains, such as medical scientific document summarization. With this motivation behind, this paper developed an integrated framework for abstractive summarization of medical scientific documents that integrates topic-aware Heterogeneous Graph Neural Network with a Transformer model. The suggested framework uses Latent Dirichlet Allocation (LDA) for topic modeling to uncover latent topics and global information, thus preserving document-level attributes important for creation of effective summaries. In addition to topic modeling, the framework utilized a Heterogeneous Graph Neural Network (HGNN), capable of capturing the relationship between sentences through graph-based document representation, and allows for the concurrent updating of both local and global information. Finally, the framework is integrated with a Transformer decoder, which greatly enhances the ability of model to produce accurate and informative abstractive summaries. The performance of proposed framework is evaluated on publicly available PubMed dataset related to medical scientific papers. Experimental results illustrate that the suggested framework for abstractive summarization showed superior performance as compared to the state-of-the-art models, achieving high F1-Scores: 46.03 for Rouge-1, 21.42 for Rouge-2, and 39.71 for Rouge-L. Our research makes a significant contribution to the field of natural language processing, particularly in the area of medical scientific document summarization. It demonstrates superior performance and provides a deeper understanding of document structure, and has the potential to impact various applications by offering efficient access to information.","2024","2025-02-26 20:39:14","2025-02-26 20:39:14","","113855-113866","","","12","","","","","","","","","","English","","","","WOS:001297355400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","abstractive summarization; BERT; GAT; LDA; medical documents; TF-IDF; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PRN4QWCH","journalArticle","2021","Ananthanarayana, T; Srivastava, P; Chintha, A; Santha, A; Landy, B; Panaro, J; Webster, A; Kotecha, N; Sah, S; Sarchet, T; Ptucha, R; Nwogu, I","Deep Learning Methods for Sign Language Translation","ACM TRANSACTIONS ON ACCESSIBLE COMPUTING","","1936-7228","10.1145/3477498","","Many sign languages are bona fide natural languages with grammatical rules and lexicons hence can benefit from machine translation methods. Similarly, since sign language is a visual-spatial language, it can also benefit from computer vision methods for encoding it. With the advent of deep learning methods in recent years, significant advances have been made in natural language processing (specifically neural machine translation) and in computer vision methods (specifically image and video captioning). Researchers have therefore begun expanding these learning methods to sign language understanding. Sign language interpretation is especially challenging, because it involves a continuous visual-spatial modality where meaning is often derived based on context. The focus of this article, therefore, is to examine various deep learning-based methods for encoding sign language as inputs, and to analyze the efficacy of several machine translation methods, over three different sign language datasets. The goal is to determine which combinations are sufficiently robust for sign language translation without any gloss-based information. To understand the role of the different input features, we perform ablation studies over the model architectures (input features + neural translation models) for improved continuous sign language translation. These input features include body and finger joints, facial points, as well as vector representations/embeddings from convolutional neural networks. The machine translation models explored include several baseline sequenceto-sequence approaches, more complex and challenging networks using attention, reinforcement learning, and the transformer model. We implement the translation methods over multiple sign languages-German (GSL), American (ASL), and Chinese sign languages (CSL). From our analysis, the transformer model combined with input embeddings from ResNet50 or pose-based landmark features outperformed all the other sequence-to-sequence models by achieving higher BLEU2-BLEU4 scores when applied to the controlled and constrained GSL benchmark dataset. These combinations also showed significant promise on the other less controlled ASL and CSL datasets.","2021-12","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","4","14","","","","","","","","","","English","","","","WOS:000713067200006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;20<br/>Cited Reference Count:&nbsp;&nbsp;101</p>","","","accessibility; attention; Deaf and Hard-of-Hearing; deep learning; REINFORCEMENT; ROBOTICS; sequence modeling; Sign language translation; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FREBLV5G","journalArticle","2023","Wang, N; Tan, SR; Xie, XL; Li, HR; Jiang, JH","Event Feature Pre-training Model Based on Public Opinion Evolution","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","The comments in the evolution of network public opinion events not only reflect the attitude of netizens towards the event itself, but also are the key basis for mastering the dynamics of public opinion. According to the comment data in the event evolution process, an event feature vector pre-training model NL2ER-Transformer is constructed to realize the real-time automatic extraction of event features. Firstly, a semi -supervised multi-label curriculum learning model is proposed to generate comment words, event word vectors, event words, and event sentences, so that a public opinion event is mapped into a sequence similar to vectorized natural language. Secondly, based on the Transformer structure, a training method is proposed to simulate the evolution process of events, so that the event vector generation model can learn the evolution law and the characteristics of reversal events. Finally, the event vectors generated by the presented NL2ER-Transformer model are compared with the event vectors generated by the current mainstream models such as XLNet and RoBerta. This paper tests the pre-trained model NL2ER-Transformer and three pre -trained benchmark models on four downstream classification models. The experimental results show that using the vectors generated by NL2ER-Transformer to train downstream models compared to using the vectors generated by other pre-trained benchmark models to train downstream models, the accuracy, recall, and F1 values are 16.66%, 44.44%, and 19% higher than the best downstream model. At the same time, in the evolutionary capability analysis test, only four events show partial errors. In terms of performance of semi-supervised model, the proposed semi-supervised multi-label curriculum learning model outperforms mainstream models in four indicators by 6%, 23%, 8%, and 15%, respectively.","2023-04","2025-02-26 20:39:14","2025-02-26 20:39:14","","197-206","","4","14","","","","","","","","","","English","","","","WOS:000988095000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","Event vectorization; evolution of public opinion event; multi label semi supervised learning; NL2ER-transformer model; public opinion reversal prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2P48IZ8U","journalArticle","2024","Xiong, Y; Guo, XY; Xu, JJ","CNN-Transformer: A deep learning method for automatically identifying learning engagement","EDUCATION AND INFORMATION TECHNOLOGIES","","1360-2357","10.1007/s10639-023-12058-z","","Learning engagement is an essential indication to define students' learning pacification in the class, and its automated identification technique is the foundation for exploring how to effectively explain the motive of learning impact modifications and making intelligent teaching choices. Current research have demonstrated that there is a direct link between learning engagement and emotional investment and behavioural investment, and it is appropriate and required to apply artificial intelligence to perform autonomous assessment. Unfortunately, the number of relevant research is limited, and the features of learning engagement in certain contexts have not been thoroughly examined. In this research, we highlight the features of a particular application scenario of learning engagement: the application scenario of learning engagement has to incorporate both the coarse-grained information of human body position and the fine-grained information of facial expressions. On the basis of this analysis, a fine-grained learning participation recognition model that suppresses background clutter information is presented. This model can effectively extract coarse and fine-grained information to improve the recognition of learning participation in real-world teaching situations. Particularly, the CNN-Transformer model suggested in this study employs CNN to extract fine-grained information of facial expressions and Transformer to recover coarse-grained information of human body position. Simultaneously, we gathered and categorised real teaching data based on the features of learning engagement situations and enhanced the data quality via crowdsourcing and expert verification. The experimental findings indicate that the CNN-Transformer model can accurately predict the learning engagement of unknown participants with a 92.9% rate of accuracy. Comparative trials reveal that the model's recognition impact is much greater than that of other sophisticated deep learning approaches. Our research offers a framework for future work on deep learning approaches in learning engagement settings.","2024-06","2025-02-26 20:39:14","2025-02-26 20:39:14","","9989-10008","","8","29","","","","","","","","","","English","","","","WOS:001255508400047","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;0</p>","","","Artificial intelligence; Deep learning; Learning engagement identification; Precision teaching","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HZ9APJ6Z","journalArticle","2024","Zhang, FX; Sang, GM; Liu, Z; Lin, HF; Zhang, YJ","A doctor's diagnosis experience enhanced transformer model for automatic diagnosis","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2024.108675","","Automatic diagnosis, as an important research direction in artificial intelligence engineering, has advanced significantly in recent years. In real diagnostic scenarios, after the patient informs the doctor about their most obvious symptoms, the doctor is often required to guide the patient to uncover potential symptom information. The doctor then makes the final diagnosis after obtaining sufficient evidence. Previous work has modeled this as a sequential decision-making process and trained an optimal policy using RL-based methods, achieving a high diagnosis correctness rate. However, the RL-based method only finds symptom sequences that improve reward through random trials, failing to directly capture the inter-relationships between symptom sequences in the inquiry process. Also, the doctors' diagnostic experience, especially symptoms that often co-occur and are located in close proximity to each other in the doctors' inquiry symptom sequence, has not been well explored in previous implementations. To address this, we propose a model that further enhances the learning of doctors' diagnostic experience based on a two-part transformer model that completes symptom inquiry and disease diagnosis separately. We introduce a Doctor Diagnosis Experience Reinforcement Module (DDEM) to the symptom sequence inquiry part, reducing the model's sensitivity to the order of symptom sequences within the same symptom cluster. Then, we further enhance the learning of this symptom distribution by corresponding reinforcement learning reward rules. Also, we propose three new transition rules when transitioning the symptom inquiry model to the disease diagnosis model to enable the symptom inquiry model and the disease diagnosis model to collaborate in a manner that closely aligns with the diagnostic logic used by doctors. Experiments on three public real-world medical dialogue datasets demonstrate that the proposed model improves diagnostic accuracy by 2%, 1.4%, and 0.7% and shows a clear advantage in symptom recall rate, highlighting its effectiveness.","2024-08","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","134","","","","","","","","","","English","","","","WOS:001248451100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Automatic diagnosis; Medical consultation records; Medical dialogue systems; Neural networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"289YBF26","journalArticle","2024","Panneerselvam, V; Thiagarajan, R","Toward accurate multi-region air quality prediction: integrating transformer-based deep learning and crossover boosted dynamic arithmetic optimization (CDAO)","SIGNAL IMAGE AND VIDEO PROCESSING","","1863-1703","10.1007/s11760-024-03061-z","","One of the global environmental challenges is air pollution that has severe implications for human health and the ecosystem. The general factors affected in the air quality are emissions from diverse sources, meterological conditions, and regional topography. The air pollutant measures how much amount of materials present in the air and the mainly affected particulate materials are PM10 and PM2.5. PM10 represents small particles in dust and smoke, but PM2.5 is a fine particle matter that is more dangerous. For acquiring efficient public health interventions and environmental management, the accurate air quality prediction models are required. This research paper proposes a transformer-based deep learning model for multi-region air quality prediction. The transformer model's self-attention mechanism enables it to handle complex spatiotemporal dependencies in air quality data from multiple regions simultaneously. This proposed model develops a robust and efficient air quality prediction model and integrates the crossover boosted dynamic arithmetic optimization (CDAO) algorithm for hyperparameter tuning. The proposed transformer-based model is optimized to forecast future pollutant concentrations in different regions based on historical air quality data, meteorological parameters, and geographical information. CDAO dynamically explores the hyperparameter space, efficiently finding the optimal set of hyperparameters for the transformer model, leading to better results achievement. The research employs air quality data in India for the study period from 2018 to 2022. Data preprocessing includes handling missing values and normalization, ensuring data consistency. The model achieves better outcomes in accurately predicting air pollutant concentrations across multiple regions compared to baseline models and other hyperparameter tuning techniques. The CDAO algorithm significantly reduces the convergence time and enhances the model's performance, leading to better results attainment.","2024-07","2025-02-26 20:39:14","2025-02-26 20:39:14","","4145-4156","","5","18","","","","","","","","","","English","","","","WOS:001190197300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","Air quality prediction; Crossover operation; Dynamic arithmetic optimization; Geographical information; Meteorological parameters; Self-attention mechanism; Spatial features; Temporal features","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BJZ4ZALQ","journalArticle","2024","Li, J; Xiong, P; Li, Y; Feng, QK","DAS Noise Suppression Network Based on Distributing-Local-Attention Expansion","IEEE GEOSCIENCE AND REMOTE SENSING LETTERS","","1545-598X","10.1109/LGRS.2024.3433006","","Distributed acoustic sensing (DAS) has been progressively used in acquiring vertical seismic profiles. However, DAS signals are susceptible to be contaminated by diverse noise, causing many difficulties in the interpretation of DAS VSP. Most of the existing methods for DAS noise suppression rely on either global or local information for the extraction of signal features. They neglected that both local detail and long-distance relevant features are required for denoising. To address this issue, we propose a U-shaped network with a combination of convolutional neural networks (CNNs) and refining transformers, named Urefiner. We employ CNN as a preprocessing step for the transformer model. The transformer model relies on the attention map to extract global features, while the CNN module will aggregate similar features within the attention map to facilitate local information processing. To facilitate the fusion of local information and global information, the distributing-local-attention (DLA) module is induced to calculate the weighted aggregation in the attention map between CNN and transformer, which can improve the effective receptive field of the network in local areas. Additionally, to improve the network's attention to seismic signals for signal protection, we introduce a learnable linear matrix to expand attention map. It can aggregate the information acquired from different attention heads into a learnable weight matrix for the attention calculation. This linear weighting scheme can promote the interconnections among diverse attention heads, thereby facilitating the fusion of extracted information. Based on the above designs, the proposed Urefiner can augment the effective receptive field to amplify the significance of signal features in the attention map. Experimental results show that the network can effectively suppress various noises in DAS VSP and accurately protecting weak seismic signals.","2024","2025-02-26 20:39:14","2025-02-26 20:39:14","","","","","21","","","","","","","","","","English","","","","WOS:001287339700011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","Convolution; Convolutional neural network (CNN); distributed acoustic sensing (DAS); Feature extraction; Noise; Noise reduction; noise suppression; Optical filters; transformer; Transformers; Vectors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q2FH8WLB","journalArticle","2025","Hong, L; Liu, Y; Xu, MQ; Deng, WH","Combining deep reinforcement learning with heuristics to solve the traveling salesman problem","CHINESE PHYSICS B","","1674-1056","10.1088/1674-1056/ad95f1","","Recent studies employing deep learning to solve the traveling salesman problem (TSP) have mainly focused on learning construction heuristics. Such methods can improve TSP solutions, but still depend on additional programs. However, methods that focus on learning improvement heuristics to iteratively refine solutions remain insufficient. Traditional improvement heuristics are guided by a manually designed search strategy and may only achieve limited improvements. This paper proposes a novel framework for learning improvement heuristics, which automatically discovers better improvement policies for heuristics to iteratively solve the TSP. Our framework first designs a new architecture based on a transformer model to make the policy network parameterized, which introduces an action-dropout layer to prevent action selection from overfitting. It then proposes a deep reinforcement learning approach integrating a simulated annealing mechanism (named RL-SA) to learn the pairwise selected policy, aiming to improve the 2-opt algorithm's performance. The RL-SA leverages the whale optimization algorithm to generate initial solutions for better sampling efficiency and uses the Gaussian perturbation strategy to tackle the sparse reward problem of reinforcement learning. The experiment results show that the proposed approach is significantly superior to the state-of-the-art learning-based methods, and further reduces the gap between learning-based methods and highly optimized solvers in the benchmark datasets. Moreover, our pre-trained model M can be applied to guide the SA algorithm (named M-SA (ours)), which performs better than existing deep models in small-, medium-, and large-scale TSPLIB datasets. Additionally, the M-SA (ours) achieves excellent generalization performance in a real-world dataset on global liner shipping routes, with the optimization percentages in distance reduction ranging from 3.52% to 17.99%.","2025-01-01","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","1","34","","","","","","","","","","English","","","","WOS:001390034700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","07.05.Mh; 87.55.de; 87.55.kd; ALGORITHM; deep reinforcement learning; simulated annealing algorithm; transformer model; traveling salesman problem; whale optimization algorithm","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"87Z3QGJY","journalArticle","2024","Li, WZ; Liu, CS; Xu, YY; Niu, CJ; Li, RX; Li, M; Hu, CH; Tian, L","An interpretable hybrid deep learning model for flood forecasting based on Transformer and LSTM","JOURNAL OF HYDROLOGY-REGIONAL STUDIES","","2214-5818","10.1016/j.ejrh.2024.101873","","Study region: Flood formation involves complex nonlinear processes and numerous variables, with data-driven models becoming a key non-engineering approach to flood prevention and mitigation. Yet, single machine learning models are insufficient to fully capture the complex dynamics of the flood process. Study focus: We propose an interpretable flood forecasting hybrid model based on Transformer, LSTM, and Adaptive Random Search Algorithm (AGRS), termed as AGRS-LSTM-Transformer. Investigating the predictive performance of the hybrid model, this study compares it against AGRS-LSTM, AGRS-Transformer, AGRS-BP, and AGRS-MLP models, utilizing flood data from 1971 to 2013 years in the Jingle watershed. New hydrological insights for the region: The AGRS-LSTM-Transformer model demonstrates superior performance over benchmark models, achieving accurate runoff forecasts with a lead time of 1-6 hours. It achieves a Nash-Sutcliffe Efficiency (NSE) greater than 0.905, and root mean squared error (RMSE), mean absolute error (MAE), Bias, and relative error (RE) values for the runoff process below 34.891 m3/s, 25.125 m3/s, 9.537 %, and 8.025 %, respectively. The coupling between the LSTM layers and the Transformer input components plays a crucial role in the architecture of the AGRS-LSTM-Transformer model. Rainfall from stations situated near the main river channel and downstream flow sections exerted a positive influence. Runoff from the preceding moment significantly impacts the predicted flow, with the contribution of runoff inputs exceeding that of rainfall. Inputs nearer to the forecast moment do not invariably improve forecasting accuracy, and historical rainfall and runoff volumes with extended lag times may detrimentally impact the model prediction. The study highlights the potential of hybrid datadriven models in enhancing the accuracy of flood forecasting, offering insights for reducing uncertainty in flood prediction and interpreting machine learning flood forecasting models. This provides a scientific basis for flood early warning systems and water resource management.","2024-08","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","54","","","","","","","","","","English","","","","WOS:001261969900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","Adaptive random search algorithm; AGRS-LSTM-Transformer; Flood forecasting; Interpretability; Machine learning; Rainfall-runoff","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9EJ8EJK8","journalArticle","2024","Miao, SB; Zhang, CX; Piao, YS; Miao, YL","Classification and Model Explanation of Traditional Dwellings Based on Improved Swin Transformer","BUILDINGS","","2075-5309","10.3390/buildings14061540","","The extraction of features and classification of traditional dwellings plays significant roles in preserving and ensuring the sustainable development of these structures. Currently, challenges persist in subjective classification and the accuracy of feature extraction. This study focuses on traditional dwellings in Gansu Province, China, employing a novel model named Improved Swin Transformer. This model, based on the Swin Transformer and parallel grouped Convolutional Neural Networks (CNN) branches, aims to enhance the accuracy of feature extraction and classification precision. Furthermore, to validate the accuracy of feature extraction during the prediction process and foster trust in AI systems, explainability research was conducted using Grad-CAM-generated heatmaps. Initially, the Gansu Province Traditional Dwelling Dataset (GTDD) is established. On the constructed GTDD dataset, the Improved Swin Transformer attains an accuracy of 90.03% and an F1 score of 87.44%. Comparative analysis with ResNet-50, ResNeXt-50, and Swin Transformer highlights the outstanding performance of the improved model. The confusion matrix of the Improved Swin Transformer model reveals the classification results across different regions, indicating that the primary influencing factors are attributed to terrain, climate, and cultural aspects. Finally, using Grad-CAM-generated heatmaps for explaining classifications, it is observed that the Improved Swin Transformer model exhibits more accurate localization and focuses on features compared to the other three models. The model demonstrates exceptional feature extraction ability with minimal influence from the surrounding environment. Simultaneously, through the heatmaps generated by the Improved Swin Transformer for traditional residential areas in five regions of Gansu, it is evident that the model accurately extracts architectural features such as roofs, facades, materials, windows, etc. This validates the consistency of features extracted by the Improved Swin Transformer with traditional methods and enhances trust in the model and decision-making. In summary, the Improved Swin Transformer demonstrates outstanding feature extraction ability and accurate classification, providing valuable insights for the protection and style control of traditional residential areas.","2024-06","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","6","14","","","","","","","","","","English","","","","WOS:001254412600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;84</p>","","","CNN; explainability; feature extraction and classification; Grad-CAM; Swin Transformer; traditional dwellings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SVUBPFLD","journalArticle","2024","Li, WZ; Liu, CS; Hu, CH; Niu, CJ; Li, RX; Li, M; Xu, YY; Tian, L","Application of a hybrid algorithm of LSTM and Transformer based on random search optimization for improving rainfall-runoff simulation","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-62127-7","","Flood forecasting using traditional physical hydrology models requires consideration of multiple complex physical processes including the spatio-temporal distribution of rainfall, the spatial heterogeneity of watershed sub-surface characteristics, and runoff generation and routing behaviours. Data-driven models offer novel solutions to these challenges, though they are hindered by difficulties in hyperparameter selection and a decline in prediction stability as the lead time extends. This study introduces a hybrid model, the RS-LSTM-Transformer, which combines Random Search (RS), Long Short-Term Memory networks (LSTM), and the Transformer architecture. Applied to the typical Jingle watershed in the middle reaches of the Yellow River, this model utilises rainfall and runoff data from basin sites to simulate flood processes, and its outcomes are compared against those from RS-LSTM, RS-Transformer, RS-BP, and RS-MLP models. It was evaluated against RS-LSTM, RS-Transformer, RS-BP, and RS-MLP models using the Nash-Sutcliffe Efficiency Coefficient (NSE), Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and Bias percentage as metrics. At a 1-h lead time during calibration and validation, the RS-LSTM-Transformer model achieved NSE, RMSE, MAE, and Bias values of 0.970, 14.001m(3)/s, 5.304m(3)/s, 0.501% and 0.953, 14.124m(3)/s, 6.365m(3)/s, 0.523%, respectively. These results demonstrate the model's superior simulation capabilities and robustness, providing more accurate peak flow forecasts as the lead time increases. The study highlights the RS-LSTM-Transformer model's potential in flood forecasting and the advantages of integrating various data-driven approaches for innovative modelling.","2024-05-16","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","1","14","","","","","","","","","","English","","","","WOS:001297865300079","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","Deep learning; DROUGHTS; FLOOD; Flood forecasting; HYDROLOGICAL MODEL; MEMORY; PREDICTION; Rainfall-runoff; Random search optimization; RECURRENT NEURAL-NETWORK; RS-LSTM-transformer; The middle reaches of the Yellow River","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JGLSJGXP","journalArticle","2024","Alosaimi, W; Saleh, H; Hamzah, AA; El-Rashidy, N; Alharb, A; Elaraby, A; Mostafa, S","ArabBert-LSTM: improving Arabic sentiment analysis based on transformer model and Long Short-Term Memory","FRONTIERS IN ARTIFICIAL INTELLIGENCE","","2624-8212","10.3389/frai.2024.1408845","","Sentiment analysis also referred to as opinion mining, plays a significant role in automating the identification of negative, positive, or neutral sentiments expressed in textual data. The proliferation of social networks, review sites, and blogs has rendered these platforms valuable resources for mining opinions. Sentiment analysis finds applications in various domains and languages, including English and Arabic. However, Arabic presents unique challenges due to its complex morphology characterized by inflectional and derivation patterns. To effectively analyze sentiment in Arabic text, sentiment analysis techniques must account for this intricacy. This paper proposes a model designed using the transformer model and deep learning (DL) techniques. The word embedding is represented by Transformer-based Model for Arabic Language Understanding (ArabBert), and then passed to the AraBERT model. The output of AraBERT is subsequently fed into a Long Short-Term Memory (LSTM) model, followed by feedforward neural networks and an output layer. AraBERT is used to capture rich contextual information and LSTM to enhance sequence modeling and retain long-term dependencies within the text data. We compared the proposed model with machine learning (ML) algorithms and DL algorithms, as well as different vectorization techniques: term frequency-inverse document frequency (TF-IDF), ArabBert, Continuous Bag-of-Words (CBOW), and skipGrams using four Arabic benchmark datasets. Through extensive experimentation and evaluation of Arabic sentiment analysis datasets, we showcase the effectiveness of our approach. The results underscore significant improvements in sentiment analysis accuracy, highlighting the potential of leveraging transformer models for Arabic Sentiment Analysis. The outcomes of this research contribute to advancing Arabic sentiment analysis, enabling more accurate and reliable sentiment analysis in Arabic text. The findings reveal that the proposed framework exhibits exceptional performance in sentiment classification, achieving an impressive accuracy rate of over 97%.","2024-07-02","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","7","","","","","","","","","","English","","","","WOS:001272456700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","Arabic sentiment analysis; deep learning; Long Short-Term Memory; machine learning; sentiment analysis; transformer models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R6T2VJFT","journalArticle","2024","Li, Y; Jia, Z; Liu, ZB; Shao, HD; Zhao, W; Liu, ZQ; Wang, BD","Interpretable intelligent fault diagnosis strategy for fixed-wing UAV elevator fault diagnosis based on improved cross entropy loss","MEASUREMENT SCIENCE AND TECHNOLOGY","","0957-0233","10.1088/1361-6501/ad3666","","The current popular machine learning-based fault diagnosis methods make it difficult to explain the diagnostic results, leading to low user trust in such diagnostic techniques. In this regard, this paper explores the study of the interpretability of intelligent fault diagnosis algorithms using the elevator of a fixed-wing unmanned aerial vehicle (UAV) as a diagnostic object. The Transformer model combines excellent modeling capability and efficient sequence data processing, is chosen to mine fault signal features to guarantee accurate diagnosis. Among the proposed interpretable fault diagnosis models, the local interpretable model-agnostic explanations (LIME) model is used to provide explicit interpretability for the decision-making process of the diagnosis model. In addition, a loss function called RDCE (reinforced diagnostic cross-entropy) Loss is designed to minimize the negative impact of different sample sizes for different fault types on the diagnostic performance. This loss function is designed to weigh the various types of faults to speed up the convergence of the model and improve the diagnostic accuracy. By comparing the proposed diagnostic strategy with other commonly used machine learning models, including long short term memory and recurrent neural network (RNN), the average diagnostic accuracy of the proposed diagnostic strategy is 99.97%, significantly better than that of the comparison algorithms. At the same time, this paper provides an in-depth interpretable analysis of the diagnostic process of the Transformer. The diagnostic process of the Transformer model gives the reasons for the diagnostic results from the point of view of the kind of features processed by the model. Based on this, the diagnostic model is simplified. After streamlining the number of features from 40 to 24 according to their importance, the diagnostic accuracy of the model is improved by 0.26%, and the diagnostic efficiency is improved. In addition, the proposed diagnostic strategy also shows significant advantages in terms of noise robustness.","2024-07-01","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","7","35","","","","","","","","","","English","","","","WOS:001199599000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","ALGORITHMS; fault diagnosis; fixed-wing UAV elevator; interpretable; loss function; transformer; TRANSFORMER; U-NET","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YYTQ7URC","journalArticle","2024","Zhang, T; Zhu, JK; Zhang, FK; Zhao, SJ; Liu, W; He, RH; Dong, HQ; Hong, QQ; Tan, CW; Li, P","Residual swin transformer for classifying the types of cotton pests in complex background","FRONTIERS IN PLANT SCIENCE","","1664-462X","10.3389/fpls.2024.1445418","","Background Cotton pests have a major impact on cotton quality and yield during cotton production and cultivation. With the rapid development of agricultural intelligence, the accurate classification of cotton pests is a key factor in realizing the precise application of medicines by utilize unmanned aerial vehicles (UAVs), large application devices and other equipment.Methods In this study, a cotton insect pest classification model based on improved Swin Transformer is proposed. The model introduces the residual module, skip connection, into Swin Transformer to improve the problem that pest features are easily confused in complex backgrounds leading to poor classification accuracy, and to enhance the recognition of cotton pests. In this study, 2705 leaf images of cotton insect pests (including three insect pests, cotton aphids, cotton mirids and cotton leaf mites) were collected in the field, and after image preprocessing and data augmentation operations, model training was performed.Results The test results proved that the accuracy of the improved model compared to the original model increased from 94.6% to 97.4%, and the prediction time for a single image was 0.00434s. The improved Swin Transformer model was compared with seven kinds of classification models (VGG11, VGG11-bn, Resnet18, MobilenetV2, VIT, Swin Transformer small, and Swin Transformer base), and the model accuracy was increased respectively by 0.5%, 4.7%, 2.2%, 2.5%, 6.3%, 7.9%, 8.0%.Discussion Therefore, this study demonstrates that the improved Swin Transformer model significantly improves the accuracy and efficiency of cotton pest detection compared with other classification models, and can be deployed on edge devices such as utilize unmanned aerial vehicles (UAVs), thus providing an important technological support and theoretical basis for cotton pest control and precision drug application.","2024-08-27","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","15","","","","","","","","","","English","","","","WOS:001308136200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","complex background; CONVOLUTION; cotton pests; deep learning; DIAGNOSIS; swin transformer; unmanned aerial vehicles","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IUFW7P8I","journalArticle","2024","Ghaith, S","Deep context transformer: bridging efficiency and contextual understanding of transformer models","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-024-05453-7","","This paper introduces the deep context transformer (DCT), which is a novel transformer model designed to enhance the efficiency and accuracy of processing contextually interlinked sequences in natural language processing (NLP) tasks, particularly in dialogue systems and code completion. Although they are powerful, traditional transformer models, struggle to manage extended sequences and complex data structures because of their fixed-length context window and uniform attention mechanism. DCT addresses these limitations by implementing a chunked transformer methodology, where sequences in a dialogue or code chunk are treated as standalone sequences and part of a broader context. This approach is complemented by decayed attention weighting, which scales down cross-attention weights based on the sequence age within the chunk, and an innovative positional encoding scheme that reflects both the token's position within a sequence and the sequence's position within a chunk. DCT was evaluated using the Schema-Guided Dialogue dataset from the Eighth Dialog System Technology Challenge and a subset of the IBM Project CodeNet for code completion, focusing on metrics such as character error rate, word error rate, and Bilingual Evaluation Understudy (BLEU) scores. The results revealed improvements in character error rate, word error rate, and BLEU scores compared to baseline models, with a notable increase in dialogue fluency and code completion accuracy. These achievements underscore the model's advanced contextual understanding, which demonstrates its effectiveness in NLP and programming language tasks. Additionally, a variant of the model was explored using Bidirectional Encoder Representations from Transformers as the encoder, which demonstrates similar improvements in performance metrics; however, it tended to repeat responses due to missing positional encoding across encoder chunk sequences. The ability of DCT to maintain context over extended conversations and code chunks demonstrated its potential as a transformative tool in dialogue systems and code completion, with applications extending to document summarization, and language translation.","2024-10","2025-02-26 20:39:15","2025-02-26 20:39:15","","8902-8923","","19","54","","","","","","","","","","English","","","","WOS:001263440700003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","ANOMALY DETECTION; Attention mechanism in NLP; Chunked transformer models; Contextual sequence processing; Transformer model efficiency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DPHYEQWZ","journalArticle","2022","Hechavarria, AA; Shafiq, MO","A modified attention mechanism powered by Bayesian Network for user activity analysis and prediction","DATA & KNOWLEDGE ENGINEERING","","0169-023X","10.1016/j.datak.2022.102034","","Analyzing and predicting user activity is important in the current digital era with a lot of use cases and applications. In this paper, we present an approach that facilitates a modification of the attention mechanism in a Transformer model. This work enables to improve the predictive capacity of a forecasting model which is progressively fed by somewhat erratic and small data generated by the early stages of online activity. The key element of the work is to use a Bayesian Network (BN) as a tool for feature engineering that helps to modify the attention mechanism in the Transformer model in that scenario. The model predicts the next activity on a sequence of online activities that the user will engage in while interacting with a Learning Management System (LMS). Click-stream data refers to a detailed log of how participants navigate through an online platform during a working session. The main application of our work is to improve the Predictor module of a smart hybrid-classifier for an LMS. Several configurations and architectures for the RNN-powered predictor, are tested and assessed. The results of the improved predictive capacity of this work can be useful to users in an online learning environment where early assistance in quasi-real time is required. This research answers the questions of how click-stream data can assist in refining the tasks of the Attention mechanism to improve the quality of the prediction. Performance is measured by the accuracy, right-content and first-state accuracy scores for the incoming sequence and compared across alternative models. The method also provides systematic customization of the attention mechanism in Transformers that can be applied to a range of problems involving click-stream data.","2022-07","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","140","","","","","","","","","","English","","","","WOS:000815771100005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Bayesian Graph Networks; BEHAVIOR; Click-stream data; CLICKSTREAM; Deep learning; Hybrid methods; LEARNING MANAGEMENT-SYSTEMS; STUDENTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y37UF76N","journalArticle","2024","Xu, HL; Yang, X; Hu, YH; Wang, DQ; Liang, ZY; Mu, H; Wang, YY; Shi, L; Gao, HQ; Song, DQ; Cheng, ZJ; Lu, Z; Zhao, XN; Lu, J; Wang, BW; Hu, ZY","Trusted artificial intelligence for environmental assessments: An explainable high-precision model with multi-source big data","ENVIRONMENTAL SCIENCE AND ECOTECHNOLOGY","","2666-4984","10.1016/j.ese.2024.100479","","Environmental assessments are critical for ensuring the sustainable development of human civilization. The integration of artificial intelligence (AI) in these assessments has shown great promise, yet the ""black box"" nature of AI models often undermines trust due to the lack of transparency in their decision-making processes, even when these models demonstrate high accuracy. To address this challenge, we evaluated the performance of a transformer model against other AI approaches, utilizing extensive multivariate and spatiotemporal environmental datasets encompassing both natural and anthropogenic indicators. We further explored the application of saliency maps as a novel explainability tool in multi-source AI-driven environmental assessments, enabling the identification of individual indicators' contributions to the model's predictions. We find that the transformer model outperforms others, achieving an accuracy of about 98% and an area under the receiver operating characteristic curve (AUC) of 0.891. Regionally, the environmental assessment values are predominantly classified as level II or III in the central and southwestern study areas, level IV in the northern region, and level V in the western region. Through explainability analysis, we identify that water hardness, total dissolved solids, and arsenic concentrations are the most influential indicators in the model. Our AI-driven environmental assessment model is accurate and explainable, offering actionable insights for targeted environmental management. Furthermore, this study advances the application of AI in environmental science by presenting a robust, explainable model that bridges the gap between machine learning and environmental governance, enhancing both understanding and trust in AI-assisted environmental assessments. (c) 2024 The Authors. Published by Elsevier B.V. on behalf of Chinese Society for Environmental Sciences, Harbin Institute of Technology, Chinese Research Academy of Environmental Sciences. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).","2024-11","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","22","","","","","","","","","","English","","","","WOS:001308967100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;79</p>","","","CONSTRUCTION; CONTAMINATION; DRINKING-WATER; Explainable AI; EXPOSURE; GROUNDWATER VULNERABILITY ASSESSMENT; HEALTH-RISK ASSESSMENT; Intelligent environmental assessment; MODIFIED DRASTIC MODEL; Multi-source data; POLLUTION; Transformer; UNCERTAINTIES; URANIUM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3RI9U59Y","journalArticle","2024","Li, FN; Lang, S; Tian, Y; Hong, BY; Rolf, B; Noortwyck, R; Schulz, R; Reggelin, T","A transformer-based deep reinforcement learning approach for dynamic parallel machine scheduling problem with family setups","JOURNAL OF INTELLIGENT MANUFACTURING","","0956-5515","10.1007/s10845-024-02470-8","","The parallel machine scheduling problem (PMSP) involves the optimized assignment of a set of jobs to a collection of parallel machines, which is a proper formulation for the modern manufacturing environment. Deep reinforcement learning (DRL) has been widely employed to solve PMSP. However, the majority of existing DRL-based frameworks still suffer from generalizability and scalability. More specifically, the state and action design still heavily rely on human efforts. To bridge these gaps, we propose a practical reinforcement learning-based framework to tackle a PMSP with new job arrivals and family setup constraints. We design a variable-length state matrix containing full job and machine information. This enables the DRL agent to autonomously extract features from raw data and make decisions with a global perspective. To efficiently process this novel state matrix, we elaborately modify a Transformer model to represent the DRL agent. By integrating the modified Transformer model to represent the DRL agent, a novel state representation can be effectively leveraged. This innovative DRL framework offers a high-quality and robust solution that significantly reduces the reliance on manual effort traditionally required in scheduling tasks. In the numerical experiment, the stability of the proposed agent during training is first demonstrated. Then we compare this trained agent on 192 instances with several existing approaches, namely a DRL-based approach, a metaheuristic algorithm, and a dispatching rule. The extensive experimental results demonstrate the scalability of our approach and its effectiveness across a variety of scheduling scenarios. Conclusively, our approach can thus solve the scheduling problems with high efficiency and flexibility, paving the way for application of DRL in solving complex and dynamic scheduling problems.","2024-08-08","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","","","","","","","","","","","English","","","","WOS:001286363100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;86</p>","","","ALGORITHM; Deep reinforcement learning; Dynamic parallel machine scheduling; Family setups; FORMULATIONS; MEAN WEIGHTED TARDINESS; Multi-head attention; New job arrivals; SEQUENCE; SMARTGANTT; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4W7JZFIE","journalArticle","2025","Ding, WP; Geng, Y; Huang, JS; Ju, HR; Wang, HP; Lin, CT","MGRW-Transformer: Multigranularity Random Walk Transformer Model for Interpretable Learning","IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS","","2162-237X","10.1109/TNNLS.2023.3326283","","Deep-learning models have been widely used in image recognition tasks due to their strong feature-learning ability. However, most of the current deep-learning models are ""black box"" systems that lack a semantic explanation of how they reached their conclusions. This makes it difficult to apply these methods to complex medical image recognition tasks. The vision transformer (ViT) model is the most commonly used deep-learning model with a self-attention mechanism that shows the region of influence as compared to traditional convolutional networks. Thus, ViT offers greater interpretability. However, medical images often contain lesions of variable size in different locations, which makes it difficult for a deep-learning model with a self-attention module to reach correct and explainable conclusions. We propose a multigranularity random walk transformer (MGRW-Transformer) model guided by an attention mechanism to find the regions that influence the recognition task. Our method divides the image into multiple subimage blocks and transfers them to the ViT module for classification. Simultaneously, the attention matrix output from the multiattention layer is fused with the multigranularity random walk module. Within the multigranularity random walk module, the segmented image blocks are used as nodes to construct an undirected graph using the attention node as a starting node and guiding the coarse-grained random walk. We appropriately divide the coarse blocks into finer ones to manage the computational cost and combine the results based on the importance of the discovered features. The result is that the model offers a semantic interpretation of the input image, a visualization of the interpretation, and insight into how the decision was reached. Experimental results show that our method improves classification performance with medical images while presenting an understandable interpretation for use by medical professionals.","2025-01","2025-02-26 20:39:15","2025-02-26 20:39:15","","1104-1118","","1","36","","","","","","","","","","English","","","","WOS:001107442700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Graph random walk; interpretable method; multigranularity formal analysis; self-attention mechanism; vision transformer (ViT)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z25SER85","journalArticle","2024","Zhao, ZS; Hao, XH; Shao, DH; Ji, WZ; Feng, TW; Zhao, Q; He, WX; Dai, LY; Zheng, ZJ; Liu, Y","A Snow Depth Downscaling Algorithm Based on Deep Learning Fusion of Enhanced Passive Microwave and Cloud-Free Optical Remote Sensing Data in China","REMOTE SENSING","","2072-4292","10.3390/rs16244756","","High spatial resolution snow depth (SD) is crucial for hydrological, ecological, and disaster research. However, passive microwave SD product (10/25 km) is increasingly insufficient to meet contemporary requirements due to its coarse spatial resolution, particularly in heterogeneous alpine areas. In this study, we develop a superior SD downscaling algorithm based on the FT-Transformer (Feature Tokenizer + Transformer) model, termed FTSD. This algorithm fuses the latest calibrated enhanced resolution brightness temperature (CETB) (3.125/6.25 km) with daily cloud-free optical snow data (500 m), including snow cover fraction (SCF) and snow cover days (SCD). Developed and evaluated using 42,692 ground measurements across China from 2000 to 2020, FTSD demonstrated notable improvements in accuracy and spatial resolution of SD retrieval. Specifically, the RMSE of temporal and spatiotemporal independent validation for FTSD is 7.64 cm and 9.74 cm, respectively, indicating reliable generalizability and stability. Compared with the long-term series of SD in China (25 km, RMSE = 10.77 cm), FTSD (500 m, RMSE = 7.67 cm) provides superior accuracy, especially improved by 48% for deep snow (> 40 cm). Moreover, with the higher spatial resolution, FTSD effectively captures the SD's spatial heterogeneity in the mountainous regions of China. When compared with downscaling algorithms utilizing the raw TB data and the traditional random forest model, the CETB data and FT-Transformer model optimize the RMSE by 10.08% and 4.84%, respectively, which demonstrates the superiority of FTSD regarding data sources and regression methods. Collectively, these results demonstrate that the innovative FTSD algorithm exhibits reliable performance for SD downscaling and has the potential to provide a robust data foundation for meteorological and environmental research.","2024-12","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","24","16","","","","","","","","","","English","","","","WOS:001385643100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","CLIMATE; COVER; deep learning; downscaling; enhanced spatial resolution; MASS; MODEL; PATTERNS; PRODUCT; RECORD; RETRIEVAL; snow depth","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KXWE75RQ","journalArticle","2024","Ge, Q; Li, J; Wang, XH; Deng, YY; Zhang, KY; Sun, HY","LiteTransNet: An interpretable approach for landslide displacement prediction using transformer model with attention mechanism","ENGINEERING GEOLOGY","","0013-7952","10.1016/j.enggeo.2024.107446","","Accurate landslide displacement prediction is crucial for effective early warning systems to mitigate hazards. The importance of historical information varies with time during prediction due to the underlying landslide deformation mechanism. Despite advances in dynamic machine learning models like Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU), they struggle to fully capture and interpret the varying importance of historical information during prediction, resulting in decreased accuracy and limited understanding of landslide physical mechanisms. Additionally, these approaches rely on manual feature selection, which is independent of the learning process and therefore is prone to estimation errors. To address these challenges, we propose LiteTransNet, a Lightweighted Transformer Network tailored for landslide displacement prediction. Built on the revolutionary Transformer model for sequential data, LiteTransNet leverages localized self-attention to selectively focus on relevant timestamps and provides interpretable results through its attention heatmap. Furthermore, LiteTransNet performs end-to-end time series modeling without extensive feature engineering. We validate LiteTransNet on two landslides in China's Three Gorges Reservoir Area and demonstrate its improved accuracy over recurrent baselines utilizing feature selection methods. Notably, the attention heatmap generated by LiteTransNet provides interpretable insights into the model's temporal dependency learning. It uncovers the varying importance of historical information at different timestamps, showcasing how LiteTransNet's attention aligns with specific periods of the external environment that cause significant disruptions in the landslide system. Our findings reveal that these disruptions continuously impact displacement prediction until their effects fade or are replaced by subsequent intense disturbances, which traditional recurrent methods are unable to capture. Further experiment shows that LiteTransNet enhances efficiency through its streamlined architecture and its parallelization capability. Overall, LiteTransNet innovates landslide prediction by providing accuracy, interpretability, and efficiency, enhancing understanding of deformation mechanisms to facilitate effective early warning systems.","2024-03","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","331","","","","","","","","","","English","","","","WOS:001199750700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","3 GORGES RESERVOIR; Attention mechanism; BAISHUIHE LANDSLIDE; Interpretable machine learning; Landslide displacement prediction; MACHINE; Three gorges reservoir area; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AX7VKS7H","journalArticle","2024","Hossain, MM; Hossain, MS; Safran, M; Alfarhood, S; Alfarhood, M; Mridha, MF","A Hybrid Attention-Based Transformer Model for Arabic News Classification Using Text Embedding and Deep Learning","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3522061","","Efficient classification of Arabic news items has become more crucial for efficient information management and analysis due to the fast growth of online news material. This paper proposes a hybrid Attention-Based Transformer Model (ABTM) for Arabic news categorization that uses deep learning and classical text representations to improve classification accuracy and interpretability. Given the increasing amount of Arabic news materials, robust categorization systems are crucial for properly managing and analyzing this information. To deal with the complexities of the Arabic language and enrich the dataset, we used a thorough preparation pipeline that includes text cleaning, tokenization, lemmatization, and data augmentation approaches. We combined a bespoke attention embedder with classic TF-IDF and Bag-of-Words features to provide a comprehensive feature set that includes both the text's contextual and statistical aspects. We benchmarked our technique using cutting-edge Arabic language models, such as AraBERTv1-base and asafaya/bert-base-arabic. We use (local interpretable model agnostic explanation) text explainer to offer insights into model predictions, improving our findings' interpretability. Our results show that the ABTM strategy considerably enhances classification performance, with high accuracy and reasonable explanations for model decisions. This classification includes a wide range of news categories, including politics, sports, culture, the economy, and a variety of themes, representing the diversity of Arabic news. This study contributes to the field of Arabic natural language processing by offering a novel method that combines deep learning with traditional techniques, thereby advancing the state of Arabic news classification. Enhanced classification accuracy and interpretability facilitate better management and understanding of the rich and growing Arabic news content, supporting informed decision-making and knowledge discovery.","2024","2025-02-26 20:39:15","2025-02-26 20:39:15","","198046-198066","","","12","","","","","","","","","","English","","","","WOS:001386558700034","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Accuracy; Analytical models; Arabic news classifications; Arabic text classifications; Data models; Deep learning; hybrid transformer; Predictive models; Sentiment analysis; SENTIMENT ANALYSIS; Syntactics; Text categorization; Tokenization; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QXUAICE5","journalArticle","2023","Liu, XH; Ye, K; van Vlijmen, HWT; IJzerman, A; van Westen, GJP","DrugEx v3: scaffold-constrained drug design with graph transformer-based reinforcement learning","JOURNAL OF CHEMINFORMATICS","","1758-2946","10.1186/s13321-023-00694-z","","Rational drug design often starts from specific scaffolds to which side chains/substituents are added or modified due to the large drug-like chemical space available to search for novel drug-like molecules. With the rapid growth of deep learning in drug discovery, a variety of effective approaches have been developed for de novo drug design. In previous work we proposed a method named DrugEx, which can be applied in polypharmacology based on multi-objective deep reinforcement learning. However, the previous version is trained under fixed objectives and does not allow users to input any prior information (i.e. a desired scaffold). In order to improve the general applicability, we updated DrugEx to design drug molecules based on scaffolds which consist of multiple fragments provided by users. Here, a Transformer model was employed to generate molecular structures. The Transformer is a multi-head self-attention deep learning model containing an encoder to receive scaffolds as input and a decoder to generate molecules as output. In order to deal with the graph representation of molecules a novel positional encoding for each atom and bond based on an adjacency matrix was proposed, extending the architecture of the Transformer. The graph Transformer model contains growing and connecting procedures for molecule generation starting from a given scaffold based on fragments. Moreover, the generator was trained under a reinforcement learning framework to increase the number of desired ligands. As a proof of concept, the method was applied to design ligands for the adenosine A(2A) receptor (A(2A)AR) and compared with SMILES-based methods. The results show that 100% of the generated molecules are valid and most of them had a high predicted affinity value towards A(2A)AR with given scaffolds.","2023-02-20","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","1","15","","","","","","","","","","English","","","","WOS:000934589300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;31<br/>Total Times Cited:&nbsp;&nbsp;34<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Adenosine A(2A) receptor; ADENOSINE RECEPTORS; Deep learning; DISCOVERY; Drug design; Multi-objective optimization; Policy gradient; Reinforcement learning; TOOL; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VP3EDZDE","journalArticle","2024","Ko, YS; Parkinson, J; Liu, C; Wang, W","TUnA: an uncertainty-aware transformer model for sequence-based protein-protein interaction prediction","BRIEFINGS IN BIOINFORMATICS","","1467-5463","10.1093/bib/bbae359","","Protein-protein interactions (PPIs) are important for many biological processes, but predicting them from sequence data remains challenging. Existing deep learning models often cannot generalize to proteins not present in the training set and do not provide uncertainty estimates for their predictions. To address these limitations, we present TUnA, a Transformer-based uncertainty-aware model for PPI prediction. TUnA uses ESM-2 embeddings with Transformer encoders and incorporates a Spectral-normalized Neural Gaussian Process. TUnA achieves state-of-the-art performance and, importantly, evaluates uncertainty for unseen sequences. We demonstrate that TUnA's uncertainty estimates can effectively identify the most reliable predictions, significantly reducing false positives. This capability is crucial in bridging the gap between computational predictions and experimental validation.","2024-07-25","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","5","25","","","","","","","","","","English","","","","WOS:001275455100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","deep learning; protein-protein interaction prediction; uncertainty awareness","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P7UXJ2DV","journalArticle","2023","Tao, FF; Pi, YL; Deng, MH; Tang, YJ; Yuan, C","Research on Intelligent Grading Evaluation of Water Conservancy Project Safety Risks Based on Deep Learning","WATER","","2073-4441","10.3390/w15081607","","With the rise of artificial intelligence and big data technologies, it is increasingly significant to apply these emerging technologies to scientific decision-making in water conservancy project construction management in the face of many problems in the process of water conservancy project construction. Different from using traditional assessment methods for risk classification of water conservancy construction hazards, this paper integrates a priori attention and constructs a transformer risk prediction model based on a sliding window, which deeply explores the data value of water conservancy construction hazards information, further predicts the risk level of water conservancy construction hazards and realizes efficient and intelligent management of water conservancy project construction hazard identification management.","2023-04","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","8","15","","","","","","","","","","English","","","","WOS:000977922000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","a priori knowledge; deep learning; hazard sources; MANAGEMENT; risk evaluation; task scenarios; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N8CCIJ6D","journalArticle","2023","Liu, XH; Lei, ZY","Dynamic Tracking Aggregation with Transformers for RGB-T Tracking","JOURNAL OF INFORMATION PROCESSING SYSTEMS","","1976-913X","10.3745/JIPS.01.0092","","RGB-thermal (RGB-T) tracking using unmanned aerial vehicles (UAVs) involves challenges with regards to the similarity of objects, occlusion, fast motion, and motion blur, among other issues. In this study, we propose dynamic tracking aggregation (DTA) as a unified framework to perform object detection and data association. The proposed approach obtains fused features based a transformer model and an L1-norm strategy. To link the current frame with recent information, a dynamically updated embedding called dynamic tracking identification (DTID) is used to model the iterative tracking process. For object association, we designed a long short-term tracking aggregation module for dynamic feature propagation to match spatial and temporal embeddings. DTA achieved a highly competitive performance in an experimental evaluation on public benchmark datasets.","2023-02","2025-02-26 20:39:15","2025-02-26 20:39:15","","80-88","","1","19","","","","","","","","","","English","","","","WOS:000946671000007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","Cross-modal Fusion; Dynamic Tracking Aggregation; RGB-T Tracking; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"73FMKKY5","journalArticle","2023","Liu, B; Liu, KX; Qi, XQ; Zhang, WJ; Li, B","Classification of deep-sea cold seep bacteria by transformer combined with Raman spectroscopy","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-023-28730-w","","Raman spectroscopy is a rapid analysis method of biological samples without labeling and destruction. At present, the commonly used Raman spectrum classification models include CNN, RNN, etc. The transformer has not been used for Raman spectrum identification. This paper introduces a new method of transformer combined with Raman spectroscopy to identify deep-sea cold seep microorganisms at the single-cell level. We collected the Raman spectra of eight cold seep bacteria, each of which has at least 500 spectra for the training of transformer model. We compare the transformer classification model with other deep learning classification models. The experimental results show that this method can improve the accuracy of microbial classification. Our average isolation level accuracy is more than 97%.","2023-02-24","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","1","13","","","","","","","","","","English","","","","WOS:000942280900030","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","CELLS; IDENTIFICATION; RESPIRATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X9PYSI6A","journalArticle","2024","Li, JL; Zhang, YS","Regressive vision transformer for dog cardiomegaly assessment","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-023-50063-x","","Cardiac disease is one of the leading causes of death in dogs. Automatic cardiomegaly detection has great significance in helping clinicians improve the accuracy of the diagnosis process. Deep learning methods show promising results in improving cardiomegaly classification accuracy, while they are still not widely applied in clinical trials due to the difficulty in mapping predicted results with input radiographs. To overcome these challenges, we first collect large-scale dog heart X-ray images. We then develop a dog heart labeling tool and apply a few-shot generalization strategy to accelerate the label speed. We also develop a regressive vision transformer model with an orthogonal layer to bridge traditional clinically used VHS metric with deep learning models. Extensive experimental results demonstrate that the proposed model achieves state-of-the-art performance.","2024-01-17","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","1","14","","","","","","","","","","English","","","","WOS:001184473900024","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T62PQ87K","journalArticle","2021","Wang, YY; Zhong, XY; Chen, X","Influence of saturation levels on transformer equivalent circuit model","JOURNAL OF ELECTRICAL ENGINEERING-ELEKTROTECHNICKY CASOPIS","","1335-3632","10.2478/jee-2021-0054","","This paper presents a modelling approach for a transformer with different saturation levels. First, the magnetic field distributions at different saturation levels in the transformer are analyzed by using numerical simulations. Then, the characteristics of the leakage magnetic flux are analyzed, and the magnetic circuits with varying leakage reluctance topologies are modeled. Finally, based on the mature duality relationship between electric and magnetic circuits, the equivalent electric circuit models are obtained. These kinds of models embody the effect of different saturation levels on the connection points of the leakage flux branches, and it can fully reflect the various working states of the transformer. The accuracy of the models is verified by comparing the circuit simulation results with those of FEM transient simulations.","2021-12","2025-02-26 20:39:15","2025-02-26 20:39:15","","381-387","","6","72","","","","","","","","","","English","","","","WOS:000754711600004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;17</p>","","","duality principle; leakage flux; PART I; saturation level; SYSTEM; transformer model; TRANSIENTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C8EDQIWY","journalArticle","2024","Wang, D; Xia, ZY; Wang, L; Yan, J; Yin, HL","Gas Graph Convolutional Transformer for Robust Generalization in Adaptive Gas Mixture Concentration Estimation","ACS SENSORS","","2379-3694","10.1021/acssensors.3c02654","","Gas concentration estimation has a tremendous research significance in various fields. However, existing methods for estimating the concentration of mixed gases generally depend on specific data-preprocessing methods and suffer from poor generalizability to diverse types of gases. This paper proposes a graph neural network-based gas graph convolutional transformer model (GGCT) incorporating the information propagation properties and the physical characteristics of temporal sensor data. GGCT accurately predicts mixed gas concentrations and enhances its generalizability by analyzing the concentration tokens. The experimental results highlight the GGCT's robust performance, achieving exceptional levels of accuracy across most tested gas components, underscoring its strong potential for practical applications in mixed gas analysis.","2024-03-21","2025-02-26 20:39:15","2025-02-26 20:39:15","","1927-1937","","4","9","","","","","","","","","","English","","","","WOS:001189772000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","deep learning; DISCRIMINATION; gas mixture concentration estimation; gas sensor arrays; graph neural network; real-timegas mixture analysis; SENSORS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"887HPI8R","journalArticle","2021","Zhang, XY; Liu, XH; Guo, FH; Xiao, GX; Wang, P","Calculation of DC Bias Reactive Power Loss of Converter Transformer via Finite Element Analysis","IEEE TRANSACTIONS ON POWER DELIVERY","","0885-8977","10.1109/TPWRD.2020.2991293","","This paper proposes a novel and applicable approach to calculate the reactive power loss of converter transformer under dc bias. By using this proposed method, only general information of the converter transformer and the network is needed for the calculation within a certain dc current range. Specifically, a three-dimensional model of +/- 800 kV converter transformer model for simulation test is established by the finite element method. Through simulation test, the electromagnetic characteristics and reactive loss characteristics of converter transformer under dc bias can be obtained, and the relationship between the bias current and the reactive loss of +/- 800 kV converter transformer is quantified. Simulation results validate the feasibility of proposed algorithm.","2021-04","2025-02-26 20:39:15","2025-02-26 20:39:15","","751-759","","2","36","","","","","","","","","","English","","","","WOS:000633440400022","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;21<br/>Total Times Cited:&nbsp;&nbsp;24<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","3-PHASE; Converter transformer; dc bias; FIELD; finite element model; reactive power loss; TRANSIENT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JCSUCWLR","journalArticle","2023","Zhang, YH; Hou, W","Vision Transformer with hierarchical structure and windows shifting for person re-identification","PLOS ONE","","1932-6203","10.1371/journal.pone.0287979","","Extracting rich feature representations is a key challenge in person re-identification (Re-ID) tasks. However, traditional Convolutional Neural Networks (CNN) based methods could ignore a part of information when processing local regions of person images, which leads to incomplete feature extraction. To this end, this paper proposes a person Re-ID method based on vision Transformer with hierarchical structure and window shifting. When extracting person image features, the hierarchical Transformer model is constructed by introducing the hierarchical construction method commonly used in CNN. Then, considering the importance of local information of person images for complete feature extraction, the self-attention calculation is performed by shifting within the window region. Finally, experiments on three standard datasets demonstrate the effectiveness and superiority of the proposed method.","2023-06-30","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","6","18","","","","","","","","","","English","","","","WOS:001025404600015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DQQFB6L7","journalArticle","2024","Guan, YX; Hu, JH; Wang, YT; Gu, WT; Xi, HJ","Blending News Text and Economic Policy Uncertainty to Forecast the Company's Unexpected Earnings","JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT INFORMATICS","","1343-0130","10.20965/jaciii.2024.p0776","","Employing Chinese A-share market data, this study explores how news text and economic policy uncertainty (EPU) can be combined to predict a company's unanticipated earnings using the XL (extra long) Transformer and long short term memory (LSTM) models. The results show that adding news text features or the EPU index can improve the model's predictive performance. However, adding the EPU index improves the model prediction performance by a tiny amount. Next, news headlines have better predictive performance relative to news content. Meanwhile, as a supplement to news headlines, news content can further improve predictive performance. Finally, the XL-Transformer model has better predictive performance than the LSTM model, but the improvement in the effect is limited.","2024-07","2025-02-26 20:39:15","2025-02-26 20:39:15","","776-782","","4","28","","","","","","","","","","English","","","","WOS:001346228100004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;13</p>","","","deep learning; economic policy uncertainty; news texts; unanticipated returns","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WC5NEJUW","journalArticle","2024","Liu, JK; Long, XY; Jiang, C; Liao, WW","Multi-feature vision transformer for automatic defect detection and quantification in composites using thermography","NDT & E INTERNATIONAL","","0963-8695","10.1016/j.ndteint.2023.103033","","This paper proposes a novel multi-feature vision transformer model for automatic defect detection and quantification in composites using thermography. Firstly, a sampling strategy for infrared data is proposed to address the issues of data class overlap and imbalance. Secondly, multiple feature fusion is employed to aggregate various important infrared features that exhibit strong correlations with defects. Furthermore, a multi-feature vision transformer (VIT) model that leverages self-attention mechanisms to capture global context and long-range dependencies in the composite images is developed. Experiments are performed to verify the effectiveness of the proposed method. The results show that the proposed method has excellent performance in terms of both accuracy and generalization capability.","2024-04","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","143","","","","","","","","","","English","","","","WOS:001162557900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Automatic defect detection and quantification; Composite materials; Deep learning; Multi -feature vision transformer; NETWORK; Thermography","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SGHYDHW2","journalArticle","2023","AlShehhi, A; Welsch, R","Artificial intelligence for improving Nitrogen Dioxide forecasting of Abu Dhabi environment agency ground-based stations","JOURNAL OF BIG DATA","","2196-1115","10.1186/s40537-023-00754-z","","Nitrogen Dioxide (NO2) is a common air pollutant associated with several adverse health problems such as pediatric asthma, cardiovascular mortality,and respiratory mortality. Due to the urgent society's need to reduce pollutant concentration, several scientific efforts have been allocated to understand pollutant patterns and predict pollutants' future concentrations using machine learning and deep learning techniques. The latter techniques have recently gained much attention due it's capability to tackle complex and challenging problems in computer vision, natural language processing, etc. In the NO2 context, there is still a research gap in adopting those advanced methods to predict the concentration of pollutants. This study fills in the gap by comparing the performance of several state-of-the-art artificial intelligence models that haven't been adopted in this context yet. The models were trained using time series crossvalidation on a rolling base and tested across different periods using NO2 data from 20 monitoring ground-based stations collected by Environment Agency- Abu Dhabi, United Arab Emirates. Using the seasonal Mann-Kendall trend test and Sen's slope estimator, we further explored and investigated the pollutants trends across the different stations. This study is the first comprehensive study that reported the temporal characteristic of NO2 across seven environmental assessment points and compared the performance of the state-of-the-art deep learning models for predicting the pollutants' future concentration. Our results reveal a difference in the pollutants concentrations level due to the geographic location of the different stations, with a statistically significant decrease in the NO2 annual trend for the majority of the stations. Overall, NO2 concentrations exhibit a similar daily and weekly pattern across the different stations, with an increase in the pollutants level during the early morning and the first working day. Comparing the state-of-the-art model performance transformer model demonstrate the superiority of (MAE:0.04 (+/- 0.04),MSE:0.06 (+/- 0.04), RMSE:0.001 (+/- 0.01), R-2: 0.98 (+/- 0.05)), compared with LSTM (MAE:0.26 (+/- 0.19), MSE:0.31 (+/- 0.21), RMSE:0.14 (+/- 0.17), R-2: 0.56 (+/- 0.33)), InceptionTime (MAE: 0.19 (+/- 0.18), MSE: 0.22 (+/- 0.18), RMSE:0.08 (+/- 0.13), R-2:0.38 (+/- 1.35)), ResNet (MAE:0.24 (+/- 0.16), MSE:0.28 (+/- 0.16), RMSE:0.11 (+/- 0.12), R-2:0.35 (+/- 1.19)), XceptionTime (MAE:0.7 (+/- 0.55), MSE:0.79 (+/- 0.54), RMSE:0.91 (+/- 1.06), R-2: -4.83 (+/- 9.38)), and MiniRocket (MAE:0.21 (+/- 0.07), MSE:0.26 (+/- 0.08), RMSE:0.07 (+/- 0.04), R-2: 0.65 (+/- 0.28)) to tackle this challenge. The transformer model is a powerful model for improving the accurate forecast of the NO2 levels and could strengthen the current monitoring system to control and manage the air quality in the region.","2023-06-02","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","1","10","","","","","","","","","","English","","","","WOS:001000526700002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Artificial Intelligence; Deep Learning; Forecast; Nitrogen Dioxide; NO2; PREDICTION; Temporal Models; Transformer Model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TN45EKSH","journalArticle","2024","Zhang, WX; Liu, Z; Song, Y; Lu, YX; Feng, ZP","Prediction of multi-physics field distribution on gas turbine endwall using an optimized surrogate model with various deep learning frames","INTERNATIONAL JOURNAL OF NUMERICAL METHODS FOR HEAT & FLUID FLOW","","0961-5539","10.1108/HFF-10-2023-0620","","PurposeTo improve the speed and accuracy of turbine blade film cooling design process, the most advanced deep learning models were introduced into this study to investigate the most suitable define for prediction work. This paper aims to create a generative surrogate model that can be applied on multi-objective optimization problems.Design/methodology/approachThe latest backbone in the field of computer vision (Swin-Transformer, 2021) was introduced and improved as the surrogate function for prediction of the multi-physics field distribution (film cooling effectiveness, pressure, density and velocity). The basic samples were generated by Latin hypercube sampling method and the numerical method adopt for the calculation was validated experimentally at first. The training and testing samples were calculated at experimental conditions. At last, the surrogate model predicted results were verified by experiment in a linear cascade.FindingsThe results indicated that comparing with the Multi-Scale Pix2Pix Model, the Swin-Transformer U-Net model presented higher accuracy and computing speed on the prediction of contour results. The computation time for each step of the Swin-Transformer U-Net model is one-third of the original model, especially in the case of multi-physics field prediction. The correlation index reached more than 99.2% and the first-order error was lower than 0.3% for multi-physics field. The predictions of the data-driven surrogate model are consistent with the predictions of the computational fluid dynamics results, and both are very close to the experimental results. The application of the Swin-Transformer model on enlarging the different structure samples will reduce the cost of numerical calculations as well as experiments.Research limitations/implicationsThe number of U-Net layers and sample scales has a proper relationship according to equation (8). Too many layers of U-Net will lead to unnecessary nonlinear variation, whereas too few layers will lead to insufficient feature extraction. In the case of Swin-Transformer U-Net model, incorrect number of U-Net layer will reduce the prediction accuracy. The multi-scale Pix2Pix model owns higher accuracy in predicting a single physical field, but the calculation speed is too slow. The Swin-Transformer model is fast in prediction and training (nearly three times faster than multi Pix2Pix model), but the predicted contours have more noise. The neural network predicted results and numerical calculations are consistent with the experimental distribution.Originality/valueThis paper creates a generative surrogate model that can be applied on multi-objective optimization problems. The generative adversarial networks using new backbone is chosen to adjust the output from single contour to multi-physics fields, which will generate more results simultaneously than traditional surrogate models and reduce the time-cost. And it is more applicable to multi-objective spatial optimization algorithms. The Swin-Transformer surrogate model is three times faster to computation speed than the Multi Pix2Pix model. In the prediction results of multi-physics fields, the prediction results of the Swin-Transformer model are more accurate.","2024-09-02","2025-02-26 20:39:15","2025-02-26 20:39:15","","2865-2889","","8","34","","","","","","","","","","English","","","","WOS:001130398600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Data driven; DESIGN; Film cooling; FILM-COOLING EFFECTIVENESS; Gas turbine; Prediction; ROWS; Surrogate model; TURBOMACHINERY; VANE ENDWALL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UN7T9EZA","journalArticle","2024","Ohi, AQ; Gavrilova, ML","Self-Supervised Open-Set Speaker Recognition with Laguerre-Voronoi Descriptors","SENSORS","","1424-8220","10.3390/s24061996","","Speaker recognition is a challenging problem in behavioral biometrics that has been rigorously investigated over the last decade. Although numerous supervised closed-set systems inherit the power of deep neural networks, limited studies have been made on open-set speaker recognition. This paper proposes a self-supervised open-set speaker recognition that leverages the geometric properties of speaker distribution for accurate and robust speaker verification. The proposed framework consists of a deep neural network incorporating a wider viewpoint of temporal speech features and Laguerre-Voronoi diagram-based speech feature extraction. The deep neural network is trained with a specialized clustering criterion that only requires positive pairs during training. The experiments validated that the proposed system outperformed current state-of-the-art methods in open-set speaker recognition and cluster representation.","2024-03","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","6","24","","","","","","","","","","English","","","","WOS:001192822000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","behavioral biometric; deep neural network; Laguerre-Voronoi diagram; open-set speaker recognition; representation learning; self-supervised learning; smart sensors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TZHBTXIR","journalArticle","2023","Fucinato, K; Niebuhr, O; Norskov, S; Fischer, K","Charismatic speech features in robot instructions enhance team creativity","FRONTIERS IN COMMUNICATION","","2297-900X","10.3389/fcomm.2023.1115360","","This study examines whether a social robot can enable team creativity and increase team performance depending on its speaking style. The aim is to provide insight into human teams' creativity and performance when exposed to different ways of speaking by a social robot, that is, when the robotic creativity facilitator is using different acoustic-prosodic features. In one condition, participants received their instructions from the robot in a ""charismatic"" speaking style, in the other, the robot used a less engaging way of speaking. The results show that when the robot's speech is based on charismatic speech characteristics, it is significantly better at enhancing team creativity and performance than when its speech uses fewer charismatic speech characteristics. The robot's speaking style thus influences its effectiveness as team creativity facilitator.","2023-05-22","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","8","","","","","","","","","","English","","","","WOS:000998909000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","charismatic speech; human-robot interaction; PERFORMANCE; robot speech; speech prosody; STYLE; team creativity; WORK","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QYE4D7AD","journalArticle","2022","Khare, V; Singh, M","Performance Analysis of Different Classifiers for Tele-Diagnosis of Parkinson's Disease","WIRELESS PERSONAL COMMUNICATIONS","","0929-6212","10.1007/s11277-021-08901-6","","Parkinson's disease (PD) is a second most progressive neurodegenerative disorder. Millions of people across the world are affected with this disease. In recent days, there are significant research has been reported for the screening of PD using Dysphonia features. In this study, a new weights generation method named as Kernel Fuzzy C-means Ratio based on different clustering technique (KFCM, FCM and KCM) has been proposed. The main aim of this work is to transform non-separable speech features in the dataset to a linearly separable such that the classification can be enhanced. In classification stage, six different classifiers are used to classify the weighted data and significant improvement in sensitivity, accuracy and specificity parameters are recorded.","2022-01","2025-02-26 20:39:15","2025-02-26 20:39:15","","331-348","","1","122","","","","","","","","","","English","","","","WOS:000686994200008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","DOPAMINERGIC SYSTEM; Fuzzy C-means ratio (FCM); K-means clustering (KCM); Kernel Fuzzy C-means (K-FCM); Kernel Fuzzy C-means ratio (KFCMR); Parkinson's disease (PD); People with Parkinson's (PWP); Support Vector Machine (SVM)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F5WLBMGQ","journalArticle","2021","Wu, BW; Liu, CR; Ishi, CT; Ishiguro, H","Modeling the Conditional Distribution of Co-Speech Upper Body Gesture Jointly Using Conditional-GAN and Unrolled-GAN","ELECTRONICS","","2079-9292","10.3390/electronics10030228","","Co-speech gestures are a crucial, non-verbal modality for humans to communicate. Social agents also need this capability to be more human-like and comprehensive. This study aims to model the distribution of gestures conditioned on human speech features. Unlike previous studies that try to find injective functions that map speech to gestures, we propose a novel, conditional GAN-based generative model to not only convert speech into gestures but also to approximate the distribution of gestures conditioned on speech through parameterization. An objective evaluation and user study show that the proposed model outperformed the existing deterministic model, indicating that generative models can approximate real patterns of co-speech gestures better than the existing deterministic model. Our results suggest that it is critical to consider the nature of randomness when modeling co-speech gestures.","2021-02","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","3","10","","","","","","","","","","English","","","","WOS:000614975600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;15<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","deep learning; EXPRESSION; generative model; gesture generation; neural network; social robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"93M97PYJ","journalArticle","2025","Xie, J; Chu, D","Character emotion recognition algorithm in small sample video based on multimodal feature fusion","INTERNATIONAL JOURNAL OF BIOMETRICS","","1755-8301","10.1504/IJBM.2024.10063382","","In order to overcome the problems of poor recognition accuracy and low recognition accuracy in traditional character emotion recognition algorithms, this paper proposes a small sample video character emotion recognition algorithm based on multimodal feature fusion, aiming to overcome the problems of low accuracy and poor precision in traditional algorithms. The steps of this algorithm include extracting facial image scene features and expression features from small sample videos, using GloVe technology to extract text features, and obtaining character speech features through filter banks. Subsequently, a bidirectional LSTM model was used to fuse multimodal features, and emotions were classified using fully connected layers and softmax functions. The experimental results show that the method achieves an emotion recognition accuracy of up to 98.6%, with a recognition rate of 64% for happy emotions and 62% for neutral emotions.","2025","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","1-2","17","","","","","","","","","","English","","","","WOS:001391609800007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;15</p>","","","attention mechanism; bidirectional LSTM model; multimodal feature fusion; softmax function","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EJLAB4J8","journalArticle","2021","Liu, XC; Sahidullah, M; Kinnunen, T","Optimizing Multi-Taper Features for Deep Speaker Verification","IEEE SIGNAL PROCESSING LETTERS","","1070-9908","10.1109/LSP.2021.3122796","","Multi-taper estimators provide low-variance power spectrum estimates that can be used in place of the windowed discrete Fourier transform (DFT) to extract speech features such as mel-frequency cepstral coefficients (MFCCs). Even if past work has reported promising automatic speaker verification (ASV) results with Gaussian mixture model-based classifiers, the performance of multi-taper MFCCs with deep ASV systems remains an open question. Instead of a static-taper design, we propose to optimize the multi-taper estimator jointly with a deep neural network trained for ASV tasks. With a maximum improvement on the SITW corpus of 25.8% in terms of equal error rate over the static-taper, our method helps preserve a balanced level of leakage and variance, providing more robustness.","2021","2025-02-26 20:39:15","2025-02-26 20:39:15","","2187-2191","","","28","","","","","","","","","","English","","","","WOS:000722031300008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Discrete Fourier transforms; Feature extraction; Mel frequency cepstral coefficient; MFCC; Multi-taper spectrum; Neural networks; RECOGNITION; speaker verification; Standards; Stochastic processes; Task analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GKEZBD5R","journalArticle","2025","Xu, SY; Cao, YH; Zhang, ZH; Wang, MJ","Two-stage UNet with channel and temporal-frequency attention for multi-channel speech enhancement","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2024.103154","","In multi-channel speech enhancement, spectral masking and beamforming are two standard techniques. We propose a two-stage model combining the advantages of both approaches to enhance network performance. We propose the temporal-frequency self-attention block to effectively extract speech features in the temporal- frequency dimension with low complexity. We propose the residual efficient channel attention block, a lightweight module that learns channel attention through inter-channel interaction. Besides, We propose the real and imaginary beamforming as a replacement for traditional beamforming, estimating filter weights from the real and imaginary parts separately and fully utilizing the spatial information of the data. According to the experimental results, the performance of this model outperforms other models on both the L3DAS22 dataset and the spatial DNS dataset. Furthermore, our model demonstrates superior denoising and dereverberation under various noise and reverberation conditions.","2025-01","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","166","","","","","","","","","","English","","","","WOS:001391076800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","Beamforming; NETWORK; Neural network; Self-attention; Speech enhancement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WYN7B2N4","journalArticle","2023","Sun, CL; Jiang, WQ; Leng, Y; Chen, FL","A new speech enhancement method based on Swin-UNet model","NOISE CONTROL ENGINEERING JOURNAL","","0736-2501","","","U-shaped Network (UNet) has shown excellent performance in a variety of speech enhancement tasks. However, because of the intrinsic limitation of convolutional operation, traditional UNet built with convolutional neural network (CNN) cannot learn global and long-term information well. In this work, we propose a new Swin-UNet-based speech enhancement method. Unlike the traditional UNet model, the CNN blocks are all replaced with Swin-Transformer blocks to explore more multiscale contextual information. Te SwinUNet model employs shifted window mechanism which not only overcomes the defect of high computational complexity of the Transformer but also enhances global information interaction by utilizing the powerful global modeling capability of the Transformer. Through hierarchical Swin-Transformer blocks, global and local speech features can be fully leveraged to improve speech reconstruction ability. Experimental results confirm that the proposed method can eliminate more background noise while maintaining good objective speech quality.& COPY; 2023 Institute of Noise Control Engineering.","2023-07","2025-02-26 20:39:15","2025-02-26 20:39:15","","258-267","","4","71","","","","","","","","","","English","","","","WOS:001066138300003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","NOISE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XTJYAVDF","journalArticle","2024","Dai, ZY; Liu, HT","PART-OF-SPEECH FEATURES IN BOB DYLAN'S SONG LYRICS: A STYLOMETRIC ANALYSIS","INTERNATIONAL JOURNAL OF HUMANITIES AND ARTS COMPUTING-A JOURNAL OF DIGITAL HUMANITIES","","1753-8548","10.3366/ijhac.2024.0335","","Honoured as a Nobel Laureate in 2016, Bob Dylan's song lyrics have garnered well-deserved recognition and appreciation for their themes, content and artistic performances. Part-of-speech characteristics are effective in denoting stylistic features of texts in stylometric studies. The present study carried out a quantitative observation of stylistic features of Dylan's lyrics. Specifically, the study focuses on parts of speech like verbs, adjectives, adverbs, nouns and pronouns. Results of the present study reveal that: (1) Based on the distribution of verbs and adjectives, Dylan's lyrics are significantly active texts, and the activity sequences (Q-sequences) have validated the result in a dynamic way; (2) Dylan's lyrics tend to present the characteristics of a written body; (3) Individualism is prominent in Dylan's lyrics accompanied by the wide use of the first-person singular pronouns.","2024-10","2025-02-26 20:39:15","2025-02-26 20:39:15","","249-264","","2","18","","","","","","","","","","English","","","","WOS:001350094200004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","Bob Dylan; Busemann coefficient; GENRE; INDIVIDUALISM; LANGUAGE; lyrics; parts of speech; PRONOUN USE; stylometry","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MFUSUSKD","journalArticle","2022","Kadu, RK; Assudani, PJ; Bhojane, S; Agrawal, T; Siddhawar, V; Kale, Y","Voice Based Authentication System for Web Applications using Machine Learning","INTERNATIONAL JOURNAL OF NEXT-GENERATION COMPUTING","","2229-4678","","","Due to security concerns, the biometric trend is being used in many systems. Biometric authentication is a cheap, easy, and reliable technology for multi-factor authentication. Cryptosystems are one such example of using biometric data. However, this could be risky as biometric information is saved for authentication purposes. Therefore, voice biometric systems provide more efficient security and unique identity than commonly used biometric systems. Although, speech recognition-based authentication systems suffer from replay attacks. In this paper, we implement and analyze a text-independent voice-based biometric authentication system based on the randomly generated input text. Since the prompted text phrase is not known to the speaker in advance, it is difficult to launch replay attacks. The system uses Mel-Frequency Cepstrum Coefficients (MFCC) to extract speech features and Gaussian Mixture Models (GMM) for speaker modeling.","2022-11","2025-02-26 20:39:15","2025-02-26 20:39:15","","1312-1320","","5","13","","","","","","","","","","English","","","","WOS:000916967000048","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;9</p>","","","Authentication; Gaussian Mixture Model; Machine Learning; Voice; Voice Activity Detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AAZQ454S","journalArticle","2024","Rusko, M; Sabo, R; Trnka, M; Zimmermann, A; Malaschitz, R; Ruzicky, E; Brandoburová, P; Kevická, V; Skorvánek, M","Slovak database of speech affected by neurodegenerative diseases","SCIENTIFIC DATA","","2052-4463","10.1038/s41597-024-04171-6","","A new Slovak speech database EWA-DB was created for research purposes aimed at early detection of neurodegenerative diseases from speech. It contains 1649 speakers performing various speech and language tasks, such as sustained vowel phonation, diadochokinesis, naming and picture description. The sample of speakers consists of individuals with Alzheimer's disease, mild cognitive impairment, Parkinson's disease, and healthy controls. In this article we describe the EWA-DB development process, the language and speech task selection, patient and healthy control recruitment, as well as the testing and recording protocol. The structure and content of the database and file formats are described in detail. We assume that the presented database could be suitable for the development of automatic systems predicting the diagnoses of Alzheimer's disease, mild cognitive impairment, and Parkinson's disease from language and speech features.","2024-12-04","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","1","11","","","","","","","","","","English","","","","WOS:001370434100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;98</p>","","","ALZHEIMERS-DISEASE; DEMENTIA; DIAGNOSIS; MILD COGNITIVE IMPAIRMENT; NAMING TEST; PARKINSONS-DISEASE; RECOGNITION; RECOMMENDATIONS; SCREENING TOOL; VERB GENERATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9HF9BD7U","journalArticle","2023","de Boer, MM; Heeren, WFL","The language dependency of /m/ in native Dutch and non-native English","JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA","","0001-4966","10.1121/10.0021288","","In forensic speaker comparisons, the current practice is to try to avoid comparisons between speech fragments in different languages. However, globalization requires an exploration of individual speech features that may show phonetic consistency across a speaker's languages. We predicted that the bilabial nasal /m/ may be minimally affected by the language spoken due to the involvement of the rigid nasal cavity in combination with a lack of fixed oral articulatory targets. The results show that indeed, L1 Dutch speakers (N = 53) had similar nasal formants and formant bandwidths when speaking in their L2 English as in their native language, suggesting language-independency of /m/ within speakers. In fact, acoustics seemed to rely more on the phonetic context than on the language spoken. Nevertheless, caution should still be exercised when sampling across languages when the languages' phoneme inventories and phonotactics show substantial differences. (C) 2023 Acoustical Society of America.","2023-10","2025-02-26 20:39:15","2025-02-26 20:39:15","","2168-2176","","4","154","","","","","","","","","","English","","","","WOS:001082938600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","1ST-LANGUAGE; IDENTIFICATION; R PACKAGE; SPEAKERS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LAFMH22C","journalArticle","2024","Vattis, K; Oubre, B; Luddy, AC; Ouillon, JS; Eklund, NM; Stephen, CD; Schmahmann, JD; Nunes, AS; Gupta, AS","Sensitive Quantification of Cerebellar Speech Abnormalities Using Deep Learning Models","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3393243","","Objective, sensitive, and meaningful disease assessments are critical to support clinical trials and clinical care. Speech changes are one of the earliest and most evident manifestations of cerebellar ataxias. This work aims to develop models that can accurately identify and quantify clinical signs of ataxic speech. We use convolutional neural networks to capture the motor speech phenotype of cerebellar ataxia based on time and frequency partial derivatives of log-mel spectrogram representations of speech. We train classification models to distinguish patients with ataxia from healthy controls as well as regression models to estimate disease severity. Classification models were able to accurately distinguish healthy controls from individuals with ataxia, including ataxia participants who clinicians rated as having no detectable clinical deficits in speech. Regression models produced accurate estimates of disease severity, were able to measure subclinical signs of ataxia, and captured disease progression over time. Convolutional networks trained on time and frequency partial derivatives of the speech signal can detect sub-clinical speech changes in ataxias and sensitively measure disease change over time. Learned speech analysis models have the potential to aid early detection of disease signs in ataxias and provide sensitive, low-burden assessment tools in support of clinical trials and neurological care.","2024","2025-02-26 20:39:15","2025-02-26 20:39:15","","62328-62340","","","12","","","","","","","","","","English","","","","WOS:001216571200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Analytical models; Ataxia; ATAXIA RATING-SCALE; Cerebrum; Convolutional neural networks; deep learning; Deep learning; Diseases; FEATURES; Spectrogram; speech; Speech analysis; SPINOCEREBELLAR; Task analysis; Time-frequency analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RG6C423X","journalArticle","2022","Zolnoori, M; Vergez, S; Kostic, Z; Jonnalagadda, SR; McDonald, MV; Bowles, KKH; Topaz, M","Audio Recording Patient-Nurse Verbal Communications in Home Health Care Settings: Pilot Feasibility and Usability Study","JMIR HUMAN FACTORS","","2292-9495","10.2196/35325","","Background: Patients' spontaneous speech can act as a biomarker for identifying pathological entities, such as mental illness. Despite this potential, audio recording patients' spontaneous speech is not part of clinical workflows, and health care organizations often do not have dedicated policies regarding the audio recording of clinical encounters. No previous studies have investigated the best practical approach for integrating audio recording of patient-clinician encounters into clinical workflows, particularly in the home health care (HHC) setting. Objective: This study aimed to evaluate the functionality and usability of several audio-recording devices for the audio recording of patient-nurse verbal communications in the HHC settings and elicit HHC stakeholder (patients and nurses) perspectives about the facilitators of and barriers to integrating audio recordings into clinical workflows. Methods: This study was conducted at a large urban HHC agency located in New York, United States. We evaluated the usability and functionality of 7 audio-recording devices in a laboratory (controlled) setting. A total of 3 devices-Saramonic Blink500, Sony ICD-TX6, and Black Vox 365-were further evaluated in a clinical setting (patients'homes) by HHC nurses who completed the System Usability Scale questionnaire and participated in a short, structured interview to elicit feedback about each device. We also evaluated the accuracy of the automatic transcription of audio-recorded encounters for the 3 devices using the Amazon Web Service Transcribe. Word error rate was used to measure the accuracy of automated speech transcription. To understand the facilitators of and barriers to integrating audio recording of encounters into clinical workflows, we conducted semistructured interviews with 3 HHC nurses and 10 HHC patients. Thematic analysis was used to analyze the transcribed interviews. Results: Saramonic Blink500 received the best overall evaluation score. The System Usability Scale score and word error rate for Saramonic Blink500 were 65% and 26%, respectively, and nurses found it easier to approach patients using this device than with the other 2 devices. Overall, patients found the process of audio recording to be satisfactory and convenient, with minimal impact on their communication with nurses. Although, in general, nurses also found the process easy to learn and satisfactory, they suggested that the audio recording of HHC encounters can affect their communication patterns. In addition, nurses were not aware of the potential to use audio-recorded encounters to improve health care services. Nurses also indicated that they would need to involve their managers to determine how audio recordings could be integrated into their clinical workflows and for any ongoing use of audio recordings during patient care management. Conclusions: This study established the feasibility of audio recording HHC patient-nurse encounters. Training HHC nurses about the importance of the audio-recording process and the support of clinical managers are essential factors for successful implementation.","2022-04","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","2","9","","","","","","","","","","English","","","","WOS:000989770500024","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","audio recording; communications; device; HHC; nurse; patients; QUALITY; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LVZCTLL7","journalArticle","2024","Heo, S; Uhm, KE; Yuk, D; Kwon, BM; Yoo, B; Kim, J; Lee, J","Deep learning approach for dysphagia detection by syllable-based speech analysis with daily conversations","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-70774-z","","Dysphagia, a disorder affecting the ability to swallow, has a high prevalence among the older adults and can lead to serious health complications. Therefore, early detection of dysphagia is important. This study evaluated the effectiveness of a newly developed deep learning model that analyzes syllable-segmented data for diagnosing dysphagia, an aspect not addressed in prior studies. The audio data of daily conversations were collected from 16 patients with dysphagia and 24 controls. The presence of dysphagia was determined by videofluoroscopic swallowing study. The data were segmented into syllables using a speech-to-text model and analyzed with a convolutional neural network to perform binary classification between the dysphagia patients and control group. The proposed model in this study was assessed in two different aspects. Firstly, with syllable-segmented analysis, it demonstrated a diagnostic accuracy of 0.794 for dysphagia, a sensitivity of 0.901, a specificity of 0.687, a positive predictive value of 0.742, and a negative predictive value of 0.874. Secondly, at the individual level, it achieved an overall accuracy of 0.900 and area under the curve of 0.953. This research highlights the potential of deep learning modal as an early, non-invasive, and simple method for detecting dysphagia in everyday environments.","2024-08-31","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","1","14","","","","","","","","","","English","","","","WOS:001304007200022","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","Artificial intelligence; ASPIRATION; Conversations; Deep learning; Dysphagia; Speech-to-text model; Syllable-based speech analysis; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H8SJ8AMX","journalArticle","2023","Westergaard, M; Lohndal, T; Lundquist, B","Variable V2 in Norwegian heritage language An effect of crosslinguistic influence?","LINGUISTIC APPROACHES TO BILINGUALISM","","1879-9264","10.1075/lab.20076.wes","","This paper discusses possible attrition of verb second (V2) word order in Norwegian heritage language by investigating a corpus of spontaneous speech produced by 50 2nd-4th generation heritage speakers in North America. The study confirms previous findings that V2 word order is generally stable in heritage situations, but nevertheless finds approximately 10% V2 violations. The cases of non-V2 word order are argued to be due to lack of activation of the heritage language grammar, making it vulnerable to crosslinguistic influence from the speakers' dominant language. This crosslinguistic influence does not simply replace V2 by non-V2, but is argued to operate more indirectly, affecting (a) the distribution of contexts for V2 word order, and (b) introducing two new distinctions into the heritage language, one (indirectly) based on a similar distinction in the dominant language (a difference between adverbs and negation with respect to verb movement), the other based on frequency of initial elements triggering V2 in non-subject-initial declaratives. Together, these findings also indicate that crosslinguistic influence affects different contexts of V2 differently, providing support for analyses that treat V2 word order as the result of many smaller rules.","2023-03-23","2025-02-26 20:39:15","2025-02-26 20:39:15","","133-162","","2","13","","","","","","","","","","English","","","","WOS:000722901400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","2ND; attrition; crosslinguistic influence; DECLARATIVES; ENGLISH; INCOMPLETE ACQUISITION; processing; V3; verb movement; VERB PLACEMENT; word order; WORD-ORDER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LSXKFEZR","journalArticle","2021","Keator, LM; Yourganov, G; Basilakos, A; Hillis, AE; Hickok, G; Bonilha, L; Rorden, C; Fridriksson, J","Independent contributions of structural and functional connectivity: Evidence from a stroke model","NETWORK NEUROSCIENCE","","2472-1751","10.1162/netn_a_00207","","Altered functional connectivity is related to severity of language impairment in poststroke aphasia. However, it is not clear whether this finding specifically reflects loss of functional coherence, or more generally, is related to decreased structural connectivity due to cortical necrosis. The aim of the current study was to investigate this issue by factoring out structural connectivity from functional connectivity measures and then relating the residual data to language performance poststroke. Ninety-seven participants with a history of stroke were assessed using language impairment measures (Auditory Verbal Comprehension and Spontaneous Speech scores from the Western Aphasia Battery-Revised) and MRI (structural, diffusion tensor imaging, and resting-state functional connectivity). We analyzed the association between functional connectivity and language and controlled for multiple potential neuroanatomical confounders, namely structural connectivity. We identified functional connections within the left hemisphere ventral stream where decreased functional connectivity, independent of structural connectivity, was associated with speech comprehension impairment. These connections exist in frontotemporal and temporoparietal regions. Our results suggest poor speech comprehension in aphasia is at least partially caused by loss of cortical synchrony in a left hemisphere ventral stream network and is not only reflective of localized necrosis or structural connectivity.","2021-11-30","2025-02-26 20:39:15","2025-02-26 20:39:15","","911-928","","4","5","","","","","","","","","","English","","","","WOS:000731689000004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;78</p>","","","ALTERNATING-CURRENT STIMULATION; ANATOMY; Aphasia; BRAIN NETWORKS; DAMAGE; DEFICITS; DORSAL; Language; LANGUAGE; LESION ANALYSIS; PATHWAYS; RECOVERY; Resting-state functional connectivity; Stroke","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8GM24R9U","journalArticle","2025","Arimoto, Y; Horiuchi, Y; Ohno, S","Determining the base frequency of the F0 contour generation model for the diverse expression of speech","ACOUSTICAL SCIENCE AND TECHNOLOGY","","1346-3969","10.1250/ast.e24.05","","A reliable method of determining the base frequency (Fb) for utterances of various speaking styles is critical to enabling stable command labeling in the Fujisaki model. To achieve stable command labeling for diverse expressions of speech, a linear fitted model was developed using the ten percentile F0 of each utterance from three corpora of various speaking styles (read, acted, and spontaneous) as the independent variable to estimate a consistent Fb for each utterance. To assess the robustness of the model for unknown utterances, the model was applied to test data, including both open and corpus-open data not used for the model development, and the difference between the estimated Fb and the trained labelers' annotated Fb was calculated. As a result, the obtained estimation model was found to fit well to the manually labeled Fbs by exhibiting a small root mean squared error (RMSE) of 0.096 and a high coefficient of determination (R2) of 0.89 for the closed dataset. Moreover, the model also exhibited a small RMSE of 0.091 and a high R2 of 0.92 for the corpus-open dataset. The results revealed that the proposed model can reliably estimate the Fb of utterances with various speaking styles.","2025","2025-02-26 20:39:15","2025-02-26 20:39:15","","78-86","","1","46","","","","","","","","","","English","","","","WOS:001379809200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Acted emotional speech; Base frequency; PARAMETERS; Read speech; Spontaneous speech; The Fujisaki model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8J4KM25W","journalArticle","2022","Freixes, M; Socoró, JC; Alías, F","Contribution of Vocal Tract and Glottal Source Spectral Cues in the Generation of Acted Happy and Aggressive Spanish Vowels","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app12042055","","The source-filter model is one of the main techniques applied to speech analysis and synthesis. Recent advances in voice production by means of three-dimensional (3D) source-filter models have overcome several limitations of classic one-dimensional techniques. Despite the development of preliminary attempts to improve the expressiveness of 3D-generated voices, they are still far from achieving realistic results. Towards this goal, this work analyses the contribution of both the the vocal tract (VT) and the glottal source spectral (GSS) cues in the generation of happy and aggressive speech through a GlottDNN-based analysis-by-synthesis methodology. Paired neutral expressive utterances are parameterised to generate different combinations of expressive vowels, applying the target expressive GSS and/or VT cues on the neutral vowels after transplanting the expressive prosody on these utterances. The conducted objective tests focused on Spanish [a], and [u] vowels show that both GSS and VT cues significantly reduce the spectral distance to the expressive target. The results from the perceptual test show that VT cues make a statistically significant contribution in the expression of happy and aggressive emotions for [a] vowels, while the GSS contribution is significant in and [u] vowels.","2022-02","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","4","12","","","","","","","","","","English","","","","WOS:000764483100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","ACOUSTICS; EMOTION; emotional database; expressive speech synthesis; glottal source; GlottDNN; inverse filtering; MODEL; numerical voice production; PERCEPTION; QUALITY; SIMULATION; speech analysis; TO-SPEECH SYNTHESIS; vocal tract","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H88YTB6C","journalArticle","2021","Vitale, F; Carbonaro, B; Cordasco, G; Esposito, A; Marrone, S; Raimo, G; Verde, L","A Privacy-Oriented Approach for Depression Signs Detection Based on Speech Analysis","ELECTRONICS","","2079-9292","10.3390/electronics10232986","","Currently, AI-based assistive technologies, particularly those involving sensitive data, such as systems for detecting mental illness and emotional disorders, are full of confidentiality, integrity, and security compromises. In the aforesaid context, this work proposes an algorithm for detecting depressive states based on only three never utilized speech markers. This reduced number of markers offers a valuable protection of personal (sensitive) data by not allowing for the retrieval of the speaker's identity. The proposed speech markers are derived from the analysis of pitch variations measured in speech data obtained through a tale reading task performed by typical and depressed subjects. A sample of 22 subjects (11 depressed and 11 healthy, according to both psychiatric diagnosis and BDI classification) were involved. The reading wave files were listened to and split into a sequence of intervals, each lasting two seconds. For each subject's reading and each reading interval, the average pitch, the pitch variation (T), the average pitch variation (A), and the inversion percentage (also called the oscillation percentage O) were automatically computed. The values of the triplet (Ti, Ai, Oi) for the i-th subject provide, all together, a 100% correct discrimination between the speech produced by typical and depressed individuals, while requiring a very low computational cost and offering a valuable protection of personal data.","2021-12","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","23","10","","","","","","","","","","English","","","","WOS:000735672100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","human-computer interaction; speech recognition; statistical parametric speech analysis; TECHNOLOGIES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VJJA5CDC","journalArticle","2023","Aryal, D; Maruthy, S","Linguistic factors and stuttering in Nepali speaking adults who stutter","CLINICAL LINGUISTICS & PHONETICS","","0269-9206","10.1080/02699206.2022.2049880","","This study aimed to determine the effect of phonological and morphological factors on the dysfluencies of Nepali-speaking adults who stutter. Eighteen Nepali-speaking adult speakers with mild to very severe developmental stuttering were recruited. The spontaneous speech sample was audio-video recorded and transcribed through orthographic transcription. A total of 350 syllables were analysed to calculate stuttering frequency. Phoneme position, phoneme category, and word length were considered as the phonological factors and word-class as morphological factors. The percentage of stuttering for each of these variables was computed. The study's outcome displayed a significant effect of phoneme position and word length but no effect of phoneme category. Significantly greater stuttering was noticed in the word-initial position and longer words compared to word-medial and shorter words, respectively. In morphological factors, content words and content-function words had a greater stuttering rate than function words. This study showed a significant effect of phoneme position, word length, and grammatical class on the frequency of dysfluency in Nepali-speaking adults who stutter but no effect of phoneme category. The phonetic complexity of these variables may lead to an increase in motor planning demand resulting in more stuttering.","2023-03-04","2025-02-26 20:39:15","2025-02-26 20:39:15","","258-271","","3","37","","","","","","","","","","English","","","","WOS:000805285100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","adults who stutter; AGE; EXCHANGE; FREQUENCY; FUNCTION WORDS; GRAMMATICAL FACTORS; LENGTH; LOCI; morphology; PHONETIC INFLUENCES; phonology; SPEAKERS; SPEECH; Stuttering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RTBAHCBV","journalArticle","2022","Chapin, K; Clarke, N; Garrard, P; Hinzen, W","A finer-grained linguistic profile of Alzheimer's disease and Mild Cognitive Impairment","JOURNAL OF NEUROLINGUISTICS","","0911-6044","10.1016/j.jneuroling.2022.101069","","Linguistic measures in spontaneous speech have shown promise in the early detection of Alz-heimer's disease (AD), but it remains unknown which specific linguistic variables show sensitivity and how language decline relates to primary memory deficits. We hypothesized that a set of fine-grained linguistic variables relating specifically to forms of syntactic complexity involved in referencing objects and events as part of episodes would show sensitivity. We tested this in speech samples obtained from a picture description task, maximally isolating language deficits from the confound of episodic memory (EM) demands. 105 participants were split into Mild Cognitive Impairment (MCI), Mild-to-Moderate AD, and healthy controls (HC). Results showed that groups did not differ on generic linguistic variables such as number or length of utterances. However, AD relative to HC produced fewer embedded adjunct clauses, indefinite noun phrases, and Aspect marking, with moderate-to-large effect sizes. MCI compared to HC produced fewer adjunct clauses as well as fewer adverbial adjuncts. Together, these results confirm language impairment in AD and MCI at the level of specific linguistic variables relating to structures required for endowing narrative with specificity and episodic richness, independently of EM demands.","2022-08","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","63","","","","","","","","","","English","","","","WOS:000774228500008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;23<br/>Total Times Cited:&nbsp;&nbsp;23<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Alzheimer's disease; COMPREHENSION; CONNECTED SPEECH; DISCOURSE; EMBEDDED CLAUSES; EPISODIC MEMORY; Grammar; LANGUAGE; Memory; Reference; Specificity; Spontaneous connected speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4L5LT8SC","journalArticle","2021","Vukovic, T","Representing variation in a spoken corpus of an endangered dialect: the case of Torlak","LANGUAGE RESOURCES AND EVALUATION","","1574-020X","10.1007/s10579-020-09522-4","","The paper presents a spoken corpus of the endangered Torlak dialect from the Timok area of Southeast Serbia. This dialect expresses a great deal of variation in the use of non-standard features under the influence of standard Serbian (SSr). Accounting for this variation, a specific methodology has been selected for collection, sampling, transcription and annotation. Between 2015 and 2017, semi-structured interviews were conducted in the field eliciting spontaneous speech in the form of long narratives about traditional culture and history. The corpus comprises 500,697 tokens of semi-orthographic transcripts representing 80 h of recording from locations evenly distributed across the Timok area of the Torlak dialect zone, thus enabling a spatial contrastive analysis. The majority of speakers in the corpus are older people whose language represents the highly non-standard variety. In order to allow for analysis of language change under the influence of SSr, the corpus includes a number of younger people whose speech is closer to SSr. Tools for automatic PoS annotation and lemmatization that were lacking were developed based on the existing resources for SSr. For tagger training, a dialect sample of 27,000 manually verified tokens was merged with an existing training set for SSr.","2021-09","2025-02-26 20:39:15","2025-02-26 20:39:15","","731-756","","3","55","","","","","","","","","","English","","","","WOS:000606389500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Lemmatization; Manual annotation; Non-standard corpora; Part-of-speech annotation; Serbian; Spoken corpora; Torlak","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JZZV6H6Y","journalArticle","2024","Wieclawski, W; Bielski, K; Jani, M; Binder, M; Adamczyk, P","Dysconnectivity of the cerebellum and somatomotor network correlates with the severity of alogia in chronic schizophrenia","PSYCHIATRY RESEARCH-NEUROIMAGING","","0925-4927","10.1016/j.pscychresns.2024.111883","","Recent fMRI resting-state findings show aberrant functional connectivity within somatomotor network (SMN) in schizophrenia. Moreover, functional connectivity aberrations of the motor system are often reported to be related to the severity of psychotic symptoms. Thus, it is important to validate those findings and confirm their relationship with psychopathology. Therefore, we decided to take an entirely data-driven approach in our fMRI resting-state study of 30 chronic schizophrenia outpatients and 30 matched control subjects. We used independent component analysis (ICA), dual regression, and seed-based connectivity analysis. We found reduced functional connectivity within SMN in schizophrenia patients compared to controls and SMN hypoconnectivity with the cerebellum in schizophrenia patients. The latter was strongly correlated with the severity of alogia, one of the main psychotic symptoms, i.e. poverty of speech and reduction in spontaneous speech,. Our results are consistent with the recent knowledge about the role of the cerebellum in cognitive functioning and its abnormalities in psychiatric disorders, e.g. schizophrenia. In conclusion, the presented results, for the first time clearly showed the involvement of the cerebellum hypoconnectivity with SMN in the persistence and severity of alogia symptoms in schizophrenia.","2024-12","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","345","","","","","","","","","","English","","","","WOS:001309486700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","5-FACTOR MODEL; BRAIN; Cerebellum; fMRI; FUNCTIONAL CONNECTIVITY; LANGUAGE; Negative symptoms; NEGATIVE-SYNDROME-SCALE; Schizophrenia; Somatomotor network; SYMPTOMS; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RHPW6X7P","journalArticle","2022","Kouba, T; Illner, V; Rusz, J","Study protocol for using a smartphone application to investigate speech biomarkers of Parkinson's disease and other synucleinopathies: SMARTSPEECH","BMJ OPEN","","2044-6055","10.1136/bmjopen-2021-059871","","Introduction Early identification of Parkinson's disease (PD) in its prodromal stage has fundamental implications for the future development of neuroprotective therapies. However, no sufficiently accurate biomarkers of prodromal PD are currently available to facilitate early identification. The vocal assessment of patients with isolated rapid eye movement sleep behaviour disorder (iRBD) and PD appears to have intriguing potential as a diagnostic and progressive biomarker of PD and related synucleinopathies. Methods and analysis Speech patterns in the spontaneous speech of iRBD, early PD and control participants' voice calls will be collected from data acquired via a developed smartphone application over a period of 2 years. A significant increase in several aspects of PD-related speech disorders is expected, and is anticipated to reflect the underlying neurodegeneration processes. Ethics and dissemination The study has been approved by the Ethics Committee of the General University Hospital in Prague, Czech Republic and all the participants will provide written, informed consent prior to their inclusion in the research. The application satisfies the General Data Protection Regulation law requirements of the European Union. The study findings will be published in peer-reviewed journals and presented at international scientific conferences.","2022-06","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","6","12","","","","","","","","","","English","","","","WOS:000820407500004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Audiology; FEATURES; Parkinson-s disease; SLEEP BEHAVIOR DISORDER; Speech pathology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JSBZKASF","journalArticle","2022","Radha, K; Bansal, M","Audio Augmentation for Non-Native Children's Speech Recognition through Discriminative Learning","ENTROPY","","1099-4300","10.3390/e24101490","","Automatic speech recognition (ASR) in children is a rapidly evolving field, as children become more accustomed to interacting with virtual assistants, such as Amazon Echo, Cortana, and other smart speakers, and it has advanced the human-computer interaction in recent generations. Furthermore, non-native children are observed to exhibit a diverse range of reading errors during second language (L2) acquisition, such as lexical disfluency, hesitations, intra-word switching, and word repetitions, which are not yet addressed, resulting in ASR's struggle to recognize non-native children's speech. The main objective of this study is to develop a non-native children's speech recognition system on top of feature-space discriminative models, such as feature-space maximum mutual information (fMMI) and boosted feature-space maximum mutual information (fbMMI). Harnessing the collaborative power of speed perturbation-based data augmentation on the original children's speech corpora yields an effective performance. The corpus focuses on different speaking styles of children, together with read speech and spontaneous speech, in order to investigate the impact of non-native children's L2 speaking proficiency on speech recognition systems. The experiments revealed that feature-space MMI models with steadily increasing speed perturbation factors outperform traditional ASR baseline models.","2022-10","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","10","24","","","","","","","","","","English","","","","WOS:000872490400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","AUTOMATIC SPEECH; data augmentation; discriminative models; mutual information; non-native children speech recognition; SHARED TASK; speed perturbation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HR9XZ5IX","journalArticle","2021","Bóna, J; Kohári, A","Rate vs. rhythm characteristics of cluttering with data from a ?syllable-timed ? language","JOURNAL OF FLUENCY DISORDERS","","0094-730X","10.1016/j.jfludis.2020.105801","","Purpose: Cluttering is a type of fluency disorder characterized by a speech rate which is perceived to be fast and/or irregular as well as by an abnormal speech rhythm. As far as we know, no research has been conducted as yet using objective measurements and acoustic phonetic description on the rhythm of cluttered speech. The aim of this study is to show by objective measurements whether there are any differences between the rhythm of cluttered and control speech, and which parameters point to such differences. Methods: For the analysis, recordings of spontaneous speech samples were taken from people who clutter (PWC) as well as from control speakers. Typical speech rhythm values and articulation rate were calculated in each speech sample. Results: Results have confirmed that the rhythm of cluttering is slightly different from that of control speech in terms of various values, but the effect size is only small. It must be noted, however, that the difference between the two groups was not apparent in all analyzed values. Conclusion: The timing differences between cluttered and control speech are manifested primarily in the articulation rate while peculiarities in speech rhythm are almost negligible.","2021-03","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","67","","","","","","","","","","English","","","","WOS:000632320400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Articulation rate; Cluttering; DURATION; QUANTIFICATION; Speech rhythm; SPEECH RHYTHM; Syllable-timed language; VARIABILITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ITL58L72","journalArticle","2024","Nylen, F; Holmberg, J; Soedersten, M","Acoustic cues to femininity and masculinity in spontaneous speech","JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA","","0001-4966","10.1121/10.0025932","","The perceived level of femininity and masculinity is a prominent property by which a speaker's voice is indexed, and a vocal expression incongruent with the speaker's gender identity can greatly contribute to gender dysphoria. Our understanding of the acoustic cues to the levels of masculinity and femininity perceived by listeners in voices is not well developed, and an increased understanding of them would benefit communication of therapy goals and evaluation in gender-affirming voice training. We developed a voice bank with 132 voices with a range of levels of femininity and masculinity expressed in the voice, as rated by 121 listeners in independent, individually randomized perceptual evaluations. Acoustic models were developed from measures identified as markers of femininity or masculinity in the literature using penalized regression and tenfold cross-validation procedures. The 223 most important acoustic cues explained 89% and 87% of the variance in the perceived level of femininity and masculinity in the evaluation set, respectively. The median fo was confirmed to provide the primary cue, but other acoustic properties must be considered in accurate models of femininity and masculinity perception. The developed models are proposed to afford communication and evaluation of gender-affirming voice training goals and improve voice synthesis efforts.","2024-05","2025-02-26 20:39:15","2025-02-26 20:39:15","","3090-3100","","5","155","","","","","","","","","","English","","","","WOS:001215860700004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","COMPUTERS; FEMALE; FUNDAMENTAL-FREQUENCY; GUIDELINES; HARMONICS; INTONATION; LISTENER PERCEPTIONS; SPEAKER GENDER; TRANSGENDER; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NKZALZT8","journalArticle","2023","Face, TL","Production of Acoustic Correlates of Stress by L2 Spanish-Speaking Immigrants to Spain","LANGUAGES","","2226-471X","10.3390/languages8040258","","Little work has examined the L2 acquisition of Spanish stress, and especially the production of its acoustic correlates, and the work that has is largely limited to inexperienced learners. This study examines the production of stress by L1 English/L2 Spanish speakers who are highly experienced with their L2, having lived much of their adult lives as immigrants in Spain. Data were collected from the reading of a short story, an extended reading with a plot was provided so that participants would not be focused on their pronunciation, thus producing speech closer to spontaneous speech while still allowing for control over what they produced. Intensity, duration, pitch and deaccenting were examined and the results from the L2 learners were compared to a control group of native speakers from Spain who performed the same task. While only one L2 learner's stress production could be classified as completely native-like, as a group, their stress production approximated native speaker norms to a greater degree than has been found for most other aspects of L2 Spanish pronunciation in previous research. Nonetheless, L2 learners seemed to transfer duration patterns from their L1 into their L2 Spanish and also deaccented stressed syllables nearly twice as often as native speakers.","2023-12","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","4","8","","","","","","","","","","English","","","","WOS:001131172300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","deaccenting; duration; immigrants; intensity; phonology; pitch; second language acquisition; Spanish; stress; ULTIMATE ATTAINMENT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"86LXUWV6","journalArticle","2021","Wilmoth, S; Defina, R; Loakes, D","They Talk Muu: Variable Elision of Tense Suffixes in Contemporary Pitjantjatjara","LANGUAGES","","2226-471X","10.3390/languages6020069","","Vowel elision is common in Pitjantjatjara and Yankunytjatjara connected speech. It also appears to be a locus of language change, with young people extending elision to new contexts; resulting in a distinctive style of speech which speakers refer to as mu ('short' speech). This study examines the productions of utterance-final past tense suffixes /-nu, - -LATIN SMALL LETTER ENGu/ by four older and four younger Pitjantjatjara speakers in spontaneous speech. This is a context where elision tends not to be sociolinguistically or perceptually salient. We find extensive variance within and between speakers in the realization of both the vowel and nasal segments. We also find evidence of a change in progress, with a mixed effects model showing that among the older speakers, elision is associated with both the place of articulation of the nasal segment and the metrical structure of the verbal stem, while among the younger speakers, elision is associated with place of articulation but metrical structure plays little role. This is in line with a reanalysis of the conditions for elision by younger speakers based on the variability present in the speech of older people. Such a reanalysis would also account for many of the sociolinguistically marked extended contexts of elision.","2021-06","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","2","6","","","","","","","","","","English","","","","WOS:000639430400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Australian languages; elision; NASAL; sound change; STOP; variation and change","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SZ65N89K","journalArticle","2023","Boye, K; Bastiaanse, R; Harder, P; Martínez-Ferreiro, S","Agrammatism in a usage-based theory of grammatical status: Impaired combinatorics, compensatory prioritization, or both?","JOURNAL OF NEUROLINGUISTICS","","0911-6044","10.1016/j.jneuroling.2022.101108","","This paper proposes an understanding of agrammatism from the perspective of a recent usagebased theory of grammatical status, the ProGram theory (Boye and Harder, 2012). According to this theory, grammatical elements have two central properties: they are by convention discursively secondary (i.e. attentional background) and dependent on combination with a host item. The paper first surveys studies of agrammatic speech which, based on or reconsidered in relation to the above-mentioned criteria, show that the usage-based theory makes correct predictions about the behaviour of linguistic elements in agrammatic speech. Subsequently, the paper outlines and discusses two hypotheses about the mechanism behind agrammatism that can be derived from each of the two central properties of grammatical items. According to the prominence hypothesis, agrammatism is due to insufficient overall processing resources; this leads to a prioritization of lexical over grammatical expressions because the latter, being discursively secondary, can be dispensed with for communicative purposes. According to the dependence hypothesis, agrammatism results from an impaired capacity for combining or unifying simple elements into complex wholes: This impairment affects grammatical elements in particular, because these are dependent on (combination with) host items.","2023-02","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","65","","","","","","","","","","English","","","","WOS:000880410400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;109</p>","","","Agrammatism; Attention; AVAILABILITY; COMPLEXITY; COMPREHENSION; Discourse prominence; Grammar; ORGANIZATION; PREPOSITIONS; PRIMARY PROGRESSIVE APHASIA; SENTENCE PRODUCTION; SPONTANEOUS SPEECH; TENSE; Usage -based; VERBS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QWSLD6UH","journalArticle","2022","Szeteli, A; Gocsal, A; Szente, G; Alberti, G","Differentiation of segmentally identical expressions occurring in the same or different sentence zones in Hungarian by duration, pitch, intensity and irregular voicing","ACTA LINGUISTICA ACADEMICA","","2559-8201","10.1556/2062.2022.00535","","The paper presents the interpretation and explanation of the findings of two pieces of experimental research within the framework of Varga's (2016) pitch-tier model of the Hungarian declarative sentence. One of the experiments was established to investigate the information-structural contribution of quantified expressions (such as mindharom baratom 'all three of my friends' and Csaba is 'Csaba also'). The other experiment explored the acoustic features of the spontaneous-speech specific discourse marker hat 'well/so'. The two topics can be regarded as interconnected if Varga's model is interpreted in the strong sense that pitch presumably in a more or less strong correlation with intensity is responsible for indicating the topic-comment dichotomy and other factors of the discourse-embedding of sentences. Thus, the reconciliation of our data with Varga's model requires the consideration of the pitch-tier substructures in their complex dynamism. The experiments support the plausible hypothesis that the variants of the discourse marker hat as part of the preparatory contour primarily differ in duration, while is-quantifiers in different pitch-tier parts differ in terms of pitch values.","2022-06","2025-02-26 20:39:15","2025-02-26 20:39:15","","163-187","","2","69","","","","","","","","","","English","","","","WOS:000815039900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","duration; FOCUS; intensity; pitch tier; quantifiers and discourse markers in Hungarian; topic-comment dimension","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E8BBE6G2","journalArticle","2025","Eaton, CT; Thomas, S; Jones, D; Carnaby, G","How about that? Psycholinguistic characteristics of formulaic language that predict fluency in individuals with post-stroke aphasia","APHASIOLOGY","","0268-7038","10.1080/02687038.2025.2451659","","PurposeFormulaic language is an under-explored area of research in the field of acquired language disorders as compared to propositional language. The primary purpose of this study was to explore the utility of a proposed theoretical formulaic language model (Van Lancker Sidtis, 2022) for individuals with post-stroke aphasia to inform research and clinical practice.MethodThe dataset included previously described formulaic language extracted from Aphasiabank speech samples produced by 144 individuals with fluent and non-fluent aphasias. Formulaic language items were coded according to six psycholinguistic characteristics from the theoretical model. Between-group comparisons and regression analyses were run to determine whether particular psycholinguistic characteristics of produced formulaic items could predict speaker fluency.ResultsFindings revealed formulaic language differences between fluent and nonfluent aphasias based on the theoretical model. Importantly, psycholinguistic characteristics of frequency and syntactic completeness along with presence of apraxia of speech predicted fluency status with high accuracy (88.4% of individuals with fluent and 70.3% with nonfluent aphasia).ConclusionsFindings in this study illustrate how theoretically-driven analyses of formulaic language production may enhance diagnostic and intervention practices in post-stroke aphasia.","2025-01-24","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","","","","","","","","","","","English","","","","WOS:001402393100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","ALZHEIMERS-DISEASE; ENGLISH; EXPRESSIONS; Formulaic language; FREQUENCY; post-stroke aphasia; SEQUENCES; spontaneous language; SPONTANEOUS SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C2RVWNT6","journalArticle","2023","Hao, YX; Jin, ZH; Yang, QH; Wang, XL; Liu, HT","To predict L2 writing quality using lexical richness indices: An investigation of learners of Chinese as a Foreign Language","SYSTEM","","0346-251X","10.1016/j.system.2023.103123","","The majority of current lexical richness indices are based on Indo-European languages, especially English, with a lack of research that investigates their applicability to diverse language types. This study examines the applicability of 44 lexical richness indices, based on Indo-European languages, to Chinese, with a specific emphasis on investigating their predictive power for the writing quality of Chinese as a Foreign Language (CFL) learners. The present study reveals that five indices (Number of Different Words, Uber Index, Corrected Verb Variation1, Lexical Frequency Profile, and Verb Sophistication1) assessing English as a second language (L2) can also effectively predict the writing quality of CFL learners, and six indices (Verb Variation, Verb Variation1, Function Words Ratio_ auxiliary, Function Words Ratio_ pronoun, Lexical Density1, and Lexical Density2) may be more suitable for measuring Chinese, but not English. Moreover, transformed indices demonstrate a better capacity to measure L2 Chinese compared to traditional indices. In conducting a preliminary exploration of effective indices for measuring the lexical richness of Chinese interlanguage, this study emphasizes their potential impact on L2 teaching and suggests directions for future research.","2023-11","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","118","","","","","","","","","","English","","","","WOS:001072073900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;91</p>","","","DIVERSITY; FEATURES; Learners of Chinese as a foreign language; Lexical diversity; Lexical richness; Lexical sophistication; SPONTANEOUS SPEECH; STUDENTS; VOCABULARY; Writing quality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RR36SN7P","journalArticle","2023","Tendera, A; Rispoli, M; Sethilselvan, A; Chon, H; Loucks, TM","It's Mine, . . . It's Mine: Unsolicited Repetitions Are Reduced in Toddlers","LANGUAGE AND SPEECH","","0023-8309","10.1177/00238309221119185","","A phenomenon called ""repetition reduction"" can increase articulation rate in adults by facilitating phonetic and motor processes, which indicates flexibility in the control of articulation rate. Young children, who speak much slower, may not have the same speech motor flexibility resulting in the absence of the repetition reduction effect. In this study, we tested whether spontaneous repetitions of young children are produced with a faster articulation rate than their original utterances. Twelve monolingual English-speaking children were observed at four time points between 2;0 and 3;0 years of age. A significant increase in articulation rate and syllable count was found using multilevel models for all utterances over the 1-year period. At each time point, however, the repeated utterances were produced significantly faster than the original utterances even though the content and syllable count differed minimally. Our findings conform to the pattern of adult studies suggesting that a ""naturistic"" form of repetition reduction is already present in the speech of children at 2;0 years. Although certain aspects of speech motor control are undergoing rapid development, existing motor capability at 2;0 already supports flexible changes in articulation rate including repetition reduction.","2023-09","2025-02-26 20:39:15","2025-02-26 20:39:15","","734-755","","3","66","","","","","","","","","","English","","","","WOS:000858356000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","Articulation rate; ARTICULATION RATE; BETWEEN-SPEAKER; development; INTERSPEAKER VARIATION; LANGUAGE; LEXICAL REPETITION; PRESCHOOL-CHILDREN; repetition reduction; speech; SPONTANEOUS SPEECH; WITHIN-SPEAKER VARIATION; WORD DURATION; YOUNG","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6F9UTSQS","journalArticle","2021","Auer, P; Siegel, V","Grammatical Gender in the German Multiethnolect","JOURNAL OF GERMANIC LINGUISTICS","","1470-5427","10.1017/S1470542720000082","","While major restructurings and simplifications have been reported for gender systems of other Germanic languages in multiethnolectal speech, this article demonstrates that the three-way gender distinction of German is relatively stable among young speakers from an immigrant background. We investigate gender in a German multiethnolect based on a corpus of approximately 17 hours of spontaneous speech produced by 28 young speakers in Stuttgart (mainly from Turkish and Balkan background). German is not their second language, but (one of) their first language(s), which they have fully acquired from childhood. We show that the gender system does not show signs of reduction in the direction of a two-gender system, nor of wholesale loss. We also argue that the position of gender in the grammar is weakened by independent innovations, such as the frequent use of bare nouns in grammatical contexts where German requires a determiner. Another phenomenon that weakens the position of gender is the simplification of adjective-noun agreement and the emergence of a generalized gender-neutral suffix for prenominal adjectives (that is, schwa). The disappearance of gender and case marking in the adjective means that the grammatical category of gender is lost in Adj + N phrases (without a determiner).","2021-03","2025-02-26 20:39:15","2025-02-26 20:39:15","","5-29","","1","33","","","","","","","","","","English","","","","WOS:000616646100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","ACQUISITION; bare nouns; DUTCH; gender agreement in German; gender loss in German; multiethnolect","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BMQ2K3QW","journalArticle","2022","Arnett, S; Mozeiko, J","Evaluating the Accuracy of Self-Ratings of Language in Adults with Aphasia and Non-Brain Injured Adults: A Pilot Study","SEMINARS IN SPEECH AND LANGUAGE","","0734-0478","10.1055/s-0042-1749432","","Rating scales are frequently used in research and clinical practice with people with aphasia (PWA) to characterize communication in the home environment. However, it remains unclear whether responses provided on rating scales accurately reflect the communication that occurs. We aim to evaluate the accuracy of PWA's self-perceptions of verbal language use as measured by a rating scale and determine whether this accuracy is different from that of non-brain-injured (NBI) participants. Four PWA and four NBI participants completed a rating scale estimating their amount of verbal language production as compared with their communication partner. Audio recordings from participants' home environments were analyzed for proportion of words and conversational turns contributed by the participant, which were compared with rating scale estimates. Perceptions of verbal language output among both PWA and NBI participants showed variable accuracy, with discrepancies between estimates and objective data across both groups. The reliability of rating scales in quantifying language output appears questionable, suggesting they may not accurately represent naturalistic language environments of PWA. Additional research with larger sample sizes is warranted to investigate whether this trend is consistent across a larger population of individuals with aphasia.","2022-11","2025-02-26 20:39:15","2025-02-26 20:39:15","","378-390","","05","43","","","","","","","","","","English","","","","WOS:000826451400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","aphasia; EFFICIENCY; FUNCTIONAL COMMUNICATION; home environment; INFORMATIVENESS; PEOPLE; rating scales; self-perception; SPONTANEOUS SPEECH; STROKE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ECYL6N4F","journalArticle","2021","Cohn, AC; Renwick, MEL","Embracing multidimensionality in phonological analysis","LINGUISTIC REVIEW","","0167-6318","10.1515/tlr-2021-2060","","We pursue the idea, implicit in much current phonological research, that understanding the multiple factors that shape speech production and perception is within the purview of phonology. In particular, increased access to naturalistic data has highlighted the multidimensional reality of variation in spoken language. At the same time, longstanding methods of doing phonology including impressionistic analysis, and laboratory and experimental studies remain crucial to understanding native speaker competence and grammar. We advocate for an expanded methodological toolbox in phonological analysis, using an iterative approach that crucially includes naturalistic corpus data. Integrating across multiple data sources offers fuller insight into the nature of the phonological system and native speaker-hearer ability. Several case studies highlight findings gained through linked, iterative studies, showing the importance of naturalistic data for a richer understanding of phonological phenomena, and leading us to reflect on desiderata for corpora to reveal speaker-specific patterns in fine phonetic detail and variability, which we argue are part of a speaker-hearer's phonological competence. Phonological analysis that embraces the full spectrum of variation in spoken language data (from categorical to gradient, and systematic to sporadic) contributes to a deeper understanding of phonology in this richer sense.","2021-02","2025-02-26 20:39:15","2025-02-26 20:39:15","","101-139","","1","38","","","","","","","","","","English","","","","WOS:000629283300005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;127</p>","","","ABSTRACTIONS; EXEMPLARS; FUNCTIONAL LOAD; laboratory phonology; linguistic corpora; linguistic variation; naturalistic data; PERCEPTION; phonetics; PHONETICS; phonological analysis; SPONTANEOUS SPEECH; USAGE; VARIABILITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KWXP8HMZ","journalArticle","2024","Bircan, BB; Kara, I; Kayikci, MEK","Syllable- and word-based measures of stuttering in speech samples of Turkish-speaking school-aged children","CLINICAL LINGUISTICS & PHONETICS","","0269-9206","10.1080/02699206.2023.2186764","","Linguistic factors influence the likelihood of occurrence of stuttering instances on a certain word within an utterance. However, studies on the relationship between stuttering instances and linguistic factors of Turkish-speaking individuals are scarce. This study aimed to determine the syllable- and word-based measures of stuttering speech samples of Turkish-speaking school-aged children who stutter. Stuttering-like disfluencies (SLDs) and lexical categories were identified after transcription of 61 children's spontaneous speech samples (age range = 6-16). Syllable-, word- and utterance-level measures were employed. Syllable-based and word-based stuttering frequency findings were significantly different (p < .001); SLDs were more likely to occur at the utterance-initial (p < .001) and word-initial (p < .001) positions; content words were more likely to be stuttered and, there was a relation between the occurrence of SLDs and utterance length (p = .001). Since there is great variability between word-based and syllable-based measures, and SLDs tend to occur at word onsets, using word-based measures in Turkish would provide a measure of stuttering frequency that is comparable to the literature. Moreover, findings support that phrases requiring greater demands on utterance planning increase the possibility of occurrence of stuttering instances.","2024-03-03","2025-02-26 20:39:15","2025-02-26 20:39:15","","185-202","","3","38","","","","","","","","","","English","","","","WOS:000946596200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","COMPLEXITY; DIFFICULTY; DISFLUENCIES; LENGTH; lexical class; PRESCHOOL-CHILDREN; school-aged children; Stuttering; utterance position; word position","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P4UFEFWR","journalArticle","2021","Alam, F; Ramírez, L; Migdalek, M","Other children's words in the linguistic environment of infants and young children from distinct social groups in Argentina (Las palabras de otros ninos en el entorno linguistico de bebes y ninos pequenos de distintos grupos sociales de Argentina)","JOURNAL FOR THE STUDY OF EDUCATION AND DEVELOPMENT","","0210-3702","10.1080/02103702.2021.1888489","","This present research analyses the linguistic environmental setting in homes of children under the age of two years from different social groups and looks at the extent to which the speech from other children contributes to shaping that environment. The corpus includes recordings of spontaneous speech from middle-class households in residential urban areas, from lower socioeconomic classes in marginalized urban areas and from impoverished semi-rural areas. Beta regressions were used to estimate whether place of residence could explain the proportion of words from other children that were directed, as well as those that were not directed, towards the child under study. The results showed that children from impoverished semi-rural areas and children from residential areas hear a higher proportion of non-directed words than children from marginalized urban areas. However, when child-directed speech is considered, the two lower socioeconomic groups, urban and semi-rural, hear a higher proportion of words than their residential peers. These results reveal heterogeneity within social groups.","2021-04-03","2025-02-26 20:39:15","2025-02-26 20:39:15","","269-302","","2","44","","","","","","","","","","English","","","","WOS:000639740400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","child-directed and non-child directed speech; intragroup differences; linguistic environment; socioeconomic differences; young children","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z8Z5Q4RN","journalArticle","2023","Castilla-Earls, A; Ronderos, J; Fitton, L","Spanish Bilingual Morphosyntactic Development in Bilingual Children With and Without Developmental Language Disorder: Articles, Clitics, Verbs, and the Subjunctive Mood","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2023_JSLHR-23-00091","","Purpose: The purpose of this study was to examine the growth of previously established clinical markers of developmental language disorder (DLD) in Spanish-speaking bilingual children with and without DLD. Method: Forty-three bilingual children with DLD and 57 typically developing children were tested 3 times over a 2-year period. Their average age at Time 1 was 5;10 (years;months). All children completed an elicitation task examining the production of articles, clitics, verbs, and the subjunctive mood in Spanish at each time point, in addition to other behavioral testing in Spanish and English. We used growth curve analysis to examine change patterns of the morphosyn-tactic structures over time. Results: At the onset of the study, children without DLD produced higher accuracy rates than children with DLD across all morphosyntactic structures. In addition, there was a positive effect of time on all structures. Furthermore, the interaction between time and DLD was statistically significant for clitic pronouns. Conclusion: In agreement with previous literature on language growth in mono-lingual children with DLD, bilingual children with DLD showed language growth that was parallel to that of bilingual children without DLD but with significantly lower levels of attainment.","2023-12","2025-02-26 20:39:15","2025-02-26 20:39:15","","4678-4698","","12","66","","","","","","","","","","English","","","","WOS:001146666600018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","ACQUISITION; AGREEMENT; ENGLISH; GROWTH; IMPAIRMENT; MEAN LENGTH; MORPHOLOGY; PRESCHOOL-CHILDREN; SPEAKING CHILDREN; SPONTANEOUS SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2AX7H4FT","journalArticle","2024","Goh, E; Wu, HC","Code-switching in computer-mediated communication by Gen Z Japanese Americans","LINGUISTICS VANGUARD","","2199-174X","10.1515/lingvan-2024-0031","","This study, as one of the first in its kind, focuses on code-switching in computer-mediated communication (CMC) among Gen Z Japanese Americans who have been simultaneous bilinguals since childhood. We collected a dataset of 1,561 online text messages that were exchanged between these bilinguals and found intriguing code-switching patterns not typically observed in spontaneous speech nor reported in the literature. First, we find a surprisingly high portion of Japanese usage in the dataset and noticed high occurrences of Japanese auxiliary verbs and low occurrences of Japanese pronouns compared to the English counterparts. The data suggests these bilinguals have a strong grasp of both languages and are actively code-switching to construct their bilingual and bicultural identity over text. Second, our data shows that preferences for a type of code-switching (intra-sentential or inter-sentential) when texting friends are not a reflection of language proficiency or constraints of the CMC medium, but rather reflect the frequency with which the speakers orally code-switch and speak the embedded language at home. Moreover, we observe the speakers' development of a CMC style of Japanese-English code-switching through using romanized Japanese words, elongating Japanese words using romanization, mixing writing scripts, and writing English words in Japanese characters.","2024-12-31","2025-02-26 20:39:15","2025-02-26 20:39:15","","615-628","","1","10","","","","","","","","","","English","","","","WOS:001383229000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","bilingualism; CMC style; Japanese-English; text messages; writing systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"43CEAG2I","journalArticle","2024","Wehrle, S; Grice, M; Vogeley, K","Filled Pauses Produced by Autistic Adults Differ in Prosodic Realisation, but not Rate or Lexical Type","JOURNAL OF AUTISM AND DEVELOPMENTAL DISORDERS","","0162-3257","10.1007/s10803-023-06000-y","","We examined the use of filled pauses in conversations between homogeneous pairs of autistic and non-autistic adults. A corpus of semi-spontaneous speech was used to analyse the rate, lexical type (nasal ""uhm"" or non-nasal ""uh""), and prosodic realisation (rising, level or falling) of filled pauses. We used Bayesian modelling for statistical analysis. We found an identical rate of filled pauses and an equivalent preference of ""uhm"" over ""uh"" across groups, but also a robust group-level difference regarding the intonational realisation of filled pauses: non-autistic controls produced a considerably higher proportion of filled pause tokens realised with the canonical level pitch contour than autistic speakers. Despite the fact that filled pauses are a frequent and impactful part of speech, previous work on their conversational use in autism spectrum disorder (ASD) is limited. Our account is the first to analyse the intonational realisation of filled pauses in ASD and the first to investigate conversations between autistic adults in this context. Our results on rate and lexical type can help to contextualise previous research, while the novel findings on intonational realisation set the stage for future investigations.","2024-07","2025-02-26 20:39:15","2025-02-26 20:39:15","","2513-2525","","7","54","","","","","","","","","","English","","","","WOS:000980853300002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;106</p>","","","ADOLESCENTS; Autism spectrum disorder; BIAS; Conversation; DECLINATION; DISORDERS; Filled pause; FREQUENCY; Hesitation; HESITATION; Prosody; SPECTRUM QUOTIENT AQ; SPEECH; UH; UM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DZ5XXMNV","journalArticle","2024","Miao, YZ; Rose, H; Hosseini, S","The Interaction Effect of Pronunciation and Lexicogrammar on Comprehensibility: A Case of Mandarin-Accented English","LANGUAGE AND SPEECH","","0023-8309","10.1177/00238309231156918","","Scholars have argued that comprehensibility (i.e., ease of understanding), not nativelike performance, should be prioritized in second language learning, which inspired numerous studies to explore factors affecting comprehensibility. However, most of these studies did not consider potential interaction effects of these factors, resulting in a limited understanding of comprehensibility and less precise implications. This study investigates how pronunciation and lexicogrammar influences the comprehensibility of Mandarin-accented English. A total of 687 listeners were randomly allocated into six groups and rated (a) one baseline and (b) one of six experimental recordings for comprehensibility on a 9-point scale. The baseline recording, a 60 s spontaneous speech by an L1 English speaker with an American accent, was the same across groups. The six 75-s experimental recordings were the same in content but differed in (a) speakers' degree of foreign accent (American, moderate Mandarin, and heavy Mandarin) and (b) lexicogrammar (with errors vs. without errors). The study found that pronunciation and lexicogrammar interacted to influence comprehensibility. That is, whether pronunciation affected comprehensibility depended on speakers' lexicogrammar, and vice versa. The results have implications for theory-building to refine comprehensibility, as well as for pedagogy and testing priorities.","2024-03","2025-02-26 20:39:15","2025-02-26 20:39:15","","3-18","","1","67","","","","","","","","","","English","","","","WOS:000943427000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Comprehensibility; FLUENCY; FOREIGN ACCENT; INTELLIGIBILITY; LISTENER; listening; speaking; SPEECH; speech perception","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"94HWMF32","journalArticle","2023","Atak, A","Exploring the sentiment in Borsa Istanbul with deep learning","BORSA ISTANBUL REVIEW","","2214-8450","10.1016/j.bir.2023.12.010","","Sentiment analysis holds immense importance in finance and economics, addressing crucial issues such as principal-agent dynamics and information imbalances. The rise of natural language processing signifies a groundbreaking era in sentiment analysis, enabling the effective extraction of insights from textual data. Our research investigates the impact of qualitative financial data on firm valuation, utilizing sentiment extracted from annual financial disclosures, focusing on companies listed on the Borsa Istanbul Stock Exchange from 1998 to 2022. Employing a pre-trained transformer model, we develop sentiment indices and integrate textual data using a system-generalized method of moments. Our study aims to uncover how sentiment expressed in financial disclosures aids in mitigating challenges related to asymmetric information.","2023-12","2025-02-26 20:39:15","2025-02-26 20:39:15","","S84-S95","","","23","","","","","","","","","","English","","","","WOS:001154222500009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Asymmetric information; CORPORATE DISCLOSURE; COST; Emerging market; Endogeneity; Financial disclosure; FinBERT; FinRoBERTa; GMM; INFORMATION; INVESTOR SENTIMENT; MARKET; NLP; PANEL-DATA; RETURNS; Sentiment; Tone","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9Z6D4D5P","journalArticle","2023","Shetty, A; Kale, Y; Patil, Y; Patil, R; Sharma, S","Optimal transformers based image captioning using beam search","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-023-17359-6","","Image Captioning is the process of generating textual descriptions of given images. It encompasses two major fields of deep learning, computer vision, and natural language processing. This paper presents an Image Captioning model which uses the Convolution Neural Network (CNN) model for feature extraction and a transformer architecture for the generation of sequences from these feature vectors. For feature extraction, this paper uses different CNN architectures like Xception, InceptionV3, ResNet50V2, VGG19, DenseNet201, ResNet152V2, EfficientNetV2B3, EfficientNetV2B0. The proposed method takes advantage of the transformer model for faster processing, and Beam search is implemented to get the top N most probable sequences for each image. The architecture is trained on Flickr8k dataset and the model outperforms the existing methods. The proposed model achieves a BLEU_4 score of 0.2184 on the Flickr8k dataset.","2023-10-31","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","","","","","","","","","","","English","","","","WOS:001090305500011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Attention; Computer vision; Deep learning; Image captioning; Sequence models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HWSCV33C","journalArticle","2023","Sang, YN; Chen, Y; Zhang, JW","Neural Machine Translation Research on Syntactic Information Fusion Based on the Field of Electrical Engineering","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app132312905","","Neural machine translation has achieved good translation results, but needs further improvement in low-resource and domain-specific translation. To this end, the paper proposed to incorporate source language syntactic information into neural machine translation models. Two novel approaches, namely Contrastive Language-Image Pre-training(CLIP) and Cross-attention Fusion (CAF), were compared to a base transformer model on EN-ZH and ZH-EN pair machine translation focusing on the electrical engineering domain. In addition, an ablation study on the effect of both proposed methods was presented. Among them, the CLIP pre-training method improved significantly compared with the baseline system, and the BLEU values in the EN-ZH and ZH-EN tasks increased by 3.37 and 3.18 percentage points, respectively.","2023-12","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","23","13","","","","","","","","","","English","","","","WOS:001116656200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","graph neural network; neural machine translation; syntax parsing tree; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MVI7ZHJQ","journalArticle","2022","Peng, ZY; Guo, PC","A Data Organization Method for LSTM and Transformer When Predicting Chinese Banking Stock Prices","DISCRETE DYNAMICS IN NATURE AND SOCIETY","","1026-0226","10.1155/2022/7119678","","The accurate prediction of stock prices is not an easy task.The long short-term memory (LSTM) neural network and the transformer are good machine learning models for times series forecasting. In this paper, we use LSTM and transformer to predict prices of banking stocks in China's A-share market. It is shown that organizing the input data can help get accurate outcomes of the models. In this paper, we first introduce some basic knowledge about LSTM and present prediction results using a standard LSTM model.Then, we show how to organize the input data during the training period and give the comparison results for not only LSTM but also the transformer model.The numerical results show that the prediction results of LSTM and transformer can be improved after the input data are organized when training.","2022-01-04","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","2022","","","","","","","","","","English","","","","WOS:000790337200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FGXC7G3P","journalArticle","2024","Zerbian, S; Zuban, Y; Klotz, M","Intonational Features of Spontaneous Narrations in Monolingual and Heritage Russian in the US-An Exploration of the RUEG Corpus","LANGUAGES","","2226-471X","10.3390/languages9010002","","This article presents RuPro, a new corpus resource of prosodically annotated speech by Russian heritage speakers in the U.S. and monolingually raised Russian speakers. The corpus contains data elicited in formal and informal communicative situations, by male/female and adolescent/adult speakers. The resource is presented with its architecture and annotation, and it is shown how it is used for the analysis of intonational features of spontaneous mono- and bilingual Russian speech. The analyses investigate the length of intonation phrases, types and number of pitch accents, and boundary tones. It emerges that the speaker groups do not differ in the inventory of pitch accents and boundary tones or in the relative frequency of these tonal events. However, they do differ in the length of intonation phrases (IPs), with heritage speakers showing shorter IPs also in the informal communicative situation. Both groups also differ concerning the number of pitch accents used on content words, with heritage speakers using more pitch accents than monolingually raised speakers. The results are discussed with respect to register differentiation and differences in prosodic density across both speaker groups.","2024-01","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","1","9","","","","","","","","","","English","","","","WOS:001151441400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","boundary tone; corpus; heritage Russian; intonation; intonation phrase; monolingual Russian; pitch accent; prosody; PROSODY; SPEECH; spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"REIBMAEB","journalArticle","2023","Quiroga, MS; Rosemberg, CR; Alam, F","Lexical Composition of the Vocabulary of Four-Year-Old Children From Different Social Groups and its Relationship to the Linguistic Environment","REVISTA DE ESTUDOS DA LINGUAGEM","","0104-0588","10.17851/2237-2083.31.1.10-50","","The aim of this study was to analyze the lexical composition of child expressive vocabulary and its relationship with linguistic input of four-year-old children from different social backgrounds. From a spontaneous speech corpus, we analyzed the transcriptions of 19 children from two different social backgrounds (n = 38), corresponding to 456 hours of recordings, and we analyzed the lexical diversity and quantity of nouns, adjectives, and verbs, both in child vocabulary and input they were exposed to. The analysis of variance showed that in both cases there was a greater noun type quantity compared to the other word classes, but a greater token quantity of verbs. Beta regressions with child vocabulary as a dependent variable showed that belonging to a socioeconomic group was a predictor of the three lexical classes' types, but only of the adjective's tokens; the presence of each word class in the linguistic input was a predictor of all three word classes, and only of adjective and verb types. These results manifest the complexity of early childhood experiences and the need to pay attention to the various contexts where children acquire language.","2023-01","2025-02-26 20:39:15","2025-02-26 20:39:15","","10-50","","1","31","","","","","","","","","","English","","","","WOS:000939393300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;93</p>","","","ACQUISITION; child production; DIRECTED SPEECH; ENGLISH; JAPANESE CHILDREN; LANGUAGE INPUT; LEARNING WORDS; lexical composition; linguistic input; NOUN BIAS; SOCIOECONOMIC-STATUS; SPANISH; VERBS; vocabulary","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QDN85QYM","journalArticle","2021","Engemann, UM; Plag, I","Phonetic reduction and paradigm uniformity effects in spontaneous speech","MENTAL LEXICON","","1871-1340","10.1075/ml.20023.eng","","Recent work on the acoustic properties of complex words has found that morphological information may influence the phonetic properties of words, e.g. acoustic duration. Paradigm uniformity has been proposed as one mechanism that may cause such effects. In a recent experimental study Seyfarth et al. (2017) found that the stems of English inflected words (e.g. frees) have a longer duration than the same string of segments in a homophonous mono-morphemic word (e.g. freeze), due to the coactivation of the longer articulatory gesture of the bare stem (e.g. free). However, not all effects predicted by paradigm uniformity were found in that study, and the role of frequency-related phonetic reduction remained inconclusive. The present paper tries to replicate the effect using conversational speech data from a different variety of English (i.e. New Zealand English), using the QuakeBox Corpus (Walsh et al. 2013). In the presence of word-form frequency as a predictor, stems of plurals were not found to be significantly longer than the corresponding strings of comparable noncomplex words. The analysis revealed, however, a frequency-induced gradient paradigm uniformity effect: plural stems become shorter with increasing frequency of the bare stem.","2021","2025-02-26 20:39:15","2025-02-26 20:39:15","","165-198","","1","16","","","","","","","","","","English","","","","WOS:000714715900008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;92</p>","","","acoustic duration; ACTIVATION; articulation; DURATIONS; ENGLISH; FREQUENCY; INCOMPLETE NEUTRALIZATION; MORPHOLOGICAL COMPLEXITY; morphology; paradigm uniformity; phonetic reduction; PREDICTABILITY; PROSODIC BOUNDARY; WORDS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F7RIRUHQ","journalArticle","2023","Xu, CS; Li, JY; Feng, B; Lu, BL","A Financial Time-Series Prediction Model Based on Multiplex Attention and Linear Transformer Structure","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13085175","","Financial time-series prediction has been an important topic in deep learning, and the prediction of financial time series is of great importance to investors, commercial banks and regulators. This paper proposes a model based on multiplexed attention mechanisms and linear transformers to predict financial time series. The linear transformer model has a faster model training efficiency and a long-time forecasting capability. Using a linear transformer reduces the original transformer's complexity and preserves the decoder's multiplexed attention mechanism. The results show that the proposed method can effectively improve the prediction accuracy of the model, increase the inference speed of the model and reduce the number of operations, which has new implications for the prediction of financial time series.","2023-04","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","8","13","","","","","","","","","","English","","","","WOS:000977574300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","financial time-series prediction; linear transformer; multiplexed attention mechanism","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CFPCCSWG","journalArticle","2024","Panigrahy, S; Karmakar, S","Hydrophobicity classification of polymeric insulators using a masked autoencoder model in vision transformer","COMPUTERS & ELECTRICAL ENGINEERING","","0045-7906","10.1016/j.compeleceng.2024.109165","","The loss of hydrophobicity on the polymeric insulator's surface leads to a continuous water channel formation. This water channel formation can initiate dry band arcing and subsequent flashover. Therefore, accurately identifying the hydrophobicity class is crucial as it provides the surface ageing information of the polymeric insulators. This study proposed a novel approach utilizing a masked autoencoder-based vision transformer image classifier to classify the hydrophobic condition of polymeric insulators accurately. A comprehensive series of tests were conducted on deep learning image classifier models to assess robustness. The experimental findings demonstrated that the vision transformer model exhibited a significant recognition accuracy of 99.69%, surpassing the performance of the CNN, pre -trained CNN, and ViT models.","2024-05","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","116","","","","","","","","","","English","","","","WOS:001222196700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","Convolutional Neural Network (CNN); Hydrophobicity classification; Polymeric insulator; Pre-trained CNN; Vision Transformer (ViT)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7SKU67U7","journalArticle","2024","Pavlopoulos, J; Romell, A; Curman, J; Steinert, O; Lindgren, T; Borg, M; Randl, K","Automotive fault nowcasting with machine learning and natural language processing","MACHINE LEARNING","","0885-6125","10.1007/s10994-023-06398-7","","Automated fault diagnosis can facilitate diagnostics assistance, speedier troubleshooting, and better-organised logistics. Currently, most AI-based prognostics and health management in the automotive industry ignore textual descriptions of the experienced problems or symptoms. With this study, however, we propose an ML-assisted workflow for automotive fault nowcasting that improves on current industry standards. We show that a multilingual pre-trained Transformer model can effectively classify the textual symptom claims from a large company with vehicle fleets, despite the task's challenging nature due to the 38 languages and 1357 classes involved. Overall, we report an accuracy of more than 80% for high-frequency classes and above 60% for classes with reasonable minimum support, bringing novel evidence that automotive troubleshooting management can benefit from multilingual symptom text classification.","2024-02","2025-02-26 20:39:15","2025-02-26 20:39:15","","843-861","","2","113","","","","","","","","","","English","","","","WOS:001075969400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","Automotive fault nowcasting; Multilingual text classification; Natural language processing; NEURAL-NETWORKS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JEZH8397","journalArticle","2024","Li, KH; Yang, SG; Zhao, L; Wang, WW","Weakly labeled sound event detection with a capsule-transformer model","DIGITAL SIGNAL PROCESSING","","1051-2004","10.1016/j.dsp.2023.104347","","Sound event detection (SED) is a widely studied field that has achieved considerable success. The dynamic routing mechanism of capsule networks has been used for SED, but its performance in capturing global information of audio is still limited. In this paper, we propose a method for SED that by combining the capsule network with transformer leverages the strength of transformer in capturing global features with that of capsule network in capturing local features. The proposed method was evaluated on the DCASE 2017 Task 4 weakly labeled dataset. The obtained F-score and Equal Error Rate are 60.6% and 0.75, respectively. Compared to other baseline systems, our method achieves significantly improved performance. Keywords: Sound event detection, audio tagging, gated convolution, transformer, capsule network.","2024-03","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","146","","","","","","","","","","English","","","","WOS:001165837800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Audio tagging; Capsule network; Gated convolution; Sound event detection; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M26H2WML","journalArticle","2022","Zhang, HQ; Wang, ZX; Song, JF; Li, XY","Transformer for the Building Segmentation of Urban Remote Sensing","PHOTOGRAMMETRIC ENGINEERING AND REMOTE SENSING","","0099-1112","10.14358/PERS.21-00076R2","","The automatic extraction of urban buildings based on remote sens-ing images is important for urban dynamic monitoring, planning, and management. The deep learning has significantly helped improve the accuracy of building extraction. Most remote sensing image segmentation methods are based on convolution neural networks, which comprise encoding and decoding structures. However, the convolution operation cannot learn the remote spatial correlation. Herein we propose the Shift Window Attention of building SWAB-net based on the transformer model to solve the semantic segmenta-tion of building objects. Moreover, the shift window strategy was adopted to determine buildings using urban satellite images with 4 m resolution to extract the features of sequence images efficiently and accurately. We evaluated the proposed network on SpaceNet 7, and the results of comprehensive analysis showed that the net-work is conducive for efficient remote sensing image research.","2022-09","2025-02-26 20:39:15","2025-02-26 20:39:15","","603-609","","9","88","","","","","","","","","","English","","","","WOS:000861076400011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CCHB8NTX","journalArticle","2021","González-López, S; Bethard, S; Orozco, FCE; López-Monroy, AP","Consumer Cynicism Identification for Spanish Reviews using a Spanish Transformer Model","PROCESAMIENTO DEL LENGUAJE NATURAL","","1135-5948","10.26342/2021-66-9","","Companies pay close attention to how consumers react on social media to their products or services. Our work focuses on the identification of Consumer Cynicism, defined as a negative attitude that can have a broad or specific focus and comprises cognitive, affective, and behavioral components. We create a corpus of 619 Spanish-language comments on YouTube car reviews, annotated for four cynicism constructs: Dissatisfaction, Alienation, Skepticism, and Hostility. We compare different classification formulations (binary vs. multi-label) and different pre-trained models (Spanish BETO vs. multilingual BERT). We find binary classifiers derived from BETO consistently outperform multi-label classifiers and classifiers derived from BERT. Our best models achieve F1 of 0.83 for Dissatisfaction, 0.77 for Hostility, 0.71 for Skepticism and 0.70 for Alienation.","2021-03","2025-02-26 20:39:15","2025-02-26 20:39:15","","111-120","","66","","","","","","","","","","","English","","","","WOS:000654021000009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","binary classification model; Consumer Cynicism; multi-label model; social media","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RYXIDDFR","journalArticle","2024","Qiu, W; Xiong, LJ; Li, N; Wang, YB; Zhang, YS","UTR: A UNet-like transformer for efficient unsupervised medical image registration","IMAGE AND VISION COMPUTING","","0262-8856","10.1016/j.imavis.2024.105209","","The existing medical image registration algorithms have the problem of low registration accuracy when processing large deformation medical images. In order to improve registration performance and utilize the global context extraction ability of Transformers without causing high computational complexity, a UNet-like Transformer model combining CNN and Transformer was constructed for 3D medical image registration tasks. We use the Efficient Global Local Attention (EGLA) mechanism to construct a Transformer encoder to further address the difficulty of modeling long-distance dependencies in existing medical image registration networks. We leverage the local modeling capabilities of CNN and the long-distance information capture capabilities of Transformer to achieve high-precision registration. The algorithm has undergone detailed validation experiments on two public datasets. The qualitative and quantitative registration results validate the effectiveness of the proposed model.","2024-10","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","150","","","","","","","","","","English","","","","WOS:001296922900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Dual branch attention; Medical imaging; Transformer; Unsupervised registration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FM66D6QN","journalArticle","2022","Sagirova, A; Burtsev, M","Complexity of symbolic representation in working memory of Transformer correlates with the complexity of a task","COGNITIVE SYSTEMS RESEARCH","","2214-4366","10.1016/j.cogsys.2022.05.002","","Even though Transformers are extensively used for Natural Language Processing tasks, especially for machine translation, they lack an explicit memory to store key concepts of processed texts. This paper explores the properties of the content of symbolic working memory added to the Transformer model decoder. Such working memory enhances the quality of model predictions in machine translation task and works as a neural-symbolic representation of information that is important for the model to make correct translations. The study of memory content revealed that translated text keywords are stored in the working memory, pointing to the relevance of memory content to the processed text. Also, the diversity of tokens and parts of speech stored in memory correlates with the complexity of the corpora for machine translation task.","2022-09","2025-02-26 20:39:15","2025-02-26 20:39:15","","16-24","","","75","","","","","","","","","","English","","","","WOS:000810884600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","Machine translation; Neuro-symbolic representation; Transformer; Working memory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FLS2HTSF","journalArticle","2024","Hsueh, TC; Fainman, Y; Lin, BL","Optical Comb-Based Monolithic Photonic-Electronic Accelerators for Self-Attention Computation","IEEE JOURNAL OF SELECTED TOPICS IN QUANTUM ELECTRONICS","","1077-260X","10.1109/JSTQE.2024.3425456","","This paper adopts advanced monolithic silicon-photonics integrated-circuits manufacturing capabilities to realize system-on-chip photonic-electronic linear-algebra accelerators for self-attention computation in various applications of deep-learning neural networks and Large Language Models. With the features of holistic co-design approaches, optical comb-based broadband modulations, and consecutive matrix-multiplication architecture, the system/circuit/device-level simulations of the proposed accelerator can achieve 2.14-TMAC/s/mm(2) computation density and 27.9-fJ/MAC energy efficiency with practical considerations of power/area overhead due to photonic-electronic on-chip conversions, integrations, and calibrations.","2024-09","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","5","30","","","","","","","","","","English","","","","WOS:001288638000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Computational modeling; Computer architecture; DESIGN; Frequency comb; large language model; Linear accelerators; linear algebra; matrix-matrix multiplication; matrix-vector multiplication; micro-resonator; monolithic integration; Photonics; racetrack resonator; RESONATORS; self-attention; silicon photonics; System-on-chip; Three-dimensional displays; transformer model; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"747AY954","journalArticle","2024","Kotstein, S; Decker, C","RESTBERTa: a Transformer-based question answering approach for semantic search in Web API documentation","CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND APPLICATIONS","","1386-7857","10.1007/s10586-023-04237-x","","To enable machines to process state-of-practice Web API documentation, we propose a Transformer model for the generic task of identifying a Web API element within a syntax structure that matches a natural language query. We solve this semantic-search task with Transformer-based question answering and demonstrate the applicability of our approach to two different tasks, namely the discovery of endpoints and the identification of parameters in payload schemas. With samples from 2321 OpenAPI documentation, we prepare different datasets and fine-tune pre-trained BERT models to these two tasks. We evaluate the generalizability and the robustness of our fine-tuned models. We achieve accuracies of 81.95% for the parameter-matching and 88.44% for the endpoint-discovery task.","2024-07","2025-02-26 20:39:15","2025-02-26 20:39:15","","4035-4061","","4","27","","","","","","","","","","English","","","","WOS:001152697700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","BERT; Endpoint discovery; Parameter matching; Question answering; Semantic search; SERVICES; Web API documentation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ENGZPW39","journalArticle","2024","Xiao, BJ; Nguyen, M; Yan, WQ","Apple ripeness identification from digital images using transformers","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-023-15938-1","","We describe a non-destructive test of apple ripeness using digital images of multiple types of apples. In this paper, fruit images are treated as data samples, artificial intelligence models are employed to implement the classification of fruits and the identification of maturity levels. In order to obtain the ripeness classifications of fruits, we make use of deep learning models to conduct our experiments; we evaluate the test results of our proposed models. In order to ensure the accuracy of our experimental results, we created our own dataset, and obtained the best accuracy of fruit classification by comparing Transformer model and YOLO model in deep learning, thereby attaining the best accuracy of fruit maturity recognition. At the same time, we also combined YOLO model with attention module and gave the fast object detection by using the improved YOLO model.","2024-01","2025-02-26 20:39:15","2025-02-26 20:39:15","","7811-7825","","3","83","","","","","","","","","","English","","","","WOS:001006598900004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Object detection; Transformer; YOLO","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WMWYH9QI","journalArticle","2024","Hao, JK; Kwapong, WR; Shen, T; Fu, HZ; Xu, YW; Lu, QK; Liu, SY; Zhang, J; Liu, YH; Zhao, YF; Zheng, YL; Frangi, AF; Zhang, ST; Qi, H; Zhao, YT","Early detection of dementia through retinal imaging and trustworthy AI","NPJ DIGITAL MEDICINE","","2398-6352","10.1038/s41746-024-01292-5","","Alzheimer's disease (AD) is a global healthcare challenge lacking a simple and affordable detection method. We propose a novel deep learning framework, Eye-AD, to detect Early-onset Alzheimer's Disease (EOAD) and Mild Cognitive Impairment (MCI) using OCTA images of retinal microvasculature and choriocapillaris. Eye-AD employs a multilevel graph representation to analyze intra- and inter-instance relationships in retinal layers. Using 5751 OCTA images from 1671 participants in a multi-center study, our model demonstrated superior performance in EOAD (internal data: AUC = 0.9355, external data: AUC = 0.9007) and MCI detection (internal data: AUC = 0.8630, external data: AUC = 0.8037). Furthermore, we explored the associations between retinal structural biomarkers in OCTA images and EOAD/MCI, and the results align well with the conclusions drawn from our deep learning interpretability analysis. Our findings provide further evidence that retinal OCTA imaging, coupled with artificial intelligence, will serve as a rapid, noninvasive, and affordable dementia detection.","2024-10-20","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","1","7","","","","","","","","","","English","","","","WOS:001336299800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","ALZHEIMERS ASSOCIATION WORKGROUPS; COGNITIVE IMPAIRMENT; DIAGNOSTIC GUIDELINES; DISEASE; NATIONAL INSTITUTE; PREVALENCE; RECOMMENDATIONS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CVMK3FI2","journalArticle","2023","Mattke, S; Batie, D; Chodosh, J; Felten, K; Flaherty, E; Fowler, NR; Kobylarz, FA; O'Brien, K; Paulsen, R; Pohnert, A; Possin, KL; Sadak, T; Ty, D; Walsh, A; Zissimopoulos, JM","Expanding the use of brief cognitive assessments to detect suspected early-stage cognitive impairment in primary care","ALZHEIMERS & DEMENTIA","","1552-5260","10.1002/alz.13051","","Introduction: Mild cognitive impairment remains substantially underdiagnosed, especially in disadvantaged populations. Failure to diagnose deprives patients and families of the opportunity to treat reversible causes, make necessary life and lifestyle changes and receive disease-modifying treatments if caused by Alzheimer's disease. Primary care, as the entry point for most, plays a critical role in improving detection rates. Methods: We convened a Work Group of national experts to develop consensus recommendations for policymakers and third-party payers on ways to increase the use of brief cognitive assessments (BCAs) in primary care. Results: The group recommended three strategies to promote routine use of BCAs: providing primary care clinicians with suitable assessment tools; integrating BCAs into routine workflows; and crafting payment policies to encourage adoption of BCAs. Disscussion: Sweeping changes and actions of multiple stakeholders are necessary to improve detection rates of mild cognitive impairment so that patients and families may benefit from timely interventions.","2023-09","2025-02-26 20:39:15","2025-02-26 20:39:15","","4252-4259","","9","19","","","","","","","","","","English","","","","WOS:000970137300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;25<br/>Total Times Cited:&nbsp;&nbsp;25<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Alzheimer's; ALZHEIMERS-DISEASE; cognitive assessment; DEMENTIA; dementia detection; UPDATE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NISSCGIK","journalArticle","2021","Rodrigues Makiuchi, M; Warnita, T; Inoue, N; Shinoda, K; Yoshimura, M; Kitazawa, M; Funaki, K; Eguchi, Y; Kishimoto, T","Speech Paralinguistic Approach for Detecting Dementia Using Gated Convolutional Neural Network","IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS","","0916-8532","10.1587/transinf.2020EDP7196","","We propose a non-invasive and cost-effective method to automatically detect dementia by utilizing solely speech audio data. We extract paralinguistic features for a short speech segment and use Gated Convolutional Neural Networks (GCNN) to classify it into dementia or healthy. We evaluate our method on the Pitt Corpus and on our own dataset, the PROMPT Database. Our method yields the accuracy of 73.1% on the Pitt Corpus using an average of 114 seconds of speech data. In the PROMPT Database, our method yields the accuracy of 74.7% using 4 seconds of speech data and it improves to 80.8% when we use all the patient's speech data. Furthermore, we evaluate our method on a three-class classification problem in which we included the Mild Cognitive Impairment (MCI) class and achieved the accuracy of 60.6% with 40 seconds of speech data.","2021-11","2025-02-26 20:39:15","2025-02-26 20:39:15","","1930-1940","","11","E104D","","","","","","","","","","English","","","","WOS:000716561600015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","ALZHEIMERS-DISEASE; AUTOMATIC DIAGNOSIS; convolutional neural network; dementia detection; gating mechanism; LANGUAGE; MILD COGNITIVE IMPAIRMENT; MINI-MENTAL-STATE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4AU6PH2X","journalArticle","2024","Alshehhi, T; Ayesh, A; Yang, YJ; Chen, F","Combining pathological and cognitive tests scores: A novel data analytics process to improve dementia prediction models","TECHNOLOGY AND HEALTH CARE","","0928-7329","10.3233/THC-220598","","BACKGROUND: The term 'dementia' covers a range of progressive brain diseases from which many elderly people suffer. Traditional cognitive and pathological tests are currently used to detect dementia, however, applications using Artificial Intelligence (AI) methods have recently shown improved results from improved detection accuracy and efficiency. OBJECTIVE: This research paper investigates the efficacy of one type of data analytics called supervised learning to detect Alzheimer's disease (AD) - a common dementia condition. METHODS: The aim is to evaluate cognitive tests and common biological markers (biomarkers) such as cerebrospinal fluid (CSF) to develop predictive classification systems for dementia detection. RESULTS: A data analytics process has been proposed, implemented, and tested against real data obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) repository. CONCLUSION: The models showed good power in predicting AD levels, notably from specified cognitive tests' scores and tauopathy related features.","2024","2025-02-26 20:39:15","2025-02-26 20:39:15","","2039-2056","","4","32","","","","","","","","","","English","","","","WOS:001283885400003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Alzheimer's disease; ALZHEIMERS-DISEASE; biomarkers; CDR; data analytics; dementia; FUNCTIONAL-ACTIVITIES; medical screening; SCALE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"78I2VPR3","journalArticle","2023","Ayoub, M; Liao, ZF; Li, LF; Wong, KKL","HViT: Hybrid vision inspired transformer for the assessment of carotid artery plaque by addressing the cross-modality domain adaptation problem in MRI","COMPUTERIZED MEDICAL IMAGING AND GRAPHICS","","0895-6111","10.1016/j.compmedimag.2023.102295","","Background: Medical image classification is crucial for accurate and efficient diagnosis, and deep learning frameworks have shown significant potential in this area. When a general learning deep model is directly deployed to a new dataset with heterogeneous features, the effect of domain shifts is usually ignored, which degrades the performance of deep learning models and leads to inaccurate predictions.Purpose: This study aims to propose a framework that utilized the cross-modality domain adaptation and accu-rately diagnose and classify MRI scans and domain knowledge into stable and vulnerable plaque categories by a modified Vision Transformer (ViT) model for the classification of MRI scans and transformer model for domain knowledge classification.Methods: This study proposes a Hybrid Vision Inspired Transformer (HViT) framework that employs a con-volutional layer for image pre-processing and normalization and a 3D convolutional layer to enable ViT to classify 3D images. Our proposed HViT framework introduces a slim design with a multi-branch network and channel attention, improving patch embedding extraction and information learning. Auxiliary losses target shallow features, linking them with deeper ones, enhancing information gain, and model generalization. Furthermore, replacing the MLP Head with RNN enables better backpropagation for improved performance. Moreover, we utilized a modified transformer model with LSTM positional encoding and Golve word vector to classify domain knowledge. By using ensemble learning techniques, specifically stacking ensemble learning with hard and soft prediction, we combine the predictive power of both models to address the cross-modality domain adaptation problem and improve overall performance.Results: The proposed framework achieved an accuracy of 94.32% for carotid artery plaque classification into stable and vulnerable plaque by addressing the cross-modality domain adaptation problem and improving overall performance.Conclusion: The model was further evaluated using an independent dataset acquired from different hardware protocols. The results demonstrate that the proposed deep learning model significantly improves the general-ization ability across different MRI scans acquired from different hardware protocols without requiring addi-tional calibration data.","2023-10","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","109","","","","","","","","","","English","","","","WOS:001079546100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Carotid artery Plaque; CONVOLUTIONAL NEURAL-NETWORK; Cross-modality domain adaptation; Deep Learning; Self-attention mechanism; Vision transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CMCNV8EP","journalArticle","2024","Kazama, K; Fujita, K; Shinoda, Y; Koike, S","Sika deer trajectory prediction considering environmental factors by timeseries transformer-based architecture","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.123630","","Recently, the damage to agriculture, forestry, and fishery by wildlife has become a serious social problem. The damage caused by a conflict between wildlife and human society often causes less motivation for farming and is expected to significantly inhibit the development of local agriculture and forestry. However, the current management of wildlife is limited to primitive methods such as stabilizing the population by culling reliant on experience. To prevent this problem, the trajectory prediction of wildlife is one of the solutions for efficient wildlife management. In this study, we propose a machine learning architecture for predicting wildlife trajectories, considering surrounding environmental factors. Particularly, we propose a machine learning architecture that more accurately predicts trajectories using a timeseries transformer model that can learn long-term dependencies and add a submodel that can consider surrounding environmental factors. The proposed architecture allows interpreting which past trajectory areas should be focused on when predicting a trajectory by visualizing the weight of the focus mechanism, one of the elements comprising the transformer model. Further, the proposed architecture can decide the priority of elements of a multivariate timeseries input by considering a variable selection network (VSN), which considers the relationship of timeseries between a given time point and those before and after using casual convolutions. The main advantage of our methods is to understand the potential environmental factors to predict animal trajectories by analyzing the importance of each input feature representation in VSN. We experimented to evaluate the proposed method using one of the largest biologging datasets of sika deer ( Cervus nippon ) in Kanagawa Prefecture, Japan. The proposed method outperforms existing methods on various evaluation metrics and can effectively consider environmental factors in predicting trajectories. In addition, we analyze the results and show that the proposed architecture can pay attention to the times that individuals moved significantly within the observation period by visualizing the trajectories for the best and worst cases and the weight of each environmental factor.","2024-09-15","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","250","","","","","","","","","","English","","","","WOS:001224031600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Animal trajectory; Biologging; Cervus nippon; Timeseries prediction; Trajectory prediction; Transformer; VEGETATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SKQ7W9DZ","journalArticle","2024","Zhou, W; Miwa, S; Wang, HY; Okamoto, K","Assessment of the state-of-the-art AI methods for critical heat flux prediction","INTERNATIONAL COMMUNICATIONS IN HEAT AND MASS TRANSFER","","0735-1933","10.1016/j.icheatmasstransfer.2024.107844","","Critical Heat Flux (CHF) plays a pivotal role in ensuring reliability and safety within boiling two-phase flow systems. Despite the development of numerous CHF prediction tools using conventional empirical correlations, machine learning, and deep learning methods, the complex mechanisms underlying CHF continue to challenge the development of a unified, accurate, and robust prediction model. The complexity is further exacerbated by varying experimental dataset developed over the decades of CHF research. In response to these challenges, the present study leverages state-of-the-art AI method, including ANN, CNN, Transformer model, and transfer learning techniques. The proposed AI-based CHF prediction model, particularly the Transformer model employing self-attention mechanisms, dynamically assigns importance to different parts of the input data. The approach significantly improves the model's capability for CHF prediction. The results indicate that the predictive performance of the Transformer-based AI model exceeds that of the Look-Up Table (LUT) method and a benchmark model from the OECD-NEA based on the database encompasses 24,579 CHF data point conducted in vertical, uniformly heated, water-cooled tubes from 59 distinct sources over the past 60 years. The five-input AI model achieved the best predictive performance: Mean P/M of 1.008, Std. P/M of 0.122, RMSPE of 12.3%, MAPE of 7.22%, NRMSE of 9.91%, and Q2 of 1.26%. Moreover, the AI-based CHF prediction model's prediction behaviors are examined and compared with the LUT method. This comparison confirms the model's resistance to overfitting. Finally, by utilizing transfer learning, the model's ability to predict CHF in tubes is extended to annulus and plate geometries. The CHF prediction results of transfer learning to annulus geometry are as follows: Mean P/M of 1.012, Std. P/M of 0.134, RMSPE of 13.4%, MAPE of 8.51%, NRMSE of 10.42%, and Q2 of 8.31%, showcasing the flexibility and robustness of AI-based CHF prediction model towards different flow channels.","2024-11","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","158","","","","","","","","","","English","","","","WOS:001287654000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","CHF; Critical heat flux; Deep learning; Heat transfer; Neural network; Transfer learning; TUBES; WATER-FLOW","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QLBVZ5WJ","journalArticle","2024","Wang, YM; Wang, CL; Wang, B; Wang, HW","Combination of feature selection methods and lightweight Transformer model for estimating the canopy water content of alpine shrub using spectral data","INFRARED PHYSICS & TECHNOLOGY","","1350-4495","10.1016/j.infrared.2024.105304","","Monitoring canopy water content in alpine scrub is crucial for hydrological and ecological studies in the Qilian Mountains. However, traditional measurement methods are time-consuming and inconvenient to implement due to the harsh climate and lack of transportation in alpine regions. In our study, a new method was proposed to estimate the canopy water content of alpine shrub using spectral data. The water content data for samples with alpine scrub canopy reflectance spectra in the range of 350 - 2500 nm was collected. Then, a lightweight Transformer regression model was built based on three different feature selection methods (the successive projections algorithm, genetic algorithm, and principal component analysis) to predict the canopy water content of shrubs. The proposed model was compared with three traditional machine learning models: random forest, support vector regression, and back -propagation neural network. The results reveal that the lightweight Transformer model demonstrates strong fitting and generalization capabilities in using only full -band spectra as input, which may be attributed to Transformer ' s own self -attention mechanism. From cross -validation, the RMSE and R 2 of the model on the training (validation) set are 0.0201 (0.0233) and 0.968 (0.965), respectively. Furthermore, the performance of all regression models is enhanced after feature selection. On the validation set, PCA-Transformer has the smallest RMSE (0.0147) and largest R 2 (0.985), and its running efficiency is improved by 81.69 % relative to the full -band spectra as input. In the additional test set, the predictive ability of the models remain stable. SPA -Transformer has the smallest RMSE (0.0111) and largest R 2 (0.986). These suggest the excellent performance of lightweight Transformer on the task of estimating scrub water content and the ability of feature selection methods to optimize models. The results show that PCA-Transformer is an accurative and effictive tool to estimate plant water content, and offer a foundation for monitoring large-scale canopy water content in alpine regions using remote sensing technology.","2024-06","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","139","","","","","","","","","","English","","","","WOS:001230749400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","Alpine shrub; Canopy water content; CHLOROPHYLL; Feature selection; INDEXES; LEAVES; LIGHT; Plant monitoring; REFLECTANCE; Spectral data; T ransformer; WHEAT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"58DQ8G33","journalArticle","2023","Gao, M; Wei, CJ; Zhao, XG; Huang, RJ; Li, BZ; Yang, J; Gao, Y; Liu, SS; Xiong, LH","Intelligent Optimization of Gas Flooding Based on Multi-Objective Approach for Efficient Reservoir Management","PROCESSES","","2227-9717","10.3390/pr11072226","","The efficient development of oil reservoirs mainly depends on the comprehensive optimization of the subsurface fluid flow process. As an intelligent analysis technique, artificial intelligence provides a novel solution to multi-objective optimization (MOO) problems. In this study, an intelligent agent model based on the Transformer framework with the assistance of the multi-objective particle swarm optimization (MOPSO) algorithm has been utilized to optimize the gas flooding injection-production parameters in a well pattern in the Middle East. Firstly, 10 types of surveillance data covering 12 years from the target reservoir were gathered to provide a data foundation for model training and analysis. The prediction performance of the Transformer model reflected its higher accuracy compared to traditional reservoir numerical simulation (RNS) and other intelligent methods. The production prediction results based on the Transformer model were 21, 12, and 4 percentage points higher than those of RNS, bagging, and the bi-directional gated recurrent unit (Bi-GRU) in terms of accuracy, and it showed similar trends in the gas-oil ratio (GOR) prediction results. Secondly, the Pareto-based MOPSO algorithm was utilized to fulfil the two contradictory objectives of maximizing oil production and minimizing GOR simultaneously. After 10,000 iterations, the optimal injection-production parameters were proposed based on the generated Pareto frontier. To validate the feasibility and superiority of the developed approach, the development effects of three injection-production schemes were predicted in the intelligent agent model. In the next 400 days of production, the cumulative oil production increased by 25.3% compared to the average distribution method and 12.7% compared to the reservoir engineering method, while GOR was reduced by 27.1% and 15.3%, respectively. The results show that MOPSO results in a strategy that more appropriately optimizes oil production and GOR compared to some previous efforts published in the literature. The injection-production parameter optimization method based on the intelligent agent model and MOPSO algorithm can help decision makers to update the conservative development strategy and improve the development effect.","2023-07","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","7","11","","","","","","","","","","English","","","","WOS:001036645700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","ALGORITHM; artificial intelligence; attention; CLASSIFICATION; gas flooding; injection-production optimization; MODELS; multi-objective optimization; NETWORK; OBJECTIVES; PARTICLE SWARM OPTIMIZATION; PREDICTION; RESPONSE-SURFACE METHODOLOGY; SHORT-TERM; WELL PLACEMENT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WXXIW7AS","journalArticle","2024","Li, ZQ; Li, ZY; Ji, Z; Xie, YS; Zhang, Y; Yang, ZL; Shi, Z; Qie, LL; Zhang, L; Zhang, ZH; Gu, HR","Improvement of Space-Observation of Aerosol Chemical Composition by Synergizing a Chemical Transport Model and Ground-Based Network Data","REMOTE SENSING","","2072-4292","10.3390/rs16234390","","Aerosol chemical components are critical parameters that influence the atmospheric environment, climate effects, and human health. Retrieving global columnar atmospheric aerosol components from satellite observations provides foundational data and practical value. This study develops a method for retrieving aerosol component composition from polarized satellite data by synergizing a chemical transport model with ground-based remote sensing data. The method enables the rapid acquisition of columnar mass concentrations for seven aerosol components on a global scale, including black carbon (BC), brown carbon (BrC), organic carbon (OC), ammonium sulfate (AS), aerosol water (AW), dust (DU), and sea salt (SS). We first establish a remote sensing model based on the multiple solution mixing mechanism (MSM2) to obtain aerosol chemical components using AERONET ground-based measurements. We then employ a cross-layer adaptive fusion (CAF)-Transformer model to learn the spatial distribution characteristics of aerosol components from the MERRA-2 model. Furthermore, we optimize the retrieval model by transfer learning from the ground-based composition data to achieve satellite remote sensing of aerosol components. Residual analysis indicates that the retrieval model exhibits robust generalization capabilities for components such as BC, OC, AS, and DU, achieving a coefficient of determination of 0.7. Moreover, transfer learning effectively enhances the consistency between satellite retrievals and ground-based remote sensing results, with an average improvement of 0.23 in the correlation coefficient. We present annual and seasonal means of global distributions of the retrieved aerosol component concentrations, with a major focus on the spatial and temporal variations of BC and DU. Additionally, we analyze three typical atmospheric environmental cases, wildfire, dust storm, and particulate pollution, by comparing our retrievals with model data and other datasets. This demonstrates the ability of satellite remote sensing to identify the location, intensity, and impact range of environmental pollution events. Satellite-retrieved aerosol component data offers high spatial resolution and efficiency, particularly providing significant advantages for near-real-time monitoring of regional atmospheric environmental events.","2024-12","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","23","16","","","","","","","","","","English","","","","WOS:001377701800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","AERONET; aerosol components; BLACK CARBON; BROWN CARBON; COMPONENTS; MERRA-2; NORTHERN INDIA; REPRESENTATION; RETRIEVAL; SATELLITE; satellite polarimetric sensor; SIMULATION; SUBMICRON AEROSOL; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H587HAW4","journalArticle","2023","Wang, Y; Wang, Z; Wang, XY; Kang, XY","Multi-step-ahead and interval carbon price forecasting using transformer-based hybrid model","ENVIRONMENTAL SCIENCE AND POLLUTION RESEARCH","","0944-1344","10.1007/s11356-023-29196-z","","Accurate and stable carbon price forecasts serve as a reference for assessing the stability of the carbon market and play a vital role in enhancing investment and operational decisions. However, realizing this goal is still a significant challenge, and researchers usually ignore multi-step-ahead and interval forecasting due to the non-linear and non-stationary characteristics of carbon price series and its complex fluctuation features. In this study, a novel hybrid model for accurately predicting carbon prices is proposed. The proposed model combines multi-step-ahead and interval carbon price forecasting based on the Hampel identifier (HI), time-varying filtering-based empirical mode decomposition (TVFEMD), and transformer model. First, HI identifies and corrects outliers in carbon price. Second, TVFEMD decomposes carbon price into several intrinsic mode functions (imfs) to reduce the non-linear and non-stationarity of carbon price to obtain more regular features in series. Next, these imfs are reconstructed by sample entropy (SE). Subsequently, the orthogonal array tuning method is used to optimize the transformer model's hyperparameters to obtain the optimal model structure. Finally, after hyperparameter optimization and quantile loss function, the transformer is used to perform multi-step-ahead and interval forecasting on each part of the reconstruction, and the final prediction result is obtained by summing them up. Five pilot carbon trading markets in China were selected as experimental objects to verify the proposed model's prediction performance. Various benchmark models and evaluation indicators were selected for comparison and analysis. Experimental results show that the proposed HI-TVFEMD-transformer hybrid model achieves an average MAE of 0.6546, 1.3992, 1.6287, and 2.2601 for one-step, three-step, five-step, and ten-step-ahead forecasting, respectively, which significantly outperforms other models. Furthermore, interval forecasts almost always have a PICI above 0.95 at a confidence interval of 0.1, thereby indicating the effectiveness of the hybrid model in describing the uncertainty in the forecasts. Therefore, the proposed hybrid model is a reliable carbon price forecasting tool that can provide a dependable reference for policymakers and investors.","2023-09","2025-02-26 20:39:15","2025-02-26 20:39:15","","95692-95719","","42","30","","","","","","","","","","English","","","","WOS:001045140500011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","Carbon price; DECOMPOSITION; Interval forecasting; Multi-step-ahead forecasting; NETWORK; OATM; Transformer; TVFEMD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7S42FVXT","journalArticle","2022","Suda, H; Saito, D; Fukayama, S; Nakano, T; Goto, M","Singer Diarization for Polyphonic Music With Unison Singing","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2022.3166262","","This paper introduces a new framework for singer diarization, which is a technique to reveal who sings when in songs with multiple singers. Although various techniques have been developed to analyze and extract features of singing voices in musical audio signals, most of them assume that a song is sung by a single singer, and singer diarization for multiple singers has not been well studied in the field of singing information processing. To deal with multiple speakers in speech analysis, speaker diarization has been explored to handle overlapped speech voices, but cannot handle singing voices well because of acoustic differences between singing and speech voices. This paper therefore proposes a new diarization framework specialized in singing voices. To achieve high accuracy in overlap detection, this paper proposes a novel acoustic feature named Cosacorr score, which is helpful in estimating whether a song is sung by more than one singer. After extracting singing voices from polyphonic music by using a singing voice separation technique, the framework adopts an existing ArcFace technique to extract discriminative singer representations from short segments of the separated singing voices. The framework is evaluated by using a new private dataset of unison singing voices, which is constructed using commercially available compact discs (CDs). The experimental results show that the proposed framework outperformed the baseline method for speaker diarization in terms of diarization error rate (DER).","2022","2025-02-26 20:39:15","2025-02-26 20:39:15","","1531-1545","","","30","","","","","","","","","","English","","","","WOS:000791755700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Data mining; DATABASE; Feature extraction; Information processing; Music information processing; music information retrieval; singer diarization; SPEAKER DIARIZATION; Speech analysis; Synchronization; Timbre; unison singing; Voice activity detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BFH72JDK","journalArticle","2023","Cai, LW; Wen, C; Jiang, JW; Liang, CB; Zheng, HM; Su, Y; Chen, CZ","Classification of diabetic maculopathy based on optical coherence tomography images using a Vision Transformer model","BMJ OPEN OPHTHALMOLOGY","","2397-3269","10.1136/bmjophth-2023-001423","","PurposeTo develop a Vision Transformer model to detect different stages of diabetic maculopathy (DM) based on optical coherence tomography (OCT) images.MethodsAfter removing images with poor quality, a total of 3319 OCT images were extracted from the Eye Center of the Renmin Hospital of Wuhan University and randomly split the images into training and validation sets in a 7:3 ratio. All macular cross-sectional scan OCT images were collected retrospectively from the eyes of DM patients from 2016 to 2022. One of the OCT stages of DM, including early diabetic macular oedema (DME), advanced DME, severe DME and atrophic maculopathy, was labelled on the collected images, respectively. A deep learning (DL) model based on Vision Transformer was trained to detect four OCT grading of DM.ResultsThe model proposed in our paper can provide an impressive detection performance. We achieved an accuracy of 82.00%, an F1 score of 83.11%, an area under the receiver operating characteristic curve (AUC) of 0.96. The AUC for the detection of four OCT grading (ie, early DME, advanced DME, severe DME and atrophic maculopathy) was 0.96, 0.95, 0.87 and 0.98, respectively, with an accuracy of 90.87%, 89.96%, 94.42% and 95.13%, respectively, a precision of 88.46%, 80.31%, 89.42% and 87.74%, respectively, a sensitivity of 87.03%, 88.18%, 63.39% and 89.42%, respectively, a specificity of 93.02%, 90.72%, 98.40% and 96.66%, respectively and an F1 score of 87.74%, 84.06%, 88.18% and 88.57%, respectively.ConclusionOur DL model based on Vision Transformer demonstrated a relatively high accuracy in the detection of OCT grading of DM, which can help with patients in a preliminary screening to identify groups with serious conditions. These patients need a further test for an accurate diagnosis, and a timely treatment to obtain a good visual prognosis. These results emphasised the potential of artificial intelligence in assisting clinicians in developing therapeutic strategies with DM in the future.","2023-12","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","1","8","","","","","","","","","","English","","","","WOS:001134783300006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","EYES; Imaging; Macula; MACULAR EDEMA; MORPHOLOGY; PATTERNS; Retina; RETINOPATHY; VISUAL-ACUITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HCW5YJH4","journalArticle","2023","Levin, R; Aravkin, AY; Kim, M","Patient-specific quality assurance failure prediction with deep tabular models","BIOMEDICAL PHYSICS & ENGINEERING EXPRESS","","2057-1976","10.1088/2057-1976/acd255","","Purpose. Patient-specific quality assurance (PSQA) failures in radiotherapy can cause a delay in patient care and increase the workload and stress of staff. We developed a tabular transformer model based directly on the multi-leaf collimator (MLC) leaf positions (without any feature engineering) to predict IMRT PSQA failure in advance. This neural model provides an end-to-end differentiable map from MLC leaf positions to the probability of PSQA plan failure, which could be useful for regularizing gradient-based leaf sequencing optimization algorithms and generating a plan that is more likely to pass PSQA. Method. We retrospectively collected DICOM RT PLAN files of 968 patient plans treated with volumetric arc therapy. We constructed a beam-level tabular dataset with 1873 beams as samples and MLC leaf positions as features. We trained an attention-based neural network FT-Transformer to predict the ArcCheck-based PSQA gamma pass rates. In addition to the regression task, we evaluated the model in the binary classification context predicting the pass or fail of PSQA. The performance was compared to the results of the two leading tree ensemble methods (CatBoost and XGBoost) and a non-learned method based on mean-MLC-gap. Results. The FT-Transformer model achieves 1.44% Mean Absolute Error (MAE) in the regression task of the gamma pass rate prediction and performs on par with XGBoost (1.53 % MAE) and CatBoost (1.40 % MAE). In the binary classification task of PSQA failure prediction, FT-Transformer achieves 0.85 ROC AUC (compared to the mean-MLC-gap complexity metric achieving 0.72 ROC AUC). Moreover, FT-Transformer, CatBoost, and XGBoost all achieve 80% true positive rate while keeping the false positive rate under 20%. Conclusions. We demonstrated that reliable PSQA failure predictors can be successfully developed based solely on MLC leaf positions. FT-Transformer offers an unprecedented benefit of providing an end-to-end differentiable map from MLC leaf positions to the probability of PSQA failure.","2023-07-01","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","4","9","","","","","","","","","","English","","","","WOS:000986339100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","CLINICAL IMPLEMENTATION; DELIVERY; IMRT; machine learning; METRICS; OPTIMIZATION; patient safety; QA; quality assurance; radiotherapy; tabular deep learning; TREATMENT PLAN COMPLEXITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QW4HBEGZ","journalArticle","2021","Su, XY; Liu, HM; Tao, LF; Lu, C; Suo, ML","An end-to-end framework for remaining useful life prediction of rolling bearing based on feature pre-extraction mechanism and deep adaptive transformer model","COMPUTERS & INDUSTRIAL ENGINEERING","","0360-8352","10.1016/j.cie.2021.107531","","In practical engineering, accurate prediction of remaining useful life (RUL) is always necessary for effective preparation of engineering assets, human resources and maintenance actions. With the improvement of computing power and the passionate requirements for the high prediction accuracy of complex systems, more and more deep model-based frameworks have been developed for RUL prediction. In general, these frameworks consist of two stages: the first one is the manual operation of feature extraction and feature selection; the second one is the RUL prediction that mainly employs the recurrent deep models. However, such the frameworks do not fully take advantage of the deep models since they still rely on much prior knowledge and do not achieve the satisfied prediction performance. In this paper, a novel two stage framework with less prior knowledge, namely, end-to-end framework, is proposed to improve the forecasting performance. In our first stage, a feature preextraction mechanism is designed to pre-extract the low-level features in relatively high dimensional space, which requires no additional manual operations of feature fusion and feature selection in existing methods. In our second stage, adaptive transformer, a new deep model integrating the attention mechanism and the recurrent architecture, is proposed to model the relationships between these low-level features and the RULs directly, which suppresses the issue of vanishing gradients and is more suitable for representing the complex temporal degradation characteristics. Two public bearing datasets are employed to validate the effectiveness of the proposed framework in this paper. In these two case studies, some existing state-of-the-art RUL prediction approaches are fully compared, and the critical hyperparameters and components of our framework are analyzed in details. The experimental results reveal our advantage on adaptive degradation modeling and accurate RUL prediction, and help to interpret the impact of the proposed framework architecture on bearing RUL prediction.","2021-11","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","161","","","","","","","","","","English","","","","WOS:000704428500005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;71<br/>Total Times Cited:&nbsp;&nbsp;71<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Adaptive transformer model; Deep learning; Feature pre-extraction mechanism; FEATURE-SELECTION; LSTM; NETWORKS; PERFORMANCE DEGRADATION ASSESSMENT; PROGNOSTICS; Remaining useful life prediction; Rolling bearing; ROTATING MACHINERY; SYSTEMS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y6DY3BXL","journalArticle","2024","Hou, ML; Wei, JH; Shi, Y; Hou, SL; Zhang, WQ; Xu, JQ; Wu, Y; Wang, H","Hydroformer: Frequency Domain Enhanced Multi-Attention Transformer for Monthly Lake Level Reconstruction With Low Data Input Requirements","WATER RESOURCES RESEARCH","","0043-1397","10.1029/2024WR037166","","Lake level changes are critical indicators of hydrological balance and climate change, yet long-term monthly lake level reconstruction is challenging with incomplete or short-term data. Data-driven models, while promising, struggle with nonstationary lake level changes and complex dependencies on meteorological factors, limiting their applicability. Here, we introduce the Hydroformer, a frequency domain enhanced multi-attention Transformer model designed for monthly lake level reconstruction, utilizing reanalysis data. This model features two innovative mechanisms: (a) Frequency-Enhanced Attention (FEA) for capturing long-term temporal dependence, and (b) Causality-based Cross-dimensional Attention (CCA) to elucidate how specific meteorological factors influence lake level. Seasonal and trend patterns of catchment meteorological factors and lake level are initially identified by a time series decomposition block, then independently learned and refined within the model. Tested across 50 lakes globally, the Hydroformer excelled in reconstruction periods ranging from half to three times the training-test length. The model exhibited good performance even when training data missing rates were below 50%, particularly in lakes with significant seasonal fluctuations. The Hydroformer demonstrated robust generalization across lakes of varying sizes, from 10.11 to 18,135 km2, with median values for R2, MAE, MSE, and RMSE at 0.813, 0.313, 0.215, and 0.4, respectively. Furthermore, the Hydroformer outperformed data-driven models, improving MSE by 29.2% and MAE by 24.4% compared to the next best model, the FEDformer. Our method proposes a novel approach for reconstructing long-term water level changes and managing lake resources under climate change. Lake water levels, as key indicators of hydrologic dynamics and catchment balance, are vital for understanding climate impacts and managing water resources. However, the lack of continuous measurements for most global lakes, combined with the inability of traditional data-driven models to effectively decipher complex interactions with catchment hydrological processes, leads to significant gaps in generalizability, accuracy, and reconstructive length. Given these limitations, accurate monthly reconstructions of lake level remain a persistent challenge. To address this, we develop Hydroformer, an innovative frequency domain enhanced multi-attention Transformer model, utilizing reanalysis data for monthly lake level reconstruction. It employs two innovative attention mechanisms: Frequency-Enhanced Attention for capturing long-term temporal dependencies and Causality-based Cross-dimensional Attention for cross-dimensional causal dependencies between catchment meteorological factors and lake level. Through a decomposition block, the model efficiently recognizes and refines inherent seasonal and trend patterns, leading to a comprehensive understanding of lake behaviors. Through testing on 50 global lakes, the Hydroformer has exhibited exceptional performance in reconstructing water levels for lakes ranging from 10.11 to 18,135 km2, adeptly handling short-term, long-term, and varying proportions of data gaps. It notably outperforms supervised data-driven models. This positions it as a vital instrument for monthly lake level reconstruction, showcasing the power of integrating advanced artificial intelligence techniques in hydrological modeling. A novel frequency domain enhanced multi-attention Transformer model, Hydroformer, has been built for reconstructing monthly lake level using reanalysis data The model accurately extends reconstructions 2-3 times the training data length, excelling with less than 50% missing training data Hydroformer surpasses advanced AI-based models, improving MSE and MAE by over 20% and demonstrating strong generalization across lakes of varying sizes","2024-10","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","10","60","","","","","","","","","","English","","","","WOS:001321821500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;85</p>","","","Causality-based Cross-dimensional Attention (CCA) mechanism; DECLINE; Frequency-Enhanced Attention (FEA) mechanism; Lake level reconstruction; Multi-Attention mechanism; TIME-SERIES; Transformer-based model; WATER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HXRS6GNE","journalArticle","2025","Song, JC; Zhu, S; Li, W; Xue, GX; Gao, XY","A novel robust heating load prediction algorithm based on hybrid residual network and temporal fusion transformer model","ENERGY","","0360-5442","10.1016/j.energy.2025.134779","","The district heating system involves a wide range and large scale, and the change of heat load exhibits significant non-linear, multi-coupling characteristics due to the influence of meteorological, building thermal inertia of numerous system factors. Additionally, the problem of missing values in the actual heating system also causes the existing heat load prediction models to frequently have difficulties in extracting the complex trends of the historical heat load data and result in the lack of prediction accuracy, which is detrimental to the supply-demand balance and leads to severe environmental problems such as energy wastage. A hybrid heat load prediction model based on Residual Network and Temporal Fusion Transformer algorithms was proposed in this paper to address the complexity of heat load changes in district heating system. The excellent capability of Residual Network in mining historical information contributes to the effective imputation of missing values and the establishment of a sound data foundation for the subsequent construction of data-driven heat load prediction models. The Gated Residual Network, multi-head attention mechanism, and other functional units in the Temporal fusion transformer model were sufficient to adequately extract the features and patterns of the historical heat load data and achieve reliable heat load prediction. Detailed comparative experiments with the actual data from four heat exchange stations at the district heating system in Anyang were conducted in this paper to validate the performance of the proposed hybrid heat load prediction model based on Residual Network and temporal fusion transformer. The mean absolute percentage error of the heat load prediction results in the four sites were all below 0.05 in the comparison experiments. The error metrics of Mean absolute error, Mean square error, and Root mean square error were also lower than other state-of-the-art algorithms. The feasibility and effectiveness of this model in practical applications are verified through experiments, which provide a new research perspective and practical reference for the heat load prediction of district heating system.","2025-03-01","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","318","","","","","","","","","","English","","","","WOS:001422514100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Heating load; Prediction model; Residual network; Temporal fusion transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FBCMK2XB","journalArticle","2022","Koeshidayatullah, A; Al-Azani, S; Baraboshkin, E; Alfarraj, M","FaciesViT: Vision transformer for an improved core lithofacies prediction","FRONTIERS IN EARTH SCIENCE","","2296-6463","10.3389/feart.2022.992442","","Lithofacies classification is a fundamental step to perform depositional and reservoir characterizations in the subsurface. However, such a classification is often hindered by limited data availability and biased and time-consuming analysis. Recent work has demonstrated the potential of image-based supervised deep learning analysis, specifically convolutional neural networks (CNN), to optimize lithofacies classification and interpretation using core images. While most works have used transfer learning to overcome limited datasets and simultaneously yield a high-accuracy prediction. This method raises some serious concerns regarding how the CNN model learns and makes a prediction as the model was originally trained with entirely different datasets. Here, we proposed an alternative approach by adopting a vision transformer model, known as FaciesViT, to mitigate this issue and provide improved lithofacies prediction. We also experimented with various CNN architectures as the baseline models and two different datasets to compare and evaluate the performance of our proposed model. The experimental results show that the proposed models significantly outperform the established CNN architecture models for both datasets and in all cases, achieving an f1 score and weighted average in all tested metrics of 95%. For the first time, this study highlights the application of the Vision Transformer model to a geological dataset. Our findings show that the FaciesViT model has several advantages over conventional CNN models, including (i) no hyperparameter fine-tuning and exhaustive data augmentation required to match the accuracy of CNN models; (ii) it can work with limited datasets; and (iii) it can better generalize the classification to a new, unseen dataset. Our study shows that the application of the Vision transformer could further optimize image recognition and classification in the geosciences and mitigate some of the issues related to the generalizability and the explainability of deep learning models. Furthermore, the implementation of our proposed FaciesViT model has been shown to improve the overall performance and reproducibility of image-based core lithofacies classification which is significant for subsurface reservoir characterization in different basins worldwide.","2022-10-04","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","10","","","","","","","","","","English","","","","WOS:000871098700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","AI; CLASSIFICATION; deep learning; GAS-FIELD; geosciences; IDENTIFICATION; lithofacies; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TD9DRBV2","journalArticle","2024","Yuan, ZB; Hien, PL","Pre-trained transformer model as a surrogate in multiscale computational homogenization framework for elastoplastic composite materials subjected to generic loading paths","COMPUTER METHODS IN APPLIED MECHANICS AND ENGINEERING","","0045-7825","10.1016/j.cma.2024.116745","","A composite material typically exhibits complex behavior at the engineer scale, arising from the interactions between its underlying constituent phases, as well as the competitions between micro -processes. It is generally a daunting task to develop an engineering model to adequately capture the essential micro mechanisms that propagate onto the macro scale. To this end, the multiscale computational homogenization (FE2) method enables a consistent coupling across length scales, to give results that compare well with direct numerical simulations having the full micro-structural details, without the need for any constitutive assumptions nor calibrations at the macro scale. Despite its predictive capabilities, the typical computational homogenization method is still computationally too expensive for most practical problems, as the coupling between micro and macro scales are solved simultaneously during its numerical implementation. In this presentation, focusing on the elastoplastic behavior of fiber-reinforced composite, we address this bottleneck with an offline development of a microscopic surrogate model for a given micro-structure, to be incorporated into a standard nonlinear FE framework, for rapid online implementations at the macro scale. For the offline training phase, we adopt the transformer-based architecture within a pre-training and fine-tuning framework. The proposed pre-trained transformer model is capable of parallelizing computations to effectively capture global dependencies within the strain-stress data sequences. To reduce the data generation cost, a constructed source representative volume element (RVE) having a single central heterogeneity with an identical volume fraction with the target RVE is utilized, to rapidly generate a huge source dataset for a pre-training process. The performance of the surrogate model is first demonstrated by comparing its predictions under random loading paths against the reference homogenized RVE responses. Next, the surrogate model is incorporated into a macro FE framework, and its predictive capabilities illustrated via the generic loading of two specimens with different microstructures, each having a different loading-unloading path. Finally, a chunking method is discussed as a potential remedy for managing very long load sequences.","2024-03-01","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","421","","","","","","","","","","English","","","","WOS:001165606700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Composite materials; Elastoplastic behavior; MECHANICAL METAMATERIALS; Multiscale computational homogenization; Pre-trained transformer; Pre-training and fine-tuning; Self-attention","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VIPH6BGY","journalArticle","2023","Pribuisis, K; Pribuisiene, R; Padervinskis, E; Ulozas, V","Substitution voicing index: towards improved speech assessment in patients who have undergone laryngeal oncosurgery","CLINICAL LINGUISTICS & PHONETICS","","0269-9206","10.1080/02699206.2022.2059398","","This study aimed to develop a multidimensional model for the evaluation of substitution voicing (SV) after laryngeal oncosurgery. The study group consisted of 121 adult male individuals: 59 patients with SV after laryngeal oncosurgery (endolaryngeal cordectomy, partial laryngectomy, total laryngectomy with tracheoesophageal prosthesis) and 62 healthy controls. A multidimensional protocol for the assessment of SV included, 1) self-reported speech evaluation with a short version of the Speech Handicap Index, 2) auditory-perceptual assessment, and 3) acoustic speech analysis using AMPEX (R) (Auditory Model Based Pitch Extractor) software. Moderate correlations were observed between parameters from self-reported auditory-perceptual and acoustic speech analysis domains. The multidimensional Substitution Voicing Index (SVI), including markers from these domains, was elaborated by using linear stepwise regression to determine the optimal set of parameters for categorising SV patients. The lowest mean SVI score was revealed in the control subgroup corresponding to the normal speech, followed by cordectomy subgroup and partial laryngectomy subgroup. The highest mean SVI score was revealed in the total laryngectomy subgroup, reflecting the most severely deteriorated quality of SV. One-way analysis of variance identified statistically significant differences between the mean SVI scores in separate subgroups. The results demonstrated the potential benefits of the SVI for a multidimensional evaluation of SV in patients after laryngeal oncosurgery.","2023-07-03","2025-02-26 20:39:15","2025-02-26 20:39:15","","583-598","","7","37","","","","","","","","","","English","","","","WOS:000805680100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","CANCER; CLASSIFICATION; CORDECTOMY; HANDICAP INDEX; Laryngeal carcinoma; MULTIDIMENSIONAL ASSESSMENT; OUTCOMES; QUALITY-OF-LIFE; RELIABILITY; substitution voicing; substitution voicing index; VOICES; WORKING COMMITTEE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2M7N8BSP","journalArticle","2023","Chung, H; Ko, H; Lee, H; Yon, DK; Lee, WH; Kim, TS; Kim, KW; Lee, J","Development and validation of a deep learning model to diagnose COVID-19 using time-series heart rate values before the onset of symptoms","JOURNAL OF MEDICAL VIROLOGY","","0146-6615","10.1002/jmv.28462","","One of the effective ways to minimize the spread of COVID-19 infection is to diagnose it as early as possible before the onset of symptoms. In addition, if the infection can be simply diagnosed using a smartwatch, the effectiveness of preventing the spread will be greatly increased. In this study, we aimed to develop a deep learning model to diagnose COVID-19 before the onset of symptoms using heart rate (HR) data obtained from a smartwatch. In the deep learning model for the diagnosis, we proposed a transformer model that learns HR variability patterns in presymptom by tracking relationships in sequential HR data. In the cross-validation (CV) results from the COVID-19 unvaccinated patients, our proposed deep learning model exhibited high accuracy metrics: sensitivity of 84.38%, specificity of 85.25%, accuracy of 84.85%, balanced accuracy of 84.81%, and area under the receiver operating characteristics (AUROC) of 0.8778. Furthermore, we validated our model using external multiple datasets including healthy subjects, COVID-19 patients, as well as vaccinated patients. In the external healthy subject group, our model also achieved high specificity of 77.80%. In the external COVID-19 unvaccinated patient group, our model also provided similar accuracy metrics to those from the CV: balanced accuracy of 87.23% and AUROC of 0.8897. In the COVID-19 vaccinated patients, the balanced accuracy and AUROC dropped by 66.67% and 0.8072, respectively. The first finding in this study is that our proposed deep learning model can simply and accurately diagnose COVID-19 patients using HRs obtained from a smartwatch before the onset of symptoms. The second finding is that the model trained from unvaccinated patients may provide less accurate diagnosis performance compared with the vaccinated patients. The last finding is that the model trained in a certain period of time may provide degraded diagnosis performances as the virus continues to mutate.","2023-02","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","2","95","","","","","","","","","","English","","","","WOS:001034949300118","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","COVID-19; deep learning; early diagnosis; heart rate; heart rate variability; smartwatch; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YVYJ2KW2","journalArticle","2024","Islam, MR; Rahman, MM; Ali, MS; Nafi, AA; Alam, MS; Godder, TK; Miah, MS; Islam, MK","Enhancing breast cancer segmentation and classification: An Ensemble Deep Convolutional Neural Network and U-net approach on ultrasound images","MACHINE LEARNING WITH APPLICATIONS","","2666-8270","10.1016/j.mlwa.2024.100555","","Breast cancer is a condition where the irregular growth of breast cells occurs uncontrollably, leading to the formation of tumors. It poses a significant threat to women's lives globally, emphasizing the need for enhanced methods of detecting and categorizing the disease. In this work, we propose an Ensemble Deep Convolutional Neural Network (EDCNN) model that exhibits superior accuracy compared to several transfer learning models and the Vision Transformer model. Our EDCNN model integrates the strengths of the MobileNet and Xception models to improve its performance in breast cancer detection and classification. We employ various preprocessing techniques, including image resizing, data normalization, and data augmentation, to prepare the data for analysis. By following these measures, the formatting is optimized, and the model's capacity to make generalizations is improved. We trained and evaluated our proposed EDCNN model using ultrasound images, a widely available modality for breast cancer imaging. The outcomes of our experiments illustrate that the EDCNN model attains an exceptional accuracy of 87.82% on Dataset 1 and 85.69% on Dataset 2, surpassing the performance of several well-known transfer learning models and the Vision Transformer model. Furthermore, an AUC value of 0.91 on Dataset 1 highlights the robustness and effectiveness of our proposed model. Moreover, we highlight the incorporation of the Grad-CAM Explainable Artificial Intelligence (XAI) technique to improve the interpretability and transparency of our proposed model. Additionally, we performed image segmentation using the U-Net segmentation technique on the input ultrasound images. This segmentation process allowed for the identification and isolation of specific regions of interest, facilitating a more comprehensive analysis of breast cancer characteristics. In conclusion, the study presents a creative approach to detecting and categorizing breast cancer, demonstrating the superior performance of the EDCNN model compared to well-established transfer learning models. Through advanced deep learning techniques and image segmentation, this study contributes to improving diagnosis and treatment outcomes in breast cancer.","2024-06","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","16","","","","","","","","","","English","","","","WOS:001239561900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","Breast cancer; Ensemble model; Preprocessing; Segmentation; U -net model; Ultrasound images","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CXCG6IMF","journalArticle","2023","Varma, S; Peter, JD","Enhanced transformer model for video caption generation","EXPERT SYSTEMS","","0266-4720","10.1111/exsy.13392","","Automatic Video captioning system is a method of describing the content in a video by analysing its visual aspects with regard to space and time and producing a meaningful caption that explains the video. A decade of research in this area has resulted in a steep growth in the quality and appropriateness of the generated caption compared with the expected result. The research has been driven from the very basic method to most advanced transformer method. Machine generated caption of a video must be adhering to many expected standards. For humans, this task may be a trivial one, however its not the same for a machine to analyse the content and generate a semantically coherent description for it. The caption which is generated in a natural language must also adhere to its lexical and syntactical structure. The video captioning process is a culmination of computer vision and natural language processing tasks. Commencing with template based conventional approach, it has surpassed statistical method, traditional deep learning approaches and is now in the trend of using transformers. This work made an extensive study of the literature and has proposed an improved transformer-based architecture for video captioning process. The transformer architecture made use of an encoder and decoder model that has two and three sublayers respectively. Multi-head self attention and cross attention are part of the model which bring about very beneficial results. The decoder is auto-regressive and uses a masked layer to prevent the model from foreseeing future words in the caption. An enhanced encoder-decoder Transformer model with CNN for feature extraction has been used in our work. This model captures the long-range dependencies and temporal relationships more effectively. The model has been evaluated with benchmark datasets and compared with state-of-the-art methods and found to be slightly better in the performance. The performance scores are slightly varying for BLEU, METEOR, ROUGE and CIDEr. Furthermore, we propose the idea of curriculum learning if incorporated can improve the results again.","2023-07-05","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","","","","","","","","","","","English","","","","WOS:001022848400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","curriculum learning; deep learning; encoder-decoder; engineering applications; neural networks; transformer; video caption","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8UEFH38Z","journalArticle","2023","Kamble, T; Deokar, S; Wadne, VS; Gadekar, DP; Vanjari, HB; Mange, P","Predictive Resource Allocation Strategies for Cloud Computing Environments Using Machine Learning","JOURNAL OF ELECTRICAL SYSTEMS","","1112-5209","","","Cloud computing revolutionizes fast-changing technology. Companies' computational resource use is changing. Businesses can quickly adapt to changing market conditions and operational needs with cloud-based solutions' adaptability, scalability, and cost-efficiency. IT operations and service delivery have changed due to widespread computational resource access. Cloud computing efficiently allocates resources in cloud environments, making it crucial to this transformation. Resource allocation impacts efficiency, cost, performance, and SLAs. Users and providers can allocate cloud resources based on workloads using elasticity, scalability, and on-demand provisioning. IT economics and operational effectiveness have changed due to rapid and flexible resource allocation. Proactive versus reactive resource allocation is key to understanding cloud resource management challenges and opportunities. Reactive strategies allocate resources only when shortages or surpluses occur at demand. This responsive strategy often leads to inefficiencies like over- or under-allocation, which raises costs and lowers performance. Predictive analysis and workload forecasting predict resource needs in proactive resource allocation. Optimize resource use to avoid shortages and over-provisioning. Attention has been drawn to proactive predictive resource allocation. These methods predict resource needs using historical data, machine learning, and predictive analytics. Predictive strategies optimize resource allocation by considering future decisions. Reduced bottlenecks boost user satisfaction and lower operational costs. Matching resource distribution to workloads optimizes cloud resource management. Resource allocation prediction improves with deep learning. CNN, LSTM, and Transformer cloud resource forecasting algorithms are promising. New tools for accurate and flexible workload predictions have come from their ability to spot intricate patterns in historical data. This paper compares CNN, LSTM, and Transformer deep learning algorithms for cloud computing resource allocation forecasting. This study determines the best predictive accuracy and workload ada1ptability algorithm using Google Cluster Data (GCD). The study evaluates upgrading cloud computing resource allocation with the Transformer model. This study advances predictive resource allocation strategies, which can help cloud service providers and organizations improve resource utilization, cost-effectiveness, and performance in the face of rapid technological change.","2023-06","2025-02-26 20:39:15","2025-02-26 20:39:15","","68-77","","2","19","","","","","","","","","","English","","","","WOS:001166468300008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Cloud Computing; Deep Learning Algorithms; Predictive Strategies; Resource Allocation; Transformer Model.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K562FTYW","journalArticle","2024","Zhang, JY; Gao, J; Gao, FZ","Time series land subsidence monitoring and prediction based on SBAS-InSAR and GeoTemporal transformer model","EARTH SCIENCE INFORMATICS","","1865-0473","10.1007/s12145-024-01487-0","","Land subsidence, the loss of elevation of the earth's surface caused by natural and human-induced factors, has become a significant global concern. It poses substantial threats to urban planning, construction, and sustainable development. Monitoring and predicting regional land subsidence are particularly crucial. Interferometric Synthetic Aperture Radar (InSAR) and deep learning provide valuable insights into monitoring and predicting land subsidence. However, methods for accurate and long-term monitoring and predicting time series land subsidence still have limitations. Firstly, most models only utilize historical data and overlook the combined effects of various factors, including human activities and urbanization. Secondly, the spatiotemporal correlation of subsidence across different locations and times is underestimated. Thirdly, the nonlinearity of land subsidence is not adequately addressed. To address these challenges, this study assesses land deformation patterns from January 2018 to December 2022, using Sentinel-1 InSAR data processed through Small Baseline Subset-InSAR (SBAS-InSAR). The result shows that the annual average deformation rate ranged from -6.39 to 8.27 mm/year, with maximum cumulative subsidence and uplift of 27.62 mm and 36.62 mm, respectively. Subsequently, a GeoTemporal Transformer (GTformer) model based on the Transformer model is proposed. It captures nonlinearities and spatiotemporal correlations between land subsidence and influencing factors by generating spatiotemporal distance matrices. The results demonstrate the efficacy of the GTformer model in improving prediction accuracy by incorporating urbanization factors and constructing spatiotemporal distance matrices. Compared with traditional machine learning models, the R2 of GTformer has increased by at least 14.6%, and compared with the standard Transformer, it has increased by 4%. The predictions closely align with observed subsidence patterns, highlighting the reliability. Moreover, this study underscores the critical role of urbanization factors in land subsidence mechanisms. The GTformer model provides a novel approach that integrates multiple factors and spatiotemporal correlation to predict land subsidence. The methodology offers a valuable tool for urban planners and decision-makers to effectively manage urban development and mitigate geological disaster risks.","2024-12-01","2025-02-26 20:39:15","2025-02-26 20:39:15","","5899-5911","","6","17","","","","","","","","","","English","","","","WOS:001313567300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","GROUNDWATER; InSAR; Land subsidence; LICSAR; RADAR INTERFEROMETRY; Spatiotemporal heterogeneity; Time series; Transformer; WEIGHTED REGRESSION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TM73IX9A","journalArticle","2021","Niimi, K; Fujimoto, A; Kano, Y; Otsuki, Y; Enoki, H; Okanishi, T","Speech Analysis Using Artificial Intelligence as a Peri-Operative Evaluation: A Case Report of a Patient with Temporal Lobe Epilepsy Secondary to Tuberous Sclerosis Complex Who Underwent Epilepsy Surgery","BRAIN SCIENCES","","2076-3425","10.3390/brainsci11050568","","Background: Improved conversational fluency is sometimes identified postoperatively in patients with epilepsy, but improvements can be difficult to assess using tests such as the intelligence quotient (IQ) test. Evaluation of pre- and postoperative differences might be considered subjective at present because of the lack of objective criteria. Artificial intelligence (AI) could possibly be used to make the evaluations more objective. The aim of this case report is thus to analyze the speech of a young female patient with epilepsy before and after surgery. Method: The speech of a nine-year-old girl with epilepsy secondary to tuberous sclerosis complex is recorded during interviews one month before and two months after surgery. The recorded speech is then manually transcribed and annotated, and subsequently automatically analyzed using AI software. IQ testing is also conducted on both occasions. The patient remains seizure-free for at least 13 months postoperatively. Results: There are decreases in total interview time and subjective case markers per second, whereas there are increases in morphemes and objective case markers per second. Postoperatively, IQ scores improve, except for the Perceptual Reasoning Index. Conclusions: AI analysis is able to identify differences in speech before and after epilepsy surgery upon an epilepsy patient with tuberous sclerosis complex.","2021-05","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","5","11","","","","","","","","","","English","","","","WOS:000653560600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","artificial intelligence; epilepsy; intelligence quotient; OUTCOMES; PERCEPTION; QUALITY-OF-LIFE; speech analysis; surgery; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F8K6Z82R","journalArticle","2025","Cui, Y; Kim, E; Yan, SZ; Yu, Q","Wheel flat detection using long short-term memory and transformer models with a 1:10 scale railway test rig","ADVANCES IN MECHANICAL ENGINEERING","","1687-8132","10.1177/16878132251314988","","In railway systems, the detection of wheel flats is essential for ensuring safety and reducing maintenance costs. This study compares the performance of Long Short-Term Memory and Transformer models in detecting wheel flats using data from a 1:10 scale railway test rig. The findings indicate that the Transformer model significantly outperforms the Long Short-Term Memory model, especially when feature-level sensor fusion is employed, achieving an average error as low as 0.0069 mm with percentage of error at 5.30%, minimizing the maximum error to 0.0985 mm. The study emphasizes the potential of Transformer models in railway diagnostics, particularly for applications requiring high accuracy and reliability. The insights gained from this research have practical implications for improving the precision of wheel flat detection in real-world railway operations, enhancing both safety and efficiency.","2025-01","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","1","17","","","","","","","","","","English","","","","WOS:001406126200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","LSTM; scaled test rig; sensor fusion; transformer; Wheel flat","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BGWHZIZ4","journalArticle","2024","Cavalcanti, AP; Mello, RF; Gasevic, D; Freitas, F","Towards Explainable Prediction Feedback Messages Using BERT","INTERNATIONAL JOURNAL OF ARTIFICIAL INTELLIGENCE IN EDUCATION","","1560-4292","10.1007/s40593-023-00375-w","","Educational feedback is a crucial factor in the student's learning journey, as through it, students are able to identify their areas of deficiencies and improve self-regulation. However, the literature shows that this is an area of great dissatisfaction, especially in higher education. Providing effective feedback becomes an increasingly challenging task as the number of students increases. Therefore, this article explores the use of automated content analysis to examine instructor feedback based on reputable models from the literature that provide best practices and classify feedback at different levels. For this, this article proposes using the transformer model BERT to classify feedback messages. The proposed method outperforms previous works by up to 35.71% in terms of Cohen's kappa. Finally, this study adopted an explainable artificial intelligence to provide insights into the most predictive features for each classifier analyzed.","2024-09","2025-02-26 20:39:15","2025-02-26 20:39:15","","1046-1071","","3","34","","","","","","","","","","English","","","","WOS:001099992900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","BERT; Explainable artificial intelligence; Feedback; FORMATIVE ASSESSMENT; NEURAL-NETWORKS; Online learning; STUDENTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7XE3KDJ4","journalArticle","2022","Pordanjani, SR; Naïdjate, M; Bracikowski, N; Fratila, M; Mahseredjian, J; Rezaei-Zare, A","Electromagnetic Modeling of Transformers in EMT-Type Software by a Circuit-Based Method","IEEE TRANSACTIONS ON POWER DELIVERY","","0885-8977","10.1109/TPWRD.2022.3177137","","This work proposes a fully circuit-based method for modelling electrical transformers. This method not only offers the advantages of circuit-based methods and can be implemented in electromagnetic transient (EMT) type software, but it can also provide a detailed representation of transformers, comparable to the finite element method (FEM). The proposed method enables a detailed geometrical modelling, as well as representation of magnetic flux paths and consideration of iron core saturation. It can be implemented in EMT-type software to see the effect of power networks on transformers. In addition, the proposed method can represent internal faults in transformers. The problem is constrained to a 2-D domain, which is often used in FEMs to represent the magnetic behavior of power equipment. Finite element analysis based on ANSYS Maxwell is used to verify the proposed method.","2022-12","2025-02-26 20:39:15","2025-02-26 20:39:15","","5402-5413","","6","37","","","","","","","","","","English","","","","WOS:000891435100084","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","electromagnetic transients; FIELD; finite element method (FEM); magnetic circuits; MID-FREQUENCY TRANSIENTS; Transformer model; winding fault","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"78U83V7M","journalArticle","2024","Taghibeyglou, B; Kaufman, JM; Fossat, Y","Machine Learning-Enabled Hypertension Screening Through Acoustical Speech Analysis: Model Development and Validation","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3443688","","Hypertension, referred to as the ""silent killer"" by the World Health Organization, affects over 35% of the global population. Early diagnosis and behavioural interventions have been shown to mitigate morbidity and mortality associated with this condition. However, conventional methods of measuring blood pressure and accordingly identifying hypertension, such as sphygmomanometry, require technical expertise and may not be readily accessible, particularly in remote or underserved areas. Automatic blood pressure measurement devices offer an alternative but are often inaccessible in certain populations. In this study, we propose a novel framework for detecting hypertension through acoustic analysis of speech. By recording speech across multiple sessions and analyzing its temporal and spectral characteristics, we aim to identify indicators of hypertension. We explore two thresholds for labeling individuals with hypertension: 1) systolic blood pressure (SBP) >= 135 mmHg or diastolic blood pressure (DBP) >= 85 mmHg and 2) SBP >= 140 mmHg or DBP >= 90 mmHg. Our study involved 245 participants, including 91 females. We developed predictive models for each gender and assessed their performance using leave-one-subject-out validation. For the first threshold, the balanced accuracy achieved was 84% for females and 77% for males. For the second threshold, the corresponding balanced accuracies were 63% for females and 86% for males. These results demonstrate the potential of utilizing speech-based representations for non-invasive screening of hypertension.","2024","2025-02-26 20:39:15","2025-02-26 20:39:15","","123621-123629","","","12","","","","","","","","","","English","","","","WOS:001311222200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Accuracy; Acoustic representation; Acoustics; BLOOD-PRESSURE; health monitoring; HEART-FAILURE; hypertension; Hypertension; machine learning; Organizations; Predictive models; speech analysis; Speech analysis; Vectors; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HBV6LNX7","journalArticle","2021","Ampomah, IKE; McClean, S; Hawe, G","Dual contextual module for neural machine translation","MACHINE TRANSLATION","","0922-6567","10.1007/s10590-021-09282-0","","Self-attention-based encoder-decoder frameworks have drawn increasing attention in recent years. The self-attention mechanism generates contextual representations by attending to all tokens in the sentence. Despite improvements in performance, recent research argues that the self-attention mechanism tends to concentrate more on the global context with less emphasis on the contextual information available within the local neighbourhood of tokens. This work presents the Dual Contextual (DC) module, an extension of the conventional self-attention unit, to effectively leverage both the local and global contextual information. The goal is to further improve the sentence representation ability of the encoder and decoder subnetworks, thus enhancing the overall performance of the translation model. Experimental results on WMT'14 English-German (En -> De) and eight IWSLT translation tasks show that the DC module can further improve the translation performance of the Transformer model.","2021-12","2025-02-26 20:39:15","2025-02-26 20:39:15","","571-593","","4","35","","","","","","","","","","English","","","","WOS:000706564800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Deep neural representation learning; Global contexts; Local contexts; Self-attention networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"54HF8I2Z","journalArticle","2024","Chang, SW; Kim, DS","Scalable Transformer Accelerator with Variable Systolic Array for Multiple Models in Voice Assistant Applications","ELECTRONICS","","2079-9292","10.3390/electronics13234683","","Transformer model is a type of deep learning model that has quickly become fundamental in natural language processing (NLP) and other machine learning tasks. Transformer hardware accelerators are usually designed for specific models, such as Bidirectional Encoder Representations from Transformers (BERT), and vision Transformer models, like the ViT. In this study, we propose a Scalable Transformer Accelerator Unit (STAU) for multiple models, enabling efficient handling of various Transformer models used in voice assistant applications. Variable Systolic Array (VSA) centralized design, along with control and data preprocessing in embedded processors, enables matrix operations of varying sizes. In addition, we propose an efficient variable structure and a row-wise data input method for natural language processing where the word count changes. The proposed scalable Transformer accelerator accelerates text summarization, audio processing, image search, and generative AI used in voice assistance.","2024-12","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","23","13","","","","","","","","","","English","","","","WOS:001377882800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","accelerator; data preprocessing; quantization; softmax; systolic array; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RB8UHA3E","journalArticle","2024","Jiang, T; Zhou, ZJ; Zhang, ZD; Cao, SQ; Wang, YD; Liu, YD","MEHunter: transformer-based mobile element variant detection from long reads","BIOINFORMATICS","","1367-4803","10.1093/bioinformatics/btae557","","Mobile genetic elements (MEs) are heritable mutagens that significantly contribute to genetic diseases. The advent of long-read sequencing technologies, capable of resolving large DNA fragments, offers promising prospects for the comprehensive detection of ME variants (MEVs). However, achieving high precision while maintaining recall performance remains challenging mainly brought by the variable length and similar content of MEV signatures, which are often obscured by the noise in long reads. Here, we propose MEHunter, a high-performance MEV detection approach utilizing a fine-tuned transformer model adept at identifying potential MEVs with fragmented features. Benchmark experiments on both simulated and real datasets demonstrate that MEHunter consistently achieves higher accuracy and sensitivity than the state-of-the-art tools. Furthermore, it is capable of detecting novel potentially individual-specific MEVs that have been overlooked in published population projects.Availability and implementation MEHunter is available from https://github.com/120L021101/MEHunter.","2024-09-20","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","9","40","","","","","","","","","","English","","","","WOS:001316622400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;12</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TATBP479","journalArticle","2023","Kang, ZH; Xue, JZ; Lai, CS; Wang, Y; Yuan, HL; Xu, FY","Vision Transformer-Based Photovoltaic Prediction Model","ENERGIES","","1996-1073","10.3390/en16124737","","Sensing the cloud movement information has always been a difficult problem in photovoltaic (PV) prediction. The information used by current PV prediction methods makes it challenging to accurately perceive cloud movements. The obstruction of the sun by clouds will lead to a significant decrease in actual PV power generation. The PV prediction network model cannot respond in time, resulting in a significant decrease in prediction accuracy. In order to overcome this problem, this paper develops a visual transformer model for PV prediction, in which the target PV sensor information and the surrounding PV sensor auxiliary information are used as input data. By using the auxiliary information of the surrounding PV sensors and the spatial location information, our model can sense the movement of the cloud in advance. The experimental results confirm the effectiveness and superiority of our model.","2023-06","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","12","16","","","","","","","","","","English","","","","WOS:001014217300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","auxiliary information; FORECAST; photovoltaic prediction; POWER; SVM; visual transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4PHVPZ72","journalArticle","2022","Chi, C; Yang, F; Ren, ZX","Reduced Order Model Based on Combined POD/LDEIM-Q for Nonlinear Thermoelectric Coupling","IEEE TRANSACTIONS ON MAGNETICS","","0018-9464","10.1109/TMAG.2022.3185980","","The insulation evaluation in converter transformer is a nonlinear thermoelectric coupling problem whose numerical solution is time consuming. To decrease the computation cost, a discrete empirical interpolation method (DEIM) is usually utilized to approximate the nonlinear term with a reduced order model (ROM), but it suffers sometimes from the unstable convergence problem. In this article, a local DEIM based on QR factorization (LDEIM-Q) is proposed. It has a better error bound and can avoid the unexpected instabilities. The LDEIM-Q is combined with the proper orthogonal decomposition (POD) to deal with the nonlinear thermoelectric coupling. A converter transformer model is taken as an example to validate our method in terms of accuracy and efficiency.","2022-09","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","9","58","","","","","","","","","","English","","","","WOS:000845075000102","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;14</p>","","","Couplings; Electric fields; EMPIRICAL INTERPOLATION METHOD; Finite element analysis; Mathematical models; nonlinear thermoelectric coupling; Oil insulation; Power transformer insulation; Read only memory; reduced order modeling; REDUCTION; Voltage","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SD4QN7BS","journalArticle","2022","De-Dios-Flores, I; Garcia, M","A computational psycholinguistic evaluation of the syntactic abilities of Galician BERT models at the interface of dependency resolution and training time","PROCESAMIENTO DEL LENGUAJE NATURAL","","1135-5948","10.26342/2022-69-1","","This paper explores the ability of Transformer models to capture subject-verb and noun-adjective agreement dependencies in Galician. We conduct a series of word prediction experiments in which we manipulate dependency length together with the presence of an attractor noun that acts as a lure. First, we evaluate the overall performance of the existing monolingual and multilingual models for Galician. Secondly, to observe the effects of the training process, we compare the different degrees of achievement of two monolingual BERT models at different training points. We also release their checkpoints and propose an alternative evaluation metric. Our results confirm previous findings by similar works that use the agreement prediction task and provide interesting insights into the number of training steps required by a Transformer model to solve long-distance dependencies.","2022-09","2025-02-26 20:39:15","2025-02-26 20:39:15","","15-26","","69","","","","","","","","","","","English","","","","WOS:000898606900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","agreement dependencies; BERT models; Galician; targeted syntactic evaluation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JXPC99EA","journalArticle","2022","Kwon, S; Lee, GG","Self-feeding training method for semi-supervised grammatical error correction","COMPUTER SPEECH AND LANGUAGE","","0885-2308","10.1016/j.csl.2022.101435","","Grammatical error correction (GEC) has been successful with deep and complex neural machine translation models, but the annotated data to train the model are scarce. We propose a novel self-feeding training method that generates incorrect sentences from freely available correct sentences. The proposed training method can generate appropriate wrong sentences from unlabeled sentences, using a data generation model trained as an autoencoder. It can also add artificial noise to correct sentences to automatically generate incorrect sentences. We show that the GEC models trained with the self-feeding training method are successful without extra annotated data or deeper neural network-based models, achieving F-0.5 score of 0.5982 on the CoNLL-2014 Shared Task test data with a transformer model. The results also show that fully unlabeled training is possible for data-scarce domains and languages.","2022-01","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","77","","","","","","","","","","English","","","","WOS:000858986000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Data augmentation; Grammatical error correction; Natural language processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4YLFT5KX","journalArticle","2023","Aleman, E; Micozzi, JP; Vera, SV","Congressional Committees, Electoral Connections, and Legislative Speech","POLITICAL RESEARCH QUARTERLY","","1065-9129","10.1177/10659129221119200","","This article examines the effects of committee specialization and district characteristics on speech participation by topic and congressional forum. It argues that committee specialization should increase speech participation during legislative debates, while district characteristics should affect the likelihood of speech participation in non-lawmaking forums. To examine these expectations, we analyze over 100,000 speeches delivered in the Chilean Chamber of Deputies between 1990 and 2018. To carry out our topic classification task, we utilize the recently developed state-of-the-art multilingual Transformer model XLM-RoBERTa. Consistent with informational theories, we find that committee specialization is a significant predictor of speech participation in legislative debates. In addition, consistent with theories purporting that legislative speech serves as a vehicle for the electoral connection, we find that district characteristics have a significant effect on speech participation in non-lawmaking forums.","2023-06","2025-02-26 20:39:15","2025-02-26 20:39:15","","994-1011","","2","76","","","","","","","","","","English","","","","WOS:000841971100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Chile; CHILE; committees; DETERMINANTS; electoral connection; legislative speech; POSITION; PRESIDENTIAL SYSTEMS; specialization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2FFFEJQS","journalArticle","2022","Hrúz, M; Gruber, I; Kanis, J; Bohácek, M; Hlavác, M; Krnoul, Z","One Model is Not Enough: Ensembles for Isolated Sign Language Recognition","SENSORS","","1424-8220","10.3390/s22135043","","In this paper, we dive into sign language recognition, focusing on the recognition of isolated signs. The task is defined as a classification problem, where a sequence of frames (i.e., images) is recognized as one of the given sign language glosses. We analyze two appearance-based approaches, I3D and TimeSformer, and one pose-based approach, SPOTER. The appearance-based approaches are trained on a few different data modalities, whereas the performance of SPOTER is evaluated on different types of preprocessing. All the methods are tested on two publicly available datasets: AUTSL and WLASL300. We experiment with ensemble techniques to achieve new state-of-the-art results of 73.84% accuracy on the WLASL300 dataset by using the CMA-ES optimization method to find the best ensemble weight parameters. Furthermore, we present an ensembling technique based on the Transformer model, which we call Neural Ensembler.","2022-07","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","13","22","","","","","","","","","","English","","","","WOS:000824167200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;20<br/>Total Times Cited:&nbsp;&nbsp;20<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","CNN; ensemble; sign language recognition; TASK; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RAPWGRJI","journalArticle","2023","Hassanian, R; Myneni, H; Helgadóttir, A; Riedel, M","Deciphering the dynamics of distorted turbulent flows: Lagrangian particle tracking and chaos prediction through transformer-based deep learning models","PHYSICS OF FLUIDS","","1070-6631","10.1063/5.0157897","","Turbulent flow is a complex and vital phenomenon in fluid dynamics, as it is the most common type of flow in both natural and artificial systems. Traditional methods of studying turbulent flow, such as computational fluid dynamics and experiments, have limitations such as high computational costs, experiment costs, and restricted problem scales and sizes. Recently, artificial intelligence has provided a new avenue for examining turbulent flow, which can help improve our understanding of its flow features and physics in various applications. Strained turbulent flow, which occurs in the presence of gravity in situations such as combustion chambers and shear flow, is one such case. This study proposes a novel data-driven transformer model to predict the velocity field of turbulent flow, building on the success of this deep sequential learning technique in areas such as language translation and music. The present study applied this model to experimental work by Hassanian et al., who studied distorted turbulent flow with a specific range of Taylor microscale Reynolds numbers 100 < R e ? < 120. The flow underwent a vertical mean strain rate of 8 s( - 1 )in the presence of gravity. The Lagrangian particle tracking technique recorded every tracer particle's velocity field and displacement. Using this dataset, the transformer model was trained with different ratios of data and used to predict the velocity of the following period. The model's predictions significantly matched the experimental test data, with a mean absolute error of 0.002-0.003 and an R-2 score of 0.98. Furthermore, the model demonstrated its ability to maintain high predictive performance with less training data, showcasing its potential to predict future turbulent flow velocity with fewer computational resources. To assess the model, it has been compared to the long short-term memory and gated recurrent units model. High-performance computing machines, such as JUWELS-DevelBOOSTER at the Juelich Supercomputing Center, were used to train and run the model for inference.","2023-07","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","7","35","","","","","","","","","","English","","","","WOS:001027280500012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","FIELD; UNSTEADY-FLOW","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6KHJK8B3","journalArticle","2024","Han, XM; Feng, JX; Xu, HM; Du, SY; Li, JC","A hypergraph transformer method for brain disease diagnosis","FRONTIERS IN MEDICINE","","2296-858X","10.3389/fmed.2024.1496573","","Objective To address the high-order correlation modeling and fusion challenges between functional and structural brain networks.Method This paper proposes a hypergraph transformer method for modeling high-order correlations between functional and structural brain networks. By utilizing hypergraphs, we can effectively capture the high-order correlations within brain networks. The Transformer model provides robust feature extraction and integration capabilities that are capable of handling complex multimodal brain imaging.Results The proposed method is evaluated on the ABIDE and ADNI datasets. It outperforms all the comparison methods, including traditional and graph-based methods, in diagnosing different types of brain diseases. The experimental results demonstrate its potential and application prospects in clinical practice.Conclusion The proposed method provides new tools and insights for brain disease diagnosis, improving accuracy and aiding in understanding complex brain network relationships, thus laying a foundation for future brain science research.","2024-11-14","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","11","","","","","","","","","","English","","","","WOS:001365272000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","brain disease diagnosis; brain network; high-order correlation; hypergraph computation; NETWORK; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8YXQISIW","journalArticle","2024","Drikakis, D; Kokkinakis, IW; Fung, D; Spottswood, SM","Self-supervised transformers for turbulent flow time series","PHYSICS OF FLUIDS","","1070-6631","10.1063/5.0214468","","There has been a rapid advancement in deep learning models for diverse research fields and, more recently, in fluid dynamics. This study presents self-supervised transformers' deep learning for complex turbulent flow signals across various test problems. Self-supervision aims to leverage the ability to extract meaningful representations from sparse flow time-series data to improve the transformer model accuracy and computational efficiency. Two high-speed flow cases are considered: a supersonic compression ramp and shock-boundary layer interaction over a statically deformed surface. Several training scenarios are investigated across the two different supersonic configurations. The training data concern wall pressure fluctuations due to their importance in aerodynamics, aeroelasticity, noise, and acoustic fatigue. The results provide insight into transformers, self-supervision, and deep learning with application to complex time series. The architecture is extendable to other research domains where time series data are essential.","2024-06","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","6","36","","","","","","","","","","English","","","","WOS:001239606400015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","HIGH-ORDER; LARGE-EDDY SIMULATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B7RJ69RV","journalArticle","2024","Kwon, G; Lee, H","Multi-scale recurrent transformer model for predicting KSTAR PF superconducting coil temperature","PLASMA PHYSICS AND CONTROLLED FUSION","","0741-3335","10.1088/1361-6587/ad3671","","Superconducting coils play a critical role in a superconducting-based nuclear fusion device. As the temperature of superconducting magnets increases with a change in current, it is important to predict their temperature to prevent excessive temperature rise of coils and operate them efficiently. We present multi-scale recurrent transformer system, a deep learning model for forecasting the temperature of superconducting coils. Our system recurrently predicts future temperature data of the superconducting coil using the previous data obtained from a multi-scale Korea Superconducting Tokamak Advanced Research poloidal field coil dataset and latent data calculated from previous time step. We apply a multi-scale temperature downsampling approach in our model to effectively learn both the details and the overall structure of the temperature data. We demonstrate the effectiveness of our model through experiments and comparisons with existing models.","2024-05-01","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","5","66","","","","","","","","","","English","","","","WOS:001196323200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;14</p>","","","deep learning; prediction; superconducting coil temperature","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E2RN9UYG","journalArticle","2023","Alnuqaydan, A; Gleyzer, S; Prosper, H","SYMBA: symbolic computation of squared amplitudes in high energy physics with machine learning","MACHINE LEARNING-SCIENCE AND TECHNOLOGY","","2632-2153","10.1088/2632-2153/acb2b2","","The cross section is one of the most important physical quantities in high-energy physics and the most time consuming to compute. While machine learning has proven to be highly successful in numerical calculations in high-energy physics, analytical calculations using machine learning are still in their infancy. In this work, we use a sequence-to-sequence model, specifically, a transformer, to compute a key element of the cross section calculation, namely, the squared amplitude of an interaction. We show that a transformer model is able to predict correctly 97.6% and 99% of squared amplitudes of quantum chromodynamics and quantum electrodynamics processes, respectively, at a speed that is up to orders of magnitude faster than current symbolic computation frameworks. We discuss the performance of the current model, its limitations and possible future directions for this work.","2023-03-01","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","1","4","","","","","","","","","","English","","","","WOS:000920938400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","high energy physics; machine learning; physics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZRP3MCMX","journalArticle","2022","Wang, XQ; Yao, CS; Zhang, Y; Yu, JH; Qiao, HR; Zhang, CY; Wu, YJ; Bai, RR; Duan, HL","From theory to experiment: transformer-based generation enables rapid discovery of novel reactions","JOURNAL OF CHEMINFORMATICS","","1758-2946","10.1186/s13321-022-00638-z","","Deep learning methods, such as reaction prediction and retrosynthesis analysis, have demonstrated their significance in the chemical field. However, the de novo generation of novel reactions using artificial intelligence technology requires further exploration. Inspired by molecular generation, we proposed a novel task of reaction generation. Herein, Heck reactions were applied to train the transformer model, a state-of-art natural language process model, to generate 4717 reactions after sampling and processing. Then, 2253 novel Heck reactions were confirmed by organizing chemists to judge the generated reactions. More importantly, further organic synthesis experiments were performed to verify the accuracy and feasibility of representative reactions. The total process, from Heck reaction generation to experimental verification, required only 15 days, demonstrating that our model has well-learned reaction rules in-depth and can contribute to novel reaction discovery and chemical space exploration.","2022-09-02","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","1","14","","","","","","","","","","English","","","","WOS:000849207400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","ARYLATION; Deep learning; DESIGN; Heck reactions; MODEL; Reaction generation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LPB6X9BN","journalArticle","2024","Khalladi, SA; Ouessai, A; Benamara, NK; Keche, M","Efficient Road Traffic Video Congestion Classification Based on the Multi-Head Self-Attention Vision Transformer Model","TRANSPORT AND TELECOMMUNICATION JOURNAL","","1407-6160","10.2478/ttj-2024-0003","","Due to rapid population growth, traffic congestion has become one of the major issues in urban areas. The utilization of technology may help to address this issue. This paper proposes a new Multi-head Self-attention Vision Transformer (MSViT) based macroscopic approach, for road traffic congestion classification. To evaluate this approach, we use the UCSD (University of California San Diego) dataset that includes different weather conditions (clear, overcast and rainy) and different traffic scenarios (light, medium and heavy). The classification accuracy reached a high level of 99.76% with this dataset and 99.37% when night-mode frames are added to it. The proposed MSViT based method outperforms the state-of-the-art macroscopic and microscopic methods that have been evaluated using the same UCSD dataset, which makes it an efficient solution for traffic congestion prediction.","2024-02-01","2025-02-26 20:39:15","2025-02-26 20:39:15","","20-30","","1","25","","","","","","","","","","English","","","","WOS:001163195400004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","deep learning; macroscopic approach; multi-head self-attention; Road traffic classification; vision transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3D3B67GH","journalArticle","2023","Dong, H; Donegan, S; Shah, M; Chi, YJ","A lightweight transformer for faster and robust EBSD data collection","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-023-47936-6","","Three dimensional electron back-scattered diffraction (EBSD) microscopy is a critical tool in many applications in materials science, yet its data quality can fluctuate greatly during the arduous collection process, particularly via serial-sectioning. Fortunately, 3D EBSD data is inherently sequential, opening up the opportunity to use transformers, state-of-the-art deep learning architectures that have made breakthroughs in a plethora of domains, for data processing and recovery. To be more robust to errors and accelerate this 3D EBSD data collection, we introduce a two step method that recovers missing slices in an 3D EBSD volume, using an efficient transformer model and a projection algorithm to process the transformer's outputs. Overcoming the computational and practical hurdles of deep learning with scarce high dimensional data, we train this model using only synthetic 3D EBSD data with self-supervision and obtain superior recovery accuracy on real 3D EBSD data, compared to existing methods.","2023-12-01","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","1","13","","","","","","","","","","English","","","","WOS:001126964000008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","RECONSTRUCTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WZP49YWG","journalArticle","2024","Shang, J; Wu, ZH; Xiao, ZW; Zhang, YF; Wang, JB","BERT4Cache: a bidirectional encoder representations for data prefetching in cache","PEERJ COMPUTER SCIENCE","","2376-5992","10.7717/peerj-cs.2258","","Cache plays a crucial role in improving system response time, alleviating server pressure, and achieving load balancing in various aspects of modern information systems. The data prefetch and cache replacement algorithms are significant fi cant factors influencing fl uencing caching performance. Due to the inability to learn user interests and preferences accurately, existing rule-based and data mining caching algorithms fail to capture the unique features of the user access behavior sequence, resulting in low cache hit rates. In this article, we introduce BERT4Cache, an end-to-end bidirectional Transformer model with attention for data prefetch in cache. BERT4Cache enhances cache hit rates and ultimately improves cache performance by predicting the user's ' s imminent future requested objects and prefetching them into the cache. In our thorough experiments, we show that BERT4Cache achieves superior results in hit rates and other metrics compared to generic reactive and advanced proactive caching strategies.","2024-08-29","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","10","","","","","","","","","","English","","","","WOS:001302066100003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","fi cial intelligence; Neural networks; Text mining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6GZR4XS7","journalArticle","2024","Park, J; Jo, J; Yoon, S","Mass spectra prediction with structural motif-based graph neural networks","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-51760-x","","Mass spectra, which are agglomerations of ionized fragments from targeted molecules, play a crucial role across various fields for the identification of molecular structures. A prevalent analysis method involves spectral library searches, where unknown spectra are cross-referenced with a database. The effectiveness of such search-based approaches, however, is restricted by the scope of the existing mass spectra database, underscoring the need to expand the database via mass spectra prediction. In this research, we propose the Motif-based Mass Spectrum prediction Network (MoMS-Net), a GNN-based architecture to predict the mass spectra pattern utilizing the structural motif information of the molecule. MoMS-Net considers both a molecule and its substructures as a graph form, which facilitates the incorporation of long-range dependencies while using less memory compared to the graph transformer model. We evaluated our model over various types of mass spectra and showed the validity and superiority over the conventional models.","2024-01-16","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","1","14","","","","","","","","","","English","","","","WOS:001146669200021","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","PEPTIDES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X975AXBI","journalArticle","2024","Jojoa, M; Eftekhar, P; Nowrouzi-Kia, B; Garcia-Zapirain, B","Natural language processing analysis applied to COVID-19 open-text opinions using a distilBERT model for sentiment categorization","AI & SOCIETY","","0951-5666","10.1007/s00146-022-01594-w","","COVID-19 is a disease that affects the quality of life in all aspects. However, the government policy applied in 2020 impacted the lifestyle of the whole world. In this sense, the study of sentiments of people in different countries is a very important task to face future challenges related to lockdown caused by a virus. To contribute to this objective, we have proposed a natural language processing model with the aim to detect positive and negative feelings in open-text answers obtained from a survey in pandemic times. We have proposed a distilBERT transformer model to carry out this task. We have used three approaches to perform a comparison, obtaining for our best model the following average metrics: Accuracy: 0.823, Precision: 0.826, Recall: 0.793 and F1 Score: 0.803.","2024-06","2025-02-26 20:39:15","2025-02-26 20:39:15","","883-890","","3","39","","","","","","","","","","English","","","","WOS:000886192400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Deep learning; DistilBERT; Natural language processing; Sentiment analysis; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y5Z5SM8K","journalArticle","2023","Cui, YN; Chen, K; Zhang, LY; Wang, HT; Bai, L; Elliston, D; Ren, W","Atomic Positional Embedding-Based Transformer Model for Predicting the Density of States of Crystalline Materials","JOURNAL OF PHYSICAL CHEMISTRY LETTERS","","1948-7185","10.1021/acs.jpclett.3c02036","","The rapid advancement of machine learning has revolutionized quite a few science fields, leading to a surge in the development of highly efficient and accurate materials discovery methods. Recently, predictions of multiple related properties have received attention, with a particular emphasis on spectral properties, where the electronic density of states (DOS) stands out as the fundamental data with enormous potential to advance our understanding of crystalline materials. Leveraging the power of the Transformer framework, we introduce an Atomic Positional Embedding-Based Transformer (APET), which surpasses existing state-of-the-art models for predicting ab initio DOS. APET utilizes atomic periodical positions as its positional embedding, which incorporates all of the structural information in a crystal, providing a more complete and accurate representation. Furthermore, the interpretability of APET enables us to discover the underlying physical properties of materials with greater precision and accuracy.","2023-08-30","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","","","","","","","","","","","English","","","","WOS:001059048700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I2R79V3F","journalArticle","2023","Mei, XY; Liu, ZL; Singh, A; Lange, M; Boddu, P; Gong, JQX; Lee, J; DeMarco, C; Cao, CD; Platt, S; Sivakumar, G; Gross, B; Huang, MQ; Masseaux, J; Dua, S; Bernheim, A; Chung, MC; Deyer, T; Jacobi, A; Padilla, M; Fayad, ZA; Yang, Y","Interstitial lung disease diagnosis and prognosis using an AI system integrating longitudinal data","NATURE COMMUNICATIONS","","2041-1723","10.1038/s41467-023-37720-5","","For accurate diagnosis of interstitial lung disease (ILD), a consensus of radiologic, pathological, and clinical findings is vital. Management of ILD also requires thorough follow-up with computed tomography (CT) studies and lung function tests to assess disease progression, severity, and response to treatment. However, accurate classification of ILD subtypes can be challenging, especially for those not accustomed to reading chest CTs regularly. Dynamic models to predict patient survival rates based on longitudinal data are challenging to create due to disease complexity, variation, and irregular visit intervals. Here, we utilize RadImageNet pretrained models to diagnose five types of ILD with multimodal data and a transformer model to determine a patient's 3-year survival rate. When clinical history and associated CT scans are available, the proposed deep learning system can help clinicians diagnose and classify ILD patients and, importantly, dynamically predict disease progression and prognosis.","2023-04-20","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","1","14","","","","","","","","","","English","","","","WOS:001022525400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2C8AS3JU","journalArticle","2025","Nakamura, S; Yasuo, N; Sekijima, M","Molecular optimization using a conditional transformer for reaction-aware compound exploration with reinforcement learning","COMMUNICATIONS CHEMISTRY","","2399-3669","10.1038/s42004-025-01437-x","","Designing molecules with desirable properties is a critical endeavor in drug discovery. Because of recent advances in deep learning, molecular generative models have been developed. However, the existing compound exploration models often disregard the important issue of ensuring the feasibility of organic synthesis. To address this issue, we propose TRACER, which is a framework that integrates the optimization of molecular property optimization with synthetic pathway generation. The model can predict the product derived from a given reactant via a conditional transformer under the constraints of a reaction type. The molecular optimization results of an activity prediction model targeting DRD2, AKT1, and CXCR4 revealed that TRACER effectively generated compounds with high scores. The transformer model, which recognizes the entire structures, captures the complexity of the organic synthesis and enables its navigation in a vast chemical space while considering real-world reactivity constraints.","2025-02-08","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","1","8","","","","","","","","","","English","","","","WOS:001416629500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;91</p>","","","DESIGN; DRIVEN; GENERATION; LIBRARY; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VR96ZB32","journalArticle","2024","Sliwiak, P; Shah, SAA","Text-to-text generative approach for enhanced complex word identification","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2024.128501","","This paper presents a novel approach for solving the Complex Word Identification (CWI) task using the text-to- text generative model. The CWI task involves identifying complex words in text, which is a challenging Natural Language Processing task. To our knowledge, it is a first attempt to address CWI problem into text-to-text context. In this work, we propose a new methodology that leverages the power of the Transformer model to evaluate complexity of words in binary and probabilistic settings. We also propose a novel CWI dataset, which consists of 62,200 phrases, both complex and simple. We train and fine-tune our proposed model on our CWI dataset. We also evaluate its performance on separate test sets across three different domains. Our experimental results demonstrate the effectiveness of our proposed approach compared to state-of-the-art methods.","2024-12-28","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","","610","","","","","","","","","","English","","","","WOS:001313698500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","Complex word identification; Generative AI; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VJLM6AHU","journalArticle","2024","Wang, ZH; Yu, JQ; Gao, JH; Bai, Y; Wan, ZJ","MutaPT: A Multi-Task Pre-Trained Transformer for Classifying State of Disorders of Consciousness Using EEG Signal","BRAIN SCIENCES","","2076-3425","10.3390/brainsci14070688","","Deep learning (DL) has been demonstrated to be a valuable tool for classifying state of disorders of consciousness (DOC) using EEG signals. However, the performance of the DL-based DOC state classification is often challenged by the limited size of EEG datasets. To overcome this issue, we introduce multiple open-source EEG datasets to increase data volume and train a novel multi-task pre-training Transformer model named MutaPT. Furthermore, we propose a cross-distribution self-supervised (CDS) pre-training strategy to enhance the model's generalization ability, addressing data distribution shifts across multiple datasets. An EEG dataset of DOC patients is used to validate the effectiveness of our methods for the task of classifying DOC states. Experimental results show the superiority of our MutaPT over several DL models for EEG classification.","2024-07","2025-02-26 20:39:15","2025-02-26 20:39:15","","","","7","14","","","","","","","","","","English","","","","WOS:001276636300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","CONVOLUTIONAL NEURAL-NETWORKS; deep learning; disorders of consciousness; DOC state classification; self-supervised pre-training; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VW2VFZUV","journalArticle","2023","Zou, BY; Sima, W; Yang, M; Duan, P; Li, YF; Luo, XX; Qiu, YT; de León, F","Reconstructing Primary Voltage Across Inductive VTs-Part II: Validation, Application, and Analysis","IEEE TRANSACTIONS ON POWER DELIVERY","","0885-8977","10.1109/TPWRD.2022.3213720","","This two-part paper presents an inverse method to reconstruct the primary voltage of a VT from the available distorted secondary signals. In this second part, the performance of the proposed inverse method is validated by simulation using a 10 kV inductive voltage transformer (VT). Additionally, four laboratory experiments are performed to show the potential applications of the proposed method. These experiments closely represent realistic field conditions. The simulation and experimental results verify the accuracy and reliability of the method. The robustness and parameter accessibility are discussed. The novel inverse method provides an effective solution for the accurate reproduction of high-frequency transients and low-frequency over-voltages measurements. Furthermore, the reconstructed primary voltage waveforms provide usable data for the study of voltages in power systems.","2023-04","2025-02-26 20:39:15","2025-02-26 20:39:15","","1363-1374","","2","38","","","","","","","","","","English","","","","WOS:000966564100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Black-box model; duality; FERRORESONANCE; Frequency measurement; Inverse problems; Lightning; Resistance; SIMULATION; TRANSFORMER MODEL; Transient analysis; transient voltage; TRANSIENTS; Voltage measurement; voltage transformer; Windings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TPRW9L39","journalArticle","2022","Alshanqiti, AM; Albouq, S; Alkhodre, AB; Namoun, A; Nabil, E","Employing a Multilingual Transformer Model for Segmenting Unpunctuated Arabic Text","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app122010559","","Long unpunctuated texts containing complex linguistic sentences are a stumbling block to processing any low-resource languages. Thus, approaches that attempt to segment lengthy texts with no proper punctuation into simple candidate sentences are a vitally important preprocessing task in many hard-to-solve NLP applications. In this paper, we propose (PDTS) a punctuation detection approach for segmenting Arabic text, built on top of a multilingual BERT-based model and some generic linguistic rules. Furthermore, we showcase how PDTS can be effectively employed as a text tokenizer for unpunctuated documents (i.e., mimicking the transcribed audio-to-text documents). Experimental findings across two evaluation protocols (involving an ablation study and a human-based judgment) demonstrate that PDTS is practically effective in both performance quality and computational cost.","2022-10","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","20","12","","","","","","","","","","English","","","","WOS:000872209000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","cross-lingual BERT model; mask-fill prediction; Masked Language Modeling; missing punctuations; NLP linguistic rules; text splitting; text tokenization; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QXXDDWMG","journalArticle","2022","Pospíchal, J; Kubovcík, M; Luptáková, ID","Solar Irradiance Forecasting with Transformer Model","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app12178852","","Solar energy is one of the most popular sources of renewable energy today. It is therefore essential to be able to predict solar power generation and adapt energy needs to these predictions. This paper uses the Transformer deep neural network model, in which the attention mechanism is typically applied in NLP or vision problems. Here, it is extended by combining features based on their spatiotemporal properties in solar irradiance prediction. The results were predicted for arbitrary long-time horizons since the prediction is always 1 day ahead, which can be included at the end along the timestep axis of the input data and the first timestep representing the oldest timestep removed. A maximum worst-case mean absolute percentage error of 3.45% for the one-day-ahead prediction was obtained, which gave better results than the directly competing methods.","2022-09","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","17","12","","","","","","","","","","English","","","","WOS:000850957300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","correlations; NASA POWER; NEURAL-NETWORKS; renewable energy; sequence-to-sequence prediction; solar irradiance; transformer; weather","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GVBWPU8M","journalArticle","2025","Clauwaert, J; Mcvey, Z; Gupta, R; Yannuzzi, I; Basrur, V; Nesvizhskii, AI; Menschaert, G; Prensner, JR","Deep learning to decode sites of RNA translation in normal and cancerous tissues","NATURE COMMUNICATIONS","","2041-1723","10.1038/s41467-025-56543-0","","The biological process of RNA translation is fundamental to cellular life and has wide-ranging implications for human disease. Accurate delineation of RNA translation variation represents a significant challenge due to the complexity of the process and technical limitations. Here, we introduce RiboTIE, a transformer model-based approach designed to enhance the analysis of ribosome profiling data. Unlike existing methods, RiboTIE leverages raw ribosome profiling counts directly to robustly detect translated open reading frames (ORFs) with high precision and sensitivity, evaluated on a diverse set of datasets. We demonstrate that RiboTIE successfully recapitulates known findings and provides novel insights into the regulation of RNA translation in both normal brain and medulloblastoma cancer samples. Our results suggest that RiboTIE is a versatile tool that can significantly improve the accuracy and depth of Ribo-Seq data analysis, thereby advancing our understanding of protein synthesis and its implications in disease.","2025-02-02","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","1","16","","","","","","","","","","English","","","","WOS:001411014100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","IDENTIFICATION; ULTRAFAST","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KS3UEVAD","journalArticle","2024","Escou, L; Descampe, A; Fairon, C","Automated text classification of opinion vs. news French press articles. A comparison of transformer and feature-based approaches","LANGUAGE & COMMUNICATION","","0271-5309","10.1016/j.langcom.2024.09.004","","This study explores Natural Language Processing (NLP) methods for distinguishing between press articles belonging to the journalistic genres of 'objective' news and 'subjective' opinion. Two classification models are compared: CamemBERT, a French transformer model fine-tuned for the task, and a machine learning model using 32 linguistic features. Trained on 8000 Belgian French articles, both models are evaluated on 1000 Canadian French articles. Results show CamemBERT's superiority but highlight potential for hybrid approaches and emphasizes the need for robust and transparent methods in NLP. The research contributes to understanding NLP's role in journalism by addressing challenges of point of view detection in press discourse. (c) 2024 Elsevier Ltd. All rights are reserved, including those for text and data mining, AI training, and similar technologies.","2024-11","2025-02-26 20:39:16","2025-02-26 20:39:16","","129-140","","","99","","","","","","","","","","English","","","","WOS:001337772300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","Discourse analysis; Explainability; Feature-based model; JOURNALISM; OBJECTIVITY; SENTIMENT ANALYSIS; Subjectivity; SUBJECTIVITY; Text classification; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6HEP5VEY","journalArticle","2023","Ye, Z; Li, SH; Mi, X; Shao, BY; Dai, Z; Ding, B; Feng, SW; Sun, B; Shen, Y; Xiao, ZD","STMHCpan, an accurate Star-Transformer-based extensible framework for predicting MHC I allele binding peptides","BRIEFINGS IN BIOINFORMATICS","","1467-5463","10.1093/bib/bbad164","","Peptide-major histocompatibility complex I (MHC I) binding affinity prediction is crucial for vaccine development, but existing methods face limitations such as small datasets, model overfitting due to excessive parameters and suboptimal performance. Here, we present STMHCPan (STAR-MHCPan), an open-source package based on the Star-Transformer model, for MHC I binding peptide prediction. Our approach introduces an attention mechanism to improve the deep learning network architecture and performance in antigen prediction. Compared with classical deep learning algorithms, STMHCPan exhibits improved performance with fewer parameters in receptor affinity training. Furthermore, STMHCPan outperforms existing ligand benchmark datasets identified by mass spectrometry. It can also handle peptides of arbitrary length and is highly scalable for predicting T-cell responses. Our software is freely available for use, training and extension through Github ().","2023-05-19","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","3","24","","","","","","","","","","English","","","","WOS:000980601400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","deep learning; MHC I allele; Star-Transformer; tumor neoantigen prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JUD9SIXW","journalArticle","2024","Wang, Q; Dong, YQ; Xu, N; Xu, F; Mou, C; Chen, FX","Image Classification of Tree Species in Relatives Based on Dual-Branch Vision Transformer","FORESTS","","1999-4907","10.3390/f15122243","","Tree species in relatives refer to species belonging to the same genus with high morphological similarity and small botanical differences, making it difficult to perform classification and usually requiring manual identification by experts. To reduce labor costs and achieve accurate species identification, we conducted research on the image classification of tree species in relatives based on deep learning and proposed a dual-branch feature fusion Vision Transformer model. This model is designed with a dual-branch architecture and two effective blocks, a Residual Cross-Attention Transformer Block and a Multi-level Feature Fusion method, to enhance the influence of shallow network features on the final classification and enable the model to capture both overall image information and detailed features. Finally, we conducted ablation studies and comparative experiments to validate the effectiveness of the model, achieving an accuracy of 90% on the tree relatives dataset.","2024-12","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","12","15","","","","","","","","","","English","","","","WOS:001384379100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","image classification; tree species classification; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JSI93EP2","journalArticle","2022","Xue, ZY; Liu, QT; Shi, HC; Zou, RY; Jiang, XH","A Transformer-Based DeepFake-Detection Method for Facial Organs","ELECTRONICS","","2079-9292","10.3390/electronics11244143","","Nowadays, deepfake detection on subtle-expression manipulation, facial-detail modification, and smeared images has become a research hotspot. Existing deepfake-detection methods on the whole face are coarse-grained, where the details are missing due to the negligible manipulated size of the image. To address the problems, we propose to build a transformer model for a deepfake-detection method by organ, to obtain the deepfake features. We reduce the detection weight of defaced or unclear organs to prioritize the detection of clear and intact organs. Meanwhile, to simulate the real-world environment, we build a Facial Organ Forgery Detection Test Dataset (FOFDTD), which includes the images of mask face, sunglasses face, and undecorated face collected from the network. Experimental results on four benchmarks, i.e., FF++, DFD, DFDC-P, Celeb-DF, and for FOFDTD datasets, demonstrated the effectiveness of our proposed method.","2022-12","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","24","11","","","","","","","","","","English","","","","WOS:000901066000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","generated face; generative adversarial network; image-forensics detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YC8UG65E","journalArticle","2023","Feng, S; Zhu, XQ; Ma, SQ; Lan, Q","GIT: A Transformer-Based Deep Learning Model for Geoacoustic Inversion","JOURNAL OF MARINE SCIENCE AND ENGINEERING","","2077-1312","10.3390/jmse11061108","","Geoacoustic inversion is a challenging task in marine research due to the complex environment and acoustic propagation mechanisms. With the rapid development of deep learning, various designs of neural networks have been proposed to solve this issue with satisfactory results. As a data-driven method, deep learning networks aim to approximate the inverse function of acoustic propagation by extracting knowledge from multiple replicas, outperforming conventional inversion methods. However, existing deep learning networks, mainly incorporating stacked convolution and fully connected neural networks, are simple and may neglect some meaningful information. To extend the network backbone for geoacoustic inversion, this paper proposes a transformer-based geoacoustic inversion model with additional frequency and sensor 2-D positional embedding to perceive more information from the acoustic input. The simulation experimental results indicate that our proposed model achieves comparable inversion results with the existing inversion networks, demonstrating its effectiveness in marine research.","2023-06","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","6","11","","","","","","","","","","English","","","","WOS:001014907700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","2-D positional embedding; deep learning; geoacoustic inversion; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SG799YLB","journalArticle","2022","Wang, K; Johnson, CW; Bennett, KC; Johnson, PA","Predicting Future Laboratory Fault Friction Through Deep Learning Transformer Models","GEOPHYSICAL RESEARCH LETTERS","","0094-8276","10.1029/2022GL098233","","Machine learning models using seismic emissions as input can predict instantaneous fault characteristics such as displacement and friction in laboratory experiments, and slow slip in Earth. Here, we address whether the seismic/acoustic emission (AE) from laboratory experiments contains information about future frictional behavior. The approach uses a convolutional encoder-decoder containing a transformer model in the latent space, similar to models used for natural language processing. We test the model limits using progressively larger AE input time windows and progressively larger output friction time windows. The results demonstrate that very near-term friction predictions are indeed contained in the AE signal, and predictions are progressively worse farther into the future. The future predictions by the model of impending failure in the near-term are remarkably robust. This first effort predicting future fault frictional behavior with machine learning will aid in guiding efforts for applications in Earth.","2022-10-16","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","19","49","","","","","","","","","","English","","","","WOS:000865979400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","STICK-SLIP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4ACU4AGH","journalArticle","2024","Ji, DJ; Chung, BC","Transformer-Based Efficient CSI Feedback for THz Band FDD MIMO Systems","IEEE WIRELESS COMMUNICATIONS LETTERS","","2162-2337","10.1109/LWC.2023.3329019","","Machine learning algorithms have been extensively explored for the feedback of multiple-input multiple-output (MIMO) channel state information (CSI) in orthogonal frequency division multiplexing (OFDM) systems. However, their viability in sixth-generation (6G) wireless communication systems, operating in the terahertz (THz) band, remains uncertain. To address this, we propose ChannelTransformer, a transformer-model-based CSI feedback scheme that incorporates multi-head self-attention and a CSI-feedback-aware transformer structure, and a lightweight user equipment (UE) model. Through simulations in the DeepMIMO O1 scenario at 140GHz, ChannelTransformer demonstrates superior performance in terms of normalized mean square error (NMSE) and cosine similarity across various feedback lengths compared to conventional schemes with a much smaller UE model size.","2024-02","2025-02-26 20:39:16","2025-02-26 20:39:16","","343-346","","2","13","","","","","","","","","","English","","","","WOS:001167560000029","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;16</p>","","","6G mobile communication; Antenna arrays; CHANNEL; channel feedback; Computational modeling; Computer architecture; deep learning; Machine learning for communications; multiple-input multiple-output; Receiving antennas; Tensors; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ACZDPTGS","journalArticle","2023","Zhuge, RB; Wang, JH; Xu, ZL; Xu, Y","Single image denoising with a feature-enhanced network","NEURAL NETWORKS","","0893-6080","10.1016/j.neunet.2023.08.056","","Recent Transformer-based networks have shown impressive performance on single image denoising tasks. While the Transformer model promotes the interaction of long-range features, it generally involves high computational complexity. In this paper, we propose a feature-enhanced denoising network (FEDNet) by combining CNN architectures with Transformers. Specifically, we propose an effective cross-channel attention to boost the interaction of channel information and enhance channel features. In order to fully exploit image features, we incorporate Transformer blocks into minimum-scale layers of the network, which can not only capture the long-distance dependency of low-resolution features but also reduce the multiplier-accumulator operations (MACs). Meanwhile, a structure-preserving block is designed to enhance the structural feature extraction. Experimental results on both synthetic and real-world datasets demonstrate that our model can achieve the state-of-the-art denoising performance with low computational costs.","2023-11","2025-02-26 20:39:16","2025-02-26 20:39:16","","313-325","","","168","","","","","","","","","","English","","","","WOS:001088537600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","Channel attention; Image denoising; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AVZ2X37A","journalArticle","2024","Tang, BY; Feng, F","Efficient and expressive high-resolution image synthesis via variational autoencoder-enriched transformers with sparse attention mechanisms","JOURNAL OF ELECTRONIC IMAGING","","1017-9909","10.1117/1.JEI.33.3.033002","",". We introduce a method for efficient and expressive high-resolution image synthesis, harnessing the power of variational autoencoders (VAEs) and transformers with sparse attention (SA) mechanisms. By utilizing VAEs, we can establish a context-rich vocabulary of image constituents, thereby capturing intricate image features in a superior manner compared with traditional techniques. Subsequently, we employ SA mechanisms within our transformer model, improving computational efficiency while dealing with long sequences inherent to high-resolution images. Extending beyond traditional conditional synthesis, our model successfully integrates both nonspatial and spatial information while also incorporating temporal dynamics, enabling sequential image synthesis. Through rigorous experiments, we demonstrate our method's effectiveness in semantically guided synthesis of megapixel images. Our findings substantiate this method as a significant contribution to the field of high-resolution image synthesis.","2024-05-01","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","3","33","","","","","","","","","","English","","","","WOS:001286845500013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","context-rich vocabulary; high-resolution image synthesis; sequential image synthesis; sparse attention mechanisms; transformers; variational autoencoders","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AMBXNRBN","journalArticle","2022","Wu, JR; Chen, QL","Pruning Adapters with Lottery Ticket","ALGORITHMS","","1999-4893","10.3390/a15020063","","Massively pre-trained transformer models such as BERT have gained great success in many downstream NLP tasks. However, they are computationally expensive to fine-tune, slow for inference, and have large storage requirements. So, transfer learning with adapter modules has been introduced and has become a remarkable solution for those problems. Nevertheless, recent studies reveal that the parameters in adapters are actually still quite redundant, which could slow down inference speed when fusing multiple adapters for a specific downstream task, and thus, they can be further reduced. To address this issue, we propose three novel ways to prune the adapter modules iteratively based on the prestigious Lottery Ticket Hypothesis. Extensive experiments on the GLUE datasets show that the pruned adapters can achieve state-of-the-art results, with sizes reduced significantly while performance remains unchanged, and some pruned adapters even outperform the ones with the same size that are fine-tuned alone without pruning.","2022-02","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","2","15","","","","","","","","","","English","","","","WOS:000763978400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","adapter; pre-trained transformer model; prune","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QHS6R357","journalArticle","2024","Sun, LY; Li, WQ; Xu, YJ","Ghost-UNet: Lightweight model for underwater image enhancement","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2024.108585","","Light scattering and absorption during underwater propagation lead to colour distortion and fogging in underwater images, lacking reference for undegraded images, posing challenges in directly applying the underwater images to real-world scenes. We provide a novel approach for generating underwater images by utilizing a conditional diffusion model to address this issue. Besides, we present a novel approach called Ghost-UNet to address the issue of substantial memory and computational demands in implementations of deep convolutional neural networks. Compared with previous methods, our method exceeds 3.8% and 1.7% in the peak signal-to-noise ratio and underwater colour image quality evaluation respectively. Additionally, our method leads to a 0.016-second gain in test speed. The parameters of Ghost-UNet is 1/39 of a transformer model. Ghost-UNet is highly suitable for real-time underwater image enhancement network implementation.","2024-07","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","133","","","","","","","","","","English","","","","WOS:001293741700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Conditional diffusion model; Generative network; Lightweight model; Underwater image enhancement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q69R2ICL","journalArticle","2023","Leippold, M","Sentiment spin: Attacking financial sentiment with GPT-3","FINANCE RESEARCH LETTERS","","1544-6123","10.1016/j.frl.2023.103957","","In this study, we explore the susceptibility of financial sentiment analysis to adversarial attacks that manipulate financial texts. With the rise of AI readership in the financial sector, companies are adapting their language and disclosures to fit AI processing better, leading to concerns about the potential for manipulation. In the finance literature, keyword-based methods, such as dictionaries, are still widely used for financial sentiment analysis due to their perceived transparency. However, our research demonstrates the vulnerability of keyword-based approaches by successfully generating adversarial attacks using the sophisticated transformer model, GPT-3. With a success rate of nearly 99% for negative sentences in the Financial Phrase Bank, a widely used database for financial sentiment analysis, we highlight the importance of incorporating robust methods, such as context-aware approaches such as BERT, in financial sentiment analysis.","2023-07","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","55","","","","","","","","","","English","","","","WOS:001089857500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;31<br/>Total Times Cited:&nbsp;&nbsp;33<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","FinBERT; GPT-3; Keyword-based approach; sentiment analysis in financial markets","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZWM99LTP","journalArticle","2022","Chemerinsky, E","FREE SPEECH DEAD ZONES","UNIVERSITY OF ILLINOIS LAW REVIEW","","0276-9948","","","The Supreme Court has created an elaborate framework for free speech analysis involving distinctions between content-based and content -neutral government regulations, as well as the application of the levels of scrutiny. But the Court also has created some free speech ""dead zones "" where First Amendment principles don't apply at all and the government always wins. This Article identifies some of these free speech dead zones- for speech of government employees on the job in the scope of their duties, for government speech, and for speech related to the military. The Article argues that free speech dead zones are undesirable and unnecessary.","2022","2025-02-26 20:39:16","2025-02-26 20:39:16","","1695-1710","","5","","","","","","","","","","","English","","","","WOS:000875633500002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;13</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YZTDY8X9","journalArticle","2024","Chen, XY; Ge, YF; Zhang, YS; Qian, T","Leveraging Transformer-Based Non-Parametric Probabilistic Prediction Model for Distributed Energy Storage System Dispatch","PROCESSES","","2227-9717","10.3390/pr12040779","","In low-voltage distribution networks, distributed energy storage systems (DESSs) are widely used to manage load uncertainty and voltage stability. Accurate modeling and estimation of voltage fluctuations are crucial to informed DESS dispatch decisions. However, existing parametric probabilistic approaches have limitations in handling complex uncertainties, since they always rely on predefined distributions and complex inference processes. To address this, we integrate the patch time series Transformer model with the non-parametric Huberized composite quantile regression method to reliably predict voltage fluctuation without distribution assumptions. Comparative simulations on the IEEE 33-bus distribution network show that the proposed model reduces the DESS dispatch cost by 6.23% compared to state-of-the-art parametric models.","2024-04","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","4","12","","","","","","","","","","English","","","","WOS:001210501700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","chance-constrained programming; composite quantile regression; distributed energy storage system; DISTRIBUTION NETWORK; low-voltage distribution networks; non-parametric probabilistic prediction; OPTIMIZATION; PatchTST; QUANTILE REGRESSION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"93XYEQPK","journalArticle","2024","Sun, HQ; Liu, Z; Lian, WM; Wang, GZ","Social Network Public Opinion Analysis Using BERT-BMA in Big Data Environment","INTERNATIONAL JOURNAL OF INFORMATION TECHNOLOGIES AND SYSTEMS APPROACH","","1935-570X","10.4018/IJITSA.352509","","The existing social network public opinion analysis methods have problems such as poor semantic expression quality and weak detection ability in short texts. Therefore, a social network public opinion analysis method based on BERT-BMA is proposed. To normalize the comment text, the rumor text is initially transferred to a word vector matrix using the BERT (Bidirectional Encoder Representations from Transformer) model. The BiLSTM-based network architecture is subsequently employed to acquire the trace features of data transmission. Ultimately, this study employs the multi-head attention mechanism to extract feature information that is more significant in the analysis of online public opinion by mining the dependency relationships between users, resulting in increasing ability to detect public opinion emergencies. The experimental outcomes indicate that the results on the Twitter data set and Weibo dataset are superior to other comparative models.","2024","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","1","17","","","","","","","","","","English","","","","WOS:001317417800003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Big Data; BiLSTM; Emergency Detection and Search; MEDIA; Public Opinion Analysis; Social Network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4X86ID85","journalArticle","2021","Kreutter, D; Schwaller, P; Reymond, JL","Predicting enzymatic reactions with a molecular transformer","CHEMICAL SCIENCE","","2041-6520","10.1039/d1sc02362d","","The use of enzymes for organic synthesis allows for simplified, more economical and selective synthetic routes not accessible to conventional reagents. However, predicting whether a particular molecule might undergo a specific enzyme transformation is very difficult. Here we used multi-task transfer learning to train the molecular transformer, a sequence-to-sequence machine learning model, with one million reactions from the US Patent Office (USPTO) database combined with 32 181 enzymatic transformations annotated with a text description of the enzyme. The resulting enzymatic transformer model predicts the structure and stereochemistry of enzyme-catalyzed reaction products with remarkable accuracy. One of the key novelties is that we combined the reaction SMILES language of only 405 atomic tokens with thousands of human language tokens describing the enzymes, such that our enzymatic transformer not only learned to interpret SMILES, but also the natural language as used by human experts to describe enzymes and their mutations.","2021-05-25","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","","","","","","","","","","","English","","","","WOS:000656562100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;39<br/>Total Times Cited:&nbsp;&nbsp;42<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","AMINATION; MECHANISM; OUTCOMES; OXIDATION; PROMISCUITY; SUBSTRATE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9TC7BD5M","journalArticle","2023","Guntuboina, C; Das, A; Mollaei, P; Kim, S; Farimani, AB","PeptideBERT: A Language Model Based on Transformers for Peptide Property Prediction","JOURNAL OF PHYSICAL CHEMISTRY LETTERS","","1948-7185","10.1021/acs.jpclett.3c02398","","Recent advances in language models have enabled the protein modeling community with a powerful tool that uses transformers to represent protein sequences as text. This breakthrough enables a sequence-to-property prediction for peptides without relying on explicit structural data. Inspired by the recent progress in the field of large language models, we present PeptideBERT, a protein language model specifically tailored for predicting essential peptide properties such as hemolysis, solubility, and nonfouling. The PeptideBERT utilizes the ProtBERT pretrained transformer model with 12 attention heads and 12 hidden layers. Through fine-tuning the pretrained model for the three downstream tasks, our model is state of the art (SOTA) in predicting hemolysis, which is crucial for determining a peptide's potential to induce red blood cells as well as nonfouling properties. Leveraging primarily shorter sequences and a data set with negative samples predominantly associated with insoluble peptides, our model showcases remarkable performance.","2023-11-13","2025-02-26 20:39:16","2025-02-26 20:39:16","","10427-10434","","46","14","","","","","","","","","","English","","","","WOS:001141601000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;18<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","NONSPECIFIC INTERACTIONS; THERAPEUTICS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CKGDZ9A6","journalArticle","2024","Ossewaarde, R; Pijnenburg, Y; Keulen, A; Jonkers, R; Leijnen, S","Role of pause duration in primary progressive aphasia","APHASIOLOGY","","0268-7038","10.1080/02687038.2024.2366285","","AimsTo detect differences in speech fluency in separate primary progressive aphasia syndromes (PPA) using automated analysis techniques. The resulting linguistic features are evaluated for their use in a predictive model to identify common patterns in speakers with PPA. As fluency is observable in audio recordings, its quantification may provide a low-cost instrument that augments spontaneous speech analyses in clinical practice.Methods and ProceduresSpeech was recorded in 14 controls, 7 nonfluent variant (nfvPPA) and 8 semantic variant (svPPA) speakers. The recordings were annotated for speech and non-speech with Kaldi, a common toolkit for speech processing software. Variables relating to fluency (pause rate, number of pauses, length of pauses) were analyzed.Outcomes and ResultsThe best fitting distribution of pause duration was a combination of two Gaussian distributions, corresponding with pause categories short vs. long.Group level differences were found in the rate of pauses and proportion of silence: nfvPPA speakers use more short pauses relative to long pauses than control speakers, and the duration of short and long pauses is longer; svPPA speakers use more longer pauses relative to short pauses. Their short pauses are significantly shorter than those from control speakers.Participants in both PPA groups pause more frequently. SvPPA speakers are typically perceived as fluent. However, our analysis shows their fluency patterns to be distinct from control speakers, if the long-short distinction is observed.Outcomes and ResultsThe best fitting distribution of pause duration was a combination of two Gaussian distributions, corresponding with pause categories short vs. long.Group level differences were found in the rate of pauses and proportion of silence: nfvPPA speakers use more short pauses relative to long pauses than control speakers, and the duration of short and long pauses is longer; svPPA speakers use more longer pauses relative to short pauses. Their short pauses are significantly shorter than those from control speakers.Participants in both PPA groups pause more frequently. SvPPA speakers are typically perceived as fluent. However, our analysis shows their fluency patterns to be distinct from control speakers, if the long-short distinction is observed.Outcomes and ResultsThe best fitting distribution of pause duration was a combination of two Gaussian distributions, corresponding with pause categories short vs. long.Group level differences were found in the rate of pauses and proportion of silence: nfvPPA speakers use more short pauses relative to long pauses than control speakers, and the duration of short and long pauses is longer; svPPA speakers use more longer pauses relative to short pauses. Their short pauses are significantly shorter than those from control speakers.Participants in both PPA groups pause more frequently. SvPPA speakers are typically perceived as fluent. However, our analysis shows their fluency patterns to be distinct from control speakers, if the long-short distinction is observed.ConclusionsAutomatic measurements of pause duration show meaningful distinctions across the groups and might provide future aid in clinical assessment.","2024-06-21","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","","","","","","","","","","","English","","","","WOS:001251606200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;80</p>","","","Aphasia, primary progressive (MeSH ID D018888); automatic fluency assessment; frontotemporal dementia (MeSH ID D057180); LANGUAGE; primary progressive nonfluent aphasia (MeSH ID D057178); speech disorders (MeSH ID D013064); SPONTANEOUS SPEECH; VERSION; VOICE ACTIVITY DETECTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IUQASNI8","journalArticle","2025","Warner, N; Brenner, D; Tucker, BV; Ernestus, M","Non-Native Listeners' Use of Information in Parsing Ambiguous Casual Speech","LANGUAGES","","2226-471X","10.3390/languages10010008","","During conversation, speakers produce reduced speech, and this can create homophones: 'we were' and 'we're' can both be realized as [(sic)], and 'he was' and 'he's' can be realized as [iz]. We investigate the types of information non-native listeners (Dutch L1-English L2) use to perceive the tense of such verbs, making comparisons with previous results from native listeners. The Dutch listeners were almost as successful as natives (average percentage correct for 'is'/'was' in the most accurate condition: 81% for Dutch, 88% for natives). The two groups showed many of the same patterns, indicating that both make strong use of whatever acoustic information is available in the signal, even if it is heavily reduced. The Dutch listeners showed one crucial difference: a minimal amount of context around the target, just enough to signal speech rate, did not help Dutch listeners to recover the longer forms, i.e., was/were, from reduced pronunciations. Only the full utterance context (containing syntactic/semantic information such as 'yesterday' or another tensed verb) helped Dutch listeners to recover from reduction. They were not able to adjust their criteria based on the surrounding speech rate as native listeners were. This study contributes to understanding how L2 learners parse information from spontaneous speech in a World Englishes setting with inputs from multiple dialects.","2025-01","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","1","10","","","","","","","","","","English","","","","WOS:001408566400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","acoustic reduction; BENEFIT; COMPREHENSION; INTELLIGIBILITY; L2 listening; PERCEPTION; RECOGNITION; SPEAKING RATE; speech perception; speech reduction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NI68VD5V","journalArticle","2024","Eliatamby, A; Valian, V","Children's early negative auxiliaries are true auxiliaries","LANGUAGE ACQUISITION","","1048-9223","10.1080/10489223.2024.2356668","","This study investigates young children's acquisition of functional categories through their use of negative words and negative auxiliaries in particular. Drawing from CHILDES, we analyze twelve months of spontaneous speech by 14 children (youngest age 1;9, oldest age 3;1) and their mothers, in order to assess whether children's earliest negative productions are morphological combinations and reflect possession of abstract syntactic categories or are instead input-driven formulae. In five analyses we show that (i) two-year-olds use a wide and overlapping range of negative and positive auxiliaries; (ii) the range of the negative auxiliaries children produce is strongly correlated with the range of the positive auxiliaries they produce; (iii) children's most common negative auxiliary, don't, is used grammatically with respect to the syntactic category being negated and with respect to overt markings of tense; (iv) children's subject agreement errors with don't are mirrored by subject agreement errors with do, have, and haven't; and (v) children omit auxiliaries with not at rates that cannot be attributed to properties of their input. Our findings support the hypothesis that children's earliest negations are syntactically adult-like and reflect the possession of abstract syntactic categories. By age 2, English-learning children productively combine auxiliary, negation, and tense categories and syntactically differentiate different negative morphemes.","2024-07-08","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","","","","","","","","","","","English","","","","WOS:001264679400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","ACQUISITION; CATEGORIES; CUES; FUNCTIONAL MORPHEMES; VERBS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U5WPLKUQ","journalArticle","2023","Conwell, E; Horvath, G; Kuznia, A; Agauas, SJ","Developmental consistency in the use of subphonemic information during real-time sentence processing","LANGUAGE COGNITION AND NEUROSCIENCE","","2327-3798","10.1080/23273798.2022.2159993","","Apparently homophonous sequences contain acoustic information that differentiates their meanings [Gahl. (2008). Time and thyme are not homophones: The effect of lemma frequency on word durations in spontaneous speech. Language, 84(3), 474-496; Quene. (1992). Durational cues for word segmentation in Dutch. Journal of Phonetics, 20(3), 331-350]. Adults use this information to segment embedded homophones [e.g. ham vs. hamster; Salverda et al. (2003). The role of prosodic boundaries in the resolution of lexical embedded in speech comprehension. Cognition, 90(1), 51-89] in fluent speech. Whether children also do this is unknown, as is whether listeners of any age use such information to disambiguate lexical homophones. In two experiments, 48 English-speaking adults and 48 English-speaking 7 to 10-year-old children viewed sets of four images and heard sentences containing phonemically identical sequences while their eye movements were continuously tracked. As in previous research, adults showed greater fixation of target meanings when the acoustic properties of an embedded homophone were consistent with the target than when they were consistent with the alternate interpretation. They did not show this difference for lexical homophones. Children's behaviour was similar to that of adults, indicating that the use of subphonemic information in homophone processing is consistent over development.","2023-07-03","2025-02-26 20:39:16","2025-02-26 20:39:16","","860-871","","6","38","","","","","","","","","","English","","","","WOS:000902161600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","AMBIGUITY; BOUNDARIES; CHILDREN; CUE; eye-tracking; homophones; HOMOPHONES; Language development; LEMMA-FREQUENCY; SENSITIVITY; Sentence processing; subphonemic processing; THYME; WORD SEGMENTATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XTETT49D","journalArticle","2021","Byun, SW; Kim, JH; Lee, SP","Multi-Modal Emotion Recognition Using Speech Features and Text-Embedding","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app11177967","","Recently, intelligent personal assistants, chat-bots and AI speakers are being utilized more broadly as communication interfaces and the demands for more natural interaction measures have increased as well. Humans can express emotions in various ways, such as using voice tones or facial expressions; therefore, multimodal approaches to recognize human emotions have been studied. In this paper, we propose an emotion recognition method to deliver more accuracy by using speech and text data. The strengths of the data are also utilized in this method. We conducted 43 feature vectors such as spectral features, harmonic features and MFCC from speech datasets. In addition, 256 embedding vectors from transcripts using pre-trained Tacotron encoder were extracted. The acoustic feature vectors and embedding vectors were fed into each deep learning model which produced a probability for the predicted output classes. The results show that the proposed model exhibited more accurate performance than in previous research.","2021-09","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","17","11","","","","","","","","","","English","","","","WOS:000694166700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","emotion recognition; multi-modal emotion recognition; speech emotion recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EJ3YPBT5","journalArticle","2023","Duskaeva, LR","SPEECH ORGANIZATION OF THE METATEXT IN TELEGRAM POSTS","VESTNIK MOSKOVSKOGO UNIVERSITETA. SERIYA 10. ZHURNALISTIKA","","0320-8079","10.30547/vestnik.journ.1.2023.3065","","The paper is devoted to the metatext speech features of popular science Telegram channels' posts. Metatext is defined as a subtext structure organized by various-level language means. Reflecting another communicant' formation of thought and speech, metatext helps the author to manage the impact on the reader's attention and, on the other hand, helps the reader to understand the author's intention. The paper focuses on metatext markers forming two lines: the first one depicts the speech interaction of the scientist and the popularizer, and the second one represents the speech interaction of the author and the addressee. It was established that the metatext expressiveness is fueled by the attitude toward the expression novelty, i.e. creativity. Linguocreative components in metatext lines contribute, firstly, to the expression of an assessment of someone else's speech and thinking activity, and secondly, to the organization of personality-oriented communication, helping to involve the reader in an intellectual cooperation.","2023-01","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","1","","","","","","","","","","","English","","","","WOS:000974912500002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","linguocreativity; media linguistics; metatext; objection; popular science; Telegram channel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4IG2R4PL","journalArticle","2022","Llanos, F; Gnanateja, GN; Chandrasekaran, B","Principal component decomposition of acoustic and neural representations of time-varying pitch reveals adaptive efficient coding of speech covariation patterns","BRAIN AND LANGUAGE","","0093-934X","10.1016/j.bl.2022.105122","","Understanding the effects of statistical regularities on speech processing is a central issue in auditory neuroscience. To investigate the effects of distributional covariance on the neural processing of speech features, we introduce and validate a novel approach: decomposition of time-varying signals into patterns of covariation extracted with Principal Component Analysis. We used this decomposition to assay the sensory representation of pitch covariation patterns in native Chinese listeners and non-native learners of Mandarin Chinese tones. Sensory representations were examined using the frequency-following response, a far-field potential that reflects phaselocked activity from neural ensembles along the auditory pathway. We found a more efficient representation of the covariation patterns that accounted for more redundancy in the form of distributional covariance. Notably, long-term language and short-term training experiences enhanced the sensory representation of these covariation patterns.","2022-07","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","230","","","","","","","","","","English","","","","WOS:000795075800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","BRAIN-STEM; CUES; Efficient coding; FREQUENCY; Frequency following response; LANGUAGE; Lexical tones; MANDARIN; PERCEPTION; Principal component analysis; Speech perception; Statistical learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U748BMFW","journalArticle","2022","Martínez-Molina, N; Siponkoski, ST; Pitkäniemi, A; Moisseinen, N; Kuusela, L; Pekkola, J; Laitinen, S; Särkämö, ER; Melkas, S; Kleber, B; Schlaug, G; Sihvonen, A; Särkämö, T","Neuroanatomical correlates of speech and singing production in chronic post-stroke aphasia","BRAIN COMMUNICATIONS","","2632-1297","10.1093/braincomms/fcac001","","A classical observation in neurology is that aphasic stroke patients with impairments in speech production can nonetheless sing the same utterances. This preserved ability suggests a distinctive neural architecture for singing that could contribute to speech recovery. However, to date, these structural correlates remain unknown. Here, we combined a multivariate lesion-symptom mapping and voxel-based morphometry approach to analyse the relationship between lesion patterns and grey matter volume and production rate in speech and singing tasks. Lesion patterns for spontaneous speech and cued repetition extended into frontal, temporal and parietal areas typically reported within the speech production network. Impairment in spontaneous singing was associated with damage to the left anterior-posterior superior and middle temporal gyri. Preservation of grey matter volume in the same regions where damage led to poor speech and singing production supported better performance in these tasks. When dividing the patients into fluent and dysfluent singers based on the singing performance from demographically matched controls, we found that the preservation of the left middle temporal gyrus was related to better spontaneous singing. These findings provide insights into the structural correlates of singing in chronic aphasia and may serve as biomarkers to predict treatment response in clinical trials using singing-based interventions for speech rehabilitation.","2022-01-04","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","1","4","","","","","","","","","","English","","","","WOS:000804710200038","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","aphasia; DEFICITS; lesion-symptom mapping; MEMORY; PITCH; PRESERVATION; RECOVERY; REGIONS; SINGERS; singing; SPEAKING; speech; STROKE; THERAPY; voxel-based morphometry","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K33P8LZ2","journalArticle","2021","Lee, JK; Ko, MH; Park, SH; Kim, GW","Prediction of Aphasia Severity in Patients with Stroke Using Diffusion Tensor Imaging","BRAIN SCIENCES","","2076-3425","10.3390/brainsci11030304","","This study classified the severity of aphasia through the Western Aphasia Battery and determined the optimal cut-off value for each Language-Related White Matter fiber and their combinations, we further examined the correlations between Language-Related White Matter and Western Aphasia Battery subscores. This retrospective study recruited 64 patients with aphasia. Mild/moderate and severe aphasia were classified according to cut-off Aphasia Quotient score of 51 points. Diffusion tensor imaging and fractional anisotropy reconstructed Language-Related White Matter in multiple fasciculi. We determined the area under the covariate-adjusted receiver operating characteristic curve to evaluate the accuracy of predicting aphasia severity. The optimal fractional-anisotropy cut-off values for the individual fibers of the Language-Related White Matter and their combinations were determined. Their correlations with Western Aphasia Battery subscores were analyzed. The arcuate and superior longitudinal fasciculi showed fair accuracy, the inferior frontal occipital fasciculus poor accuracy, and their combinations fair accuracy. Correlations between Language-Related White Matter parameters and Western Aphasia Battery subscores were found between the arcuate, superior longitudinal, and inferior frontal occipital fasciculi and spontaneous speech, auditory verbal comprehension, repetition, and naming. Diffusion-tensor-imaging-based language-Related White Matter analysis may help predict the severity of language impairment in patients with aphasia following stroke.","2021-03","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","3","11","","","","","","","","","","English","","","","WOS:000633440800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;78</p>","","","aphasia; ARCUATE FASCICULUS; CONNECTIVITY; diffusion tensor imaging; DISCONNECTION; DORSAL; LANGUAGE PATHWAYS; LESION; SPEECH PRODUCTION; stroke; TRACTOGRAPHY; UNCINATE FASCICULUS; white matter; WHITE-MATTER TRACTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JPNCM4HB","journalArticle","2024","Puffay, C; Vanthornhout, J; Gillis, M; De Clercq, P; Accou, B; Van Hamme, H; Francart, T","Classifying coherent versus nonsense speech perception from EEG using linguistic speech features","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-69568-0","","When a person listens to natural speech, the relation between features of the speech signal and the corresponding evoked electroencephalogram (EEG) is indicative of neural processing of the speech signal. Using linguistic representations of speech, we investigate the differences in neural processing between speech in a native and foreign language that is not understood. We conducted experiments using three stimuli: a comprehensible language, an incomprehensible language, and randomly shuffled words from a comprehensible language, while recording the EEG signal of native Dutch-speaking participants. We modeled the neural tracking of linguistic features of the speech signals using a deep-learning model in a match-mismatch task that relates EEG signals to speech, while accounting for lexical segmentation features reflecting acoustic processing. The deep learning model effectively classifies coherent versus nonsense languages. We also observed significant differences in tracking patterns between comprehensible and incomprehensible speech stimuli within the same language. It demonstrates the potential of deep learning frameworks in measuring speech understanding objectively.","2024-08-14","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","1","14","","","","","","","","","","English","","","","WOS:001294096300069","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","CNN; Deep learning; EEG decoding; ENTRAINMENT; FREQUENCY; Linguistics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CMK3VIM4","journalArticle","2023","Mukai, Y; Jaervikivi, J; Tucker, BV","The role of phonology-to-orthography consistency in predicting the degree of pupil dilation induced in processing reduced and unreduced speech","APPLIED PSYCHOLINGUISTICS","","0142-7164","10.1017/S0142716423000279","","The relationship between the ways in which words are pronounced and spelled has been shown to affect spoken word processing, and a consistent relationship between pronunciation and spelling has been reported as a possible cause of unreduced pronunciations being easier to process than reduced counterparts although reduced pronunciations occur more frequently. In the present study, we investigate the effect of pronunciation-to-spelling consistency for reduced and unreduced pronunciations in L1 and L2 listeners of a logographic language. More precisely, we compare L1 and L2 Japanese listeners to probe whether they use orthographic information differently when processing reduced and unreduced speech. Using pupillometry, the current study provides evidence that extends the hypothesis about the role of orthography in the processing of reduced speech. Orthographic realization matters in processing for L1 and L2 advanced listeners. More specifically, how consistent the orthographic realization is with its phonological form (phonology-to-orthography consistency) modulates the extent to which reduced pronunciation induces additional processing costs. The results are further discussed in terms of their implications for how listeners process reduced speech and the role of the orthographic form in speech processing.","2023-09","2025-02-26 20:39:16","2025-02-26 20:39:16","","784-815","","5","44","","","","","","","","","","English","","","","WOS:001007754800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;138</p>","","","FEEDBACK CONSISTENCY; FRENCH SCHWA; FREQUENCY; generalized additive modelling; JAPANESE; KANJI; LANGUAGE; NEIGHBORHOOD ACTIVATION; PERCEPTION; PRONUNCIATION; pronunciation-to-spelling consistency; pupillometry; spoken word recognition; SPOKEN WORD RECOGNITION; spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8MS4ECIV","journalArticle","2023","Kang, YL; Ha, S","Effect of Integrated Phonological Awareness Intervention for Children with Speech Sound Disorders","COMMUNICATION SCIENCES AND DISORDERS-CSD","","2288-1328","10.12963/csd.23946","","Objectives: Some children with speech sound disorders (SSD) are likely to have difficulty with phonological awareness skills and develop reading problems when they reach school age. This study aimed to examine the effect of the integrated phonological awareness intervention for children with SSD.Methods: Three children with SSD participated in the intervention study. All of them were 5 years old and showed consonant accuracy of about 50-80% in word levels of the Assessment of Phonology and Articulation for Children (APAC) test. They had no previous experience in speech therapy or specific phonological awareness training. Integrated phonological awareness which emphasized production practices for target phonemes as well as phonological awareness tasks were provided to the three children for approximately 12 weeks within a multiple baseline and AB design.Results: All the three children showed improvements in consonant accuracy of spontaneous speech as well as all target phonemes. Also, they showed progress in phonological awareness skills at syllable and body-coda levels. The intervention effects were maintained after the intervention phases were completed.Conclusion: This study confirmed that integrated phonological awareness intervention was effective in improving articulation and phonological awareness skills for children with SSD. It is expected that the intervention would prevent them from showing reading difficulties.","2023-03","2025-02-26 20:39:16","2025-02-26 20:39:16","","127-142","","1","28","","","","","","","","","","English","","","","WOS:000974294300010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Consonant accuracy; Integrated phonological awareness intervention; LITERACY SKILLS; Multi-ple baseline design; Phonological awareness; Speech sound disorders","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y8WNQEPS","journalArticle","2023","Li, Y","Referentiality and thematic importance: The discourse functions of Zauzou classifiers","LINGUA","","0024-3841","10.1016/j.lingua.2023.103477","","Marking referentiality is one of the major discourse functions of numeral classifiers in Mainland Southeast Asian lan-guages. However, the reference types of classified and unclassified noun phrases exhibit some extent of fluidity. This paper presents the discourse functions of classified and unclassified noun phrases in Zauzou, a less-studied Tibeto-Burman language in China. Zauzou noun phrases in spontaneous speech indicate no simple correspondence between the presence/absence of a classifier and any fixed referential values (i.e., (in)definiteness and specificity). Findings of both qualitative and quantitative studies only point to a tendency of using classifier phrases to express individualized references and bare nouns for unindividualized references. The fluidity in the reference type of classified and unclas-sified noun phrases can be largely explained by the split in definiteness and thematic importance of a referent in dis-course. Notably, thematic importance plays a secondary role in determining the form of a noun phrase in addition to referentiality. Thematically unimportant individualized referents have a higher chance to be expressed by a bare noun. This study provides a new piece of empirical evidence for the patterns of semantic-pragmatic interaction in manipulating the use of numeral classifiers as well as the typology of definiteness marking.(c) 2023 Elsevier B.V. All rights reserved.","2023-04","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","285","","","","","","","","","","English","","","","WOS:000964325300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","ASIAN LANGUAGES; BARE; Bare noun; Definiteness; DEFINITENESS; NOUNS; Numeral classifier; NUMERAL-CLASSIFIERS; Referentiality; Thematic importance; Tibeto-Burman","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6JWMFT7C","journalArticle","2023","Wehrle, S; Cangemi, F; Janz, A; Vogeley, K; Grice, M","Turn-timing in conversations between autistic adults: Typical short-gap transitions are preferred, but not achieved instantly","PLOS ONE","","1932-6203","10.1371/journal.pone.0284029","","The organisation of who speaks when in conversation is perhaps the most fundamental aspect of human communication. Research on a wide variety of groups of speakers has revealed a seemingly universal preference for between-speaker transitions consisting of very short silent gaps. Previous research on conversational turn-taking in Autism Spectrum Disorder (ASD) consists of only a handful of studies, most of which are limited in scope and based on the non-spontaneous speech of children and adolescents. No previous studies have investigated dialogues between autistic adults. We analysed the conversational turn-taking behaviour of 28 adult native German speakers in two groups of dyads, in which both interlocutors either did or did not have a diagnosis of ASD. We found no clear difference in turn-timing between the ASD and the control group overall, with both groups showing the same preference for very short silent-gap transitions that has been described for many other groups of speakers in the past. We did, however, find a clear difference between groups specifically in the earliest stages of dialogue, where ASD dyads produced considerably longer silent gaps than controls. We discuss our findings in the context of the previous literature, the implications of diverging behaviour specifically in the early stages of conversation, and the general importance of studying the neglected aspect of interactions between autistic adults.","2023-04-06","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","4","18","","","","","","","","","","English","","","","WOS:000969434300035","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;80</p>","","","COMMUNICATION; SPEAKERS; SPECTRUM QUOTIENT AQ","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9ZNVEF72","journalArticle","2021","Borise, L","Focus projection need not be based on pitch accents: evidence from Georgian","GLOSSA-A JOURNAL OF GENERAL LINGUISTICS","","2397-1835","10.16995/glossa.5733","","Based on experimental evidence, this paper shows that the prosodic realization of focus in Georgian is consistent with focus projection/percolation - the phenomenon by which prosodic prominence on a sub-constituent signals focus on a larger constituent - and can be accounted for with a Default Prosody-style analysis. In focus projection in English, object-focus utterances are realized in the same way as VP- or broad-focus utterances, because in all three cases the object carries the nuclear pitch accent. In contrast, in subject-focus utterances, the subject carries the nuclear pitch accent, which is incompatible with broad- or VP-focus interpretation; focus projection does not arise. Unlike English, Georgian, a 'phrase language', relies not on pitch accents but on boundary tones and phrasing in focus marking (Skopeteas & Fery 2010; 2016). This language type has not been explicitly addressed from the perspective of focus projection. Nevertheless, the results reported here demonstrate that the prosodic realization of subject- and object-focus in Georgian, expressed with boundary tones and duration of the stressed syllable, fits with the focus-projection pattern. This paper shows that the Georgian data can be accounted for with the Default Prosody approaches to focus projection, but not approaches employing the formal mechanism of F-projection. Accordingly, the Georgian facts provide a novel argument in favor of the Default Prosody approaches.","2021-11-18","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","1","6","","","","","","","","","","English","","","","WOS:000723082300002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;114</p>","","","GIVENNESS; INTONATION; PROSODY; READ; SPONTANEOUS SPEECH; STRESS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A4WYBE8E","journalArticle","2023","Priva, UC; Strand, E","Schwa?s duration and acoustic position in American English","JOURNAL OF PHONETICS","","0095-4470","10.1016/j.wocn.2022.101198","","Is American English schwa's position determined solely by the context in which it appears? Do vowels neutralize to schwa when their duration is shorter? We address these two inter-related questions using the Buckeye corpus to study vowel behavior across multiple contexts of spontaneous speech. We find that all except tense high vowels shift to lower F1 values when their duration is relatively short, including lax high vowels and lexical schwas, rather than toward a mid-vowel position that schwa occupies when its duration is long. However, we also replicate the finding that schwa is more dependent on both context and duration than other vowels. The results are not consis-tent with the idea that schwa's position is determined exclusively by the context in which it appears. However, schwa's shift to higher F1 values when its duration is longer is not necessarily different from other vowels' shift to higher F1 values when their duration is longer, making it unnecessary to argue that schwa's mid-vowel proper-ties are due to having a target in F1 terms. CO 2022 The Author(s). Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).","2023-01","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","96","","","","","","","","","","English","","","","WOS:000907603300003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","American English; Assimilation; CONTEXT; Corpus study; Duration; FREQUENCY; LENITION; MODEL; Neutralization; Schwa; VOWEL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ENVRBPIQ","journalArticle","2024","Wu, YL; Luo, XL; Guo, FC; Lu, TH; Liu, CM","Research on multi-scenario adaptive acoustic encoders based on neural architecture search","FRONTIERS IN PHYSICS","","2296-424X","10.3389/fphy.2024.1404503","","This paper presents the Scene Adaptive Acoustic Encoder (SAAE) method, which is tailored to diverse acoustic environments for adaptive design. Hand-crafted acoustic encoders often struggle to adapt to varying acoustic conditions, resulting in performance degradation in end-to-end speech recognition tasks. To address this challenge, the proposed SAAE method learns the differences in acoustic features across different environments and accordingly designs suitable acoustic encoders. By incorporating neural architecture search technology, the effectiveness of the encoder design is enhanced, leading to improved speech recognition performance. Experimental evaluations on three commonly used Mandarin and English datasets (Aishell-1, HKUST, and SWBD) demonstrate the effectiveness of the proposed method. The SAAE method achieves an average error rate reduction of more than 5% compared with existing acoustic encoders, highlighting its capability to deeply analyze speech features in specific scenarios and design high-performance acoustic encoders in a targeted manner.","2024-12-12","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","12","","","","","","","","","","English","","","","WOS:001382802400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","acoustic encoder; acoustic features; automatic speech recognition; multi-scenario; neural architecture search","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QM7P77U6","journalArticle","2024","Fresno, ED; López, VM; Batalla, FN","Study of phonological processes in prelingually deaf children with cochlear implants","REVISTA DE INVESTIGACION EN LOGOPEDIA","","2174-5218","10.5209/rlog.90678","","The main aim of the present study was to analyse and compare the frequency and nature of phonological processes in 19 cochlear-implanted prelingually deafened children between 3;0 and 4;6 years of hearing age with a group of 160 normal hearing children. A second aim was to determine whether the nature and frequency of phonological processes varied as a function of elicitation method in CI children. All participants were recorded in spontaneous conversation, which was transcribed and analysed using the CLAN software of the CHILDES Project. The phonological processes paradigm was adopted for the analysis, assessing development based on a phonological error rate calculated from the total number of processes produced and the tokens in spontaneous speech. In addition, CI participants were administered the Phonological Assessment of Child Speech Test. CI participants have a higher phonological error rate than their hearing age peers in all age groups, which would imply slower phonological development. In relation to the nature of the processes, they found more difficulties in processes that reduce the structural complexity of words followed by substitution processes. No significant differences were observed between the auditory age groups in the classes of processes according to the method of elicitation. Early diagnosis of deafness and the use of cochlear implants are emphasized for adequate phonological development.","2024","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","2","14","","","","","","","","","","English","","","","WOS:001245438000006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","ACCURACY; ACQUISITION; AGE; ASSIMILATION; Cochlear implant; hearing age; HEARING-LOSS; KNOWLEDGE; phonological development; phonological processes; SKILLS; SPEECH; SYLLABLES; VOCALIZATIONS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4TTCGP72","journalArticle","2022","Magyari, L; Pléh, C; Forgács, B","The Hungarian hubris syndrome","PLOS ONE","","1932-6203","10.1371/journal.pone.0273226","","Powerful figures, such as politicians, who show a behavioural pattern of exuberant self-confidence, recklessness, and contempt for others may be the subject of the acquired personality disorder, the hubris syndrome, which has been demonstrated to leave its mark on speech patterns. Our study explores characteristic language patterns of Hungarian prime ministers (PMs) with a special emphasis on one of the key indicators of hubris, the shift from the first person ""I"" to ""we"" in spontaneous speech. We analyzed the ratio of the first-person singular (""I"") and plural (""we"") pronouns and verbal inflections in the spontaneous parliamentary speeches of four Hungarian PMs between 1998-2018. We found that Viktor Orban during his second premiership (2010-2014) used first person plural relative to singular inflections more often than the other three PMs during their terms. Orban and another Hungarian PM, Ferenc Gyurcsany, who were re-elected at some point showed an increased ratio of first-person plural vs. singular inflections and personal pronouns by their second term, likely reflecting increasing hubristic tendencies. The results show that the ratio of ""I"" and ""we"" usually studied in English texts also show changes in a structurally different language, Hungarian. This finding suggests that it is extended periods of premiership that may increase hubristic behaviour in political leaders, not only experiencing excessive power. The results are particularly elucidating regarding the role of re-elections in political leaders' hubristic speech-and behaviour.","2022-08-24","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","8","17","","","","","","","","","","English","","","","WOS:000853083500060","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","LEADERSHIP; NARCISSISM; POWER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RIX9MHMV","journalArticle","2022","AI-Atroshi, C; Beulah, JR; Singamaneni, KK; Cyril, CPD; Neelakandan, S; Velmurugan, S","Automated speech based evaluation of mi!d cognitive impairment and Alzheimer's disease detection using with deep belief network model","INTERNATIONAL JOURNAL OF HEALTHCARE MANAGEMENT","","2047-9700","10.1080/20479700.2022.2097764","","Early detection of Moderate Cognitive Impairment (MCI) and Alzheimer's disease (AD) is critical for increasing survival rates. Speech feature extraction is used in prior MCI and AD detection algorithms during neuropsychological assessments by medical specialists. The study's goal is to create an MCI and AD detection model using Automatic Speech Recognition (ASR) and a DL model. The suggested approach largely employs the Gaussian Mixture Model (GMM) for ASR in the patient's spontaneous speech. Furthermore, the Deep Belief Network (DBN) model is used to extract feature vectors from identified voice data. Finally, the SoftMax (SM) classifier is used to detect the presence of MCI and AD disorders in the used speech signals. A series of simulations were run to assess the superior performance of the GMM-DBN (Gaussian Mixture Model-Deep Belief Network model). Effectively describes the distribution of data observations as a weighted average of parameterized Gaussian distributions. The testing results indicated the GMM-DBN model's superior performance, with maximum accuracy of 90.28% and 86.76% on the binary and multiple class classifications, DN respectively. The GMM-DBN methodology has been successful in the classification of multiple classes, as evidenced by its Fl-score reaching a maximum of 90.19% and its accuracy reaching 90.28%.","2022-07-08","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","","","","","","","","","","","English","","","","WOS:000823622500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;16<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Alzheimer disease; Automatic speech recognition; deep learning; mild cognitive impairment; neuropsychological assessment; SELECTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ATWNETBK","journalArticle","2023","Sharma, S; Malhotra, R; Sharma, A; Bala, J; Rattan, P; Vashisht, S","Unsupervised voice activity detection with improved signal-to-noise ratio in noisy environment","INTERNATIONAL JOURNAL OF NANOTECHNOLOGY","","1475-7435","10.1504/IJNT.2023.131122","","To identify voiced and unvoiced signals, this research provides an extended voice characteristic detection strategy for noisy settings that uses feature extraction and unvoiced feature normalisation. In a high signal to noise ratio environment, the proposed method develops a recognition model by recovering characteristics for categorisation of spoken and unvoiced signals. The novelty of this method is that it uses feature extraction to classify voiced and unvoiced signals with a higher signal-to-noise ratio (SNR). Furthermore, by combining two classifiers in a hybrid model, the model is less affected by noise for speech features, and identification performance improves. The model was tested for its ability to increase recognition accuracy. The proposed method produces better results than existing methods, with an accuracy of 99.73% and SNR of 25.61 dB. The proposed model LFV-KANN also handles increases in noise power efficiently through the hybridisation of two classifiers: artificial neural network (ANN) and K-means clustering.","2023","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","1-4","20","","","","","","","","","","English","","","","WOS:001000397500022","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;17</p>","","","support vector machine; TIMIT dataset; unsupervised learning; voice activity detector","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"77XPEVGN","journalArticle","2023","dos Santos, VB; Ayres, A; Kieling, MLM; Miglorini, EC; Jardim, LB; Schumacher-Schuh, AF; Rieder, CRD; de Castilhos, RM; Spencer, K; Rothe-Neves, R; Olchik, MR","Differences in spontaneous speech fluency between Parkinson's disease and spinocerebellar ataxia type 3","FRONTIERS IN NEUROLOGY","","1664-2295","10.3389/fneur.2023.1179287","","BackgroundThe basal ganglia and cerebellum both have a role in speech production although the effect of isolated involvement of these structures on speech fluency remains unclear. ObjectiveThe study aimed to assess the differences in the articulatory pattern in patients with cerebellar vs. basal ganglia disorders. MethodsA total of 20 individuals with Parkinson's disease (PD), 20 with spinocerebellar ataxia type 3 (SCA3), and 40 controls (control group, CG) were included. Diadochokinesis (DDK) and monolog tasks were collected. ResultsThe only variable that distinguished SCA3 carriers from the CG was the number of syllables in the monolog, with SCA3 patients of a significantly lower number. For patients with PD, the number of syllables, phonation time, DDK, and monolog were significantly lower than for CG. Patients with PD were significantly worse compared to patients with SCA3 in the number of syllables and phonation time in DDK, and phonation time in monolog. Additionally, there was a significant correlation between the number of syllables in the monolog and the MDS-UPDRS III for participants with PD, and the Friedreich Ataxia Rating Scale for participants with SCA3 suggesting a relationship between speech and general motor functioning. ConclusionThe monolog task is better at discriminating individuals with cerebellar vs. Parkinson's diseases as well as differentiating healthy control and was related to the severity of the disease.","2023-05-05","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","14","","","","","","","","","","English","","","","WOS:000989415600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","ACQUISITION; articulation disorders; dysarthria; DYSARTHRIA; Parkinson's disease; speech disorders; spinocerebellar ataxia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HLJDEDTF","journalArticle","2021","Liu, D; Chen, LX; Wang, ZY; Diao, GQ","Speech Expression Multimodal Emotion Recognition Based on Deep Belief Network","JOURNAL OF GRID COMPUTING","","1570-7873","10.1007/s10723-021-09564-0","","Aiming at the problems of insufficient information and poor recognition rate in single-mode emotion recognition, a multi-mode emotion recognition method based on deep belief network is proposed. Firstly, speech and expression signals are preprocessed and feature extracted to obtain high-level features of single-mode signals. Then, the high-level speech features and expression features are fused by using the bimodal deep belief network (BDBN), and the multimodal fusion features for classification are obtained, and the redundant information between modes is removed. Finally, the multi-modal fusion features are classified by LIBSVM to realize the final emotion recognition. Based on the Friends data set, the proposed model is demonstrated experimentally. The experimental results show that the recognition accuracy of multimodal fusion feature is the best, which is 90.89%, and the unweighted recognition accuracy of the proposed model is 86.17%, which is better than other comparison methods, and has certain research value and practicability.","2021-06","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","2","19","","","","","","","","","","English","","","","WOS:000651803500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;26<br/>Total Times Cited:&nbsp;&nbsp;28<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Bimodal deep belief network; Expression signal; LIBSVM; Multimodal emotion recognition; Speech signal; VIDEO","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VXHT5JS4","journalArticle","2021","Zhang, HL","Voice Keyword Retrieval Method Using Attention Mechanism and Multimodal Information Fusion","SCIENTIFIC PROGRAMMING","","1058-9244","10.1155/2021/6662841","","A cross-modal speech-text retrieval method using interactive learning convolution automatic encoder (CAE) is proposed. First, an interactive learning autoencoder structure is proposed, including two inputs of speech and text, as well as processing links such as encoding, hidden layer interaction, and decoding, to complete the modeling of cross-modal speech-text retrieval. Then, the original audio signal is preprocessed and the Mel frequency cepstrum coefficient (MFCC) feature is extracted. In addition, the word bag model is used to extract the text features, and then the attention mechanism is used to combine the text and speech features. Through interactive learning CAE, the shared features of speech and text modes are obtained and then sent to modal classifier to identify modal information, so as to realize cross-modal voice text retrieval. Finally, experiments show that the performance of the proposed algorithm is better than that of the contrast algorithm in terms of recall rate, accuracy rate, and false recognition rate.","2021-01-25","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","2021","","","","","","","","","","English","","","","WOS:000617625200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q6ZLB5IY","journalArticle","2022","Chang, LC; Hung, JW","A Preliminary Study of Robust Speech Feature Extraction Based on Maximizing the Probability of States in Deep Acoustic Models","APPLIED SYSTEM INNOVATION","","2571-5577","10.3390/asi5040071","","This study proposes a novel robust speech feature extraction technique to improve speech recognition performance in noisy environments. This novel method exploits the information provided by the original acoustic model in the automatic speech recognition (ASR) system to learn a deep neural network that converts the original speech features. This deep neural network is trained to maximize the posterior accuracy of the state sequences of acoustic models with respect to the speech feature sequences. Compared with the robustness methods that retrain or adapt acoustic models, the new method has the advantages of less computation load and faster training. In the experiments conducted on the medium-vocabulary TIMIT database and task, the presented method provides lower word error rates than the unprocessed baseline and speech-enhancement-based techniques. These results indicate that the presented method is promising and worth further developing.","2022-08","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","4","5","","","","","","","","","","English","","","","WOS:000846238200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","deep learning; ENHANCEMENT; INTELLIGIBILITY; MASK; NETWORKS; NOISE; noise-robust acoustic features; RECOGNITION; speech recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VNC9CEKW","journalArticle","2021","Petrone, C; D'Alessandro, D; Falk, S","Working memory differences in prosodic imitation","JOURNAL OF PHONETICS","","0095-4470","10.1016/j.wocn.2021.101100","","Speakers strongly vary in their imitation abilities, but the factors underlying this variation are still unclear. This study examined whether individual differences in working memory affect the accuracy of imitation of phonological and phonetic aspects of French prosody. Thirty-six French native speakers were asked to listen to twenty sentences extracted from a read and a spontaneous speech corpus, and to repeat the words and the way the utterances were said. Overall, obligatory phonological events (boundary tones and the H* tone of LH* rises) were more accurately reproduced than optional phonological ones (the Hi tone of LHi rises) and their speaker-specific phonetic details. Speakers with higher working memory capacities were more accurate in phonological imitation of both obligatory and optional phonological events, possibly because of their increased capacity in retaining the prosodic charac-teristics of the utterances. Imitating read speech, which was richer in terms of number of LHi rises, was slightly more difficult for speakers with low working memory capacities. There was no relation between working memory and imitation of phonetic aspects, which showed more idiosyncratic patterns of imitation. Our findings indicate that working memory constraints should be taken into account in modelling prosodic imitation, along with linguistic and task-specific factors. (c) 2021 Elsevier Ltd. All rights reserved.","2021-11","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","89","","","","","","","","","","English","","","","WOS:000720503000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;101</p>","","","ATTENTION; CAPACITY; FEATURES; French; INDIVIDUAL-DIFFERENCES; INTONATION; LANGUAGE PRODUCTION; Prosodic imitation; SCOPE; Speaking style; STORAGE; Working memory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L3XUJX69","journalArticle","2023","Guo, ZQ; Ling, ZH","Exploring the Topics of Audio Words for Detecting Alzheimer's Disease From Spontaneous Speech","IEEE SIGNAL PROCESSING LETTERS","","1070-9908","10.1109/LSP.2023.3334696","","Many studies have utilized speech data to automatically detect Alzheimer's Disease (AD). However, most of them simply take the speech data from a subject participating in a task (e.g., picture description) as a whole audio sequence, and lack considerations on separate utterances that may be related to different topics in the picture and are of different importance for discriminating AD patients from healthy controls. To this end, this letter proposes an AD detection method with topic modeling for utterances composed of audio words. First, an audio word discovery algorithm using Byte Pair Encoding (BPE) is designed to tokenize speech data without relying on text transcriptions. Then, a topic model is built that assigns each utterance a topic label in an unsupervised way. Finally, an Audio-Word HuBERT (AW-HuBERT) model integrating utterance-level topic labels is constructed for AD detection. This model is pretrained by training the existing HuBERT model with audio word sequences. The final decision for a recording is made by the weighted sum of utterance-level classification possibilities, and topic-dependent Area-Under-Curve (AUC) values are used as the weights. Experimental results on the DementiaBank dataset show that the proposed method achieves a better AD detection accuracy than state-of-the-art methods.","2023","2025-02-26 20:39:16","2025-02-26 20:39:16","","1727-1731","","","30","","","","","","","","","","English","","","","WOS:001116800400012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Alzheimer's disease; deep learning; natural language processing; NATURAL-HISTORY; Speech processing; TESTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TPCMYVVY","journalArticle","2024","Denbaum-Restrepo, N; Restrepo-Ramos, F","A Sociolinguistic Examination of the Dual Usted in Medellin, Colombia: Evidence from Semi-spontaneous Speech and Implicit Language Attitudes","HISPANIA-A JOURNAL DEVOTED TO THE TEACHING OF SPANISH AND PORTUGUESE","","0018-2133","10.1353/hpn.2024.a921463","","The system of second person singular forms of address (2PS) in Medellin, Colombia is tripartite consisting of tit, vos, and usted, while also including the existence of a dual usted. The current study compares usage of the intimate usted versus the distant usted with data from an oral discourse completion task (DCT) while also investigating listeners' implicit language attitudes toward the usage of usted utilizing the matched guise technique. A sample of speakers from Medellin (N=72) stratified by age, sex, and education level completed an oral DCT, and a subset (N=38) also completed a matched guise task. For usage, it was found that intimate usted occurred 36.7% of the time with distant usted occurring 63.3% of the time. A multivariate mixed effects regression selected all fixed effects as significant. Specifically, intimate usted was favored by commands, statements, indirect commands, male interlocutors, same age interlocutors, male speakers, younger speakers, and speakers with high school education. These findings show that although the default usted usage is with distant interlocutors, the intimate usted is extremely vital, especially between men and with younger speakers. The current study also demonstrates the importance of comparing usage data and attitudinal data.","2024-03","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","1","107","","","","","","","","","","English","","","","WOS:001223267800013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Colombian Spanish; dual usted; language attitudes; LIKERT; matched guise technique; second person singular forms of address","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T5W8HUJK","journalArticle","2023","Cuartero, M; Domínguez, M; Cabo, DPY","Examining Oral (Dis)Fluency in-uh- -Spanish as a Heritage Language","LANGUAGES","","2226-471X","10.3390/languages8030173","","Silence, self-interruptions, or hesitations in spontaneous speech are often interpreted as markers of oral disfluency as they lead to difficulties in delivering a message and in processing it. The main purpose of this study is to examine how such markers of discourse structure factor into the overall oral fluency of 58 US Spanish heritage language learners enrolled in Spanish classes at the college level. Participants were grouped according to age of onset of bilingualism (i.e., sequential or simultaneous) and the order in which they acquired each language (i.e., English first or Spanish first). After completing a semi-controlled oral production task, in both Spanish and English, breakdown pauses and repair pauses were extracted and then analyzed in terms of quantity, quality, and mean duration. Our findings revealed (i) that all groups produced shorter pauses in English, their dominant language; and (ii) that all experimental groups behaved very similarly in Spanish despite having had different experiences with bilingualism growing up. Albeit tentatively, given the sample size and the nature of the present study, we take these findings to suggest that type of heritage bilingualism and the order in which each language was acquired does not seem to play a significant role in terms of production of breakdown and repair pauses.","2023-09","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","3","8","","","","","","","","","","English","","","","WOS:001076205200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","age of acquisition; fluency; FLUENCY; heritage speakers; HESITATION PHENOMENA; pauses; PAUSES; proficiency; Spanish; SPEAKERS; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AITTWTRX","journalArticle","2024","Nirmal, A; Jayaswal, D; Kachare, PH","Statistically Significant Duration-Independent-based Noise-Robust Speaker Verification","INTERNATIONAL JOURNAL OF MATHEMATICAL ENGINEERING AND MANAGEMENT SCIENCES","","2455-7749","10.33889/IJMEMS.2024.9.1.008","","A speaker verification system models individual speakers using different speech features to improve their robustness. However, redundant features degrade the system's performance. This paper presents Statistically Significant Duration -Independent Mel frequency Cepstral Coefficients (SSDI-MFCC) features with the Extreme Gradient Boost classifier for improving the noiserobustness of speaker models. Eight statistical descriptors are used to generate signal duration -independent features, and a statistically significant feature subset is obtained using a t -test. A redeveloped Librispeech database by adding noises from the AURORA database to simulate real-world test conditions for speaker verification is used for evaluation. The SSDI-MFCC is compared with Principal Component Analysis (PCA) and Genetic Algorithm (GA). The comparative results showed average equal error rate improvements by 4.93 % and 3.48 % with the SSDI-MFCC than GA-MFCC and PCA-MFCC in clean and noisy conditions, respectively. A significant reduction in verification time is observed using SSDI-MFCC than the complete feature set.","2024-02","2025-02-26 20:39:16","2025-02-26 20:39:16","","147-162","","1","9","","","","","","","","","","English","","","","WOS:001198850400007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Extreme gradient boost; Feature selection; FEATURE-SELECTION; FEATURES; Mel-frequency cepstral coefficients; MFCC; Speaker verification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I95EKQDV","journalArticle","2023","Iqbal, JLM; Kumar, MS; Mishra, G; Asha, GR; Saritha, AN; Karthik, A; BonthuKotaiah, N","Facial emotion recognition using geometrical features based deep learning techniques","INTERNATIONAL JOURNAL OF COMPUTERS COMMUNICATIONS & CONTROL","","1841-9836","10.15837/ijccc.2023.4.4644","","In recent years, intelligent emotion recognition is active research in computer vision to understand the dynamic communication between machines and humans. As a result, automatic emotion recog-nition allows the machine to assess and acquire the human emotional state to predict the intents based on the facial expression. Researchers mainly focus on speech features and body motions; identifying affect from facial expressions remains a less explored topic. Hence, this paper proposes a novel approach for intelligent facial emotion recognition using optimal geometrical features from facial landmarks using VGG-19s (FCNN). Here, we utilize Haarcascade to detect the subject face and determine the distance and angle measurements.The entire process is to classify the facial ex-pressions based on extracting relevant features with the normalized angle and distance measures. The experimental analysis shows high accuracy on the MUG dataset of 94.22% and 86.45% on GEMEP datasets, respectively.","2023-08","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","4","18","","","","","","","","","","English","","","","WOS:001019345800007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Emotion Recognition; Facial Analysis; Facial Landmarks; Feature Extraction; Geometrical features; Hyper parameters; MANET; VGG-19s","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MTLHCN9F","journalArticle","2024","Eigsti, IM; Pouw, W","Deliberate synchronization of speech and gesture: effects of neurodiversity and development","LANGUAGE AND COGNITION","","1866-9808","10.1017/langcog.2024.33","","The production of speech and gesture is exquisitely temporally coordinated. In autistic individuals, speech-gesture synchrony during spontaneous discourse is disrupted. To evaluate whether this asynchrony reflects motor coordination versus language production processes, the current study examined deliberately performed hand movements during speech in youth with autism spectrum disorder (ASD) compared to neurotypical youth. Neurotypical adult performance provided a mature baseline. Participants read aloud rhythmic nursery rhymes, while producing a beat-like hand movement. An automated pixel-change video measure identified kinematic peaks; using smoothed acoustic envelope analyses, we identified peaks in speech. Results indicated few diagnostic group differences in explicit speech-movement coordination, although adolescent performance differed from adults. Adults demonstrated higher tempo and greater rhythmicity in their coordination; this group difference suggests that the method is sufficiently subtle to reveal individual differences and that this form of complex coordination undergoes ongoing maturation beyond adolescence. The sample is small, and thus results are necessarily preliminary. In the context of prior speech-gesture coordination studies, these findings of intact synchrony are consistent with the hypothesis that it is the demands of discourse planning, rather than motor coordination, that have led to prior findings of asynchrony during spontaneous speech; this possibility awaits future research.","2024-12","2025-02-26 20:39:16","2025-02-26 20:39:16","","1812-1833","","4","16","","","","","","","","","","English","","","","WOS:001318054600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;118</p>","","","ACQUISITION; autism spectrum disorder; beat gesture; BEHAVIOR; CHILDREN; COMMUNICATIVE DEVELOPMENT; HIGH-FUNCTIONING AUTISM; INFANTILE-AUTISM; JOINT ATTENTION; LANGUAGE-DEVELOPMENT; MOTOR; perception-action coordination; praxis motor control; SPECTRUM DISORDERS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5MWLGPKZ","journalArticle","2024","Listanti, A; Torregrossa, J","The development of postverbal subjects in L2 Italian: A multifactorial corpus analysis","APPLIED PSYCHOLINGUISTICS","","0142-7164","10.1017/S014271642400002X","","Most studies on the acquisition of postverbal subjects (VS) in L2 Italian focus on a limited number of linguistic factors that tend to be associated with the production of VS in L1 (e.g., verb class and subject discourse status). Moreover, they analyze homogeneous groups of learners in terms of proficiency, mostly through controlled experiments. In this paper, we present a cross-sectional corpus study based on a multifactorial analysis of the L2 use of VS structures in semi-spontaneous speech. We analyze the production of VSs by learners of different levels of proficiency (A1-C2), considering linguistic factors that trigger the production of VS in L1, but have been unaccounted for in L2 studies (e.g., agentivity of the subject, syntactic configuration of the sentence, contrastive focus). We use a cumulative link mixed model to show how the features of verbs and subjects in VS structures change across proficiency levels. The results indicate learners' progressive mastery of the mechanisms of assignment of the subject function to the postverbal constituent and increasing sensitivity to contrastive focus as a feature relevant for the use of VS. Furthermore, we observe that psychological verbs associated with the use of VS are produced from the earliest stages of L2 acquisition.","2024-01","2025-02-26 20:39:16","2025-02-26 20:39:16","","180-212","","1","45","","","","","","","","","","English","","","","WOS:001161283000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;80</p>","","","ACQUISITION; adult second language acquisition; COMPLEXITY; FOCUS; INTERFACES; LANGUAGE; language production; SYNTAX; WORD-ORDER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7KE67TDI","journalArticle","2022","Lozano-Goupil, J; Raffard, S; Capdevielle, D; Aigoin, E; Marin, L","Gesture-speech synchrony in schizophrenia: A pilot study using a kinematic-acoustic analysis","NEUROPSYCHOLOGIA","","0028-3932","10.1016/j.neuropsychologia.2022.108347","","Severe impairment of social functioning is the core feature of schizophrenia that persists despite treatment, and contributes to chronic functional disability. Abnormal non-verbal behaviors have been reported during interpersonal interactions but the temporal coordination of co-speech gestures with language abilities have been poorly studied to date in this pathology. Using the dynamical systems framework, the goal of the current study was to investigate whether gestures and speech synchrony is impaired in schizophrenia, exploring a new approach to report communicational skill disorders. Performing the first continuous kinematic-acoustic analysis in individuals with schizophrenia, we examined gesture-speech synchrony in solo spontaneous speech and in sensorimotor synchronization task. The experimental group consisted of twenty-eight participants with a diagnosis of schizophrenia and the control group consisted of twenty-four healthy participants age-gender-education matched. The results showed that spontaneous gesture-speech synchrony was preserved while intentional finger tapping-speech synchrony was impaired. In sensorimotor synchronization task, the schizophrenia group displayed greater asynchronies between finger tapping and syllable uttering and lower stability of coordination patterns. These findings suggest a specific deficit in time delay of information circulation and processing, especially in explicit functions. Thus, investigating intrapersonal coordination in schizophrenia may constitute a promising window into brain/behavior dynamic relationship.","2022-09-09","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","174","","","","","","","","","","English","","","","WOS:000874773800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;94</p>","","","BEHAVIOR; BRAIN ACTIVATION; CONNECTIVITY; Dynamic systems; EMOTIONAL PROSODY; Gesture -speech synchrony; Kinematics; MANUAL GESTURE; NONVERBAL-COMMUNICATION; RECOGNITION; Schizophrenia; Sensorimotor synchronization; SOCIAL COGNITION; SPECTRUM DISORDERS; VALIDATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X3AC6B72","journalArticle","2022","Faes, J; De Maeyer, S; Gillis, S","Speech intelligibility of children with an auditory brainstem implant: a triple-case study","CLINICAL LINGUISTICS & PHONETICS","","0269-9206","10.1080/02699206.2021.1988148","","Auditory brainstem implantation (ABI) is a relative recent development in paediatric hearing restoration. Consequently, young-implanted children's productive language has not received much attention. This study investigated speech intelligibility of children with ABI (N = 3) in comparison to children with cochlear implants (CI) and children with typical hearing (TH). Spontaneous speech samples were recorded from children representing the three groups matched on cumulative vocabulary level. Untrained listeners (N = 101) rated the intelligibility of one-word utterances on a continuous scale and transcribed each utterance. The rating task yielded a numerical score between 0 and 100, and similarities and differences between the listeners' transcriptions were captured by a relative entropy score. The speech intelligibility of children with CI and children with TH was similar. Speech intelligibility of children with ABI was well below that of the children with CI and TH. But whereas one child with ABI's intelligibility approached that of the control groups with increasing lexicon size, the intelligibility of the two other children with ABI did not develop in a similar direction. Overall, speech intelligibility was only moderate in the three groups of children, with quite low ratings and considerable differences in the listeners' transcriptions, resulting in high relative entropy scores.","2022-12-02","2025-02-26 20:39:16","2025-02-26 20:39:16","","1067-1092","","12","36","","","","","","","","","","English","","","","WOS:000778921500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;93</p>","","","2ND YEAR; AGE; Auditory brainstem implant; child language; cochlear implant; COCHLEAR IMPLANT; DEAF-CHILDREN; HEARING-LOSS; LANGUAGE-DEVELOPMENT; PERCEPTION; perceptual experiment; SINGLE-WORD INTELLIGIBILITY; speech intelligibility; VARIABILITY; YOUNG-CHILDREN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KDZEIEKY","journalArticle","2024","Naik, NB; Mathew, PJ; Kundra, P","Scope of artificial intelligence in airway management","INDIAN JOURNAL OF ANAESTHESIA","","0019-5049","10.4103/ija.ija_1228_23","","The evolution of artificial intelligence (AI) systems in the field of anaesthesiology owes to notable advancements in data processing, databases, algorithmic programs, and computation power. Over the past decades, its accelerated progression has enhanced safety in anaesthesia by improving the efficiency of equipment, perioperative risk assessments, monitoring, and drug administration systems. AI in the field of anaesthesia aims to improve patient safety, optimise resources, and improve the quality of anaesthesia management in all phases of perioperative care. The use of AI is likely to impact difficult airway management and patient safety considerably. AI has been explored to predict difficult intubation to outperform conventional airway examinations by integrating subjective factors, such as facial appearance, speech features, habitus, and other poorly known features. This narrative review delves into the status of AI in airway management, the most recent developments in this field, and its future clinical applications.","2024-01","2025-02-26 20:39:16","2025-02-26 20:39:16","","105-110","","1","68","","","","","","","","","","English","","","","WOS:001144146100017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Airway management; algorithmic programmes airway; anaesthesiology; ANESTHESIA; artificial intelligence; CHIN-SUPPORT; CLASSIFICATION; COMPLICATIONS; DIFFICULT INTUBATION; intelligence; management; METAANALYSIS; model; PATIENT; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JANW9GJM","journalArticle","2024","Zhang, K; Ting, HN; Choo, YM","Baby cry recognition based on SLGAN model data generation and deep feature fusion","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2023.122681","","Deep learning models have been applied in baby cry recognition to enhance the recognition accuracy. However, the current research still suffers from data imbalance problem, which leads to bias in model learning. Sparse Autoencoder Long Short-Term Memory based Generative Adversarial Network (SLGAN) is proposed to solve the data imbalance problem. The proposed SLGAN model generates new baby cry data to ensure the number of samples for every cry class is equal. Speech features are extracted using Mel-spectrograms and Short-Time Fourier Transform (STFT). Two deep learning models, i.e. VGG16 and VGG19 are used to extract the deep features. The deep features are then dimensionally reduced by using Principal Component Analysis (PCA). A sparse autoencoder model is used to fuse the deep features. Finally, the fused features are trained and classified using the Deep Neural Network. The experimental results show that the proposed method outperforms the existing methods.","2024-05-15","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","242","","","","","","","","","","English","","","","WOS:001133970600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Baby cry; CLASSIFICATION; Data generation; Feature fusion; Generative adversarial networks (GANs); Sparse autoencoder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VD896BRZ","journalArticle","2023","Ilias, L; Askounis, D; Psarras, J","Detecting dementia from speech and transcripts using transformers","COMPUTER SPEECH AND LANGUAGE","","0885-2308","10.1016/j.csl.2023.101485","","Alzheimer's disease (AD) constitutes a neurodegenerative disease with serious consequences to peoples' everyday lives, if it is not diagnosed early since there is no available cure. Alzheimer's is the most common cause of dementia, which constitutes a general term for loss of memory. Due to the fact that dementia affects speech, existing research initiatives focus on detecting dementia from spontaneous speech. However, little work has been done regarding the conversion of speech data to Log-Mel spectrograms and Mel-frequency cepstral coefficients (MFCCs) and the usage of pretrained models. Concurrently, little work has been done in terms of both the usage of transformer networks and the way the two modalities, i.e., speech and transcripts, are combined in a single neural network. To address these limitations, first we represent speech signal as an image and employ several pretrained models, with Vision Transformer (ViT) achieving the highest evaluation results. Secondly, we propose multimodal models. More specifically, our introduced models include Gated Multimodal Unit in order to control the influence of each modality towards the final classification and crossmodal attention so as to capture in an effective way the relationships between the two modalities. Extensive experiments conducted on the ADReSS Challenge dataset demonstrate the effectiveness of the proposed models and their superiority over state-of-the-art approaches.","2023-04","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","79","","","","","","","","","","English","","","","WOS:000960675900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;79</p>","","","Crossmodal attention; Dementia; Gated multimodal unit; log-Mel spectrogram; Mel-frequency cepstral coefficients; RECOGNITION; Speech; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W9RQTLXD","journalArticle","2021","Robinson, GA; Shi, L; Nott, Z; Ceslis, A","A Brief Executive Language Screen for Frontal Aphasia","BRAIN SCIENCES","","2076-3425","10.3390/brainsci11030353","","Aphasia assessment tools have primarily focused on classical aphasia type and severity, with minimal incorporation of recent findings that suggest a significant role of executive control operations in language generation. Assessment of the interface between language and executive functions is needed to improve detection of spontaneous speech difficulties. In this study we develop a new Brief Executive Language Screen (BELS), a brief tool specifically designed to assess core language and executive functions shown to be involved in spontaneous generation of language. Similar to other measures of aphasia, the BELS assesses articulation and core language skills (repetition, naming and comprehension). Unique additions to the BELS include assessments of spontaneous connected speech, word fluency (phonemic/semantic) and sentence completion (verbal initiation, inhibition and selection). One-hundred and eight healthy controls and 136 stroke patients were recruited. Confirmatory factor analysis was used to determine construct validity and logistic regression was used to evaluate the discriminative validity, informing the final version of the BELS. The results showed that the BELS is sensitive for articulation and nominal language deficits, and it measures executive aspects of spontaneous language generation, which is a hallmark of frontal dynamic aphasia. The results have encouraging theoretical and practical implications.","2021-03","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","3","11","","","","","","","","","","English","","","","WOS:000633428300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","aphasia screening; DYNAMIC APHASIA; executive functions; GENERATION; IMPAIRMENTS; inhibitory control; initiation; language test; LEXICAL ACCESS; PROGRESSIVE SUPRANUCLEAR PALSY; propositional language; selection; SELECTION; SPEECH; STROKE; verbal fluency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"79U5F2UA","journalArticle","2023","Sultana, S; Rahman, MS","Acoustic feature analysis and optimization for Bangla speech emotion recognition","ACOUSTICAL SCIENCE AND TECHNOLOGY","","1346-3969","10.1250/ast.44.157","","To better understand human behavior, it is essential to investigate the speech features that contribute the most to emotional expressions. In this study, we investigated how different emotions affect the acoustic properties of speech. This study explored a new set of widely utilized acoustic features to recognize emotions from audios. Experimental investigation using the Bangla and English emotional datasets were conducted using SVM, Random forest, and XGBoost algorithm. We used the Grid Search method with five-fold cross-validation to select the optimal parameters for obtaining the best results from the models. Again a five-fold cross-validation was applied to evaluate the models' effectiveness in emotion perception. The XGBoost analysis was employed to calculate the feature importance of speech emotion identification from the datasets. We found that selecting the most important features allows a high level of accuracy in using ML models that is competitive with deep learning models' performance while utilizing less computational complexity.","2023","2025-02-26 20:39:16","2025-02-26 20:39:16","","157-166","","3","44","","","","","","","","","","English","","","","WOS:000975885000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","Feature optimization; FEATURE-SELECTION; Machine learning; Random forest; SIGNALS; Speech emotion recognition; SVM; XGBoost","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5U76WRDM","journalArticle","2024","Lee, H; Cho, M; Kwon, HY","Attention-based speech feature transfer between speakers","FRONTIERS IN ARTIFICIAL INTELLIGENCE","","2624-8212","10.3389/frai.2024.1259641","","In this study, we propose a simple yet effective method for incorporating the source speaker's characteristics in the target speaker's speech. This allows our model to generate the speech of the target speaker with the style of the source speaker. To achieve this, we focus on the attention model within the speech synthesis model, which learns various speaker features such as spectrogram, pitch, intensity, formant, pulse, and voice breaks. The model is trained separately using datasets specific to the source and target speakers. Subsequently, we replace the attention weights learned from the source speaker's dataset with the attention weights from the target speaker's model. Finally, by providing new input texts to the target model, we generate the speech of the target speaker with the styles of the source speaker. We validate the effectiveness of our model through similarity analysis utilizing five evaluation metrics and showcase real-world examples.","2024-02-26","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","7","","","","","","","","","","English","","","","WOS:001179282200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;11</p>","","","attention mechanism; feature transfer; speech features; speech similarity; speech synthesis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7R5ED3LK","journalArticle","2022","Khan, DUR; Ali, SA; Khan, HD","A Comparison of Machine Learning Methods using Correlated Speech Features in the Presence of Varied Noise","INTERNATIONAL JOURNAL OF COMPUTER SCIENCE AND NETWORK SECURITY","","1738-7906","10.22937/IJCSNS.2022.22.4.63","","Speech signal analysis processing helps extract information from both clean and noisy speech signals, and machine learning algorithms provide robust analytical tools for signal exploration. In this research (14) speech signal features were analyzed using machine learning tools with the following corpuses of speech commands: clean speech, with average noise, and with high noise. The analysis is based on the selection of the most correlated feature of distant and noisy speech along with the implementation of three (03) conventional learning (random forest nearest neighbor, voting model, and support vector machine (SVM)) and deep learning (Long short-term memory (LSTM)) models. This study presents a comprehensive result of selected features with clean, average noise, and very high-noise speech corpuses. The respective signal features performed well with a support vector machine (SVM) with no noise and average noise corpuses. However, LSTM shows significant results with high-noise corpus inters with macro-and average-weighted accuracy.","2022-04-30","2025-02-26 20:39:16","2025-02-26 20:39:16","","535-544","","4","22","","","","","","","","","","English","","","","WOS:000800673100013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","learning algorithms; LSTM; robust speech; speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A8F6KMNW","journalArticle","2023","Mangal, M; Kumar, P; Munjal, S; Sharma, RK","Endoscopic evaluation of velopharyngeal function in cleft lip palate patients-A correlation with speech analysis","JOURNAL OF PLASTIC RECONSTRUCTIVE AND AESTHETIC SURGERY","","1748-6815","10.1016/j.bjps.2022.10.041","","Background: Speech abnormalities due to velopharyngeal insufficiency (VPI) sig-nificantly affect communication skills, self-esteem, and scholastic performance. It leads to a poor social, emotional, educational, and behavioral development and a poor quality of life overall in cleft lip palate (CLP) patients. Its early diagnosis and severity assessment using video-nasoendoscopy and speech assessment can significantly contribute to management. The present study evaluated VPI in CLP patients using both tools. Methods: A total of 48 patients with repaired cleft palate were subjected to speech and video-nasoendoscopic assessment. Speech assessment measured severity of hypernasality, speech in-telligibility, and voice quality. Video-nasoendoscopy evaluated velopharyngeal port closure to grade the severity of VPI. The speech assessment and video-nasoendoscopy findings were ana-lyzed and correlated. Results: There was a moderately strong statistically significant negative correlation between the grade of VPI and hypernasality ( r =-0.542, p = 0.000). There was a stronger statistically significant negative correlation of grade of velopharyngeal port insufficiency with speech intel-ligibility ( r =-0.634, p = 0.000). About 72% of the patients had abnormal voice quality. Conclusion: This study is the first attempt at diagnosing and grading VPI on a quantitative scoring based on a ratio scale for the motion of soft palate and pharyngeal walls. The strong correlation between endoscopic grading and speech analysis findings warrants further evalua-tion of nasoendoscopic grading of VPI in more studies.(c) 2022 British Association of Plastic, Reconstructive and Aesthetic Surgeons. Published by El-sevier Ltd. All rights reserved.","2023-02","2025-02-26 20:39:16","2025-02-26 20:39:16","","170-176","","","77","","","","","","","","","","English","","","","WOS:000987124400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","analysis; Cleft palate; DYSFUNCTION; INCOMPETENCE; insufficiency (VPI); Nasoendoscopy; Perceptual speech; Velopharyngeal","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VRAX6GMQ","journalArticle","2024","Angelopoulou, G; Kasselimis, D; Goutsos, D; Potagas, C","A Methodological Approach to Quantifying Silent Pauses, Speech Rate, and Articulation Rate across Distinct Narrative Tasks: Introducing the Connected Speech Analysis Protocol (CSAP)","BRAIN SCIENCES","","2076-3425","10.3390/brainsci14050466","","The examination of connected speech may serve as a valuable tool for exploring speech output in both healthy speakers and individuals with language disorders. Numerous studies incorporate various fluency and silence measures into their analyses to investigate speech output patterns in different populations, along with the underlying cognitive processes that occur while speaking. However, methodological inconsistencies across existing studies pose challenges in comparing their results. In the current study, we introduce CSAP (Connected Speech Analysis Protocol), which is a specific methodological approach to investigate fluency metrics, such as articulation rate and speech rate, as well as silence measures, including silent pauses' frequency and duration. We emphasize the importance of employing a comprehensive set of measures within a specific methodological framework to better understand speech output patterns. Additionally, we advocate for the use of distinct narrative tasks for a thorough investigation of speech output in different conditions. We provide an example of data on which we implement CSAP to showcase the proposed pipeline. In conclusion, CSAP offers a comprehensive framework for investigating speech output patterns, incorporating fluency metrics and silence measures in distinct narrative tasks, thus allowing a detailed quantification of connected speech in both healthy and clinical populations. We emphasize the significance of adopting a unified methodological approach in connected speech studies, enabling the integration of results for more robust and generalizable conclusions.","2024-05","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","5","14","","","","","","","","","","English","","","","WOS:001232428400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;72</p>","","","APHASIA; articulation rate; connected speech; DEFICITS; DISCOURSE; MARKER; QUANTITATIVE-ANALYSIS; SENTENCE PRODUCTION; silent pauses; speech rate; SPONTANEOUS LANGUAGE PRODUCTION; STORY; WORD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L3MVPKIL","journalArticle","2021","Amato, F; Borzi, L; Olmo, G; Orozco-Arroyave, JR","An algorithm for Parkinson's disease speech classification based on isolated words analysis","HEALTH INFORMATION SCIENCE AND SYSTEMS","","2047-2501","10.1007/s13755-021-00162-8","","Introduction Automatic assessment of speech impairment is a cutting edge topic in Parkinson's disease (PD). Language disorders are known to occur several years earlier than typical motor symptoms, thus speech analysis may contribute to the early diagnosis of the disease. Moreover, the remote monitoring of dysphonia could allow achieving an effective follow-up of PD clinical condition, possibly performed in the home environment. Methods In this work, we performed a multi-level analysis, progressively combining features extracted from the entire signal, the voiced segments, and the on-set/off-set regions, leading to a total number of 126 features. Furthermore, we compared the performance of early and late feature fusion schemes, aiming to identify the best model configuration and taking advantage of having 25 isolated words pronounced by each subject. We employed data from the PC-GITA database (50 healthy controls and 50 PD patients) for validation and testing. Results We implemented an optimized k-Nearest Neighbours model for the binary classification of PD patients versus healthy controls. We achieved an accuracy of 99.4% in 10-fold cross-validation and 94.3% in testing on the PC-GITA database (average value of male and female subjects). Conclusion The promising performance yielded by our model confirms the feasibility of automatic assessment of PD using voice recordings. Moreover, a post-hoc analysis of the most relevant features discloses the option of voice processing using a simple smartphone application.","2021-07-30","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","1","9","","","","","","","","","","English","","","","WOS:000679721900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;27<br/>Total Times Cited:&nbsp;&nbsp;31<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Artificial Intelligence; DYSARTHRIA; FREQUENCY; Isolated words; k-Nearest neighbours; Parkinson's disease; Speech analysis; Speech impairment; Telemedicine; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WE662A4A","journalArticle","2024","Rizhinashvili, D; Sham, AH; Anbarjafari, G","Enhanced speech emotion recognition using averaged valence arousal dominance mapping and deep neural networks","SIGNAL IMAGE AND VIDEO PROCESSING","","1863-1703","10.1007/s11760-024-03406-8","","This study delves into advancements in speech emotion recognition (SER) by establishing a novel approach for emotion mapping and prediction using the Valence-Arousal-Dominance (VAD) model. Central to this research is the creation of reliable emotion-to-VAD mappings, achieved by averaging outcomes from multiple pre-trained networks applied to the RAVDESS dataset. This approach adeptly resolves prior inconsistencies in emotion-to-VAD mappings and establishes a dependable framework for SER. The study also introduces a refined SER model, integrating the pre-trained Wave2Vec 2.0 with Long Short-Term Memory (LSTM) networks and linear layers, culminating in an output layer representing valence, arousal, and dominance. Notably, this model exhibits commendable accuracy across various datasets, such as RAVDESS, EMO-DB, CREMA-D, and TESS, thereby showcasing its robustness and adaptability, an improvement over earlier models susceptible to dataset-specific overfitting. The research further unveils a comprehensive speech analysis application, adept at denoising, segmenting, and profiling emotions in speech segments. This application features interactive emotion tracking and sentiment reports, illustrating its practicality in diverse applications. The study recognizes ongoing challenges in SER, especially in managing the subjective nature of emotion perception and integrating multimodal data. Although the research marks a progression in SER technology, it underscores the need for continuous research and careful consideration of ethical aspects in deploying such technologies. This work contributes to the SER domain by introducing a dependable method for emotion mapping, a robust model for emotion recognition, and a user-friendly application for practical implementations.","2024-09","2025-02-26 20:39:16","2025-02-26 20:39:16","","7445-7454","","10","18","","","","","","","","","","English","","","","WOS:001268845200002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Deep neural networks; FEATURES; LSTM; Speech analysis; Speech emotion recognition; Valence arousal dominance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XZC7LHRZ","journalArticle","2023","Shrivastava, P; Tripathi, N; Singh, BK; Dewangan, BK","Comparative Analysis of Classifiers for the Assessment of Respiratory Disorders Using Speech Parameters","ARCHIVES OF ACOUSTICS","","0137-5075","10.24425/aoa.2022.142905","","Non-invasive techniques for the assessment of respiratory disorders have gained increased importance in recent years due to the complexity of conventional methods. In the assessment of respiratory disorders, machine learning may play a very essential role. Respiratory disorders lead to variation in the production of speech as both go hand in hand. Thus, speech analysis can be a useful means for the pre-diagnosis of respiratory disorders. This article aims to develop a machine learning approach to differentiate healthy speech from speech corresponding to different respiratory disorders (affected). Thus, in the present work, a set of 15 relevant and efficient features were extracted from acquired data, and classification was done using different classifiers for healthy and affected speech. To assess the performance of different classifiers, accuracy, specificity (Sp), sensitivity (Se), and area under the receiver operating characteristic curve (AUC) was used by applying both multi-fold cross-validation methods (5-fold and 10-fold) and the holdout method. Out of the studied classifiers, decision tree, support vector machine (SVM), and k-nearest neighbor (KNN) were found more appropriate in providing correct assessment clinically while considering 15 features as well as three significant features (Se > 89%, Sp > 89%, AUC > 82%, and accuracy > 99%). The conclusion was that the proposed classifiers may provide an aid in the simple assessment of respiratory disorders utilising speech parameters with high efficiency. In the future, the proposed approach can be evaluated for the detection of specific respiratory disorders such as asthma, COPD, etc.","2023","2025-02-26 20:39:16","2025-02-26 20:39:16","","13-24","","1","48","","","","","","","","","","English","","","","WOS:000946268600002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","affected speech; CLASSIFICATION; classification techniques; DIAGNOSIS; healthy speech; machine learning; PREDICTION; respiratory disorders; speech analysis; SUPPORT VECTOR MACHINES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RKPN5A7D","journalArticle","2024","Rini, PL; Gayathri, KS","Revolutionizing dementia detection: Leveraging vision and Swin transformers for early diagnosis","AMERICAN JOURNAL OF MEDICAL GENETICS PART B-NEUROPSYCHIATRIC GENETICS","","1552-4841","10.1002/ajmg.b.32979","","Dementia, an increasingly prevalent neurological disorder with a projected threefold rise globally by 2050, necessitates early detection for effective management. The risk notably increases after age 65. Dementia leads to a progressive decline in cognitive functions, affecting memory, reasoning, and problem-solving abilities. This decline can impact the individual's ability to perform daily tasks and make decisions, underscoring the crucial importance of timely identification. With the advent of technologies like computer vision and deep learning, the prospect of early detection becomes even more promising. Employing sophisticated algorithms on imaging data, such as positron emission tomography scans, facilitates the recognition of subtle structural brain changes, enabling diagnosis at an earlier stage for potentially more effective interventions. In an experimental study, the Swin transformer algorithm demonstrated superior overall accuracy compared to the vision transformer and convolutional neural network, emphasizing its efficiency. Detecting dementia early is essential for proactive management, personalized care, and implementing preventive measures, ultimately enhancing outcomes for individuals and lessening the overall burden on healthcare systems.","2024-10","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","7","195","","","","","","","","","","English","","","","WOS:001202443100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","CNN; deep learning; dementia; PET scans; Swin transformer; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5GFDJTSC","journalArticle","2022","Tripathi, T; Kumar, R","Performance Comparison of Machine Learning Algorithms for Dementia Progression Detection","INTERNATIONAL JOURNAL OF SOFTWARE SCIENCE AND COMPUTATIONAL INTELLIGENCE-IJSSCI","","1942-9045","10.4018/IJSSCI.312553","","Dementia is a neurological disease that that encompasses a wide range of conditions like verbal communication, problem-solving, and other judgment abilities that are severely sufficient to interfere with daily life. It is among the leading causes of vulnerability among the elderly all over the world. A considerable amount of research has been conducted in this area so that we can perform early detection of the disease, yet further research into its betterment is still an emerging trend. This article compares the performance of multiple machine learning models for dementia detection and classification using brain MRI data, including support vector machine, random forest, AdaBoost, and XGBoost. Meanwhile, the research conducts a systematic assessment of papers for the clinical categorization of dementia using ML algorithms and neuroimaging data. The authors used 373 participants from the OASIS database. Among the tested models, RF model exhibited the best performance with 83.92% accuracy, 87.5% precision, 81.67% recall, 84.48% F1-score, 81.67% sensitivity, and 88.46% specificity.","2022","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","1","14","","","","","","","","","","English","","","","WOS:000924286200024","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Alzheimer's Disease; ALZHEIMERS-DISEASE; Classification; CLASSIFICATION; DIAGNOSIS; Machine Learning; Magnetic Resonance Imaging; MILD COGNITIVE IMPAIRMENT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XDCI8MKJ","journalArticle","2023","Zhao, JS; Berge, TW; Geipel, J","Transformer in UAV Image-Based Weed Mapping","REMOTE SENSING","","2072-4292","10.3390/rs15215165","","Weeds affect crop yield and quality due to competition for resources. In order to reduce the risk of yield losses due to weeds, herbicides or non-chemical measures are applied. Weeds, especially creeping perennial species, are generally distributed in patches within arable fields. Hence, instead of applying control measures uniformly, precision weeding or site-specific weed management (SSWM) is highly recommended. Unmanned aerial vehicle (UAV) imaging is known for wide area coverage and flexible operation frequency, making it a potential solution to generate weed maps at a reasonable cost. Efficient weed mapping algorithms need to be developed together with UAV imagery to facilitate SSWM. Different machine learning (ML) approaches have been developed for image-based weed mapping, either classical ML models or the more up-to-date deep learning (DL) models taking full advantage of parallel computation on a GPU (graphics processing unit). Attention-based transformer DL models, which have seen a recent boom, are expected to overtake classical convolutional neural network (CNN) DL models. This inspired us to develop a transformer DL model for segmenting weeds, cereal crops, and 'other' in low-resolution RGB UAV imagery (about 33 mm ground sampling distance, g.s.d.) captured after the cereal crop had turned yellow. Images were acquired during three years in 15 fields with three cereal species (Triticum aestivum, Hordeum vulgare, and Avena sativa) and various weed flora dominated by creeping perennials (mainly Cirsium arvense and Elymus repens). The performance of our transformer model, 1Dtransformer, was evaluated through comparison with a classical DL model, 1DCNN, and two classical ML methods, i.e., random forest (RF) and k-nearest neighbor (KNN). The transformer model showed the best performance with an overall accuracy of 98.694% on pixels set aside for validation. It also agreed best and relatively well with ground reference data on total weed coverage, R2 = 0.598. In this study, we showed the outstanding performance and robustness of a 1Dtransformer model for weed mapping based on UAV imagery for the first time. The model can be used to obtain weed maps in cereals fields known to be infested by perennial weeds. These maps can be used as basis for the generation of prescription maps for SSWM, either pre-harvest, post-harvest, or in the next crop, by applying herbicides or non-chemical measures.","2023-11","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","21","15","","","","","","","","","","English","","","","WOS:001100295700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","1Dtransformer; CIRSIUM-ARVENSE; low-resolution UAV image; MANAGEMENT; perennial weed mapping; USAGE; VISION; WHEAT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FAY9Z86R","journalArticle","2024","Oliver, M; Allou, N; Devineau, M; Allyn, J; Ferdynus, C","A transformer model for cause-specific hazard prediction","BMC BIOINFORMATICS","","1471-2105","10.1186/s12859-024-05799-2","","Backgroud Modelling discrete-time cause-specific hazards in the presence of competing events and non-proportional hazards is a challenging task in many domains. Survival analysis in longitudinal cohorts often requires such models; notably when the data is gathered at discrete points in time and the predicted events display complex dynamics. Current models often rely on strong assumptions of proportional hazards, that is rarely verified in practice; or do not handle sequential data in a meaningful way. This study proposes a Transformer architecture for the prediction of cause-specific hazards in discrete-time competing risks. Contrary to Multilayer perceptrons that were already used for this task (DeepHit), the Transformer architecture is especially suited for handling complex relationships in sequential data, having displayed state-of-the-art performance in numerous tasks with few underlying assumptions on the task at hand.Results Using synthetic datasets of 2000-50,000 patients, we showed that our Transformer model surpassed the CoxPH, PyDTS, and DeepHit models for the prediction of cause-specific hazard, especially when the proportional assumption did not hold. The error along simulated time outlined the ability of our model to anticipate the evolution of cause-specific hazards at later time steps where few events are observed. It was also superior to current models for prediction of dementia and other psychiatric conditions in the English longitudinal study of ageing cohort using the integrated brier score and the time-dependent concordance index. We also displayed the explainability of our model's prediction using the integrated gradients method.Conclusions Our model provided state-of-the-art prediction of cause-specific hazards, without adopting prior parametric assumptions on the hazard rates. It outperformed other models in non-proportional hazards settings for both the synthetic dataset and the longitudinal cohort study. We also observed that basic models such as CoxPH were more suited to extremely simple settings than deep learning models. Our model is therefore especially suited for survival analysis on longitudinal cohorts with complex dynamics of the covariate-to-outcome relationship, which are common in clinical practice. The integrated gradients provided the importance scores of input variables, which indicated variables guiding the model in its prediction. This model is ready to be utilized for time-to-event prediction in longitudinal cohorts.","2024-05-03","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","1","25","","","","","","","","","","English","","","","WOS:001221282900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Cause-specific hazard; Competing risks; English longitudinal study of ageing; Synthetic data; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I2GFA86V","journalArticle","2023","Kumar, S; Ghosal, T; Ekbal, A","DeepMetaGen: an unsupervised deep neural approach to generate template-based meta-reviews leveraging on aspect category and sentiment analysis from peer reviews","INTERNATIONAL JOURNAL ON DIGITAL LIBRARIES","","1432-5012","10.1007/s00799-023-00348-3","","Peer reviews form an essential part of scientific communication. Scholarly peer review is probably the most accepted way to evaluate research papers by involving multiple experts to review the concerned research independently. Usually, the area chair, the program chair, or the editor takes a call weighing the reviewer's judgments. It communicates the decision to the author via writing a meta-review by summarizing the review comments. With the exponential rise in research paper submissions and the corresponding rise in the reviewer pool, it becomes stressful for the chairs/editors to manage conflicts, arrive at a consensus, and also write an informative meta-review. Here in this work, we propose a novel deep neural network-based approach for generating meta-reviews in an unsupervised fashion. To generate consistent meta-reviews, we use a generic template where the task is like to slot-fill the template with the generated meta-review text. We consider the setting where only peer reviews with no summaries or meta-reviews are provided and propose an end-to-end neural network model to perform unsupervised opinion-based abstractive summarization. We first use an aspect-based sentiment analysis model, which classifies the review sentences with the corresponding aspects (e.g., novelty, substance, soundness, etc.) and sentiment. We then extract opinion phrases from reviews for the corresponding aspect and sentiment labels. Next, we train a transformer model to reconstruct the original reviews from these extraction. Finally, we filter the selected opinions according to their aspect and/or sentiment at the time of summarization. The selected opinions of each aspect are used as input to the trained Transformer model, which uses them to construct an opinion summary. The idea is to give a concise meta-review that maximizes information coverage by focusing on aspects and sentiment present in the review, coherence, readability, and redundancy. We evaluate our model on the human written template-based meta-reviews to show that our framework outperforms competitive baselines. We believe that the template-based meta-review generation focusing on aspect and sentiment will help the editor/chair in decision-making and assist the meta-reviewer in writing better and more informative meta-reviews. We make our codes available athttps:// github.com/sandeep82945/Unsupervised-meta-review-generation.","2023-12","2025-02-26 20:39:16","2025-02-26 20:39:16","","263-281","","4","24","","","","","","","","","","English","","","","WOS:000947254800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","Deep learning; Meta-review generation; Peer reviews; Unsupervised summarization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YP6R8XY6","journalArticle","2025","Gaber, M; Ahmed, M; Janicke, H","Zero day ransomware detection with Pulse: Function classification with Transformer models and assembly language","COMPUTERS & SECURITY","","0167-4048","10.1016/j.cose.2024.104167","","Finding automated AI techniques to proactively defend against malware has become increasingly critical. The ability of an AI model to correctly classify novel malware is dependent on the quality of the features it is trained with and the authenticity of the features is dependent on the analysis tool. Peekaboo, a Dynamic Binary Instrumentation tool defeats evasive malware to capture its genuine behaviour. The ransomware Assembly instructions captured by Peekaboo, follow Zipf's law, a principle also observed in natural languages, indicating Transformer models are particularly well-suited to binary classification. We propose Pulse, a novel framework for zero day ransomware detection with Transformer models and Assembly language. Pulse, trained with the Peekaboo ransomware and benign software data, uniquely identify truly new samples with high accuracy. Pulse eliminates any familiar functionality across the test and training samples, forcing the Transformer model to detect malicious behaviour based solely on context and novel Assembly instruction combinations.","2025-01","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","148","","","","","","","","","","English","","","","WOS:001348190000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","AI; Assembly; Dynamic binary instrumentation; Feature extraction; LLM; Malware analysis; Ransomware; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6JP9S25V","journalArticle","2024","Xu, LX; Liu, HF; Yuan, X; Chen, EH; Tang, YY","GraKerformer: A Transformer With Graph Kernel for Unsupervised Graph Representation Learning","IEEE TRANSACTIONS ON CYBERNETICS","","2168-2267","10.1109/TCYB.2024.3465213","","While highly influential in deep learning, especially in natural language processing, the Transformer model has not exhibited competitive performance in unsupervised graph representation learning (UGRL). Conventional approaches, which focus on local substructures on the graph, offer simplicity but often fall short in encapsulating comprehensive structural information of the graph. This deficiency leads to suboptimal generalization performance. To address this, we proposed the GraKerformer model, a variant of the standard Transformer architecture, to mitigate the shortfall in structural information representation and enhance the performance in UGRL. By leveraging the shortest-path graph kernel (SPGK) to weight attention scores and combining graph neural networks, the GraKerformer effectively encodes the nuanced structural information of graphs. We conducted evaluations on the benchmark datasets for graph classification to validate the superior performance of our approach.","2024-12","2025-02-26 20:39:16","2025-02-26 20:39:16","","7320-7332","","12","54","","","","","","","","","","English","","","","WOS:001336018500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Computational modeling; Computer architecture; Encoding; Feature extraction; Graph kernel; Graph neural networks; graph neural networks (GNNs); Kernel; Network architecture; NETWORKS; Representation learning; structural encoding method; transformer; Transformers; Vectors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IIBBJB8C","journalArticle","2024","Baviskar, A; Nazir, FU; Hansen, AD; Das, K; Pal, BC","Strategic optimization framework considering unobservability in multi-voltage active distribution networks","INTERNATIONAL JOURNAL OF ELECTRICAL POWER & ENERGY SYSTEMS","","0142-0615","10.1016/j.ijepes.2024.110127","","An increase in the share of weather-dependent generation at low voltage levels necessitates incorporating the low-voltage network in optimizing a distribution network. Optimization in a multi-voltage network requires significant computation time and effort due to many nodes operating at different voltage levels. This research proposes a decomposition and strategic optimization method to reduce the computation requirements for such large multi-voltage distribution networks. The proposed algorithm reduces the space complexity and the computation time required for solving the optimization routines of these multi-voltage distribution networks. A virtual transformer model incorporates tap-changer as a continuous variable in the semidefinite programming power flow optimization model. The zero-duality gap condition for multiple virtual transformers is proven empirically. Compared to a centralized optimization using the same power flow model, the proposed framework reduced the computation time by 96%.","2024-10","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","161","","","","","","","","","","English","","","","WOS:001302105400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Controllability; Distributed Renewable Generation; EXPLOITING SPARSITY; Multi-voltage Distribution Network; Observability; On-load tap changers; PENETRATION; Reactive Power; STATE ESTIMATION; Voltage-Violations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VB9U6DCU","journalArticle","2024","Krishnan, PT; Krishnadoss, P; Khandelwal, M; Gupta, D; Nihaal, A; Kumar, TS","Enhancing brain tumor detection in MRI with a rotation invariant Vision Transformer","FRONTIERS IN NEUROINFORMATICS","","1662-5196","10.3389/fninf.2024.1414925","","Background The Rotation Invariant Vision Transformer (RViT) is a novel deep learning model tailored for brain tumor classification using MRI scans.Methods RViT incorporates rotated patch embeddings to enhance the accuracy of brain tumor identification.Results Evaluation on the Brain Tumor MRI Dataset from Kaggle demonstrates RViT's superior performance with sensitivity (1.0), specificity (0.975), F1-score (0.984), Matthew's Correlation Coefficient (MCC) (0.972), and an overall accuracy of 0.986.Conclusion RViT outperforms the standard Vision Transformer model and several existing techniques, highlighting its efficacy in medical imaging. The study confirms that integrating rotational patch embeddings improves the model's capability to handle diverse orientations, a common challenge in tumor imaging. The specialized architecture and rotational invariance approach of RViT have the potential to enhance current methodologies for brain tumor detection and extend to other complex imaging tasks.","2024-06-18","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","18","","","","","","","","","","English","","","","WOS:001259439600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","brain tumor classification; deep learning; IMAGES; MRI; rotated patch embeddings; rotational invariance; Vision Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6T74EBXW","journalArticle","2022","Wang, CJ; Chen, YY; Zhang, SQ; Zhang, QH","Stock market index prediction using deep Transformer model","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2022.118128","","Applications of deep learning in financial market prediction have attracted widespread attention from investors and scholars. From convolutional neural networks to recurrent neural networks, deep learning methods exhibit superior ability to capture the non-linear characteristics of stock markets and, accordingly, achieve a high performance on stock market index prediction. In this paper, we utilize the latest deep learning framework, Transformer, to predict the stock market index. Transformer was initially developed for the natural language processing problem, and has recently been applied to time series forecasting. Through the encoder-decoder architecture and the multi-head attention mechanism, Transformer can better characterize the underlying rules of stock market dynamics. We implement several back-testing experiments on the main stock market indices worldwide, including CSI 300, S&P 500, Hang Seng Index, and Nikkei 225. All the experiments demonstrate that Transformer outperforms other classic methods significantly and can gain excess earnings for investors.","2022-12-01","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","208","","","","","","","","","","English","","","","WOS:000835498400004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;88<br/>Total Times Cited:&nbsp;&nbsp;91<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Deep learning; ERROR; SHORT-TERM-MEMORY; Stock index prediction; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"USK23UKA","journalArticle","2022","Nakai, K; Chen, YW; Han, XH","Enhanced deep bottleneck transformer model for skin lesion classification*","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2022.103997","","Background and objectives: Skin cancer is the most common cancer worldwide, and therein the malignant melanoma may lead to less than 5-year life expectancy. Via early-stage detection and recognition, even the deadliest melanoma can be cured to greatly increase the patient's survival rate. Recently dermoscopy imaging is capable of capturing high-resolution magnified images of the infected skin region to automatic lesion classification, and deep learning network has been witnessed great potential of accurately recognizing different types of skin lesions. This study aims to exploit a novel deep model to enhance the skin lesion recognition performance.Methods: In spite of the remarkable progress, the existing deep network based methods naively deploy the proposed network architectures in generic image classification to the skin lesion classification, and there has still large space for performance improvement. This study presents an enhanced deep bottleneck transformer model, which incorporates self-attention to model the global correlation of the extracted features from the conventional deep models, for boosting the skin lesion performance. Specifically, we exploit an enhanced transformer module via incorporating a dual position encoding module to integrate encoded position vector on both key and query vectors for balance learning. By replacing the bottleneck spatial convolutions of the late-stage blocks in the baseline deep networks with the enhanced module, we construct a novel deep skin lesion classification model to lift the skin lesion classification performance.Results: We conduct extensive experiments on two benchmark skin lesion datasets: ISIC2017 and HAM10000 to verify the recognition performance of different deep models. The three quantitative metrics of accuracy, sensitivity and specificity on the ISIC2017 dataset with our method reach to 92.1%, 90.1% and 91.9%, respectively, which manifests very good balance result between the sensitivity and specificity, while the results on the accuracy and precision for the HAM10000 dataset are 95.84% and 96.1%.Conclusions: Results on both datasets have demonstrated that our proposed model can achieve superior performance over the baseline models as well as the state-of-the-art methods. This superior results using the incorporated model of the transformer of convolution module would inspire further research on the wide application of the transformer-based block for the real scenario without large-scale dataset.","2022-09","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","78","","","","","","","","","","English","","","","WOS:000895682200007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;23<br/>Total Times Cited:&nbsp;&nbsp;23<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","ACCURACY; CANCER; Deep learning; DERMOSCOPY; DIAGNOSIS; Lesion classification; MELANOMA; Position knowledge; Self-attention; Skin cancer; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E9TBV7J4","journalArticle","2025","Luo, XB; Peng, LX; Ke, ZY; Lin, JH; Yu, ZW","PA-Net: A hybrid architecture for retinal vessel segmentation☆","PATTERN RECOGNITION","","0031-3203","10.1016/j.patcog.2024.111254","","This paper proposes a hybrid architecture, PA-Net, which amalgamates the strengths of convolutional neural networks and the transformer model to enhance the precision of retinal vessel segmentation. We propose a novel component, the Lightweight Parallel Transformer (LPT), to augment the transformer's adaptability for the task of retinal vessel segmentation. This LPT addresses the shortcomings of standard transformer that are highly dependent on large datasets and computing resources, and can capture long-range dependencies to prevent slender vessels from breaking. Furthermore, we introduce an Adaptive Vascular Feature Fusion module to offset the vascular information loss induced by downsampling layers, thereby enhancing microvessel recognition. The effectiveness of PA-Net was assessed across four distinct datasets: DRIVE, CHASE_DB1, STARE, and HRF, with sensitivities of 0.8284, 0.8570, 0.8813, and 0.8497, respectively. The results suggest that the proposed method outperforms other state-of-the-art alternatives.","2025-05","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","161","","","","","","","","","","English","","","","WOS:001382247000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","ATTENTION; Deep learning; Feature fusion; IMAGES; Retinal images; Retinal vessel segmentation; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JCTPH2DX","journalArticle","2024","Zheng, WF; Lu, SY; Yang, YS; Yin, ZT; Yin, LR","Lightweight transformer image feature extraction network","PEERJ COMPUTER SCIENCE","","2376-5992","10.7717/peerj-cs.1755","","In recent years, the image feature extraction method based on Transformer has become a research hotspot. However, when using Transformer for image feature extraction, the model's complexity increases quadratically with the number of tokens entered. The quadratic complexity prevents vision transformer-based backbone networks from modelling high-resolution images and is computationally expensive. To address this issue, this study proposes two approaches to speed up Transformer models. Firstly, the self-attention mechanism's quadratic complexity is reduced to linear, enhancing the model's internal processing speed. Next, a parameter-less lightweight pruning method is introduced, which adaptively samples input images to filter out unimportant tokens, effectively reducing irrelevant input. Finally, these two methods are combined to create an efficient attention mechanism. Experimental results demonstrate that the combined methods can reduce the computation of the original Transformer model by 30%-50%, while the efficient attention mechanism achieves an impressive 60%-70% reduction in computation.","2024-01-31","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","10","","","","","","","","","","English","","","","WOS:001156835700007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;80<br/>Total Times Cited:&nbsp;&nbsp;80<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Efficient attention; Image feature extraction; Pruning; Quadratic complexity; Self-attention mechanism; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TAXECQYL","journalArticle","2023","Tan, KJ; Mao, WY; Guo, XZ; Lu, HX; Zhang, C; Cao, ZZ; Wang, XA","CST: Complex Sparse Transformer for Low-SNR Speech Enhancement","SENSORS","","1424-8220","10.3390/s23052376","","Speech enhancement tasks for audio with a low SNR are challenging. Existing speech enhancement methods are mainly designed for high SNR audio, and they usually use RNNs to model audio sequence features, which causes the model to be unable to learn long-distance dependencies, thus limiting its performance in low-SNR speech enhancement tasks. We design a complex transformer module with sparse attention to overcome this problem. Different from the traditional transformer model, this model is extended to effectively model complex domain sequences, using the sparse attention mask balance model's attention to long-distance and nearby relations, introducing the pre-layer positional embedding module to enhance the model's perception of position information, adding the channel attention module to enable the model to dynamically adjust the weight distribution between channels according to the input audio. The experimental results show that, in the low-SNR speech enhancement tests, our models have noticeable performance improvements in speech quality and intelligibility, respectively.","2023-03","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","5","23","","","","","","","","","","English","","","","WOS:000947669200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","attention mechanisms; NOISE; speech enhancement; transformer; UNET architecture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S9CBHCLS","journalArticle","2022","Guo, HY; Keyvan-Ekbatani, M; Xie, K","Lane change detection and prediction using real-world connected vehicle data","TRANSPORTATION RESEARCH PART C-EMERGING TECHNOLOGIES","","0968-090X","10.1016/j.trc.2022.103785","","Prediction of lane changes (LCs) provides critical information to enhance traffic safety and efficiency in a connected and automated driving environment. It is essential to precisely detect LCs from driving data to lay the groundwork for LC prediction. This study aims to develop LC detection and prediction models using large-scale real-world data collected by connected vehicles (CVs). At first, an autoencoder was used to detect LCs, and proved to be more precise and robust than conventional methods. Next, a transformer-based LC prediction model was developed, which concentrated computation power on key information via an attention mechanism. It outperformed the baseline models in terms of accuracy and computational efficiency. The prediction horizon was also analyzed and LC could be accurately predicted up to two seconds in advance. At last, the transformer model was implemented for real-time prediction and demonstrated a great potential for practical applications.","2022-09","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","142","","","","","","","","","","English","","","","WOS:000835328300005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;24<br/>Total Times Cited:&nbsp;&nbsp;28<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","Autoencoder; BEHAVIOR; Connected vehicle; Lane change detection; Lane change prediction; MODEL; NETWORKS; RECOGNITION; Transformer; WAVELET","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M99EFAEY","journalArticle","2022","Gao, W; Zhang, XM; He, QS; Lin, BR; Huang, WX","Command prediction based on early 3D modeling design logs by deep neural networks","AUTOMATION IN CONSTRUCTION","","0926-5805","10.1016/j.autcon.2021.104026","","Command prediction based on BIM logs is an important computer-aided design (CAD) method to help avoiding design errors especially on early design stages in architecture, engineering and construction (AEC). On this issue, methods for data preprocessing, predictive model training and model evaluation are three primary questions to answer. In this study, a data augmentation method is developed to prepare high quality data input for 3D modeling event logs. A standard Transformer model is trained with the augmented data as input. Six predictive models on three different input data are compared for evaluating the method. In this case, the most accurate of the six models is Transformer with 94% accuracy on top one command prediction. As results, the data augmentation method proposed in this study improves the accuracy of the predictive models up to 1.75 times. Intelligent CAD tool for command prediction with high accuracy during 3D modeling design can be further developed.","2022-01","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","133","","","","","","","","","","English","","","","WOS:000716999200003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Architectural design; BEHAVIOR; BIM logs; Machine learning; Process mining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JWXS4AK8","journalArticle","2024","Mahdi, MA; Ahamad, S; Saad, SA; Dafhalla, A; Alqushaibi, A; Qureshi, R","Segmentation of Head and Neck Tumors Using Dual PET/CT Imaging: Comparative Analysis of 2D, 2.5D, and 3D Approaches Using UNet Transformer","CMES-COMPUTER MODELING IN ENGINEERING & SCIENCES","","1526-1492","10.32604/cmes.2024.055723","","The segmentation of head and neck (H&N) tumors in dual Positron Emission Tomography/Computed Tomography (PET/CT) imaging is a critical task in medical imaging, providing essential information for diagnosis, treatment planning, and outcome prediction. Motivated by the need for more accurate and robust segmentation methods, this study addresses key research gaps in the application of deep learning techniques to multimodal medical images. Specifically, it investigates the limitations of existing 2D and 3D models in capturing complex tumor structures and proposes an innovative 2.5D UNet Transformer model as a solution. The primary research questions guiding this study are: (1) How can the integration of convolutional neural networks (CNNs) and transformer networks enhance segmentation accuracy in dual PET/CT imaging? (2) What are the comparative advantages of 2D, 2.5D, and 3D model configurations in this context? To answer these questions, we aimed to develop and evaluate advanced deep-learning models that leverage the strengths of both CNNs and transformers. Our proposed methodology involved a comprehensive preprocessing pipeline, including normalization, contrast enhancement, and resampling, followed by segmentation using 2D, 2.5D, and 3D UNet Transformer models. The models were trained and tested on three diverse datasets: HeckTor2022, AutoPET2023, and SegRap2023. Performance was assessed using metrics such as Dice Similarity Coefficient, Jaccard Index, Average Surface Distance (ASD), and Relative Absolute Volume Difference (RAVD). The findings demonstrate that the 2.5D UNet Transformer model consistently outperformed the 2D and 3D models across most metrics, achieving the highest Dice and Jaccard values, indicating superior segmentation accuracy. For instance, on the HeckTor2022 dataset, the 2.5D model achieved a Dice score of 81.777 and a Jaccard index of 0.705, surpassing other model configurations. The 3D model showed strong boundary delineation performance but exhibited variability across datasets, while the 2D model, although effective, generally underperformed compared to its 2.5D and 3D counterparts. Compared to related literature, our study confirms the advantages of incorporating additional spatial context, as seen in the improved performance of the 2.5D model. This research fills a significant gap by providing a detailed comparative analysis of different model dimensions and their impact on H&N segmentation accuracy in dual PET/CT imaging.","2024","2025-02-26 20:39:16","2025-02-26 20:39:16","","2351-2373","","3","141","","","","","","","","","","English","","","","WOS:001331055000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","clinical oncology; deep learning; multi-modal imaging; neural networks; PET/CT imaging; tumor segmentation; weighted fusion transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9XE36VTK","journalArticle","2024","Zhong, JY; Chen, YT; Gao, J; Lv, XH","Drone image recognition and intelligent power distribution network equipment fault detection based on the transformer model and transfer learning","FRONTIERS IN ENERGY RESEARCH","","2296-598X","10.3389/fenrg.2024.1364445","","In today's era of rapid technological advancement, the emergence of drone technology and intelligent power systems has brought tremendous convenience to society. However, the challenges associated with drone image recognition and intelligent grid device fault detection are becoming increasingly significant. In practical applications, the rapid and accurate identification of drone images and the timely detection of faults in intelligent grid devices are crucial for ensuring aviation safety and the stable operation of power systems. This article aims to integrate Transformer models, transfer learning, and generative adversarial networks to enhance the accuracy and efficiency of drone image recognition and intelligent grid device fault detection.In the methodology section, we first employ the Transformer model, a deep learning model based on self-attention mechanisms that has demonstrated excellent performance in handling image sequences, capturing complex spatial relationships in images. To address limited data issues, we introduce transfer learning, accelerating the learning process in the target domain by training the model on a source domain. To further enhance the model's robustness and generalization capability, we incorporate generative adversarial networks to generate more representative training samples.In the experimental section, we validate our model using a large dataset of real drone images and intelligent grid device fault data. Our model shows significant improvements in metrics such as specificity, accuracy, recall, and F1-score. Specifically, in the experimental data, we observe a notable advantage of our model over traditional methods in both drone image recognition and intelligent grid device fault detection. Particularly in the detection of intelligent grid device faults, our model successfully captures subtle fault features, achieving an accuracy of over 90%, an improvement of more than 17% compared to traditional methods, and an outstanding F1-score of around 91%.In summary, this article achieves a significant improvement in the fields of drone image recognition and intelligent grid device fault detection by cleverly integrating Transformer models, transfer learning, and generative adversarial networks. Our approach not only holds broad theoretical application prospects but also receives robust support from experimental data, providing strong support for research and applications in related fields.","2024-08-29","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","12","","","","","","","","","","English","","","","WOS:001310299200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","artificial intelligence; electrical equipment defect recognition; image intelligent processing; power systems; ViT model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P45533WI","journalArticle","2025","Zhou, G; Peng, MJ; Wang, H; Sun, DB; Li, ZK","Research on fault diagnosis method and interpretability of nuclear power plant based on hybrid transformer model","ANNALS OF NUCLEAR ENERGY","","0306-4549","10.1016/j.anucene.2024.111157","","In order to improve the accuracy of the fault diagnosis, a hybrid Transformer (HTransformer) model for fault diagnosis in nuclear power plants (NPPs) is proposed. By concatenating convolutional neural networks and gated recurrent unit networks in front of the Transformer encoder, the spatiotemporal feature information of the input information is effectively capture. However, the high reliability demand for NPPs requires researchers to be able to explain the decision-making behavior of deep learning models. The interpretability of the HTransformer model has been preliminarily studied based on the Shapley additive explanations (SHAP) method. The result shows that the HTransformer model has a higher fault diagnosis accuracy of 99.5% compared to other deep learning fault diagnosis models. The preliminary research result on the interpretability of fault diagnosis models based on the SHAP method provides a possibility for deep learning models to be applied in the practical engineering of NPPs.","2025-04","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","213","","","","","","","","","","English","","","","WOS:001397670700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Deep learning; Fault diagnosis; Nuclear power plant; Shapley additive explanations; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WFPCETEW","journalArticle","2023","Park, JB; Lee, HJ; Yang, HL; Kim, EH; Lee, HC; Jung, CW; Kim, HS","Machine learning-based prediction of intraoperative hypoxemia for pediatric patients","PLOS ONE","","1932-6203","10.1371/journal.pone.0282303","","BackgroundReducing the duration of intraoperative hypoxemia in pediatric patients by means of rapid detection and early intervention is considered crucial by clinicians. We aimed to develop and validate a machine learning model that can predict intraoperative hypoxemia events 1 min ahead in children undergoing general anesthesia. MethodsThis retrospective study used prospectively collected intraoperative vital signs and parameters from the anesthesia ventilator machine extracted every 2 s in pediatric patients undergoing surgery under general anesthesia between January 2019 and October 2020 in a tertiary academic hospital. Intraoperative hypoxemia was defined as oxygen saturation <95% at any point during surgery. Three common machine learning techniques were employed to develop models using the training dataset: gradient-boosting machine (GBM), long short-term memory (LSTM), and transformer. The performances of the models were compared using the area under the receiver operating characteristics curve using randomly assigned internal testing dataset. We also validated the developed models using temporal holdout dataset. Pediatric patient surgery cases between November 2020 and January 2021 were used. The performances of the models were compared using the area under the receiver operating characteristic curve (AUROC). ResultsIn total, 1,540 (11.73%) patients with intraoperative hypoxemia out of 13,130 patients' records with 2,367 episodes were included for developing the model dataset. After model development, 200 (13.25%) of the 1,510 patients' records with 289 episodes were used for holdout validation. Among the models developed, the GBM had the highest AUROC of 0.904 (95% confidence interval [CI] 0.902 to 0.906), which was significantly higher than that of the LSTM (0.843, 95% CI 0.840 to 0.846 P < .001) and the transformer model (0.885, 95% CI, 0.882-0.887, P < .001). In holdout validation, GBM also demonstrated best performance with an AUROC of 0.939 (95% CI 0.936 to 0.941) which was better than LSTM (0.904, 95% CI 0.900 to 0.907, P < .001) and the transformer model (0.929, 95% CI 0.926 to 0.932, P < .001). ConclusionsMachine learning models can be used to predict upcoming intraoperative hypoxemia in real-time based on the biosignals acquired by patient monitors, which can be useful for clinicians for prediction and proactive treatment of hypoxemia in an intraoperative setting.","2023-03-01","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","3","18","","","","","","","","","","English","","","","WOS:000942456500012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","ANESTHESIA; CHILDREN; PERIOPERATIVE CARDIAC-ARREST; RISK","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9U5UDWIU","journalArticle","2023","Zhang, HY; Tang, HL; Zhang, WX","Aurora retrieval in all-sky images based on hash vision transformer","HELIYON","","2405-8440","10.1016/j.heliyon.2023.e20609","","Auroras are bright occurrences when high-energy particles from the magnetosphere and solar wind enter Earth's atmosphere through the magnetic field and collide with atoms in the upper atmosphere. The morphological and temporal characteristics of auroras are essential for studying large-scale magnetospheric processes. While auroras are visible to the naked eye from the ground, scientists use deep learning algorithms to analyze all-sky images to understand this phenomenon better. However, the current algorithms face challenges due to inefficient utilization of global features and neglect the excellent fusion of local and global feature representations extracted from aurora images. Hence, this paper introduces a Hash-Transformer model based on Vision Transformer for aurora retrieval from all-sky images. Experimental results based on real-world data demonstrate that the proposed method effectively improves aurora image retrieval performance. It provides a new avenue to study aurora phenomena and facilitates the development of related fields.","2023-10","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","10","9","","","","","","","","","","English","","","","WOS:001114025200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","All-sky images; Aurora image retrieval; CLASSIFICATION; Deep learning; SCALE; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2W2ZC57K","journalArticle","2023","Wang, W; Yang, X; Tang, JH","Vision Transformer With Hybrid Shifted Windows for Gastrointestinal Endoscopy Image Classification","IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY","","1051-8215","10.1109/TCSVT.2023.3277462","","Automated classification of gastrointestinal endoscope images can help reduce the workload of doctors and improve the accuracy of diagnoses. The rapidly developed vision Transformer, represented by Swin Transformer, has become an impressive technique for medical image classification. However, Swin Transformer cannot capture the long-range dependency well in complex gastrointestinal endoscopy images. As a result, it fails to represent features of some widely-spread targets in digestive tract images, such as normal-z-line and esophagitis, effectively. To solve this problem, we propose a novel vision Transformer model based on hybrid shifted windows for digestive tract image classification, which can obtain both short-range and long-range dependency concurrently. Extensive experiments demonstrate the superiority of our method to the state-of-the-art methods with a classification accuracy of 95.42% on the Kvasir v2 dataset and a classification accuracy of 86.81% on the HyperKvasir dataset.","2023-09","2025-02-26 20:39:16","2025-02-26 20:39:16","","4452-4461","","9","33","","","","","","","","","","English","","","","WOS:001063316800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","computer aided diagnosis; Convolutional neural networks; DIAGNOSIS; Diseases; Endoscopes; Feature extraction; FEATURES; gastrointestinal endoscope; Gastrointestinal tract; Image classification; NETWORK; Transformers; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"93FLT2DL","journalArticle","2023","Vojnovic, N; Vidakovic, J; Vidakovic, M","Decoupled load flow for large-scale multiphase distribution networks","SUSTAINABLE ENERGY GRIDS & NETWORKS","","2352-4677","10.1016/j.segan.2023.101049","","The load flow procedure is the base procedure for various power applications in the distribution management systems. The modern distribution networks are significantly larger than the old ones and the need for the accurate and fast load flow calculation is understandable. This paper presents a decoupled model of consumers, line sections, and three-phase transformers which are integrated in the proposed backward-forward sweep procedure. The radialization procedure for the multi-phase weakly-meshed distribution networks has also been introduced. The decoupled load flow procedure has been presented in detail with its performance evaluated when applied on large-scale distribution networks. The results show that the speedup of the decoupled backward-forward procedure compared to the traditional coupled based one is up to 90%. The decoupled solution is more suited for the concurrent approach which will be analyzed in the future work.& COPY; 2023 Elsevier Ltd. All rights reserved.","2023-06","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","34","","","","","","","","","","English","","","","WOS:001042990300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","3-PHASE DISTRIBUTION NETWORK; ALGORITHM; Backward-forward sweep; Decoupled network model; Load flow; POWER-FLOW; TRANSFORMER MODEL; UML","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2NC9AXPI","journalArticle","2022","Pu, SL; Chu, L; Hu, JC; Li, SB; Li, JH; Sun, W","SGGformer: Shifted Graph Convolutional Graph-Transformer for Traffic Prediction","SENSORS","","1424-8220","10.3390/s22229024","","Accurate traffic prediction is significant in intelligent cities' safe and stable development. However, due to the complex spatiotemporal correlation of traffic flow data, establishing an accurate traffic prediction model is still challenging. Aiming to meet the challenge, this paper proposes SGGformer, an advanced traffic grade prediction model which combines a shifted window operation, a multi-channel graph convolution network, and a graph Transformer network. Firstly, the shifted window operation is used for coarsening the time series data, thus, the computational complexity can be reduced. Then, a multi-channel graph convolutional network is adopted to capture and aggregate the spatial correlations of the roads in multiple dimensions. Finally, the improved graph Transformer based on the advanced Transformer model is proposed to extract the long-term temporal correlation of traffic data effectively. The prediction performance is evaluated by using actual traffic datasets, and the test results show that the SGGformer proposed exceeds the state-of-the-art baseline.","2022-11","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","22","22","","","","","","","","","","English","","","","WOS:000887664300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","deep learning; Graph Transformer; multi-channel GCN; shifted window operation; traffic prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9S9E54KM","journalArticle","2024","Koutsouvelis, P; Chybowski, B; Gonzalez-Sulser, A; Abdullateef, S; Escudero, J","Preictal period optimization for deep learning-based epileptic seizure prediction","JOURNAL OF NEURAL ENGINEERING","","1741-2560","10.1088/1741-2552/ad9ad0","","Objective. Accurate seizure prediction could prove critical for improving patient safety and quality of life in drug-resistant epilepsy. While deep learning-based approaches have shown promising performance using scalp electroencephalogram (EEG) signals, the incomplete understanding and variability of the preictal state imposes challenges in identifying the optimal preictal period (OPP) for labeling the EEG segments. This study introduces novel measures to capture model behavior under different preictal definitions and proposes a data-centric deep learning methodology to identify the OPP. Approach. We trained a competent subject-specific CNN-Transformer model to detect preictal EEG segments using the open-access CHB-MIT dataset. To capture the temporal dynamics of the model's predictions, we fitted a sigmoidal curve to the model outputs obtained from uninterrupted multi-hour EEG recordings prior to seizure onset. From this fitted curve, we derived key performance measures reflecting the timing of predictions, including classifier convergence, average error, output stability, and the transition between interictal and preictal states. These measures were then combined to compute the Continuous Input-Output Performance Ratio, a novel metric designed to comprehensively compare model behavior across different preictal definitions (60, 45, 30, and 15 min) and suggest the OPP for each patient. Main results. The CNN-Transformer model achieved state-of-the-art performance (area under the curve of 99.35% and F1-score of 97.46%) using minimally pre-processed EEG signals. The 60-minute preictal definition was associated with earlier seizure prediction, lower error in the preictal state, and reduced output fluctuations, leading to significantly higher CIOPR scores (p < 0.001). Conventional accuracy-related metrics (sensitivity, specificity, F1-score) were less sensitive to varying preictal definitions and often discordant with CIOPR findings. Cross- and intra-patient heterogeneities in the prediction times were also observed, complicating the establishment of a global preictal interval. Significance. The newly developed metrics demonstrate that varying the preictal period significantly impacts the timing of predictions in ways not captured by conventional accuracy-related metrics. Understanding this impact and the inter-seizure heterogeneities is essential for developing intelligent systems tailored to individual patient needs and for underlining practical limitations in detecting the preictal period in real-world clinical applications.","2024-12-01","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","6","21","","","","","","","","","","English","","","","WOS:001385884000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","CNN; deep learning; EEG; interictal; NEURAL-NETWORK; preictal; seizure prediction; TERM; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"878XDIP3","journalArticle","2023","Jin, YP; Bhatia, A; Wanvarie, D; Le, PTV","Towards improving coherence and diversity of slogan generation","NATURAL LANGUAGE ENGINEERING","","1351-3249","10.1017/S1351324921000474","","Previous work in slogan generation focused on utilising slogan skeletons mined from existing slogans. While some generated slogans can be catchy, they are often not coherent with the company's focus or style across their marketing communications because the skeletons are mined from other companies' slogans. We propose a sequence-to-sequence (seq2seq) Transformer model to generate slogans from a brief company description. A naive seq2seq model fine-tuned for slogan generation is prone to introducing false information. We use company name delexicalisation and entity masking to alleviate this problem and improve the generated slogans' quality and truthfulness. Furthermore, we apply conditional training based on the first words' part-of-speech tag to generate syntactically diverse slogans. Our best model achieved a ROUGE-1/-2/-L F-1 score of 35.58/18.47/33.32. Besides, automatic and human evaluations indicate that our method generates significantly more factual, diverse and catchy slogans than strong long short-term memory and Transformer seq2seq baselines.","2023-03","2025-02-26 20:39:16","2025-02-26 20:39:16","","254-286","","2","29","","","","","","","","","","English","","","","WOS:000751158900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","Natural language generation; Sequence-to-sequence model; Slogan generation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HKABHI9R","journalArticle","2022","Xie, F; Zhang, DL; Liu, CM","Global-Local Self-Attention Based Transformer for Speaker Verification","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app121910154","","Transformer models are now widely used for speech processing tasks due to their powerful sequence modeling capabilities. Previous work determined an efficient way to model speaker embeddings using the Transformer model by combining transformers with convolutional networks. However, traditional global self-attention mechanisms lack the ability to capture local information. To alleviate these problems, we proposed a novel global-local self-attention mechanism. Instead of using local or global multi-head attention alone, this method performs local and global attention in parallel in two parallel groups to enhance local modeling and reduce computational cost. To better handle local location information, we introduced locally enhanced location encoding in the speaker verification task. The experimental results of the VoxCeleb1 test set and the VoxCeleb2 dev set demonstrated the improved effect of our proposed global-local self-attention mechanism. Compared with the Transformer-based Robust Embedding Extractor Baseline System, the proposed speaker Transformer network exhibited better performance in the speaker verification task.","2022-10","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","19","12","","","","","","","","","","English","","","","WOS:000866629200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","self-attention mechanism; speaker recognition; speaker verification; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QH8M2A4I","journalArticle","2022","Wang, JJ; Hu, J; Sun, HT; Xu, MD; Yu, Y; Liu, Y; Cheng, L","MGPLI: exploring multigranular representations for protein-ligand interaction prediction","BIOINFORMATICS","","1367-4803","10.1093/bioinformatics/btac597","","Motivation: The capability to predict the potential drug binding affinity against a protein target has always been a fundamental challenge in silico drug discovery. The traditional experiments in vitro and in vivo are costly and time-consuming which need to search over large compound space. Recent years have witnessed significant success on deep learning-based models for drug-target binding affinity prediction task. Results: Following the recent success of the Transformer model, we propose a multigranularity protein-ligand interaction (MGPLI) model, which adopts the Transformer encoders to represent the character-level features and fragment-level features, modeling the possible interaction between residues and atoms or their segments. In addition, we use the convolutional neural network to extract higher-level features based on transformer encoder outputs and a highway layer to fuse the protein and drug features. We evaluate MGPLI on different protein-ligand interaction datasets and show the improvement of prediction performance compared to state-of-the-art baselines.","2022-10-31","2025-02-26 20:39:16","2025-02-26 20:39:16","","4859-4867","","21","38","","","","","","","","","","English","","","","WOS:000859211200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","BINDING-AFFINITY; DATABASE; NEURAL-NETWORK","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"APU75K3X","journalArticle","2024","Zhao, Y; Yang, JX; Wang, WB; Yang, HL; Niyato, D","TranDRL: A Transformer-Driven Deep Reinforcement Learning Enabled Prescriptive Maintenance Framework","IEEE INTERNET OF THINGS JOURNAL","","2327-4662","10.1109/JIOT.2024.3436110","","Industrial systems require reliable predictive maintenance strategies to enhance operational efficiency and reduce downtime. Existing studies rely on the heuristic models which may struggle to capture complex temporal dependencies. This article introduces an integrated framework that leverages the capabilities of the Transformer and deep reinforcement learning (DRL) algorithms to optimize the system maintenance actions. Our approach employs the Transformer model to effectively capture complex temporal patterns in IoT sensor data, thus accurately predicting the remaining useful life (RUL) of equipment. Additionally, the DRL component of our framework provides cost-effective and timely maintenance recommendations. Numerous experiments conducted on the NASA C-MPASS data set demonstrate that our approach has a performance similar to the ground truth results and could be obviously better than the baseline methods in terms of RUL prediction accuracy as the time cycle increases. Additionally, the experimental results demonstrate the effectiveness of optimizing maintenance actions.","2024-11-01","2025-02-26 20:39:16","2025-02-26 20:39:16","","35432-35444","","21","11","","","","","","","","","","English","","","","WOS:001342828900103","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Deep reinforcement learning (DRL); Machinery; Maintenance; MODEL; PREDICTION; Prediction algorithms; Predictive maintenance; Predictive models; prescriptive maintenance; PRIMA; Task analysis; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QF8K9EMP","journalArticle","2024","Marusov, A; Grabar, V; Maximov, Y; Sotiriadi, N; Bulkin, A; Zaytsev, A","Long-term drought prediction using deep neural networks based on geospatial weather data","ENVIRONMENTAL MODELLING & SOFTWARE","","1364-8152","10.1016/j.envsoft.2024.106127","","The problem of high-quality drought forecasting up to a year in advance is critical for agriculture planning and insurance. Yet, it is still unsolved with reasonable accuracy due to data complexity and aridity stochasticity. We tackle drought data by introducing an end-to-end approach that adopts a spatio-temporal neural network model with accessible open monthly climate data as the input. Our systematic research employs diverse proposed models and five distinct environmental regions as a testbed to evaluate the efficacy of the Palmer Drought Severity Index (PDSI) prediction. Key aggregated findings are the exceptional performance of a Transformer model, EarthFormer, in making accurate short-term (up to six months) forecasts. At the same time, the Convolutional LSTM excels in longer-term forecasting. Both models achieved high ROC AUC scores: 0.948 for one month ahead and 0.617 for twelve months ahead forecasts, becoming closer to perfect ROC-AUC by 54% and 16%, respectively, c.t. classic approaches.","2024-08","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","179","","","","","","","","","","English","","","","WOS:001267738300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","Climate; Deep learning; Drought forecasting; Long-term forecasting; Weather","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IJYFFA6D","journalArticle","2024","Parikh, P; Penfield, J","Automatic Question Answering From Large ESG Reports","INTERNATIONAL JOURNAL OF DATA WAREHOUSING AND MINING","","1548-3924","10.4018/IJDWM.352513","","ESG reports contain crucial information about the corporations' environmental impact, social responsibilities, and governance. Many compliance audits rely on answering questions based on these reports. Moreover, for tasks such as Scope 3 GHG emissions estimation, a company needs to look at the ESG reports of all its typically numerous suppliers to tabulate its own compliance reports. Manually finding specific information from these large documents is immensely time-consuming. This paper presents the first system that automatically answers questions from an ESG report, using advanced machine learning and natural language processing. The proposed system also locates and highlights a cropped screenshot from the report providing the answer. The authors devise two methods for inferring the textual answer, one based on a transformer model pre-trained for extractive question answering and another using a large language model. The task-agnostic method overcomes the challenge of the lengthiness of ESG reports in a cost-effective manner.","2024","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","1","20","","","","","","","","","","English","","","","WOS:001322301000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","Artificial Intelligence; ESG; Large Language Models; LLM; Machine Learning; Natural Language Processing; NLP; Question Answering; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BZZ86FY7","journalArticle","2021","Er, S; Yang, SH; Zhao, T","COUnty aggRegation mixup AuGmEntation (COURAGE) COVID-19 prediction","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-021-93545-6","","The global spread of COVID-19, the disease caused by the novel coronavirus SARS-CoV-2, has casted a significant threat to mankind. As the COVID-19 situation continues to evolve, predicting localized disease severity is crucial for advanced resource allocation. This paper proposes a method named COURAGE (COUnty aggRegation mixup AuGmEntation) to generate a short-term prediction of 2-week-ahead COVID-19 related deaths for each county in the United States, leveraging modern deep learning techniques. Specifically, our method adopts a self-attention model from Natural Language Processing, known as the transformer model, to capture both short-term and long-term dependencies within the time series while enjoying computational efficiency. Our model solely utilizes publicly available information for COVID-19 related confirmed cases, deaths, community mobility trends and demographic information, and can produce state-level predictions as an aggregation of the corresponding county-level predictions. Our numerical experiments demonstrate that our model achieves the state-of-the-art performance among the publicly available benchmark models.","2021-07-12","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","1","11","","","","","","","","","","English","","","","WOS:000677492300004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5VWGGNVA","journalArticle","2024","Li, X; Sun, QL; Zhang, YF; Sha, J; Zhang, M","Enhancing hydrological extremes prediction accuracy: Integrating diverse loss functions in Transformer models","ENVIRONMENTAL MODELLING & SOFTWARE","","1364-8152","10.1016/j.envsoft.2024.106042","","In this hydrological study, we developed a Transformer-based model to forecast urban river discharges and predict flood peaks, crucial for flood mitigation in urban areas prone to inundation. Utilizing daily precipitation data from 63 meteorological stations and flow data from hydrological stations, we established a correlation using the Random Forest method to determine the lag time between precipitation and flow. The model, enhanced with alternative loss functions - Weighted MSE Loss (WMSE), Huber Loss (Hloss), and Quantile Loss (Qloss) - instead of traditional Mean Squared Error (MSE), aims to project daily flow rates for seven days. Our findings indicate that Hloss significantly reduces absolute errors in peak value predictions, while WMSE improves linear correlation in forecasting. The accuracy remains stable for the initial four days, with a decrease from the fifth day. This approach, integrating diverse loss functions, presents a novel method for accurately predicting river discharges, offering vital insights for proactive flood management.","2024-06","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","177","","","","","","","","","","English","","","","WOS:001231714200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","ERROR; Hydrological forecasting; IMPLEMENTATION; Loss functions; Peak flow prediction; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SC8LS75H","journalArticle","2024","Xiao, ZX; Chen, YZ; Yao, JJ; Zhang, L; Liu, ZL; Wu, ZH; Yu, XW; Pan, Y; Zhao, L; Ma, C; Liu, XY; Liu, W; Li, X; Yuan, YX; Shen, DG; Zhu, DJ; Yao, DZ; Liu, TM; Jiang, X","Instruction-ViT: Multi-modal prompts for instruction learning in vision transformer","INFORMATION FUSION","","1566-2535","10.1016/j.inffus.2023.102204","","Prompts play a crucial role in enhancing the control, adaptability, and scalable application of large language models. In recent years, strategies involving prompts have also been applied to visual models. However, the extent to which the fusion of multi-modal prompts (e.g., text or image prompts) can improve downstream task performance in visual models has not been systematically investigated. To address this issue, this paper focuses on adapting the design of prompts based on instruction tuning in a vision transformer model for visual tasks, which we have named Instruction-ViT. The key idea involves implementing and fusing multi-modal prompts (either text or image prompts) related to category information, guiding the fine-tuning of the model. Based on the experiments conducted on several image understanding tasks, including classification, segmentation, image captioning, and object detection, we observe consistently improved performance and domain adaptability. Our work presents an innovative strategy for fusing multi-modal prompts, enhancing performance and adaptability in visual models.","2024-04","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","104","","","","","","","","","","English","","","","WOS:001149978300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Instruction learning; Multi-modal information fusion; Multi-modal prompt; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KC582UAN","journalArticle","2021","Zhang, JF; Zhang, H; Ding, S; Zhang, XX","Power Consumption Predicting and Anomaly Detection Based on Transformer and K-Means","FRONTIERS IN ENERGY RESEARCH","","2296-598X","10.3389/fenrg.2021.779587","","With the advancement of technology and science, the power system is getting more intelligent and flexible, and the way people use electric energy in their daily lives is changing. Monitoring the condition of electrical energy loads, particularly in the early detection of aberrant loads and behaviors, is critical for power grid maintenance and power theft detection. In this paper, we combine the widely used deep learning model Transformer with the clustering approach K-means to estimate power consumption over time and detect anomalies. The Transformer model is used to forecast the following hour's power usage, and the K-means clustering method is utilized to optimize the prediction results, finally, the anomalies is detected by comparing the predicted value and the test value. On real hourly electric energy consumption data, we test the proposed model, and the results show that our method outperforms the most commonly used LSTM time series model.</p>","2021-10-22","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","9","","","","","","","","","","English","","","","WOS:000716386700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;23<br/>Total Times Cited:&nbsp;&nbsp;25<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","anomaly detection; ARIMA; K-means; LOAD; LSTM; MODEL; NETWORK; power consumption prediction; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RAP8ECAC","journalArticle","2025","Jagadesh, BN; Mantena, SV; Sathe, AP; Rao, TP; Lella, KK; Pabboju, SS; Vatambeti, R","Enhancing food recognition accuracy using hybrid transformer models and image preprocessing techniques","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-025-90244-4","","This study presents a robust approach for continuous food recognition essential for nutritional research, leveraging advanced computer vision techniques. The proposed method integrates Mutually Guided Image Filtering (MuGIF) to enhance dataset quality and minimize noise, followed by feature extraction using the Visual Geometry Group (VGG) architecture for intricate visual analysis. A hybrid transformer model, combining Vision Transformer and Swin Transformer variants, is introduced to capitalize on their complementary strengths. Hyperparameter optimization is performed using the Improved Discrete Bat Algorithm (IDBA), resulting in a highly accurate and efficient classification system. Experimental results highlight the superior performance of the proposed model, achieving a classification accuracy of 99.83%, significantly outperforming existing methods. This study underscores the potential of hybrid transformer architectures and advanced preprocessing techniques in advancing food recognition systems, offering enhanced accuracy and efficiency for practical applications in dietary monitoring and personalized nutrition recommendations.","2025-02-15","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","1","15","","","","","","","","","","English","","","","WOS:001422758800030","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Improved discrete bat algorithm; Mutually guided image filtering; Swin transformer; Vision transformer; Visual geometry group","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WX34U2V8","journalArticle","2024","Cui, H; Lei, JY","An Algorithmic Study of Transformer-Based Road Scene Segmentation in Autonomous Driving","WORLD ELECTRIC VEHICLE JOURNAL","","2032-6653","10.3390/wevj15110516","","Applications such as autonomous driving require high-precision semantic image segmentation technology to identify and understand the content of each pixel in the images. Compared with traditional deep convolutional neural networks, the Transformer model is based on pure attention mechanisms, without convolutional layers or recurrent neural network layers. In this paper, we propose a new network structure called SwinLab, which is an improvement upon the Swin Transformer. Experimental results demonstrate that the improved SwinLab model achieves a segmentation accuracy comparable to that of deep convolutional neural network models in applications such as autonomous driving, with an MIoU of 77.61. Additionally, comparative experiments on the CityScapes dataset further validate the effectiveness and generalization of this structure. In conclusion, by refining the Swin Transformer, this paper simplifies the model structure, improves the training and inference speed, and maintains high accuracy, providing a more reliable semantic image segmentation solution for applications such as autonomous driving.","2024-11","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","11","15","","","","","","","","","","English","","","","WOS:001366403800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","attention mechanism; autonomous driving; semantic segmentation; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NX2UPWG6","journalArticle","2024","Liu, CY; Liu, H; Chen, H; Du, WC; Yang, HY","Touchformer: A Transformer-Based Two-Tower Architecture for Tactile Temporal Signal Classification","IEEE TRANSACTIONS ON HAPTICS","","1939-1412","10.1109/TOH.2023.3346956","","Haptic temporal signal recognition plays an important supporting role in robot perception. This paper investigates how to improve classification performance on multiple types of haptic temporal signal datasets using a Transformer model structure. By analyzing the feature representation of haptic temporal signals, a Transformer-based two-tower structural model, called Touchformer, is proposed to extract temporal and spatial features separately and integrate them using a self-attention mechanism for classification. To address the characteristics of small sample datasets, data augmentation is employed to improve the stability of the dataset. Adaptations to the overall architecture of the model and the training and optimization procedures are made to improve the recognition performance and robustness of the model. Experimental comparisons on three publicly available datasets demonstrate that the Touchformer model significantly outperforms the benchmark model, indicating our approach's effectiveness and providing a new solution for robot perception.","2024-07","2025-02-26 20:39:16","2025-02-26 20:39:16","","396-404","","3","17","","","","","","","","","","English","","","","WOS:001319051000005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Data models; Feature extraction; Haptic interfaces; Robot sensing systems; Robots; signal processing; spatial features; Tactile perception; temporal features; Timing; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4UPF7SR3","journalArticle","2021","Mao, KL; Xiao, X; Xu, TY; Rong, Y; Huang, JZ; Zhao, PL","Molecular graph enhanced transformer for retrosynthesis prediction","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2021.06.037","","With massive possible synthetic routes in chemistry, retrosynthesis prediction is still a challenge for researchers. Recently, retrosynthesis prediction is formulated as a Machine Translation (MT) task. Namely, since each molecule can be represented as a Simplified Molecular-Input Line-Entry System (SMILES) string, the process of retrosynthesis is analogized to a process of language translation from the product to reactants. However, the MT models that applied on SMILES data usually ignore the information of natural atomic connections and the topology of molecules. To make more chemically plausible constrains on the atom representation learning for better performance, in this paper, we propose a Graph Enhanced Transformer (GET) framework, which adopts both the sequential and graphical information of molecules. Four different GET designs are proposed, which fuse the SMILES representations with atom embeddings learned from our improved Graph Neural Network (GNN). Empirical results show that our model significantly outperforms the vanilla Transformer model in test accuracy. (c) 2021 Elsevier B.V. All rights reserved.","2021-10-07","2025-02-26 20:39:16","2025-02-26 20:39:16","","193-202","","","457","","","","","","","","","","English","","","","WOS:000689714800015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;38<br/>Total Times Cited:&nbsp;&nbsp;41<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","DESIGN; Graph neural network; Molecular pattern; Retrosynthesis; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6IRZLQM9","journalArticle","2024","Chen, YL; Wan, Z; Li, YY; He, X; Wei, X; Han, J","Graph Curvature Flow-Based Masked Attention","JOURNAL OF CHEMICAL INFORMATION AND MODELING","","1549-9596","10.1021/acs.jcim.4c01616","","Graph neural networks (GNNs) have revolutionized drug discovery in chemistry and biology, enhancing efficiency and reducing resource demands. However, classical GNNs often struggle to capture long-range dependencies due to challenges like oversmoothing and oversquashing. Graph Transformers address these issues by employing global self-attention mechanisms that allow direct information exchange between any pair of nodes, enabling the modeling of long-range interactions. Despite this, Graph Transformers often face difficulties in capturing the nuanced structural information on graphs. To overcome these challenges, we introduce the CurvFlow-Transformer, a novel graph Transformer model incorporating a curvature flow-based masked attention mechanism. By leveraging a topologically enhanced mask matrix, the attention layer can effectively detect subtle structural differences within graphs, balancing the focus between global mutual information and local structural details of molecules. The CurvFlow-Transformer demonstrates superior performance on the MoleculeNet data set, surpassing several state-of-the-art models across various tasks. Moreover, the model provides unique insights into the relationship between molecular structure and chemical properties by analyzing the attention heat coefficients of individual atoms.","2024-10-24","2025-02-26 20:39:16","2025-02-26 20:39:16","","8153-8163","","21","64","","","","","","","","","","English","","","","WOS:001340740300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","CHEMISTRY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4GITHC86","journalArticle","2024","Widmann, T; Simonsen, KB","Setting the tone: the diffusion of moral and moral-emotional appeals across political and public discourse","POLITICAL SCIENCE RESEARCH AND METHODS","","2049-8470","10.1017/psrm.2024.34","","Whether a topic is seen in a moral or moral-emotional light has significant political implications. Yet, we lack knowledge about the process of moralization: Who defines the way topics are communicated about? Where prior research has investigated the relative power of different actors to place a topic on the agenda or shape opinions, we study who sets the moral and moral-emotional tone of debate. To do so, we zoom in on immigration discourse in Germany and analyze fine-grained social media data from politicians, political parties, newspapers, and members of the public over a period of more than four years. After employing a transformer model to identify moral and moral-emotional appeals, we use structural vector autoregression models to demonstrate the important role of radical-right challengers in shaping public discourse in a negative moral-emotional direction. The results inform theories of moralization and political entrepreneurship.","2024-09-16","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","","","","","","","","","","","English","","","","WOS:001312571400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","computational text analysis; immigration; moral rhetoric; moral-emotional rhetoric; political discourse; radical right","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V7LS9C74","journalArticle","2021","La Ganga, A; Re, R; Guglielmi, P","Input Parallel Output Series Structure of Planar Medium Frequency Transformers for 200 kW Power Converter: Model and Parameters Evaluation","ENERGIES","","1996-1073","10.3390/en14051450","","Nowadays, the demand for high power converters for DC applications, such as renewable sources or ultra-fast chargers for electric vehicles, is constantly growing. Galvanic isolation is mandatory in most of these applications. In this context, the Solid State Transformer (SST) converter plays a fundamental role. The adoption of the Medium Frequency Transformers (MFT) guarantees galvanic isolation in addition to high performance in reduced size. In the present paper, a multi MFT structure is proposed as a solution to improve the power density and the modularity of the system. Starting from 20kW planar transformer model, experimentally validated, a multi-transformer structure is analyzed. After an analytical treatment of the Input Parallel Output Series (IPOS) structure, an equivalent electrical model of a 200kW IPOS (made by 10 MFTs) is introduced. The model is validated by experimental measurements and tests.","2021-03","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","5","14","","","","","","","","","","English","","","","WOS:000628124000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","CANCELLATION; DYNAMIC CIRCUIT MODEL; IPOS; LEAKAGE INDUCTANCE; MAGNETIC CORES; model; NOISE; power transformers; Solid State Transformer; STRAY CAPACITANCES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TWUW9QBN","journalArticle","2024","Xia, CX; Duan, XZ; Gao, XJ; Ge, B; Li, KC; Fang, XJ; Zhang, Y; Yang, K","PCTDepth: Exploiting Parallel CNNs and Transformer via Dual Attention for Monocular Depth Estimation","NEURAL PROCESSING LETTERS","","1370-4621","10.1007/s11063-024-11524-0","","Monocular depth estimation (MDE) has made great progress with the development of convolutional neural networks (CNNs). However, these approaches suffer from essential shortsightedness due to the utilization of insufficient feature-based reasoning. To this end, we propose an effective parallel CNNs and Transformer model for MDE via dual attention (PCTDepth). Specifically, we use two stream backbones to extract features, where ResNet and Swin Transformer are utilized to obtain local detail features and global long-range dependencies, respectively. Furthermore, a hierarchical fusion module (HFM) is designed to actively exchange beneficial information for the complementation of each representation during the intermediate fusion. Finally, a dual attention module is incorporated for each fused feature in the decoder stage to improve the accuracy of the model by enhancing inter-channel correlations and focusing on relevant spatial locations. Comprehensive experiments on the KITTI dataset demonstrate that the proposed model consistently outperforms the other state-of-the-art methods.","2024-02-26","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","2","56","","","","","","","","","","English","","","","WOS:001171282500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","Attention; CNNs; Hierarchical interaction fusion; Monocular depth estimation; NETWORK; SHAPE; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YV65KUAN","journalArticle","2023","Pi, F; Tian, SW; Pei, XJ; Chen, P; Wang, X; Wang, XW","AdaTrans: An adaptive transformer for IoT Malware detection based on sensitive API call graph and inter-component communication analysis","JOURNAL OF INTELLIGENT & FUZZY SYSTEMS","","1064-1246","10.3233/JIFS-233556","","With the development of the Internet of Things (IoT), mobile devices are playing an increasingly important role in our daily lives. There are various malware threats present in these mobile devices, which can steal users' personal information. Some malware exploits Inter-Component Communication (ICC) to execute malicious activities for unauthorized data access and system control, enabling communication between different components within an app and between different apps. In this paper, we propose an Adaptive Transformer-based malware framework (named AdaTrans) that combines sensitive Application Programming Interface (API)- and ICC-related features. The framework first extracts sensitive function call subgraphs (SFCS) to reflect the caller-callee relationships, and then utilizes ICC interactions to reveal hidden communication patterns in malicious activities. Moreover, we propose a novel adaptive Transformer model to detect malicious behaviors. We evaluate our framework on real-world datasets and demonstrate that AdaTrans consistently outperforms other existing state-of-the-art systems.","2023","2025-02-26 20:39:16","2025-02-26 20:39:16","","11439-11452","","6","45","","","","","","","","","","English","","","","WOS:001120921100139","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","ICC; Internet of things; Malware detection; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WICYJD3W","journalArticle","2022","Li, P; Wu, J; Wang, YX; Lan, Q; Xiao, WB","STM: Spectrogram Transformer Model for Underwater Acoustic Target Recognition","JOURNAL OF MARINE SCIENCE AND ENGINEERING","","2077-1312","10.3390/jmse10101428","","With the evolution of machine learning and deep learning, more and more researchers have utilized these methods in the field of underwater acoustic target recognition. In these studies, convolutional neural networks (CNNs) are the main components of recognition models. In recent years, a neural network model Transformer that uses a self-attention mechanism was proposed and achieved good performance in deep learning. In this paper, we propose a Transformer-based underwater acoustic target recognition model STM. To the best of our knowledge, this is the first work to introduce Transformer into the underwater acoustic field. We compared the performance of STM with CNN, ResNet18, and other multi-class algorithm models. Experimental results illustrate that under two commonly used dataset partitioning methods, STM achieves 97.7% and 89.9% recognition accuracy, respectively, which are 13.7% and 50% higher than the CNN Model. STM also outperforms the state-of-the-art model CRNN-9 by 3.1% and ResNet18 by 1.8%.","2022-10","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","10","10","","","","","","","","","","English","","","","WOS:000872848600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;23<br/>Total Times Cited:&nbsp;&nbsp;23<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","deep learning; Transformer; underwater acoustic target recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VTRMSQS3","journalArticle","2022","Moon, J; Park, G; Yang, M; Jeong, J","Design and Verification of Process Discovery Based on NLP Approach and Visualization for Manufacturing Industry","SUSTAINABILITY","","2071-1050","10.3390/su14031103","","When a consultant of a company that provides a smart factory solution consults with a customer, it is difficult to define the outline of the manufacturing process and create all activities within the process by case. It requires a large amount of resources from the company to perform a task. In this study, we propose a process discovery automation system that helps consultants define manufacturing processes. In addition, for process discovery, a fully attention-based transformer model, which has recently shown a strong performance, was applied. To be useful to consultants, we solved the black box characteristics of the deep learning model applied to process discovery and proposed a visualization method that can be used in the monitoring system when explaining the discovery process. In this study, we used the event log of the metal fabrication process to perform the modeling, visualization, and evaluation.","2022-02","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","3","14","","","","","","","","","","English","","","","WOS:000759391000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","FRAMEWORK; manufacturing industry; process discovery; process mining; process visualization; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DZ6AICJL","journalArticle","2025","Choi, WJ; Yang, M; You, IL; Yoon, YS; Ryu, GS; An, GH; Yoon, JS","Discoloration Characteristics of Mechanochromic Sensors in RGB and HSV Color Spaces and Displacement Prediction","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app15031066","","Mechanochromic sensors are promising for structural health monitoring as they can visually monitor the deformation caused by discoloration. Most studies have focused on the large deformation problems over 100% strain; however, it is necessary to investigate the discoloration characteristics in a small deformation range to apply it to engineering structures, such as reinforced concrete. In this study, a photonic crystal-based discoloration sensor was investigated to determine the discoloration characteristics of the red, green, and blue (RGB) as well as hue, saturation, and value (HSV) color spaces according to displacement levels. B and S showed the highest sensitivity and linear discoloration at displacements < 1 mm, whereas R and H showed significant discoloration characteristics at displacements > 1 mm. The Vision Transformer model based on RGB and HSV channels was linearly predictable up to 4 mm displacement with an accuracy of R-2 0.89, but errors were found at the initial displacement within 2 mm.","2025-02","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","3","15","","","","","","","","","","English","","","","WOS:001420115200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","discoloration; HSV; mechanochromic sensor; RGB; structure health monitoring","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LQUHM9WM","journalArticle","2024","Gao, L; Shao, ZK; Luo, ZQ; Hu, HB; Turkay, C; Chen, SM","TransforLearn: Interactive Visual Tutorial for the Transformer Model","IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS","","1077-2626","10.1109/TVCG.2023.3327353","","The widespread adoption of Transformers in deep learning, serving as the core framework for numerous large-scale language models, has sparked significant interest in understanding their underlying mechanisms. However, beginners face difficulties in comprehending and learning Transformers due to its complex structure and abstract data representation. We present TransforLearn, the first interactive visual tutorial designed for deep learning beginners and non-experts to comprehensively learn about Transformers. TransforLearn supports interactions for architecture-driven exploration and task-driven exploration, providing insight into different levels of model details and their working processes. It accommodates interactive views of each layer's operation and mathematical formula, helping users to understand the data flow of long text sequences. By altering the current decoder-based recursive prediction results and combining the downstream task abstractions, users can deeply explore model processes. Our user study revealed that the interactions of TransforLearn are positively received. We observe that TransforLearn facilitates users' accomplishment of study tasks and a grasp of key concepts in Transformer effectively.","2024-01","2025-02-26 20:39:16","2025-02-26 20:39:16","","891-901","","1","30","","","","","","","","","","English","","","","WOS:001159106500097","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Deep learning; Explorable explanations; NEURAL-NETWORKS; Transformer; Visual tutorial","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"STRFK4HV","journalArticle","2024","Yakovleva, D; Telnov, S; Makarov, I; Filchenkov, A","Bid Landscape Forecasting and Cold Start Problem With Transformers","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3360493","","In Real-Time Bidding, advertisers aim to optimally bid within a limited budget constraint. Effective bidding strategies require bid landscape forecasting to predict the probability distribution of market price for each advertisement auction. This distribution has a complicated form with many peaks. Moreover, all probabilities of bids depend on each other. Most existing solutions mainly focus on learning a parameterized model based on some heuristic assumptions of distribution forms. In this paper, we propose a Transformer model that takes into account dependencies between bids improving the bid landscape forecasting. We also increase the quality of model prediction on the advertisement cold start for the cases of insufficient data. Our experiments on two real-world industrial datasets prove that the proposed model statistically significantly outperforms the state-of-the-art solutions both in terms of ANLP metrics by 8.75% and ROC-AUC by 1.1%. In addition, we show the industrial applicability of our approach.","2024","2025-02-26 20:39:16","2025-02-26 20:39:16","","19117-19127","","","12","","","","","","","","","","English","","","","WOS:001160969200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Bid forecasting; cold start; REGRESSION; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XMM9FR4D","journalArticle","2024","Qiao, YM; Jiang, WY; Su, GF; Jiang, JC; Li, X; Wang, F","A transformer-based neural network for ignition location prediction from the final wildfire perimeter","ENVIRONMENTAL MODELLING & SOFTWARE","","1364-8152","10.1016/j.envsoft.2023.105915","","Ignition location prediction is crucial for wildfire incident investigation and events reconstruction. However, existing models mainly focus on simulating the wildfire forward and rarely trace the ignition backward. In this paper, a novel transformer-based neural network named ILNet was proposed to predict the ignition location backward from the final wildfire perimeter. The ILNet first concatenated all wildfire-driven data as a composite image and divided it into several regular patches. Then, the self-attention mechanism was adopted to extract global spatial features with a variable scale among these patches. These features were further decoded to output semantic masks of growth phase and ignition phase. The geometric center of ignition phase was defined as the ignition location. Finally, a real wildfire was chosen as the study case. The results show the competitive performance of ILNet model (MIoU: 88.45%, IDE_N: 1.99%, computation time: 0.57s), enabling to improve the traditional field work for government agencies.","2024-01","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","","172","","","","","","","","","","English","","","","WOS:001138272400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","Deep learning; Ignition location prediction; Transformer model; Wildfire incident","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6BN8H4P2","journalArticle","2023","Hemmasian, A; Farimani, AB","Reduced-order modeling of fluid flows with transformers","PHYSICS OF FLUIDS","","1070-6631","10.1063/5.0151515","","Reduced-order modeling (ROM) of fluid flows has been an active area of research for several decades. The huge computational cost of direct numerical simulations has motivated researchers to develop more efficient alternative methods, such as ROMs and other surrogate models. Similar to many application areas, such as computer vision and language modeling, machine learning and data-driven methods have played an important role in the development of novel models for fluid dynamics. The transformer is one of the state-of-the-art deep learning architectures that has made several breakthroughs in many application areas of artificial intelligence in recent years, including but not limited to natural language processing, image processing, and video processing. In this work, we investigate the capability of this architecture in learning the dynamics of fluid flows in a ROM framework. We use a convolutional autoencoder as a dimensionality reduction mechanism and train a transformer model to learn the system's dynamics in the encoded state space. The model shows competitive results even for turbulent datasets.","2023-05","2025-02-26 20:39:16","2025-02-26 20:39:16","","","","5","35","","","","","","","","","","English","","","","WOS:000993580200003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","FRAMEWORK","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FAA8R9G2","journalArticle","2022","La Quatra, M; Cagliero, L","Transformer-based highlights extraction from scientific papers","KNOWLEDGE-BASED SYSTEMS","","0950-7051","10.1016/j.knosys.2022.109382","","Highlights are short sentences used to annotate scientific papers. They complement the abstract content by conveying the main result findings. To automate the process of paper annotation, highlights extraction aims at extracting from 3 to 5 paper sentences via supervised learning. Existing approaches rely on ad hoc linguistic features, which depend on the analyzed context, and apply recurrent neural networks, which are not effective in learning long-range text dependencies. This paper leverages the attention mechanism adopted in transformer models to improve the accuracy of sentence relevance estimation. Unlike existing approaches, it relies on the end-to-end training of a deep regression model. To attend patterns relevant to highlights content it also enriches sentence encodings with a section-level contextualization. The experimental results, achieved on three different benchmark datasets, show that the designed architecture is able to achieve significant performance improvements compared to the state-of-the-art. (c) 2022 Published by Elsevier B.V.","2022-09-27","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","252","","","","","","","","","","English","","","","WOS:000853854000011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Extractive summarization; Highlights extraction; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HXSK4VMF","journalArticle","2021","Wang, SH; Shi, SM; Huang, HY","Enhanced encoder for non-autoregressive machine translation","MACHINE TRANSLATION","","0922-6567","10.1007/s10590-021-09285-x","","Non-autoregressive machine translation aims to speed up the decoding procedure by discarding the autoregressive model and generating the target words independently. Because non-autoregressive machine translation fails to exploit target-side information, the ability to accurately model source representations is critical. In this paper, we propose an approach to enhance the encoder's modeling ability by using a pre-trained BERT model as an extra encoder. With a different tokenization method, the BERT encoder and the Raw encoder can model the source input from different aspects. Furthermore, having a gate mechanism, the decoder can dynamically determine which representations contribute to the decoding process. Experimental results on three translation tasks show that our method can significantly improve the performance of non-autoregressive MT, and surpass the baseline non-autoregressive models. On the WMT14 EN -> DE translation task, our method achieves 27.87 BLEU with a single decoding step. This is a comparable result with the baseline autoregressive Transformer model which obtains a score of 27.8 BLEU.","2021-12","2025-02-26 20:39:17","2025-02-26 20:39:17","","595-609","","4","35","","","","","","","","","","English","","","","WOS:000719174300003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Machine translation; Non-autoregressive; Pre-training language model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BMFBGX65","journalArticle","2024","Zhu, HZ; Xu, WX; Huang, J; Yu, BC","Graph-geometric message passing via a graph convolution transformer for FKP regression","SCIENCE CHINA-INFORMATION SCIENCES","","1674-733X","10.1007/s11432-023-4107-3","","In this paper, the forward kinematics problem (FKP) of the Gough-Stewart platform (GSP) with six degrees of freedom (6 DoFs) is estimated via deep learning. We propose a graph convolution transformer model by systematically analyzing some challenges encountered with using deep learning regression on large-scale data. We attempt to leverage the graph-geometric message as input and singular value decomposition (SVD) orthogonalization for SO(3) manifold learning. This study is the first in which a robot with a sophisticated closed-loop mechanism is described by a graph structure and a specific deep learning model is proposed to solve the FKP of the GSP. Qualitative and quantitative experiments on our dataset demonstrate that our model is feasible and superior to other methods. Our method can guarantee error percentages of translation and rotation less than 1 mm and 1 degrees of 81.9% and 96.7%, respectively.","2024-12","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","12","67","","","","","","","","","","English","","","","WOS:001353749800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","deep learning; forward kinematics problem; Gough-Stewart platform; graph convolution transformer; graph-structured learning; KINEMATICS SOLUTION; MANIPULATOR; NEURAL-NETWORK; STEWART","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WZAW3BDN","journalArticle","2024","Kong, XJ; Chen, ZY; Li, JX; Bi, JH; Shen, GJ","KGNext: Knowledge-Graph-Enhanced Transformer for Next POI Recommendation With Uncertain Check-Ins","IEEE TRANSACTIONS ON COMPUTATIONAL SOCIAL SYSTEMS","","2329-924X","10.1109/TCSS.2024.3396506","","The next point-of-interest (POI) recommendation aims to predict users' future movements based on their historical trajectories. However, in reality, users may provide uncertain check-in records, resulting in uploaded data that lack precise location information and is instead ambiguous. Despite this challenge, only a limited number of studies have addressed this issue, often overlooking the intricate interactions among users, POIs, and POI categories. To that end, we propose a novel model called knowledge-graph-enhanced transformer (KGNext). KGNext leverages transition and interaction graphs derived from our constructed transitional-interactive knowledge graph (TIKG) to uncover both general movement patterns and varied user preferences regarding POIs and POI categories. Furthermore, KGNext integrates comprehensive contextual information from historical trajectories with TIKG to generate user trajectory embeddings. These encoded features are then utilized by a transformer model to provide fine-grained predictions of the next POI. Experimental results on three real-world datasets demonstrate the superiority of KGNext.","2024-10","2025-02-26 20:39:17","2025-02-26 20:39:17","","6637-6648","","5","11","","","","","","","","","","English","","","","WOS:001236633400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Knowledge graph; POI recommendation; Transformer; uncertain check-ins","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7PUZBKAX","journalArticle","2024","Radosavovic, I; Xiao, TT; Zhang, BK; Darrell, T; Malik, J; Sreenath, K","Real-world humanoid locomotion with reinforcement learning","SCIENCE ROBOTICS","","2470-9476","10.1126/scirobotics.adi9579","","Humanoid robots that can autonomously operate in diverse environments have the potential to help address labor shortages in factories, assist elderly at home, and colonize new planets. Although classical controllers for humanoid robots have shown impressive results in a number of settings, they are challenging to generalize and adapt to new environments. Here, we present a fully learning-based approach for real-world humanoid locomotion. Our controller is a causal transformer that takes the history of proprioceptive observations and actions as input and predicts the next action. We hypothesized that the observation-action history contains useful information about the world that a powerful transformer model can use to adapt its behavior in context, without updating its weights. We trained our model with large-scale model-free reinforcement learning on an ensemble of randomized environments in simulation and deployed it to the real-world zero-shot. Our controller could walk over various outdoor terrains, was robust to external disturbances, and could adapt in context.","2024-04-17","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","89","9","","","","","","","","","","English","","","","WOS:001204055100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","DYNAMICS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WN8LJCGN","journalArticle","2024","Lieskovska, E; Jakubec, M; Kudela, P","Traffic Flow Prediction in Urban Networks: Integrating Sequential Neural Network Architectures","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","The rapid growth of urban areas has significantly compounded traffic challenges, amplifying concerns about congestion and the need for efficient traffic management. Accurate short-term traffic flow prediction remains important for strategic infrastructure planning within these expanding urban networks. This study explores a Transformer-based model designed for traffic flow prediction, conducting a comprehensive comparison with established models such as Long Short-Term Time-Delay Neural Network (TDNN). Our approach integrates traditional time series values with derived time-related features, enhancing the model's predictive capabilities. The aim is to effectively capture temporal dependencies within operational data. Despite the effectiveness of existing models, internal complexities persist due to diverse road conditions that influence traffic dynamics. The proposed Transformer model consistently demonstrates competitive performance and offers adaptability when learning from longer time spans. However, the simpler BiLSTM model proved to be the most effective when applied to the utilized data.","2024-01","2025-02-26 20:39:17","2025-02-26 20:39:17","","708-714","","1","15","","","","","","","","","","English","","","","WOS:001250400300037","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","machine learning; short-term prediction; Traffic flow; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JEAKBDZA","journalArticle","2024","Zhang, H; Qu, WZ; Long, HZ; Chen, M","The Intelligent Advertising Image Generation Using Generative Adversarial Networks and Vision Transformer: A Novel Approach in Digital Marketing","JOURNAL OF ORGANIZATIONAL AND END USER COMPUTING","","1546-2234","10.4018/JOEUC.340932","","With the continuous evolution of digital marketing, the generation of advertising images has become crucial in capturing user interest and enhancing advertising effectiveness. However, existing methods face limitations in meeting the diverse and creative demands of advertising content, necessitating innovative algorithms to improve advertising generation outcomes. In addressing these challenges, this study proposes a deep learning algorithm framework that cleverly integrates a generative adversarial network and an VGG-based visual transformer model to enhance the effectiveness of advertising image generation. Systematic experimentation shows that the model proposed in this article achieves an AUC metric value of more than 0.7 on several datasets. The results of the experiments demonstrate that the novel algorithm significantly improves the attractiveness of advertising content, particularly showcasing substantial benefits in website operations during online evaluation experiments.","2024","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","1","36","","","","","","","","","","English","","","","WOS:001209502000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","advertising content generation; digital marketing; e-commerce; Sequence Generative Adversarial Networks (SeqGAN); Vision Transformer (ViT); Visual Geometry Group (VGG)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RII7KC2A","journalArticle","2023","Sankelo, J; Jijiyo, P","In the Belly of the River: Water-Related Traditional Practices and the Moral Authority of Murle Mothers","NORDIC JOURNAL OF AFRICAN STUDIES","","1459-9465","10.53228/njas.v32i4.1038","","This study illustrates the significance of water for the Murle people of South Sudan. Drawing from ethnographic fieldwork, we analyse traditional practices and metaphorical expressions in the spontaneous speech of male members of the la & eng;o age-set. We show that the spoken language embodies metaphorical expressions of the Murle cattle- and land-based identity and demonstrate how Indigenous knowledge manifests itself in water-related expressions and in traditional practices related to water. In these traditional practices water is used to foster peace, convey blessings, purify, and enhance fertility. The study also offers a new perspective on the role and agency of women in Murle age-sets, highlighting the role of a female diviner of the la & eng;o age-set. Female traditional experts, such as dole ci lilu, draw moral authority from the Murle tradition which regards women as the mothers of all society, and use spiritual power to promote peace and build relationships through advice. In turn, male chiefs performing traditional rituals deal with the ill effects of conflict, ensuring unity in the society and continuity of the tradition. The results indicate a complementary approach among the male and female experts of Murle tradition ( k epsilon ran epsilon ). This gendered study supplies a nuanced understanding of the transformative potential that Murle spirituality and traditional water- related practices can have among young men and women in an age-set society.","2023","2025-02-26 20:39:17","2025-02-26 20:39:17","","383-401","","4","32","","","","","","","","","","English","","","","WOS:001378287000003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","diviners; la & eng; Murle; o age-set; South Sudan; VIOLENCE; water-related traditional practices","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KSFK57S5","journalArticle","2024","Tejedor, J; Toledano, DT","Whisper-based spoken term detection systems for search on speech ALBAYZIN evaluation challenge","EURASIP JOURNAL ON AUDIO SPEECH AND MUSIC PROCESSING","","1687-4722","10.1186/s13636-024-00334-w","","The vast amount of information stored in audio repositories makes necessary the development of efficient and automatic methods to search on audio content. In that direction, search on speech (SoS) has received much attention in the last decades. To motivate the development of automatic systems, ALBAYZIN evaluations include a search on speech challenge since 2012. This challenge releases several databases that cover different acoustic domains (i.e., spontaneous speech from TV shows, conference talks, parliament sessions, to name a few) aiming to build automatic systems that retrieve a set of terms from those databases. This paper presents a baseline system based on the Whisper automatic speech recognizer for the spoken term detection task in the search on speech challenge held in 2022 within the ALBAYZIN evaluations. This baseline system will be released with this publication and will be given to participants in the upcoming SoS ALBAYZIN evaluation in 2024. Additionally, several analyses based on some term properties (i.e., in-language and foreign terms, and single-word and multi-word terms) are carried out to show the Whisper capability at retrieving terms that convey specific properties. Although the results obtained for some databases are far from being perfect (e.g., for broadcast news domain), this Whisper-based approach has obtained the best results on the challenge databases so far so that it presents a strong baseline system for the upcoming challenge, encouraging participants to improve it.","2024-02-29","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","1","2024","","","","","","","","","","English","","","","WOS:001172833500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;111</p>","","","ALBAYZIN evaluations; DOCUMENT-RETRIEVAL; KEYWORD SEARCH; QUERY; Search on speech; Spoken term detection; Whisper","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YWCABXPE","journalArticle","2024","He, R; Yuan, XF; Hinzen, W","Episodic Thinking in Alzheimer's Disease Through the Lens of Language: Linguistic Analysis and Transformer-Based Classification","AMERICAN JOURNAL OF SPEECH-LANGUAGE PATHOLOGY","","1058-0360","10.1044/2023_AJSLP-23-00066","","Purpose: Episodic memory decline is a hallmark of Alzheimer's disease (AD) and linked to deficits in episodic thinking directed to the future. We addressed the question whether a deficit in episodic thinking can be picked up directly from connected speech and its detection can be automatized. Method: We linguistically classified 2,809 utterances (including embedded clauses in the utterances) from picture descriptions from 70 healthy older controls, 82 people with mild probable AD (pAD), and 46 people with moderate pAD for whether they were episodic, nonepisodic, or ""other"" (e.g., off -task). Generalized linear regression models were used to investigate how ratios of these categories change in AD, controlling for age, gender, and education. Finally, we applied deep learning technique to explore the feasibility of automating the episodicity analysis. Results: Decline in episodicity significantly distinguished controls from both mild pAD and moderate pAD. Correlation analysis suggested this decline not to be an effect of age, gender, and education but of cognitive ability. The decline was not compensated by an increase of nonepisodic utterances but mainly of off -task expressions. A transformer -based classifier to explore the possibility of automatizing the classification of episodicity achieved a macro F1 score of 0.913 in the ternary classification. Conclusion: These results show that a loss of episodicity is an early effect in AD that is manifested in spontaneous speech and can be reliably measured by both humans and machines.","2024-01","2025-02-26 20:39:17","2025-02-26 20:39:17","","87-95","","1","33","","","","","","","","","","English","","","","WOS:001195828700031","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","MEMORY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZVUIBVVU","journalArticle","2022","Pinchbeck, GG; Brown, D; Mclean, S; Kramer, B","Validating word lists that represent learner knowledge in EFL contexts: The impact of the definition of word and the choice of source corpora","SYSTEM","","0346-251X","10.1016/j.system.2022.102771","","While word-frequency lists have been commonly used as indexes of word usefulness, their role as a proxy for learner word knowledge is unclear. Word knowledge in a structured sample (N = 625) of Japanese university-level EFL learners, operationalized using dichotomous Rasch modeling of test-item data, was used as an external reference criterion to investigate two issues germane to the development of word lists representing learner knowledge in EFL contexts: 1) the definition of word and 2) the choice of reference corpus. On the former, corpus-derived, word-frequency lists based on either word orthographic forms, flemmas, or word families were generated from 18 different corpora. Word-frequency lists using flemma-based word groupings resulted in higher correlations with learner population word knowledge as compared with those using word-familybased groupings across all 18 sets of word lists tested. On the latter, lists derived from corpora of spontaneous speech, fictional TV/movies for younger viewers, and narrative written texts consistently showed higher correlations with word knowledge than those derived from nonconversational speech, or any non-fiction written text genre. These results suggest that megacorpora compiled from conveniently available electronic written texts may not be ideal as scales for diagnostic vocabulary testing or as indexes used in readability formulae.","2022-06","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","106","","","","","","","","","","English","","","","WOS:000781854500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;89</p>","","","ABILITY; Assessment; English as a foreign language; Frequency; FREQUENCY; INCIDENTAL VOCABULARY ACQUISITION; MORPHOLOGICAL AWARENESS; Morphology; Register; Vocabulary; Word list","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2VRVREF7","journalArticle","2024","Liu, XY; Chen, ZX; Xu, ZQ; Zheng, ZW; Ma, FS; Wang, YJ","Enhancement of Underwater Images through Parallel Fusion of Transformer and CNN","JOURNAL OF MARINE SCIENCE AND ENGINEERING","","2077-1312","10.3390/jmse12091467","","Ocean exploration is crucial for utilizing its extensive resources. Images captured by underwater robots suffer from issues such as color distortion and reduced contrast. To address the issue, an innovative enhancement algorithm is proposed, which integrates Transformer and Convolutional Neural Network (CNN) in a parallel fusion manner. Firstly, a novel transformer model is introduced to capture local features, employing peak-signal-to-noise ratio (PSNR) attention and linear operations. Subsequently, to extract global features, both temporal and frequency domain features are incorporated to construct the convolutional neural network. Finally, the image's high and low frequency information are utilized to fuse different features. To demonstrate the algorithm's effectiveness, underwater images with various levels of color distortion are selected for both qualitative and quantitative analyses. The experimental results demonstrate that our approach outperforms other mainstream methods, achieving superior PSNR and structural similarity index measure (SSIM) metrics and yielding a detection performance improvement of over ten percent.","2024-09","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","9","12","","","","","","","","","","English","","","","WOS:001323807600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","global features; image enhancement; local features; parallel fusion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JNB436DE","journalArticle","2024","Li, C; Cai, H; Jiang, XY","Refine neutrino events reconstruction with BEiT-3","JOURNAL OF INSTRUMENTATION","","1748-0221","10.1088/1748-0221/19/06/T06003","","Neutrino Events Reconstruction has always been crucial for IceCube Neutrino Observatory. In the Kaggle competition ""IceCube - Neutrinos in Deep Ice"", many solutions use Transformer. We present ISeeCube, a pure Transformer model based on TorchScale (the backbone of BEiT-3). When having relatively same amount of total trainable parameters, our model outperforms the 2 nd place solution. By using TorchScale , the lines of code drop sharply by about 80% and a lot of new methods can be tested by simply adjusting configs. We compared two fundamental models for predictions on a continuous space, regression and classification, trained with MSE Loss and CE Loss respectively. We also propose a new metric, overlap ratio, to evaluate the performance of the model. Since the model is simple enough, it has the potential to be used for more purposes such as energy reconstruction, and many new methods such as combining it with GraphNeT can be tested more easily. The code and pretrained models are available at https://github.com/ChenLi2049/ISeeCube.","2024-06","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","6","19","","","","","","","","","","English","","","","WOS:001243013900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Data processing methods; Neutrino detectors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VMUIIJS5","journalArticle","2023","VanGessel, FG; Perry, E; Mohan, S; Barham, OM; Cavolowsky, M","Natural language processing for knowledge discovery and information extraction from energetics corpora","PROPELLANTS EXPLOSIVES PYROTECHNICS","","0721-3115","10.1002/prep.202300109","","We present a demonstration of the utility of Natural Language Processing (NLP) for aiding research into energetic materials and associated systems. The NLP method enables machine understanding of textual data, offering an automated route to knowledge discovery and information extraction from energetics text. We apply three established unsupervised NLP models: Latent Dirichlet Allocation, Word2Vec, and the Transformer to a large curated dataset of energetics-related scientific articles. We demonstrate that each NLP algorithm is capable of identifying energetic topics and concepts, generating a language model which aligns with Subject Matter Expert knowledge. Furthermore, we present a document classification pipeline for energetics text. Our classification pipeline achieves 59-76 % accuracy depending on the NLP model used, with the highest performing Transformer model rivaling inter-annotator agreement metrics. The NLP approaches studied in this work can identify concepts germane to energetics and therefore hold promise as a tool for accelerating energetics research efforts and energetics material development. image","2023-11","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","11","48","","","","","","","","","","English","","","","WOS:001076295500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","detonation science; energetics; knowledge discovery; large language models; NLP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TLJ39ZN8","journalArticle","2023","Lu, XW; Bai, CY; Zhu, AJ; Zhu, YL; Wang, KZ","MCFormer: A Transformer-Based Detector for Molecular Communication With Accelerated Particle-Based Solution","IEEE COMMUNICATIONS LETTERS","","1089-7798","10.1109/LCOMM.2023.3303091","","Molecular communication (MC) enables communication at the nanoscale where traditional electromagnetic waves are ineffective, and accurate signal detection is essential for practical implementation. However, due to the lack of accurate mathematical models, statistical-based signal detection methods are not applicable, and existing deep learning-based models exhibit relative simplicity in design. This letter integrates ideas from natural language processing into MC and proposes the MCFormer, a detector based on the classical Transformer model. Additionally, we propose an accelerated particle-based simulation algorithm using matrix operations for rapid generation of high-quality training data with a lower complexity than traditional methods. The experimental results demonstrate that the MCFormer achieves nearly optimal accuracy in a noise-free environment, surpassing the performance of the Deep Neural Network (DNN). Moreover, MCFormer can show optimal performance in environments with significant levels of unknown noise. All the codes can be found at https://github.com/Xiwen-Lu/MCFormer.","2023-10","2025-02-26 20:39:17","2025-02-26 20:39:17","","2837-2841","","10","27","","","","","","","","","","English","","","","WOS:001099949300058","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;14</p>","","","detector design; Molecular communication; signal detection; simulation; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QH9563M2","journalArticle","2023","Li, JX; Si, GN; Liang, XY; An, ZL; Tian, PX; Zhou, FY","Partition-Based Point Cloud Completion Network with Density Refinement","ENTROPY","","1099-4300","10.3390/e25071018","","In this paper, we propose a novel method for point cloud complementation called PADPNet. Our approach uses a combination of global and local information to infer missing elements in the point cloud. We achieve this by dividing the input point cloud into uniform local regions, called perceptual fields, which are abstractly understood as special convolution kernels. The set of point clouds in each local region is represented as a feature vector and transformed into N uniform perceptual fields as the input to our transformer model. We also designed a geometric density-aware block to better exploit the inductive bias of the point cloud's 3D geometric structure. Our method preserves sharp edges and detailed structures that are often lost in voxel-based or point-based approaches. Experimental results demonstrate that our approach outperforms other methods in reducing the ambiguity of output results. Our proposed method has important applications in 3D computer vision and can efficiently recover complete 3D object shapes from missing point clouds.","2023-07","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","7","25","","","","","","","","","","English","","","","WOS:001036068100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","convolutional neural networks; geometric density; gridding; point cloud completion; radar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8YLDIGUU","journalArticle","2023","Zhu, YB; Zhao, WT; Hua, R; Wu, XX","Topic-aware video summarization using multimodal transformer","PATTERN RECOGNITION","","0031-3203","10.1016/j.patcog.2023.109578","","Video summarization aims to generate a short and compact summary to represent the original video. Existing methods mainly focus on how to extract a general objective synopsis that precisely summaries the video content. However, in real scenarios, a video usually contains rich content with multiple top-ics and people may cast diverse interests on the visual contents even for the same video. In this pa -per, we propose a novel topic-aware video summarization task that generates multiple video summaries with different topics. To support the study of this new task, we first build a video benchmark dataset by collecting videos from various types of movies and annotate them with topic labels and frame-level importance scores. Then we propose a multimodal Transformer model for the topic-aware video summa-rization, which simultaneously predicts topic labels and generates topic-related summaries by adaptively fusing multimodal features extracted from the video. Experimental results show the effectiveness of our method. (c) 2023 Elsevier Ltd. All rights reserved.","2023-08","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","140","","","","","","","","","","English","","","","WOS:000976856500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Multimodal transformer; NETWORKS; Topic-aware video summarization; Video summarization dataset","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QTJ9EWH7","journalArticle","2023","Liu, P; Chen, L; Zhang, HP; Zhang, YX; Liu, C; Li, C; Wang, ZH","PEAR: Positional-encoded Asynchronous Autoregression for satellite anomaly detection","PATTERN RECOGNITION LETTERS","","0167-8655","10.1016/j.patrec.2023.10.007","","This paper proposes a Positional-Encoded Asynchronous AutoRegression (PEAR) method for satellite anomaly detection. We empirically observe that a single classification model can hardly detect unknown anomalous situations and neglect the Markov nature of temporal satellite data. To address this, we adopt an autoregressive model to deal with the prediction of unknown anomaly for satellite data. We further propose a non-uniform temporal encoding method for asynchronous data and a median filtering method for more accurate detection. To reduce the effect of outliers, we employ an adaptive threshold selection method to achieve a more robust classification boundary. We test the proposed method on the time series prediction models including LSTM and transformers and we further employ the positional encoding strategy to improve the modeling capabilities of the Transformer model on high-frequency information. Experiments on real satellite data demonstrate that the proposed PEAR method outperforms the baseline method by 55.79%.","2023-12","2025-02-26 20:39:17","2025-02-26 20:39:17","","96-101","","","176","","","","","","","","","","English","","","","WOS:001108946400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Anomaly detection; Autoregressive model; MODEL; Positional encoding; Satellite data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4FLBYFLN","journalArticle","2025","Wang, LY; Cao, YZ; Xiang, JH","ST-TNet: An spatio-temporal joint transformer network for CSI feedback in FDD-MIMO systems","PHYSICAL COMMUNICATION","","1874-4907","10.1016/j.phycom.2024.102570","","In recent years, deep learning methods have been shown to have strong potential and superiority in reducing channel state information (CSI) feedback overhead and further improving feedback accuracy to maximize the performance benefits of massive Multiple-Input Multiple-Output (MIMO) in frequency division duplex (FDD) mode. As the CSI matrices are transformed into sequences for input to the Transformer model, the rearrangement leads to the loss of the original physical location relationships. Based on this problem, this paper proposes a transformer decoder based on spatio-temporal joint (ST-T). We employ a spatial attention mechanism to compensate for this information loss and focus on key spatial features more accurately, further exploiting the potential of single- and two-layer transformers in reconstructing CSI matrices. The results are validated by simulations based on DCRNet and CLNet encoders, which show that higher performance can be achieved with lower computational load compared to other lightweight models.","2025-02","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","68","","","","","","","","","","English","","","","WOS:001375727300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","Attention; CSI feedback; Deep learning; Lightweighting; Massive MIMO; Transformer; WIRELESS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IRI7HBGE","journalArticle","2024","Li, R; Du, JL; Qin, Z; Zhang, SK; Du, CX; Zhou, Y; Xiao, ZS","Entanglement structure detection via computer vision","PHYSICAL REVIEW A","","2469-9926","10.1103/PhysRevA.110.012448","","Quantum entanglement plays a pivotal role in various quantum information processing tasks. However, a universal and effective way to detect entanglement structures is still lacking, especially for high-dimensional and multipartite quantum systems. Noticing the mathematical similarities between the common representations of many-body quantum states and the data structures of images, we are inspired to employ advanced computer vision technologies for data analysis. In this work, we propose a hybrid convolutional neural network-transformer model for both the classification of Greenberger-Horne-Zeilinger and W states and the detection of various entanglement structures. By leveraging the feature-extraction capabilities of convolutional neural networks and the powerful modeling abilities of transformers, we not only can effectively reduce the time and computational resources required for the training process but can also obtain high detection accuracies. Through numerical simulation and physical verification, it is confirmed that our hybrid model is more effective than traditional techniques and thus offers a powerful tool for characterizing multipartite entanglement structures.","2024-07-19","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","1","110","","","","","","","","","","English","","","","WOS:001274477000003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","INEQUALITIES; INFORMATION; QUANTUM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JBH9X8UI","journalArticle","2024","Devi, RSS; Kumar, VRV; Sivakumar, P","InViTMixup: plant disease classification using convolutional vision transformer with Mixup augmentation","JOURNAL OF THE CHINESE INSTITUTE OF ENGINEERS","","0253-3839","10.1080/02533839.2024.2346490","","Computer vision-based research is carried out to enhance the crop yield with automation solutions. In Tamil N & amacr;du, tomato cultivation is carried out in many districts, including Coimbatore, and its contribution to the Indian economy, i.e. GDP growth, is significant. This paper proposes InViT Mixup, a novel approach toward image classification of diseased tomato leaves. The effectiveness of convolutional neural network (CNN) in obtaining spatial information and the attention mechanism of vision transformers, along with Mixup data augmentation, are combined, and the model's generalization in predicting the diseased tomato based on leaf symptoms is evaluated. The proposed convolutional transformer model improvised the classification results of tomato disease in terms of accuracy and training speed compared to pure CNN or transformer-based models. In the proposed work, 10 tomato leaf disease classes from the PlantVillage dataset are used. Top-1 accuracy of 93.5% and Top-5 accuracy of 99.7% are achieved.","2024-07-03","2025-02-26 20:39:17","2025-02-26 20:39:17","","520-527","","5","47","","","","","","","","","","English","","","","WOS:001217827000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","Hsieh, Sun-Yuan; inception V3; Lin, Limei; mixup augmentation; Transfer learning; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9RZ8HBG9","journalArticle","2023","Shim, BS; Hou, JU","Improving Estimation of Layer Thickness and Identification of Slicer for 3D Printing Forensics","SENSORS","","1424-8220","10.3390/s23198250","","This study emphasizes the significance of estimating the layer thickness and identifying slicer programs in the realm of 3D printing forensics. With the progress in 3D printing technology, precise estimation of the layer thickness has become crucial. However, previous research on layer thickness estimation has mainly treated the problem as a classification task, which is inadequate for continuous layer thickness parameters. Furthermore, previous studies have concentrated on hardware-based printer identification, but the identification of slicer programs through 3D objects is a vital aspect of the software domain and can provide valuable clues for 3D printing forensics. In this study, a regression-based approach utilizing a vision transformer model was proposed. Experiments conducted on the SI3DP++ dataset demonstrated that the proposed model could handle a broad range of data and outperform the current classification models. Additionally, this study proposed a new research direction by introducing slicer program identification, which significantly contributes to the field of 3D printing forensics.","2023-10","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","19","23","","","","","","","","","","English","","","","WOS:001081640700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","3D printing; artificial intelligence; image forensics; MODELS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EL636GZU","journalArticle","2024","Yang, ZY; Nashik, S; Huang, CT; Aibin, M; Coria, L","Next-Gen Remote Airport Maintenance: UAV-Guided Inspection and Maintenance Using Computer Vision","DRONES","","2504-446X","10.3390/drones8060225","","This paper presents a novel system for the automated monitoring and maintenance of gravel runways in remote airports, particularly in Northern Canada, using Unmanned Aerial Vehicles (UAVs) and computer vision technologies. Due to the geographic isolation and harsh weather conditions, these airports face unique challenges in runway maintenance. Our approach integrates advanced deep learning algorithms and UAV technology to provide a cost-effective, efficient, and accurate means of detecting runway defects, such as water pooling, vegetation encroachment, and surface irregularities. We developed a hybrid approach combining the vision transformer model with image filtering and thresholding algorithms, applied on high-resolution UAV imagery. This system not only identifies various types of defects but also evaluates runway smoothness, contributing significantly to the safety and reliability of air transport in these areas. Our experiments, conducted across multiple remote airports, demonstrate the effectiveness of our approach in real-world scenarios, offering significant improvements over traditional manual inspection methods.","2024-06","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","6","8","","","","","","","","","","English","","","","WOS:001256340800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","computer vision; remote airports; UAV","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F2DFDRVZ","journalArticle","2024","Huang, CY; Chen, LC","The Impact of Short Video Live Broadcast on the Sales of Sports Machinery and Equipment","INTERNATIONAL JOURNAL OF E-COLLABORATION","","1548-3673","10.4018/IJeC.344027","","This paper proposes a neural network model based on deep learning, which can better analyze the impact of short video live broadcast on sports machinery and equipment. Firstly, this paper proposes a U-Net-based convolutional neural network as the backbone network of this paper, which mainly realizes the impact of short video live broadcast on sales. Secondly, this paper proposes a dense residual module based on the Transformer lightweight module, which can effectively improve the global modeling ability of the network model and improve the prediction accuracy of the network model. Finally, through a large number of experiments, it is proved that the convolutional neural network based on U-Net proposed in this paper can be better used for the task of short video live broadcast for the sales of sports machinery and equipment, and achieves better prediction accuracy and reasoning speed.","2024","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","1","20","","","","","","","","","","English","","","","WOS:001301028600018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","CITY; Deep Learning; E-Commerce; Mobile Multimedia; Residual Module; Short Video Live Broadcast; Sports Machinery Sales; Transformer Model; U-Net Network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UTX86VLQ","journalArticle","2023","Li, J; Bao, Y; Liu, WX; Ji, PX; Wang, LK; Wang, ZB","Twins transformer: Cross-attention based two-branch transformer network for rotating bearing fault diagnosis","MEASUREMENT","","0263-2241","10.1016/j.measurement.2023.113687","","Due to the inherent shortcomings of traditional depth models, the Transformer model based on the self-attention mechanism has become popular in the field of fault diagnosis. The current Transformer's self-attentive mechanism provides an alternative way of thinking, which can make direct association between each signal. However, it can only focus on the association information within a sequence, and it is difficult to understand the information gap between samples. Therefore, this paper proposes the two-branch Twins attention, which for the first time uses cross-attention to focus on information associations between samples. Twins attention uses crossattention to learn information associations between samples in addition to retaining the information associations within sequences learned by self-attention. The performance of the proposed model was validated on four popular bearing datasets. Compared to the original transformer structure, the average accuracy of each dataset improved by 1.73% to 99.42%, leading the noise experiments.","2023-12","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","223","","","","","","","","","","English","","","","WOS:001109372800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;20<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Attention mechanisms; Cross-attention; Fault diagnosis; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EASUQN2A","journalArticle","2024","Zhang, HY; Zhang, XY; Jiang, QZ; Li, L; Zheng, BH; Sun, WW","Cross-View Location Alignment Enhanced Spatial-Topological Aware Dual Transformer for Travel Time Estimation","IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS","","1524-9050","10.1109/TITS.2024.3463501","","Accurately estimating route travel time is crucial for intelligent transportation systems. Urban road networks and routes can be viewed from spatial and topological perspectives while existing works typically focus on one view and disregard important information from the other perspective. In this paper, we propose TTEFORMER, a novel travel time estimation model. It incorporates an alignment-enhanced spatial-topological aware dual transformer model to adaptively incorporate intra- and inter-view features in the route, guided by cross-view location alignment matrices with clear correspondences between locations in two views. Additionally, we propose a sparsity-aware dual-view traffic feature extraction module to effectively capture temporal traffic state changes. Compared to baseline models, TTEFORMER demonstrates improved performance on the MAPE and MAE metrics for Chengdu and Shanghai datasets, achieving improvements of 8.32%, 7.03%, 8.06% and 9.51% respectively, validating the effectiveness of TTEFORMER in travel time estimation.","2024-12","2025-02-26 20:39:17","2025-02-26 20:39:17","","20508-20522","","12","25","","","","","","","","","","English","","","","WOS:001328983800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","multi-view learning; PREDICTION; ROAD NETWORKS; spatial-temporal data mining; transformer; Travel time estimation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R7Q5U6X6","journalArticle","2024","Uddin, S; Nawaz, T; Ferryman, J; Rashid, N; Asaduzzaman, M; Nawaz, R","Skeletal Keypoint-Based Transformer Model for Human Action Recognition in Aerial Videos","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3354389","","Several efforts have been made to develop effective and robust vision-based solutions for human action recognition in aerial videos. Generally, the existing methods rely on the extraction of either spatial features (patch-based methods) or skeletal key points (pose-based methods) that are fed to a classifier. Unlike the patch-based methods, the pose-based methods are generally regarded to be more robust to background changes and computationally efficient. Moreover, at the classification stage, the use of deep networks has generated significant interest within the community; however, the need remains to develop accurate and computationally effective deep learning-based solutions. To this end, this paper proposes a lightweight Transformer network-based method for human action recognition in aerial videos using the skeletal keypoints extracted using YOLOv8. The effectiveness of the proposed method is shown on a well-known public dataset containing 13 action classes, achieving very encouraging performance in terms of accuracy and computational cost as compared to several existing related methods.","2024","2025-02-26 20:39:17","2025-02-26 20:39:17","","11095-11103","","","12","","","","","","","","","","English","","","","WOS:001150441600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","Action recognition; aerial videos; transformer network; video surveillance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WW5I9UNG","journalArticle","2023","Yu, C; Hu, B; Cheng, XC; Yin, GQ; Wang, ZG","Remote sensing building damage assessment with a multihead neighbourhood attention transformer","INTERNATIONAL JOURNAL OF REMOTE SENSING","","0143-1161","10.1080/01431161.2023.2242590","","Most existing remote sensing disaster assessment methods rely on convolutional neural networks (CNNs). Although CNNs can extract effective semantic features, determining global spatial relationships remains limited due to the locality of convolutional operations. The recently developed transformer-based method can extract global information from images effectively by encoding image tokens. However, its consumption of computational resources varies markedly with increasing image resolution. In this paper, we propose a novel transformer-based neural network for disaster assessment problems. The network uses a multihead neighbourhood attention (MNA) transformer as the base layer of the encoder to achieve more efficient self-attention computation. In addition, the bitemporal feature fusion module (BFFM) performs differential enhancement and injects the change information to the decoder via skip connections. The multiscale tokenizer generates multiscale image tokens to mitigate the loss of detail during encoding. Experimental results on three datasets show that the proposed method outperforms existing methods.","2023-08-18","2025-02-26 20:39:17","2025-02-26 20:39:17","","5069-5100","","16","44","","","","","","","","","","English","","","","WOS:001046523200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Building damage assessment; change detection; deep learning; remote sensing images; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E5KX87EC","journalArticle","2023","Dang, M; Wang, HX; Nguyen, TH; Tightiz, L; Tien, LD; Nguyen, TN; Nguyen, NP","CDD-TR: Automated concrete defect investigation using an improved deformable transformers","JOURNAL OF BUILDING ENGINEERING","","2352-7102","10.1016/j.jobe.2023.106976","","Public infrastructures, such as bridges, dams, and buildings, play a key role in urban develop-ment. Structural inspection by visually monitoring and inspecting the structures for defects has become increasingly vital to prevent structural deterioration. However, previously, the structural inspection was primarily carried out manually, which was time-consuming, error-prone, and tedious. Therefore, this study proposes an efficient concrete defect detection system based on a transformer model. Four primary contributions are (i) a novel defect detection framework motivated by the deformable transformers (Deformable DETR); (ii) the use of a big concrete defect dataset containing four common defect types; (iii) multiple modules are introduced to the original Deformable DETR model and help the model achieve better performance; and (iv) visualization of the model's deformable attention weights to show the model effectiveness in detecting and localizing defects. The framework outperforms previous state-of-the-art object detection networks and obtains the mean Average Precision (mAP) of 63.8%.","2023-09-15","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","75","","","","","","","","","","English","","","","WOS:001056847700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Concrete defect; Deep learning; Defect detection; Detr; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6N63FIEN","journalArticle","2024","Song, YN; Du, HQ; Piao, TY; Shi, HY","Research on Financial Risk Intelligent Monitoring and Early Warning Model Based on LSTM, Transformer, and Deep Learning","JOURNAL OF ORGANIZATIONAL AND END USER COMPUTING","","1546-2234","10.4018/JOEUC.337607","","As global financial markets continue to evolve and change, financial risk monitoring and early warning have become increasingly important. However, the complexity and diversity of financial markets have led to the emergence of multidimensional and multimodal data. Traditional risk monitoring methods face difficulties in handling such diverse data and adapting to the monitoring and early warning needs of emerging risk types. To address these issues, this article proposes a financial risk intelligent monitoring and early warning model that integrates deep learning to better cope with uncertainty and risk in the financial market. Firstly, the authors introduce an LSTM model in the initial approach, trained on historical financial market data, to capture long-term dependencies and trends in the data, enabling effective monitoring of financial risk. They also optimize the model architecture to improve its performance and prediction accuracy. Secondly, the authors further introduce a transformer model with self -attention mechanism to better handle sequential data.","2024","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","1","36","","","","","","","","","","English","","","","WOS:001185409200014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Deep Learning; Early Warning; Financial Risk; LSTM; Monitoring; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V6MPUXW2","journalArticle","2024","Li, H; Zhao, JL; Huo, H; Fang, S; Chen, JJ; Yao, LT; Hua, YR","T3SRS: Tensor Train Transformer for compressing sequential recommender systems","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2023.122260","","In recent years, attention mechanisms have gained popularity in sequential recommender systems (SRSs) due to obtaining dynamic user preferences efficiently. However, over-parameterization of these models often increases the risk of overfitting. To address this challenge, we propose a Transformer model based on tensor train networks. Initially, we propose a tensor train layer (TTL) to accommodate the original weight matrix, thus reducing the space complexity of the mapping layer. Based on the TTL, we reconfigure the multi-head attention module and the position-wise feed-forward network. Finally, a tensor train layer replaces the output layer to complete the overall compression. According to the experimental results, the proposed model compresses SRSs parameters effectively, achieving compression rates of 76.2%-85.0%, while maintaining or enhancing sequence recommendation performance. To our knowledge, the Tensor Train Transformer is the first model compression approach for Transformer-based SRSs, and the model is broadly applicable.","2024-03-15","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","238","","","","","","","","","","English","","","","WOS:001106973300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Model compression; Sequential recommender systems; Tensor train network; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GJAQZQI3","journalArticle","2023","Lu, YA; Qin, WB; Zhou, C; Liu, ZH","Automated detection of dangerous work zone for crawler crane guided by UAV images via Swin Transformer","AUTOMATION IN CONSTRUCTION","","0926-5805","10.1016/j.autcon.2023.104744","","Crawler crane overturning often results in many casualties and property damage. However, the existing research on overturning prevention mainly focuses on the internal factors of crawler cranes while ignoring the envi-ronmental factors represented by the subgrade bearing capacity. On this basis, this work summarizes three types of dangerous work zones including dangerous work zone with pit, dangerous work zone with unhardened area, and dangerous work zone with water with poor subgrade bearing capacity and develops an automated method for detection. A Mask Transformer model is adopted by using Swin Transformer as backbone network to recognize and segment the images obtained from an unmanned aerial vehicle. The detected images are trans-formed into a safety risk map that provides the driver with risk information about the dangerous work zone. Results show that the model proposed, which has been applied in a real engineering project, achieves a good detection effect.","2023-03","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","147","","","","","","","","","","English","","","","WOS:000964779700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;16<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","CONSTRUCTION; Dangerous work zone; RESOURCES; Safety risk map; STABILITY; Subgrade bearing capacity; Swin Transformer; SYSTEM; TECHNOLOGY; TRACKING; UAV","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V3UGZTWW","journalArticle","2023","Chen, JX; Cheng, YQ; Zhang, JX","Anti-local occlusion intelligent classification method based on MobileNet for hazardous waste","INTERNATIONAL JOURNAL OF MODELLING IDENTIFICATION AND CONTROL","","1746-6172","10.1504/IJMIC.2023.131203","","Anti-local occlusion intelligent classification methods based on MobileNet and VTM for hazardous waste are investigated in this paper. Three image datasets with ten kinds of hazardous waste and 5,000.0 samples are constructed, which include the image dataset with without occlusion, the image dataset with 15% occlusion, and the image dataset with random occlusion. Based on them, the MobileNet and VTM intelligent classification model are constructed, trained, and tested, respectively. It can be seen from testing results that the classification accuracies of VTM and MobileNet are very high for the image dataset with without occlusion. But as occlusion area on images go up or randomly changes, the classification accuracies of VTM and MobileNet go down for 15% and random occlusion cases. The testing results show that classification accuracy of MobileNet model is better than that of VTM model for hazardous waste with or without occlusion.","2023","2025-02-26 20:39:17","2025-02-26 20:39:17","","333-340","","4","42","","","","","","","","","","English","","","","WOS:001000397200006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","hazardous waste classification; MobileNet; occluded target identification; SEMANTIC SEGMENTATION; vision transformer model; VTM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D2ESPHEN","journalArticle","2021","Kumawat, D; Kumar, R; Macwan, T; Ghosh, J; Tanna, R; Aich, S; Jha, SK; Raju, D; ADTIYA-U Team","Electrical-Model of ADITYA-U Tokamak","INDIAN JOURNAL OF PHYSICS","","0973-1458","10.1007/s12648-019-01647-9","","An Electrical-Model is developed for ADITYA-U Tokamak to study the generation of different shapes and duration of LVs out of the total available flux, which is 0.6 Vs in positive convertor supply. Loop voltage (LV) is required to be controlled during plasma discharge to optimize and predict the breakdown of plasma, proper impurity burn-through time, plasma current magnitude and duration of the plasma as per the experimental requirement. Loop voltage waveform is governed by selecting different magnitudes of resistance values, switching time and duration of external resistance in the wave shaping primary circuit. Loop voltage control system has been modelled using simulation code (Electrical-Model). Same results have been validated with the modelling of ohmic wave shaping circuit in MATLAB-Simulink. Temporal profile of loop voltage has been incorporated for ADITYA-U Tokamak for several plasma discharges, and detailed observations and results are presented in the paper.","2021-03","2025-02-26 20:39:17","2025-02-26 20:39:17","","523-530","","3","95","","","","","","","","","","English","","","","WOS:000622342900016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;12</p>","","","−; 50; 52; 55; ADITYA-U Tokamak; b; Fa; Loop voltage; Plasma; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"77US9NKV","journalArticle","2024","Zhang, K; Li, XN; Ye, HY; Lin, KJ; Chen, SR; Law, R","How can ChatGPT assist hospitality and tourism education?","JOURNAL OF TEACHING IN TRAVEL & TOURISM","","1531-3220","10.1080/15313220.2024.2384743","","Artificial intelligence (AI) poses new challenges and opportunities for hospitality and tourism (H&T) education. This study explores how ChatGPT, a chatbot powered by a generative pre-trained transformer model, can affect H&T curriculum design and delivery. Using secondary data from academic articles, news reports, and official documents, the paper applies curriculum theory and stakeholder theory to examine the competencies, expectations, and interests of H&T students, educators, and industry practitioners regarding ChatGPT. This study reveals that ChatGPT can enhance learning outcomes and experiences, improve educational equity and efficiency, and raise ethical, technical, and pedagogical issues for H&T education. This research note also offers insights and recommendations for H&T educators to integrate ChatGPT into their teaching practices and prepare students for research work and careers that incorporate generative AI. Moreover, the study contributes to the literature on H&T education by examining the role and impact of ChatGPT as an innovative and emerging technology.","2024-10-01","2025-02-26 20:39:17","2025-02-26 20:39:17","","438-448","","4","24","","","","","","","","","","English","","","","WOS:001280835300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Artificial intelligence; CatGPT; CURRICULUM; education; TIME; tourism and hospitality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IBKKLAMT","journalArticle","2023","Wang, NN; Niu, XS; Yuan, YY; Sun, YZ; Li, R; You, GL; Zhao, AT","A coordinate attention enhanced swin transformer for handwriting recognition of Parkinson's disease","IET IMAGE PROCESSING","","1751-9659","10.1049/ipr2.12820","","Diagnosing Parkinson's disease (PD) in its early stages is a significant challenge in medicine. Hand tremors and dysgraphia, which are typical early motor symptoms of PD, can manifest for decades before a formal diagnosis is made. Therefore, handwriting analysis has become an important tool for detecting PD. While many machine learning algorithms have been applied in this area, they struggle to capture the subtle changes in handwriting and must describe features from various perspectives. To address these issues, this paper proposes a Coordinate Attention Enhanced Swin Transformer (CAS Transformer) model for PD handwriting recognition. It establishes the long-term dependence of features on the joint coordinate attention application, which enables the model to more accurately localize the important features of handwriting data and also extract the fuzzy edge features of handwriting images.These characteristics of the CAS Transformer enable it to outperform current advanced deep learning methods in classification, with an accuracy of 92.68% in experiments conducted on two handwritten datasets.","2023-07","2025-02-26 20:39:17","2025-02-26 20:39:17","","2686-2697","","9","17","","","","","","","","","","English","","","","WOS:000976363100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","DIAGNOSIS; feature extraction; image classification; NEURAL-NETWORK","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2AX76AD4","journalArticle","2023","Li, HC; Chen, AB; Yi, JZ; Chen, WJ; Yang, DW; Zhou, GX; Peng, WX","Environmental Sound Classification Based on CAR-Transformer Neural Network Model","CIRCUITS SYSTEMS AND SIGNAL PROCESSING","","0278-081X","10.1007/s00034-023-02339-w","","Environment Sound Classification (ESC) has been a challenging task in the audio field due to the different types of ambient sounds involved. In this paper, we propose a method for the ESC tasks based on the CAR-Transformer neural network model, which includes stages of sound sample pre-processing, deep learning-based feature extraction, and classifier classification. We convert the one-dimensional audio signal into two-dimensional Mel Frequency Cepstral Coefficients (MFCC) and use them as the feature map of the audio. The CAR-Transformer model was used for feature extraction, and after dimensionality reduction of the extracted feature map, we use the fully connected layer as a classifier of the feature map to obtain the final results. The method achieves a classification accuracy of 96.91% on the UrbanSound8K dataset, while the number of parameters in the model is only 0.16 M. The results of this paper were compared with other state-of-art research.","2023-09","2025-02-26 20:39:17","2025-02-26 20:39:17","","5289-5312","","9","42","","","","","","","","","","English","","","","WOS:000978147300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Attention; Environment sound classification; MFCC; RECOGNITION; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9SFUBNVM","journalArticle","2022","Ye, F; Hu, J; Huang, TQ; You, LJ; Weng, B; Gao, JY","Transformer for EI Nino-Southern Oscillation Prediction","IEEE GEOSCIENCE AND REMOTE SENSING LETTERS","","1545-598X","10.1109/LGRS.2021.3100485","","Accurate prediction of EI Nino-southern oscillation (ENSO) is of great significance to seasonal climate forecast. Recently, a convolutional neural network (CNN) has shown an optimal skill for ENSO prediction. However, it is difficult for the convolutional kernel to capture long-range precursors of ENSO due to its build-in local property. The transformer model has long been used in natural language processing (NLP) for its ability to focus on global features. Here, we introduce it to the ENSO research community and propose the ENSO transformer (ENSOTR). We show that using the ENSOTR model, the monthly average Nino3.4 index can be skillfully predicted up to one and a half years ahead. The model can also predict strong EI Nino cases more than a year ahead, such as 1997-1998. Experimental results show that our model achieves better skill than CNN for ENSO prediction.","2022","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","19","","","","","","","","","","English","","","","WOS:000730789400166","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;21<br/>Total Times Cited:&nbsp;&nbsp;22<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","ATMOSPHERE; Atmospheric modeling; Convolution; Convolutional neural network (CNN); deep learning; EI Nino southern oscillation (ENSO); ENSO; ENSO transformer (ENSOTR); Feature extraction; Indexes; Kernel; Meteorology; MODEL; Predictive models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HN2IYUHR","journalArticle","2024","Kazm, A; Ali, A; Hashim, H","Transformer Encoder with Protein Language Model for Protein Secondary Structure Prediction","ENGINEERING TECHNOLOGY & APPLIED SCIENCE RESEARCH","","2241-4487","10.48084/etasr.6855","","In bioinformatics, protein secondary structure prediction plays a significant role in understanding protein function and interactions. This study presents the TE_SS approach, which uses a transformer encoderbased model and the Ankh protein language model to predict protein secondary structures. The research focuses on the prediction of nine classes of structures, according to the Dictionary of Secondary Structure of Proteins (DSSP) version 4. The model's performance was rigorously evaluated using various datasets. Additionally, this study compares the model with the state -of -the -art methods in the prediction of eight structure classes. The findings reveal that TE_SS excels in nine- and three-class structure predictions while also showing remarkable proficiency in the eight-class category. This is underscored by its performance in Qs and SOV evaluation metrics, demonstrating its capability to discern complex protein sequence patterns. This advancement provides a significant tool for protein structure analysis, thereby enriching the field of bioinformatics.","2024-04","2025-02-26 20:39:17","2025-02-26 20:39:17","","13124-13132","","2","14","","","","","","","","","","English","","","","WOS:001198238800069","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Ankh protein language model; bioinformatics; NETWORKS; nine-class protein prediction; protein secondary structure prediction; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RAEG8XBQ","journalArticle","2024","Liu, Q; Tang, HB; Wu, LF; Chao, Z","Deep Learning-Driven E-Commerce Marketing Communication for Recommending Shopping System and Optimizing User Experience","JOURNAL OF ORGANIZATIONAL AND END USER COMPUTING","","1546-2234","10.4018/JOEUC.343258","","As competition in the realm of e-commerce escalates, the provision of personalized and precise shopping recommendations emerges as a pivotal strategy for e-commerce platforms striving to engage users effectively. Traditional recommendation systems often grapple with challenges such as the inability to capture intricate relationships, limited personalization, and issues concerning diversity. In response to these challenges, this study introduces cutting-edge deep learning techniques, namely Transformer models, Generative Adversarial Networks (GANs), and reinforcement learning, with the aim of bolstering the recommendation accuracy and user experience within e-commerce shopping systems.Initially, we harness Transformer models, capitalizing on their exceptional performance in processing sequential data to adeptly extract and learn representations of both product and user features. This facilitates a more profound understanding of the correlations between products and user shopping behaviors, thus empowering the system to offer more tailored recommendations.","2024","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","1","36","","","","","","","","","","English","","","","WOS:001293789600007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","E-Commerce; Generative Adversarial Networks; Marketing Communication; Personalized Recommendations; Reinforcement Learning; Transformer Model; User Experience","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VW5TWKBJ","journalArticle","2022","Pokhrel, P; Ioup, E; Simeonov, J; Hoque, MT; Abdelguerfi, M","A Transformer-Based Regression Scheme for Forecasting Significant Wave Heights in Oceans","IEEE JOURNAL OF OCEANIC ENGINEERING","","0364-9059","10.1109/JOE.2022.3173454","","In this article, we present a novel approach for forecasting significant wave heights in oceanic waters. We propose an algorithm based on the WaveWatch III, differencing, and a transformer neural network (Transformer). The data becomes stationary after first-order differencing, performed with the observed significant wave height and the wave height forecasts obtained from WaveWatch III. We perform a case study on a group of 92 buoys using WaveWatch III hindcasts. The Transformer model then provides the statistical forecasts of the residuals. The Transformer-based proposed framework obtains the root mean square error of 0.231 m for two days ahead forecasting. Our proposed method outperforms existing state-of-the-art machine learning and numerical approaches for significant wave heights prediction. Our results suggest that combining numerical and machine learning approaches gives better performance than using either alone.","2022-10","2025-02-26 20:39:17","2025-02-26 20:39:17","","1010-1023","","4","47","","","","","","","","","","English","","","","WOS:000824733600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;91</p>","","","Data assimilation; forecasting; Forecasting; Mathematical models; MODEL; NETWORKS; Numerical models; Oceans; PREDICTION SYSTEM; Predictive models; residual correction; significant wave heights; TIME-SERIES; Transformer; Transformers; Wind forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"26ZCR3KC","journalArticle","2024","Fiaz, A; Raza, B; Faheem, M; Raza, A","A deep fusion-based vision transformer for breast cancer classification","HEALTHCARE TECHNOLOGY LETTERS","","2053-3713","10.1049/htl2.12093","","Breast cancer is one of the most common causes of death in women in the modern world. Cancerous tissue detection in histopathological images relies on complex features related to tissue structure and staining properties. Convolutional neural network (CNN) models like ResNet50, Inception-V1, and VGG-16, while useful in many applications, cannot capture the patterns of cell layers and staining properties. Most previous approaches, such as stain normalization and instance-based vision transformers, either miss important features or do not process the whole image effectively. Therefore, a deep fusion-based vision Transformer model (DFViT) that combines CNNs and transformers for better feature extraction is proposed. DFViT captures local and global patterns more effectively by fusing RGB and stain-normalized images. Trained and tested on several datasets, such as BreakHis, breast cancer histology (BACH), and UCSC cancer genomics (UC), the results demonstrate outstanding accuracy, F1 score, precision, and recall, setting a new milestone in histopathological image analysis for diagnosing breast cancer.","2024-10-23","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","","","","","","","","","","","English","","","","WOS:001339774200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","artificial intelligence; breast cancer; classification; deep learning; histopathology images; machine learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q4SEHFL5","journalArticle","2023","Liu, YX; Pan, SR; Wang, YG; Xiong, F; Wang, L; Chen, QF; Lee, VCS","Anomaly Detection in Dynamic Graphs via Transformer","IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING","","1041-4347","10.1109/TKDE.2021.3124061","","Detecting anomalies for dynamic graphs has drawn increasing attention due to their wide applications in social networks, e-commerce, and cybersecurity. Recent deep learning-based approaches have shown promising results over shallow methods. However, they fail to address two core challenges of anomaly detection in dynamic graphs: the lack of informative encoding for unattributed nodes and the difficulty of learning discriminate knowledge from coupled spatial-temporal dynamic graphs. To overcome these challenges, in this paper, we present a novel <bold>T</bold>ransformer-based <bold>A</bold>nomaly <bold>D</bold>etection framework for <bold>DY</bold>namic graphs (<bold>TADDY</bold>). Our framework constructs a comprehensive node encoding strategy to better represent each node's structural and temporal roles in an evolving graphs stream. Meanwhile, TADDY captures informative representation from dynamic graphs with coupled spatial-temporal patterns via a dynamic graph transformer model. The extensive experimental results demonstrate that our proposed TADDY framework outperforms the state-of-the-art methods by a large margin on six real-world datasets.","2023-12-01","2025-02-26 20:39:17","2025-02-26 20:39:17","","12081-12094","","12","35","","","","","","","","","","English","","","","WOS:001105152100052","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;129<br/>Total Times Cited:&nbsp;&nbsp;147<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Anomaly detection; dynamic graphs; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"75P4YS2G","journalArticle","2023","Varghese, A; Kamal, S; Kurian, J","Transformer-based temporal sequence learners for arrhythmia classification","MEDICAL & BIOLOGICAL ENGINEERING & COMPUTING","","0140-0118","10.1007/s11517-023-02858-3","","An electrocardiogram (ECG) plays a crucial role in identifying and classifying cardiac arrhythmia. Traditional methods employ handcrafted features, and more recently, deep learning methods use convolution and recursive structures to classify heart signals. Considering the time sequence nature of the ECG signal, a transformer-based model with its high parallelism is proposed to classify ECG arrhythmia. The DistilBERT transformer model, pre-trained for natural language processing tasks, is used in the proposed work. The signals are denoised and then segmented around the R peak and oversampled to get a balanced dataset. The input embedding step is skipped, and only positional encoding is done. The final probabilities are obtained by adding a classification head to the transformer encoder output. The experiments on the MIT-BIH dataset show that the suggested model is excellent in classifying various arrhythmias. The model achieved 99.92% accuracy, 0.99 precision, sensitivity, and F1 score on the augmented dataset with a ROC-AUC score of 0.999.","2023-08","2025-02-26 20:39:17","2025-02-26 20:39:17","","1993-2000","","8","61","","","","","","","","","","English","","","","WOS:001007629300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","Attention; ECG; HEARTBEAT CLASSIFICATION; Time-series; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DDBGE4UY","journalArticle","2023","Zhang, ZN; Chen, Y; He, BS; Zhang, ZJ","NIOT: A Novel Inference Optimization of Transformers on Modern CPUs","IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS","","1045-9219","10.1109/TPDS.2023.3269530","","In the machine learning era, model inference efficiency is one of the most important issues for machine learning systems. It is a major challenge to find the optimal configuration in a huge search space as the combinations of kernel fusion, memory tiling, and thread allocation strategies result in highly variable and unpredictable inference performance. The problem is particularly pronounced in models with large parameter matrices such as Transformers. In this article, we aim to develop a general and powerful framework for inference optimization, called NIOT, to achieve desirable efficiency for the prevailing Transformer-like models on CPUs. To take full advantage of modern CPU features such as SIMD and cache hierarchy, NIOT employs various methods to provide promising strategies tailored to the target Transformer model. Our C++ implementation of NIOT shows significant performance improvements over popular well-optimized model-serving runtimes such as PyTorch and ONNXRuntime.","2023-06","2025-02-26 20:39:17","2025-02-26 20:39:17","","1982-1995","","6","34","","","","","","","","","","English","","","","WOS:000992499400022","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Acceleration; Bit error rate; Computational modeling; CPU; Instruction sets; Layout; MATRIX-MATRIX MULTIPLICATION; neural network; Optimization; Resource management; transformers; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MY692VXQ","journalArticle","2022","Larsson, I; Kinn, K","Stability and Change in the C-Domain in American Swedish","LANGUAGES","","2226-471X","10.3390/languages7040256","","This article introduces American Swedish (AmSw) into the discussion of the C-domain in heritage Scandinavian. The study is based on spontaneous speech data from the Swedish part of the Corpus of American Nordic Speech (CANS), compared to a baseline of homeland Swedish dialect speakers. We show that the C-domain in AmSw is primarily characterized by stability; this is evidenced by a relatively robust V2 syntax and left dislocation patterns that resemble the homeland baseline. However, we also show that AmSw diverges in some respects: there are some V2 violations and a stronger preference for SV clauses (subject-initial main clauses) at the expense of XVS clauses (non-subject-initial main clauses). These results are similar to previous findings from American Norwegian. We argue that the diverging patterns exhibited by AmSw speakers are not indicative of any fundamental change in their Swedish grammar. The occasional V2 violations are attributed to parallel activation of English and Swedish, and speakers sometimes failing to inhibit English, which is their dominant language. The increase of SV clauses is analyzed as a preference for the canonical word order of the dominant language, but within the limits of what the heritage grammar permits. The patterns in AmSw can be described as cases of attrition and cross-linguistic influence; however, we argue for a nuanced use of these terms.","2022-12","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","4","7","","","","","","","","","","English","","","","WOS:000902584600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;79</p>","","","ACQUISITION; attrition; C-domain; cross-linguistic influence; DECLARATIVES; heritage languages; Swedish; V2; V3; WORD-ORDER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PCIDCL9N","journalArticle","2022","Rao, LA; Roberts, AC; Schafer, R; Rademaker, A; Blaze, E; Esparza, M; Salley, E; Coventry, C; Weintraub, S; Mesulam, MM; Rogalski, E","The Reliability of Telepractice Administration of the Western Aphasia Battery-Revised in Persons With Primary Progressive Aphasia","AMERICAN JOURNAL OF SPEECH-LANGUAGE PATHOLOGY","","1058-0360","10.1044/2021_AJSLP-21-00150","","Purpose: The use of telepractice in the field of communication disorders offers an opportunity to provide care for those with primary progressive aphasia (PPA). The Western Aphasia Battery-Revised (WAB-R) is used for differential diagnosis, to assess severity of aphasia, and to identify a language profile of strengths and challenges. Telehealth administration of the WAB-R is supported for those with chronic aphasia due to stroke but has not yet been systematically explored in neurodegenerative dementia syndromes. To fill this gap, in-person and telehealth performance on the WAB-R from participants with mild to moderate PPA was compared. Method: Nineteen participants with mild to moderate PPA were administered the WAB-R in person and over videoconferencing. Videoconferencing administration included modifications to the testing protocol to ensure smooth completion of the assessment. Subtest and Aphasia Quotient (WAB-AQ) summary scores were compared using concordance coefficients to measure the relationship between the administration modes. Results: In-person and telehealth scores showed strong concordance for the WAB-AQ, Auditory Verbal Comprehension subtest, and Naming & Word Finding subtest. The Spontaneous Speech test summary score had slightly lower concordance, indicating the need for caution when comparing these scores across administration modes. Conclusion: These findings support extending the use of telehealth administration of the WAB-R via videoconferencing to those with mild to moderate PPA given appropriate modifications to testing protocol.","2022-03","2025-02-26 20:39:17","2025-02-26 20:39:17","","881-895","","2","31","","","","","","","","","","English","","","","WOS:000767033300017","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;15<br/>Total Times Cited:&nbsp;&nbsp;16<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","ADULTS; CARE; CLASSIFICATION; IN-PERSON; INDIVIDUALS; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9FWHKANL","journalArticle","2025","Mareková, L; Benus, S","Speech Fluency Production and Perception in L1 (Slovak) and L2 (English) Read Speech","LANGUAGE AND SPEECH","","0023-8309","10.1177/00238309241230899","","Research on fluency in native (L1) and non-native (L2) speech production and perception helps us understand how individual L1 speaking style might affect perceived L2 fluency and how this relationship might be reflected in L1 versus L2 oral assessment. While the relationship between production and perception of fluency in spontaneous speech has been studied, the information provided by reading has been overlooked. We argue that reading provides a direct and controlled way to assess language proficiency that might complement information gained from spontaneous speaking. This work analyzes the relationship between speech fluency production and perception in passages of L1 (Slovak) and L2 (English) read by 57 undergraduate Slovak students of English and rated for fluency by 15 English teachers who are Slovak natives. We compare acoustic production measures between L1 and L2 and analyze how their effect on perceived fluency differs for the two languages. Our main finding is that the articulation rate, the overall number of pauses, and the number of between-clause and mid-clause pauses predict ratings differently in L1 Slovak versus L2 English. The speech rate and durations of pauses predict ratings similarly in both languages. The contribution of our results to understanding fluency aspects of spontaneous and read speech, the relationship between L1 and L2, the relationship between production and perception, and to the teaching of L2 English are discussed.","2025-03","2025-02-26 20:39:17","2025-02-26 20:39:17","","36-62","","1","68","","","","","","","","","","English","","","","WOS:001179473800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","L1 versus L2 fluency; PAUSES; Speech fluency; speech production versus speech perception","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PUKV4GE3","journalArticle","2023","Song, JU; Kim, M; Park, J","Acoustic correlates of perceived personality from Korean utterances in a formal communicative setting","PLOS ONE","","1932-6203","10.1371/journal.pone.0293222","","The aim of the present study was to find acoustic correlates of perceived personality from the speech produced in a formal communicative setting-that of Korean customer service employees in particular. This work extended previous research on voice personality impressions to a different sociocultural and linguistic context in which speakers are expected to speak politely in a formal register. To use naturally produced speech rather than read speech, we devised a new method that successfully elicited spontaneous speech from speakers who were role-playing as customer service employees, while controlling for the words and sentence structures they used. We then examined a wide range of acoustic properties in the utterances, including voice quality and global acoustic and segmental properties using Principal Component Analysis. Subjects of the personality rating task listened to the utterances and rated perceived personality in terms of the Big-Five personality traits. While replicating some previous findings, we discovered several acoustic variables that exclusively accounted for the personality judgments of female speakers; a more modal voice quality increased perceived conscientiousness and neuroticism, and less dispersed formants reflecting a larger body size increased the perceived levels of extraversion and openness. These biases in personality perception likely reflect gender and occupation-related stereotypes that exist in South Korea. Our findings can also serve as a basis for developing and evaluating synthetic speech for Voice Assistant applications in future studies.","2023-10-31","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","10","18","","","","","","","","","","English","","","","WOS:001099905400027","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","ENGLISH; F0; FACES; GENDER; INFERENCE; MANIPULATIONS; PITCH; POLITENESS; SPEECH RATE; VOICE QUALITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H8M4ZIJP","journalArticle","2024","Vu, MT; Hiraga, M; Miura, N; Masuda, A","Failure Mode Classification for Rolling Element Bearings Using Time-Domain Transformer-Based Encoder","SENSORS","","1424-8220","10.3390/s24123953","","In this paper, we propose a Transformer-based encoder architecture integrated with an unsupervised denoising method to learn meaningful and sparse representations of vibration signals without the need for data transformation or pre-trained data. Existing Transformer models often require transformed data or extensive computational resources, limiting their practical adoption. We propose a simple yet competitive modification of the Transformer model, integrating a trainable noise reduction method specifically tailored for failure mode classification using vibration data directly in the time domain without converting them into other domains or images. Furthermore, we present the key architectural components and algorithms underlying our model, emphasizing interpretability and trustworthiness. Our model is trained and validated using two benchmark datasets: the IMS dataset (four failure modes) and the CWRU dataset (four and ten failure modes). Notably, our model performs competitively, especially when using an unbalanced test set and a lightweight architecture.","2024-06","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","12","24","","","","","","","","","","English","","","","WOS:001256318300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","failure detection; failure mode classification; FAULT-DIAGNOSIS; signal denoising; smart diagnostics; vibrations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TWW4XKQG","journalArticle","2024","Zhu, ZL; Zhang, SY; Qiu, LNX; Wang, H; Luo, GL","Axis-Based Transformer UNet for RGB Remote Sensing Image Denoising","IEEE SIGNAL PROCESSING LETTERS","","1070-9908","10.1109/LSP.2024.3418717","","Remote sensing images are different from ordinary images in that they have higher resolution, contain information of a larger area, and are characterized by strip-like objects in many scenes. The traditional Transformer model based on the moving window to calculate the attention is difficult to obtain the overall features when extracting the features of strip-shaped objects and is easily interfered by the surrounding features. To address this problem, this paper innovatively designs an axial Transformer module and constructs a U-shaped hierarchical encoder-decoder structure network (ATUNet). The network improves its ability to extract global features and resist interference from irrelevant features through the axial attention mechanism. We synthesize multiple test sets with noise levels for experiments using three datasets, NWPU-RESISC45, UCMerced_LandUse, and OPTIMAL-31. The experiments show that our network has good resistance to high noise and generalization ability.","2024","2025-02-26 20:39:17","2025-02-26 20:39:17","","2515-2519","","","31","","","","","","","","","","English","","","","WOS:001320552200006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","Axis-based transformer module; Convolution; Feature extraction; image denoising; Image denoising; Noise reduction; Remote sensing; remote sensing imagery; Task analysis; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5QYF43QH","journalArticle","2024","Peng, WL; Zhou, T; Chen, YY","Enhancing mass spectrometry data analysis: A novel framework for calibration, outlier detection, and classification","PATTERN RECOGNITION LETTERS","","0167-8655","10.1016/j.patrec.2024.03.026","","Mass spectrometry (MS) is a powerful analytical technique in metabolomics, enabling the identification and quantification of metabolites. However, analyzing MS data poses challenges such as batch effects, outliers, and high-dimensional data. In this paper, we propose a comprehensive framework for MS data analysis. The framework integrates data calibration, outlier detection, and automatic classification modules. Data calibration is performed using a deep autoencoder to remove batch effects. Outlier detection combines multiple algorithms through ensemble learning to identify and remove outliers. Automatic classification utilizes a transformer model to handle high-dimensional data and capture global feature relationships. Experimental results on myocardial infarction (MI) and coronary heart disease (CHD) datasets demonstrate the effectiveness of the framework. It outperforms traditional classification models and achieves higher accuracy. The proposed framework provides a robust solution for MS data analysis, facilitating more accurate classification and enabling reliable biological insights in metabolomics research.","2024-06","2025-02-26 20:39:17","2025-02-26 20:39:17","","1-8","","","182","","","","","","","","","","English","","","","WOS:001224452600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Data analysis framework; Data calibration; Ensemble learning; Mass spectrometry; METABOLOMICS; Outlier detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AJDAPGTU","journalArticle","2023","Angelis, GF; Timplalexis, C; Salamanis, AI; Krinidis, S; Ioannidis, D; Kehagias, D; Tzovaras, D","Energformer: A New Transformer Model for Energy Disaggregation","IEEE TRANSACTIONS ON CONSUMER ELECTRONICS","","0098-3063","10.1109/TCE.2023.3237862","","In recent years, a lot of progress has been reported in the field of energy disaggregation, also referred to as Non-Intrusive Load Monitoring (NILM). Despite the fact that there are many studies focusing on the residential sector, there is considerably less research interest for the industrial sector. In this paper, we present a deep neural network based on Transformers, targeted towards capturing complex patterns in long sequences of data. The proposed transformer architecture employs 1D spatial convolutions in self-attention, and modifications inside the attention computations manage to reduce computational complexity without any loss in predictive accuracy. In order to evaluate the performance of the proposed deep learning architecture, a set of experiments has been conducted using a publicly available dataset. The experimental results indicate that the proposed model achieves better disaggregation accuracy compared to other state-of-the-art NILM models.","2023-08","2025-02-26 20:39:17","2025-02-26 20:39:17","","308-320","","3","69","","","","","","","","","","English","","","","WOS:001049985800008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;21<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;88</p>","","","BONFERRONI; CLASSIFICATION; deep learning; neural networks; NEURAL-NETWORK; Non-intrusive load monitoring; NONINTRUSIVE LOAD DISAGGREGATION; POWER; SELECTION; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EIQE3TWC","journalArticle","2023","Pérez-Toro, PA; Vásquez-Correa, JC; Bocklet, T; Nöth, E; Orozco-Arroyave, JR","User State Modeling Based on the Arousal-Valence Plane: Applications in Customer Satisfaction and Health-Care","IEEE TRANSACTIONS ON AFFECTIVE COMPUTING","","1949-3045","10.1109/TAFFC.2021.3112543","","The acoustic analysis helps to discriminate emotions according to non-verbal information, while linguistics aims to capture verbal information from written sources. Acoustic and linguistic analyses can be addressed for different applications, where information related to emotions, mood, or affect are involved. The Arousal-Valence plane is commonly used to model emotional states in a multidimensional space. This study proposes a methodology focused on modeling the user's state based on the Arousal-Valence plane in different scenarios. Acoustic and linguistic information are used as input to feed different deep learning architectures mainly based on convolutional and recurrent neural networks, which are trained to model the Arousal-Valence plane. The proposed approach is used for the evaluation of customer satisfaction in call-centers and for health-care applications in the assessment of depression in Parkinson's disease and the discrimination of Alzheimer's disease. F-scores of up to 0.89 are obtained for customer satisfaction, of up to 0.82 for depression in Parkinson's patients, and of up to 0.80 for Alzheimer's patients. The proposed approach confirms that there is information embedded in the Arousal-Valence plane that can be used for different purposes.","2023-04","2025-02-26 20:39:17","2025-02-26 20:39:17","","1533-1546","","2","14","","","","","","","","","","English","","","","WOS:001000299100050","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","acoustic; Acoustics; alzheimer's disease; ALZHEIMERS-DISEASE; Arousal-valence plane; customer satisfaction; Customer satisfaction; DEEP NEURAL-NETWORKS; DEMENTIA; depression; Depression; DISCOURSE; Diseases; EMOTION RECOGNITION; Feature extraction; FUSION; IMPAIRMENT; linguistic; Linguistics; Mood; parkinson's disease; PARKINSONS-DISEASE; SPONTANEOUS SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E5EFF3CD","journalArticle","2023","Benway, NR; Preston, JL; Hitchcock, E; Rose, Y; Salekin, A; Liang, W; McAllister, T","Reproducible Speech Research With the Artificial Intelligence-Ready PERCEPT Corpora","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2023_JSLHR-22-00343","","Background: Publicly available speech corpora facilitate reproducible research by providing open-access data for participants who have consented/assented to data sharing among different research teams. Such corpora can also support clinical education, including perceptual training and training in the use of speech analysis tools.Purpose: In this research note, we introduce the PERCEPT (Perceptual Error Rating for the Clinical Evaluation of Phonetic Targets) corpora, PERCEPT-R (Rhotics) and PERCEPT-GFTA (Goldman-Fristoe Test of Articulation), which together contain over 36 hr of speech audio (> 125,000 syllable, word, and phrase utterances) from children, adolescents, and young adults aged 6- 24 years with speech sound disorder (primarily residual speech sound disor-ders impacting //) and age-matched peers. We highlight PhonBank as the repository for the corpora and demonstrate use of the associated speech analysis software, Phon, to query PERCEPT-R. A worked example of research with PERCEPT-R, suitable for clinical education and research training, is included as an appendix. Support for end users and information/descriptive statistics for future releases of the PERCEPT corpora can be found in a dedi-cated Slack channel. Finally, we discuss the potential for PERCEPT corpora to support the training of artificial intelligence clinical speech technology appropriate for use with children with speech sound disorders, the develop-ment of which has historically been constrained by the limited representation of either children or individuals with speech impairments in publicly available training corpora.Conclusions: We demonstrate the use of PERCEPT corpora, PhonBank, and Phon for clinical training and research questions appropriate to child citation speech. Increased use of these tools has the potential to enhance reproducibil-ity in the study of speech development and disorders.","2023-06","2025-02-26 20:39:17","2025-02-26 20:39:17","","1986-2009","","6","66","","","","","","","","","","English","","","","WOS:001040991300009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","RECOGNITION; ULTRASOUND","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XXSR8SZQ","journalArticle","2025","Liu, H; Liu, Y; Yao, SL; Yu, TS; Gao, K; Hao, PC; He, SQ; Chen, J; Wang, X","ISTFormer: lightweight transformer for enhanced super-resolution of coal rock images via iterative feature extraction","VISUAL COMPUTER","","0178-2789","10.1007/s00371-024-03793-6","","Coal rock image acquisition often suffers from poor quality due to challenges such as inadequate lighting, noise, and sensor limitations. To address these issues, we introduce ISTFormer, a lightweight transformer-based approach for coal rock image super-resolution. ISTFormer integrates a global permuted self-attention block with a local convolutional block, leveraging iterative up-and-down sampling to extract comprehensive features from low-resolution images. Experiments on benchmark datasets and a custom coal rock dataset, CD-188, demonstrate ISTFormer's superiority over existing lightweight super-resolution methods, achieving state-of-the-art results with improved PSNR and SSIM scores. By open-sourcing our algorithm's code and datasets, we aim to foster further developments in this field. This work presents a significant step toward enhancing coal rock image quality for improved identification and classification accuracy. Our source code is available at: https://github.com/haoliuliuhao/ISTFormer.","2025-02-03","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","","","","","","","","","","","English","","","","WOS:001411649900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","Attention; Coal rock image; Iterative up-and-down sampling; Lightweight; Super-resolution; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"78YT5FDV","journalArticle","2024","Luo, YD; Yu, SM","H3D-Transformer: A Heterogeneous 3D (H3D) Computing Platform for Transformer Model Acceleration on Edge Devices","ACM TRANSACTIONS ON DESIGN AUTOMATION OF ELECTRONIC SYSTEMS","","1084-4309","10.1145/3649219","","Prior hardware accelerator designs primarily focused on single-chip solutions for 10 MB-class computer vi-sion models. The GB-class transformer models for natural language processing (NLP) impose challenges on existing accelerator design due to the massive number of parameters and the diverse matrix multiplication (MatMul) workloads involved. This work proposes a heterogeneous 3D-based accelerator design for trans-former models, which adopts an interposer substrate with multiple 3D memory/logic hybrid cubes optimized for accelerating different MatMul workloads. An approximate computing scheme is proposed to take advan-tage of heterogeneous computing paradigms of mixed-signal compute-in-memory (CIM) and digital tensor processing units (TPU). From the system-level evaluation results, 10 TOPS/W energy efficiency is achieved for the BERT and GPT2 model, which is about 2.6 x similar to 3.1 x higher than the baseline with 7 nm TPU and stacked FeFET memory.","2024-05","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","3","29","","","","","","","","","","English","","","","WOS:001227235300007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Compute-in-memory; DNN accelerator; heterogeneous 3D integration; MEMORY SRAM MACRO; multi-head self-attention; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SJUPSZ3E","journalArticle","2024","Balaji, PA; Venkatesh, SN; Sugumaran","Fault Diagnosis of Suspension System Based on Spectrogram Image and Vision Transformer","EKSPLOATACJA I NIEZAWODNOSC-MAINTENANCE AND RELIABILITY","","1507-2711","10.17531/ein/174860","","The suspension system in an automobile is essential for comfort and control. Implementing a monitoring system is crucial to ensure proper function, prevent accidents, maintain performance, and reduce both downtime and costs. Traditionally, diagnosing faults in suspension systems has relied on specialized setups and vibration analysis. The conventional approach typically involves either wavelet analysis or a machine learning approach. While these methods are effective, they often demand specialized expertise and time consumable. Alternatively, using deep learning for suspension system fault diagnosis enables faster and more precise real-time fault detection. This study explores the use of vision transformers as an innovative approach to fault diagnosis in suspension systems, utilizing spectrogram images. The process involves extracting spectrogram images from vibration signals, which serve as inputs for the vision transformer model. The test results demonstrate that the proposed fault diagnosis system achieves an impressive accuracy rate of 98.12% in identifying faults.","2024","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","1","26","","","","","","","","","","English","","","","WOS:001198399700020","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","condition monitoring; fault diagnosis; image generation; McPherson suspension system; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RKP5QUAX","journalArticle","2024","Song, YN; An, XW; Zhang, WK; Sun, KY; Zhang, AQ","Catalyzing Financial Risk Control Excellence: A Novel Fusion Model - PSO-Boost-Trans","JOURNAL OF ORGANIZATIONAL AND END USER COMPUTING","","1546-2234","10.4018/JOEUC.353303","","In today's financial landscape, characterized by the rapid growth of fintech and the extensive application of big data, the volume and complexity of financial transaction data are increasing. This has heightened the need for intelligent risk control models, posing significant challenges to traditional methods. In this case, research on intelligent risk control models based on deep learning has emerged as a new solution. This paper proposes a PSO-Xgboost-Transformer fusion deep learning model designed to enhance the performance of traditional risk control approaches in managing financial risks. The model integrates the Particle Swarm Optimization (PSO) algorithm, the Xgboost model, and the Transformer model to leverage their respective strengths. Initially, the PSO algorithm is employed to select and optimize features, thereby enhancing the model's robustness and generalization capabilities. Subsequently, the Xgboost model uses these optimized features for prediction and evaluation, generating preliminary risk prediction results.","2024","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","1","36","","","","","","","","","","English","","","","WOS:001317396800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","ANOMALY DETECTION; CREDIT; Deep Learning; Financial Risk Control; INTRUSION; Particle Swarm Optimization; Transformer; Xgboost; XGBOOST","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CFAWBX5X","journalArticle","2021","Kim, JH; Chung, CW","Development of high-efficiency capacitive discharge using magnetic resonance wireless power transfer systems","PLASMA SOURCES SCIENCE & TECHNOLOGY","","0963-0252","10.1088/1361-6595/abe810","","We developed a high-efficiency source in a capacitively coupled plasma using magnetic resonance wireless power transfer (MRWPT) systems, which has the advantage that the matcher efficiency is very high at low gas pressures (2 mTorr to 20 mTorr) and high density plasmas (about 1 x 10(10) cm(-3) to 5 x 10(10) cm(-3)). At the non-resonance conditions, most of the RF power is dissipated by the transmitter coil and the plasma is not discharged. However, at the resonance condition, the plasma is discharged as the current flowing through the transmitter coil rapidly decreases, and the matcher efficiency is higher than 90% in all experiments. For analysis, the transformer model with MRWPT systems is developed. The experimental result is consistent with the model, and the results are discussed with the relevant physical mechanisms.","2021-05","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","5","30","","","","","","","","","","English","","","","WOS:000659669900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","capacitively coupled plasma; ENERGY; FUNCTIONAL SEPARATION; ion density distribution; magnetic resonance wireless power transfer; matcher efficiency; plasma diagnostics; RF","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"63YZ95A4","journalArticle","2024","Matiasovitsová, K; Cechová, P; Sláma, J; Homolková, K; Smolík, F","Mean Length of Utterance in Czech Toddlers: Validity Estimates and Comparison of Words, Morphemes, and Syllables","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2023_JSLHR-23-00251","","Purpose: We examined the properties of mean length of utterance (MLU) in Czech, a morphologically complex Slavic language. We compared the scores of MLU calculated in different units and based on different sample lengths and assessed its validity against another transcript and test -based measures. Method: One hundred nine children were recorded during free -play at 2;6 and 3;11 (years;months). We compared MLU in syllables, morphemes, and words (MLU w ) in transcripts of different lengths (50, 75, 100, and all available utterances). For evaluating the validity of MLU, we also calculated Index of Productive Syntax (IPSyn) and number of different words (NDW) and used results of receptive vocabulary and grammar comprehension tests. Results: The different MLU measures based on different sample lengths correlated closely with MLU in transcripts of all utterances (all r s > .87). We found mostly strong correlations between MLU, IPSyn, and NDW at both time points and weak or moderate correlations between MLU and grammar and vocabulary. Regression models showed the significant unique effect of MLU w at 2;6 for MLU w (beta = .29) and grammar (beta = .33) at 3;11 and vocabulary (beta = .27) at 3;7. Conclusion: MLU w based on all utterances was confirmed as a valid measure of early language skills in Czech, as it is stable in time and shows concurrent and predictive relations with other transcript -based and test -based measures.","2024-03","2025-02-26 20:39:17","2025-02-26 20:39:17","","837-852","","3","67","","","","","","","","","","English","","","","WOS:001218428700006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;68</p>","","","ACQUISITION; CHILDREN; COMPLEXITY; GRAMMAR; IPSYN; LANGUAGE; MLU; SAMPLE-SIZE; SPONTANEOUS SPEECH; VOCABULARY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"73N6WTHR","journalArticle","2025","Blanchette, F; Yacomelo, JAD; Eads, A; Lai, LF; Harman, A; Hunt, L","The Pennsylvania English Final Rise-Fall: Intonation, Pragmatics, and Regional Variation","JOURNAL OF ENGLISH LINGUISTICS","","0075-4242","10.1177/00754242241311619","","In contrast to the common final rising pattern of Mainstream English yes/no questions, these questions may be produced with a final rising then falling intonation in parts of Central and Western Pennsylvania (PA). Researchers have suggested that this pattern is pragmatically conditioned, used either when a particular response is expected, or when the speaker wishes to communicate the answer is not-at-issue. While previous work on this regional final rise-fall pattern has been limited to observations of spontaneous speech, this paper presents the results of a pair of production and perception experiments aimed at obtaining a more detailed characterization of its acoustic correlates and testing hypotheses regarding its pragmatic conditioning. The results replicate and extend previous findings, illustrating highly variable fluctuations in fundamental frequency across yes/no question tokens that share a final rise-fall pattern, and a tendency toward using this pattern to imply that the speaker already has some idea of what the answer to the question will be. Comparison of the perceptions of speakers from Central PA with speakers from outside the Midland Dialect region suggests that pragmatic knowledge of this intonational variant may be region-specific. The results are discussed in the context of recent work in which intonation is shown to be a marker of social group or region, providing an example where regional intonational variation appears to be shaped at least in part by pragmatic meaning.","2025-02-17","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","","","","","","","","","","","English","","","","WOS:001423732500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Central Pennsylvania English; intonation; polar questions; pragmatic context; regional variation; RISING PITCH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UFPWL3ET","journalArticle","2021","Lawson, E; Stuart-Smith, J","Lenition and fortition of /r/ in utterance-final position, an ultrasound tongue imaging study of lingual gesture timing in spontaneous speech","JOURNAL OF PHONETICS","","0095-4470","10.1016/j.wocn.2021.101053","","The most fundamental division in English dialects is the rhotic/non-rhotic division. The mechanisms of historical /r/-loss sound change are not well understood, but studying a contemporary /r/-loss sound change in a rhotic variety of English can provide new insights. We know that /r/ weakening in contemporary Scottish English is a gesture-timing based phenomenon and that it is socially indexical, but we have no phonetic explanation for the predominance of weak /r/ variants in utterance-final position. Using a socially-stratified conversational ultrasound tongue imaging speech corpus, this study investigates the effects of boundary context, along with other linguistic and social factors such as syllable stress, following-consonant place and social class, on lingual gesture timing in / r/ and strength of rhoticity. Mixed-effects modelling identified that utterance-final context conditions greater anterior lingual gesture delay in /r/ and weaker-sounding /r/s, but only in working-class speech. Middle-class speech shows no anterior lingual gesture delay for /r/ in utterance-final position and /r/ is audibly strengthened in this position. It is unclear whether this divergence is due to variation in underlying tongue shape for /r/ in these social-class communities, or whether utterance-final position provides a key location for the performance of social class using salient variants of /r/. CO 2021 Elsevier Ltd. All rights reserved.","2021-05","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","86","","","","","","","","","","English","","","","WOS:000651800000007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Articulatory phonetics; Fortition; Lenition; Rhoticity; Sociophonetics; Sound change","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7GK38NTP","journalArticle","2024","Fiaz, A; Raza, B; Faheem, M; Raza, A","A deep fusion-based vision transformer for breast cancer classification","HEALTHCARE TECHNOLOGY LETTERS","","2053-3713","10.1049/htl2.12093","","Breast cancer is one of the most common causes of death in women in the modern world. Cancerous tissue detection in histopathological images relies on complex features related to tissue structure and staining properties. Convolutional neural network (CNN) models like ResNet50, Inception-V1, and VGG-16, while useful in many applications, cannot capture the patterns of cell layers and staining properties. Most previous approaches, such as stain normalization and instance-based vision transformers, either miss important features or do not process the whole image effectively. Therefore, a deep fusion-based vision Transformer model (DFViT) that combines CNNs and transformers for better feature extraction is proposed. DFViT captures local and global patterns more effectively by fusing RGB and stain-normalized images. Trained and tested on several datasets, such as BreakHis, breast cancer histology (BACH), and UCSC cancer genomics (UC), the results demonstrate outstanding accuracy, F1 score, precision, and recall, setting a new milestone in histopathological image analysis for diagnosing breast cancer.","2024-12","2025-02-26 20:39:17","2025-02-26 20:39:17","","471-484","","6","11","","","","","","","","","","English","","","","WOS:001405599300021","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","artificial intelligence; breast cancer; classification; deep learning; histopathology images; machine learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KJJ4IWTT","journalArticle","2023","Dash, S; Sahoo, NC","Attention-Based Multitask Probabilistic Network for Nonintrusive Appliance Load Monitoring","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2023.3273663","","Monitoring individual appliances' operating state and energy consumption in a building enables significant energy-saving opportunities. These days, smart meters perform this task nonintrusively using sophisticated signal processing, machine-learning, and/or deep-learning (DL) approaches. To this end, this article proposes a novel multitask DL model that uses readily available low-frequency energy data from the smart meter for simultaneous appliance state detection (SD) and energy disaggregation (ED). The model creatively adopts and customizes the famous transformer model from the field of language modeling for the above task. Furthermore, the model output is produced as a mixture of probability density functions to handle uncertainties. The model performance is evaluated using the publicly available REFIT and UKDALE datasets. The test results indicate the proposed model's superiority, generalizability, and transferability compared to other state-of-the-art models.","2023","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","72","","","","","","","","","","English","","","","WOS:000994621200019","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","ARCHITECTURE; Attention model; Convolutional neural networks; Energy consumption; energy disaggregation (ED); Feature extraction; Hidden Markov models; mixture density network (MDN); Multitasking; NILM; nonintrusive load monitoring (NILM); Task analysis; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QFKWUFZX","journalArticle","2022","Jurkovic, M; Zarko, D","Calculation of current distribution in parallel-connected transformer winding sections in the case of asymmetric magnetic field during short-circuit test","ELECTRIC POWER SYSTEMS RESEARCH","","0378-7796","10.1016/j.epsr.2022.108141","","In this paper, an algorithm for calculating the asymmetric current distribution in parallel-connected high-voltage winding sections of a transformer during a short-circuit test caused by an asymmetric magnetic field is described. This calculation is essential in multi-winding transformers, such as traction transformers and rectifier transformers, which have a high-voltage winding consisting of sections connected in parallel, where the number of sections is equal to the number of low-voltage windings and only one low-voltage winding is shorted during the short-circuit test. An optimization method, combined with a semi-analytical transformer model based on conformal mapping, is used to calculate the magnetic field and find a combination of currents in parallel-connected sections assuming equal induced voltages, i.e. flux linkages, in each section. The results of the calculation show good agreement with measurements carried out on the traction transformer for an electric multiple unit.","2022-09","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","210","","","","","","","","","","English","","","","WOS:000812797300003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Conformal mapping; Current distribution; Schwarz-Christoffel transformation; Short-circuit voltage","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H8TSUGZ9","journalArticle","2022","Li, YW; Lv, S; Liu, XH; Zhang, QY","Incorporating Transformers and Attention Networks for Stock Movement Prediction","COMPLEXITY","","1076-2787","10.1155/2022/7739087","","Predicting stock movements is a valuable research field that can help investors earn more profits. As with time-series data, the stock market is time-dependent and the value of historical information may decrease over time. Accurate prediction can be achieved by mining valuable information with words on social platforms and further integrating it with actual stock market conditions. However, many methods still cannot effectively dig deep into hidden information, integrate text and stock prices, and ignore the temporal dependence. Therefore, to solve the above problems, we propose a transformer-based attention network framework that uses historical text and stock prices to capture the temporal dependence of financial data. Among them, the transformer model and attention mechanism are used for feature extraction of financial data, which has fewer applications in the financial field, and effective analysis of key information to achieve an accurate prediction. A large number of experiments have proved the effectiveness of our proposed method. The actual simulation experiment verifies that our model has practical application value.","2022-02-27","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","2022","","","","","","","","","","English","","","","WOS:000773076800003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J8HWIST7","journalArticle","2024","Rana, R; Higgins, N; Haque, KN; Burke, K; Turner, K; Stedman, T","Feasibility of Mental Health Triage Call Priority Prediction Using Machine Learning","NURSING REPORTS","","2039-439X","10.3390/nursrep14040303","","Background: Optimum efficiency and responsiveness to callers of mental health helplines can only be achieved if call priority is accurately identified. Currently, call operators making a triage assessment rely heavily on their clinical judgment and experience. Due to the significant morbidity and mortality associated with mental illness, there is an urgent need to identify callers to helplines who have a high level of distress and need to be seen by a clinician who can offer interventions for treatment. This study delves into the potential of using machine learning (ML) to estimate call priority from the properties of the callers' voices rather than evaluating the spoken words. Method: Phone callers' speech is first isolated using existing APIs, then features or representations are extracted from the raw speech. These are then fed into a series of deep learning neural networks to classify priority level from the audio representation. Results: Development of a deep learning neural network architecture that instantly determines positive and negative levels in the input speech segments. A total of 459 call records from a mental health helpline were investigated. The final ML model achieved a balanced accuracy of 92% correct identification of both positive and negative instances of call priority. Conclusions: The priority level provides an estimate of voice quality in terms of positive or negative demeanor that can be simultaneously displayed using a web interface on a computer or smartphone.","2024-12","2025-02-26 20:39:17","2025-02-26 20:39:17","","4162-4172","","4","14","","","","","","","","","","English","","","","WOS:001384498700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","artificial intelligence; automated distress screen; deep learning; distress; mental health; spontaneous speech; triage; voice computing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AZZWW56E","journalArticle","2024","Ozturk, S; Özçaliskan, S","Gesture's Role in the Communication of Adults With Different Types of Aphasia","AMERICAN JOURNAL OF SPEECH-LANGUAGE PATHOLOGY","","1058-0360","10.1044/2024_AJSLP-23-00046","","Purpose: Adults with aphasia gesture more than adults without aphasia. However, less is known about the role of gesture in different discourse contexts for individuals with different types of aphasia. In this study, we asked whether patterns of speech and gesture production of individuals with aphasia vary by aphasia and discourse type and also differ from the speech and gestures produced by adults without aphasia. Method: We compared the amount, diversity, and complexity of speech and gesture production in adults with anomic or Broca's aphasia and adults with no aphasia ( n = 20/group) in their first- versus third-person narratives. Results: Adults with Broca's aphasia showed the lowest performance in their amount, diversity, and complexity of speech production, followed by adults with anomic aphasia and adults without aphasia. This pattern was reversed for gesture production. Speech and gesture production also varied by discourse context. Adults with either type of aphasia used a lower amount of and less diverse speech in third-person than in first-person narratives; this pattern was also reversed for gesture production. Conclusions: Overall, our results provide evidence for a compensatory role of gesture in aphasia communication. Adults with Broca's aphasia, who showed the greatest speech production difficulties, also relied most on gesture, and this pattern was particularly pronounced in the third-person narrative context.","2024-07","2025-02-26 20:39:17","2025-02-26 20:39:17","","1811-1830","","4","33","","","","","","","","","","English","","","","WOS:001273922300014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","DISCOURSE; DIVERSITY; FLUENT; ICONIC GESTURES; LEXICAL ACCESS; NORMAL LANGUAGE; PEOPLE; SPEAKING; SPONTANEOUS SPEECH; THINKING","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7VUY5Z2M","journalArticle","2024","Bolyanatz, M; Jiménez, A; DePue, IS","Acoustic Correlates of Subtypes of Irony in Chilean Spanish","LANGUAGES","","2226-471X","10.3390/languages9010022","","Utterances containing verbal irony display prosodic particularities that distinguish them from non-ironic speech. While some prosodic features of irony have been identified in Spanish, previous studies have not accounted for different subtypes, nor have they examined this phenomenon in Chilean Spanish despite the unique intonation patterns in this dialect. This study examined the acoustic and prosodic correlates of five subtypes of irony (jocularity, rhetorical questions, understatements, hyperbole, and sarcasm) spontaneously occurring in the casual speech of sociolinguistic interviews with fifteen Chilean women. We segmented 3907 syllable nuclei from 197 spontaneously occurring instances of irony and compared the syllables within the ironic utterances to those in the pre-ironic utterances, along seven acoustic and prosodic variables: pitch range, duration, F0, F1, F2, H1*-H2*, and HNR. The results showed that the speakers favored jocularity and did not produce sarcasm or understatements, and that jocularity, hyperbole, and rhetorical questions significantly differed from the baseline utterances along a variety of acoustic and prosodic measures. We argue that these cues contributed to marking the ironic utterances as salient, allowing these women to talk about difficult real-life events with a touch of humor. Our study provides additional evidence for the connection between prosody and pragmatics in Chilean Spanish and lays the groundwork for further examination of irony and prosody in this and other Spanish dialects.","2024-01","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","1","9","","","","","","","","","","English","","","","WOS:001151266400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;95</p>","","","conversational humor; HUMOR; HYPERBOLE; irony; LANGUAGE; METAPHOR; PERCEPTION; PRAGMATICS; PROSODY; prosody-pragmatics interface; SPEECH; spontaneous speech; TO-NOISE RATIO; voice quality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DVVQWPR2","journalArticle","2022","Xie, XH; Zhang, T; Bai, TJ; Chen, C; Ji, GJ; Tian, YH; Yang, JY; Wang, K","Resting-State Neural-Activity Alterations in Subacute Aphasia after Stroke","BRAIN SCIENCES","","2076-3425","10.3390/brainsci12050678","","Linguistic deficits are frequent symptoms among stroke survivors. The neural mechanism of post-stroke aphasia (PSA) was incompletely understood. Recently, resting-state functional magnetic resonance imaging (rs-fMRI) was widely used among several neuropsychological disorders. However, previous rs-fMRI studies of PSA were limited to very small sample size and the absence of reproducibility with different neuroimaging indexes. The present study performed comparisons with static and dynamic amplitude of low-frequency fluctuations (ALFF) and functional connectivity (FC) based on modest sample size (40 PSA and 37 healthy controls). Compared with controls, PSA showed significantly increased static ALFF predominantly in the bilateral supplementary motor area (SMA) and right hippocampus-parahippocampus (R HIP-ParaHip) and decreased static ALFF in right cerebellum. The increased dynamic ALFF in SMA and decreased dynamic ALFF in right cerebellum were also found in PSA. The static and dynamic ALFF in right cerebellum was positively correlated with spontaneous speech. The FC between the SMA and R HIP-ParaHip was significantly stronger in patients than controls and positively correlated with ALFF in bilateral SMA. In addition, the FC between the R HIP-ParaHip and the right temporal was also enhanced in patients and negatively correlated with repetition, naming, and comprehension score. These findings revealed consistently abnormal intrinsic neural activity in SMA and cerebellum, which may underlie linguistic deficits in PSA.","2022-05","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","5","12","","","","","","","","","","English","","","","WOS:000802448000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","ALFF; BRAIN ACTIVITY; CEREBELLUM; COMPREHENSION; dynamic; FC; FUNCTIONAL CONNECTIVITY; LANGUAGE REORGANIZATION; NETWORK CONNECTIVITY; NEURONAL-ACTIVITY; PRIMARY PROGRESSIVE APRAXIA; RECOVERY; SEVERITY; stroke; subacute aphasia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FIDINL8J","journalArticle","2022","Levy-Forsythe, Z; Hacohen, A","Finiteness marking in Russian-speaking children with Specific Language Impairment","FIRST LANGUAGE","","0142-7237","10.1177/01427237211058254","","Much crosslinguistic acquisition research explores finiteness marking in typical development and Specific Language Impairment (SLI). Research into Russian, however, has focused on typical acquisition, not SLI. This article presents a first attempt to investigate finiteness marking in monolingual Russian-speaking children with SLI. We test two competing hypotheses: the Extended Optional Infinitive (EOI) hypothesis and the morphological richness account. The former predicts a large proportion of non-finite forms in the speech of children with SLI crosslinguistically. Due to the rich morphological verbal system of Russian, the latter hypothesis predicts that finiteness marking in Russian SLI will be relatively unimpeded, except for 'near-miss' errors. To test these predictions, we analyzed picture-story narrative samples collected from 67 monolingual Russian-acquiring children aged 4;1 to 4;11. All samples are part of the BiSLI corpus created by Tribushinina and colleagues and publicly available through the CHILDES project. We found that, similar to both aged-matched typically developing (TD) controls (N = 24) and younger TD children (N = 23), children with SLI (N = 20) are essentially adultlike in terms of finiteness marking of verbal forms in the matrix clause. The handful of errors observed in the SLI sample involved substitutions in only one inflectional category. These findings provide support for the morphological richness hypothesis over the EOI model of Russian SLI.","2022-02","2025-02-26 20:39:17","2025-02-26 20:39:17","","124-143","","1","42","","","","","","","","","","English","","","","WOS:000727862600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;94</p>","","","ACQUISITION; AGREEMENT; ENGLISH; Extended Optional Infinitive; finiteness marking; GRAMMAR; INFINITIVE VERBS; MARKER; morphological richness; MORPHOLOGY DEFICITS; root infinitives; Russian; SLI; Specific Language Impairment; SPONTANEOUS SPEECH; TENSE; VERBAL INFLECTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JJPA26WF","journalArticle","2022","Abdel-Aty, H; Gould, IR","Large-Scale Distributed Training of Transformers for Chemical Fingerprinting","JOURNAL OF CHEMICAL INFORMATION AND MODELING","","1549-9596","10.1021/acs.jcim.2c00715","","Transformer models have become a popular choice for various machine learning tasks due to their often outstanding performance. Recently, transformers have been used in chemistry for classifying reactions, reaction prediction, physiochemical property prediction, and more. These models require huge amounts of data and localized compute to train effectively. In this work, we demonstrate that these models can successfully be trained for chemical problems in a distributed manner across many computers-a more common scenario for chemistry institutions. We introduce MFBERT: Molecular Fingerprints through Bidirectional Encoder Representations from Transformers. We use distributed computing to pre-train a transformer model on one of the largest aggregate datasets in chemical literature and achieve state-of-the-art scores on a virtual screening benchmark for molecular fingerprints. We then fine-tune our model on smaller, more specific datasets to generate more targeted fingerprints and assess their quality. We utilize a Sentence-Piece tokenization model, where the whole procedure from raw molecular representation to molecular fingerprints becomes data-driven, with no explicit tokenization rules.","2022-10-24","2025-02-26 20:39:17","2025-02-26 20:39:17","","4852-4862","","20","62","","","","","","","","","","English","","","","WOS:000870062700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;14<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","SMALL MOLECULES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G2EV3Z98","journalArticle","2021","Behzad, M; Li, XB; Zhao, GY","Disentangling 3D/4D Facial Affect Recognition With Faster Multi-View Transformer","IEEE SIGNAL PROCESSING LETTERS","","1070-9908","10.1109/LSP.2021.3111576","","In this paper, we propose MiT: a novel multi-view transformer model(1) for 3D/4D facial affect recognition. MiT incorporates patch and position embeddings from various patches of multi-views and uses them for learning various facial muscle movements to showcase an effective recognition performance. We also propose a multi-view loss function that is not only gradient-friendly, and hence speeds up the gradient computation during back-propagation, but it also leverages the correlation associated with the underlying facial patterns among multi-views. Additionally, we offer multi-view weights that are trainable and learnable, and help substantially in training. Finally, we equip our model with distributed performance for faster learning and computational convenience. With the help of extensive experiments, we show that our model outperform the existing methods on widely-used datasets for 3D/4D FER.","2021","2025-02-26 20:39:17","2025-02-26 20:39:17","","1913-1917","","","28","","","","","","","","","","English","","","","WOS:000702552400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","3D; 4D faces; Affect; Circuit faults; Computational modeling; emotion recognition; EXPRESSION RECOGNITION; FACE; Faces; Feature extraction; Hidden Markov models; multi-views; NETWORK; Three-dimensional displays; Training; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GTDSI69A","journalArticle","2025","Myers, BR; Mathy, P; Roy, N","Behavioral Treatment Approaches to Lowering Pitch in the Female Voice","JOURNAL OF VOICE","","0892-1997","10.1016/j.jvoice.2022.08.008","","Purpose. To assess the outcomes of three voice therapy treatment approaches with an emphasis on lowering speaking pitch. Transmasculine and cisgender individuals may desire to lower their speaking pitch, yet there has not been a method described in the literature to do this effectively using only behavioral techniques. Method. To investigate these approaches, we enrolled 32 adult cisgender females and randomly assigned them to one of four treatment groups: vocal function exercises (VFE), resonant voice therapy (RVT), lip-rounding therapy (LRT), and a control group. Participants received individual instruction and feedback on the given exercise program, and they continued to practice daily for 4 weeks. Results. Acoustic recordings were collected before treatment, immediately after the first session, and after 4 weeks of treatment. Results showed a lower minimum pitch in the physiological range, lower speaking fundamental frequency (SFF) in reading, and lower SFF in spontaneous speech-with treatment groups performing better than the control group. Additionally, participants' self-rating of the vocal effort expended to speak in a low pitch decreased over the treatment period. Conclusions. Each treatment approach (VFE, RVT, and LRT) was successful in lowering the speaking pitch of cisgender females. These methods would likely be useful for clients seeking to speak in a lower pitch. Future research may expand results to include clinical populations, such as transmasculine individuals.","2025-01","2025-02-26 20:39:17","2025-02-26 20:39:17","","286e1-286e11","","1","39","","","","","","","","","","English","","","","WOS:001414647400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","Acoustic analysis; COMMUNICATION; FORMANT FREQUENCIES; FUNDAMENTAL-FREQUENCY; INDIVIDUALS; PERCEPTION; PHONATION; Pitch range; RANGE; SPEECH; TESTOSTERONE THERAPY; Transgender; Vocal effort; VOCAL-TRACT LENGTH; Voice therapy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HSPGCDIG","journalArticle","2021","Travis, CE; Cacoullos, RT","Categories and Frequency: Cognition Verbs in Spanish Subject Expression","LANGUAGES","","2226-471X","10.3390/languages6030126","","Are semantic classes of verbs genuine or do they merely mask idiosyncrasies of frequent verbs? Here, we examine the interplay between semantic classes and frequent verb-form combinations, providing new evidence from variation patterns in spontaneous speech that linguistic categories are centered on high frequency members to which other members are similar. We offer an account of the well-known favoring effect of cognition verbs on Spanish subject pronoun expression by considering the role of high-frequency verbs (e.g., creer 'think' and saber 'know') and particular expressions ((yo) creo 'I think', (yo) no se 'I don't know'). Analysis of variation in nearly 3000 tokens of unexpressed and pronominal subjects in conversational data replicates well-established predictors, but highlights that the cognition verb effect is really one of 1sg cognition verbs. In addition, particular expressions stand out for their high frequency relative to their component parts (for (yo) creo, proportion of lexical type, and proportion of pronoun). Further analysis of 1sg verbs with frequent expressions as fixed effects reveals shared patterns with other cognition verbs, including an association with non-coreferential contexts. Thus, classes can be identified by variation constraints and contextual distributions that are shared among class members and are measurably different from those of the more general variable structure. Cognition verbs in variable Spanish subject expression form a class anchored in lexically particular constructions.","2021-09","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","3","6","","","","","","","","","","English","","","","WOS:000702288900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","cognition verbs; constructions; contextual distribution; frequency measures; LEXICAL FREQUENCY; linguistic categories; PRONOUN EXPRESSION; Spanish; subject pronoun expression; USAGE; variation constraints; VARIATIONIST","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"77KDF3I4","journalArticle","2022","Meer, P; Fuchs, R","The Trini Sing-Song: Sociophonetic variation in Trinidadian English prosody and differences to other varieties1","LANGUAGE AND SPEECH","","0023-8309","10.1177/0023830921998404","","The current study provides a phonetic perspective on the questions of whether a high degree of variability in pitch may be considered a characteristic, endonormative feature of Trinidadian English (TrinE) at the level of speech production and contribute to what is popularly described as 'sing-song' prosody. Based on read and spontaneous data from 111 speakers, we analyze pitch level, range, and dynamism in TrinE in comparison to Southern Standard British (BrE) and Educated Indian English (IndE) and investigate sociophonetic variation in TrinE prosody with a view to these global F0 parameters. Our findings suggest that a large pitch range could potentially be considered an endonormative feature of TrinE that distinguishes it from other varieties (BrE and IndE), at least in spontaneous speech. More importantly, however, it is shown that a high degree of pitch variation in terms of range and dynamism is not as much characteristic of TrinE as a whole as it is of female Trinidadian speakers. An important finding of this study is that pitch variation patterns are not homogenous in TrinE, but systematically sociolinguistically conditioned across gender, age, and ethnic groups, and rural and urban speakers. The findings thus reveal that there is a considerable degree of systematic local differentiation in TrinE prosody. On a more general level, the findings may be taken to indicate that endonormative tendencies and sociolinguistic differentiation in TrinE prosody are interlinked.","2022-12","2025-02-26 20:39:17","2025-02-26 20:39:17","","923-957","","4","65","","","","","","","","","","English","","","","WOS:000630815700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;98</p>","","","ACCENTS; ATTITUDES; FUNDAMENTAL-FREQUENCY; LANGUAGE VARIATION; pitch range; PRESTIGE; prosody; sociolinguistics; STANDARD; Trinidadian English; variation and change","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NDDR9XHL","journalArticle","2023","Agbavor, F; Liang, HL","Artificial Intelligence-Enabled End-To-End Detection and Assessment of Alzheimer's Disease Using Voice","BRAIN SCIENCES","","2076-3425","10.3390/brainsci13010028","","There is currently no simple, widely available screening method for Alzheimer's disease (AD), partly because the diagnosis of AD is complex and typically involves expensive and sometimes invasive tests not commonly available outside highly specialized clinical settings. Here, we developed an artificial intelligence (AI)-powered end-to-end system to detect AD and predict its severity directly from voice recordings. At the core of our system is the pre-trained data2vec model, the first high-performance self-supervised algorithm that works for speech, vision, and text. Our model was internally evaluated on the ADReSSo (Alzheimer's Dementia Recognition through Spontaneous Speech only) dataset containing voice recordings of subjects describing the Cookie Theft picture, and externally validated on a test dataset from DementiaBank. The AI model can detect AD with average area under the curve (AUC) of 0.846 and 0.835 on held-out and external test set, respectively. The model was well-calibrated (Hosmer-Lemeshow goodness-of-fit p-value = 0.9616). Moreover, the model can reliably predict the subject's cognitive testing score solely based on raw voice recordings. Our study demonstrates the feasibility of using the AI-powered end-to-end model for early AD diagnosis and severity prediction directly based on voice, showing its potential for screening Alzheimer's disease in a community setting.","2023-01","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","1","13","","","","","","","","","","English","","","","WOS:000914597300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;17<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Alzheimer's disease; data2vec; dementia; end-to-end; large language models; speech and language","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9YMM4J68","journalArticle","2024","Tizón-Couto, D; Lorenz, D","Learning to predict: Second language perception of reduced multi-word sequences","SECOND LANGUAGE RESEARCH","","0267-6583","10.1177/02676583241246147","","The cognitive entrenchment of frequent sequences comes as 'chunking' (holistic storage) and as 'procedure strengthening' (predicting elements in a sequence). A growing body of research shows effects of entrenchment of multi-word sequences in the native language, which is learned and shaped continuously and intuitively. But how do they affect second language (L2) speakers, whose language acquisition is more analytic but who nonetheless also learn through usage? The present study tests advanced English learners' receptive processing of multi-word sequences with a word-monitoring experiment. Recognition of to in the construction V to V-inf was tested for full and reduced forms ([t(sic)] vs. [(sic)]), conditioned by the general frequency of the V-to sequence and the transitional probability (TP) of to given the verb (V > to). The results are compared with those previously obtained from native speakers. Results show that recognition profits from surface frequency, but not from TP. Reduced forms delay recognition, but this is mitigated in high-frequency sequences. Unlike native speakers, advanced learners do not exhibit a chunking effect of high-frequency reduced forms, and no facilitating effect of TP. We attribute these findings to learners' lesser experience with spontaneous speech and phonetic reduction. They recognize reduced forms less easily, show weaker entrenchment of holistic representations, and do not draw on the full range of probabilistic cues available to native speakers.","2024-05-28","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","","","","","","","","","","","English","","","","WOS:001234763200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;112</p>","","","1ST; chunking; COLLOCATIONS; entrenchment; FORMULAIC SEQUENCES; FREQUENCY; frequency effects; LANGUAGE; LEARNERS; multi-word sequences; phonetic reduction; PHONOLOGICAL VARIATION; RECOGNITION; REPRESENTATION; second language processing; to-infinitive; USAGE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RFPT6V7I","journalArticle","2023","Jacewicz, E; Fox, RA; Holt, CE","Dialect and gender perception in relation to the intelligibility of low-pass and high-pass filtered spontaneous speech","JOURNAL OF THE ACOUSTICAL SOCIETY OF AMERICA","","0001-4966","10.1121/10.0020906","","Most cues to speech intelligibility are within a narrow frequency range, with its upper limit not exceeding 4 kHz. It is still unclear whether speaker-related (indexical) information is available past this limit or how speaker characteristics are distributed at frequencies within and outside the intelligibility range. Using low-pass and high-pass filtering, we examined the perceptual salience of dialect and gender cues in both intelligible and unintelligible speech. Setting the upper frequency limit at 11 kHz, spontaneously produced unique utterances (n = 400) from 40 speakers were high-pass filtered with frequency cutoffs from 0.7 to 5.56 kHz and presented to listeners for dialect and gender identification and intelligibility evaluation. The same material and experimental procedures were used to probe perception of low-pass filtered and unmodified speech with cutoffs from 0.5 to 1.1 kHz. Applying statistical signal detection theory analyses, we found that cues to gender were well preserved at low and high frequencies and did not depend on intelligibility, and the redundancy of gender cues at higher frequencies reduced response bias. Cues to dialect were relatively strong at low and high frequencies; however, most were in intelligible speech, modulated by a differential intelligibility advantage of male and female speakers at low and high frequencies. (C) 2023 Acoustical Society of America.","2023-09","2025-02-26 20:39:17","2025-02-26 20:39:17","","1667-1683","","3","154","","","","","","","","","","English","","","","WOS:001079145600004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","ACOUSTIC CHARACTERISTICS; AMERICAN; DISCRIMINATION; ENGLISH; IDENTIFICATION; SEX; SPEAKER; STATISTICAL DECISION-THEORY; VOICE; VOWEL CHANGE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H3HV5EFM","journalArticle","2024","Soo, R; Babel, M; Johnson, KA","Cross-Linguistic Phonetic Variation in Bilingual Speech: Cantonese /n/ > [l] Merger in Early Cantonese-English Bilinguals","LANGUAGE AND SPEECH","","0023-8309","10.1177/00238309241280182","","/n/ is merging with /l/ in Cantonese, as well as in several other Chinese languages. The Cantonese merger appears categorical, with /n/ becoming /l/ syllable-initially. This project aims to describe /n/ and /l/ in Cantonese and English speech from early Cantonese-English bilinguals to better understand the status of the merger in Cantonese and its potential for cross-linguistic mutual influence. We examine early bilinguals' (n = 34) speech using the Speech in Cantonese and English (SpiCE) corpus, focusing on pre-vocalic /n/ and /l/ onsets in both languages. Items were auditorily coded for their perceived category identity, and two acoustic measures anticipated to have the potential to differentiate /n/ and /l/ within and across languages were applied. In English, bilinguals maintained a clear contrast between /n/ and /l/ in the auditory coding and in acoustic measurements. In Cantonese, however, there were higher rates of [l] for /n/ items, in line with the merger, and [n] for /l/ items, indicating hypercorrection of the pattern. Across languages, bilinguals produced language-specific /l/s, but there were no acoustic differences between Cantonese and English /n/. The participation of Cantonese /n/ in a sound change does not appear to compromise English /n/s' patterning, suggesting that Cantonese and English /n/ are maintained as distinct categories in the minds of early bilinguals.","2024-10-23","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","","","","","","","","","","","English","","","","WOS:001346799600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;82</p>","","","AGE; bilinguals; CONSONANTS; INTERFERENCE; LANGUAGE CONTEXT; laterals; nasals; Sound change; SPANISH; spontaneous speech; SYSTEMS; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZUG7YM98","journalArticle","2021","Voniati, L; Tafiadis, D; Armostis, S; Kosma, EI; Chronopoulos, SK","Lexical Diversity in Cypriot-Greek-Speaking Toddlers: A Preliminary Longitudinal Study","FOLIA PHONIATRICA ET LOGOPAEDICA","","1021-7762","10.1159/000507621","","Background/Aims: The number of different words (NDW), an essential measure of lexical diversity, is extremely valuable towards providing data regarding children's language development. However, in Cyprus, practitioners are deprived of the opportunity to utilize NDW, as no normative data exist for toddlers who speak Cypriot Greek (CYG). Methods: The language samples of 36 monolingual CYG-speaking toddlers (aged 36, 40, 44, and 48 months) with a typical course of language development were collected and quantitatively analyzed. Based on the language sample analysis, we ascertained typical NDW values at the aforementioned ages and tested through a linear mixed-effects model whether gender and age affected NDW. Results: The results showed that age significantly predicted NDW increase; gender did not emerge as a significant predictor of NDW, but this may be due to the small statistical power. Conclusion: This study intends to provide the first step towards longitudinal investigation of the level of NDW for CYG-speaking children with a typical course of language development. The provided data, which could serve as preliminary norms, may be used - under some restrictions for the time being - during language assessment. Moreover, these acquired data could contribute to the development of an NDW database for diverse CYG-speaking populations of different age ranges in the future.","2021-07","2025-02-26 20:39:17","2025-02-26 20:39:17","","277-288","","4","73","","","","","","","","","","English","","","","WOS:000675341500003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;78</p>","","","Cypriot-Greek-speaking children; IMPAIRMENT; Language sample analysis; LANGUAGE SAMPLE MEASURES; Lexical diversity; MEAN LENGTH; MLU; Number of different words; PRESCHOOL-CHILDREN; RELIABILITY; SLI; SPONTANEOUS SPEECH; UTTERANCE; VOCABULARY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SUIHSV43","journalArticle","2022","Anand, AK; Suri, N; Ganesh, J; Vepuri, R; Kumar, R; Tiwari, N","Comparison of Outcomes in Unilateral and Bilateral Pediatric Cochlear Implants: Our Experience","INDIAN JOURNAL OF OTOLARYNGOLOGY AND HEAD & NECK SURGERY","","2231-3796","10.1007/s12070-021-02458-3","","The aim of our study is to compare the outcomes in unilateral and bilateral cochlear implants in pediatric age and also between simultaneous and sequential cochlear implant surgery. This retrospective study was carried out with 83 children aged between 12 months to 2.5 years which included 41 children with bilateral Cochlear implants and 42 with unilateral implants. Out of these 41 children, 21 were simultaneous and 20 were sequential cochlear implant. All the children were operated at civil hospital Gandhinagar, Gujarat, India. CAP, SIR, localization, traffic noise and speech in noise scores were assessed at regular intervals over the period of 4 years. Also the drug administration time, surgical time, operating room time were assessed for simultaneous and sequential cochlear implant surgery. Children with bilateral simultaneous implants fared significantly better with CAP, SIR, localization, speech noise and traffic noise scores than sequential bilateral implants and unilateral implants with a significant difference of means t tests between the two groups. Simultaneous cochlear implant surgery is associated with reduced surgical time, operating room time, it shortens the total in patient stay. There is less of drug administration and bilateral ones are stimulated simultaneously. Bilateral cochlear implants perform better with respect to auditory perception skills and spontaneous speech when compared with unilateral implants, but simultaneous surgery is better and safe option for pediatric cochlear implantation.","2022-08","2025-02-26 20:39:17","2025-02-26 20:39:17","","707-713","","SUPPL 1","74","","","","","","","","","","English","","","","WOS:000630278600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","Bilateral cochlear implant; Binaural hearing; Prelingual deafness; Speech noise and traffic noise scores","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QZAUEVF7","journalArticle","2024","Korecky-Kröll, K; Camber, M; Uzunkaya-Sharma, K; Dressler, WU","German Noun Plurals in Simultaneous Bilingual vs. Successive Bilingual vs. Monolingual Kindergarten Children: The Role of Linguistic and Extralinguistic Variables","LANGUAGES","","2226-471X","10.3390/languages9090306","","(1) Background: The complex phenomenon of German noun plural inflection is investigated in three groups of German-speaking kindergarten children: (a) monolinguals (1L1), (b) simultaneous bilinguals (2L1) also acquiring Croatian, and (c) successive bilinguals (L2) acquiring Turkish as L1. Predictions of the usage-based schema model and of Natural Morphology concerning different linguistic variables are used to explore their impact on plural acquisition in the three groups of children. (2) Methods: A longitudinal study (from mean age 3;1 to 4;8) is conducted using two procedures (a formal plural test and spontaneous recordings in kindergarten), and the data are analyzed using generalized linear (mixed-effects) regression models in R. (3) Results: All children produce more errors in the metalinguistically challenging test compared to spontaneous speech, with L2 children being particularly disadvantaged. Socioeconomic status (henceforth SES) and teachers' plural type frequency are most relevant for 1L1 children, and kindergarten exposure is more relevant for L2 children, while the linguistic variables are more important for 2L1 children. (4) Conclusions: The main predictions of the schema model and of Natural Morphology are largely confirmed. All of the linguistic variables investigated show significant effects in some analyses, but morphotactic transparency turns out to be the most relevant variable for all three groups of children.","2024-09","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","9","9","","","","","","","","","","English","","","","WOS:001323339300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","ACQUISITION; ENGLISH; INPUT; input-output relations; MARKING; monolingual first language acquisition; Natural Morphology; noun plurals; Schema Model; simultaneous bilingualism; successive bilingualism","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H3PS2QPA","journalArticle","2024","Lee, Y; Oh, S; Lim, S","A Study on the Using of Endings (""Eomi"") of 3- to 5-Year-Old Children in Spontaneous Language Samples","COMMUNICATION SCIENCES AND DISORDERS-CSD","","2288-1328","10.12963/csd.240014","","Objectives: Considering that language development is the development of language use ability, endings, which are essential for sentence construction, can be said to be a good indicator of language development as well as grammatical development. This study attempted to systematically and comprehensively examine the overall and subcategory use of endings in spontaneous speech for children aged 3 to 5 whose syntactic skills are rapidly developing. Methods: Language samples containing 50 utterances were collected from a total of 150 children aged 3 to 5 years (50 in each age group) through a semi-structured procedure. 'Eomi's are classified into four subcategories: prefinal Eomi (PE), Sentence-closing Eomi (SE), Connecting Eomi (CE), Transformative Eomi (TE). The number of total Eomi (NTE) use, the number of different Eomi (NDE) of overall Eomi & all subcategories of Eomi were analyzed. Results: The NTE & NDE of overall Eomi and all subcategories except SE significantly increased between the 3-year-old group and two older groups, but not between two older groups. Regression analysis demonstrated that the NDE of final Eomi and the NTE of CE significantly explained chronological age in the 3-year-old group. Conclusion: It was confirmed that NDE along with NTE of overall and all subcategories of Eomi consistently increased actively between the ages of 3 and 4. Also NDE along with NTE of Eomi should be considered in language assessment and intervention.","2024-06","2025-02-26 20:39:17","2025-02-26 20:39:17","","185-197","","2","29","","","","","","","","","","English","","","","WOS:001276902100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","Eomi; Eomi development; Grammatical development; Grammatical marker; Spontaneous language","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R296EZT5","journalArticle","2022","Beaulieu, S; Bejarano, J; French, LM; Reinke, K","Professional Identities of French Lx Economic Immigrants: Perceptions from a Local French-Speaking Community","LANGUAGES","","2226-471X","10.3390/languages7020140","","Communicative expertise in the host society's dominant language is central to newcomers' socio-professional integration. To date, SLA research has largely ignored laypeople's perspectives about Lx communicative expertise, though they are the ultimate judges of real-life interactional success. Sociolinguistic studies have shown that laypeople may base their judgments of Lx speech not only on linguistic criteria, but also on extralinguistic factors such as gender and language background. To document laypeople perspectives, we investigated the professional characteristics attributed to four ethnolinguistic groups of French Lx economic immigrants (Spanish, Chinese, English and Farsi) who were nearing completion of the government-funded French language training program in Quebec City, Canada. We asked L1 naive listeners (N = 49) to evaluate spontaneous speech excerpts, similar in terms of content and speech qualities, produced by a man and a woman from each target group. After they listened to each audio excerpt, we asked listeners to select the characteristics they associated with that person from a list of the most frequent professional qualities found in job advertisements. Data analysis showed that few Lx users were perceived as having strong communication skills in French. Logistic regression revealed no significant relationships between language group, gender, communicative effectiveness, and professional characteristics. However, there were significant associations between communicative effectiveness with the following characteristics: can work independently, can relate to others, is dynamic, has a sense of initiative, and shows leadership skills.","2022-06","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","2","7","","","","","","","","","","English","","","","WOS:000817488700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","ACCENTS; ATTITUDES; economic immigrants; ENGLISH; IMPRESSIONS; LANGUAGE; perceived oral proficiency; PERSPECTIVE; professional identities; PROFICIENCY; SKILLS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z5TP8SBQ","journalArticle","2025","Abdelaziz, A; Wagner, M; Naigles, LR","Associations Between Joint Attention, Supported Joint Engagement and Language in TD Children and Children with ASD: Potential Sources of Individual and Group Differences in Language Outcomes","LANGUAGE LEARNING AND DEVELOPMENT","","1547-5441","10.1080/15475441.2024.2336047","","Joint Attention (JA) and Supported Joint Engagement (Supported JE) have each been reported to predict later language development in typically developing (TD) children and children with Autism Spectrum Disorder (ASD). In this longitudinal study including 33 TD children (20 months at V1) and 30 children with ASD (33 months at V1), the contributions of JA and Supported JE to later language, assessed via standardized tests and spontaneous speech, were directly compared. Frequency and durations of JA and Supported JE episodes were coded from 30-minute interactions with caregivers; subsequent language skills were assessed two years later. JA duration in the ASD group significantly predicted later standardized and spontaneous language, most strongly in the low-verbal ASD subgroup. Supported JE measures did not positively predict later language in either group. These findings suggest that JA played a larger role with children with ASD with low-verbal abilities, but not with children with ASD with high-verbal abilities nor with the TD children. The current study adds to existing literature by providing further support for studying children with ASD as two subgroups based on their verbal abilities (high vs low), as well as directly comparing the effects of JA and Supported JE on later language development in such groups. Implications for further research are discussed.","2025-01-02","2025-02-26 20:39:17","2025-02-26 20:39:17","","27-57","","1","21","","","","","","","","","","English","","","","WOS:001203822000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;92</p>","","","ABILITIES; ACQUISITION; AUTISM SPECTRUM DISORDERS; DIRECTED SPEECH; EMERGENCE; INPUT; PREDICTORS; TODDLERS; VOCABULARY; YOUNG-CHILDREN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AEXN3EMM","journalArticle","2021","Roa-Rojas, P; Grinstead, J; Silva-Pereyra, J; Fernández, T; Rodríguez-Camacho, M","Syntactic Gender Agreement Processing on Direct-Object Clitics by Spanish-Speaking Children with Developmental Language Disorder: Evidence from ERP","CHILDREN-BASEL","","2227-9067","10.3390/children8030175","","Children with developmental language disorder (DLD) have a psycholinguistic profile evincing multiple syntactic processing impairments. Spanish-speaking children with DLD struggle with gender agreement on clitics; however, the existing evidence comes from offline, elicitation tasks. In the current study, we sought to determine whether converging evidence of this deficit can be found. In particular, we use the real-time processing technique of event-related brain potentials (ERP) with direct-object clitic pronouns in Spanish-speaking children with DLD. Our participants include 15 six-year-old Mexican Spanish-speaking children with DLD and 19 typically developing, age-matched (TD) children. Auditory sentences that matched or did not match the gender features of antecedents represented in pictures were employed as stimuli in a visual-auditory gender agreement task. Gender-agreement violations were associated with an enhanced anterior negativity between 250 and 500 ms post-target onset in the TD children group. In contrast, children with DLD showed no such effect. This absence of the left anterior negativity (LAN) effect suggests weaker lexical representation of morphosyntactic gender features and/or non-adult-like morphosyntactic gender feature checking for the DLD children. We discuss the relevance of these findings for theoretical accounts of DLD. Our findings may contribute to a better understanding of syntactic agreement processing and language disorders.","2021-03","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","3","8","","","","","","","","","","English","","","","WOS:000633460300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;102</p>","","","ACQUISITION; clitics; ERP; gender agreement; GRAMMATICAL GENDER; IMPAIRMENT; MORPHOLOGY; SENTENCE COMPREHENSION; Spanish; specific language impairment; SPONTANEOUS SPEECH; UNIQUE CHECKING CONSTRAINT; VERB INFLECTIONS; WORKING-MEMORY; YOUNG-CHILDREN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VR3MQB2Z","journalArticle","2021","Kornder, L; Mennen, I","Listeners' Linguistic Experience Affects the Degree of Perceived Nativeness of First Language Pronunciation","FRONTIERS IN PSYCHOLOGY","","1664-1078","10.3389/fpsyg.2021.717615","","The aim of this study was to explore if and to what extent Austrian-English late sequential bilinguals who have been living in a second language (L2) environment for several decades are perceived to sound native in their first language (L1) when being compared to monolingual Austrian German (AG) control speakers. Furthermore, this investigation aimed to identify if listeners differ in their judgments of nativeness of L1 pronunciation depending on their own language background. For this purpose, two groups of native Austrian German listeners (N = 30 each), who differed regarding their linguistic background (Austrian German monolingual and Austrian German-English bilingual listeners) were asked to rate spontaneous speech samples produced by Austrian English bilingual and Austrian German monolingual speakers. Results showed that the bilingual L1 speech was perceived to sound overall less native compared to monolingual control speech. It was further observed that the two listener groups significantly differed in their perception of nativeness: Bilingual listeners were overall less likely to judge bilingual L1 pronunciation to sound non-native compared to monolingual listeners. To date, this is the first study to show that listener experience influences their perception of nativeness of L1 pronunciation and, thus, adds a new dimension to the notion of the native speaker.</p>","2021-10-08","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","12","","","","","","","","","","English","","","","WOS:000710915400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;130</p>","","","(Austrian) German; bilingualism; BRAZILIAN PORTUGUESE; DYNAMIC-SYSTEMS; English; first language attrition; foreign accent; FOREIGN ACCENT; L1; L2; nativeness perception; PHONETIC DRIFT; SPANISH-ENGLISH BILINGUALS; SPEECH; STOP CONSONANTS; VOICE-ONSET TIME","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L8CA27XQ","journalArticle","2025","You, ZY; Wang, X; Xu, JW; Wang, H; Yan, RQ","Signal generation for bolt loosening detection with unbalanced datasets based on the CBAM-VAE","MEASUREMENT","","0263-2241","10.1016/j.measurement.2024.115589","","Bolt looseness has adverse influences on the stability and safety of engineering structures. Neural network algorithms can effectively monitor health conditions using impedance signals. However, impedance data of engineering structures in damaged conditions is challenging to obtain. The data would also exhibit an imbalanced distribution, yielding deterioration of the accuracy of health monitoring. In this study, we propose a data augmentation method based on a Variational Autoencoder model with a convolutional block attention module. This method addressed the issue of imbalanced data by generating new data. A Transformer model was adopted for training and fault classification. Without employing data augmentation methods, the max accuracy is 85.71%. However, experimental results demonstrate the remarkable effectiveness of this approach in enhancing and classifying imbalanced datasets, with an average accuracy of 89.35% and the highest accuracy of 94.81% after enhancement. The proposed method can be applied to health conditions identification of buildings, bridges, and trusses.","2025-01-30","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","240","","","","","","","","","","English","","","","WOS:001302985400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Bolt looseness; Convolutional Block Attention Module; Data Augmentation; IDENTIFICATION; SENSORS; Transformer; Variational Autoencoder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N6P9QBGE","journalArticle","2023","Mayer, Z; Kahn, J; Hou, Y; Götz, M; Volk, R; Schultmann, F","Deep learning approaches to building rooftop thermal bridge detection from aerial images","AUTOMATION IN CONSTRUCTION","","0926-5805","10.1016/j.autcon.2022.104690","","Thermal bridges are weak points of building envelopes that can lead to energy losses, collection of moisture, and formation of mould in the building fabric. To detect thermal bridges of large building stocks, drones with thermographic cameras can be used. As the manual analysis of comprehensive image datasets is very time-consuming, we investigate deep learning approaches for its automation. For this, we focus on thermal bridges on building rooftops recorded in panorama drone images from our updated dataset of Thermal Bridges on Building Rooftops (TBBRv2), containing 926 images with 6,927 annotations. The images include RGB, thermal, and height information. We compare state-of-the-art models with and without pretraining from five different neural network architectures: MaskRCNN R50, Swin-T transformer, TridentNet, FSAF, and a MaskRCNN R18 baseline. We find promising results, especially for pretrained models, scoring an Average Recall above 50% for detecting large thermal bridges with a pretrained Swin-T Transformer model.","2023-02","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","146","","","","","","","","","","English","","","","WOS:000895020500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Building analysis; Computer vision; Deep learning; Drones; Object detection; Thermal bridges; THERMOGRAPHY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"35KCSTJI","journalArticle","2022","Ran, ZD; Lu, XB","Camera domain adaptation based on cross-patch transformers for person re-identification","PATTERN RECOGNITION LETTERS","","0167-8655","10.1016/j.patrec.2022.05.005","","As an essential task applied to video surveillance, person re-identification (Re-ID) suffers from variations across different cameras. In this paper we propose an effective transformer-based Re-ID framework for learning the identity-discriminative and camera-invariant feature representations. In contrast to the recent direction of using generative models to augment training data and enhance the invariance to input variations, we show that explicitly designing a novel adversarial loss from the perspective of feature representation learning helps to penalize the distribution discrepancy across multiple camera domains effectively. Recently, the pure transformer model has gained much attention due to its strong representation capabilities. We employ a pure transformer encoder to extract a global feature vector for the patch tokens of each person image. Notably, a novel cross-patch encoder is introduced to obtain structural information between image patches. Extensive experiments on three challenging datasets demonstrate the effectiveness and superiority of the proposed learning framework. (C) 2022 Published by Elsevier B.V.","2022-07","2025-02-26 20:39:17","2025-02-26 20:39:17","","84-90","","","159","","","","","","","","","","English","","","","WOS:000830083900012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Metric learning; MULTISCALE; Person re-identification; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YL4MFHK6","journalArticle","2023","Åke, S; Hartelius, L; Jakola, AS; Antonsson, M","Experiences of language and communication after brain-tumour treatment: A long-term follow-up after glioma surgery","NEUROPSYCHOLOGICAL REHABILITATION","","0960-2011","10.1080/09602011.2022.2080720","","The purpose of this study was to explore how persons having received various treatments for glioma, a type of brain tumour, experience their language, speech, and communication in everyday life. Twelve persons with low-grade glioma and one with high-grade glioma who had undergone tumour resection in 2014-2016 in different tumour locations were interviewed using a semi-structured protocol. The video-recorded interviews were transcribed and analysed using qualitative content analysis, which revealed three manifest categories, nine sub-categories and one latent theme. Participants experienced changed communication that affected word finding, motor speech and comprehension. They also expressed how communication required a greater effort; time and context were important factors and participants felt frustrated with their communication. Further, they were dealing with changes and used multiple strategies to manage communication. For most participants it did not affect their everyday life, but it was not like before. In addition, participants adapted their way of living to manage illness-related problems. Uncertainty was a latent theme which emanated from the participants' illness experience, reflecting how living with a slow-growing brain tumour affects life-decisions and views of perceived symptoms. Discussion of how results can be interpreted in relation to previous research and health care are included.","2023-08-09","2025-02-26 20:39:17","2025-02-26 20:39:17","","1225-1261","","7","33","","","","","","","","","","English","","","","WOS:000805322400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","APHASIA; Brain tumour; CLASSIFICATION; Cognitive communication; Communication impairment; DISABILITY; ELOQUENT AREAS; Glioma; INDIVIDUALS; LOW-GRADE GLIOMA; OF-LIFE; Qualitative content analysis; QUALITATIVE CONTENT-ANALYSIS; RESECTION; SPONTANEOUS SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9Q3S3JKG","journalArticle","2022","Kim, H; Walker, A; Shea, J; Hillis, AE","Written Discourse Task Helps to Identify Progression from Mild Cognitive Impairment to Dementia","DEMENTIA AND GERIATRIC COGNITIVE DISORDERS","","1420-8008","10.1159/000519884","","Purpose: We aimed to investigate: (1) the clinical, diagnostic value of a written discourse task, and (2) the relationship between executive functions and written discourse within the spectrum of individuals with mild cognitive impairment (MCI). Method: To determine whether written discourse performance predicts clinical course among individuals with MCI, we retrospectively classified individuals with MCI as converters (N = 26) who were later diagnosed with dementia or as a stable MCI group (N = 45). We quantified core word measures from written discourse samples obtained from the Cookie Theft picture description task. Result: Written discourse measures differentiated converters from the stable MCI group. Converters produced a fewer number of core words than the stable MCI group. A measure of executive function significantly predicted performance on the production of core words in written discourse for the converters. In a multivariable regression, production of core words remained the only explanatory variable closely associated with the progression to dementia in MCI. Conclusion: Written discourse tasks can predict the likelihood of MCI progressing to dementia, independently of recall and an executive function measure. Correlational results suggest that written discourse performance was associated with executive function as measured by the Trail Making Test. Our findings emphasize the usefulness of including written discourse tasks in language assessment batteries targeting preclinical dementia populations.","2022-01","2025-02-26 20:39:17","2025-02-26 20:39:17","","446-453","","5","50","","","","","","","","","","English","","","","WOS:000754677800005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","APHASIA; Assessment measures; Behavioral neurology; Cognitive functioning; DEFICITS; DISEASE; EXECUTIVE FUNCTION; LANGUAGE; MEMORY; Mild cognitive impairment and dementia; REVISION; SPONTANEOUS SPEECH; TRAIL; Written discourse","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SMEJ23MZ","journalArticle","2021","Diez-Itza, E; Vergara, P; Barros, M; Miranda, M; Martínez, V","Assessing Phonological Profiles in Children and Adolescents With Down Syndrome: The Effect of Elicitation Methods","FRONTIERS IN PSYCHOLOGY","","1664-1078","10.3389/fpsyg.2021.662257","","In the context of comparing linguistic profiles across neurodevelopmental disorders, Down syndrome (DS) has captured growing attention for its uneven profile. Although specific weaknesses in grammatical and phonological processing have been reported, research evidence on phonological development remains scarce, particularly beyond early childhood. The purpose of this study was to explore the phonological profiles of children and adolescents with Down syndrome. The profiles were based on the frequency and relative proportion of the processes observed by classes, and they were compared to those of typically developing preschool children of similar verbal age. A complementary goal was to assess the effect of two different methods of elicitation: a test of articulation and spontaneous speech sampling. Finally, intergroup and intragroup differences in full match percentages between three positions at syllable-level (complex onset, medial coda, and final coda) were assessed. The results of the present study confirmed that the frequency of phonological processes in children and adolescents with DS is atypically high and is above what is expected for lexical age and at the same level as grammatical age. Highly increased frequency of processes, consistent in all kinds of processes and positions at the syllable-level, and asynchronous with verbal age and mental age suggest atypical developmental trajectories of phonological development in the Down syndrome population.","2021-05-12","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","12","","","","","","","","","","English","","","","WOS:000654213300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","ARTICULATION; atypical language development; CONVERSATIONAL SPEECH; Down syndrome; elicitation methods; FRAGILE-X-SYNDROME; LANGUAGE; neurodevelopmental disorders; phonological profiles; SHORT-TERM-MEMORY; SKILLS; SPEECH COMPREHENSIBILITY; STUDENTS; WILLIAMS-SYNDROME; WORDS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CJYW9EGH","journalArticle","2023","Svindt, V; Gosztolya, G; Gráczi, TE","Narrative recall in relapsing-remitting multiple sclerosis: A potentially useful speech task for detecting subtle cognitive changes","CLINICAL LINGUISTICS & PHONETICS","","0269-9206","10.1080/02699206.2023.2170830","","Our research studied relapsing-remitting multiple sclerosis (RRMS). In half of the RRMS cases, mild cognitive difficulties are present, but often remain undetected despite their adverse effects on individuals' daily life. Detecting subtle cognitive alterations using speech analysis have rarely been implemented in MS research. We applied automatic speech recognition technology to devise a speech task with potential diagnostic value. Therefore, we used two narrative tasks adjusted for the neural and cognitive characteristics of RRMS; namely narrative recall and personal narrative. In addition to speech analysis, we examined the information processing speed, working memory, verbal fluency, and naming skills. Twenty-one participants with RRMS and 21 gender-, age-, and education-matched healthy controls took part in the study. All the participants with RRMS achieved a normal performance on Addenbrooke's Cognitive Examination. The following parameters of speech were measured: articulation and speech rate, the proportion, duration, frequency, and average length of silent and filled pauses. We found significant differences in the temporal parameters between groups and speech tasks. ROC analysis produced high classification accuracy for the narrative recall task (0.877 and 0.866), but low accuracy for the personal narrative task (0.617 and 0.592). The information processing speed affected the speech of the RRMS group but not that of the control group. The higher cognitive load of the narrative recall task may be the cause of significant changes in the speech of the RRMS group relative to the controls. Results suggest that narrative recall task may be effective for detecting subtle cognitive changes in RRMS.","2023-06-03","2025-02-26 20:39:17","2025-02-26 20:39:17","","549-566","","4-6","37","","","","","","","","","","English","","","","WOS:000921869500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","AGE; automatic speech recognition technology (ASR); DEFICITS; DYSFUNCTION; FLUENCY; IMPAIRMENT; MATTER; narrative recall; personal narrative; Relapsing-remitting multiple sclerosis (RRMS); ROC analysis (receiver operating characteristics); SUBTYPES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CU9VRZUG","journalArticle","2022","Teferra, BG; Borwein, S; DeSouza, DD; Simpson, W; Rheault, L; Rose, J","Acoustic and Linguistic Features of Impromptu Speech and Their Association With Anxiety: Validation Study","JMIR MENTAL HEALTH","","2368-7959","10.2196/36828","","Background: The measurement and monitoring of generalized anxiety disorder requires frequent interaction with psychiatrists or psychologists. Access to mental health professionals is often difficult because of high costs or insufficient availability. The ability to assess generalized anxiety disorder passively and at frequent intervals could be a useful complement to conventional treatment and help with relapse monitoring. Prior work suggests that higher anxiety levels are associated with features of human speech. As such, monitoring speech using personal smartphones or other wearable devices may be a means to achieve passive anxiety monitoring.Objective: This study aims to validate the association of previously suggested acoustic and linguistic features of speech with anxiety severity.Methods: A large number of participants (n=2000) were recruited and participated in a single web-based study session. Participants completed the Generalized Anxiety Disorder 7-item scale assessment and provided an impromptu speech sample in response to a modified version of the Trier Social Stress Test. Acoustic and linguistic speech features were a priori selected based on the existing speech and anxiety literature, along with related features. Associations between speech features and anxiety levels were assessed using age and personal income as covariates. Results: Word count and speaking duration were negatively correlated with anxiety scores (r=-0.12; P<.001), indicating that participants with higher anxiety scores spoke less. Several acoustic features were also significantly (P<.05) associated with anxiety, including the mel-frequency cepstral coefficients, linear prediction cepstral coefficients, shimmer, fundamental frequency, and first formant. In contrast to previous literature, second and third formant, jitter, and zero crossing rate for the z score of the power spectral density acoustic features were not significantly associated with anxiety. Linguistic features, including negative-emotion words, were also associated with anxiety (r=0.10; P<.001). In addition, some linguistic relationships were sex dependent. For example, the count of words related to power was positively associated with anxiety in women (r=0.07; P=.03), whereas it was negatively associated with anxiety in men (r=-0.09; P=.01).Conclusions: Both acoustic and linguistic speech measures are associated with anxiety scores. The amount of speech, acoustic quality of speech, and gender-specific linguistic characteristics of speech may be useful as part of a system to screen for anxiety, detect relapse, or monitor treatment.","2022-07-08","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","7","9","","","","","","","","","","English","","","","WOS:000848666800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;10<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","acoustic features; DISORDERS; generalized anxiety disorder; impromptu speech; linguistic features; mental health; mobile phone; RESPONSES; STRESS; TRAIT ANXIETY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4KCL7VAG","journalArticle","2024","Zaninotto, AL; Makary, MM; Rowe, HP; Eshghi, M; Tseng, CE; Chan, JM; Zürcher, NR; Hooker, J; Lewis, A; Keegan, M; Gifford, RF; Green, JR; Babu, S","Speech motor impairment in ALS is associated with multiregional cortical thinning beyond primary motor cortex","FRONTIERS IN NEUROLOGY","","1664-2295","10.3389/fneur.2024.1451177","","Introduction: Cortical thinning is well-documented in individuals with amyotrophic lateral sclerosis (ALS), yet its association with speech deterioration remains understudied. This study characterizes anatomical changes in the brain within the context of speech impairment patterns in individuals with ALS, providing insight into the disease's multiregional spread and biology. Methods: To evaluate patterns of cortical thickness in speakers with ALS with and without functional speech changes compared to healthy controls (HCs) using whole-brain and region of interest (ROI) analyses. Forty individuals with ALS and 22 HCs underwent a T1-weighted 3-Tesla magnetic resonance imaging (MRI). Individuals with ALS were divided into two groups based on the preserved speech [ps-ALS] (n = 18) or deteriorated speech [ds-ALS] (n = 22) as measured by the ALSFRSF-R speech subscore (=4 or <4 points, respectively). Sixteen a priori-defined and automatically segmented cortical and subcortical brain ROIs were selected based on their previously documented roles in speech production. Two cortical thickness analyses were performed: (1) group-level whole-brain surface-based analyses and (2) group-level ROI analyses. A case study of 6 ALS individuals examined the cortical thickness, and their speech was characterized using quantitative and qualitative measures. Results: Based on the group-level whole-brain surface-based analyses, the ds-ALS group demonstrated significant cortical thinning compared to HCs in the left primary motor and somatosensory cortices and the right inferior parietal lobe with its adjacent lateral occipital cortical regions. The ps-ALS group demonstrated no significant cortical thinning compared to HCs. Based on the group-level ROI analyses, the ds-ALS group demonstrated significant cortical thinning compared to HCs in bilateral middle motor cortices, right posterior dorsal premotor cortex, and left anterior cingulate cortex. The case study analysis revealed that ALS speakers with speech features characteristic of spastic dysarthria exhibited cortical thinning, while those with speech features characteristic of flaccid dysarthria did not. Discussion: Individuals with ALS have anatomical changes involving multiregional neocortical areas beyond the primary motor cortex that may manifest as subjective (i.e., clinical judgment) and objective (i.e., speaking rate) changes in speech production. Further longitudinal work in ALS is needed to better understand the link between MRI cortical thickness changes and bulbar dysfunction.","2024-10-01","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","15","","","","","","","","","","English","","","","WOS:001334439500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","ACTIVATION; amyotrophic lateral sclerosis (ALS); AMYOTROPHIC-LATERAL-SCLEROSIS; brain atrophy; CONNECTIVITY; dysarthria; DYSARTHRIA; EXECUTIVE DYSFUNCTION; IN-VIVO; INTEGRATION; MRI; neurodegeneration; SEGMENTATION; speech impairment; speech motor control; SUBCOMPONENTS; SUPERIOR LONGITUDINAL FASCICULUS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L4XMVSTB","journalArticle","2022","de Leon-Martinez, S; Ruiz, M; Parra-Vargas, E; Chicchi-Giglioli, I; Courtet, P; Lopez-Castroman, J; Artes, A; Baca-Garcia, E; Porras-Segovia, AA; Barrigon, ML","Virtual reality and speech analysis for the assessment of impulsivity and decision-making: protocol for a comparison with neuropsychological tasks and self-administered questionnaires","BMJ OPEN","","2044-6055","10.1136/bmjopen-2021-058486","","Introduction Impulsivity is present in a range of mental disorders and has been associated with suicide. Traditional measures of impulsivity have certain limitations, such as the lack of ecological validity. Virtual reality (VR) may overcome these issues. This study aims to validate the VR assessment tool 'Spheres & Shield Maze Task' and speech analysis by comparing them with traditional measures. We hypothesise that these innovative tools will be reliable and acceptable by patients, potentially improving the simultaneous assessment of impulsivity and decision-making. Methods and analysis This study will be carried out at the University Hospital Fundacion Jimenez Diaz (Madrid, Spain). Our sample will consist of adults divided into three groups: psychiatric outpatients with a history of suicidal thoughts and/or behaviours, psychiatric outpatients without such a history and healthy volunteers. The target sample size was established at 300 participants (100 per group). Participants will complete the Barrett Impulsiveness Scale 11; the Urgency, Premeditation, Perseverance, Sensation Seeking, Positive Urgency, Impulsive Behaviour Scale; Iowa Gambling Task; Continuous Performance Test; Stop signal Task, and Go/no-go task, three questions of emotional affect, the Spheres & Shield Maze Task and two satisfaction surveys. During these tasks, participant speech will be recorded. Construct validity of the VR environment will be calculated. We will also explore the association between VR-assessed impulsivity and history of suicidal thoughts and/or behaviour, and the association between speech and impulsivity and decision-making. Ethics and dissemination This study was approved by the Ethics Committee of the University Hospital Fundacien Jimenez Diaz (PIC128-21_FJD). Participants will be required to provide written informed consent. The findings will be presented in a series of manuscripts that will be submitted to peer-reviewed journals for publication.","2022-07","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","7","12","","","","","","","","","","English","","","","WOS:000826598000004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","SUICIDE ATTEMPTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5UTMMLWE","journalArticle","2023","Huang, J; Zhao, YL; Tian, ZX; Qu, W; Du, X; Zhang, J; Tan, YL; Wang, ZR; Tan, SP","Evaluating the clinical utility of speech analysis and machine learning in schizophrenia: A pilot study","COMPUTERS IN BIOLOGY AND MEDICINE","","0010-4825","10.1016/j.compbiomed.2023.107359","","Background: Schizophrenia is a serious mental disorder that significantly impacts social functioning and quality of life. However, current diagnostic methods lack objective biomarker support. While some studies have indicated differences in audio features between patients with schizophrenia and healthy controls, these findings are influenced by demographic information and variations in experimental paradigms. Therefore, it is crucial to explore stable and reliable audio biomarkers for an auxiliary diagnosis and disease severity prediction of schizophrenia. Method: A total of 130 individuals (65 patients with schizophrenia and 65 healthy controls) read three fixed texts containing positive, neutral, and negative emotions, and recorded them. All audio signals were preprocessed and acoustic features were extracted by a librosa-0.9.2 toolkit. Independent sample t-tests were performed on two sets of acoustic features, and Pearson correlation on the acoustic features and Positive and Negative Syndrome Scale (PANSS) scores of the schizophrenia group. Classification algorithms in scikit-learn were used to diagnose schizophrenia and predict the level of negative symptoms. Results: Significant differences were observed between the two groups in the mfcc_8, mfcc_11, and mfcc_33 of mel-frequency cepstral coefficient (MFCC). Furthermore, a significant correlation was found between mfcc_7 and the negative PANSS scores. Through acoustic features, we could not only differentiate patients with schizophrenia from healthy controls with an accuracy of 0.815 but also predict the grade of the negative symptoms in schizophrenia with an average accuracy of 0.691. Conclusions: The results demonstrated the considerable potential of acoustic characteristics as reliable biomarkers for diagnosing schizophrenia and predicting clinical symptoms.","2023-09","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","164","","","","","","","","","","English","","","","WOS:001058680200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","BIOMARKER; Clinical symptom; DEPRESSION; DIAGNOSIS; ESTROGEN; FEATURES; Machine learning; MFCC; RECOGNITION; Schizophrenia; SPECTRUM DISORDERS; Speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q4MWRKV4","journalArticle","2023","Cohen, J; Richter, V; Neumann, M; Black, D; Haq, A; Wright-Berryman, J; Ramanarayanan, V","A multimodal dialog approach to mental state characterization in clinically depressed, anxious, and suicidal populations","FRONTIERS IN PSYCHOLOGY","","1664-1078","10.3389/fpsyg.2023.1135469","","BackgroundThe rise of depression, anxiety, and suicide rates has led to increased demand for telemedicine-based mental health screening and remote patient monitoring (RPM) solutions to alleviate the burden on, and enhance the efficiency of, mental health practitioners. Multimodal dialog systems (MDS) that conduct on-demand, structured interviews offer a scalable and cost-effective solution to address this need.ObjectiveThis study evaluates the feasibility of a cloud based MDS agent, Tina, for mental state characterization in participants with depression, anxiety, and suicide risk.MethodSixty-eight participants were recruited through an online health registry and completed 73 sessions, with 15 (20.6%), 21 (28.8%), and 26 (35.6%) sessions screening positive for depression, anxiety, and suicide risk, respectively using conventional screening instruments. Participants then interacted with Tina as they completed a structured interview designed to elicit calibrated, open-ended responses regarding the participants' feelings and emotional state. Simultaneously, the platform streamed their speech and video recordings in real-time to a HIPAA-compliant cloud server, to compute speech, language, and facial movement-based biomarkers. After their sessions, participants completed user experience surveys. Machine learning models were developed using extracted features and evaluated with the area under the receiver operating characteristic curve (AUC).ResultsFor both depression and suicide risk, affected individuals tended to have a higher percent pause time, while those positive for anxiety showed reduced lip movement relative to healthy controls. In terms of single-modality classification models, speech features performed best for depression (AUC = 0.64; 95% CI = 0.51-0.78), facial features for anxiety (AUC = 0.57; 95% CI = 0.43-0.71), and text features for suicide risk (AUC = 0.65; 95% CI = 0.52-0.78). Best overall performance was achieved by decision fusion of all models in identifying suicide risk (AUC = 0.76; 95% CI = 0.65-0.87). Participants reported the experience comfortable and shared their feelings.ConclusionMDS is a feasible, useful, effective, and interpretable solution for RPM in real-world clinical depression, anxiety, and suicidal populations. Facial information is more informative for anxiety classification, while speech and language are more discriminative of depression and suicidality markers. In general, combining speech, language, and facial information improved model performance on all classification tasks.","2023-09-11","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","14","","","","","","","","","","English","","","","WOS:001070311100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;79</p>","","","ADOLESCENTS; anxiety; ANXIETY; BIOMARKERS; depression; facial features; INDICATORS; LANGUAGE; machine learning; multimodal dialog systems; natural language processing; SEVERITY; SPEECH; speech features; suicide; VALIDITY; VIRTUAL HUMANS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8ZEFC3Q4","journalArticle","2023","Josephs, KA; Duffy, JR; Martin, PR; Stephens, YC; Singh, NA; Clark, HM; Botha, H; Lowe, VJ; Whitwell, JL; Utianski, RL","Acoustic analysis and neuroimaging correlates of diadochokinetic rates in mild-moderate primary progressive apraxia of speech","BRAIN AND LANGUAGE","","0093-934X","10.1016/j.bandl.2023.105254","","Speech rate can be judged clinically using diadochokinetic (DDK) tasks, such as alternating motion rates (AMR) and sequential motion rates (SMR). We evaluated whether acoustic AMR/SMR speech rates would differentiate primary progressive apraxia of speech (PPAOS) from healthy controls, and determined how DDK rates relate to phonetic and prosodic speech characteristics and brain metabolism on FDG-PET. Rate was calculated for each of three AMRs (repetitions of 'puh', 'tuh', and 'kuh') and for SMRs (repetitions of 'puhtuhkuh') for 27 PPAOS patients and 52 controls who underwent FDG-PET. PPAOS patients were slower than controls on all DDK tasks. All DDK rates correlated with apraxia of speech severity, with strongest associations with prosodic speech features. Slower DDK rates were associated with hypometabolism in the right cerebellar dentate and left supplementary motor area. Performance on AMR rate, not just SMR rate, may be impaired in mild PPAOS, but sensitivity and specificity require further study.","2023-05","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","240","","","","","","","","","","English","","","","WOS:000975151800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","Acoustic analysis; Aphasia; APHASIA; Apraxia of speech; DENTATORUBROTHALAMIC TRACT; DIAGNOSIS; DISEASE; EVOLUTION; LOGOPENIC VARIANTS; NONFLUENT; PET; Phonetic; Prosodic; TOOL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VL33JRXE","journalArticle","2022","Nasir, M; Baucom, B; Bryan, C; Narayanan, S; Georgiou, P","Modeling Vocal Entrainment in Conversational Speech Using Deep Unsupervised Learning","IEEE TRANSACTIONS ON AFFECTIVE COMPUTING","","1949-3045","10.1109/TAFFC.2020.3024972","","In interpersonal spoken interactions, individuals tend to adapt to their conversation partner's vocal characteristics to become similar, a phenomenon known as entrainment. A majority of the previous computational approaches are often knowledge driven and linear and fail to capture the inherent nonlinearity of entrainment. In this article, we present an unsupervised deep learning framework to derive a representation from speech features containing information relevant for vocal entrainment. We investigate both an encoding based approach and a more robust triplet network based approach within the proposed framework. We also propose a number of distance measures in the representation space and use them for quantification of entrainment. We first validate the proposed distances by using them to distinguish real conversations from fake ones. Then we also demonstrate their applications in relation to modeling several entrainment-relevant behaviors in observational psychotherapy, namely agreement, blame and emotional bond.","2022-07","2025-02-26 20:39:17","2025-02-26 20:39:17","","1651-1663","","3","13","","","","","","","","","","English","","","","WOS:000850863900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","BEHAVIOR; behavioral signal processing; COMPLEXITY; Computational modeling; conversations; deep learning; Encoding; Entrainment; Feature extraction; interaction; Medical treatment; Neural networks; NEURAL-NETWORKS; PHONETIC CONVERGENCE; Signal processing; SYNCHRONY; Training; triplet networks; unsupervised","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L6UFEUW6","journalArticle","2022","Xiang, XX; Zhang, XJ; Chen, HZ","A Nested U-Net With Self-Attention and Dense Connectivity for Monaural Speech Enhancement","IEEE SIGNAL PROCESSING LETTERS","","1070-9908","10.1109/LSP.2021.3128374","","With the development of deep neural networks, speech enhancement technology has been vastly improved. However, commonly used speech enhancement approaches cannot fully leverage contextual information from different scales, which limits performance improvement. To address this problem, we propose a nested U-Net with self-attention and dense connectivity (SADNUNet) for monaural speech enhancement in the time domain. SADNUNet is an encoder-decoder structure with skip connections. In SADNUNet, the multi-scale aggregation block is proposed to explore more contextual information from different scales. By this means, the advantage of global and local speech features can be fully utilized to improve speech reconstruction ability. Furthermore, dense connectivity and self-attention are incorporated in the network for better feature extraction and utterance level context aggregation. The experimental results demonstrate that the proposed approach achieves on-par or better performance than other models in objective speech intelligibility and quality scores.","2022","2025-02-26 20:39:17","2025-02-26 20:39:17","","105-109","","","29","","","","","","","","","","English","","","","WOS:000747445300002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;40<br/>Total Times Cited:&nbsp;&nbsp;43<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","CNN; Convolution; Decoding; dense connectivity; DILATED CONVOLUTIONS; Feature extraction; multi-scale aggregation block; NOISE; RECURRENT NEURAL-NETWORK; self-attention; Sensors; Signal to noise ratio; Speech enhancement; time-domain; Time-domain analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NI4MHXS9","journalArticle","2023","Xie, XP; Chen, YZ; Shen, RF; Tian, D","Research on monaural speech segregation based on feature selection","EURASIP JOURNAL ON AUDIO SPEECH AND MUSIC PROCESSING","","1687-4722","10.1186/s13636-023-00276-9","","Speech feature model is the basis of speech and noise separation, speech expression, and different styles of speech conversion. With the development of signal processing methods, the feature types and dimensions increase. Therefore, it is difficult to select appropriate features. If a single feature is used, the representation of the speech signal will be incomplete. If multiple features are used, there will be redundancy between features, which will affect the performance of speech separation. The feature described above is a combination of parameters to characterize speech. A single feature means that the combination has only one parameter. In this paper, the feature selection method is used to select and combine eight widely used speech features and parameters. The Deep Neural Network (DNN) is used to evaluate and analyze the speech separation effect of different feature groups. The comparison results show that the speech segregation effect of the complementary feature group is better. The effectiveness of the complementary feature group to improve the performance of DNN speech separation is verified.","2023-02-16","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","1","2023","","","","","","","","","","English","","","","WOS:000934521000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","Complementary feature group; Deep Neural Network (DNN); Feature selection; Group lasso; Monaural speech segregation; NOISE; REGRESSION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NM8424HJ","journalArticle","2021","Souli, S; Amami, R; Ben Yahia, S","A robust pathological voices recognition system based on DCNN and scattering transform","APPLIED ACOUSTICS","","0003-682X","10.1016/j.apacoust.2020.107854","","The Deep Neural Networks (DNNs) have recently shown a high performance applied to speech classification tasks. In this paper, we argue that the improved accuracy generated by the Deep Convolutional Neural Network (DCNN) classifier is the result of their ability to extract discriminative representations. They are efficient to the different sources of variability in speech signals. We propose, in this study, a new algorithm, called ST-DCNN in order to classify normal and pathological voices. We demonstrate the improvement of recognizing voices theory with advances in speech features in order to improve the identification pathological voices. The proposed approach operates in two steps: First, we extract scatter wavelet features. Then, we introduce the DCNN for voices classification. The performance of the proposed system is evaluated based on silent and noisy environments using various Signal-to-Noise Ratio (SNR) levels. The results underscore that our proposed system shows better performance using scattering wavelet and DCNN in a silent environment with 99.62% of recognition rate. (C) 2020 Elsevier Ltd. All rights reserved.","2021-06","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","177","","","","","","","","","","English","","","","WOS:000631292100003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","DCNN; Deep Learning; FEATURES; NEURAL-NETWORKS; Pathology recognition; Scattering transform","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FIEIKPAX","journalArticle","2021","Roberts, T; Nicolson, A; Paliwal, KK","Deep Learning-Based Single-Ended Quality Prediction for Time-Scale Modified Audio","JOURNAL OF THE AUDIO ENGINEERING SOCIETY","","1549-4950","10.17743/jaes.2021.0031","","Objective evaluation of audio processed with Time-Scale Modification (TSM) has recently seen improvement with a labeled time-scaled audio dataset used to train an objective measure. This double-ended measure was an extension of Perceptual Evaluation of Audio Quality and required reference and test signals. In this paper two single-ended objective quality measures for time-scaled audio are proposed that do not require a reference signal. Internal representations of spectrogram and speech features are learned by either a Convolutional Neural Network (CNN) or a Bidirectional Gated Recurrent Unit (BGRU) network and fed to a fully connected network to predict Subjective Mean Opinion Scores. The proposed CNN and BGRU measures respectively achieve average Root Mean Square Errors of 0.61 and 0.58 and mean Pearson Correlation Coefficients of 0.77 and 0.79 to the time-scaled audio dataset. The proposed measures are used to evaluate TSM algorithms and comparisons are provided for 15 TSM implementations. A link to implementations of the objective measures is provided.","2021-09","2025-02-26 20:39:17","2025-02-26 20:39:17","","644-655","","9","69","","","","","","","","","","English","","","","WOS:000729229700003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","ITU-T STANDARD; MODEL; SPEECH QUALITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JP8QKUZX","journalArticle","2022","Makhmudov, F; Kutlimuratov, A; Akhmedov, F; Abdallah, MS; Cho, YI","Modeling Speech Emotion Recognition via Attention-Oriented Parallel CNN Encoders","ELECTRONICS","","2079-9292","10.3390/electronics11234047","","Meticulous learning of human emotions through speech is an indispensable function of modern speech emotion recognition (SER) models. Consequently, deriving and interpreting various crucial speech features from raw speech data are complicated responsibilities in terms of modeling to improve performance. Therefore, in this study, we developed a novel SER model via attention-oriented parallel convolutional neural network (CNN) encoders that parallelly acquire important features that are used for emotion classification. Particularly, MFCC, paralinguistic, and speech spectrogram features were derived and encoded by designing different CNN architectures individually for the features, and the encoded features were fed to attention mechanisms for further representation, and then classified. Empirical veracity executed on EMO-DB and IEMOCAP open datasets, and the results showed that the proposed model is more efficient than the baseline models. Especially, weighted accuracy (WA) and unweighted accuracy (UA) of the proposed model were equal to 71.8% and 70.9% in EMO-DB dataset scenario, respectively. Moreover, WA and UA rates were 72.4% and 71.1% with the IEMOCAP dataset.","2022-12","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","23","11","","","","","","","","","","English","","","","WOS:000896175000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;18<br/>Total Times Cited:&nbsp;&nbsp;18<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","attention; convolution neural network; deep learning; modeling; speech emotion recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HJDZQLCT","journalArticle","2023","Park, D; Yu, YC; Katabi, D; Kim, HK","Adversarial Continual Learning to Transfer Self-Supervised Speech Representations for Voice Pathology Detection","IEEE SIGNAL PROCESSING LETTERS","","1070-9908","10.1109/LSP.2023.3298532","","In recent years, voice pathology detection (VPD) has received considerable attention because of the increasing risk of voice problems. Several methods, such as support vector machine and convolutional neural network-based models, achieve good VPD performance. To further improve the performance, we use a self-supervised pretrained model as feature representation instead of explicit speech features. When the pretrained model is fine-tuned for VPD, an overfitting problem occurs due to a domain shift from conversation speech to the VPD task. To mitigate this problem, we propose an adversarial task adaptive pretraining (A-TAPT) approach by incorporating adversarial regularization during the continual learning process. Experiments on VPD using the Saarbrucken Voice Database show that the proposed A-TAPT improves the unweighted average recall (UAR) by an absolute increase of 12.36% and 15.38% compared with SVM and ResNet50, respectively. It is also shown that the proposed A-TAPT achieves a UAR that is 2.77% higher than that of conventional TAPT learning.","2023","2025-02-26 20:39:17","2025-02-26 20:39:17","","932-936","","","30","","","","","","","","","","English","","","","WOS:001040020500004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Adversarial regularization; continual learning; FEATURES; fine-tuning; self-supervised pretrained model; voice pathology detection; wav2vec 2.0","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WJUHW2FB","journalArticle","2023","Li, L; Li, J; Wang, DY; Wang, XQ; Qiao, SS","Sinc-attention feature extraction for trivial-event based speaker verification","ELECTRONICS LETTERS","","0013-5194","10.1049/ell2.12812","","Human speech contains trivial events that are non-subjectively controlled and are limited by physical characteristics. These events are represented by a series of extremely short utterances, such as the 'hmm' phrase used for expressing doubt or confirmation. In speaker verification (SV), such events can be a robust choice to verify the real speaker from disguised speech since they are less affected by the randomness of pronunciation. However, trivial events like 'hmm' contain little linguistic information and are extremely short, thus the performance of SV systems will decrease drastically. In this letter, a Sinc-Attention feature extraction method is proposed to extract more discriminative speech features from speech signals to achieve a robust SV system for trivial events. Learnable filters are utilized to obtain low-level representations of the speech for SV. Moreover, a novel adaptive weighting of features inspired by attention mechanisms is proposed, which effectively improves the representation capability of speaker features. The experiments on different models prove that our method helps SV systems achieve a lower equal error rate (EER) than hand-crafted feature-based systems.","2023-05","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","9","59","","","","","","","","","","English","","","","WOS:000984732900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","feature extraction; RECOGNITION; speaker recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4FD28E7G","journalArticle","2023","Lamperski, A","Nonasymptotic Pointwise and Worst-Case Bounds for Classical Spectrum Estimators","IEEE TRANSACTIONS ON SIGNAL PROCESSING","","1053-587X","10.1109/TSP.2023.3330526","","Spectrum estimation is a fundamental methodology in the analysis of time-series data, with applications including medicine, speech analysis, and control design. The asymptotic theory of spectrum estimation is well-understood, but the theory is limited when the number of samples is fixed and finite. This paper gives non-asymptotic error bounds for a broad class of spectral estimators, both pointwise (at specific frequencies) and in the worst case over all frequencies. The general method is used to derive error bounds for the classical Blackman-Tukey, Bartlett, and Welch estimators. In particular, these are first non-asymptotic error bounds for Bartlett and Welch estimators.","2023","2025-02-26 20:39:17","2025-02-26 20:39:17","","4273-4287","","","71","","","","","","","","","","English","","","","WOS:001123968900007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","machine learning; nonparametric statistics; Time series analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C6YTHEHQ","journalArticle","2024","Jha, K; Srivastava, S; Jain, A","A novel speaker verification approach featuring multidomain acoustics based on the weighted city block Minkowski distance","ETRI JOURNAL","","1225-6463","10.4218/etrij.2023-0485","","Access control is vital in interconnected environments like the Internet of Things, Industry 4.0, and smart connectivity, ensuring authorized access for security. Biometric-based access, particularly speaker verification (SV), enhances security with unique vocal features, offering nonintrusive authentication with continuous monitoring. Single-domain features prove insufficient in distinguishing similar traits, prompting latest SV advancements to adopt multidomain-based speech features. This paradigm addresses the limitations of single-domain features by amalgamating the merits of individual domains, establishing a cutting-edge approach. It utilizes cepstral-frequency-time domain feature fusion, achieved via cepstral mean-variance normalization for generalizability. The weighted city block Minkowski distance is proposed to compare reference and test speech templates. Parameters are computed based on the confusion matrix, template matching distance functions, dynamic acoustic conditions, and additive white Gaussian noise. A deep convolutional neural network classifier is assessed on open-source LibriSpeech and Speaker in the Wild corpora, surpassing the current methodologies.","2024-08-19","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","","","","","","","","","","","English","","","","WOS:001293449500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","additive white Gaussian noise; deep convolutional neural network; multidomain acoustic feature; speaker verification; weighted distance function","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J7NIUDN5","journalArticle","2023","Wang, YY; Gu, Y; Yin, YF; Han, YP; Zhang, H; Wang, S; Li, CY; Quan, D","Multimodal transformer augmented fusion for speech emotion recognition","FRONTIERS IN NEUROROBOTICS","","1662-5218","10.3389/fnbot.2023.1181598","","Speech emotion recognition is challenging due to the subjectivity and ambiguity of emotion. In recent years, multimodal methods for speech emotion recognition have achieved promising results. However, due to the heterogeneity of data from different modalities, effectively integrating different modal information remains a difficulty and breakthrough point of the research. Moreover, in view of the limitations of feature-level fusion and decision-level fusion methods, capturing fine-grained modal interactions has often been neglected in previous studies. We propose a method named multimodal transformer augmented fusion that uses a hybrid fusion strategy, combing feature-level fusion and model-level fusion methods, to perform fine-grained information interaction within and between modalities. A Model-fusion module composed of three Cross-Transformer Encoders is proposed to generate multimodal emotional representation for modal guidance and information fusion. Specifically, the multimodal features obtained by feature-level fusion and text features are used to enhance speech features. Our proposed method outperforms existing state-of-the-art approaches on the IEMOCAP and MELD dataset.","2023-05-22","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","17","","","","","","","","","","English","","","","WOS:001000081800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;12<br/>Total Times Cited:&nbsp;&nbsp;14<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","hybrid fusion; modal interaction; multimodal enhancement; speech emotion recognition; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FII85NI4","journalArticle","2023","Sun, H; Gao, X; Guo, LY; Tao, LQ; Guo, ZH; Shao, YS; Cui, TR; Yang, Y; Pu, X; Ren, TL","Graphene-based dual-function acoustic transducers for machine learning-assisted human-robot interfaces","INFOMAT","","2567-3165","10.1002/inf2.12385","","Human-robot interface (HRI) electronics are critical for realizing robotic intelligence. Here, we report graphene-based dual-function acoustic transducers for machine learning-assisted human-robot interfaces (GHRI). The GHRI functions both an artificial ear through the triboelectric acoustic sensing mechanism and an artificial mouth through the thermoacoustic sound emission mechanism. The success of the integrated device is also attributed to the multifunctional laser-induced graphene, as either triboelectric materials, electrodes, or thermoacoustic sources. By systematically optimizing the structure parameters, the GHRI achieves high sensitivity (4500 mV Pa-1) and operating durability (1 000 000 cycles and 60 days), capable of recognizing speech identities, emotions, content, and other information in the human speech. With the assistance of machine learning, 30 speech categories are trained by a convolutional neural network, and the accuracy reaches 99.66% and 96.63% in training datasets and test datasets. Furthermore, GHRI is used for artificial intelligence communication based on recognized speech features. Our work shows broad prospects for the development of robotic intelligence.","2023-02","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","2","5","","","","","","","","","","English","","","","WOS:000880012000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;67<br/>Total Times Cited:&nbsp;&nbsp;69<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","DESIGN; human-robot interface; laser-induced graphene; machine learning; SPEECH RECOGNITION; thermoacoustic; TRANSPARENT; triboelectric nanogenerator; TRIBOELECTRIC NANOGENERATOR","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MIPF8JRZ","journalArticle","2023","Sim, JH","Negotiating social meanings in a plural society: Social perceptions of variants of /l/ in Singapore English","LANGUAGE IN SOCIETY","","0047-4045","10.1017/S0047404522000173","","This study illustrates how speech features that emerged from language contact and acquisition in a pluralistic society can accrue diverse social-indexical meanings over time. The social perceptions towards three variants of coda /l/ in Singapore English-namely dark-l, the variant associated with prescriptive norms, and clear-l and vocalised-l, which are variants that arose through language contact-are examined. The findings show that clear-l and vocalised-l are associated with specific ethnic groups and have equally diverse meanings, but their meanings have evolved differently; vocalised-l is an emerging local standard, whereas clear-l remains largely stigmatised Their diverse meanings are shown to be connected by social factors within a network of interrelated signs, and their interpretations are dependent on the hearer's experiences, such that we are observing different parts of the sociolinguistic reality. Restricted experiences with the social world and regulation of social perception are also shown to potentially contribute to accent-based prejudices.","2023-09","2025-02-26 20:39:17","2025-02-26 20:39:17","","617-644","","4","52","","","","","","","","","","English","","","","WOS:000792339100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","ethnolect; ETHNOLECTS; Indexicality; LANGUAGE; language contact; lateral consonant; LATERALS; LISTENER; new Englishes; REPERTOIRE; social perception","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CAIVAC58","journalArticle","2021","Ma, ZQ; Zhang, JP; Li, TY; Yang, R; Wang, HB","A Parameter Transfer Method for an HMM-DNN Heterogeneous Model Using a Scarce Mongolian Language Data Set","ELEKTROTEHNISKI VESTNIK","","0013-5852","","","The Hidden Markov Model-Deep Neural Network (HMM-DNN) is one of the most successful architectures in the speech recognition. Although HMM-DNN achieves state-of-the-art results in the English and Mandarin language, and there are many un-updated parameters in the training of the HMM-DNN acoustic model on a small-scale Mongolian data set. This involves the model network training under-fitted to learn the data set features. In a speech-recognition scenario, the under-fitting of speech features leads to a problem of the system accuracy. The paper defines a concept of a homogeneous heterogeneous model and proposes a parameter learning method for the HMM-DNN heterogeneous model for a scarce Mongolian data set. KALDI is used as an experimental platform, the TIMIT English data set as a source data set, and the scarce Mongolian data set as a target data set. Using the proposed parameter transfer method, a considerably improved recognition accuracy for the Mongolian data set is achieved.","2021","2025-02-26 20:39:17","2025-02-26 20:39:17","","33-40","","1-2","88","","","","","","","","","","English","","","","WOS:000654215500005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","Heterogeneous Model; HMM-DNN Model; Homogeneous Model; Parameter Transfer; RECOGNITION; Transfer Learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L6RZJB2L","journalArticle","2022","Lu, SJ; Abozinadah, E; Erkec, E","Image design and interaction technology based on Fourier inverse transform","APPLIED MATHEMATICS AND NONLINEAR SCIENCES","","2444-8656","10.2478/amns.2021.1.00061","","As one of the main directions of applied mathematics research, inverse Fourier transform (FT) has been widely used in image speech analysis and other fields in recent decades of development. FT is the basic content of digital image processing technology. In practical analysis, image design and interaction can be realised by using time-space domain and frequency domain, which can accurately obtain image information characteristics and achieve the expected application goals. In this paper, based on the understanding of FT and inverse transform, an improved algorithm is used to lay the foundation for the realisation of image design and interactive technology.","2022-07-01","2025-02-26 20:39:17","2025-02-26 20:39:17","","493-502","","2","7","","","","","","","","","","English","","","","WOS:000734598000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;8</p>","","","Fourier transform; Image design; Improved algorithm; Interactive technology; Inverse Fourier transform; MATLAB","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XTGQT9VQ","journalArticle","2023","Yi, YF; Tian, Y; He, C; Fan, YJ; Hu, XL; Xu, YP","DBT: multimodal emotion recognition based on dual-branch transformer","JOURNAL OF SUPERCOMPUTING","","0920-8542","10.1007/s11227-022-05001-5","","There are very few labeled datasets in speech emotion recognition. The reason is that emotion is subjective and requires much time for labeling experts to identify emotion categories, while the wav2vec2.0 model is a general model for obtaining speech representations through self-supervised training. Therefore, we try to apply it to speech-emotion recognition tasks. We propose a multimodal dual-branch transformer network. For the speech processing branch, first, we use wav2vec2.0 to extract speech features. Then, a fine-tuning strategy and a self-attention-based inter-layer feature fusion strategy are used. Second, a fully convolutional classification network is used for emotion classification. Then, we use RoBERTa for text emotion recognition and bimodal fusion by an improved weighted Dempster-Shafer (DS) strategy. In addition, we propose an accuracy-weighted label smoothing method, which can improve recognition accuracy. We perform comprehensive experiments on two benchmarks: IEMOCAP and CASIA, covering both Chinese and English datasets. The experimental results show that the proposed method has higher accuracy than state-of-the-art methods.","2023-05","2025-02-26 20:39:17","2025-02-26 20:39:17","","8611-8633","","8","79","","","","","","","","","","English","","","","WOS:000901675100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Adaptive interlayer fusion; Model fine-tuning; wav2vec2.0; Weighted DS strategy; Weighted label smoothing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VN7R9ENP","journalArticle","2021","Zhang, HY; Huang, HM; Han, H","Attention-Based Convolution Skip Bidirectional Long Short-Term Memory Network for Speech Emotion Recognition","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2020.3047395","","Speech emotion recognition is a challenging task in natural language processing. It relies heavily on the effectiveness of speech features and acoustic models. However, existing acoustic models may not handle speech emotion recognition efficiently for their built-in limitations. In this work, a novel deep-learning acoustic model called attention-based skip convolution bi-directional long short-term memory, abbreviated as SCBAMM, is proposed to recognize speech emotion. It has eight hidden layers, namely, two dense layers, convolutional layer, skip layer, mask layer, Bi-LSTM layer, attention layer, and pooling layer. SCBAMM makes better use of spatiotemporal information and captures emotion-related features more effectively. In addition, it solves the problems of gradient exploding and gradient vanishing in deep learning to some extent. On the databases EMO-DB and CASIA, the proposed model SCBAMM achieves an accuracy rate of 94.58% and 72.50%, respectively. As far as we know, compared with peer models, this is the best accuracy rate.","2021","2025-02-26 20:39:17","2025-02-26 20:39:17","","5332-5342","","","9","","","","","","","","","","English","","","","WOS:000608206600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;77</p>","","","attention mechanism; Emotion recognition; MODEL; NEURAL-NETWORK; skip connection; SPECTRAL FEATURES; weighted pooling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H9RNVN6D","journalArticle","2025","Missaoui, I; Lachiri, Z","Stationary wavelet Filtering Cepstral coefficients (SWFCC) for robust speaker identification","APPLIED ACOUSTICS","","0003-682X","10.1016/j.apacoust.2024.110435","","Extracting robust effective speech features is one of the challenging topics in the speaker recognition field, especially in noisy conditions. It can substantially improve the robustness recognition accuracy of persons from their voice signals against such conditions. This paper proposes a new feature extraction approach called Stationary Wavelet Filtering Cepstral Coefficients (SWFCC) for noisy speaker recognition. The proposed approach incorporates a Stationary Wavelet Filterbank (SWF) and an Implicit Wiener Filtering (IWF) technique. The SWF is based on the stationary wavelet packet transform, which is a shift-invariant transform. The performance of the proposed SWFCC approach is evaluated on the TIMIT dataset in the presence of different types of environmental noise, which are taken from the Aurora dataset. Our experimental results using the Gaussian Mixture ModelUniversal Background Model (GMM-UBM) as a classifier show that SWFCC outperforms various feature extraction techniques like MFCC, PNCC, and GFCC in terms of recognition accuracy.","2025-03-01","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","231","","","","","","","","","","English","","","","WOS:001385776200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","coefficients; Feature extraction; GMM-UBM; Implicit wiener filtering; PACKET; Robust speaker recognition; SPEECH WAVE; Stationary wavelet filtering cepstral; Stationary wavelet packet transform; SWFCC; SWT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T75DZ7QE","journalArticle","2021","Feng, Y; Cheng, Y","Short Text Sentiment Analysis Based on Multi-Channel CNN With Multi-Head Attention Mechanism","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2021.3054521","","In view of the limited text features of short texts, features of short texts should be mined from various angles, and multiple sentiment feature combinations should be used to learn the hidden sentiment information. A novel sentiment analysis model based on multi-channel convolutional neural network with multi-head attention mechanism (MCNN-MA) is proposed. This model combines word features with part of speech features, position features and dependency syntax features separately to form three new combined features, and inputs them into the multi-channel convolutional neural network, as well as integrates the multi-head attention mechanism to more fully learn the sentiment information in the text. Finally, experiments are carried out on two Chinese short text data sets. The experimental results show that the MCNN-MA model has a higher classification accuracy and a relatively low training time cost compared with other baseline models.","2021","2025-02-26 20:39:17","2025-02-26 20:39:17","","19854-19863","","","9","","","","","","","","","","English","","","","WOS:000615025800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;50<br/>Total Times Cited:&nbsp;&nbsp;54<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","Analytical models; CLASSIFICATION; convolutional neural network; Convolutional neural networks; Data models; Dictionaries; Feature extraction; multi-channel; multi-head attention mechanism; Sentiment analysis; short text; Syntactics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3UCVC3UJ","journalArticle","2024","Wu, D; Zheng, YY; Cheng, P","Triple Channel Feature Fusion Few-Shot Intent Recognition With Orthogonality Constrained Multi-Head Attention","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3369902","","Intent recognition in few-shot scenarios is a hot research topic in natural language understanding tasks. Aiming at the problems of insufficient consideration of fine-grained features of the text and insufficient training of features in the process of model fine-tuning, the Triple Channel IntentBERT and Orthogonality Constrained Multi-Head Attention Model (TMH-IntentBERT) is proposed. The part-of-speech features, word features and keyword features are combined to extract fine-grained features of data. And the a priori knowledge of the text is fully utilized. Context information is captured through multi-head attention to learn diversified representations. At the same time, the context and score vector regularization terms are added to reduce the position and representation redundancy between heads and enhance the diversity. The experimental results show that on the public dataset, the TMH-IntentBERT model has a minimum increase of 0.63%, 0.73%, 0.79%, and 1.10% in accuracy, precision, F1 value and AUROC compared with CONVBERT, TOD-BERT, WikiHowRoBERTA, IntentBERT and DFT++, respectively.","2024","2025-02-26 20:39:17","2025-02-26 20:39:17","","31685-31696","","","12","","","","","","","","","","English","","","","WOS:001173310600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","feature fusion; few-shot; IntentBERT; Intention recognition; multi-head attention; NETWORK","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7CEYGQ32","journalArticle","2023","Jia, HC","Simulation of English part-of-speech classification based on artificial intelligence and additive logistic regression","SOFT COMPUTING","","1432-7643","10.1007/s00500-023-08490-5","","English part-of-speech classification technology is a technology that can process text data, can effectively solve the problem of messy data in text information categories, make data structured and organized, and facilitate people to obtain effective information implicit in the text. This article transforms the original polynomial distribution into a generalized linear model and uses logistic regression algorithm for specific implementation. Moreover, the model proposed in this paper inherits the good explanatory characteristics of the decision tree, and it locally uses logistic regression to fit the data, which greatly improves the function space that logistic regression can fit. In addition, due to changes in the decision theory of logistic regression leaf nodes, the corresponding tree branch theory also needs to be changed accordingly. Finally, this paper designs experiments to study the performance of the model constructed in this paper. The research results show that the model constructed in this paper has high accuracy in the extraction and classification of English part-of-speech features.","2023-05-29","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","","","","","","","","","","","English","","","","WOS:000998543000009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;15</p>","","","Additive logistic regression; Artificial intelligence; Classification; English part of speech; Machine recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"62B63CNH","journalArticle","2024","Liu, YM; Luo, Q","DEEP MACHINE LEARNING-BASED ANALYSIS FOR INTELLIGENT PHONETIC LANGUAGE RECOGNITION","SCALABLE COMPUTING-PRACTICE AND EXPERIENCE","","1895-1767","10.12694/scpe.v25i3.2710","","Modern speech generating systems can produce results that are almost as visually realistic as actual sounds. They still require further production management. This research presents a paradigm for managing prosodic output using explicit, unambiguous, and understandable parameters. We utilize this strategy to emphasize key words and provide a variety of architectural possibilities based on a richness of labelled resources. In an objective voice, we compare the options for producing data with or without labels. We assess them using listening tests that demonstrate our ability to retain the same level of naturalness while effectively attaining regulated concentration over a specific area.","2024-04-12","2025-02-26 20:39:17","2025-02-26 20:39:17","","1557-1563","","3","25","","","","","","","","","","English","","","","WOS:001206408600025","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","lexical focus; machine learning; MEMS; Prosody management; SENSOR; speech analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LAJV7GDV","journalArticle","2022","Zhao, M; Li, J; Xiang, LQ; Zhang, ZH; Peng, SL","A diagnosis model of dementia via machine learning","FRONTIERS IN AGING NEUROSCIENCE","","1663-4365","10.3389/fnagi.2022.984894","","As the aging population poses serious challenges to families and societies, the issue of dementia has also received increasing attention. Dementia detection often requires a series of complex tests and lengthy questionnaires, which are time-consuming. In order to solve this problem, this article aims at the diagnosis method of questionnaire survey, hoping to establish a diagnosis model to help doctors make a diagnosis through machine learning method, and use feature selection method to select important questions to reduce the number of questions in the questionnaire, so as to reduce medical and time costs. In this article, Clinical Dementia Rating (CDR) is used as the data source, and various methods are used for modeling and feature selection, so as to combine similar attributes in the data set, reduce the categories, and finally use the confusion matrix to judge the effect. The experimental results show that the model established by the bagging method has the best effect, and the accuracy rate can reach 80% of the true diagnosis rate; in terms of feature selection, the principal component analysis (PCA) has the best effect compared with other methods.","2022-09-07","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","14","","","","","","","","","","English","","","","WOS:000856138100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","bagging; dementia; diagnosis model; machine learning; principal component analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3ZPV2IDR","journalArticle","2022","Ruthirakuhan, M; Ismail, Z; Herrmann, N; Gallagher, D; Lanctôt, KL","Mild behavioral impairment is associated with progression to Alzheimer's disease: A clinicopathological study","ALZHEIMERS & DEMENTIA","","1552-5260","10.1002/alz.12519","","Introduction Mild behavioral impairment (MBI) is characterized by later-life emergence of neuropsychiatric symptoms. Investigating its relationship with progression to Alzheimer's disease (AD) would provide insight on its importance as a predictor of AD. Methods Cognitively normal participants (N = 11,372) from the National Alzheimer's Coordinating Center were stratified by MBI status, using the Neuropsychiatric Inventory-Questionnaire. We investigated whether MBI and its domains were predictors of progression to clinically-diagnosed AD. MBI as a predictor of progression to neuropathology-confirmed AD was also investigated in those with neuropathological data. Results Six percent (N = 671) of participants progressed to AD. MBI (N = 2765) was a significant predictor of progression to clinically-diagnosed (hazard ratio [HR] = 1.75) and neuropathology-confirmed AD (HR = 1.59). MBI domains were also associated with clinically-diagnosed AD, with psychosis having the greatest effect (HR = 6.49). Discussion These findings support the biological underpinnings of MBI, emphasizing the importance of later life behavioral changes in dementia detection and prognostication.","2022-11","2025-02-26 20:39:17","2025-02-26 20:39:17","","2199-2208","","11","18","","","","","","","","","","English","","","","WOS:000748893300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;37<br/>Total Times Cited:&nbsp;&nbsp;37<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Alzheimer's disease; CHECKLIST; COGNITIVE IMPAIRMENT; DEMENTIA; DISORDERS; GUIDELINES; mild behavioral impairment; NATIONAL INSTITUTE; NEURODEGENERATION; neuropathology; neuropsychiatric symptoms; NEUROPSYCHIATRIC SYMPTOMS; PREVALENCE; RISK-FACTORS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MA7D9SG5","journalArticle","2024","Walker, GM; Fridriksson, J; Hickok, G","Assessing Relative Linguistic Impairment With Model-Based Item Selection","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2024_JSLHR-23-00439","","Purpose: A picture naming test is presented that reveals impairment to specific mechanisms involved in the naming process, using accuracy scores on curated item sets. A series of psychometric validation experiments are reported. Method: Using a computational model that enables estimation of item difficulty at the lexical and sublexical stages of word retrieval, two complimentary sets of items were constructed that challenge the respective psycholinguistic levels of representation. The difference in accuracy between these item sets yields the relative linguistic impairment (RLI) score. In a cohort of 91 people with chronic left-hemisphere stroke who enrolled in a clinical trial for anomia, we assessed psychometric properties of the RLI score and then used the new scale to make predictions about other language behaviors, lesion distributions, and functional activation during naming. Results: RLI scores had adequate psychometric properties for clinical significance. RLI scores contained predictive information about spontaneous speech fluency, over and above accuracy. A dissociation was observed between performance on the RLI item sets and performance on the subtests of an independent language battery. Sublexical RLI was significantly associated with apraxia of speech and with lesions encompassing perisylvian regions, while lexical RLI was associated with lesions to deep white matter. The RLI construct was reflected in functional brain activity during naming, independent of overall accuracy, with a respective shift of activation between dorsal and ventral networks responsible for different aspects of word retrieval. Conclusion: The RLI assessment satisfies the psychometric requirements to serve as a useful clinical measure.","2024-08","2025-02-26 20:39:17","2025-02-26 20:39:17","","2600-2619","","8","67","","","","","","","","","","English","","","","WOS:001299611300008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;83</p>","","","ANOMIA; APHASIA; LEXICAL ACCESS; NAMING ERRORS; RETRIEVAL; SEMANTIC INTERFERENCE; SHORT FORMS; SPEECH; THERAPY; WORD PRODUCTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7BDG9BSP","journalArticle","2024","Rechenberg, L; Meurer, EM; Melos, M; Nienov, OH; Corleta, HV; Capp, E","Voice, Speech, and Clinical Aspects During Pregnancy: A Longitudinal Study","JOURNAL OF VOICE","","0892-1997","10.1016/j.jvoice.2022.04.019","","Background. Pregnancy involves anatomical, physiological, and metabolic changes in a woman's body. However, the effects of these changes on the voice remains unclear, particularly regarding the clinical characteristics. Objectives. We aimed to evaluate changes in vocal and speech acoustic measures and the relationship between them and clinical aspects in women during pregnancy. Method. A prospective, longitudinal study was carried out with 41 low risk, adult, pregnant women, followed for prenatal care. Demographic and anthropometric data as well as lifestyle habits and health conditions were collected. Voice recordings of sustained vowels, and automatic and spontaneous speech were held over each trimester and analyzed by PRAAT degrees to evaluate acoustic, aerodynamic, and articulatory measures. Results. There were no changes in fundamental frequency, jitter, shimmer, and harmony to noise ratio during pregnancy. Maximum phonation time (MPT), pause rate, and pause duration reduced at the end of pregnancy. MPT was lower in sedentary pregnant women. The fundamental frequency peak rate was higher in eutrophic participants and lower in the third trimester in women with BMI >= 25 kg/m2. Pause rate was higher in pregnant women with BMI >= 25 kg/m2. There was no relationship between sleep quality, reflux, and vocal symptoms and acoustic and aerodynamic measures. Conclusions. Differences were shown in MPT and temporal pause measurements during pregnancy. Acoustic measurements did not change. There was a relationship between acoustic and aerodynamic measures and clinical variables (BMI, physical activity, and body mass gain).","2024-12","2025-02-26 20:39:17","2025-02-26 20:39:17","","1431-1438","","6","38","","","","","","","","","","English","","","","WOS:001364808100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","DISEASE; LIFE; PATTERNS; phonation-Body mass index-Physical activity; Pregnancy-Speech acoustics-Voice; QUALITY; VALIDATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6FFHB55K","journalArticle","2024","Davidson, L; Jones, OP","The role of recoverability in the implementation of non-phonemic glottalization in Hawaiian","LINGUISTICS VANGUARD","","2199-174X","10.1515/lingvan-2023-0060","","Previous research has shown that non-phonemic uses of glottalization are often prosodically determined in a variety of languages such as English, German, Polish, and Spanish. We examine the use of inserted glottalization in Hawaiian, a language that also has a phonemic glottal stop, to determine whether the distribution and realization of non-phonemic glottalization is conditioned by higher prosodic boundaries and/or prosodic prominence as found in other languages. The spontaneous speech data in this study comes from the Hawaiian-language radio program Ka Leo Hawai'i, which featured interviews with bilingual Hawaiian-English speakers in the 1970s and 1980s (Kimura, Larry (Producer). 2020. Ka Leo Hawai'i [radio program]. Kani'& amacr;ina, the digital repository of Ka Haka 'Ula O Ke'elik & omacr;lani, College of Hawaiian Language, University of Hawai'i at Hilo. Available at: https://ulukau.org/kaniaina/). Results show that non-phonemic glottalization occurs most often before an unstressed, monophthongal single-vowel grammatical marker (/a e i o/), where it is also longer, as well as before unstressed vowels and between different flanking sounds. Full closures were more likely between identical vowels, but stress does not affect realization. These results are not consistent with the use of glottalization at higher prosodic boundaries or to mark prosodic prominence. Instead, the preponderance of non-phonemic glottalization before single-vowel grammatical markers may be to ensure that these critical markers are recoverable and not perceptually subsumed by the preceding vowel.","2024-12-31","2025-02-26 20:39:17","2025-02-26 20:39:17","","3-15","","1","10","","","","","","","","","","English","","","","WOS:001235067600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","ENGLISH; glottalization; Hawaiian; INITIAL VOWELS; PERCEPTION; prosody; recoverability; SEGMENTS; VOICE QUALITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W3YPQTU4","journalArticle","2023","Braun, A; Elsässer, N; Willems, L","Disfluencies Revisited-Are They Speaker-Specific?","LANGUAGES","","2226-471X","10.3390/languages8030155","","The forensic application of phonetics relies on individuality in speech. In the forensic domain, individual patterns of verbal and paraverbal behavior are of interest which are readily available, measurable, consistent, and robust to disguise and to telephone transmission. This contribution is written from the perspective of the forensic phonetic practitioner and seeks to establish a more comprehensive concept of disfluency than previous studies have. A taxonomy of possible variables forming part of what can be termed disfluency behavior is outlined. It includes the ""classical"" fillers, but extends well beyond these, covering, among others, additional types of fillers as well as prolongations, but also the way in which fillers are combined with pauses. In the empirical section, the materials collected for an earlier study are re-examined and subjected to two different statistical procedures in an attempt to approach the issue of individuality. Recordings consist of several minutes of spontaneous speech by eight speakers on three different occasions. Beyond the established set of hesitation markers, additional aspects of disfluency behavior which fulfill the criteria outlined above are included in the analysis. The proportion of various types of disfluency markers is determined. Both statistical approaches suggest that these speakers can be distinguished at a level far above chance using the disfluency data. At the same time, the results show that it is difficult to pin down a single measure which characterizes the disfluency behavior of an individual speaker. The forensic implications of these findings are discussed.","2023-09","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","3","8","","","","","","","","","","English","","","","WOS:001071742400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;81</p>","","","BREATHING PATTERNS; ER; FILLED PAUSES; fillers; forensic voice comparison; HESITATION PHENOMENA; hesitations; INDIVIDUALITY; lengthening; MARKERS; paraverbal behavior; SIGNAL; SPEECH; UH; UM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EUKITA2Z","journalArticle","2023","Yu, MM; Qin, F","Research on the Applicability of Transformer Model in Remote-Sensing Image Segmentation","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13042261","","Transformer models have achieved great results in the field of computer vision over the past 2 years, drawing attention from within the field of remote sensing. However, there are still relatively few studies on this model in the field of remote sensing. Which method is more suitable for remote-sensing segmentation? In particular, how do different transformer models perform in the face of high-spatial resolution and the multispectral resolution of remote-sensing images? To explore these questions, this paper presents a comprehensive comparative analysis of three mainstream transformer models, including the segmentation transformer (SETRnet), SwinUnet, and TransUnet, by evaluating three aspects: a visual analysis of feature-segmentation results, accuracy, and training time. The experimental results show that the transformer structure has obvious advantages for the feature-extraction ability of large-scale remote-sensing data sets and ground objects, but the segmentation performance of different transfer structures in different scales of remote-sensing data sets is also very different. SwinUnet exhibits better global semantic interaction and pixel-level segmentation prediction on the large-scale Potsdam data set, and the SwinUnet model has the highest accuracy metrics for KAPPA, MIoU, and OA in the Potsdam data set, at 76.47%, 63.62%, and 85.01%, respectively. TransUnet has better segmentation results in the small-scale Vaihingen data set, and the three accuracy metrics of KAPPA, MIoU, and OA are the highest, at 80.54%, 56.25%, and 85.55%, respectively. TransUnet is better able to handle the edges and details of feature segmentation thanks to the network structure together built by its transformer and convolutional neural networks (CNNs). Therefore, TransUnet segmentation accuracy is higher when using a small-scale Vaihingen data set. Compared with SwinUnet and TransUnet, the segmentation performance of SETRnet in different scales of remote-sensing data sets is not ideal, so SETRnet is not suitable for the research task of remote-sensing image segmentation. In addition, this paper discusses the reasons for the performance differences between transformer models and discusses the differences between transformer models and CNN. This study further promotes the application of transformer models in remote-sensing image segmentation, improves the understanding of transformer models, and helps relevant researchers to select a more appropriate transformer model or model improvement method for remote-sensing image segmentation.","2023-02","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","4","13","","","","","","","","","","English","","","","WOS:000938804000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","CLASSIFICATION; deep learning; LAND-COVER; multihead attention; RANDOM FOREST; remote-sensing image segmentation; SETRnet; SUPPORT-VECTOR-MACHINE; SwinUner; transformer; TransUnet; visual classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EHUNWMZ6","journalArticle","2023","Çokal, D; Palominos-Flores, C; Yalinçetin, B; Türe-Abaci, O; Bora, E; Hinzen, W","Referential noun phrases distribute differently in Turkish speakers with schizophrenia","SCHIZOPHRENIA RESEARCH","","0920-9964","10.1016/j.schres.2022.06.024","","In all human languages, noun phrases (NPs) (e.g., 'a field', 'the woman with a book') are used to identify entities in discourse. Previous evidence has shown that the spontaneous speech of patients with schizophrenia (Sz) shows differences in the distribution of grammatically different types of NPs, which are in part specific to patients with formal thought disorder (FTD). Here we sought to provide the first evidence of related grammatical effects in a non-Indo-European language. Results from a picture description task in a sample of 16 Turkish speakers with FTD (+FTD), 15 without FTD (-FTD), and 27 controls revealed that relative to controls, people with Sz over-produced NPs that are 'bare' (in the sense of lacking any grammatical items such as the or a in English). The +FTD group generally showed stronger effects than -FTD, and used more pronouns and less NPs co-referring with previously mentioned NPs. In addition, the dynamic distribution of NP types over narrative time showed an effect of increased mean distance between definite NPs in -FTD relative to controls. In +FTD but no other group there was an unexpected random distribution of indefinite DPs. Incidence rates of referential anomalies increased from controls to the -FTD and +FTD groups. These findings further confirm that Sz is manifest through specific linguistic effects in the referential structure of meaning as mediated by grammar. They provide a linguistic baseline for neurocognitive models of FTD and help to define appropriate targets for the automatic extraction of linguistic features to classify psychotic speech.","2023-09","2025-02-26 20:39:17","2025-02-26 20:39:17","","104-110","","","259","","","","","","","","","","English","","","","WOS:001103890800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","Formal thought disorder; LANGUAGE; Language in psychosis; Noun phrases; PSYCHOSIS; Reference; THOUGHT; Turkish","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZPRG4U84","journalArticle","2022","Mok, XTJ; Goh, SL; Saddy, JD; Varley, R; Zimmerer, V","Language production and implicit statistical learning in typical development and children with acquired language disorders: an exploratory study","SPEECH LANGUAGE AND HEARING","","2050-571X","10.1080/2050571X.2021.1954837","","Statistical properties of language provide important cues for language learning and may be processed by domain-general cognitive systems. We investigated the relationship between implicit statistical learning (the unconscious detection of statistical regularities in input) and language production. Twenty typically developing (TD) children and nine children with acquired language disorders (ALD) (aged 6-18 years) took part in a Boston Cookie Theft picture description task. Using a computerized analysis, we investigated statistical properties, such as usage frequency of words and collocation strength of word combinations. Participants also completed a non-linguistic serial reaction time (SRT) task, which tested non-verbal, implicit statistical learning in the visual-motor modality. We determined age effects, and compared language production and SRT performance between both groups. Older TD children produced more connected language, more words, less frequent function words, more rare or novel combinations, and showed better statistical learning. Children with ALD produced less connected language, more weakly collocated combinations, displayed less lexical diversity and showed poorer statistical learning. Posthoc analyses found correlations between statistical learning and statistical properties of spoken language. Given the rarity and heterogeneity of children with ALD, group size was small and the study should be considered exploratory. However, we note that results are compatible with the view that language production draws on statistical learning and that impairment of statistical learning can be related to language disorders.","2022-07-03","2025-02-26 20:39:17","2025-02-26 20:39:17","","349-363","","3","25","","","","","","","","","","English","","","","WOS:000687776200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","Acquired language disorder; ACQUISITION; APHASIA; DISSOCIATION; FORMULAIC LANGUAGE; FREQUENCY; GRAMMAR; INDIVIDUALS; language production; paediatric; SEGMENTATION; sequential learning; SPONTANEOUS SPEECH; TIME; typical development","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CL2J48HP","journalArticle","2022","Liao, JW; Shi, Y; Xu, Y","Automatic Speech Recognition Post-Processing for Readability: Task, Dataset and a Two-Stage Pre-Trained Approach","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3219838","","Nowadays Automatic Speech Recognition (ASR) systems can accurately recognize which words are said. However, due to the disfluency, grammatical error, and other phenomena in spontaneous speech, the verbatim transcription of ASR impairs its readability, which is crucial for human comprehension and downstream tasks processing that need to understand the meaning and purpose of what is spoken. In this work, we formulate the ASR post-processing for readability (APR) as a sequence-to-sequence text generation problem that aims to transform the incorrect and noisy ASR output into readable text for humans and downstream tasks. We leverage the Metadata Extraction (MDE) corpus to construct a task-specific dataset for our study. To solve the problem of too little training data, we propose a novel data augmentation method that synthesizes large-scale training data from the grammatical error correction dataset. We propose a model based on the pre-trained language model to perform the APR task and train the model with a two-stage training strategy to better exploit the augmented data. On the constructed test set, our approach outperforms the best baseline system by a large margin of 17.53 on BLEU and 13.26 on readability-aware WER (RA-WER). The human evaluation also shows that our model can generate more human-readable transcripts than the baseline method.","2022","2025-02-26 20:39:17","2025-02-26 20:39:17","","117053-117066","","","10","","","","","","","","","","English","","","","WOS:000881971000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;86</p>","","","Annotations; ASR post-processing for readability; Automatic post-editing; Automatic speech recognition; Bit error rate; CAPITALIZATION; data augmentation; Data augmentation; natural language processing; Natural language processing; pre-trained language model; PUNCTUATION; Task analysis; Training data; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FFSBD8FL","journalArticle","2023","Lelandais, M; Thiberge, G","The role of prosody and hand gestures in the perception of boundaries in speech","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2023.05.001","","This paper investigates the use of prosodic, gestural, and syntactic information in the perception of boundaries in extracts of spontaneous speech in British English. Experiment 1 aimed at investigating the effect of prosody on naive participants' perception of boundary strength. 13 naive listeners had to rate boundary strength for 64 extracts on a 5-point scale. The stimuli all contained three tone-units, the second being a syntactic subordinate construction, which was established as a variable. The prosodic cues at the boundary between the tone-units were also established as variables, and were subject to manipulation (addition of a single cue associated with the perception of a prosodic boundary). Experiment 2 aimed at assessing the effect of gesture on naive participants' perception of boundary strength. In Experiment 2, 24 naive listeners had to measure boundary strength for 24 extracts on a 5-point scale. The stimuli all contained three tone-units, the second being a syntactic subordinate construction, which was established as a variable. The hand gestures produced in co-occurrence with the tone-units were established as variables, and were subject to manipulation. Results show that prosody modulates perceived boundary strength, but not gesture, based on the variables we included. Silent pauses have the strongest effect on perceived boundary strength, but final syllabic lengthening and pitch reset also have separate effects as single predictors. Our data also shows a trend concerning the production of two identical hand gestures in terms of configuration and trajectory.","2023-05","2025-02-26 20:39:17","2025-02-26 20:39:17","","41-65","","","150","","","","","","","","","","English","","","","WOS:001000636200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;157</p>","","","ALIGNMENT; APPOSITIVE RELATIVE CLAUSES; COORDINATION; Gesture; INTONATION; LISTENERS; MIXED MODELS; Perception; PROMINENCE; Prosody; REPRESENTATION; SHAPES; Speech boundaries; Subordination; SYNTACTIC STRUCTURE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U9WHEJVT","journalArticle","2022","Zlatintsi, A; Filntisis, PP; Garoufis, C; Efthymiou, N; Maragos, P; Menychtas, A; Maglogiannis, I; Tsanakas, P; Sounapoglou, T; Kalisperakis, E; Karantinos, T; Lazaridi, M; Garyfalli, V; Mantas, A; Mantonakis, L; Smyrnis, N","E-Prevention: Advanced Support System for Monitoring and Relapse Prevention in Patients with Psychotic Disorders Analyzing Long-Term Multimodal Data from Wearables and Video Captures","SENSORS","","1424-8220","10.3390/s22197544","","Wearable technologies and digital phenotyping foster unique opportunities for designing novel intelligent electronic services that can address various well-being issues in patients with mental disorders (i.e., schizophrenia and bipolar disorder), thus having the potential to revolutionize psychiatry and its clinical practice. In this paper, we present e-Prevention, an innovative integrated system for medical support that facilitates effective monitoring and relapse prevention in patients with mental disorders. The technologies offered through e-Prevention include: (i) long-term continuous recording of biometric and behavioral indices through a smartwatch; (ii) video recordings of patients while being interviewed by a clinician, using a tablet; (iii) automatic and systematic storage of these data in a dedicated Cloud server and; (iv) the ability of relapse detection and prediction. This paper focuses on the description of the e-Prevention system and the methodologies developed for the identification of feature representations that correlate with and can predict psychopathology and relapses in patients with mental disorders. Specifically, we tackle the problem of relapse detection and prediction using Machine and Deep Learning techniques on all collected data. The results are promising, indicating that such predictions could be made and leading eventually to the prediction of psychopathology and the prevention of relapses.","2022-10","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","19","22","","","","","","","","","","English","","","","WOS:000867032200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;128</p>","","","anomaly detection; autoencoder architectures; biometric indexes; BIPOLAR DISORDER; deep learning; digital phenotyping; facial expressions; FOLLOW-UP; HEART-RATE-VARIABILITY; INTERVENTION; NETWORKS; PRODROMAL SYMPTOMS; psychotic disorders; RATING SCALE; relapse detection; SCHIZOPHRENIA; SPEECH; spontaneous speech; TIME-SERIES ANALYSIS; wearable technologies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VLCK4IZT","journalArticle","2023","Ntemou, E; Rybka, L; Lubbers, J; Tuncer, MS; Vajkoczy, P; Rofes, A; Picht, T; Faust, K","Lesion-symptom mapping of language impairments in people with brain tumours: The influence of linguistic stimuli","JOURNAL OF NEUROPSYCHOLOGY","","1748-6645","10.1111/jnp.12305","","People with tumours in specific brain sites might face difficulties in tasks with different linguistic material. Previous lesion-symptom mapping studies (VLSM) demonstrated that people with tumours in posterior temporal regions have more severe linguistic impairments. However, to the best of our knowledge, preoperative performance and lesion location on tasks with different linguistic stimuli have not been examined. In the present study, we performed VLSM on 52 people with left gliomas to examine whether tumour distribution differs depending on the tasks of the Aachen Aphasia Test. The VLSM analysis revealed that single-word production (e.g. object naming) was associated with the inferior parietal lobe and that compound and sentence production were additionally associated with posterior temporal gyri. Word repetition was affected in people with tumours in inferior parietal areas, whereas sentence repetition was the only task to be associated with frontal regions. Subcortically, word and sentence production were found to be affected in people with tumours reaching the arcuate fasciculus, and compound production was primarily associated with tumours affecting the inferior longitudinal and inferior fronto-occipital fasciculus. Our work shows that tasks with linguistic stimuli other than single-word naming (e.g. compound and sentence production) relate to additional cortical and subcortical brain areas. At a clinical level, we show that tasks that target the same processes (e.g. repetition) can have different neural correlates depending on the linguistic stimuli used. Also, we highlight the importance of left temporoparietal areas.","2023-06","2025-02-26 20:39:17","2025-02-26 20:39:17","","400-416","","2","17","","","","","","","","","","English","","","","WOS:000917178700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","APHASIA; BROCAS; cognition; COMPREHENSION; CONSECUTIVE SERIES; glioma; GRADE-II GLIOMA; language; LEFT-HEMISPHERE TUMORS; ORGANIZATION; SENTENCE; SPONTANEOUS SPEECH; tumour; VERBS; VLSM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L3UAVQ43","journalArticle","2025","Asal, D; Kayikci, MEK; Tigrak, TK","Pragmatic Language Skills of Turkish-Speaking Children Who Stutter","FOLIA PHONIATRICA ET LOGOPAEDICA","","1021-7762","10.1159/000543382","","Introduction: The study aimed to investigate the relationship between pragmatic language skills of children who stutter (CWS) and the frequency of stuttering, with a focus on the development of these skills through peer interaction in the school years. It is well-known that CWS may face social disadvantages at school due to their limited peer interaction, which may pose a risk to the development of their pragmatic language skills. Method: The study involved 64 CWS aged between 60 and 106 months. Stuttering frequency was determined by analyzing children's spontaneous speech recordings during playtime with their parents. The children's language development was assessed using the Turkish School Age Language Development Assessment Test (TOD & Idot;L), while speech sound disorders were evaluated using the Turkish Articulation and Phonology Test (SST). Teachers of children whose language and speech sound development were typical were contacted to evaluate the pragmatic language skills of the children using the Pragmatic Language Skills Inventory (PLSI). Results: The results of the evaluation showed that 51.6% of the children had below-average pragmatic language skills. Additionally, a negative correlation was observed between the frequency of stuttering and PLSI (p < 0.05), suggesting that as the frequency of stuttering increased, pragmatic language skills scores decreased. Conclusion: CWS may face challenges in communicating effectively, despite their formal language assessment results falling within the normal range. The findings support that pragmatic language skills should be considered when treating stuttering due to their critical role in academic and social outcomes.","2025-01-03","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","","","","","","","","","","","English","","","","WOS:001415450500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","ABILITIES; COMMUNICATION; Pragmatic language skills; School age; Social skills; Stuttering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SSTYWNXI","journalArticle","2024","Radha, K; Bansal, M; Pachori, RB","Automatic speaker and age identification of children from raw speech using sincNet over ERB scale","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2024.103069","","This paper presents the newly developed non-native children's English speech (NNCES) corpus to reveal the findings of automatic speaker and age recognition from raw speech. Convolutional neural networks (CNN), which have the ability to learn low-level speech representations, can be fed directly with raw speech signals instead of using traditional hand-crafted features. Moreover, the filters that were learned using standard CNNs appeared to be noisy because they consider all elements of each filter. In contrast, sincNet can be able to generate more meaningful filters simply by replacing the first convolutional layer by a sinc-layer in standard CNNs. The low and high cutoff frequencies of the rectangular band -pass filter are the only parameters that can be learned in sincNet, which has the potential to extract significant speech cues from the speaker, such as pitch and formants. In this work, the sincNet model is significantly changed by switching from baseline Mel scale initializations to equivalent rectangular bandwidth (ERB) initializations, which has the added benefit of allocating additional filters in the lower region of the spectrum. Additionally, it needs to be highlighted that the novel sincNet model is well suited to identify the age of the children. The investigations on both read and spontaneous speech tasks in speaker identification, gender independent & dependent age-group identification of children outperform the baseline models with varying relative improvements in terms of accuracy.","2024-04","2025-02-26 20:39:17","2025-02-26 20:39:17","","","","","159","","","","","","","","","","English","","","","WOS:001228722900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","CLASSIFICATION; Convolutional neural networks; FUSION; Gender-dependent age identification; Gender-independent age identification; NETWORK; Non-native children's English speech corpus; Raw speech signals; SincNet; Speaker identification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"25I7KPDK","journalArticle","2024","Nakajima, S; Okochi, N; Mitobe, K","Enhancing movie experience by speech rate design of audio description","UNIVERSAL ACCESS IN THE INFORMATION SOCIETY","","1615-5289","10.1007/s10209-024-01178-z","","Speech rate conversion in screen readers is a crucial human-computer interface that allows persons with vision disabilities to access audiovisual media. However, its potential utility in audio descriptions (ADs) has not been researched extensively. This study investigated the effect of AD speech rates on information access and film aesthetics. The appropriate speech rate for human-narrated and synthesized ADs of short scenes from Japanese movies was evaluated by involving blind, partially blind, and sighted participants. An arranged staircase procedure and software developed to enable AD speech rate adjustments through keyboard operations were employed. The results obtained from blind and partially blind participants indicated lower mean appropriate speech rates of the single AD with human and synthesized voices for information access than those of screen readers in previous studies but higher than the standard spontaneous speech rate. The presence of the film sound did not significantly impact the average speech rate of either the human or synthesized AD. However, the variability of the speech rate decreased specifically for the synthesized AD. Additionally, a statistically significant positive correlation emerged between the appropriate speech rates determined for human and synthesized ADs, strengthened experimentally with short movie scenes with multiple ADs. The comments by blind and partially blind participants and sighted participants' ratings demonstrated the positive effect of appropriate sequential changes in speech rate on the sense of presence and immersion in movies. The speech rate design of ADs presents an opportunity to improve the comfort of listening to ADs and augment the movie experience.","2024-12-04","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","","","","","","","","","","","English","","","","WOS:001370384500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Audio description; Blind; Cinema; Speech rate conversion; Speech synthesis; Vision disabilities","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GDIJ5CJ8","journalArticle","2024","Das, S; Laha, D; Sengupta, P","Study of Language Function in Bengali-Speaking Population with Motor Neuron Disease","ANNALS OF INDIAN ACADEMY OF NEUROLOGY","","0972-2327","10.4103/aian.aian_44_24","","Background: Motor neuron diseases (MNDs) have been traditionally considered to spare cognition. But recent findings show that multiple domains of cognition including language can be involved in MND patients. Most studies on language patterns of MND patients were conducted in Western nations, but data on Indian population is limited. This study is an attempt to explore the language functions of Bengali-speaking MND patients from this part of eastern India. Objective: To determine the prevalence and nature of language dysfunction in MND patients. Materials and Methods: A single-center, hospital-based, observational, cross-sectional study. The Bengali adaptation of the Western Aphasia Battery was administered to 50 cases diagnosed with MND, attending a tertiary care hospital consecutively over a 1-year period, and fulfilling the inclusion and exclusion criteria for the study. Descriptive and inferential statistics were used for expressing results. Results: Eighteen percent of cases showed impairments in spontaneous speech. Fluency was impaired in 72%, and 22% cases showed impaired naming. Moreover, 20% and 26% of cases were impaired in repetition and comprehension, respectively. Reading and writing was impaired in 16% and 26% of cases, respectively. Significant difference was found in the primary language skill scores and aphasia quotient across age groups, while no significant difference was found in these scores across education status. Conclusions: This study describes the language profiles of Bengali-speaking MND patients from eastern India, and the findings are similar to previous research works, which have shown morpho-syntactic, lexical-semantic, and phonological errors in language function.","2024-07","2025-02-26 20:39:18","2025-02-26 20:39:18","","378-383","","4","27","","","","","","","","","","English","","","","WOS:001316769300006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","ALS; AMYOTROPHIC-LATERAL-SCLEROSIS; Bengali Speakers; COGNITIVE IMPAIRMENT; DEMENTIA; DYSFUNCTION; language; Motor neuron disease","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"86VHAFMV","journalArticle","2022","Novotny, M; Tykalova, T; Ruzickova, H; Ruzicka, E; Dusek, P; Rusz, J","Automated video-based assessment of facial bradykinesia in de-novo Parkinson's disease","NPJ DIGITAL MEDICINE","","2398-6352","10.1038/s41746-022-00642-5","","Even though hypomimia is a hallmark of Parkinson's disease (PD), objective and easily interpretable tools to capture the disruption of spontaneous and deliberate facial movements are lacking. This study aimed to develop a fully automatic video-based hypomimia assessment tool and estimate the prevalence and characteristics of hypomimia in de-novo PD patients with relation to clinical and dopamine transporter imaging markers. For this cross-sectional study, video samples of spontaneous speech were collected from 91 de-novo, drug-naive PD participants and 75 age and sex-matched healthy controls. Twelve facial markers covering areas of forehead, nose root, eyebrows, eyes, lateral canthal areas, cheeks, mouth, and jaw were used to quantitatively describe facial dynamics. All patients were evaluated using Movement Disorder Society-Unified PD Rating Scale and Dopamine Transporter Single-Photon Emission Computed Tomography. Newly developed automated facial analysis tool enabled high-accuracy discrimination between PD and controls with area under the curve of 0.87. The prevalence of hypomimia in de-novo PD cohort was 57%, mainly associated with dysfunction of mouth and jaw movements, and decreased variability in forehead and nose root wrinkles (p < 0.001). Strongest correlation was found between reduction of lower lip movements and nigro-putaminal dopaminergic loss (r = 0.32, p = 0.002) as well as limb bradykinesia/rigidity scores (r = -0.37 p < 0.001). Hypomimia represents a frequent, early marker of motor impairment in PD that can be robustly assessed via automatic video-based analysis. Our results support an association between striatal dopaminergic deficit and hypomimia in PD.","2022-07-18","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","1","5","","","","","","","","","","English","","","","WOS:000826991800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","EXPRESSIONS; SMILE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BJT2AMN6","journalArticle","2021","Kim, N; Davis, BL","Vowel Context Effects on Consonant Repetition in Early Words","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2020_JSLHR-20-00216","","Purpose: Consonant repetitions within words are a well attested speech error pattern in children's early speech acquisition. We investigated the role of intervening vowel context in understanding speech forms containing consonant repetitions in early words. Intrasyllabic consonant-vowel (CV) sequences within consonant-vowel-consonant (CVC) and consonant-vowel-consonant-vowel (CVCV) forms containing consonant repetitions were analyzed to evaluate whether children's lack of independent movement control for the tongue in word-level sequences might contribute to these observed speech patterns. Method: Spontaneous speech data produced by 10 typically developing children learning American English were analyzed longitudinally from the onset of word use to 36 months. Overall patterns and word shape effects for nine CV combinations occurring in their CVC and CVCV word shapes that contained repeated nonadjacent consonants and the intervening vowel were analyzed. Results: Three CV combinations-coronal-front vowel, labial-central vowel, and dorsal-back vowel-occurred at above-chance levels. Preference for these CV patterns was strong in CVCV but not in CVC word shapes. These CV combinations occurred frequently at all time periods analyzed for CVCV's while decreasing across time for CVC's. Conclusions: Analysis of intrasyllabic patterns within word forms containing consonant repetitions revealed that consonant repetitions in many early words occurred at above-chance levels in the context of articulatorily compatible vowels. Results suggest that children's production system capacities are an important contributing principle accounting for vowel context effects within word forms containing consonant repetitions during earliest speech acquisition.","2021-01","2025-02-26 20:39:18","2025-02-26 20:39:18","","40-50","","1","64","","","","","","","","","","English","","","","WOS:000611186900004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","ACQUISITION; CHILDHOOD; CHILDREN; COMPLEXITY; COORDINATION; JAW; LIP; PATTERNS; SPEECH PRODUCTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DZ3JPJ5V","journalArticle","2024","Han, CL; Pan, JN; Du, JC; Feng, LY; Ma, HQ; Tang, JQ","Efficacy of different rehabilitation therapies on post-stroke aphasia patients: A network meta-analysis","MEDICINE","","0025-7974","10.1097/MD.0000000000038255","","Background:Although several rehabilitation interventions are effective in post-stroke aphasia (PSA), the efficacy of different rehabilitation interventions compared to each other remains controversial. Here, we aimed to compare the effectiveness of varying rehabilitation interventions in PSA.Methods:Randomized controlled trials on 8 kinds of rehabilitation interventions to improve speech function in patients with PSA were searched by computer from 10 databases, including PubMed, Web of Science, Cochrane, OVID, CINAHL, Embase, CNKI, WanFang, CBM, and VIP. The search scope was from the establishment of the database to August 2023. The literature screening, extraction of basic information, and quality assessment of the literature were conducted independently by 2 researchers. Network meta-analysis (NMA) was performed using Stata 17.0 software.Results:Fifty-four studies involving 2688 patients with PSA were included. The results of NMA showed that: <Circled Digit One> in terms of improving the severity of aphasia, the therapeutic effects of repetitive transcranial magnetic stimulation were the most significant; <Circled Digit Two> motor imagery therapy was the most effective in improving spontaneous speech, repetition, and naming ability; <Circled Digit Three> in terms of improving listening comprehension ability, the therapeutic effects of mirror neuron therapy was the most significant.Conclusion:The 8 rehabilitation interventions have different focuses in improving the speech function of PSA patients, and the clinical therapists can select the optimal rehabilitation interventions in a targeted manner according to the results of this NMA and the patients' conditions and other relevant factors.","2024-05-24","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","21","103","","","","","","","","","","English","","","","WOS:001230616700071","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;79</p>","","","aphasia; BLIND; LANGUAGE; network meta-analysis; randomized controlled trial; rehabilitation intervention; SPEECH; STROKE; TRANSCRANIAL MAGNETIC STIMULATION; TRIAL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NXDILECG","journalArticle","2024","Jimenez-Bravo, M; Marrero-Aguiar, V","Multimodal prosody: gestures and speech in the perception of prominence in Spanish","FRONTIERS IN COMMUNICATION","","2297-900X","10.3389/fcomm.2024.1287363","","Multimodal communication cannot be properly understood without analyzing the natural interweaving of speech and gestures as it typically occurs in everyday spoken language, thus moving beyond studies that elicit gestures in the laboratory, most of which are also conducted for English. Therefore, this study addresses the effect of both visual and acoustic cues in the perception of prominence in Castilian Spanish using spontaneous speech from a TV talent-show. Four between-subjects experiments in each modality-audio-only and audiovisual-were conducted online, each including a different combination of manipulated cues: Exp1 (flat F0), Exp2 (flat intensity), and Exp3 (flat F0 + flat intensity), while all cues remained intact in the control experiment Exp0. Additionally, the capability of the different gesture phases to convey prominence was analyzed in their interaction with the acoustic cues. The results showed that, when prominence was perceived in manipulated stimuli, the effect of the visual information depended on the acoustic cues available in the signal and was also reduced when compared to non-manipulated stimuli, pointing to a strong integration of both modalities in prominence perception. In non-manipulated stimuli, all acoustic cues-except for spectral balance-played a role in the perception of prominence; however, when the visual information was added, it reduced the perceptual effect of the acoustic cues, and the main role played by duration was combined with that of the stroke phase of gestures.","2024-03-27","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","9","","","","","","","","","","English","","","","WOS:001199387000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;112</p>","","","ACCENTS; acoustic cues; AGREEMENT; audiovisual prosody; BEATS; EXPERTISE; gesture; INTENSITY; LISTENERS; multimodality; MUSIC; PITCH; prominence; SEX-DIFFERENCES; Spanish; SPECTRAL BALANCE; speech perception","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IP5B8IBG","journalArticle","2024","Zhu, M; Chen, F; Shi, CX; Zhang, Y","Amplitude envelope onset characteristics modulate phase locking for speech auditory-motor synchronization","PSYCHONOMIC BULLETIN & REVIEW","","1069-9384","10.3758/s13423-023-02446-4","","The spontaneous speech-to-speech synchronization (SSS) test has been shown to be an effective behavioral method to estimate cortical speech auditory-motor coupling strength through phase-locking value (PLV) between auditory input and motor output. This study further investigated how amplitude envelope onset variations of the auditory speech signal may influence the speech auditory-motor synchronization. Sixty Mandarin-speaking adults listened to a stream of randomly presented syllables at an increasing speed while concurrently whispering in synchrony with the rhythm of the auditory stimuli whose onset consistency was manipulated, consisting of aspirated, unaspirated, and mixed conditions. The participants' PLVs for the three conditions in the SSS test were derived and compared. Results showed that syllable rise time affected the speech auditory-motor synchronization in a bifurcated fashion. Specifically, PLVs were significantly higher in the temporally more consistent conditions (aspirated or unaspirated) than those in the less consistent condition (mixed) for high synchronizers. In contrast, low synchronizers tended to be immune to the onset consistency. Overall, these results validated how syllable onset consistency in the rise time of amplitude envelope may modulate the strength of speech auditory-motor coupling. This study supports the application of the SSS test to examine individual differences in the integration of perception and production systems, which has implications for those with speech and language disorders that have difficulty with processing speech onset characteristics such as rise time.","2024-08","2025-02-26 20:39:18","2025-02-26 20:39:18","","1661-1669","","4","31","","","","","","","","","","English","","","","WOS:001152231100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","ABILITY; ADULTS; Amplitude rise time; BEAT; NOISE; PERCEPTION; PERCUSSIONISTS; Phase-locking value; RESPONSES; RHYTHM; SOUNDS; Speech auditory-motor synchronization; Stimulus onset; TIME","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CLM8YEFD","journalArticle","2023","Petti, U; Baker, S; Korhonen, A; Robin, J","The Generalizability of Longitudinal Changes in Speech Before Alzheimer's Disease Diagnosis","JOURNAL OF ALZHEIMERS DISEASE","","1387-2877","10.3233/JAD-220847","","Background: Language impairment in Alzheimer's disease (AD) has been widely studied but due to limited data availability, relatively fewstudies have focused on the longitudinal change in language in the individuals who later develop AD. Significant differences in speech have previously been found by comparing the press conference transcripts of President Bush and President Reagan, who was later diagnosed with AD. Objective: In the current study, we explored whether the patterns previously established in the single AD-healthy control (HC) participant pair apply to a larger group of individuals who later receive AD diagnosis. Methods: We replicated previous methods on two larger corpora of longitudinal spontaneous speech samples of public figures, consisting of 10 and 9 AD-HC participant pairs. As we failed to find generalizable patterns of language change using previous methodology, we proposed alternative methods for data analysis, investigating the benefits of using different language features and their change with age, and compiling the single features into aggregate scores. Results: The single features that showed the strongest results were moving average type:token ratio (MATTR) and pronounrelated features. The aggregate scores performed better than the single features, with lexical diversity capturing a similar change in two-thirds of the participants. Conclusion: Capturing universal patterns of language change prior to AD can be challenging, but the decline in lexical diversity and changes in MATTR and pronoun-related features act as promising measures that reflect the cognitive changes in many participants.","2023","2025-02-26 20:39:18","2025-02-26 20:39:18","","547-564","","2","92","","","","","","","","","","English","","","","WOS:000952023800013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Alzheimer's disease; biomarker; cognitive dysfunction; CONVERSATION; dementia; DEMENTIA; early diagnosis; language; LANGUAGE; medical informatics; MILD COGNITIVE IMPAIRMENT; natural language processing; OBJECTIVE TECHNIQUE; speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M6D46VPX","journalArticle","2023","Radha, K; Bansal, M","Feature Fusion and Ablation Analysis in Gender Identification of Preschool Children from Spontaneous Speech","CIRCUITS SYSTEMS AND SIGNAL PROCESSING","","0278-081X","10.1007/s00034-023-02399-y","","The children below 6 years of age are called preliterate who use speech as one of their primary forms of communication. Fundamental frequency or pitch is a characteristic that is used to classify gender, but young children have reasonably similar pitch due to their immature vocal tract which varies from 215 to 390 Hz for both genders. Most studies for gender identification have utilized pitch and mel frequency cepstral coefficients (MFCC), because of their ability to capture the efficacy of signals. However, the performance of pitch and MFCC on noisy speech signals are poor, and as a result, they fail to accurately detect gender characteristics. Considering this limitation, the proposed work investigates the novel fusion and ablation experimentation of mel frequency cepstral coefficients (MFCC) and gamma-tone frequency cepstral coefficients (GFCC). To enhance the accuracy of a robust text-independent children gender identification model, the cepstral features are combined with the tonal descriptors (pitch and harmonic ratio). The most contributing front-end features were selected by fusion and ablation analysis and distributed to a bagged tree classifier ensemble. To manage the memory requirements, redundant features are trimmed using principle component analysis (PCA). The hyper-parameter optimization is accomplished using the grid search technique to further increase frame-level accuracy. This study is likely to be a forerunner in the field of children's speech recognition, which has been revealed to be a reliable and accurate method of gender identification.","2023-10","2025-02-26 20:39:18","2025-02-26 20:39:18","","6228-6252","","10","42","","","","","","","","","","English","","","","WOS:000990060300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","AGE; CLASSIFICATION; Ensemble of bagged trees; Gender identification; GFCC; Harmonic ratio; LOFO; MF-GFCC; MFCC; Pitch; RECOGNITION; SPEAKER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4LUEJF87","journalArticle","2021","Sanfelici, E; Schulz, P","Can Frequency Account for the Grammatical Choices of Children and Adults in Nominal Modification Contexts? Evidence from Elicited Production and Child-Directed Speech","LANGUAGES","","2226-471X","10.3390/languages6010035","","There is consensus that languages possess several grammatical variants satisfying the same conversational function. Nevertheless, it is a matter of debate which principles guide the adult speaker's choice and the child's acquisition order of these variants. Various proposals have suggested that frequency shapes adult language use and language acquisition. Taking the domain of nominal modification as its testing ground, this paper explores in two studies the role that frequency of structures plays for adults' and children's structural choices in German. In Study 1, 133 three- to six-year-old children and 21 adults were tested with an elicited production task prompting participants to identify an agent or a patient referent among a set of alternatives. Study 2 analyzed a corpus of child-directed speech to examine the frequency of passive relative clauses, which children, similar to adults, produced very often in Study 1. Importantly, passive relatives were found to be infrequent in the child input. These two results show that the high production rate of rare structures, such as passive relatives, is difficult to account for with frequency. We claim that the relation between frequency in natural speech and use of a given variant in a specific context is indirect: speakers may opt for the less grammatically complex computation rather than for the variant most frequently used in spontaneous speech.","2021-03","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","1","6","","","","","","","","","","English","","","","WOS:000636310600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","ACQUISITION; ANIMACY; child-directed speech; COMPREHENSION; corpus; elicited production; ENGLISH; frequency; German; INTERVENTION; passive; passive subject relative clause; relative clause; RELATIVE CLAUSES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TBGHQUBT","journalArticle","2022","Cassarà, A; Adli, A; Karssenberg, L","Clefts in context: A QUD-perspective on c'est / ily a utterances in spoken French","ISOGLOSS OPEN JOURNAL OF ROMANCE LINGUISTICS","","2385-4138","10.5565/rev/isogloss.197","","In this paper we present the results of a pragmatic analysis of French full clefts and monoclausal c'est /il y a utterances (e.g. c'est la femme qui l'a tu & eacute; 'it's the wife who killed him' vs. c'est la femme 'it's the wife' respectively in answer to the question 'who killed him?'), when these structures are used as pragmatic strategies to focalize the subject in spoken French. Unlike full cleft sentences, monoclausal c'est and il y a utterances have received less attention in the literature, especially with regard to focus and its realization in spontaneous speech. Investigating the opposition between full clefts and monoclausal forms as well as the questions that these clefts answer allows us to arrive at a more precise understanding of the discourse functions of these structures and the pragmatic contexts in which they are felicitous. The corpus that is used (sgs, spontaneous spoken French) contains many question -answer pairs due to its interactive setup, thus enabling a clear analysis of the types of Question Under Discussion that the clefts answer. The data show that monoclausal utterances are more likely to answer highly active QUDs, whereas full clefts are more likely to answer less active QUDs. The level of activation is determined in terms of proximity and implicitness of the QUD (immediately -preceding the cleft, further away or implicit), and - when the question is uttered explicitly - modality (wh or yes/no) also plays a role.","2022","2025-02-26 20:39:18","2025-02-26 20:39:18","","1-29","","1","8","","","","","","","","","","English","","","","WOS:001222793000008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","cleft; focus; FOCUS; French; Information Structure; Question Under Discussion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RJ7EBPB9","journalArticle","2022","Kyeong, S; Kang, H; Kim, DH","Structural Integrity and Functional Neural Activity Associated with Oral Language Function after Stroke","JOURNAL OF CLINICAL MEDICINE","","2077-0383","10.3390/jcm11113028","","(1) Background: The impairment of language function after a stroke is common. It is unclear how the brain reorganizes for language function after cerebral infarction. The aim of this observational study is to investigate the association of structural integrity and functional neural activity with language function in aphasic patients with middle cerebral artery infarction. (2) Methods: Magnetic resonance images and scores from the Western Aphasia Battery on 20 patients were retrieved from medical records. A Voxel-wise linear regression analysis was performed using fractional anisotropy maps or the fractional amplitude of low-frequency fluctuation maps as dependent variables and scores of oral language function as independent variables while controlling for age and time elapsed after stroke. (3) Results: Spontaneous speech was positively associated with fractional anisotropy in the left dorsal stream and the right posterior corpus callosum and with the fractional amplitude of the low-frequency fluctuation of cranial nuclei in the pontomedullary junction. Comprehension was positively associated with the left ventral stream. Naming was positively associated with the left ventral stream and the bilateral occipitofrontal fasciculus, as well as with the fractional amplitude of low-frequency fluctuation of the supramarginal gyrus in the left hemisphere. (4) Conclusions: The dorsal and ventral streams are important for articulation and meaning after the reorganization of neural circuits following stroke. Subdomains of oral language function with a visual component are dependent on the visual association areas located in the right hemisphere.","2022-06","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","11","11","","","","","","","","","","English","","","","WOS:000808981600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","aphasia; connectivity; DORSAL; DYNAMICS; PLASTICITY; POSTSTROKE APHASIA; recovery; RECOVERY; REORGANIZATION; RIGHT-HEMISPHERE; stroke","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PRM5JDFA","journalArticle","2025","Zhu, M; Chen, F; Chen, WP; Zhang, Y","The Impact of Executive Functions and Musicality on Speech Auditory-Motor Synchronization in Adults Who Stutter","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2024_JSLHR-24-00141","","Purpose: Stuttering is a neurodevelopmental disorder that disrupts the timing and rhythmic flow of speech production. There is growing evidence indicating that abnormal interactions between the auditory and motor cortices contribute to the development of stuttering. The present study investigated speech auditory-motor synchronization in stuttering adults and the influential factors behind it as compared to individuals without stuttering. Method: Sixteen Mandarin-speaking adults with stuttering and 19 fluent controls, who were matched for age, gender, and years of musical training, participated in the current study. Their ability to synchronize vocal speech production with accelerating auditory sequences was assessed using the spontaneous speech-to-speech synchronization test (SSS test). Additionally, all participants conducted a series of standardized behavioral tests to evaluate their musicality and executive functions. Results: Stutterers achieved significantly lower phase locking values in the SSS test compared to nonstuttering controls, indicating a potential rhythmic processing deficit in developmental stuttering. Moreover, the strength of speech auditory- motor synchronization in stutterers was significantly associated with their performance in tasks such as digit span and nonword repetition. This finding further emphasizes the strong link between rhythmic processing and working memory. Conclusions: This study provides compelling evidence for the speech rhythmic deficit in individuals with stuttering by incorporating auditory-motor processes. It would offer valuable insights into the intricate relationship between language and the brain and shed light on the potential benefits of cognitive training for speech intervention in individuals with stuttering difficulties. Supplemental Material: https://doi.org/10.23641/asha.27984362","2025-01","2025-02-26 20:39:18","2025-02-26 20:39:18","","54-68","","1","68","","","","","","","","","","English","","","","WOS:001391132400005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;73</p>","","","BEAT; BRAIN; CHILDREN; CONNECTIVITY; FLEXIBILITY; IDENTIFICATION; LANGUAGE; PERCEPTION; RHYTHM DISCRIMINATION; WORKING-MEMORY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A6QDP9RE","journalArticle","2023","Trimmis, N; Chatzi, K; Grammatsoulia, V; Feida, F; Mourtzouchos, K; Papadopoulos, A; Plotas, P","A Greek Pediatric Word Recognition Test by Picture Identification","BRAIN SCIENCES","","2076-3425","10.3390/brainsci13121643","","(1) Background: The study aimed to construct a clinically valuable closet-set WRS test with a picture identification task for young Greek-speaking children. (2) Methods: The test material was meticulously designed based on specific criteria. To determine which parts of speech are used more frequently by preschool children, a spontaneous speech sample (250 words per child) was acquired from three hundred children aged 3 to 6 years (M = 4.56, SD = 0.90). The study involved the development and application of two phonemically balanced 50-word lists suitable for young children, as well as the creation of picture representations for each response set. All testing was accomplished in an audiometric booth that exceeded the audiometric rooms' ambient noise level standards. The speech signal was routed from a laptop computer to a GSI 61 audiometer, and all test items were delivered from the audiometer to the subject. (3) Results: The results indicated that materials for a WRS test for young children are developed with high face validity and are applicable for children as young as three years old. The test satisfies the essential components needed for a WRS test. It consists of two phonemically balanced 50-word lists with low-redundancy bisyllabic words, with each list containing 227 phonemes. (5) Conclusions: This novel closed-set WRS test presents a valuable tool for assessing speech perception skills in young Greek-speaking children. The test results have various applications, including diagnosis, research, and (re)habilitation.","2023-12","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","12","13","","","","","","","","","","English","","","","WOS:001131205200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","children; LANGUAGE; picture identification task; speech audiometry; SPEECH-DISCRIMINATION SCORES; word recognition score; WRS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NLIASZ7P","journalArticle","2025","Mishra, M; Singh, JG","Fault Detection and Localization in an MT-VSC-HVDC Network via a Hybrid CNN-Transformer Model With a Multi-Head Attention Mechanism","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2025.3534247","","In this paper, a non-unit protection approach is suggested for recognizing fault events (internal and external) and their location in a High Voltage Direct Current (HVDC) system employing a deep learning (DL) model. This work utilizes a small sample size of DC current signals from one end of an HVDC-fed system, achieving a balance between data manageability and preserving vital information related to faults. The simulation of fault samples is carried out with the maximum possible operating scenarios, such as different fault resistances, locations, types of faults, and noisy conditions. Afterward, combined data with varying noise values is trained by the proposed DL model. The testing is performed under individual noise levels to evaluate model robustness and accuracy in real-time scenarios. In the DL framework, the work focuses on two core architectures, Convolutional Neural Networks (CNN) and Transformer models, and assesses their performance individually. Furthermore, it explores the hybrid model CNN-Transformer with a multi-head attention mechanism to capitalize on their combined strengths. Afterward, a detailed comparative result evaluation with other DL models is carried out to gauge robustness and accuracy in fault detection and localization. Comparative outcomes reveal that the Transformer models performed more remarkably in varying noise conditions, while recurrent models excelled in sequential data processing. The hybrid DL methods provided a balanced trade-off, improving fault detection and localization. The study utilizes several performance metrics such as accuracy, precision, recall, F1 score, MSE, RMSE, MAPE, and R2 errors to provide a comprehensive assessment. The fault detection without noise conditions attained an accuracy of 100%; however, there was a slight decrease (1.5%) in 20db noisy conditions. The proposed approach archives excellent performance in fault location tasks, such as MAPE:0.0308, MSE:1.6415, RMSE:1.2814, and R2:0.9982. The performance of the proposed approach is also validated with varying system operating conditions and comparative performance analysis with other state-of-the-art techniques. The findings offer valuable insights into the optimal model configurations and their practical applicability for reliable HVDC system protection, contributing to more effective and real-time fault diagnosis solutions.","2025","2025-02-26 20:39:18","2025-02-26 20:39:18","","26365-26383","","","13","","","","","","","","","","English","","","","WOS:001422025700045","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Accuracy; application of deep learning models; Data models; Fault detection; Fault detection and localization; Feature extraction; HVDC transmission; hybridization of CNN-Transformer model; internal and external faults; LOCATION; modeling of multi-terminal HVDC system; multi-head attention mechanism; Noise; Protection; PROTECTION; Real-time systems; Transformers; Voltage measurement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WY6ESWM4","journalArticle","2024","Eidex, Z; Wang, J; Safari, M; Elder, E; Wynne, J; Wang, TH; Shu, HK; Mao, H; Yang, XF","High-resolution 3T to 7T ADC map synthesis with a hybrid CNN-transformer model","MEDICAL PHYSICS","","0094-2405","10.1002/mp.17079","","Background7 Tesla (7T) apparent diffusion coefficient (ADC) maps derived from diffusion-weighted imaging (DWI) demonstrate improved image quality and spatial resolution over 3 Tesla (3T) ADC maps. However, 7T magnetic resonance imaging (MRI) currently suffers from limited clinical unavailability, higher cost, and increased susceptibility to artifacts.PurposeTo address these issues, we propose a hybrid CNN-transformer model to synthesize high-resolution 7T ADC maps from multimodal 3T MRI.MethodsThe Vision CNN-Transformer (VCT), composed of both Vision Transformer (ViT) blocks and convolutional layers, is proposed to produce high-resolution synthetic 7T ADC maps from 3T ADC maps and 3T T1-weighted (T1w) MRI. ViT blocks enabled global image context while convolutional layers efficiently captured fine detail. The VCT model was validated on the publicly available Human Connectome Project Young Adult dataset, comprising 3T T1w, 3T DWI, and 7T DWI brain scans. The Diffusion Imaging in Python library was used to compute ADC maps from the DWI scans. A total of 171 patient cases were randomly divided into 130 training cases, 20 validation cases, and 21 test cases. The synthetic ADC maps were evaluated by comparing their similarity to the ground truth volumes with the following metrics: peak signal-to-noise ratio (PSNR), structural similarity index measure (SSIM), and mean squared error (MSE). In addition,ResultsThe results are as follows: PSNR: 27.0 +/- 0.9 dB, SSIM: 0.945 +/- 0.010, and MSE: 2.0E-3 +/- 0.4E-3. Both qualitative and quantitative results demonstrate that VCT performs favorably against other state-of-the-art methods. We have introduced various efficiency improvements, including the implementation of flash attention and training on 176x208 resolution images. These enhancements have resulted in the reduction of parameters and training time per epoch by 50% in comparison to ResViT. Specifically, the training time per epoch has been shortened from 7.67 min to 3.86 min.ConclusionWe propose a novel method to predict high-resolution 7T ADC maps from low-resolution 3T ADC maps and T1w MRI. Our predicted images demonstrate better spatial resolution and contrast compared to 3T MRI and prediction results made by ResViT and pix2pix. These high-quality synthetic 7T MR images could be beneficial for disease diagnosis and intervention, producing higher resolution and conformal contours, and as an intermediate step in generating synthetic CT for radiation therapy, especially when 7T MRI scanners are unavailable.","2024-06","2025-02-26 20:39:18","2025-02-26 20:39:18","","4380-4388","","6","51","","","","","","","","","","English","","","","WOS:001204069500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","7T MRI; deep learning; DWI; intramodal MRI synthesis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4VMTU3MJ","journalArticle","2022","Karem, RW; Washington, KN; Crowe, K","Cross-linguistic interactions in the spontaneous productions of preschoolers who speak Jamaican-Creole and English","SPEECH LANGUAGE AND HEARING","","2050-571X","10.1080/2050571X.2021.1936914","","Knowledge of typical cross-linguistic interactions in bilingual speakers is important for informing clinical practice and avoiding misdiagnosis of typically developing bilingual children as disordered. The present study investigated cross-linguistic interactions in the spontaneous productions of Jamaican Creole (JC)-English speaking preschoolers. Participants in this study were 61 JC-English bilingual preschoolers (aged 4;2-5;10). The Index of Productive Syntax (IPSyn) and token-based analyses were used to quantify and characterize preschoolers' cross-linguistic interactions. Within-utterance cross-linguistic interactions identified using the IPSyn framework (Noun Phrases, Verb Phrases, Questions/Negation, Sentence Structures) were present for 49.6% and 41.7% of linguistic structures, in K and English respectively. Token-based analysis revealed cross-linguistic interactions, with syntax being the most often involved in the JC context and phonology in the English context, for both within- and across-utterance analyses. Children used cross-linguistic interactions more often in the JC context, at an average rate of 44.9%, compared to an average rate of 27.8% in the English context. Most cross-linguistic interactions occurred towards the end of the language sample for both languages. The results of this study provide specific knowledge regarding JC-English preschoolers' cross-linguistic interactions in spontaneous speech. This knowledge is critical to increasing speech-language pathologists' cultural competence and responsivity for interpreting dynamic language use in this bilingual population.","2022-07-03","2025-02-26 20:39:18","2025-02-26 20:39:18","","325-337","","3","25","","","","","","","","","","English","","","","WOS:000854039100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","2 LANGUAGES; assessment; bilingual; CHILDREN; code-switching; CONTEXT; cultural and linguistic diversity; English; expressive language; INDEX; Index of Productive Syntax; IPSYN; Jamaican Creole; narrative","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3HSUTH9V","journalArticle","2024","Jorgensen, LM; Jorgensen, HP; Thranegaard, C; Wang, AG","Prosody and schizophrenia. Objective acoustic measurements of monotonous and flat intonation in young Danish people with a schizophrenia diagnosis. A pilot study","NORDIC JOURNAL OF PSYCHIATRY","","0803-9488","10.1080/08039488.2023.2255177","","PurposePatients with schizophrenia have a flat and monotonous intonation. The purpose of the study was to find the variables of flat speech that differed in patients from those in healthy controls in Danish.Materials and methodsWe compared drug-naive schizophrenic patients 5 men, 13 women and 18 controls, aged 18-35 years, which had all grown up in Copenhagen speaking modern Danish standard (rigsdansk). We used two different tasks that lay different demands on the speaker to elicit spontaneous speech: a retelling of a film clip and telling a story from pictures in a book. A linguist used the computer program Praat to extract the phonetic linguistic parameters.ResultsWe found different results for the two elicitation tasks (Task 1: a retelling of a film clip, task 2: telling a story from pictures in a book). There was higher intensity variation in task one in controls and higher pitch variation in task two in controls. We found a difference in intensity with higher intensity variation in the stresses in the controls in task one and fewer syllables between each stress in the controls. We also found higher F1 variation in task one and two in the patient group and higher F2 variation in the control group in both tasks.ConclusionsThe results varied between patients and controls, but the demands also made a difference. Further research is needed to elucidate the possibilities of acoustic measures in diagnostics or linguistic treatment related to schizophrenia.","2024-01-02","2025-02-26 20:39:18","2025-02-26 20:39:18","","30-36","","1","78","","","","","","","","","","English","","","","WOS:001078064500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","ABNORMALITIES; ACCURACY; acoustics; ASSOCIATIONS; EXPERIENCES; EXPRESSION; flat speech; LANGUAGE; NEGATIVE SYMPTOM SEVERITY; prosody; Schizophrenia; SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6JDAGLCI","journalArticle","2023","Ferrari, EP; Simoes-Zenari, M; Master, S; Nemr, K","Risk of dysphonia and voice quality in performing arts students","CODAS","","2317-1782","10.1590/2317-1782/20232022036en","","Purpose: To analyse the relationship between the risk of dysphonia and vocal quality in undergraduate performing arts students. Methods: Observational cross-sectional study with 38 undergraduate students in Performing Arts. We applied screening protocols for general and specific risk of dysphonia for actors and made recordings of sustained emission of the vowel /a/, spontaneous speech and reading a text, used for perceptual analysis performed by three evaluators using the GRBASI scale. After intra and inter-rater reliability tests it was obtained final classification of the general degree of vocal deviation parameter for each participant. Comparisons were made considering groups that had or did not have other profession/activity with the use of voice, and the groups were formed from the general grade. Results: Most students were at high risk for dysphonia. All had vocal alteration, with a predominance of mild degree. Students who had another profession/activity with voice use scored higher in the specific protocol for actors, and in the sum of this protocol with the general screening protocol. There was no relationship between the degree of vocal alteration and the risk of dysphonia. Students who did not yet work professionally had more moderate or severe vocal alterations, and those who did work professionally had a higher frequency of mild vocal alterations. Conclusion: Most students were at high risk for dysphonia. All had vocal alteration, with a predominance of mild alteration. There was no relationship between the risk of dysphonia and the degree of vocal alteration.","2023","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","4","35","","","","","","","","","","English","","","","WOS:001074092200002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Art; Dysphonia; Voice; Voice Disorders; Voice Quality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UWBMU4VT","journalArticle","2023","Lupancu, VC; Iftene, A","Multilingual Fine-Grained Named Entity Recognition","COMPUTER SCIENCE JOURNAL OF MOLDOVA","","1561-4042","10.56415/csjm.v31.16","","The ""MultiCoNER II Multilingual Complex Named Entity Recognition"" task1 within SemEval 2023 competition focuses on identifying complex named entities (NEs), such as the titles of creative works (e.g., songs, books, movies), people with different titles (e.g., politicians, scientists, artists, athletes), different categories of products (e.g., food, drinks, clothing), and so on, in several languages. In the context of SemEval, our team, FII_Better, presented an exploration of a base transformer model's capabilities regarding the task, focused more specifically on five languages (English, Spanish, Swedish, German, and Italian). We took DistilBERT (a distilled version of BERT) and BERT (Bidirectional Encoder Representations from Transformers) as two examples of basic transformer models, using DistilBERT as a baseline and BERT as the platform to create an improved model. In this process, we managed to get fair results in the chosen languages. We have managed to get moderate results in the English track (we ranked 17th out of 34), while our results in the other tracks could be further improved in the future (overall third to last). MSC 2020: 68T50.","2023","2025-02-26 20:39:18","2025-02-26 20:39:18","","321-339","","3","31","","","","","","","","","","English","","","","WOS:001165026700006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7665RAMQ","journalArticle","2022","Li, MR; Dong, CY; Xiong, BY; Mu, YF; Yu, XD; Xiao, Q; Jia, HJ","STTEWS: A sequential-transformer thermal early warning system for lithium-ion battery safety","APPLIED ENERGY","","0306-2619","10.1016/j.apenergy.2022.119965","","The internal reactions of lithium-ion batteries are susceptible to temperature, which makes the temperature of significant impact on their safety and performance. Therefore, it is very important to predict the temperature trend of lithium-ion batteries and implement thermal early warning. In order to solve this thermal concern of lithium-ion batteries, this paper designed a sequential-transformer thermal early warning system (STTEWS). First, a new allied temporal convolution-recurrent diagnosis network (TCRDN) is constructed by combining LSTM and temporal convolution network (TCN) using an adaptive boosting algorithm. Then, a complete transformer thermal diagnosis network (TTDN) is established, which fuses the important information from lithium-ion battery thermal images and integrates the prediction results from TCRDN to achieve an accurate early warning function. TTDN combines state-of-the-art time series transformer and vision transformer. TCRDN and TTDN constitute the complete STTEWS. Experiments show that the accuracy and Fl score of STTEWS for thermal diagnosis on multiple datasets both exceed 95%.","2022-12-15","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","328","","","","","","","","","","English","","","","WOS:000877695500004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;18<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","CELL; CHARGE ESTIMATION; CIRCUIT; FAULT-DIAGNOSIS; Lithium-ion battery; NEURAL-NETWORK; PREDICTION; STATE; Temporal convolution network; Thermal early warning; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QG6QVVJA","journalArticle","2022","Wei, ZC; Ji, X; Zhou, L; Dang, YG; Dai, YY","A novel deep learning model based on target transformer for fault diagnosis of chemical process","PROCESS SAFETY AND ENVIRONMENTAL PROTECTION","","0957-5820","10.1016/j.psep.2022.09.039","","Deep learning is a powerful tool for feature representation, and many methods based on convolutional neural networks (CNNs) and recurrent neural networks (RNNs) have been applied on fault diagnoses for chemical processes. However, unlike attention mechanisms, these networks are inefficient when extracting features of long-term dependencies. The transformer method employs a self-attention mechanism and sequence-to-sequence model originally designed for natural language processing (NLP). This approach has attracted significant attention in recent years due to its great success in NLP fields. The fault diagnosis of a chemical process is a task based on multi-variable time series, which are similar to text sequences with a greater focus on long-term dependencies. This paper proposes a modified transformer model called Target Transformer, which includes not only a self-attention mechanism, but also a target-attention mechanism for chemical process fault diagnoses. The Tennessee Eastman (TE) process was used to evaluate our method's performance.","2022-11","2025-02-26 20:39:18","2025-02-26 20:39:18","","480-492","","","167","","","","","","","","","","English","","","","WOS:000869739300006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;32<br/>Total Times Cited:&nbsp;&nbsp;32<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","ABNORMAL SITUATION MANAGEMENT; Attention mechanism; Deep learning; Fault diagnosis; NEURAL-NETWORK; PROCESS SAFETY; SYSTEM; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9KDDZUD8","journalArticle","2024","Bittner, D; Frankenberg, C; Schröder, J","Pronoun use in preclinical and early stages of Alzheimer's dementia","COMPUTER SPEECH AND LANGUAGE","","0885-2308","10.1016/j.csl.2023.101573","","The present study aims at improving the predictive power of the use of pronouns in computational modeling of the risk of Alzheimer's dementia (AD) by (i) further determining the onset of increased pronoun use in AD and (ii) providing insights into the linguistic contexts affected by the increase early on. Pronoun use was compared longitudinally between subjects who either stayed cognitively intact (CTR-group, n = 5) or who had developed AD upon follow-up after 10-12 years (AD-group, n = 5). Data were taken from semi-structured biographical interviews, which stem from the Interdisciplinary Longitudinal Study on Adult Development and Aging (ILSE). The first interview (baseline) was conducted when all participants were still cognitively healthy. Analyses concerned the proportional distribution of 12 pronoun types and linguistic contexts of increased use. Already at baseline, the AD-group produced a significantly higher proportion of D-pronouns (der, die, das, etc.) than the CTR-group. The increase in D-pronouns did not affect linguistic contexts favoring the use of personal pronouns. Instead, we found a significantly higher proportion of D-pronouns referring to family members and a significantly higher proportion of personal pro-nouns referring to non-family humans in the AD-group than in the CTR-group. Our results suggest that the predictive power of the use of pronouns can be significantly improved in computational modeling of the risk of AD by assessing language material that induces the use of pronouns in linguistic contexts affected by the increase.","2024-03","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","84","","","","","","","","","","English","","","","WOS:001096776400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Alzheimer's disease; COGNITIVE FUNCTION; DISEASE; DISORDERS; Early recognition; LIFE; Longitudinal; Pronoun use; SPEECH; Spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZGMSSTKJ","journalArticle","2025","Saravana, L; Ngo, QH; Zhang, JH; Vu, T; Vu, TL","Integrated attentive Bi-LSTM conditional GAN for power system oscillation localization","ELECTRIC POWER SYSTEMS RESEARCH","","0378-7796","10.1016/j.epsr.2025.111456","","This paper presents an advanced deep learning framework that combines the Transformer model with either Long Short-Term Memory (LSTM) or Bidirectional Long Short-Term Memory (Bi-LSTM) in a Conditional Generative Adversarial Network (cGAN) architecture. This innovative framework is specifically designed to address forced oscillation (FO) source localization in power systems. The proposed methodology makes two key contributions to the field. Firstly, synthetic time series data during FO occurrences is generated by integrating the Transformer architecture with LSTM/ Bi-LSTM neural networks. Secondly, the cGAN's Discriminator- Classifier component is employed to predict the location of the oscillation source. The experimental results validate our framework's performance in two areas: generating synthetic oscillation datasets and enhancing FO source identification accuracy compared to traditional approaches. The proposed Transformer Bi-LSTM cGAN architecture outperforms the existing methods, particularly in challenging situations with deliberate faults and mixed fault scenarios, achieving an 87% to 96% accuracy in oscillation source identification, thus validating its viability for real-world power grid deployment.","2025-05","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","242","","","","","","","","","","English","","","","WOS:001419666800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","Bi-LSTM; cGAN; Forced oscillation; LOCATION; Multi-head attention; OSL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GV2X5FK7","journalArticle","2024","Hortúa, HJ; Mora-Valencia, A","Forecasting VIX using Bayesian deep learning","INTERNATIONAL JOURNAL OF DATA SCIENCE AND ANALYTICS","","2364-415X","10.1007/s41060-024-00562-5","","Recently, deep learning techniques are gradually replacing traditional statistical and machine learning models as the first choice for price forecasting tasks. In this paper, we leverage probabilistic deep learning for inferring the volatility index VIX. We employ the probabilistic counterpart of WaveNet, Temporal Convolutional Network (TCN), and Transformers. We show that TCN outperforms all models with an RMSE around 0.189. In addition, it has been well known that modern neural networks provide inaccurate uncertainty estimates. For solving this problem, we use the standard deviation scaling to calibrate the networks. Furthermore, we found out that MNF with Gaussian prior outperforms Reparameterization Trick and Flipout models in terms of precision and uncertainty predictions. Finally, we claim that MNF with Cauchy and LogUniform prior distributions yield well-calibrated TCN, and Transformer and WaveNet networks being the former that best infer the VIX values for one and five-step-ahead forecasting, and the probabilistic Transformer model yields an adequate forecasting for the COVID-19 pandemic period.","2024-06-14","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","","","","","","","","","","","English","","","","WOS:001246495900002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;89</p>","","","Bayesian neural networks; Calibration; DYNAMICS; Forecasting; IMPLIED VOLATILITY; INDEX; NETWORKS; PREDICTION; RETURNS; RISK PREMIUM; STOCK; Volatility index","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FKC6ZM2I","journalArticle","2022","Gustavsen, B","Inclusion of Neutral Points in Measurement-Based Frequency-Dependent Transformer Model","IEEE TRANSACTIONS ON POWER DELIVERY","","0885-8977","10.1109/TPWRD.2021.3098701","","Measurement-based wide-band black-box transformer models are well suited for simulation studies of high-frequency transients in power systems. The inclusion of neutral points in such models can be difficult when the model is required to simulate voltage transfer to windings with high-impedance loads. The difficulty arises because it is then necessary to include the small winding capacitive currents in the measurement and model extraction procedure, while at the same time the capacitances can be asymmetrical with respect to the winding ends. This paper introduces a new measurement procedure which can accurately capture the effect of such capacitive asymmetries. The procedure is demonstrated for a wye-wye connected transformer. The measurement and subsequent passive rational modeling results in two alternative models. The first is a four-terminal model with bonded high-voltage and low-voltage terminals, suitable for simulation of lightning overvoltages in distribution systems. The second is a full eight-terminal model, suitable for general purpose transient studies.","2022-06","2025-02-26 20:39:18","2025-02-26 20:39:18","","1785-1794","","3","37","","","","","","","","","","English","","","","WOS:000800228100046","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","Admittance; Admittance measurement; Current measurement; frequency dependent; Frequency measurement; modeling; MULTIPORT SYSTEMS; neutral points; PASSIVITY; Power transformer insulation; Transformer; Voltage measurement; Windings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G7G5BRAF","journalArticle","2024","Mukiri, R; Burra, VB","A Novel Vision Transformer Model for Rumor Prediction in COVID-19 Data CT Images","JOURNAL OF INTELLIGENT & FUZZY SYSTEMS","","1064-1246","10.3233/JIFS-236842","","The convergence of healthcare and deep learning has engendered transformative solutions for myriad medical challenges. Amid the COVID-19 pandemic, innovative strategies are imperative to mitigate the propagation of misinformation and myths, which can exacerbate the crisis. This study embarks on a pioneering research quest, harnessing advanced deep learning methodologies, including the novel Vision Transformer (ViT) model and state-of-the-art (SOTA) models, to predict and quell the dissemination of rumors within the COVID-19 milieu. By synergizing the capabilities of Vision Transformers (ViTs) with cutting-edge SOTA models, the proposed approach strives to elevate the precision of information disseminated through traditional and digital media platforms, thereby cultivating informed decision-making and public awareness. Central to this inquiry is the development of a bespoke vision transformer architecture, adeptly tailored to scrutinize CT images associated with COVID-19 cases. This model adeptly captures intricate patterns, anomalies, and features within the images, facilitating precise virus detection. Extending beyond conventional methodologies, the model adroitly harnesses the scalability and hierarchical learning intrinsic to deep learning frameworks. It delves into spatial relationships and finer intricacies within CT scans. An extensive dataset of COVID-19-related CT images, encompassing diverse instances, stages, and severities, is meticulously curated to fully exploit the innovative potential of the vision transformer model. Thorough training, validation, and testing refine the model's predictive prowess. Techniques like data augmentation and transfer learning bolster generalization and adaptability for real-world scenarios. The efficacy of this research is gauged through comprehensive assessments, encompassing sensitivity, specificity, and prediction accuracy. Comparative analyses against existing methods underscore the superior performance of the novel model, highlighting its transformative influence on predicting and mitigating rumor propagation during the COVID-19 pandemic. Enhanced interpretability sheds light on the decision-making process, augmenting the model's utility within real-world decision support systems. By harnessing the transformative capabilities of vision transformers and synergizing them with advanced SOTA models, this study offers a robust solution to counter the dissemination of misinformation during the pandemic. The model ' s proficiency in discerning intricate patterns in COVID-19-related CT scans signifies a pivotal leap toward combating the infodemic. This endeavor culminates in more precise public health communication and judicious decision-making, ushering in a new era of leveraging cutting-edge deep learning for societal well-being amidst the challenges posed by the COVID-19 era.","2024","2025-02-26 20:39:18","2025-02-26 20:39:18","","3635-3648","","2","46","","","","","","","","","","English","","","","WOS:001193319500037","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;78</p>","","","COVID-19; deep learning; Healthcare; INFECTIOUS-DISEASES; misinformation; rumor prediction; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L6B3HMZY","journalArticle","2024","Qian, YC; Yin, XY","Semantic-enhanced graph neural networks with global context representation","MACHINE LEARNING","","0885-6125","10.1007/s10994-024-06523-0","","Node classification is a crucial task for efficiently analyzing graph-structured data. Related semi-supervised methods have been extensively studied to address the scarcity of labeled data in emerging classes. However, two fundamental weaknesses hinder the performance: lacking the ability to mine latent semantic information between nodes, or ignoring to simultaneously capture local and global coupling dependencies between different nodes. To solve these limitations, we propose a novel semantic-enhanced graph neural networks with global context representation for semi-supervised node classification. Specifically, we first use graph convolution network to learn short-range local dependencies, which not only considers the spatial topological structure relationship between nodes, but also takes into account the semantic correlation between nodes to enhance the representation ability of nodes. Second, an improved Transformer model is introduced to reasoning the long-range global pairwise relationships, which has linear computational complexity and is particularly important for large datasets. Finally, the proposed model shows strong performance on various open datasets, demonstrating the superiority of our solutions.","2024-10","2025-02-26 20:39:18","2025-02-26 20:39:18","","7761-7781","","10","113","","","","","","","","","","English","","","","WOS:001209541700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Global context; Graph neural network; Node classification; Semantic information","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V8GBBEPP","journalArticle","2024","Sun, WR; Ma, YJ; Wang, RL","k-NN attention-based video vision transformer for action recognition","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2024.127256","","Action Recognition aims to understand human behavior and predict a label for each action. Recently, Vision Transformer (ViT) has achieved remarkable performance on action recognition, which models the long sequences token over spatial and temporal index in a video. The fully -connected self -attention layer is the fundamental key in the vanilla Transformer. However, the redundant architecture of the vision Transformer model ignores the locality of video frame patches, which involves non -informative tokens and potentially leads to increased computational complexity. To solve this problem, we propose a k -NN attention -based Video Vision Transformer (k-ViViT) network for action recognition. We adopt k -NN attention to Video Vision Transformer (ViViT) instead of original self -attention, which can optimize the training process and neglect the irrelevant or noisy tokens in the input sequence. We conduct experiments on the UCF101 and HMDB51 datasets to verify the effectiveness of our model. The experimental results illustrate that the proposed k-ViViT achieves superior accuracy compared to several state-of-the-art models on these action recognition datasets.","2024-03-14","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","574","","","","","","","","","","English","","","","WOS:001172469600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Action recognition; Attention mechanism; Transformer; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZCDHVN3K","journalArticle","2022","Chen, H; Wang, ZH; Tian, HY; Yuan, LT; Wang, X; Leng, P","A Robust Visual Tracking Method Based on Reconstruction Patch Transformer Tracking","SENSORS","","1424-8220","10.3390/s22176558","","Recently, the transformer model has progressed from the field of visual classification to target tracking. Its primary method replaces the cross-correlation operation in the Siamese tracker. The backbone of the network is still a convolutional neural network (CNN). However, the existing transformer-based tracker simply deforms the features extracted by the CNN into patches and feeds them into the transformer encoder. Each patch contains a single element of the spatial dimension of the extracted features and inputs into the transformer structure to use cross-attention instead of cross-correlation operations. This paper proposes a reconstruction patch strategy which combines the extracted features with multiple elements of the spatial dimension into a new patch. The reconstruction operation has the following advantages: (1) the correlation between adjacent elements combines well, and the features extracted by the CNN are usable for classification and regression; (2) using the performer operation reduces the amount of network computation and the dimension of the patch sent to the transformer, thereby sharply reducing the network parameters and improving the model-tracking speed.","2022-09","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","17","22","","","","","","","","","","English","","","","WOS:000851719700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","CNN; cross-attention; transformer; transformer-based tracker","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZLV5PH6S","journalArticle","2022","Cheng, LZ; Ben, PY; Qiao, YC","Research on Automatic Error Correction Method in English Writing Based on Deep Neural Network","COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE","","1687-5265","10.1155/2022/2709255","","As one of the most widely used languages in the world, English plays a vital role in the communication between China and the world. However, grammar learning in English is a difficult and long process for English learners. Especially in English writing, English learners will inevitably make various grammatical writing errors. Therefore, it is extremely important to develop a model for correcting various writing errors in English writing. This can not only be used for automatic inspection and proofreading of English texts but also enable students to achieve the purpose of autonomous practice. This paper constructs an English writing error correction model and applies it to the actual system to realize automatic checking and correction of writing errors in English composition. This paper uses the deep learning model of Seq2Seq_Attention model and transformer model to eliminate deep-level errors. Statistical learning is combined with deep learning and adopted a model integration method. The output of each model is sent to the n-gram language model for scoring, and the highest score is selected as output.","2022-03-10","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","2022","","","","","","","","","","English","","","","WOS:000779486200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","ELEMENTARY-SCHOOL STUDENTS; MODEL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J9Y3HS96","journalArticle","2021","Gustavsen, B","Passivity assessment and enforcement utilizing eigenpairs information","ELECTRIC POWER SYSTEMS RESEARCH","","0378-7796","10.1016/j.epsr.2021.107041","","Rational models can be a cause of unstable time domain simulations if they are non-passive. One commonly applied method for ensuring model passivity is to combine a passivity assessment step with a passivity enforcement step in an iterative loop where the model's residue matrices are updated in each pass. This paper shows a new variant of such scheme that is computationally more efficient than an existing one. The advantage is achieved by transferring eigenpairs information between the two steps, rather than frequency samples where passivity violations exist. This leads to fewer inactive constraints in the constrained least squares problem associated with the passivity enforcement step, and thereby faster solving. The new approach is combined with the residue perturbation method known as RP-NNLS for maximum performance. The resulting procedure is demonstrated for the modeling of components with many terminals, a white-box transformer impedance matrix, grounding mat admittance matrix, and a black-box transformer model obtained via frequency sweep measurements.","2021-05","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","194","","","","","","","","","","English","","","","WOS:000632386100015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Eigenpairs; MACROMODELS; MATRICES; MODEL; Non-negative least squares; Passivity assessment; Passivity enforcement; PERTURBATION; Residue perturbation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CPZRBETV","journalArticle","2025","Sha, ZH; Lan, Y; Zhang, C; Wang, H; Gao, ZY; Zhang, BL; Shu, H","OpTrans: enhancing binary code similarity detection with function inlining re-optimization","EMPIRICAL SOFTWARE ENGINEERING","","1382-3256","10.1007/s10664-024-10605-x","","Binary code similarity detection (BCSD) is pivotal in system security including reverse engineering, vulnerability detection and software component analysis. Recent studies on BCSD have proliferated, yet they exhibit poor performance when confronting semantic alterations (e.g., function inlining) caused by compiler optimization. To tackle this challenge, we present OpTrans, an innovative framework that fuses binary code Optimization techniques with the Transformer model for BCSD. OpTrans employs an algorithm based on binary program analysis to determine which functions should be inlined, followed by binary rewriting techniques to effectuate re-optimization on binaries. This innovative method significantly reduces false positives and enhances model performance in real-world BCSD tasks. We evaluated OpTrans on the BinaryCorp datasets, and it outperformed the state-of-the-art BCSD solutions by 21.5% on average. The inline re-optimization improved all BCSD solutions by up to 32.1%. Our ablation study and vulnerability experiment demonstrate the practicality of inline re-optimization in real-world detection scenarios, showing the usefulness of our approach.","2025-03","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","2","30","","","","","","","","","","English","","","","WOS:001383499000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Neural networks; Optimization; Similarity detection; Static analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ATHUZZG7","journalArticle","2025","Jeon, B; Hwang, J; Moon, M","Exploration of deep-learning-based dose rate estimation model for a large-volume plastic scintillation detector","NUCLEAR ENGINEERING AND TECHNOLOGY","","1738-5733","10.1016/j.net.2024.07.054","","This study explores a deep-learning-based dose rate estimation model for a large-volume plastic scintillation detector. Large-volume plastic scintillators are typically utilized as detector materials for radiation portal monitors (RPMs); however, they can also be utilized for environmental radiation monitoring. We introduced a deep-learning approach to estimate the ambient dose equivalent (H*(10)) from the spectral input using a transformer architecture. The performance of the model was compared with that of other models with conventional architectures and verified using simulated and measured spectra. In addition, we present a model explanation and an uncertainty quantification approach to ensure the reliability of the dose rate estimation model. Our verification demonstrates that the behavior of the model aligns with domain knowledge and that the uncertainty of the model's estimations increases according to the increment in the statistical uncertainties of the input spectra. The experimental results indicate that the model shows a promising performance as a practical application for RPMs.","2025-01","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","1","57","","","","","","","","","","English","","","","WOS:001398820600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Deep learning; Explainable artificial intelligence; NAI(TL); Sanity test; Spectrum-to-dose-rate estimation; Transformer model; Uncertainty quantification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K2PDDP7L","journalArticle","2025","Zhao, HY; Sun, JB; Wang, XY; Wang, YF; Su, Y; Wang, J; Wang, L","Real-time and high-accuracy defect monitoring for 3D concrete printing using transformer networks","AUTOMATION IN CONSTRUCTION","","0926-5805","10.1016/j.autcon.2024.105925","","Defects and anomalies during the 3D concrete printing (3DCP) process significantly affect final construction quality. This paper proposes a real-time, high-accuracy method for monitoring defects in the printing process using a transformer-based detector. Despite limited data availability, deep learning-based data augmentation and image processing techniques were employed to enable effective training of this complex transformer model. A range of enhancement strategies was applied to the RT-DETR, resulting in remarkable improvements, including a mAP50 of 98.1 %, mAP50-95 of 68.0 %, and a computation speed of 72 FPS. The enhanced RT-DETR outperformed state-of-the-art detectors such as YOLOv8 and YOLOv7 in detecting defects in 3DCP. Furthermore, the improved RT-DETR was used to analyze the relationships between defect count, size, and printer parameters, providing guidance for operators to fine-tune printer settings and promptly address defects. This monitoring method reduces material waste and minimizes the risk of structural collapse during the printing process.","2025-02","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","170","","","","","","","","","","English","","","","WOS:001390357900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;71</p>","","","3D concrete printing; CHALLENGES; Computer vision; Generative AI; Real-time monitoring; Transformer networks; VISION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EUMUL39K","journalArticle","2023","Zhao, J; Wang, SS; Jia, XY; Gao, Y; Zhu, W; Ma, F; Liu, Q","Underwater target perception algorithm based on pressure sequence generative adversarial network","OCEAN ENGINEERING","","0029-8018","10.1016/j.oceaneng.2023.115547","","In recent years, underwater target perception algorithms based on deep learning have attracted extensive attention. Deep learning can independently learn to extract features from a large number of labelled data, which improves the robustness of underwater target perception accuracy. However, owing to the high collection cost in the underwater natural environment and the high time cost of simulated calculations, it is often unrealistic to provide a large number of labelled data. To solve this problem, this paper proposes an underwater target perception algorithm based on a generative adversarial network (GAN). This GAN uses the transformer model to augment the samples of a small number of simulated underwater pressure sequences and then establishes a multilayer gated recurrent unit (GRU) network to recognise the azimuth, distance, and velocity of underwater targets. The experimental results show that the method proposed in this paper can effectively realise underwater target perception, and with an accuracy of 97.86%, and the root mean square errors of the target distance, azimuth, and velocity estimations are 0.1244, 0.9828, and 0.8271, respectively.","2023-10-15","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","286","","","","","","","","","","English","","","","WOS:001065521100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Deep learning; GAN; GRU; Transformer; Underwater target perception","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q2YCP8NL","journalArticle","2023","Zhang, XY; Cui, YJ; Huo, YK","Deformable patch embedding-based shift module-enhanced transformer for panoramic action recognition","VISUAL COMPUTER","","0178-2789","10.1007/s00371-023-02959-y","","360(?) video action recognition is one of the most promising fields with the popularity of omnidirectional cameras. To obtain a more precise action understanding in panoramic scene, in this paper, we propose a deformable patch embedding-based temporal shift module-enhanced vision transformer model (DS-ViT), which aims to simultaneously eliminate the distortion effects caused by equirectangular projection (ERP) and construct temporal relationship among the video sequences. Panoramic action recognition is a practical but challenging domain for the lack of panoramic feature extraction methods. With deformable patch embedding, our scheme can adaptively learn the position offsets between different pixels, which effectively captures the distorted features. The temporal shift module facilitates temporal information exchanging by shifting part of the channels with zero parameters. Thanks to the powerful encoder, DS-ViT can efficiently learn the distorted features from the ERP inputs. Simulation results show that our proposed solution outperforms the state-of-the-art two-stream solution by an action accuracy of 9.29% and an activity accuracy of 8.18%, where the recent EgoK360 dataset is employed.","2023-08","2025-02-26 20:39:18","2025-02-26 20:39:18","","3247-3257","","8","39","","","","","","","","","","English","","","","WOS:001019834000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","Action recognition; Panoramic; Temporal shift; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7S4LL8L8","journalArticle","2023","Kuang, HL; Wan, WF; Wang, YH; Wang, J; Qiu, W","Automated Collateral Scoring on CT Angiography of Patients with Acute Ischemic Stroke Using Hybrid CNN and Transformer Network","BIOMEDICINES","","2227-9059","10.3390/biomedicines11020243","","Collateral scoring plays an important role in diagnosis and treatment decisions of acute ischemic stroke (AIS). Most existing automated methods rely on vessel prominence and amount after vessel segmentation. The purpose of this study was to design a vessel-segmentation free method for automating collateral scoring on CT angiography (CTA). We first processed the original CTA via maximum intensity projection (MIP) and middle cerebral artery (MCA) region segmentation. The obtained MIP images were fed into our proposed hybrid CNN and Transformer model (MPViT) to automatically determine the collateral scores. We collected 154 CTA scans of patients with AIS for evaluation using five-folder cross validation. Results show that the proposed MPViT achieved an intraclass correlation coefficient of 0.767 (95% CI: 0.68-0.83) and a Kappa of 0.6184 (95% CI: 0.4954-0.7414) for three-point collateral score classification. For dichotomized classification (good vs. non-good and poor vs. non-poor), it also achieved great performance.","2023-02","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","2","11","","","","","","","","","","English","","","","WOS:000938947100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","acute ischemic stroke; ALBERTA STROKE; CIRCULATION; collateral scoring; COMPUTED-TOMOGRAPHY; CT angiography; FLOW; hybrid CNN and Transformer; INFARCT VOLUME; KNOWLEDGE; TISSUE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5E9L9TC2","journalArticle","2022","Gao, K; He, HJ; Lu, DN; Xu, LL; Ma, LF; Li, J","Optimizing and Evaluating Swin Transformer for Aircraft Classification: Analysis and Generalizability of the MTARSI Dataset","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3231327","","Aircraft classification via remote sensing images has many commercial and military applications. The Swin-Transformer has shown great promise, recently dominating general-purpose image classification benchmarks such as ImageNet. In this paper, we test whether the performance of the Swin-Transformer on general-purpose image classification translates to domain-specific aircraft classification using the Multi-Type Aircraft from the Remote Sensing Images dataset. We also investigate the effect of training procedure vs. model selection on the validation score. Our carefully trained Swin-Transformer model achieved an impressive 99.4 % validation set accuracy without super-resolution, and 99.5 % with super-resolution. Moreover, the generalization of models trained on the MTARSI dataset to real-world and synthetic aircraft classification is evaluated with some out-of-distribution samples. Our results demonstrate that the lack of complexity and heterogeneity of the MTARSI dataset, and the labeling errors resulted in models which struggle to achieve high accuracy on the adopted test samples despite near perfect validation scores.","2022","2025-02-26 20:39:18","2025-02-26 20:39:18","","134427-134439","","","10","","","","","","","","","","English","","","","WOS:000906221900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","Aircraft classification; deep learning; MTARSI dataset; out-of-distribution; RECOGNITION; remote sensing; self-attention; Swin transformer; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JIXL3WWC","journalArticle","2024","Huang, JH; Zhang, C","Daily Tourism Demand Forecasting with the iTransformer Model","SUSTAINABILITY","","2071-1050","10.3390/su162310678","","Accurate forecasting of tourist volume is crucial for the sustainable development of the tourism industry. Deep-learning methods based on multivariate data can enhance the accuracy of tourism demand forecasting, enabling tourism management departments and enterprises to make evidence-based decisions. This study adopts an inverted transformer approach with a self-attention mechanism, which can improve the extraction of correlation features from the time series of multiple variables. Taking Zhejiang Province, a major tourist destination in China, and Hangzhou, a famous tourist city in China, as case studies, this research considers historical tourist volume, search engine data, weather data, date pattern data, and seasonal data in daily tourism volume forecasting. By comparing the forecasting results with three benchmark models, including CNN, RNN, and LSTM, the inverted transformer model's effectiveness in forecasting the daily total visitors and overnight visitors is validated. This study's findings can be applied to forecast the regional daily tourist arrivals, enabling decision-makers in the tourism sector to make more precise forecasts and devise more dependable plans.","2024-12","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","23","16","","","","","","","","","","English","","","","WOS:001377803600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","ARRIVALS; attention mechanism; daily tourism demand; inverted transformer; multiple factors; NEURAL-NETWORK; tourism demand forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5XKFB5JZ","journalArticle","2024","Hu, X; Zhang, ZZ; Fan, ZY; Yang, JD; Yang, JQ; Li, SL; He, XH","GCN-Transformer-Based Spatio-Temporal Load Forecasting for EV Battery Swapping Stations under Differential Couplings","ELECTRONICS","","2079-9292","10.3390/electronics13173401","","To address the challenge of power absorption in grids with high renewable energy integration, electric vehicle battery swapping stations (EVBSSs) serve as critically important flexible resources. Current research on load forecasting for EVBSSs primarily employs Transformer models, which have increasingly shown a lack of adaptability to the rapid growth in scale and complexity. This paper proposes a novel data-driven forecasting model that combines the geographical feature extraction capability of graph convolutional networks (GCNs) with the multitask learning capability of Transformers. The GCN-Transformer model first leverages Spearman's rank correlation to create a multinode feature set encompassing date, weather, and historical load data. It then employs data-adaptive graph generation for dynamic spatio-temporal graph construction and graph convolutional layers for spatial aggregation tailored to each node. Unique swapping patterns are identified through node-adaptive parameter learning, while the temporal dynamics of multidimensional features are managed by the Transformer's components. Numerical results demonstrate enhanced accuracy and efficiency in load forecasting for multiple and widely distributed EVBSSs.","2024-09","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","17","13","","","","","","","","","","English","","","","WOS:001311006800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","battery swapping station; deep neural network; GCN-Transformer; load forecasting; Spearman's rank correlation coefficient","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6QJNCMZY","journalArticle","2024","Schiekiera, L; Diederichs, J; Niemeyer, H","Classifying Positive Results in Clinical Psychology Using Natural Language Processing","ZEITSCHRIFT FUR PSYCHOLOGIE-JOURNAL OF PSYCHOLOGY","","2190-8370","10.1027/2151-2604/a000563","","This study addresses the gap in machine learning tools for positive results classification by evaluating the performance of SciBERT, a transformer model pretrained on scientific text, and random forest in clinical psychology abstracts. Over 1,900 abstracts were annotated into two categories: positive results only and mixed or negative results. Model performance was evaluated on three benchmarks. The best-performing model was utilized to analyze trends in over 20,000 psychotherapy study abstracts. SciBERT outperformed all benchmarks and random forest in in-domain and out-of-domain data. The trend analysis revealed nonsignificant effects of publication year on positive results for 1990-2005, but a significant decrease in positive results between 2005 and 2022. When examining the entire time span, significant positive linear and negative quadratic effects were observed. Machine learning could support future efforts to understand patterns of positive results in large data sets. The fine-tuned SciBERT model was deployed for public use.","2024-07","2025-02-26 20:39:18","2025-02-26 20:39:18","","147-159","","3","232","","","","","","","","","","English","","","","WOS:001270054000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","BIAS; ECONOMICS; FALSE; LIFE; machine learning; metascience; natural language processing; negative results; positive results; PUBLICATION DECISIONS; RANDOMIZED CONTROLLED-TRIAL; SciBERT; TESTS; text classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S7V4QHMH","journalArticle","2024","Pau, DP; Aymone, FM","Mathematical Formulation of Learning and Its Computational Complexity for Transformers' Layers","ENG","","2673-4117","10.3390/eng5010003","","Transformers are the cornerstone of natural language processing and other much more complicated sequential modelling tasks. The training of these models, however, requires an enormous number of computations, with substantial economic and environmental impacts. An accurate estimation of the computational complexity of training would allow us to be aware in advance about the associated latency and energy consumption. Furthermore, with the advent of forward learning workloads, an estimation of the computational complexity of such neural network topologies is required in order to reliably compare backpropagation with these advanced learning procedures. This work describes a mathematical approach, independent from the deployment on a specific target, for estimating the complexity of training a transformer model. Hence, the equations used during backpropagation and forward learning algorithms are derived for each layer and their complexity is expressed in the form of MACCs and FLOPs. By adding all of these together accordingly to their embodiment into a complete topology and the learning rule taken into account, the total complexity of the desired transformer workload can be estimated.","2024-03","2025-02-26 20:39:18","2025-02-26 20:39:18","","34-50","","1","5","","","","","","","","","","English","","","","WOS:001215694700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","backpropagation; complexity; large language models; PEPITA; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PKR6QK3Q","journalArticle","2023","Huang, WK; Yu, YJ; Xu, HZ; Su, ZW; Wu, Y","Hyperbolic Music Transformer for Structured Music Generation","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3257381","","In the field of music generation, generating structured music is a highly challenging research topic. Music generation methods are currently learned in Euclidean space and usually modeled as a time series without structural properties, but due to the limitations of the time series representation in Euclidean space, the hierarchical structure of music is difficult to learn, and the generated music is poorly structured. Therefore, based on hyperbolic theory, this paper proposes a Hyperbolic Music Transformer model, which considers the hierarchy in music and models the structured components of music in hyperbolic space. Meanwhile, in order for the network to have sufficient capacity to learn music data with hierarchical and power regular structure, a hyperbolic attention mechanism is proposed, which is an extension of the attention mechanism in hyperbolic space based on the definition of hyperboloid and Klein model. Subjective and objective experiments show that the model proposed in this paper is able to generate high-quality music with structure.","2023","2025-02-26 20:39:18","2025-02-26 20:39:18","","26893-26905","","","11","","","","","","","","","","English","","","","WOS:000965753400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Data models; Electronic music; hyperbolic attention; hyperbolic music transformer; hyperbolic theory; Music information retrieveal; Recurrent neural networks; Solid modeling; Structured music generation; Task analysis; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T7UMP5NZ","journalArticle","2025","Qian, K; Zhu, DW; Wu, YT; Shen, J; Zhang, SJ","TransIST: Transformer based infrared small target tracking using multi-scale feature and exponential moving average learning","INFRARED PHYSICS & TECHNOLOGY","","1350-4495","10.1016/j.infrared.2024.105674","","Small Unmanned Aerial Vehicle (UAV) tracking against complex sky backgrounds is of significant importance in both the military and civilian domains, with traditional correlation filters imposing high requirements on feature models. Consequently, a deep learning model is designed to achieve effective infrared tracking of a small UAV target. Specifically, a transformer model is used as the backbone, and a multi-scale attention is introduced to obtain the perceptual features referring to small targets. Then, an edge suppression model named side window filter is embedded to suppress the negative effect of edge on small target tracking. Furthermore, the proposed model is trained using an exponential moving average learning strategy, which results in more precise network parameters. Experimental results demonstrate that the proposed Transformer-based Infrared Small Target Tracking (TransIST) algorithm exhibits superior performance in public near-infrared videos compared to current related algorithms, with enhanced stability over correlation filtering-based trackers. The code will be available at https://github.com/len-ayan/TransIST, contributing to the remote sensing community.","2025-03","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","145","","","","","","","","","","English","","","","WOS:001395020100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Edge suppression; Exponential moving average; Infrared tracking; MODEL; Multi-scale dilated attention; Small objects; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VBG44R2M","journalArticle","2023","Acuna, E; Aparicio, R; Palomino, V","Analyzing the Performance of Transformers for the Prediction of the Blood Glucose Level Considering Imputation and Smoothing","BIG DATA AND COGNITIVE COMPUTING","","2504-2289","10.3390/bdcc7010041","","In this paper we investigate the effect of two preprocessing techniques, data imputation and smoothing, in the prediction of blood glucose level in type 1 diabetes patients, using a novel deep learning model called Transformer. We train three models: XGBoost, a one-dimensional convolutional neural network (1D-CNN), and the Transformer model to predict future blood glucose levels for a 30-min horizon using a 60-min time series history in the OhioT1DM dataset. We also compare four methods of handling missing time series data during the model training: hourly mean, linear interpolation, cubic interpolation, and spline interpolation; and two smoothing techniques: Kalman smoothing and smoothing splines. Our experiments show that the Transformer performs better than XGBoost and 1D-CNN when only continuous glucose monitoring (CGM) is used as a predictor, and that it is very competitive against XGBoost when CGM and carbohydrate intake from the meal are used to predict blood glucose level. Overall, our results are more accurate than those appearing in the literature.","2023-03","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","1","7","","","","","","","","","","English","","","","WOS:000968459800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","1D-CNN; diabetes; glucose prediction; imputation; Kalman smoothing; smoothing splines; Transformer; XGBoosting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P5UR5ET7","journalArticle","2023","Ondin, U; Balikci, A","A Transformer Design for High-Voltage Application Using LLC Resonant Converter","ENERGIES","","1996-1073","10.3390/en16031377","","The inductor-inductor-capacitor (LLC) resonant converter is a suitable topology for wide output voltage and load range applications with limited circuit parameters. One of the most significant design boundaries of an LLC resonant converter in high-voltage applications is the parasitic capacitance effect of the main circuit components, particularly the transformer and junction capacitances of the secondary rectifier network. Parasitic capacitance effects are much higher in high-voltage applications than in low-voltage applications. Therefore, the use of an LLC resonant converter is limited to high-voltage applications. This study proposes to reduce the capacitive effects of high-voltage transformers and rectification networks with a multi-winding transformer with an integrated rectifier design and to use it in high-voltage applications with the advantages of the LLC resonant converter. For the proposed prototype, comparative experimental measurements were conducted using a conventional scheme. The measurements validate the reliability of the LLC converter for high-voltage applications, improving the output regulation performance while significantly reducing parasitic capacitances.","2023-02","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","3","16","","","","","","","","","","English","","","","WOS:000930996400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","AC-RESISTANCE; CONDUCTIVE LOSSES; EQUIVALENT-CIRCUIT; high-voltage transformers; MODEL; parasitic capacitance; PART; resonant power conversion; STRAY CAPACITANCES; transformer model; WINDINGS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TA4VZLHV","journalArticle","2022","Wang, LX; Mao, SW; Nelms, RM","Transformer for Nonintrusive Load Monitoring: Complexity Reduction and Transferability","IEEE INTERNET OF THINGS JOURNAL","","2327-4662","10.1109/JIOT.2022.3163347","","Nonintrusive load monitoring (NILM) is to obtain individual appliance's electricity consumption from aggregated smart meter data. In this article, we propose a middle window transformer model, termed Midformer, for NILM. Existing models are limited by high computational complexity, dependency on data, and poor transferability. In Midformer, we first exploit patchwise embedding to shorten the input length, and then reduce the size of queries in the attention layer by only using global attention on a few selected input locations at the center of the window to capture the global context. The cyclically shifted window technique is used to preserve connection across patches. We also follow the pretraining and fine-tuning paradigm to relieve the dependency on data, reduce the computation in modeling training, and enhance transferability of the model to unknown tasks and domains. Our experimental study using two real-world data sets demonstrates the superior performance and transferability of Midformer over three baseline models.","2022-10-01","2025-02-26 20:39:18","2025-02-26 20:39:18","","18987-18997","","19","9","","","","","","","","","","English","","","","WOS:000857705300065","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Adaptation models; Attention; Computational modeling; Data models; Hidden Markov models; Internet of Things; Load modeling; nonintrusive load monitoring (NILM); smart home; transferability; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G22BX9S9","journalArticle","2023","Wei, JH; Li, ZX; Zhu, JW; Ma, HF","Enhance understanding and reasoning ability for image captioning","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-022-03624-y","","Image captioning aims to generate a grammatically correct and semantically accurate natural language description of a given image. To better capture the complex information contained in an image and expand the relevant external knowledge outside the image to generate a better image caption, this paper proposes an end-to-end image captioning framework named Enhance Understanding and Reasoning Ability for Image Captioning (EURAIC) based on the Transformer model. EURAIC provides an enhanced visual understanding ability and caption reasoning ability to improve image captioning performance. To achieve this goal, we use the semantic features of the core objects detected from the image to guide the visual features, which incorporate information on the spatial position relationships between the objects. Then, we introduce an external knowledge network to obtain information other than the inherent content of the image. In this way, a high-quality image caption sentence can be generated for the given image. Experiments on the MSCOCO dataset prove that our method is superior to the baseline model and comparable to other state-of-the-art methods.","2023-02","2025-02-26 20:39:18","2025-02-26 20:39:18","","2706-2722","","3","53","","","","","","","","","","English","","","","WOS:000794104200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","External knowledge; Image captioning; NETWORKS; Semantic feature; Spatial position relationship; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6XPUBM3W","journalArticle","2024","Cai, DQ; Chen, KW; Lin, ZZ; Zhou, JL; Mo, XY; Zhou, T","Multi-step tap-water quality forecasting in South Korea with transformer-based deep learning model","URBAN WATER JOURNAL","","1573-062X","10.1080/1573062X.2024.2399644","","The prediction of tap water quality serves as a pivotal component in enhancing water resource management. The intricate nonlinearity and inherent instability in water quality data make this task challenging. In this paper, we present a Tap-Water Quality Temporal Prediction Network (TWQ-TPN) to accurately predict tap-water quality by focusing on the impact of temporal nonlinear patterns and long-term seasonal fluctuations. To achieve this, we design two modules, namely the Temporal Feature Extraction Module (TFEM) and the Feature Transformation and Prediction Module (FTPM). The TFEM learns complex dynamic nonlinear features in the temporal domain. The FTPM is to realize feature transformation in the high-dimensional features for long-term seasonal fluctuations. Thus, our TWQ-TPN can accurately predict tap water quality trends to help improve water management. We validate TWQ-TPN's superiority using 5 years' data from 33 major water facilities in South Korea, demonstrating excellence in pH, turbidity, and residual chlorine. Ablation experiments support TWQ-TPN's rationale.","2024-10-20","2025-02-26 20:39:18","2025-02-26 20:39:18","","1109-1120","","9","21","","","","","","","","","","English","","","","WOS:001306142200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","ALGORITHM; ARTIFICIAL NEURAL-NETWORK; deep learning; LSTM; PREDICTION; Tap water quality prediction; time series forecasting; TIME-SERIES; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KPF67D5S","journalArticle","2024","Qin, HY; Che, LY; Wei, C; Xu, F; Huang, YL; Xin, T","Experimental Direct Quantum Fidelity Learning via a Data-Driven Approach","PHYSICAL REVIEW LETTERS","","0031-9007","10.1103/PhysRevLett.132.190801","","Fidelity estimation is an important technique for evaluating prepared quantum states in noisy quantum devices. A recent theoretical work proposed a frugal approach called neural quantum fidelity estimation number of measurement operators than full quantum state tomography, it uses a weight-based floating measurement strategy that predetermines the top global Pauli operators that contribute the most to the fidelity and uses discrete fidelity intervals as predictions. In this Letter, we develop a measurement-fixed NQFE based on a transformer model which requires less measurement cost and can output continuous estimates of fidelity. Here we further experimentally apply the NQFE in a realistic situation using a nuclear spin quantum processor. We prepare the ground states of local Hamiltonians and arbitrary states and investigate how to estimate their fidelity with reference states, and we compare the fidelity estimation strategy with our and the original NQFE to conventional tomography. It is shown that NQFE can estimate the fidelity with comparable accuracy to the tomography approach. In the future, NQFE will become an important tool for benchmarking quantum states ahead of the advent of well-trusted fault-tolerant quantum computers.","2024-05-09","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","19","132","","","","","","","","","","English","","","","WOS:001229410000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","STATES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PSG68VVL","journalArticle","2023","Callan, D; Foster, J","How interesting and coherent are the stories generated by a large-scale neural language model? Comparing human and automatic evaluations of machine-generated text","EXPERT SYSTEMS","","0266-4720","10.1111/exsy.13292","","Evaluation of the narrative text generated by machines has traditionally been a challenge, particularly when attempting to evaluate subjective elements such as interest or believability. Recent improvements in narrative machine text generation have been largely driven by the emergence of transformer-based language models, trained on massive quantities of data, resulting in higher quality text generation. In this study, a corpus of stories is generated using the pre-trained GPT-Neo transformer model, with human-written prompts as inputs upon which to base the narrative text. The stories generated through this process are subsequently evaluated through both human evaluation and two automated metrics: BERTScore and BERT Next Sentence Prediction, with the aim of determining whether there is a correlation between the automatic scores and the human judgements. The results show variation in human evaluation results in comparison to modern automated metrics, suggesting further work is required to train automated metrics to identify text that is defined as interesting by humans.","2023-07","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","6","40","","","","","","","","","","English","","","","WOS:000956803900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","evaluation; machine-generated text; natural language generation; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VDQBXU3C","journalArticle","2023","Liu, QQ; Wang, XP; Song, XM","Two-stage hybrid algorithm for recognition of industrial slab numbers with data quality improvement","COMPLEX & INTELLIGENT SYSTEMS","","2199-4536","10.1007/s40747-022-00933-0","","As the unique recognition of each slab, the accurate recognition of slab number is especially critical for the hot rolling production process. However, the collected data are often of low quality due to poor production environment conditions, making traditional deep learning algorithms face more significant challenges in slab numbers recognition. In this paper, a two-stage hybrid algorithm based on convolutional neural network and Transformer is proposed to identify industrial slab numbers. In the first stage, an improved CycleGAN (HybridCy) is developed to enhance the quality of real-world unpaired data. In the second stage, a multi-scale hybrid vision transformer model (MSHy-Vit) is proposed to identify slab numbers of the improved data output of stage one. The experimental results on industrial slab data show that HybridCy exhibits stable and efficient performance. Even for low-quality data with severe geometric distortion, HybridCy can accomplish quality improvement, which can help to improve recognition accuracy. In addition, the MSHy-Vit achieves superior accuracy in the recognition of slab numbers in comparison to existing methods in the literature.","2023-06","2025-02-26 20:39:18","2025-02-26 20:39:18","","3367-3384","","3","9","","","","","","","","","","English","","","","WOS:000896910000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","CycleGAN; Data quality enhancement; Slab numbers recognition; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CZ5SDG2A","journalArticle","2022","Brückner, L; Leiva, LA; Oulasvirta, A","Learning GUI Completions with User-defined Constraints","ACM TRANSACTIONS ON INTERACTIVE INTELLIGENT SYSTEMS","","2160-6455","10.1145/3490034","","A key objective in the design of graphical user interfaces (GUIs) is to ensure consistency across screens of the same product. However, designing a compliant layout is time-consuming and can distract designers from creative thinking. This paper studies layout recommendation methods that fulfill such consistency requirements using machine learning. Given a desired element type and size, the methods suggest element placements following real-world GUI design processes. Consistency requirements are given implicitly through previous layouts from which patterns are to be learned, comparable to existing screens of a software product. We adopt two recently proposed methods for this task, a Graph Neural Network (GNN) and a Transformer model, and compare them with a custom approach based on sequence alignment and nearest neighbor search (kNN). The methods were tested on handcrafted datasets with explicit layout patterns, as well as large-scale public datasets of diverse mobile design layouts. Our results show that our instance-based learning algorithm outperforms both neural network approaches. Ultimately, this work contributes to establishing smarter design tools for professional designers with explainable algorithms that increase their efficacy.","2022-03","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","1","12","","","","","","","","","","English","","","","WOS:000775481200006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","ALGORITHM; design; INTERFACE; layout completion; layouts; machine learning; User interfaces","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XN6ITTH4","journalArticle","2023","Dumitrescu, A; Jokinen, E; Paatero, A; Kellosalo, J; Paavilainen, VO; Lähdesmaki, H","TSignal: a transformer model for signal peptide prediction","BIOINFORMATICS","","1367-4803","10.1093/bioinformatics/btad228","","MotivationSignal peptides (SPs) are short amino acid segments present at the N-terminus of newly synthesized proteins that facilitate protein translocation into the lumen of the endoplasmic reticulum, after which they are cleaved off. Specific regions of SPs influence the efficiency of protein translocation, and small changes in their primary structure can abolish protein secretion altogether. The lack of conserved motifs across SPs, sensitivity to mutations, and variability in the length of the peptides make SP prediction a challenging task that has been extensively pursued over the years.ResultsWe introduce TSignal, a deep transformer-based neural network architecture that utilizes BERT language models and dot-product attention techniques. TSignal predicts the presence of SPs and the cleavage site between the SP and the translocated mature protein. We use common benchmark datasets and show competitive accuracy in terms of SP presence prediction and state-of-the-art accuracy in terms of cleavage site prediction for most of the SP types and organism groups. We further illustrate that our fully data-driven trained model identifies useful biological information on heterogeneous test sequences.","2023-06-30","2025-02-26 20:39:18","2025-02-26 20:39:18","","i347-i356","","","39","","","","","","","","","","English","","","","WOS:001027457000042","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","TAT; TOPOLOGY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DZNAE5BV","journalArticle","2023","Yang, J; Yin, YW; Yang, LQ; Ma, SM; Huang, HY; Zhang, DD; Wei, FR; Li, ZJ","GTrans: Grouping and Fusing Transformer Layers for Neural Machine Translation","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2022.3221040","","Transformer structure, stacked by a sequence of encoder and decoder network layers, achieves significant development in neural machine translation. However, vanilla Transformer mainly exploits the top-layer representation, assuming the lower layers provide trivial or redundant information and thus ignoring the bottom-layer feature that is potentially valuable. In this work, we propose the Group-Transformer model (GTrans) that flexibly divides multi-layer representations of both encoder and decoder into different groups and then fuses these group features to generate target words. To corroborate the effectiveness of the proposed method, extensive experiments and analytic experiments are conducted on three bilingual translation benchmarks and three multilingual translation tasks, including the IWLST-14, IWLST-17, LDC, WMT-14, WMT-21 and OPUS-100 benchmark. Experimental and analytical results demonstrate that our model outperforms its Transformer counterparts by a consistent gain. Furthermore, it can be successfully scaled up to 60 encoder layers and 36 decoder layers.","2023","2025-02-26 20:39:18","2025-02-26 20:39:18","","1489-1498","","","31","","","","","","","","","","English","","","","WOS:000975166400003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","Benchmark testing; Decoding; deep transformer; EFFICIENT; Machine translation; multi-layer representation fusion; multilingual translation; Neural machine translation; Speech processing; Task analysis; Training; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W2HN5JY7","journalArticle","2024","Li, JJ; Wang, P; Li, ZC; Parnow, K; Zhao, H; Ding, WP","Enhancing Lyrics Rewriting with Weak Supervision from Grammatical Error Correction Pre-training and Reference Knowledge Fusion","ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING","","2375-4699","10.1145/3687126","","Lyric rewriting involves taking the original lyrics of a song and creatively rephrasing them while preserving their core meaning and emotional essence. Sequence-to-sequence methods often face the problem of lack of annotated corpus and difficulty in understanding lyrics when dealing with the lyric rewriting task. Inspired by the language rewriting technique, grammatical error correction (GEC) and sequence-to-sequence generation techniques, and neural machine translation (NMT) methods, we propose novel self-supervised learning methods that can effectively solve the problem of the lack of a lyric rewriting corpus. In addition, we also propose a new pretrained DAE Transformer model with data prior knowledge fusion to enhance the lyric rewriting ability. The reference-as-context model (RaC-Large) constructed by us based on these two methods achieves the best results in comparison with the baseline including large language models, fully verifying the effectiveness of the new method. We also validate the effectiveness of our approach on GEC and NMT tasks, further demonstrating the potential of our approach on a broad range of sequence-to-sequence tasks.","2024-11","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","11","23","","","","","","","","","","English","","","","WOS:001388020200005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","Computing methodologies; Lexical semantics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"24U8TTSD","journalArticle","2024","Jung, YH; Cho, I; Hsu, SH; Golparvar-Fard, M","VisualSiteDiary: A detector-free Vision-Language Transformer model for captioning photologs for daily construction reporting and image retrievals","AUTOMATION IN CONSTRUCTION","","0926-5805","10.1016/j.autcon.2024.105483","","This paper presents VisualSiteDiary, a Vision Transformer -based image captioning model which creates humanreadable captions for daily progress and work activity log, and enhances image retrieval tasks. As a model for deciphering construction photologs, VisualSiteDiary incorporates pseudo -region features, utilizes high-level knowledge in pretraining, and fine-tunes for diverse captioning styles. To validate VisualSiteDiary, a new image captioning dataset, VSD, is presented. This dataset includes many realistic yet challenging cases commonly observed in commercial building projects. Experimental results using five different metrics demonstrate that VisualSiteDiary provides superior -quality captions compared to the state-of-the-art image captioning models. Excluding the task of object recognition, the presented model also outperformed mPLUG -the state-of-the-art visual -language model- in the image retrieval task by 0.6% in precision and 0.9% in recall, respectively. Detailed discussions illustrate practical examples on how VisualSiteDiary improves the process of creating daily construction reports, paving the way for future developments in the field.","2024-09","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","165","","","","","","","","","","English","","","","WOS:001247608000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;84</p>","","","Artificial intelligence; Computer vision; Image captioning; Machine learning; Natural language generation; Project controls; Project management; SAFETY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"862HDM3P","journalArticle","2024","Huo, Y; Gang, S; Dong, L; Guan, C","An Efficient Semantic Segmentation Method for Remote-Sensing Imagery Using Improved Coordinate Attention","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14104075","","Semantic segmentation stands as a prominent domain within remote sensing that is currently garnering significant attention. This paper introduces a pioneering semantic segmentation model based on TransUNet architecture with improved coordinate attention for remote-sensing imagery. It is composed of an encoding stage and a decoding stage. Notably, an enhanced and improved coordinate attention module is employed by integrating two pooling methods to generate weights. Subsequently, the feature map undergoes reweighting to accentuate foreground information and suppress background information. To address the issue of time complexity, this paper introduces an improvement to the transformer model by sparsifying the attention matrix. This reduces the computing expense of calculating attention, making the model more efficient. Additionally, the paper uses a combined loss function that is designed to enhance the training performance of the model. The experimental results conducted on three public datasets manifest the efficiency of the proposed method. The results indicate that it excels in delivering outstanding performance for semantic segmentation tasks pertaining to remote-sensing images.","2024-05","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","10","14","","","","","","","","","","English","","","","WOS:001233113600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","coordinate attention; remote-sensing image; semantic segmentation; sparse matrix; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZVS2K4XV","journalArticle","2024","Chang, BC; Li, JJ; Wang, HY; Li, MJ","Msap: multi-scale attention probabilistic network for underwater image enhancement network","SIGNAL IMAGE AND VIDEO PROCESSING","","1863-1703","10.1007/s11760-024-03181-6","","Underwater image enhancement is a key technology for improving underwater image quality and enhancing visualization. Due to the light propagation characteristics and absorption scattering by water bodies in underwater environments, underwater images often exhibit blurring, color distortion and low contrast, which severely limit the accuracy and reliability of underwater observation, underwater navigation and underwater research. To address these problems, we propose a new probabilistic network (MSAP) to learn the enhanced distribution of degraded underwater images, in which we design a high-performance transformer model that enables it to capture long-range pixel interactions, construct the enhanced distribution by conditional variational autoencoder (VAE) and adaptive instance normalization, use an attention mechanism to locate to the interested information to suppress useless information. Afterward, we predict deterministic outcomes based on a set of samples in the distribution, and we obtain more robust and stable results in the consensus process. Moreover, qualitative analysis and quantitative evaluation show that our proposed method achieves excellent performance on three different underwater datasets, compared to the traditional UIE approach.","2024-08","2025-02-26 20:39:18","2025-02-26 20:39:18","","653-661","","SUPPL 1","18","","","","","","","","","","English","","","","WOS:001204141700005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","Attention mechanism; Deep learning; OBJECT DETECTION; Probabilistic networks; Underwater image enhancement (UIE)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PB96SARU","journalArticle","2023","He, JZ; Song, JQ; Han, ZY; Cui, M; Li, BJ; Gong, QT; Huang, WH","Multi-spectral transformer with attention fusion for diabetic macular edema classification in multicolor image","SOFT COMPUTING","","1432-7643","10.1007/s00500-023-09417-w","","Diabetic macular edema (DME) is a common cause of vision-threatening diseases. Multicolor image (MCI) enables the diagnosis of DME by providing multiple spectral images of fundus structures. However, the accuracy of existing machine learning methods is still low as they fail to exploit the characteristics of MCI. A multi-spectral vision transformer model with an attention fusion (Atfusion) module is proposed in this paper for DME classification. The transformer extracts the global features of the image using a self-attentive mechanism. In addition, a novel fusion technique - AtFusion module is created to efficiently fuse the multi-spectral features from both branches. We examine the empirical performance of the proposed algorithm on our in-house data sets. The classifier is able to predict the DME status of MCIs with accuracy of 0.951, sensitivity of 0.931, specificity of 0.953, and AUC of 0.933. The experimental results prove that the proposed methodology achieves relatively better performance than the state-of-the-art method.","2023-12-06","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","","","","","","","","","","","English","","","","WOS:001115168500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Attention mechanism; Classification; Diabetic macular edema; DISEASES; Multicolor image; RETINOPATHY; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZLMWHRUZ","journalArticle","2025","Kim, S; Kim, KK; Seo, Y","Phase diagram from nonlinear interaction between superconducting order and density: toward data-based holographic superconductor","JOURNAL OF HIGH ENERGY PHYSICS","","1029-8479","10.1007/JHEP02(2025)077","","We address an inverse problem in modeling holographic superconductors. We focus our research on the critical temperature behavior depicted by experiments. We use a physics-informed neural network method to find a mass function M (F2), which is necessary to understand phase transition behavior. This mass function describes a nonlinear interaction between superconducting order and charge carrier density. We introduce positional embedding layers to improve the learning process in our algorithm, and the Adam optimization is used to predict the critical temperature data via holographic calculation with appropriate accuracy. Consideration of the positional embedding layers is motivated by the transformer model of natural-language processing in the artificial intelligence (AI) field. We obtain holographic models that reproduce borderlines of the normal and superconducting phases provided by actual data. Our work is the first holographic attempt to match phase transition data quantitatively obtained from experiments. Also, the present work offers a new methodology for data-based holographic models.","2025-02-12","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","2","","","","","","","","","","","English","","","","WOS:001421309600002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;84</p>","","","ELECTRODYNAMICS; ENERGY; Gauge-Gravity Correspondence; Holography and Condensed Matter Physics (AdS/CMT)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZX9LECI3","journalArticle","2025","Zhu, YZ; Luo, CZ; Zou, YP; Chen, DP; Wu, KS","TimbreSense: Timbre Abnormality Detection for Bel Canto with Smart Devices","ACM TRANSACTIONS ON SENSOR NETWORKS","","1550-4859","10.1145/3708545","","With the rise of mobile devices, bel canto practitioners increasingly utilize smart devices as auxiliary tools for improving their singing skills. However, they frequently encounter timbre abnormalities during practice, which, if left unaddressed, can potentially harm their vocal organs. Existing singing assessment systems primarily focus on pitch and melody and lack real-time detection of bel canto timbre abnormalities. Moreover, the diverse vocal habits and timbre compositions among individuals present significant challenges in cross-user recognition of such abnormalities. To address these limitations, we propose TimbreSense, a novel bel canto timbre abnormality detection system. TimbreSense enables real-time detection of the five major timbre abnormalities commonly observed in bel canto singing. We introduce an effective feature extraction pipeline that captures the acoustic characteristics of bel canto singing. By applying temporal average pooling to the Short-Time Fourier Transform spectrogram, we reduce redundancy while preserving essential frequency-domain information. Our system leverages a transformer model with self-attention mechanisms to extract correlation and semantic features of overtones in the frequency domain. Additionally,","2025-01","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","1","21","","","","","","","","","","English","","","","WOS:001416077000002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","CLASSIFICATION; SINGING VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5K8V7XYL","journalArticle","2024","Luo, J; Wang, CX; Yang, JL; Zhong, XH","A Transformer-Based Approach to Leakage Detection in Water Distribution Networks","SENSORS","","1424-8220","10.3390/s24196294","","The efficient detection of leakages in water distribution networks (WDNs) is crucial to ensuring municipal water supply safety and improving urban operations. Traditionally, machine learning methods such as Convolutional Neural Networks (CNNs) and Autoencoders (AEs) have been used for leakage detection. However, these methods heavily rely on local pressure information and often fail to capture long-term dependencies in pressure series. In this paper, we propose a transformer-based model for detecting leakages in WDNs. The transformer incorporates an attention mechanism to learn data distributions and account for correlations between historical pressure data and data from the same time on different days, thereby emphasizing long-term dependencies in pressure series. Additionally, we apply pressure data normalization across each leakage scenario and concatenate position embeddings with pressure data in the transformer model to avoid feature misleading. The performance of the proposed method is evaluated by using detection accuracy and F1-score. The experimental studies conducted on simulated pressure datasets from three different WDNs demonstrate that the transformer-based model significantly outperforms traditional CNN methods.","2024-10","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","19","24","","","","","","","","","","English","","","","WOS:001332772600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","attention model; BURST DETECTION; convolutional neural network; leakage detection; LOCALIZATION; transformer; water distribution networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HMFU9QHJ","journalArticle","2024","Shu, Y; Zhu, FX; Zhang, ZQ; Zhang, M; Yang, J; Wang, Y; Wang, J","Graph embedded low-light image enhancement transformer based on federated learning for Internet of Vehicle under tunnel environment","COMPUTATIONAL INTELLIGENCE","","0824-7935","10.1111/coin.12648","","The Internet of Vehicles (IoV) autonomous driving technology based on deep learning has achieved great success. However, under the tunnel environment, the computer vision-based IoV may fail due to low illumination. In order to handle this issue, this paper deploys an image enhancement module at the terminal of the IoV to alleviate the low illumination influence. The enhanced images can be submitted through IoT to the cloud server for further processing. The core algorithm of image enhancement is implemented by a dynamic graph embedded transformer network based on federated learning which can fully utilize the data resources of multiple devices in IoV and improve the generalization. Extensive comparative experiments are conducted on the publicly available dataset and the self-built dataset which is collected under the tunnel environment. Compared with other deep models, all results confirm that the proposed graph embedded Transformer model can effectively enhance the detail information of the low-light image, which can greatly improve the following tasks in IoV.","2024-04","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","2","40","","","","","","","","","","English","","","","WOS:001200320700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","dynamic graph convolution; federated learning; Internet of Vehicles; low-light image enhancement; NETWORK; swin transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NDRPGYSK","journalArticle","2024","Guo, JY; Yang, YL; Li, H; Dai, L; Huang, BK","A parallel deep neural network for intelligent fault diagnosis of drilling pumps","ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE","","0952-1976","10.1016/j.engappai.2024.108071","","This paper introduces a novel parallel deep neural network for fault diagnosis of drilling pumps. It integrates the Convolutional Block Attention Module with the AlexNet and synchronizes with the Anomaly Transformer model to delve meticulously into both the time and time-frequency domains of signals. The method prioritizes the singular extraction and subsequent amalgamation of features, facilitating a detailed view of diagnostic data and mitigating the risk of interference and overfitting. The integration of the anomaly attention of the Anomaly Transformer with the features of the Convolutional Block Attention Module results in a distinctive dual attention mechanism that is critical to the methodology. This mechanism emphasizes essential features in both the time domain and the time-frequency domain, improving the accuracy of fault diagnosis. Verification with on-site data underscores the preeminence of the approach over existing models, signaling improved reliability and accuracy in diagnosing faults in drilling pumps. This meticulous approach offers promising advances in the study and application of fault diagnosis in energy equipment, demonstrating increased efficiency and refined accuracy.","2024-07","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","133","","","","","","","","","","English","","","","WOS:001182473400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;39<br/>Total Times Cited:&nbsp;&nbsp;39<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","Deep learning; Drilling pump; Fault diagnosis; Strain signal; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C92ABTQS","journalArticle","2023","Zhao, XY; Hu, T; Mao, CX; Yuan, Y; Li, J","HAT: A Visual Transformer Model for Image Recognition Based on Hierarchical Attention Transformation","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3314573","","In the field of image recognition, Visual Transformer (ViT) has excellent performance. However, ViT, relies on a fixed self-attentive layer, tends to lead to computational redundancy and makes it difficult to maintain the integrity of the image convolutional feature sequence during the training process. Therefore, we proposed a non-normalization hierarchical attention transfer network (HAT), which introduces threshold attention mechanism and multi head attention mechanism after pooling in each layer. The focus of HAT is shifted between local and global, thus flexibly controlling the attention range of image classification. The HAT used the smaller computational complexity to improve it's scalability, which enables it to handle longer feature sequences and balance efficiency and accuracy. HAT removes layer normalization to increase the likelihood of convergence to an optimal level during training. In order to verify the effectiveness of the proposed model, we conducted experiments on image classification and segmentation tasks. The results shows that compared with classical pyramid structured networks and different attention networks, HAT outperformed the benchmark networks on both ImageNet and CIFAR100 datasets.","2023","2025-02-26 20:39:18","2025-02-26 20:39:18","","100042-100051","","","11","","","","","","","","","","English","","","","WOS:001070588300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","attention transfer mechanism; hierarchical network; image feature; image recognition; Visual transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7UBY3Y96","journalArticle","2022","Ren, XZ; Yang, BS; Liu, DYH; Zhang, HB; Lv, XY; Yao, L; Xie, J","Effective Approaches to Neural Query Language Identification","COMPUTATIONAL LINGUISTICS","","0891-2017","10.1162/coli_a_00451","","Query language identification (Q-LID) plays a crucial role in a cross-lingual search engine. There exist two main challenges in Q-LID: (1) insufficient contextual information in queries for disambiguation; and (2) the lack of query-style training examples for low-resource languages. In this article, we propose a neural Q-LID model by alleviating the above problems from both model architecture and data augmentation perspectives. Concretely, we build our model upon the advanced Transformer model. In order to enhance the discrimination of queries, a variety of external features (e.g., character, word, as well as script) are fed into the model and fused by a multi-scale attention mechanism. Moreover, to remedy the low resource challenge in this task, a novel machine translation-based strategy is proposed to automatically generate synthetic query-style data for low-resource languages. We contribute the first Q-LID test set called QID-21, which consists of search queries in 21 languages. Experimental results reveal that our model yields better classification accuracy than strong baselines and existing LID systems on both query and traditional LID tasks.(1)","2022-12","2025-02-26 20:39:18","2025-02-26 20:39:18","","887-906","","4","48","","","","","","","","","","English","","","","WOS:000995278700006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JT6NMC5J","journalArticle","2025","Gao, L; Cui, LY; Chen, SW; Deng, LZ; Wang, XK; Yan, XH; Zhu, H","AMTrans: Auto-Correlation Multi-Head Attention Transformer for Infrared Spectral Deconvolution","TSINGHUA SCIENCE AND TECHNOLOGY","","1007-0214","10.26599/TST.2024.9010131","","Infrared spectroscopy analysis has found widespread applications in various fields due to advancements in technology and industry convergence. To improve the quality and reliability of infrared spectroscopy signals, deconvolution is a crucial preprocessing step. Inspired by the transformer model, we propose an Auto-correlation Multi-head attention Transformer (AMTrans) for infrared spectrum sequence deconvolution. The auto-correlation attention model improves the scaled dot-product attention in the transformer. It utilizes attention mechanism for feature extraction and implements attention computation using the auto-correlation function. The auto-correlation attention model is used to exploit the inherent sequence nature of spectral data and to effectively recovery spectra by capturing auto-correlation patterns in the sequence. The proposed model is trained using supervised learning and demonstrates promising results in infrared spectroscopic restoration. By comparing the experiments with other deconvolution techniques, the experimental results show that the method has excellent deconvolution performance and can effectively recover the texture details of the infrared spectrum.","2025-06","2025-02-26 20:39:18","2025-02-26 20:39:18","","1329-1341","","3","30","","","","","","","","","","English","","","","WOS:001388133900013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","auto-correlation mechanism; Computational modeling; Data models; Data processing; Deconvolution; Noise; Noise reduction; Reliability; spectral deconvolution; spectroscopy; Spectroscopy; Supervised learning; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QLVZPU2W","journalArticle","2025","Li, F; Zhang, D","Transformer-Driven Affective State Recognition from Wearable Physiological Data in Everyday Contexts","SENSORS","","1424-8220","10.3390/s25030761","","The rapid advancement in wearable physiological measurement technology in recent years has brought affective computing closer to everyday life scenarios. Recognizing affective states in daily contexts holds significant potential for applications in human-computer interaction and psychiatry. Addressing the challenge of long-term, multi-modal physiological data in everyday settings, this study introduces a Transformer-based algorithm for affective state recognition, designed to fully exploit the temporal characteristics of signals and the interrelationships between different modalities. Utilizing the DAPPER dataset, which comprises continuous 5-day wrist-worn recordings of heart rate, skin conductance, and tri-axial acceleration from 88 subjects, our Transformer-based model achieved an average binary classification accuracy of 71.5% for self-reported positive or negative affective state sampled at random moments during daily data collection, and 60.29% and 61.55% for the five-class classification based on valence and arousal scores. The results of this study demonstrate the feasibility of applying affective state recognition based on wearable multi-modal physiological signals in everyday contexts.","2025-02","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","3","25","","","","","","","","","","English","","","","WOS:001419389700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;74</p>","","","affective state recognition; multi-modal data; SPEECH EMOTION RECOGNITION; transformer model; TUTORIAL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YV78NC5A","journalArticle","2025","Kang, MJ; Jiang, LY; Li, BZ; Su, SL; Weng, M; Zhao, F","An Automated Identification Method for Place Spoofing Toponyms","TRANSACTIONS IN GIS","","1361-1682","10.1111/tgis.13291","","Place spoofing toponyms (PSTs) are intentionally misleading toponyms that convey false meanings that are inconsistent with the real scenarios they represent. At present, the negative impact of PSTs on politics and the economy, especially in pursuit of commercial profits in the making of lofty toponyms, is becoming increasingly serious. It is difficult for some government departments to distinguish PSTs efficiently and comprehensively via manual methods. Therefore, there are three aspects in the creation of PSTs that require optimization to facilitate the task: semantic unit segmentation, vector representation, and classification algorithms. This paper proposes an automated method for identifying PSTs. It employs a Transformer model trained on manually labeled semantic units to perform word segmentation, utilizes a pretrained language model to generate word vectors, and employs TextRCNN for short text classification. The automated method was evaluated with 60,000 toponyms from Wuhan, China, and the results show that the weighted F1 is 97.48%, with high precision and recall, which could serve as a reference for toponym management by government departments.","2025-02","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","1","29","","","","","","","","","","English","","","","WOS:001370631500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","place spoofing toponym; pretrained language model; segmentation of toponym; short text classification; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I3Q9PQL9","journalArticle","2023","Tao, X; Adak, C; Chun, PJ; Yan, SH; Liu, HP","ViTALnet: Anomaly on Industrial Textured Surfaces With Hybrid Transformer","IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT","","0018-9456","10.1109/TIM.2023.3250225","","The coexistence of subtle and long-range anomalies in real-world industrial applications brings significant challenges for anomaly localization. Existing methods typically train deep models by utilizing the multilevel patches or layers-fusion approaches for learning the global-local distribution; however, these methods do not consider learning local and global features simultaneously, which suffer from inaccurate localization results. To this end, a hybrid transformer model, ViTALnet, is proposed here, which is established based on fine-grained feature reconstruction. Our ViTALnet first adopts the vision transformer (ViT) to extract local discriminatory features as feature representation, which leverages the global semantic capturing capability. Then, an anomaly estimation module is proposed by integrating global attention and a pyramidal architecture to enhance contextual information for fine-grain anomaly localization. The experiments were extensively conducted on industrial anomaly localization datasets MVTec Anomaly Detection (MVTec AD)-Texture, NanoTWICE, and general textured datasets KolektorSDD2, MT Defect, and Dot-patterned Fabric, where our proposed ViTALnet outperformed major state-of-the-art (SOTA) methods.","2023","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","72","","","","","","","","","","English","","","","WOS:000955734200006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;19<br/>Total Times Cited:&nbsp;&nbsp;19<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Anomaly localization; defect inspection; textured surfaces; unsupervised learning; vision transformer (ViT)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BPTJ6DNS","journalArticle","2024","Lu, H; Wei, ZQ; Zhang, K; Wang, XZ; Ali, L; Liu, H","CTsynther: Contrastive Transformer Model for End-to-End Retrosynthesis Prediction","IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS","","1545-5963","10.1109/TCBB.2024.3455381","","Retrosynthesis prediction is a fundamental problem in organic chemistry and drug synthesis. We proposed an end-to-end deep learning model called CTsynther (Contrastive Transformer for single-step retrosynthesis prediction model) that could provide single-step retrosynthesis prediction without external reaction templates or specialized knowledge. The model introduced the concept of contrastive learning in Transformer architecture and employed a contrastive learning language representation model at the SMILES sentence level to enhance model inference by learning similarities and differences between various samples. Mixed global and local attention mechanisms allow the model to capture features and dependencies between different atoms to improve generalization. We further investigated the embedding representations of SMILES learned automatically from the model. Visualization results show that the model could effectively acquire information about identical molecules and improve prediction performance. Experiments showed that the accuracy of retrosynthesis reached 53.5% and 64.4% for with and without reaction types, respectively. The validity of the predicted reactants is improved, showing competitiveness compared with semi-template methods.","2024-11","2025-02-26 20:39:18","2025-02-26 20:39:18","","2235-2245","","6","21","","","","","","","","","","English","","","","WOS:001375732400009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Accuracy; Computational modeling; Contrastive learning; Data models; Feature extraction; PATHWAYS; Predictive models; retrosynthesis prediction; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HWMJFJWE","journalArticle","2024","Dewi, C; Arshed, MA; Christanto, HJ; Rehman, HA; Muneer, A; Mumtaz, S","Enhancing Weather Scene Identification Using Vision Transformer","WORLD ELECTRIC VEHICLE JOURNAL","","2032-6653","10.3390/wevj15080373","","The accuracy of weather scene recognition is critical in a world where weather affects every aspect of our everyday lives, particularly in areas like intelligent transportation networks, autonomous vehicles, and outdoor vision systems. The importance of weather in many aspects of our life highlights the vital necessity for accurate information. Precise weather detection is especially crucial for industries like intelligent transportation, outside vision systems, and driverless cars. The outdated, unreliable, and time-consuming manual identification techniques are no longer adequate. Unmatched accuracy is required for local weather scene forecasting in real time. This work utilizes the capabilities of computer vision to address these important issues. Specifically, we employ the advanced Vision Transformer model to distinguish between 11 different weather scenarios. The development of this model results in a remarkable performance, achieving an accuracy rate of 93.54%, surpassing industry standards such as MobileNetV2 and VGG19. These findings advance computer vision techniques into new domains and pave the way for reliable weather scene recognition systems, promising extensive real-world applications across various industries.","2024-08","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","8","15","","","","","","","","","","English","","","","WOS:001307491400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","CAMERA; global feature extraction; MobileNetV2; RECOGNITION; self-attention; VGG19; Vision Transformer; weather scene","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JZS6XKPR","journalArticle","2023","Zhang, J; Fang, ZJ; Wang, Z","Multi-feature fusion enhanced transformer with multi-layer fused decoding for image captioning","APPLIED INTELLIGENCE","","0924-669X","10.1007/s10489-022-04202-y","","The objects' semantic information of the image is vital for image captioning. Though some methods have used semantic information, the alignment between the specific semantic feature and the corresponding visual feature has not been explored. In this paper, we propose a novel Multi-Feature Fusion enhanced Transformer (MFF-Transformer) for image captioning, which can realize the multi-feature fusion by aligning the specific semantic features with their corresponding visual features for achieving a better visual feature representation. In the MFF-Transformer, a novel Interacted Multi-Feature REpresentation (IMFRE) module is proposed, which effectively fuses the visual features with the semantic features by adaptive pooling to obtain global and local multi-feature information for enhancing the visual features. In addition, a new Multi-Layer Features Fusion (MLFF) module is proposed to achieve complete and valid multi-layer decoding information for utilizing the hierarchical context of the MFF-Transformer model. Experiments on the MSCOCO dataset illustrate that our proposed MFF-Transformer can achieve good performance and outperform other state-of-the-art methods.","2023-06","2025-02-26 20:39:18","2025-02-26 20:39:18","","13398-13414","","11","53","","","","","","","","","","English","","","","WOS:000865724500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","ATTENTION; Image captioning; Multi-feature fusion enhanced transformer; Multi-layer fused decoding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X5Y83SPW","journalArticle","2022","Tang, XY; Xu, ZB; Wang, ZG","A Novel Fault Diagnosis Method of Rolling Bearing Based on Integrated Vision Transformer Model","SENSORS","","1424-8220","10.3390/s22103878","","In order to improve the diagnosis accuracy and generalization of bearing faults, an integrated vision transformer (ViT) model based on wavelet transform and the soft voting method is proposed in this paper. Firstly, the discrete wavelet transform (DWT) was utilized to decompose the vibration signal into the subsignals in the different frequency bands, and then these different subsignals were transformed into a time-frequency representation (TFR) map by the continuous wavelet transform (CWT) method. Secondly, the TFR maps were input with respective to the multiple individual ViT models for preliminary diagnosis analysis. Finally, the final diagnosis decision was obtained by using the soft voting method to fuse all the preliminary diagnosis results. Through multifaceted diagnosis tests of rolling bearings on different datasets, the diagnosis results demonstrate that the proposed integrated ViT model based on the soft voting method can diagnose the different fault categories and fault severities of bearings accurately, and has a higher diagnostic accuracy and generalization ability by comparison analysis with integrated CNN and individual ViT.","2022-05","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","10","22","","","","","","","","","","English","","","","WOS:000804119600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;47<br/>Total Times Cited:&nbsp;&nbsp;48<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","ELEMENT BEARING; fault diagnosis; integrated vision transformer; rolling bearing; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LDU9MT9F","journalArticle","2024","Kaushal, P; Singh, S","EnoUTSurv: Encoder-Based Universal Transformer for Survival Analysis-A Case Study on Right Censored Heart Failure Data","ARABIAN JOURNAL FOR SCIENCE AND ENGINEERING","","2193-567X","10.1007/s13369-024-09093-4","","Survival analysis, is a widely used technique for analysing time-to-event data, inclusive of censored data. Even though, numerous survival analysis approaches have performed well but still have some underlying assumptions and other limitations. To overcome these assumptions and limitations, a novel encoder-based transformer model ""E(no)UTSurv"" model, with dynamic adaptive computation time to predict the risk of heart failure has been proposed. The proposed model has better calibration and discriminative performance when compared to the state-of-the-art survival models. Additionally, it exhibits significant reductions in memory requirements (over 50%) and execution time (over 70%) when compared to transformer-based models, while maintaining or surpassing their performance, thus tackling the high computational requirements of the transformer architecture. To evaluate the scalability of the proposed model, its performance has been evaluated on the augmented dataset and the proposed model showcased similar enhanced performance. Thus, our experiments show that the proposed model has enhanced efficiency, optimal computational resource requirements and is scalable.","2024-05-10","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","","","","","","","","","","","English","","","","WOS:001220982400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Deep learning; Medical decision-making; REGRESSION; Survival analysis; Time-to-event analysis; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"854GBKP8","journalArticle","2024","Ahmad, M; Butt, MHF; Mazzara, M; Distefano, S; Khan, AM; Altuwaijri, HA","Pyramid Hierarchical Spatial-Spectral Transformer for Hyperspectral Image Classification","IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING","","1939-1404","10.1109/JSTARS.2024.3461851","","The transformer model encounters challenges with variable-length input sequences, leading to efficiency and scalability concerns. To overcome this, we propose a pyramid-based hierarchical spatial-spectral transformer (PyFormer). This innovative approach organizes input data hierarchically into pyramid segments, each representing distinct abstraction levels, thereby enhancing processing efficiency. At each level, a dedicated transformer encoder is applied, effectively capturing both local and global context. Integration of outputs from different levels culminates in the final input representation. In short, the pyramid excels at capturing spatial features and local patterns, while the transformer effectively models spatial-spectral correlations and long-range dependencies. Experimental results underscore the superiority of the proposed method over state-of-the-art approaches, achieving overall accuracies of 96.28% for the Pavia University dataset and 97.36% for the University of Houston dataset. In addition, the incorporation of disjoint samples augments robustness and reliability, thereby highlighting the potential of PyFormer in advancing hyperspectral image classification (HSIC).","2024","2025-02-26 20:39:18","2025-02-26 20:39:18","","17681-17689","","","17","","","","","","","","","","English","","","","WOS:001336298000003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","Computational modeling; Convolution; Data mining; Feature extraction; hyperspectral image classification (HSIC); NETWORK; Pyramid network; Semantics; spatial-spectral transformer (SST); Training; Transformers; VISION TRANSFORMER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"38637YGV","journalArticle","2024","Peng, C; Liu, YK; Ouyang, YY; Tang, ZH; Luo, L; Gui, WH","Grade Prediction of Froth Flotation Based on Multistep Fusion Transformer Model","IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS","","1551-3203","10.1109/TII.2023.3342458","","Accurate and timely foam grade prediction plays an important role in the flotation foam industry process. However, the information between foam characteristic series and foam grade series at different sampling times often does not match, making the prediction result lagging behind. A multistep fusion transformer (MSFT) model is designed in this article. First, we extract multiple froth time series as input to correlate feature information and grade information under multiple time series, then, a self-attention structure is designed to fuse at multiple scales, which enhances the degree of information correlation under different time series, finally, the information matrix is passed through the fully connected layer to obtain the final prediction result. Compared with the existing froth grade network recurrent neural networks (RNN), long short-term memory (LSTM), gated recurrent unit, Transformer, Enc-Dec (RNN), feature reconstruction-regression, Siamese time series and difference (LSTM), and FlotationNet models, the MSFT model has reduced the baseline by 30.3%, 30.3%, 30%, 66.9%, 30%, 45.8%, 55.2%, and 52.5%, respectively, among all indicators.","2024-04","2025-02-26 20:39:18","2025-02-26 20:39:18","","6030-6040","","4","20","","","","","","","","","","English","","","","WOS:001137399600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","Froth flotation process; grade prediction; multistep fusion transformer (MSFT); NETWORK; REMAINING USEFUL LIFE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UYZEGR9E","journalArticle","2023","Arevalo, SE; Buehler, MJ","Learning from nature by leveraging integrative biomateriomics modeling toward adaptive and functional materials","MRS BULLETIN","","0883-7694","10.1557/s43577-023-00610-8","","Biological systems generate a wealth of materials, and their design principles inspire and inform scientists from a broad range of fields. Nature often adapts hierarchical multilevel material architectures to achieve a set of properties for specific functions, providing templates for difficult tasks of understanding the intricate interplay between structure-property-function relationships. While these materials tend to be complex and feature intricate functional interactions across scales, molecular-based multiscale modeling, machine learning, and artificial intelligence combined with experimental approaches to synthesize and characterize materials have emerged as powerful tools for analysis, prediction, and design. This article examines materiomic graph-based modeling frameworks for assisting researchers to pursue materials-focused studies in a biological context, and provides an overview of methods that can be applied to bottom-up manufacturing, including a historical perspective of bioinspired materials research. Through the advent of novel modeling architectures and diverse systems from nature, there is potential to develop materials with improved properties.","2023-11","2025-02-26 20:39:18","2025-02-26 20:39:18","","1140-1153","","11","48","","","","","","","","","","English","","","","WOS:001086924100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;104</p>","","","ARTIFICIAL-INTELLIGENCE; BIOLOGICAL-MATERIALS; Biomaterial; Biomimetic; BONE; DESIGN; DISCOVERY; FRACTURE MECHANISMS; Machine learning; Modeling; Multiscale; NETWORKS; SILK; SIMULATION; TRANSFORMER MODEL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HSR3VPXD","journalArticle","2023","Chang, BS; Xin, J; Fu, MM; Jagota, V; Soni, M; Ray, S","Experimental design and data analysis and optimization of mechanical condition diagnosis for transformer sets","NONLINEAR ENGINEERING - MODELING AND APPLICATION","","2192-8010","10.1515/nleng-2022-0215","","The typical power transformer diagnosis approach is imprecise and unstable. A support vector machine classification algorithm is proposed, by designing an algorithm program that can improve the accuracy and speed of energy transformer diagnosis, the vibration signals of the surface twisting in different states are extracted by wavelet packet energy spectrum signal processing method, it is verified that the curve similarity between the vibration simulation model and the measured data is greater than 0.98, proving the simulation model's validity. The calculation technique of online short circuit inductance is developed from the equivalent transformer model, and the variation error of simulation results is less than 0.05% when compared to the real transformer characteristics. The suggested state diagnostic technique successfully compensates for the drawbacks of the reactance method, which is incapable of detecting and judging the slightly loose or faulty winding. The method's accuracy and superiority, as well as the practicability of the state diagnosis system, are demonstrated.","2023-08-05","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","1","12","","","","","","","","","","English","","","","WOS:001043316900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","data analysis; DC-DC CONVERTER; DISSOLVED-GAS ANALYSIS; experimental design; FAULT-DIAGNOSIS; mechanical state; SUPPORT VECTOR MACHINE; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KIBAC3NT","journalArticle","2022","Fan, YH; Wan, J; Yang, Z; Zhang, SL; Zhao, JX; Gao, G; Zhang, XJ; Shen, HY; Xiao, N; Zhang, YY; Yan, YP; Liang, XX","Coplanar Asymmetry Transformer Distributed Modeling for X-Band Drive Power Amplifier Design on GaN Process","ELECTRONICS","","2079-9292","10.3390/electronics11162478","","In this paper, a methodology for designing a distributed model for coplanar asymmetry transformer on gallium nitride (GaN) process is proposed, which can accurately characterize the transformer's feature up to a millimeter-wave band. The paper analyses a transformer-based matching circuit and proposes a practical transformer design procedure. A two stage, transformer matching based X-band power amplifier (PA) is reported here. Using the proposed transformer model and correlated transformer design procedure can sharply reduce schematic design period and optimum process time. The PA chip is designed on a 0.25 mu m GaN technology process and occupies a 1.515 mm(2) area. At a 28 V supply, the gain and output power of the PA reaches 15 dB and 29 dBm respectively, and the wideband matching transformer reaches 47.6% bandwidth. To the best of our knowledge, the distributed model for coplanar asymmetry transformer and transformer-based X-band MMIC PA on GaN process in this work is the first case among the reported papers.","2022-08","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","16","11","","","","","","","","","","English","","","","WOS:000845908400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","distributed modeling; MMIC; on-chip transformer; PAE; power amplifier","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9LQ889GP","journalArticle","2022","Su, A; Wang, XQ; Wang, L; Zhang, CY; Wu, YJ; Wu, XY; Zhao, QJ; Duan, HL","Reproducing the invention of a named reaction: zero-shot prediction of unseen chemical reactions","PHYSICAL CHEMISTRY CHEMICAL PHYSICS","","1463-9076","10.1039/d1cp05878a","","While state-of-art models can predict reactions through the transfer learning of thousands of samples with the same reaction types as those of the reactions to predict, how to prepare such models to predict ""unseen"" reactions remains an unanswered question. We aimed to study the Transformer model's ability to predict ""unseen"" reactions through ""zero-shot reaction prediction (ZSRP)"", a concept derived from zero-shot learning and zero-shot translation. We reproduced the human invention of the Chan-Lam coupling reaction where the inventor was inspired by the Suzuki reaction when improving Barton's bismuth arylation reaction. After being fine-tuned with samples from these two ""existing"" reactions, the USPTO-trained Transformer could predict ""unseen"" Chan-Lam coupling reactions with 55.7% top-1 accuracy. Our model could also mimic the later stage of the history of this reaction, where the initial case of this reaction was generalized to more reactants and reagents via ""one-shot/few-shot reaction prediction (OSRP/FSRP)"" approaches.","2022-05-04","2025-02-26 20:39:18","2025-02-26 20:39:18","","10280-10291","","17","24","","","","","","","","","","English","","","","WOS:000786478200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","ACIDS; AMINES; ARYLATION; CATALYSIS; MODEL; N-PHENYLATION; TRANSFORMER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"69EJTMRE","journalArticle","2025","Zhu, FY; Zhang, J; Dang, RC; Hu, BL; Wang, Q","MTNet: Multimodal transformer network for mild depression detection through fusion of EEG and eye tracking","BIOMEDICAL SIGNAL PROCESSING AND CONTROL","","1746-8094","10.1016/j.bspc.2024.106996","","With the increasing multimodality of biomedical data, data fusion has been widely utilized in depression research, in response to the significant rise in the incidence of depression. In our study, we propose a novel multimodal transformer network (MTNet) that integrates eye tracking with EEG data for depression detection. The MTNet effectively captures both local and global spatio-temporal characteristics of multimodal data, utilizing the global receptive field of the transformer model to capture the long-term dependencies within the data. Results confirmed that our proposed MTNet surpasses the feature-based fusion and other baseline models, with a classification accuracy of 91.79 %, which highlights the potential value of multimodal fusion with biological signals in depression detection. Moreover, we specifically concentrate on the fusion stage in multimodal fusion, carrying out analysis for early, intermediate, and late fusion respectively. Our study demonstrates that intermediate fusion yields superior performance in processing EEG and eye tracking data, effectively adapting to the heterogeneity of multimodal data.","2025-02","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","100","","","","","","","","","","English","","","","WOS:001368706900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","Deep learning; Depression detection; EEG; Eye tracking; Multimodal; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CVGJV9MV","journalArticle","2024","Mo, ST; Wang, HX; Li, BX; Xue, Z; Fan, SH; Liu, XG","Powerformer: A temporal-based transformer model for wind power forecasting","ENERGY REPORTS","","2352-4847","10.1016/j.egyr.2023.12.030","","Wind Power Forecasting has emerged as a critical and dynamic research area in response to the growing demand for renewable energy. The unpredictable and stochastic nature of wind conditions, encompassing factors such as wind speed, wind direction, air temperature, and barometric pressure, poses unique challenges for accurate forecasting of wind power generation. Reliable wind power generation forecasts are essential for optimizing energy grid management, ensuring grid stability, and facilitating the integration of wind energy with existing power systems. To address these challenges, this research introduces Powerformer, a Transformer-based model designed to improve the accuracy of wind power prediction. Powerformer utilizes the infrastructure of the Transformer with innovative modifications to address the complexity of wind power prediction, enhancing temporal feature extraction capabilities while reducing complexity. The research in this study includes a comprehensive set of experiments, revealing that Powerformer achieves superior results among all models. Furthermore, the model exhibits stronger robustness, as confirmed through a series of ablation experiments validating the reasonableness of the model design.","2024-06","2025-02-26 20:39:18","2025-02-26 20:39:18","","736-744","","","11","","","","","","","","","","English","","","","WOS:001144010400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;11<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","ERROR; PREDICTION; Renewable energy; Transformer; Wind power forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HRZQXZZD","journalArticle","2023","Chen, YH; Yang, SC; Li, H; Wang, LR; Wang, BD","Prediction of Sleep Apnea Events Using a CNN-Transformer Network and Contactless Breathing Vibration Signals","BIOENGINEERING-BASEL","","2306-5354","10.3390/bioengineering10070746","","It is estimated that globally 425 million subjects have moderate to severe obstructive sleep apnea (OSA). The accurate prediction of sleep apnea events can offer insight into the development of treatment therapies. However, research related to this prediction is currently limited. We developed a covert framework for the prediction of sleep apnea events based on low-frequency breathing-induced vibrations obtained from piezoelectric sensors. A CNN-transformer network was utilized to efficiently extract local and global features from respiratory vibration signals for accurate prediction. Our study involved overnight recordings of 105 subjects. In five-fold cross-validation, we achieved an accuracy of 85.9% and an F1 score of 85.8%, which are 3.5% and 5.3% higher than the best-performed classical model, respectively. Additionally, in leave-one-out cross-validation, 2.3% and 3.8% improvements are observed, respectively. Our proposed CNN-transformer model is effective in the prediction of sleep apnea events. Our framework can thus provide a new perspective for improving OSA treatment modes and clinical management.","2023-07","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","7","10","","","","","","","","","","English","","","","WOS:001034843800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","CNN; contactless monitoring; respiratory event prediction; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"23BB8CPI","journalArticle","2023","Er, S; Yang, SH; Zhao, T","County augmented transformer for COVID-19 state hospitalizations prediction","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-023-36378-9","","The prolonged COVID-19 pandemic has tied up significant medical resources, and its management poses a challenge for the public health care decision making. Accurate predictions of the hospitalizations are crucial for the decision makers to make informed decision for the medical resource allocation. This paper proposes a method named County Augmented Transformer (CAT). To generate accurate predictions of four-week-ahead COVID-19 related hospitalizations for every states in the United States. Inspired by the modern deep learning techniques, our method is based on a self-attention model (known as the transformer model) that is actively used in Natural Language Processing. Our transformer based model can capture both short-term and long-term dependencies within the time series while enjoying computational efficiency. Our model is a data based approach that utilizes the publicly available information including the COVID-19 related number of confirmed cases, deaths, hospitalizations data, and the household median income data. Our numerical experiments demonstrate the strength and the usability of our model as a potential tool for assisting the medical resources allocation.","2023-06-20","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","1","13","","","","","","","","","","English","","","","WOS:001063223800012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SAYQNUZI","journalArticle","2023","Vaid, A; Jiang, J; Sawant, A; Lerakis, S; Argulian, E; Ahuja, Y; Lampert, J; Charney, A; Greenspan, H; Narula, J; Glicksberg, B; Nadkarni, GN","A foundational vision transformer improves diagnostic performance for electrocardiograms","NPJ DIGITAL MEDICINE","","2398-6352","10.1038/s41746-023-00840-9","","The electrocardiogram (ECG) is a ubiquitous diagnostic modality. Convolutional neural networks (CNNs) applied towards ECG analysis require large sample sizes, and transfer learning approaches for biomedical problems may result in suboptimal performance when pre-training is done on natural images. We leveraged masked image modeling to create a vision-based transformer model, HeartBEiT, for electrocardiogram waveform analysis. We pre-trained this model on 8.5 million ECGs and then compared performance vs. standard CNN architectures for diagnosis of hypertrophic cardiomyopathy, low left ventricular ejection fraction and ST elevation myocardial infarction using differing training sample sizes and independent validation datasets. We find that HeartBEiT has significantly higher performance at lower sample sizes compared to other models. We also find that HeartBEiT improves explainability of diagnosis by highlighting biologically relevant regions of the EKG vs. standard CNNs. Domain specific pre-trained transformer models may exceed the classification performance of models trained on natural images especially in very low data regimes. The combination of the architecture and such pre-training allows for more accurate, granular explainability of model predictions.","2023-06-06","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","1","6","","","","","","","","","","English","","","","WOS:001003671300002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;25<br/>Total Times Cited:&nbsp;&nbsp;25<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","NEURAL-NETWORKS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EA78YMEW","journalArticle","2021","Altun, H; Sünter, S; Aydogmus, Ö","Modeling and analysis of a single-phase core-type transformer under inrush current and nonlinear load conditions","ELECTRICAL ENGINEERING","","0948-7921","10.1007/s00202-021-01283-9","","In this paper, a transformer model based on the equivalent electrical circuit considering the nonlinearity of the iron core has been developed. The nonlinear behavior of the iron core was taken into account by using the inverted Jiles-Atherton hysteresis model. The single-phase core-type transformer was analyzed under different energization, remnant flux for inrush current and nonlinear load conditions. Illustrative and remarkable simulation and experimental results related to inrush current along with the primary and secondary currents under nonlinear load conditions were demonstrated. In addition, magnetic flux in the iron core and the hysteresis curve as a consequence of the relation of the magnetic flux and magnetizing inrush current were demonstrated. Operation of the transformer under various nonlinear load conditions have been demonstrated with simulation and experimental results. Variation of peak value of the inrush current for different levels of remnant flux in the iron core and different switching-on angles of the voltage applied to the primary was further indicated.","2021-12","2025-02-26 20:39:18","2025-02-26 20:39:18","","2961-2972","","6","103","","","","","","","","","","English","","","","WOS:000640477400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","Atherton hysteresis model; Inrush current; Jiles–; Transformer modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PSJAFHFV","journalArticle","2023","Xu, C; Zhang, FH","Reduced-Order Ladder Network Modeling for Common-Mode Characterization of Transformers","IEEE JOURNAL OF EMERGING AND SELECTED TOPICS IN POWER ELECTRONICS","","2168-6777","10.1109/JESTPE.2023.3280034","","The ladder network with detailed parameters and explicit physical meanings is beneficial for the wideband modeling of transformers. However, due to an excessive number of sections, the high complexity of the model limits its application in the common-mode (CM) analysis of transformers working in power converters. In order to improve the applicability, in this article, the correlation between the resonant frequency of each section pair and the validity of the model is analyzed first. A valid frequency range prediction is derived then to evaluate whether the order of the model is reasonable, which forms the foundation of the proposed reduced-order modeling method. This method enables accurate transformer modeling using a ladder network with much fewer parameters. Furthermore, the reduced-order transformer model is also applied to meet the demand in the balance winding techniques and the wideband CM noise analysis. Finally, the effectiveness of the proposed method and its applications are verified by the insertion voltage gain of transformers and the CM current of the converter.","2023-08","2025-02-26 20:39:18","2025-02-26 20:39:18","","3995-4009","","4","11","","","","","","","","","","English","","","","WOS:001042129300033","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Common mode (CM); electromagnetic interfer-ence (EMI); FILTERS; FLYBACK CONVERTER; modeling; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FPZCT23L","journalArticle","2023","Ouyang, WP; Hu, YS; Ou, YJ; Chen, ZZ","Multiple visual relationship forecasting and arrangement in videos","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2023.126274","","Visual relationships in videos are often causally connected and time-dependent. The complicated tempo-ral dependency between visual relationships is overlooked in visual relationship modeling. To explore the realistic interactions and model the causality between visual relationships in videos, we propose a new task named Multiple Visual Relation Forecasting and Arrangement (MVRFA). Given a series of frames focusing on a pair, MVRFA aims to forecast the future visual relationships and their arrangement which reflects their temporal interrelationship. To evaluate the MVRFA task, we build a video dataset consisting of 1195 videos with 2666 visual relationships and corresponding arrangements annotated by 5 temporal relational classes. In addition, we present a Multi-task Relationship-centric Transformer model as a baseline, which applies graph convolution to aggregate subject-relationship -object information and uses the relationship multi-query transformer to predict the visual relationships with their arrangement. Experiments on the proposed dataset demonstrate that the proposed baseline achieves superior performance and can better handle the MVRFA task than related models.(c) 2023 Elsevier B.V. All rights reserved.","2023-07-07","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","541","","","","","","","","","","English","","","","WOS:000989976100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","Transformer; Video reasoning; Visual relationship forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7KRYVW6I","journalArticle","2025","Qi, YF; Xiao, XM; Yao, MB; Xiong, YG; Zhang, L; Cui, HT","AirFormer: Learning-Based Object Detection for Mars Helicopter","IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING","","1939-1404","10.1109/JSTARS.2024.3492346","","In future multiagent Mars detection schemes, the Mars helicopter can assist the scientific missions of Mars rovers by providing navigation information and scientific objects. However, Mars surface exhibits a complex topography with diverse objects and similar textures to the background, posing a great challenge for existing CNN-based object detection networks. In this article, we propose a novel deep learning-based object detection framework, AirFormer, for Mars helicopter. AirFormer embeds a new feature-fusion attention module, MAT, which injects various receptive field sizes into labels. This fusion module is capable of capturing the interrelations between objects with each other while simultaneously reducing computational complexity. In addition, we published a synthetic dataset from the viewpoint of the Mars helicopter: SynMars-Air, which refers to the data collected by the ZhuRong rover. Extensive experiments are conducted to validate the performance of AirFormer compared to SOTA methods. The results show that our method achieved the highest accuracy both on synthetic and real Mars landscapes.","2025","2025-02-26 20:39:18","2025-02-26 20:39:18","","100-111","","","18","","","","","","","","","","English","","","","WOS:001409622100004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Atmospheric modeling; Feature extraction; Fuses; Helicopters; Mars; Mars dataset; Mars exploration; NETWORK; object detection; Object detection; Remote sensing; Rocks; Semantic segmentation; SEMANTIC SEGMENTATION; Space vehicles; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H7JKV34V","journalArticle","2025","Ren, DF; Hu, Q; Zhang, TD","EKLT: Kolmogorov-Arnold attention-driven LSTM with Transformer model for river water level prediction","JOURNAL OF HYDROLOGY","","0022-1694","10.1016/j.jhydrol.2024.132430","","Water level prediction is crucial for water resource management and flood warnings. Hybrid LSTM-based methods are widely used but face the following challenges: (1) The attention mechanism based on the universal approximation theorem (UAT) is the mainstream method for improving performance, but its essence is infinite approximation of functions, and the accuracy is difficult to improve; (2) LSTM struggles with modeling complex, long-term dependencies. To address these problems, we apply empirical mode decomposition (EMD) and propose input-spatial attention based on the Kolmogorov-Arnold theorem (KAT) for precise water level feature representation. Cascaded LSTM and Transformer structures capture long-term dependencies. Finally, temporal attention is embedded to achieve accurate water level prediction. Experiments show the proposed method achieves RMSE, MAE, MAPE and R2 values of 0.1870, 0.1328, 1.1228 and 0.9540 in the Liaohe River of Liaoning Province, China, and 0.3027, 0.1844, 4.6034 and 0.8659 in the Hunhe River, respectively, indicating its strong predictive performance.","2025-03","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","649","","","","","","","","","","English","","","","WOS:001373357100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Attention mechanism; EMD; Kolmogorov-Arnold theorem; LSTM; TIME-SERIES; Transformer; Water level prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WIN2MTEC","journalArticle","2024","Hirota, Y; Garcia, N; Otani, M; Chu, CH; Nakashima, Y","A Picture May Be Worth a Hundred Words for Visual Question Answering","ELECTRONICS","","2079-9292","10.3390/electronics13214290","","How far can textual representations go in understanding images? In image understanding, effective representations are essential. Deep visual features from object recognition models currently dominate various tasks, especially Visual Question Answering (VQA). However, these conventional features often struggle to capture image details in ways that match human understanding, and their decision processes lack interpretability. Meanwhile, the recent progress in language models suggests that descriptive text could offer a viable alternative. This paper investigated the use of descriptive text as an alternative to deep visual features in VQA. We propose to process description-question pairs rather than visual features, utilizing a language-only Transformer model. We also explored data augmentation strategies to enhance training set diversity and mitigate statistical bias. Extensive evaluation shows that textual representations using approximately a hundred words can effectively compete with deep visual features on both the VQA 2.0 and VQA-CP v2 datasets. Our qualitative experiments further reveal that these textual representations enable clearer investigation of VQA model decision processes, thereby improving interpretability.","2024-11","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","21","13","","","","","","","","","","English","","","","WOS:001351214200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;67</p>","","","data augmentation; interpretability; textual representations; vision-and-language; visual question answering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LJ9DBQN7","journalArticle","2024","Martínez, MEP; Ruiz, MC; Solís, MDS","Harmony search for hyperparameters optimization of a low resource language transformer model trained with a novel parallel corpus Ocelotl Nahuatl - Spanish","SYSTEMS AND SOFT COMPUTING","","2772-9419","10.1016/j.sasc.2024.200152","","Nahuatl, a low-resource language, does not have an online translator application. Instead, resources are limited to dictionaries, web pages, or digital books. Given this condition, it is vital to provide as much support to the language as possible. This research aims to enhance the BLEU score in machine translation by applying the harmony search heuristic method to state-of-the-art transformers models. This is conducted by finding the optimal hyperparameter settings for the models. Models are trained and tested using a fresh moderate-size parallel corpus of 1.5k phrases. By utilizing harmony search, the study shows an improvement in the BLEU score, enhancing it by 2.569%. In order to accomplish this, various factors related to the hyperparameters need to be considered. The application of harmony search with transformers can be extended to various parallel corpora or models, taking these considerations into account.","2024-12","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","6","","","","","","","","","","English","","","","WOS:001331158000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;13</p>","","","Harmony search; Low-resource language; Metaheuristics; Nahuatl; Neural machine translation; Parallel corpus; Soft computing; Spanish; Transformer models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IWPGL7GM","journalArticle","2024","Ji, P; Zhang, C; Zhang, ZC","A method based on Vision Transformer and multiple image information for vehicle lane-changing recognition in mixed traffic and connected environment","TRANSPORTATION LETTERS-THE INTERNATIONAL JOURNAL OF TRANSPORTATION RESEARCH","","1942-7867","10.1080/19427867.2024.2377900","","To enhance the safety of autonomous vehicles in mixed traffic and connected environment, it is crucial to recognize the lane-changing intentions (LCIs) of human-driven vehicles for autonomous vehicles. This paper presents a novel method for LCI recognition, which extracts features from the driving state and relative motion of the target vehicle and its neighbors. The method applies short-time Fourier transform, Gramian angular summation field, and Gramian angular difference field to the time-series data, and generates three grayscale images, which are merged into one information fusion image (IFI) by image processing techniques. The IFIs are then classified into three categories: lane keeping, lane-changing left, and lane-changing right, using the Vision Transformer model with transfer learning to speed up convergence and reduce training cost. The experimental results demonstrate that the proposed method outperforms the traditional methods, achieving an accuracy of 95.65% for recognizing LCI 3s before the lane change point.","2024-07-17","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","","","","","","","","","","","English","","","","WOS:001268460100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Gramian angular field; information fusion image; INTERNET; Lane-changing intention; PREDICTION; short-time Fourier transform; transfer learning; Vision Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7CITK2LH","journalArticle","2024","Zhou, Y; Ali, R; Mokhtar, N; Harun, SW; Iwahashi, M","MixSegNet: A Novel Crack Segmentation Network Combining CNN and Transformer","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3438112","","In the domain of road inspection and structural health monitoring, precise crack identification and segmentation are essential for structural safety and disaster prediction. Traditional image processing technologies encounter difficulties in detecting cracks due to their morphological diversity and complex background noise. This results in low detection accuracy and poor generalization. To overcome these challenges, this paper introduces MixSegNet, a novel deep learning model that enhances crack recognition and segmentation by integrating multi-scale features and deep feature learning. MixSegNet integrates convolutional neural networks (CNNs) and transformer architectures to enhance the detection of small cracks through the extraction and fusion of fine-grained features. Comparative evaluations against mainstream models, including LRASPP, U-Net, Deeplabv3, Swin-UNet, AttuNet, and FCN, demonstrate that MixSegNet achieves superior performance on open-source datasets. Specifically, the model achieved a precision of 95.2%, a recall of 88.2%, an F1 score of 91.5%, and a mean intersection over union (mIoU) of 84.8%, thereby demonstrating its effectiveness and reliability for crack segmentation tasks.","2024","2025-02-26 20:39:18","2025-02-26 20:39:18","","111535-111545","","","12","","","","","","","","","","English","","","","WOS:001297204600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","convolutional neural network; crack images; Crack segmentation network; deep learning; image processing; self-attention mechanism; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LUKITCIV","journalArticle","2023","Oliveira, HS; Oliveira, HP","Transformers for Energy Forecast","SENSORS","","1424-8220","10.3390/s23156840","","Forecasting energy consumption models allow for improvements in building performance and reduce energy consumption. Energy efficiency has become a pressing concern in recent years due to the increasing energy demand and concerns over climate change. This paper addresses the energy consumption forecast as a crucial ingredient in the technology to optimize building system operations and identifies energy efficiency upgrades. The work proposes a modified multi-head transformer model focused on multi-variable time series through a learnable weighting feature attention matrix to combine all input variables and forecast building energy consumption properly. The proposed multivariate transformer-based model is compared with two other recurrent neural network models, showing a robust performance while exhibiting a lower mean absolute percentage error. Overall, this paper highlights the superior performance of the modified transformer-based model for the energy consumption forecast in a multivariate step, allowing it to be incorporated in future forecasting tasks, allowing for the tracing of future energy consumption scenarios according to the current building usage, playing a significant role in creating a more sustainable and energy-efficient building usage.","2023-08","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","15","23","","","","","","","","","","English","","","","WOS:001046378700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","time-series forecast; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EL6IS7Q5","journalArticle","2025","Lu, CH; Shen, YC; Guan, ZY","A modified transformer model for the extended-range forecast of intraseasonal oscillation","NPJ CLIMATE AND ATMOSPHERIC SCIENCE","","2397-3722","10.1038/s41612-025-00902-7","","Extended-range forecast has long maintained a difficult point for the seamless forecast system due to the lack of predictability, with intraseasonal oscillation (ISO), an important signal in many high-impact weather events, being an important source of that. To improve the accuracy of ISO extended-range forecast and make up the gaps in previous researches in this regard, a data-driven model ISOX is proposed for the intraseasonal components of atmospheric fields. Compared with the subseasonal forecast results from climate forecast system (CFS), and the climatological forecast, ISOX achieves higher accuracy for lead times longer than 13 days, with few spatial or temporal weak points. It also performed better in predicting the positive 2 m temperature ISO and lower tropospheric conditions in a heatwave event, surpassing CFS for lead times longer than 13 days. Finally, through gradient evaluation, the model is proved to be able to study the ISO signal movements of atmospheric systems. Thus, the success of this model may shed light on improving extended-range forecast skills and assist the timely detection and prevention of possible meteorological disasters.","2025-01-08","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","1","8","","","","","","","","","","English","","","","WOS:001392379700003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","CHINA; PREDICTION; RAINFALL; SKILL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W289KDNP","journalArticle","2024","Sakong, W; Kwon, J; Min, K; Wang, S; Kim, W","Anomaly Transformer Ensemble Model for Cloud Data Anomaly Detection","IEEE TRANSACTIONS ON CLOUD COMPUTING","","2168-7161","10.1109/TCC.2024.3466174","","The stability and user trust in cloud services depends on prompt detection and response to diverse anomalies. This study focuses on an Ensemble-based anomaly detection methodology that integrates log data with computing resource metrics, aiming to overcome the limitations of traditional single-data models. To process the unstructured nature of log data, we use the Drain Parser to transform it into a structured format, and Doc2Vec embeds it. The study adheres to a reconstruction-based approach for anomaly detection, specifically building upon the Anomaly Transformer model. The proposed model leverages the concept of an Anomaly Transformer based on the Attention mechanism. It integrates preprocessed metric data with log data for effective anomaly detection. Experiments were conducted using metric and log data collected from real-world cloud environments. The model's performance was evaluated based on accuracy, recall, precision, f1 score, and AUROC. The results demonstrate that our proposed Ensemble-based model outperforms traditional models such as LSTM, VAR, and deeplog.","2024-10","2025-02-26 20:39:18","2025-02-26 20:39:18","","1305-1313","","4","12","","","","","","","","","","English","","","","WOS:001373730300008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Anomaly detection; anomaly transformer; Classification algorithms; Cloud computing; Computational modeling; Data models; Doc2Vec; ensemble learning; log parsing; Transformers; unsupervised learning; Vectors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QKR73PV7","journalArticle","2024","Shi, HC; Sun, X; Tang, WJ; Wang, J; Su, J; Liang, P; Zhao, KN; Liu, Q; Wu, DH; Xia, W","Beam spot quality detection of 650 nm laser diode using lightweight transformer model","MEASUREMENT","","0263-2241","10.1016/j.measurement.2023.114083","","The 650 nm laser diode (LD) with high beam quality has superhigh application demand in fields such as in-formation storage, medicine and display. The accurate detection of 650 nm LD beam spots is crucial for its production and application. In this paper, to detect and classify different 650 nm LD beam spots quickly and accurately, a beam spot detection network based on the vision transformer architecture is proposed for the first time. The presented model allows better extraction of beam spot features and is extremely hardware-friendly. Meanwhile, we designed a new Transformer Block, which can optimize local information acquisition, and enhance memory access efficiency. Moreover, the first 650 nm LD beam spot image dataset, RED-LaserSpot-4K, was created. The experimental results show that the model is both lightweight and powerful, with TOP-1 Ac-curacy of 93.2 %, only 1.0G FLOPs and 12.3 M parameters. It also can provide a practice foundation for enhancing the performance of 650 nm LD.","2024-02-15","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","225","","","","","","","","","","English","","","","WOS:001165908600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","650 nm LD; Beam spot detection; Deep learning; RED-LaserSpot-4K; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XFSJS6Q6","journalArticle","2022","Li, C; Huang, XY; Song, RC; Qian, RB; Liu, X; Chen, X","EEG-based seizure prediction via Transformer guided CNN","MEASUREMENT","","0263-2241","10.1016/j.measurement.2022.111948","","Recently, most seizure prediction methods mainly utilize pure CNN or Transformer model, which cannot extract local and global features simultaneously. To this end, we propose an Electroencephalogram (EEG) seizure prediction method based on Transformer guided CNN (TGCNN), which combines the complementary advantages of CNN and Transformer. The proposed method first use short-time Fourier transform (STFT) to extract time-frequency features from EEG signals. Then, these features are fed into the alternating structure to model both local feature and long-distance dependencies, which can overcome both the deficiency of long distance dependence in CNN and the lack of local features in Transformer. Finally, the prediction result is obtained through a global average pooling layer and fully connected layer. The proposed method achieves sensitivity of 91.5%, false prediction rate (FPR) of 0.145/h, and area under curve (AUC) of 93.5% on CHB-MIT database and 82.2% sensitivity, 0.06/h FPR, and 83.5% AUC on Kaggle dataset.","2022-11-15","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","203","","","","","","","","","","English","","","","WOS:000865449100003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;48<br/>Total Times Cited:&nbsp;&nbsp;49<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","BRAIN; CLASSIFICATION; Electroencephalogram (EEG); EPILEPSY; NETWORK; Seizure prediction; SIGNALS; STFT; Transformer guided CNN (TGCNN)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9K3NX2LX","journalArticle","2024","Xu, W; Dai, WJ; Li, DY; Wu, QC","Short-Term Wind Power Prediction Based on a Variational Mode Decomposition-BiTCN-Psformer Hybrid Model","ENERGIES","","1996-1073","10.3390/en17164089","","Precise wind power forecasting is essential for the successful integration of wind power into the power grid and for mitigating the potential effects of wind power on the power system. To enhance the precision of predictions, a hybrid VMD-BiTCN-Psformer model was devised. Firstly, VMD divided the original sequence into several data components with varying time scales. Furthermore, the BiTCN network was utilized to extract the sequence features. These features, along with the climate features, were then input into the positional encoding and ProbSparse self-attention improved Transformer model. The outputs of these models were combined to obtain the ultimate wind power prediction results. For the prediction of the wind power in Fujian Province on April 26, four additional models were developed for comparison with the VMD-BiTCN-Psformer model. The VMD-BiTCN-Psformer model demonstrated the greatest level of forecast accuracy among all the models. The R2 increased by 22.27%, 12.38%, 8.93%, and 2.59%, respectively.","2024-08","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","16","17","","","","","","","","","","English","","","","WOS:001305488600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","BiTCN; NETWORK; ProbSparse self-attention; transformer; VMD; wind power forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FRFNE9SA","journalArticle","2021","Zhao, ZZ; Xia, CQ; Chi, L; Chang, XM; Li, W; Yang, T; Zomaya, AY","Short-Term Load Forecasting Based on the Transformer Model","INFORMATION","","2078-2489","10.3390/info12120516","","From the perspective of energy providers, accurate short-term load forecasting plays a significant role in the energy generation plan, efficient energy distribution process and electricity price strategy optimisation. However, it is hard to achieve a satisfactory result because the historical data is irregular, non-smooth, non-linear and noisy. To handle these challenges, in this work, we introduce a novel model based on the Transformer network to provide an accurate day-ahead load forecasting service. Our model contains a similar day selection approach involving the LightGBM and k-means algorithms. Compared to the traditional RNN-based model, our proposed model can avoid falling into the local minimum and outperforming the global search. To evaluate the performance of our proposed model, we set up a series of simulation experiments based on the energy consumption data in Australia. The performance of our model has an average MAPE (mean absolute percentage error) of 1.13, where RNN is 4.18, and LSTM is 1.93.","2021-12","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","12","12","","","","","","","","","","English","","","","WOS:000737768600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;25<br/>Total Times Cited:&nbsp;&nbsp;25<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","ARTIFICIAL NEURAL-NETWORKS; attention mechanism; deep learning; FUZZY-LOGIC; LightGBM; recurrent neural network; short-term load forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M45NF4SX","journalArticle","2024","Li, BC; Hu, YW; Guerrero, P; Hasan, M; Shi, L; Deschaintre, V; Matusik, W","Procedural Material Generation with Reinforcement Learning","ACM TRANSACTIONS ON GRAPHICS","","0730-0301","10.1145/3687979","","Modern 3D content creation heavily relies on procedural assets. In particular, procedural materials are ubiquitous in the industry, but their manipulation remains challenging. Previous work [Hu et al. 2023] conditionally generates procedural graphs that match a given input image. However, the parameter generation step limits how accurately the generated graph matches the input image, due to a reliance on supervision with scarcely available procedural data. We propose to improve parameter prediction accuracy for image-conditioned procedural material generation by leveraging reinforcement learning (RL) and present the first RL approach for procedural materials. RL circumvents the limited availability of procedural data, the domain gap between real and synthetic materials, and the need for end-to-end differentiable loss functions. Given a target image, we retrieve a procedural material and use an RL-trained transformer model to predict a set of parameters that reconstruct the target image as closely as possible. We show that using RL significantly improves parameter prediction to match a given target image compared to supervised methods on both synthetic and real target images.","2024-12","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","6","43","","","","","","","","","","English","","","","WOS:001368372600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","generative models; Procedural materials; reinforcement learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RDIGDHBK","journalArticle","2025","Rodríguez-Sánchez, F; Carrillo-de-Albornoz, J; Plaza, L","Leveraging Unsupervised Task Adaptation and Semi-Supervised Learning With Semantic-Enriched Representations for Online Sexism Detection","EXPERT SYSTEMS","","0266-4720","10.1111/exsy.13763","","Over the past decade, the proliferation of hateful and sexist content targeting women on social media has become a concerning issue, adversely affecting women's lives and freedom of expression. Previous efforts to detect online sexism have utilized monolingual ensemble transformers combined with data augmentation techniques that incorporate related-domain data, such as hate speech. However, these approaches often struggle to capture the full diversity and complexity of sexism due to limitations in the size and quality of training data. In this study, we introduce a novel sexism detection system that employs in-domain unlabeled data through unsupervised task-adaptation techniques and semi-supervised learning, using an efficient single multilingual transformer model. Additionally, we incorporate a Sentence-BERT layer to enhance our system with semantically meaningful sentence embeddings. Our proposed system outperforms existing state-of-the-art methods across all tasks and datasets, demonstrating its effectiveness in detecting and addressing sexism in social media text. These results underscore the potential of our approach, providing a foundation for further research and practical applications.","2025-02","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","2","42","","","","","","","","","","English","","","","WOS:001341027300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","IDENTIFICATION; online sexism; sexism categorization; sexism dataset; sexism detection; social media","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"URM6B7BI","journalArticle","2024","Li, Y; Meng, X; Zhang, XC","Abnormal behavior monitoring enhanced smart university stadium under the background of ""Internet plus""","INTERNET TECHNOLOGY LETTERS","","2476-1508","10.1002/itl2.560","","With the rapid development of the Internet of Things and 5G technology, smart university gymnasiums have become more and more important. However, it has become increasingly difficult for university gymnasium management, especially to detect abnormal behavior with dense crowds under limited venue space. To handle this issue, this paper designs an Artificial Intelligence Internet of Things (AIoT) abnormal behavior detection system which consists of the 5G camera, 5G transmission network and cloud platform. The 5G camera captures and transmits the video to the cloud platform by exploiting the 5G wireless sensor network. In the cloud platform, a hybrid variational autoencoder backbone which exploits the pre-trained VGG16 and Transformer model is deployed to detect abnormal behaviors. Moreover, by introducing adversarial training mechanisms, the robustness of the proposed model is effectively improved. The experimental results on our self-built gymnasium abnormal behavior dataset show that the proposed model can correctly identify most of the abnormal behaviors in the gymnasium compared to other models.","2024-07-08","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","","","","","","","","","","","English","","","","WOS:001263692900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","5G technology; abnormal behavior; adversarial training; internet plus technology; smart university gymnasium; variational autoencoder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CVD6SCIK","journalArticle","2024","Yin, XX; Yin, DS","Transformer-Based Parameter Estimation in Statistics","MATHEMATICS","","2227-7390","10.3390/math12071040","","Parameter estimation is one of the most important tasks in statistics, and is key to helping people understand the distribution behind a sample of observations. Traditionally, parameter estimation is done either by closed-form solutions (e.g., maximum likelihood estimation for Gaussian distribution) or by iterative numerical methods such as the Newton-Raphson method when a closed-form solution does not exist (e.g., for Beta distribution). In this paper, we propose a transformer-based approach to parameter estimation. Compared with existing solutions, our approach does not require a closed-form solution or any mathematical derivations. It does not even require knowing the probability density function, which is needed by numerical methods. After the transformer model is trained, only a single inference is needed to estimate the parameters of the underlying distribution based on a sample of observations. In the empirical study, we compared our approach with maximum likelihood estimation on commonly used distributions such as normal distribution, exponential distribution and beta distribution. It is shown that our approach achieves similar or better accuracy as measured by mean-square-errors.","2024-04","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","7","12","","","","","","","","","","English","","","","WOS:001200964000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;17</p>","","","deep learning; parameter estimation; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S2ZFHGU6","journalArticle","2024","Zhang, HN; Ji, YT; Wu, NR; Lu, M","A Mongolian-Chinese Neural Machine Translation Method Based on Semantic-Context Data Augmentation","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app14083442","","Neural machine translation (NMT) typically relies on a substantial number of bilingual parallel corpora for effective training. Mongolian, as a low-resource language, has relatively few parallel corpora, resulting in poor translation performance. Data augmentation (DA) is a practical and promising method to solve problems related to data sparsity and single semantic structure by expanding the size and structure of available data. In order to address the issues of data sparsity and semantic inconsistency in Mongolian-Chinese NMT processes, this paper proposes a new semantic-context DA method. This method adds an additional semantic encoder based on the original translation model, which utilizes both source and target sentences to generate different semantic vectors to enhance each training instance. The results show that this method significantly improves the quality of Mongolian-Chinese NMT tasks, with an increase of approximately 2.5 BLEU values compared to the basic Transformer model. Compared to the basic model, this method can achieve the same translation results with about half of the data, greatly improving translation efficiency.","2024-04","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","8","14","","","","","","","","","","English","","","","WOS:001210892800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","data sparseness; Mongolian neural machine translation; semantic-context data augmentation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LNQ8WRI2","journalArticle","2023","Ashmawy, M; Fakhr, MW; Maghraby, FA","Lexical Normalization Using Generative Transformer Model (LN-GTM)","INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS","","1875-6891","10.1007/s44196-023-00366-8","","Lexical Normalization (LN) aims to normalize a nonstandard text to a standard text. This problem is of extreme importance in natural language processing (NLP) when applying existing trained models to user-generated text on social media. Users of social media tend to use non-standard language. They heavily use abbreviations, phonetic substitutions, and colloquial language. Nevertheless, most existing NLP-based systems are often designed with the standard language in mind. However, they suffer from significant performance drops due to the many out-of-vocabulary words found in social media text. In this paper, we present a new (LN) technique by utilizing a transformer-based sequence-to-sequence (Seq2Seq) to build a multilingual characters-to-words machine translation model. Unlike the majority of current methods, the proposed model is capable of recognizing and generating previously unseen words. Also, it greatly reduces the difficulties involved in tokenizing and preprocessing the nonstandard text input and the standard text output. The proposed model outperforms the winning entry to the Multilingual Lexical Normalization (MultiLexNorm) shared task at W-NUT 2021 on both intrinsic and extrinsic evaluations.","2023-11-14","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","1","16","","","","","","","","","","English","","","","WOS:001100944100004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Lexical normalization; Machine translation; NLP; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U6WI2SFN","journalArticle","2021","Ferencz, I; Petreus, D","A Power Electronic Traction Transformer Model for a New Medium Voltage DC Electric Railway","ADVANCES IN ELECTRICAL AND COMPUTER ENGINEERING","","1582-7445","","","All state-of-the-art Power Electronic Traction transformers (PETT) were developed for the existent Medium Voltage (MV) AC Electric Railway Systems (ERS). This work, however, presents a PETT for a novel MVDC-ERS. We studied and evaluated various state-of-the-art PETT topologies in two previous articles to determine which is best for this application, and we presented an 8-module Input Series Output Parallel (ISOP) MVDC PETT with a total power exceeding 1.2 MW. The converter topology used in the modules is the Dual Active Bridge (DAB). In this paper, the complete mathematical model of the converter, the deduction of controller parameters and the decoupling method, and the simulation model are presented in detail. Simulations show how the system works and interacts with a traction motor, as well as its response to input voltage variation and load steps. The results and theoretical notions obtained in this project will lay the foundation of a novel smart MVDC-ERS, meanwhile an experimental prototype is under development.","2021-08","2025-02-26 20:39:18","2025-02-26 20:39:18","","99-108","","3","21","","","","","","","","","","English","","","","WOS:000691632000012","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;29</p>","","","CONVERTER; DC-DC power converters; modular construction; railway engineering; Silicon carbide; traction power supplies","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8BMU87TP","journalArticle","2024","Kibet, D; So, MS; Kang, H; Han, Y; Shin, JH","Sudden Fall Detection of Human Body Using Transformer Model","SENSORS","","1424-8220","10.3390/s24248051","","In human activity recognition, accurate and timely fall detection is essential in healthcare, particularly for monitoring the elderly, where quick responses can prevent severe consequences. This study presents a new fall detection model built on a transformer architecture, which focuses on the movement speeds of key body points tracked using the MediaPipe library. By continuously monitoring these key points in video data, the model calculates real-time speed changes that signal potential falls. The transformer's attention mechanism enables it to catch even slight shifts in movement, achieving an accuracy of 97.6% while significantly reducing false alarms compared to traditional methods. This approach has practical applications in settings like elderly care facilities and home monitoring systems, where reliable fall detection can support faster intervention. By homing in on the dynamics of movement, this model improves both accuracy and reliability, making it suitable for various real-world situations. Overall, it offers a promising solution for enhancing safety and care for vulnerable populations in diverse environments.","2024-12","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","24","24","","","","","","","","","","English","","","","WOS:001387673000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","CLASSIFICATION; fall detection; pose estimation; speed-based anomaly detection; time-series analysis; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8FYT27MC","journalArticle","2024","Lu, SQ; Gao, ZF; He, D; Zhang, LF; Ke, GL","Data-driven quantum chemical property prediction leveraging 3D conformations with Uni-Mol","NATURE COMMUNICATIONS","","2041-1723","10.1038/s41467-024-51321-w","","Quantum chemical (QC) property prediction is crucial for computational materials and drug design, but relies on expensive electronic structure calculations like density functional theory (DFT). Recent deep learning methods accelerate this process using 1D SMILES or 2D graphs as inputs but struggle to achieve high accuracy as most QC properties depend on refined 3D molecular equilibrium conformations. We introduce Uni-Mol+, a deep learning approach that leverages 3D conformations for accurate QC property prediction. Uni-Mol+ first generates a raw 3D conformation using RDKit then iteratively refines it towards DFT equilibrium conformation using neural networks, which is finally used to predict the QC properties. To effectively learn this conformation update process, we introduce a two-track Transformer model backbone and a novel training approach. Our benchmarking results demonstrate that the proposed Uni-Mol+ significantly improves the accuracy of QC property prediction in various datasets. Quantum chemical (QC) property prediction is crucial in computational chemistry. Here, the authors introduce Uni-Mol+, a deep model that uses iterative updates of 3D molecular conformations to improves the accuracy of QC property prediction.","2024-08-19","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","1","15","","","","","","","","","","English","","","","WOS:001294188500004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UU6WMVXN","journalArticle","2024","Feng, RY; Li, ZB; Liu, BW; Ding, Y","A Joint Spatiotemporal Prediction and Image Confirmation Model for Vehicle Trajectory Concatenation With Low Detection Rates","IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS","","1524-9050","10.1109/TITS.2024.3373774","","Ensuring the quality of trajectories is of utmost importance in traffic flow analysis. Traditional approaches rely on reconstructing nearly complete trajectories and subsequently denoising them. However, low detection rates often pose challenges and result in failed trajectory construction. To overcome this issue, this paper presents a trajectory concatenation method that combines NS Transformer prediction and Siamese-VGG16 similarity confirmation, specifically designed to address low detection rates. The employed transformer model can withstand missing values, efficiently extracting internal associations among multiple traffic parameters in conditions of sparse data. Furthermore, a lightweight image feature similarity verification step is integrated after trajectory prediction to find the most similar target to the image in the predicted spatiotemporal domain. Additionally, a lightweight image feature similarity verification step is integrated after trajectory prediction to identify the most similar targets within the predicted spatiotemporal domain. Experimental results demonstrate the efficacy of the proposed method, successfully connecting over 80% of fragmented tracks and yielding significant maintenance of MOTA above 0.74 under low detection accuracy.","2024-09","2025-02-26 20:39:18","2025-02-26 20:39:18","","11701-11715","","9","25","","","","","","","","","","English","","","","WOS:001189560700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","BEHAVIOR; Low detection rate; neural networks; TRACKING; TRAFFIC FLOW; trajectory concatenation; transformer prediction; VALIDATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZMG849Z7","journalArticle","2024","Oka, R; Kusumi, T; Utsumi, A","Performance evaluation of automated scoring for the descriptive similarity response task","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-56743-6","","We examined whether a machine-learning-based automated scoring system can mimic the human similarity task performance. We trained a bidirectional encoder representations from transformer-model based on the semantic similarity test (SST), which presented participants with a word pair and asked them to write about how the two concepts were similar. In Experiment 1, based on the fivefold cross validation, we showed the model trained on the combination of the responses (N = 1600) and classification criteria (which is the rubric of the SST; N = 616) scored the correct labels with 83% accuracy. In Experiment 2, using the test data obtained from different participants in different timing from Experiment 1, we showed the models trained on the responses alone and the combination of responses and classification criteria scored the correct labels in 80% accuracy. In addition, human-model scoring showed inter-rater reliability of 0.63, which was almost the same as that of human-human scoring (0.67 to 0.72). These results suggest that the machine learning model can reach human-level performance in scoring the Japanese version of the SST.","2024-03-14","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","1","14","","","","","","","","","","English","","","","WOS:001185787000011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","FLUID; INDIVIDUAL-DIFFERENCES; NORMS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XMDZQRF4","journalArticle","2024","Anjali, T; Masilamani","Explainable masked face recognition","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-023-16571-8","","The COVID-19 epidemic has made us all to understand that using face masks is one of the best ways to save ourselves from infections. Face recognition techniques often focus on the essential facial landmarks such as nose, mouth and eyes. Removing masks in airports or other public places for authentication will raise the danger of virus infection, and this will pose a challenge to the existing face recognition systems. This paper presents a novel approach to recognize masked faces that combines cropping the unmasked half of the face (the upper part of a face) image using a vision transformer model. Various scenarios are investigated in this paper. The model is trained using the images of the upper half of the face and tested on the same, full-face images with a mask and full face images without a mask. The experiments on the standard datasets, namely RMFRD, MLFW and masked CASIA-WebFace show that the proposed approach improves masked face recognition significantly compared to the existing methods. The explainability of the proposed model is demonstrated using a class activation map.","2024-03","2025-02-26 20:39:18","2025-02-26 20:39:18","","31123-31138","","10","83","","","","","","","","","","English","","","","WOS:001063374600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Cropping-based approach; Mask occlusion; Masked face recognition; Vision transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7YSW9AIQ","journalArticle","2023","Huang, YY; Xiong, WB; Zhang, HW; Zhang, WW","Yarn-Dyed Fabric Defect Detection Based on U-Shaped Swin Transformer Auto-Encoder","LASER & OPTOELECTRONICS PROGRESS","","1006-4125","10.3788/LOP220691","","Considering the non -effectiveness of traditional convolution neural networks in detecting pattern defects in yarn- dyed fabrics, a defect detection method based on a U-shaped Swin Transformer reconstruction model and residual analysis is proposed. This method uses the Transformer model to improve the extraction of global image features and enhance reconstruction while solving for the small number and unbalanced types of defective samples during the actual production process. First, the training process of the reconstructed model is completed for a certain pattern using the non -defective samples after adding noise. Subsequently, the test image is inputted into the model to obtain the reconstructed image, and its residual image and reconstructed image are calculated. Finally, the defect areas are detected and located via threshold segmentation and mathematical morphology processing. The results indicate that this method can be effectively used for the detection and location of defect areas on multiple yarn-dyed fabric patterns without requiring the marking of the defective samples.","2023-06","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","12","60","","","","","","","","","","English","","","","WOS:001020949300008","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","defect detection; image processing; machine vision; Swin Transformer; unsupervised learning; yarn-dyed fabric","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RHWA77YQ","journalArticle","2023","Swarup, S; Kushwaha, GS","Nickel and Cobalt Price Volatility Forecasting Using a Self-Attention-Based Transformer Model","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app13085072","","Both Nickel and Cobalt have been extensively used in cutting-edge technologies, such as electric vehicle battery manufacturing, stainless steel, and special alloys production. As governments focus on greener solutions for areas such as transportation and energy generation, both metals are increasingly used for energy storage purposes. However, their price uncertainty makes for an interesting case in the modern economy. This study focuses on the price volatility forecasting of Nickel and Cobalt using ANN (Artificial Neural Network) built on a special class of Transformer models used for multi-step ahead forecasts. Our results suggest that the given model is only slightly better in predictive accuracy compared to traditional sequential deep learning models such as BiLSTM (Bidirectional Long Short-Term Memory) and GRUs (gated recurrent units). Moreover, our findings also show that, like conventional approaches, in-sample behavior does not guarantee out-of-sample behavior. The given study could be utilized by industry participants for an inquiry into new and efficient ways to forecast and identify temporal-based structural patterns in commodity-based time series.","2023-04","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","8","13","","","","","","","","","","English","","","","WOS:000977538700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","commodity prices; COPPER; deep learning approaches; self attention; transformer models; volatility forecasting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DCXIICMM","journalArticle","2023","Yang, Y; Wang, X; Liu, ZF; Huang, M; Sun, SP; Zhu, QB","Detection of multi-size peach in orchard using RGB-D camera combined with an improved DEtection Transformer model","INTELLIGENT DATA ANALYSIS","","1088-467X","10.3233/IDA-220449","","The first major contribution of the paper is the proposal of using an improved DEtection Transformer network (named R2N-DETR) and Kinect-V2 camera for detecting multiple-size peaches under orchards with varied illumination and fruit occlusion. R2N-DETR model first employed Res2Net-50 to extract a fused low-high level feature map containing fine spatial features and precise semantic information of multi-size peaches from Red-Green-Blue-Depth (RGB-D) images. Second, the encoder-decoder was performed on the feature map to obtain the global context. Finally, all detected objects were detected according to each object's global context. For the detection of 1101 RGB-D images (imaged from two orchards over three years), the R2N-DETR model achieves an average precision of 0.944 and an average detecting time of 53 ms for each image. The developed system could provide precise visual guidance for robotic picking and contribute to improving yield prediction by providing accurate fruit counting.","2023","2025-02-26 20:39:18","2025-02-26 20:39:18","","1539-1554","","5","27","","","","","","","","","","English","","","","WOS:001079392000016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","APPLE DETECTION; Deep learning; FASTER R-CNN; IMAGES; open orchard; peach detection; R2N-DETR; RGB-D image","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6GXYADYD","journalArticle","2024","Kong, T; Yu, TC; Zhao, JX; Hu, ZH; Xiong, N; Wan, J; Dong, XL; Pan, Y; Zheng, HL; Zhang, L","scGAA: a general gated axial-attention model for accurate cell-type annotation of single-cell RNA-seq data","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-73356-1","","Single-cell RNA sequencing (scRNA-seq) is a key technology for investigating cell development and analysing cell diversity across various diseases. However, the high dimensionality and extreme sparsity of scRNA-seq data pose great challenges for accurate cell type annotation. To address this, we developed a new cell-type annotation model called scGAA (general gated axial-attention model for accurate cell-type annotation of scRNA-seq). Based on the transformer framework, the model decomposes the traditional self-attention mechanism into horizontal and vertical attention, considerably improving computational efficiency. This axial attention mechanism can process high-dimensional data more efficiently while maintaining reasonable model complexity. Additionally, the gated unit was integrated into the model to enhance the capture of relationships between genes, which is crucial for achieving an accurate cell type annotation. The results revealed that our improved transformer model is a promising tool for practical applications. This theoretical innovation increased the model performance and provided new insights into analytical tools for scRNA-seq data.","2024-09-27","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","1","14","","","","","","","","","","English","","","","WOS:001354536300274","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","SEQUENCING DATA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QD85B4GI","journalArticle","2024","Russo, P; Di Ciaccio, F","Deep Classification of Microplastics Through Image Fusion Techniques","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3423661","","Microplastics derived from fiber shredding are recognized by the scientific community as one of the main sources of microplastic water pollution, thus actualizing the need for techniques able to identify them with high accuracy. The recently released Holography Micro-Plastic Dataset offers the opportunity to test deep neural networks in their ability to distinguish between microplastics and other debris on a standard benchmark. The promising results obtained from the initial batch of experiments can be further improved through a combined approach which involves different image mapping techniques and recent state-of-the-art deep models. Within this framework, we analyze various image fusion schemas to merge the paired dataset images (amplitude and phase) into a single three-channel picture. We demonstrate that our proposed approach yields increased accuracy compared to both single-image data processing and other fusion techniques. Finally, the performance of our method is further enhanced by employing the Vision Transformer model as backbone, highlighting the effectiveness of the proposed approach in microplastics classification.","2024","2025-02-26 20:39:18","2025-02-26 20:39:18","","134852-134861","","","12","","","","","","","","","","English","","","","WOS:001327354000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Benchmark testing; Deep learning; digital holography; Digital systems; Holography; Image color analysis; image fusion; microplastics; Microscopy; Nanoscale devices; Plastics; Visualization; Wastewater","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7HD45CEP","journalArticle","2023","Bai, YZ; Hou, FJ; Fan, XY; Lin, WF; Lu, JH; Zhou, JY; Fan, DC; Li, L","A Lightweight Pest Detection Model for Drones Based on Transformer and Super-Resolution Sampling Techniques","AGRICULTURE-BASEL","","2077-0472","10.3390/agriculture13091812","","With the widespread application of drone technology, the demand for pest detection and identification from low-resolution and noisy images captured with drones has been steadily increasing. In this study, a lightweight pest identification model based on Transformer and super-resolution sampling techniques is introduced, aiming to enhance identification accuracy under challenging conditions. The Transformer model was found to effectively capture spatial dependencies in images, while the super-resolution sampling technique was employed to restore image details for subsequent identification processes. The experimental results demonstrated that this approach exhibited significant advantages across various pest image datasets, achieving Precision, Recall, mAP, and FPS scores of 0.97, 0.95, 0.95, and 57, respectively. Especially in the presence of low resolution and noise, this method was capable of performing pest identification with high accuracy. Furthermore, an adaptive optimizer was incorporated to enhance model convergence and performance. Overall, this study offers an efficient and accurate method for pest detection and identification in practical applications, holding significant practical value.","2023-09","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","9","13","","","","","","","","","","English","","","","WOS:001072504600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","pest detection; smart agriculture; super resolution; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SSPNDP52","journalArticle","2023","Chen, J; Yuan, GW; Zhou, H; Tan, CM; Yang, L; Li, SQ","Classification of Solar Radio Spectrum Based on Swin Transformer","UNIVERSE","","2218-1997","10.3390/universe9010009","","Solar radio observation is a method used to study the Sun. It is very important for space weather early warning and solar physics research to automatically classify solar radio spectrums in real time and judge whether there is a solar radio burst. As the number of solar radio burst spectrums is small and uneven, this paper proposes a classification method for solar radio spectrums based on the Swin transformer. First, the method transfers the parameters of the pretrained model to the Swin transformer model. Then, the hidden layer weights of the Swin transformer are frozen, and the fully connected layer of the Swin transformer is trained on the target dataset. Finally, parameter tuning is performed. The experimental results show that the method can achieve a true positive rate of 100%, which is more accurate than previous methods. Moreover, the number of our model parameters is only 20 million, which is 80% lower than that of the traditional VGG16 convolutional neural network with more than 130 million parameters.","2023-01","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","1","9","","","","","","","","","","English","","","","WOS:000916367300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","deep learning; self-attentional mechanism; solar radio spectrum; Swin transformer; transfer learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VTGJR7ZY","journalArticle","2023","Lv, XQ; Liu, ZA; Zhao, Y; Xu, G; You, XD","HBert: A Long Text Processing Method Based on BERT and Hierarchical Attention Mechanisms","INTERNATIONAL JOURNAL ON SEMANTIC WEB AND INFORMATION SYSTEMS","","1552-6283","10.4018/IJSWIS.322769","","With the emergence of a large-scale pre-training model based on the transformer model, the effect of all-natural language processing tasks has been pushed to a new level. However, due to the high complexity of the transformer's self-attention mechanism, these models have poor processing ability for long text. Aiming at solving this problem, a long text processing method named HBert based on Bert and hierarchical attention neural network is proposed. Firstly, the long text is divided into multiple sentences whose vectors are obtained through the word encoder composed of Bert and the word attention layer. And the article vector is obtained through the sentence encoder that is composed of transformer and sentence attention. Then the article vector is used to complete the subsequent tasks. The experimental results show that the proposed HBert method achieves good results in text classification and QA tasks. The F1 value is 95.7% in longer text classification tasks and 75.2% in QA tasks, which are better than the state-of-the-art model longformer.","2023","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","1","19","","","","","","","","","","English","","","","WOS:001001219100009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;16</p>","","","BERT; Hierarchical Attention; Long Text Processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QP8DFM6R","journalArticle","2022","Jie, C; Wang, ZG; Xu, D; Shen, W","Multi-objective cluster based bidding algorithm for E-commerce search engine marketing system","FRONTIERS IN BIG DATA","","2624-909X","10.3389/fdata.2022.966982","","Search engine marketing (SEM) is an important channel for the success of e-commerce. With the increasing scale of catalog items, designing an efficient modern industrial-level bidding system usually requires overcoming the following hurdles: 1. the relevant bidding features are of high sparsity, preventing an accurate prediction of the performances of many ads. 2. the large volume of bidding requests induces a significant computation burden to offline and online serving. In this article, we introduce an end-to-end structure of a multi-objective bidding system for search engine marketing for Walmart e-commerce, which successfully handles tens of millions of bids each day. The system deals with multiple business demands by constructing an optimization model targeting a mixture of metrics. Moreover, the system extracts the vector representations of ads via the Transformer model. It leverages their geometric relation to building collaborative bidding predictions via clustering to address performance features' sparsity issues. We provide theoretical and numerical analyzes to discuss how we find the proposed system as a production-efficient solution.","2022-09-26","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","5","","","","","","","","","","English","","","","WOS:000874161000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","clustering; intention embedding; multi-objective; optimization; SEM bidding","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HME4WP5H","journalArticle","2022","Yuan, L; Wang, J; Yu, LC; Zhang, XJ","Hierarchical template transformer for fine-grained sentiment controllable generation","INFORMATION PROCESSING & MANAGEMENT","","0306-4573","10.1016/j.ipm.2022.103048","","Existing methods for text generation usually fed the overall sentiment polarity of a product as an input into the seq2seq model to generate a relatively fluent review. However, these methods cannot express more fine-grained sentiment polarity. Although some studies attempt to generate aspect-level sentiment controllable reviews, the personalized attribute of reviews would be ignored. In this paper, a hierarchical template-transformer model is proposed for personalized fine-grained sentiment controllable generation, which aims to generate aspect-level sentiment controllable reviews with personalized information. The hierarchical structure can effectively learn sentiment information and lexical information separately. The template transformer uses a part of speech (POS) template to guide the generation process and generate a smoother review. To verify our model, we used the existing model to obtain a corpus named FSCG-80 from Yelp, which contains 800K samples and conducted a series of experiments on this corpus. Experimental results show that our model can achieve up to 89.93% aspect-sentiment control accuracy and generate more fluent reviews.","2022-09","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","5","59","","","","","","","","","","English","","","","WOS:000968650800009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","Fine-grained text generation; Sentiment controllable generation; Sequence-to-sequence learning; TO-TEXT GENERATION; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DJ7KNCRY","journalArticle","2022","Zhang, QY; Qin, C; Zhang, YF; Bao, FX; Zhang, CM; Liu, PD","Transformer-based attention network for stock movement prediction","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2022.117239","","Stock movement prediction is an important field of study that can help market traders make better trading decisions and earn more profit. The fusion of text from social media platforms such as Twitter and actual stock prices is an effective but difficult approach for stock movement prediction. Although some previous methods have explored this approach, there are still difficulties with the temporal dependence of financial data and insufficient effectiveness of fusing text and stock prices. To solve these problems, we propose the novel Transformer Encoder-based Attention Network (TEANet) framework, which is based on precise description through small-sample feature engineering and uses a small sample of 5 calendar days to capture the temporal dependence of financial data. In addition, this deep learning framework uses the Transformer model and multiple attention mechanisms to achieve feature extraction and effective analysis of financial data to achieve accurate prediction. Extensive experiments on four datasets demonstrate the effectiveness of our framework. Further simulations show that an actual trading strategy based on our proposed model can significantly increase profit and has practical application value.","2022-09-15","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","202","","","","","","","","","","English","","","","WOS:000830170300005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;69<br/>Total Times Cited:&nbsp;&nbsp;71<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","Attention; Deep learning; Stock movement prediction; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S3J2HJXP","journalArticle","2024","Zheng, Y; Wang, CM; Huang, CY; Li, KP; Yang, JF; Xie, N; Liu, BL; Zhang, Y","Hierarchical spatial-temporal autocorrelation graph neural network for online wind turbine fault detection","NEUROCOMPUTING","","0925-2312","10.1016/j.neucom.2024.127574","","The advancement of low-cost, non-manually labeled big data technologies for fault detection in wind turbines is crucial to guarantee their safe and efficient operation. In this context, Normal Behavior Modelling (NBM) is a prevalent approach. However, existing NBM methods for wind turbine fault detection inadequately utilize complex spatial-temporal correlations within the Supervisory Control and Data Acquisition (SCADA) during the normal behavior prediction stage. To cope with this limitation, this paper propose a hierarchical spatial-temporal autocorrelation graph neural network method for online wind turbine pitch system fault detection. This approach integrates a dynamic graph network with an adaptive structure for spatial correlation learning and a transformer model with autocorrelation attention to identify periodic time-distance correlations. Furthermore, a hierarchical neural network, specifically designed for wind turbine physical structure, enhances local information extraction through seven latent graph neural networks and a probsparse attention mechanism. The proposed method demonstrates significant effectiveness in real-world applications, as evidenced by data from a Shanghai wind farm.","2024-06-14","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","586","","","","","","","","","","English","","","","WOS:001299013300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Autocorrelation; Latent graph neural network; MODEL; Online fault detection; Pitch system; Spatial-temporal; Wind turbine","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AH8HH7FY","journalArticle","2023","Chen, RQ; Li, WX; Yang, HB","A Deep Reinforcement Learning Framework Based on an Attention Mechanism and Disjunctive Graph Embedding for the Job-Shop Scheduling Problem","IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS","","1551-3203","10.1109/TII.2022.3167380","","The job-shop scheduling problem (JSSP) is a classical NP-hard combinatorial optimization problem, and the operating efficiency of manufacturing system is affected directly by the quality of its scheduling scheme. In this article, a novel deep reinforcement learning framework is proposed for solving the classical JSSP, where each machine has to process each job exactly once. This method based on an attention mechanism and disjunctive graph embedding, and a sequence-to-sequence pattern is used to model the JSSP in the framework. A disjunctive graph embedding process based on node2vec is used to learn the disjunctive graph representations containing JSSP characteristics, thereby generalizing the model considerably. An improved transformer architecture based on a multihead attention mechanism is used to generate solutions. Containing a parallel-computing encoder and a recurrent-computing decoder, it is adept at learning long-range dependencies and effective at solving large-scale scheduling problems. Experimental results verified the effectiveness of the proposed method.","2023-02","2025-02-26 20:39:18","2025-02-26 20:39:18","","1322-1331","","2","19","","","","","","","","","","English","","","","WOS:000926964700020","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;50<br/>Total Times Cited:&nbsp;&nbsp;50<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Attention mechanism; deep reinforcement learning (DRL); graph embedding; job-shop scheduling; OPTIMIZATION; TABU SEARCH ALGORITHM; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ARXC65QU","journalArticle","2022","Tan, ZX; Yang, ZY; Zhang, M; Liu, Q; Sun, MS; Liu, Y","Dynamic Multi-Branch Layers for On-Device Neural Machine Translation","IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING","","2329-9290","10.1109/TASLP.2022.3153257","","With the rapid development of artificial intelligence (AI), there is a trend in moving AI applications, such as neural machine translation (NMT), from cloud to mobile devices. Constrained by limited hardware resources and battery, the performance of on-device NMT systems is far from satisfactory. Inspired by conditional computation, we propose to improve the performance of on-device NMT systems with dynamic multi-branch layers. Specifically, we design a layer-wise dynamic multi-branch network with only one branch activated during training and inference. As not all branches are activated during training, we propose shared-private reparameterization to ensure sufficient training for each branch. At almost the same computational cost, our method achieves improvements of up to 1.7 BLEU points on the WMT14 English-German translation task and 1.8 BLEU points on the WMT20 Chinese-English translation task over the Transformer model, respectively. Compared with a strong baseline that also uses multiple branches, the proposed method is up to 1.5 times faster with the same number of parameters.","2022","2025-02-26 20:39:18","2025-02-26 20:39:18","","958-967","","","30","","","","","","","","","","English","","","","WOS:000766602300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;25</p>","","","Conditional computation; decoding; Hardware; machine translation; Machine translation; Market research; Mobile handsets; natural language processing; Performance evaluation; Training; transformers; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EYT8G7JE","journalArticle","2025","Yan, J; Zhu, X; Wang, X; Zhang, DP","A New Fault Diagnosis Method for Rolling Bearings with the Basis of Swin Transformer and Generalized S Transform","MATHEMATICS","","2227-7390","10.3390/math13010045","","In view of the rolling bearing fault signal non-stationarity, strong noise can lead to low fault diagnosis accuracy. A Swin Transformer and generalized S Transform fault diagnosis method is proposed to solve the problems of difficult signal feature extraction and low diagnostic accuracy. Generalized S transform is used to improve the resolution of bearing fault signals, the Swin Transformer model is used to master the shallow weight required for identifying rolling bearing faults for highly fault characteristic expression signals, and the deep weight is obtained by backpropagation training. Finally, the extracted features are input into the improved Softmax classifier for fault classification. The various signal processing methods for the bearing signal processing ability are compared, and this model's diagnosis ability and the ability to resist noise are verified. The experimental results show that the method has a remarkable ability and an accuracy of above 90% in the anti-noise test and also has a good robustness.","2025-01","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","1","13","","","","","","","","","","English","","","","WOS:001393627900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","CONVOLUTIONAL NEURAL-NETWORK; fault diagnosis; generalized S transform; MACHINERY; rolling bearing; Swin Transform; vibration signal","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y32YTA47","journalArticle","2025","Zhu, JK; Liu, XD; Cheng, PL; Wang, MY; Huang, Y","Unveiling spatiotemporal patterns of wildfire risk: a transformer-based earth system analysis","CLIMATE DYNAMICS","","0930-7575","10.1007/s00382-024-07481-y","","Wildfires profoundly influence ecosystems, human societies, and economic activities as a global phenomenon. The continuing climate change increases the frequency and intensity of wildfire, resulting in urgent needs in searching for better fire management strategies. This paper aims to pave a pathway towards meeting this challenge through accurately predicting spatiotemporal pattern of global wildfire risk, using an improved Transformer model that integrates information theory and full-attention mechanisms. Experimental results demonstrate that the proposed SimAM modulated Full Attention Network shows superior performances in terms of Accuracy, Recall, and Area Under the Precision-Recall Curve. Furthermore, new discoveries based on the model find out that the wildfire risk in the northern forest region of Australia is influenced by the seasonality of the climate in North America and the Pacific and the dry winter climate in the Canadian region, illuminating the intricate relationship between the global climate and regional wildfire risk. These findings provide new tools and knowledges for understanding the mechanisms in global wildfire risk.","2025-01","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","1","63","","","","","","","","","","English","","","","WOS:001375830200003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","Deep learning; FIRE REGIMES; SimAM modulated full attention network (SimFAN); Transformer; Wildfire mechanism; Wildfire prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3RPHBWUY","journalArticle","2024","Kaushal, P; Singh, S; Vijayvergiya, R","A Kernel Attention-based Transformer Model for Survival Prediction of Heart Disease Patients","JOURNAL OF CARDIOVASCULAR TRANSLATIONAL RESEARCH","","1937-5387","10.1007/s12265-024-10537-3","","Survival analysis is employed to scrutinize time-to-event data, with emphasis on comprehending the duration until the occurrence of a specific event. In this article, we introduce two novel survival prediction models: CosAttnSurv and CosAttnSurv+DyACT. CosAttnSurv model leverages transformer-based architecture and a softmax-free kernel attention mechanism for survival prediction. Our second model, CosAttnSurv+DyACT, enhances CosAttnSurvwith Dynamic Adaptive Computation Time (DyACT) control, optimizing computation efficiency. The proposed models are validated using two public clinical datasets related to heart disease patients. When compared to other state-of-the-art models, our models demonstrated an enhanced discriminative and calibration performance. Furthermore, in comparison to other transformer architecture-based models, our proposed models demonstrate comparable performance while exhibiting significant reduction in both time and memory requirements. Overall, our models offer significant advancements in the field of survival analysis and emphasize the importance of computationally effective time-based predictions, with promising implications for medical decision-making and patient care.","2024-12","2025-02-26 20:39:18","2025-02-26 20:39:18","","1295-1306","","6","17","","","","","","","","","","English","","","","WOS:001283873900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Attention mechanisms; Automated risk analysis; Deep learning; Heart disease; REGRESSION; Survival analysis; TIME; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4EULLUVI","journalArticle","2024","Zhang, CH; Zhang, J; Zhao, JF; Zhang, TC","Prediction of Drift Trajectory in the Ocean Using Double-Branch Adaptive Span Attention","JOURNAL OF MARINE SCIENCE AND ENGINEERING","","2077-1312","10.3390/jmse12061016","","The accurate prediction of drift trajectories holds paramount significance for disaster response and navigational safety. The future positions of underwater drifters in the ocean are closely related to their historical drift patterns. Additionally, leveraging the complex dependencies between drift trajectories and ocean currents can enhance the accuracy of predictions. Building upon this foundation, we propose a Transformer model based on double-branch adaptive span attention (DBASformer), aimed at capturing the multivariate time-series relationships within drift history data and predicting drift trajectories in future periods. DBASformer can predict drift trajectories more accurately. The proposed adaptive span attention mechanism exhibits enhanced flexibility in the computation of attention weights, and the double-branch attention structure can capture the cross-time and cross-dimension dependencies in the sequences. Finally, our method was evaluated using datasets containing buoy data with ocean current velocities and Autonomous Underwater Vehicle (AUV) data. The raw data underwent cleaning and alignment processes. Comparative results with five alternative methods demonstrate that DBASformer improves prediction accuracy.","2024-06","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","6","12","","","","","","","","","","English","","","","WOS:001256152800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","attention mechanism; buoy trajectory data; drift trajectory prediction; multidimensional series; NETWORKS; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5P343MN3","journalArticle","2024","Guo, PF; Mei, YQ; Zhou, JY; Jiang, SS; Patel, VM","ReconFormer: Accelerated MRI Reconstruction Using Recurrent Transformer","IEEE TRANSACTIONS ON MEDICAL IMAGING","","0278-0062","10.1109/TMI.2023.3314747","","The accelerating magnetic resonance imaging (MRI) reconstruction process is a challenging ill-posed inverse problem due to the excessive under-sampling operation in k -space. In this paper, we propose a recurrent Transformer model, namely ReconFormer, for MRI reconstruction, which can iteratively reconstruct high-fidelity magnetic resonance images from highly under-sampled k-space data (e.g., up to 8 x acceleration). In particular, the proposed architecture is built upon Recurrent Pyramid Transformer Layers (RPTLs). The core design of the proposed method is Recurrent Scale-wise Attention (RSA), which jointly exploits intrinsic multi-scale information at every architecture unit as well as the dependencies of the deep feature correlation through recurrent states. Moreover, benefiting from its recurrent nature, ReconFormer is lightweight compared to other baselines and only contains 1.1 M trainable parameters. We validate the effectiveness of ReconFormer on multiple datasets with different magnetic resonance sequences and show that it achieves significant improvements over the state-of-the-art methods with better parameter efficiency. The implementation code and pre-trained weights are available at https://github.com/guopengf/ReconFormer.","2024-01","2025-02-26 20:39:18","2025-02-26 20:39:18","","582-593","","1","43","","","","","","","","","","English","","","","WOS:001158081600040","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;20<br/>Total Times Cited:&nbsp;&nbsp;21<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","deep learning; IMAGE; MRI; NETWORK; reconstruction; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"328TFC5S","journalArticle","2023","Zhou, L; Zhang, RH","A self-attention-based neural network for three-dimensional multivariate modeling and its skillful ENSO predictions","SCIENCE ADVANCES","","2375-2548","10.1126/sciadv.adf2827","","Large biases and uncertainties remain in real-time predictions of El Nino-Southern Oscillation (ENSO) using process-based dynamical models; recent advances in data-driven deep learning algorithms provide a promising mean to achieve superior skill in the tropical Pacific sea surface temperature (SST) modeling. Here, a specific selfattention-based neural network model is developed for ENSO predictions based on the much sought-after Transformer model, named 3D-Geoformer, which is used to predict three-dimensional (3D) upper-ocean temperature anomalies and wind stress anomalies. This purely data-driven and time-space attention-enhanced model achieves surprisingly high correlation skills for Nino 3.4 SST anomaly predictions made 18 months in advance and initiated beginning in boreal spring. Further, sensitivity experiments demonstrate that the 3DGeoformer model can depict the evolution of upper-ocean temperature and the coupled ocean-atmosphere dynamics following the Bjerknes feedback mechanism during ENSO cycles. Such successful realizations of the self-attention-based model in ENSO predictions indicate its great potential for multidimensional spatiotemporal modeling in geoscience.","2023-03-10","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","10","9","","","","","","","","","","English","","","","WOS:000960951400021","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;61<br/>Total Times Cited:&nbsp;&nbsp;64<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","2015-2016 EL-NINO; EVOLUTION; FORECASTS; MULTIMODEL ENSEMBLE; PREDICTABILITY; PROGRESS; TELECONNECTIONS; VARIABILITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X3Q9BPQ8","journalArticle","2022","Zhou, A; Zhang, YJ; Lu, MY","C-TRANSFORMER MODEL IN CHINESE POETRY AUTHORSHIP ATTRIBUTION","INTERNATIONAL JOURNAL OF INNOVATIVE COMPUTING INFORMATION AND CONTROL","","1349-4198","10.24507/ijicic.18.03.901","","Authorship attribution is broadly defined as an analysis of individuals' writing styles and has been attracting much interest. Although the problem has been widely explored, no previous studies have attempted to identify classical Chinese poetry. In this paper, we presented an evaluation system for poet popularity, and we provide the 20 most important poets in the Tang Dynasty. As a specific literal form, the theme feature plays a crucial role in Chinese poetry authorship attribution. To integrate the topic feature of a Chinese poem, we employed the latent Dirichlet allocation model to capture the extra theme information. At the same time, due to the incoherent expression of poetry text, we propose a combination model called C-Transformer to perform authorship attribution o f Chinese poetry. We conduct systematic evaluations of the proposed method on four Chinese poetry datasets, and our model achieves state-of-the-art results on related baseline methods. Through error analysis, this paper discusses the current problems and future challenges of Chinese poetry authorship attribution.","2022-06","2025-02-26 20:39:18","2025-02-26 20:39:18","","901-916","","3","18","","","","","","","","","","English","","","","WOS:000803928200015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","Authorship attribution; Chinese classical poetry; LDA; Natural language processing; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4QJRZ4AT","journalArticle","2022","Zhao, Y; Cong, G; Shi, JC; Miao, CY","QueryFormer: A Tree Transformer Model for Query Plan Representation","PROCEEDINGS OF THE VLDB ENDOWMENT","","2150-8097","10.14778/3529337.3529349","","Machine learning has become a prominent method in many database optimization problems such as cost estimation, index selection and query optimization. Translating query execution plans into their vectorized representations is non-trivial. Recently, several query plan representation methods have been proposed. However, they have two limitations. First, they do not fully utilize readily available database statistics in the representation, which characterizes the data distribution. Second, they typically have difficulty in modeling long paths of information flow in a query plan, and capturing parent-children dependency between operators. To tackle these limitations, we propose QueryFormer, a learning-based query plan representation model with a tree-structured Transformer architecture. In particular, we propose a novel scheme to integrate histograms obtained from database systems into query plan encoding. In addition, to effectively capture the information flow following the tree structure of a query plan, we develop a tree-structured model with the attention mechanism. We integrate QueryFormer into four machine learning models, each for a database optimization task, and experimental results show that QueryFormer is able to improve performance of these models significantly.","2022-04","2025-02-26 20:39:18","2025-02-26 20:39:18","","1658-1670","","8","15","","","","","","","","","","English","","","","WOS:000992381800013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;21<br/>Total Times Cited:&nbsp;&nbsp;22<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KX6JCFWY","journalArticle","2021","Kulchytska-Ruchka, I; Schöps, S","EFFICIENT PARALLEL-IN-TIME SOLUTION OF TIME-PERIODIC PROBLEMS USING A MULTIHARMONIC COARSE GRID CORRECTION","SIAM JOURNAL ON SCIENTIFIC COMPUTING","","1064-8275","10.1137/20M1314756","","This paper presents a highly parallelizable parallel-in-time algorithm for efficient solution of nonlinear time-periodic problems. It is based on the time-periodic extension of the parareal method, known to accelerate sequential computations via parallelization on the fine grid. The proposed approach reduces the complexity of the periodic parareal solution by introducing a simplified Newton algorithm, which allows an additional parallelization on the coarse grid. In particular, at each Newton iteration a multiharmonic correction is performed, which converts the block-cyclic periodic system in the time domain into a block-diagonal system in the frequency domain, thereby solving for each frequency component in parallel. The convergence analysis of the method is discussed for a one-dimensional model problem. The introduced algorithm and several existing solution approaches are compared via their application to the eddy current problem for both linear and nonlinear models of a coaxial cable. Performance of the considered methods is also illustrated for a three-dimensional transformer model.","2021","2025-02-26 20:39:18","2025-02-26 20:39:18","","C61-C88","","1","43","","","","","","","","","","English","","","","WOS:000623833100027","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","fast Fourier transform; FINITE-ELEMENT-METHOD; frequency domain solution; parallelization in time; PARAREAL; parareal algorithm; time-periodic problems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PYY59WR4","journalArticle","2024","Zhou, YX; Ye, XF; Yan, XC; Wang, T; Chen, J","Multi-Step Parking Demand Prediction Model Based on Multi-Graph Convolutional Transformer","SYSTEMS","","2079-8954","10.3390/systems12110487","","The increase in motorized vehicles in cities and the inefficient use of parking spaces have exacerbated parking difficulties in cities. To effectively improve the utilization rate of parking spaces, it is necessary to accurately predict future parking demand. This paper proposes a deep learning model based on multi-graph convolutional Transformer, which captures geographic spatial features through a Multi-Graph Convolutional Network (MGCN) module and mines temporal feature patterns using a Transformer module to accurately predict future multi-step parking demand. The model was validated using historical parking transaction volume data from all on-street parking lots in Nanshan District, Shenzhen, from September 2018 to March 2019, and its superiority was verified through comparative experiments with benchmark models. The results show that the MGCN-Transformer model has a MAE, RMSE, and R2 error index of 0.26, 0.42, and 95.93%, respectively, in the multi-step prediction task of parking demand, demonstrating its superior predictive accuracy compared to other benchmark models.","2024-11","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","11","12","","","","","","","","","","English","","","","WOS:001366499100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","deep learning; multi-graph convolutional network; multi-step prediction of parking demand; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TXZ88AKP","journalArticle","2024","Liu, HJ; Wang, LF; Wang, G","Emitter Signal Deinterleaving Based on Single PDW with Modulation-Hypothesis-Augmented Transformer","REMOTE SENSING","","2072-4292","10.3390/rs16203830","","Radar emitter signal deinterleaving based on pulse description words (PDWs) is a challenging task in the field of electronic warfare because of the parameter sparsity and uncertainty of PDWs. In this paper, a modulation-hypothesis-augmented Transformer model is proposed to identify emitters from a single PDW with an end-to-end manner. Firstly, the pulse features are enriched by the modulation hypothesis mechanism to generate I/Q complex signals from PDWs. Secondly, a multiple-parameter embedding method is proposed to expand the signal discriminative features and to enhance the identification capability of emitters. Moreover, a novel Transformer deep learning model, named PulseFormer and composed of spectral convolution, multi-layer perceptron, and self-attention based basic blocks, is proposed for discriminative feature extraction, emitter identification, and signal deinterleaving. Experimental results on synthesized PDW dataset show that the proposed method performs better on emitter signal deinterleaving in complex environments without relying on the pulse repetition interval (PRI). Compared with other deep learning methods, the PulseFormer performs better in noisy environments.","2024-10","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","20","16","","","","","","","","","","English","","","","WOS:001342296700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","IMPROVED ALGORITHM; modulation-hypothesis data argumentation; multiple parameters; PULSE; signal deinterleaving; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SSGEPM4Z","journalArticle","2024","Zhang, QJ; Jin, DH; Wang, YW; Gong, YZ","Statement-Grained Hierarchy Enhanced Code Summarization","ELECTRONICS","","2079-9292","10.3390/electronics13040765","","Code summarization plays a vital role in aiding developers with program comprehension by generating corresponding textual descriptions for code snippets. While recent approaches have concentrated on encoding the textual and structural characteristics of source code, they often neglect the global hierarchical features, causing limited code representation. Addressing this gap, our paper introduces the statement-grained hierarchy enhanced Transformer model (SHT), a novel framework that integrates global hierarchy, syntax, and token sequences to automatically generate summaries for code snippets. SHT is distinctively designed with two encoders to learn both hierarchical and sequential features of code. One relational attention encoder processes the statement-grained hierarchical graph, producing hierarchical embeddings. Subsequently, another sequence encoder integrates these hierarchical structures with token sequences. The resulting enriched representation is then fed into a vanilla Transformer decoder, which effectively generates concise and informative summarizations. Our extensive experiments demonstrate that SHT significantly outperforms state-of-the-art approaches on two widely used Java benchmarks. This underscores the effectiveness of incorporating global hierarchical information in enhancing the quality of code summarizations.","2024-02","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","4","13","","","","","","","","","","English","","","","WOS:001172143600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","code representation learning; code static analysis; COMPREHENSION; program comprehension; source code summarization; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q8VRR7SC","journalArticle","2024","Wang, Z; Liu, LZ; Dong, XJ; Liu, JX","Evaluation of neural network models and quality forecasting based on process time-series data","CANADIAN JOURNAL OF CHEMICAL ENGINEERING","","0008-4034","10.1002/cjce.25141","","Complex industrial process modelling is critically important within the context of industrial intelligence. In recent years, soft sensor techniques based on neural networks have become increasingly popular for modelling nonlinear industrial processes. This paper proposes an integrated framework of neural network modelling and evaluation for nonlinear dynamic processes. This framework achieves an integrated solution for modelling, prediction, evaluation, and network structure parameter selection. It can be applied to noisy sensors and dense data in the time domain. The framework's proposed evaluation mechanism employs two novel evaluation metrics, the variational auto-encoder (VAE)-based Kullback-Leibler (KL) divergence metric and the maximum likelihood estimation-based J metric, which both evaluate the model by mining the statistical properties of the residuals. The framework models the dynamic process with a model order based-gated recurrent units (MOb-GRU) neural network and a modified transformer model. Numerical experiments demonstrate that the evaluation mechanism functions properly in scenarios with multiple signal-to-noise ratios and multiple noise statistical properties and that the framework produces accurate modelling results.","2024-04","2025-02-26 20:39:18","2025-02-26 20:39:18","","1522-1537","","4","102","","","","","","","","","","English","","","","WOS:001104480800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","DESIGN; evaluation metrics; framework; neural networks; soft sensor; SOFT SENSORS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YDL2ATFN","journalArticle","2025","Cho, JW; Oh, J; Cha, JW","CGM: Copy Mechanism GPT with Mask for Ellipsis and Anaphora Resolution in Dialogue","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app15010005","","GPT (Generative Pre-trained Transformer) is a generative language model that demonstrates outstanding performance in the field of text generation. Generally, the attention mechanism of the transformer model behaves similarly to a copy distribution. However, due to the absence of a dedicated encoder, it is challenging to ensure that the input is retained for generation. We propose a model that emphasizes the copy mechanism in GPT. We generate masks for the input words to initialize the distribution and explicitly encourage copying through training. To demonstrate the effectiveness of our approach, we conducted experiments to restore ellipsis and anaphora in dialogue. In a single domain, we achieved 0.4319 (BLEU), 0.6408 (Rouge-L), 0.9040 (simCSE), and 0.9070 (BERTScore), while in multi-domain settings we obtained 0.4611 (BLEU), 0.6379 (Rouge-L), 0.8902 (simCSE), and 0.8999 (BERTScore). Additionally, we evaluated the operation of the copy mechanism on out-of-domain data, yielding excellent results. We anticipate that applying the copy mechanism to GPT will be useful for utilizing language models in constrained situations.","2025-01","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","1","15","","","","","","","","","","English","","","","WOS:001393484800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","copy mechanism; curriculum learning; pre-trained models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8RL65FQY","journalArticle","2024","Shardlow, M; Przybyla, P","Deanthropomorphising NLP: Can a language model be conscious?","PLOS ONE","","1932-6203","10.1371/journal.pone.0307521","","This work is intended as a voice in the discussion over previous claims that a pretrained large language model (LLM) based on the Transformer model architecture can be sentient. Such claims have been made concerning the LaMDA model and also concerning the current wave of LLM-powered chatbots, such as ChatGPT. This claim, if confirmed, would have serious ramifications in the Natural Language Processing (NLP) community due to wide-spread use of similar models. However, here we take the position that such a large language model cannot be conscious, and that LaMDA in particular exhibits no advances over other similar models that would qualify it. We justify this by analysing the Transformer architecture through Integrated Information Theory of consciousness. We see the claims of sentience as part of a wider tendency to use anthropomorphic language in NLP reporting. Regardless of the veracity of the claims, we consider this an opportune moment to take stock of progress in language modelling and consider the ethical implications of the task. In order to make this work helpful for readers outside the NLP community, we also present the necessary background in language modelling.","2024-12-04","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","12","19","","","","","","","","","","English","","","","WOS:001372873500045","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;97</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TR2GGCW9","journalArticle","2024","Xu, JL; Wen, YH; Huang, SH; Yu, Z","A multi-domain adaptive neural machine translation method based on domain data balancer","INTELLIGENT DATA ANALYSIS","","1088-467X","10.3233/IDA-230155","","Most methods for multi-domain adaptive neural machine translation (NMT) currently rely on mixing data from multiple domains in a single model to achieve multi-domain translation. However, this mixing can lead to imbalanced training data, causing the model to focus on training for the large-scale general domain while ignoring the scarce resources of specific domains, resulting in a decrease in translation performance. In this paper, we propose a multi-domain adaptive NMT method based on Domain Data Balancer (DDB) to address the problems of imbalanced data caused by simple fine-tuning. By adding DDB to the Transformer model, we adaptively learn the sampling distribution of each group of training data, replace the maximum likelihood estimation criterion with empirical risk minimization training, and introduce a reward-based iterative update of the bilevel optimizer based on reinforcement learning. Experimental results show that the proposed method improves the baseline model by an average of 1.55 and 0.14 BLEU (Bilingual Evaluation Understudy) scores respectively in English-German and Chinese-English multi-domain NMT.","2024","2025-02-26 20:39:18","2025-02-26 20:39:18","","685-698","","3","28","","","","","","","","","","English","","","","WOS:001241215600005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","domain data balancer; empirical risk minimization; machine translation; Multi-domain adaptation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BK56H9Y9","journalArticle","2024","Park, J; Lee, K; Kim, HY","Integrated Recognition Assistant Framework Based on Deep Learning for Autonomous Driving: Human-Like Restoring Damaged Road Sign Information","INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION","","1044-7318","10.1080/10447318.2023.2204274","","Unpredictable situations frequently occur in real driving environments, and it is often difficult to recognize road signs. In this case, autonomous vehicles (AVs) have a limited ability to predict areas that cannot be detected, making it difficult to judge objects accurately when some information is lost. Therefore, we propose a framework that helps AVs infer proper information under limited conditions. The entire process consists of three steps. First, the missing part of the road sign is restored using the image generative pre-trained transformer model. Next, the sample image with the highest classification accuracy and restored quality is selected among several sample images. Finally, the selected image is provided to users through the designed user interface. The proposed framework improved recognition accuracy compared with unrestored accuracy, indicating the possibility of application as a driving assistance system, and is meaningful in that it is a system that mimics human reasoning ability.","2024-08-02","2025-02-26 20:39:18","2025-02-26 20:39:18","","3982-4002","","15","40","","","","","","","","","","English","","","","WOS:000975954600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;84</p>","","","Autonomous vehicles; CAR; decision support; driving assistance system; MODEL; road sign restoration; safety driving; user experience; VEHICLES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EBT3RHAX","journalArticle","2023","Li, JH; Wang, P; Zhang, YS","DeepLabV3+Vision Transformer for Visual Bird Sound Denoising","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3294476","","Audio denoising is a task to improve the perceptual quality of noisy audio signals. There is still residual noise after the denoising of noisy signals, which will affect the quality of audio data. Traditional and deep learning-based methods are still limited to the manual addition of artificial noise or low-frequency noise. Recently, audio denoising has been transformed into an image segmentation problem, and deep neural networks have been applied to solve this problem. However, its performance is limited to shallow image segmentation models. This paper proposes a novel vision transformer model for visual bird sound denoising, combining a pyramid transformer and DeepLabV3+ network (named PtDeepLab) to filter out the noise. The proposed PtDeepLab model is based on the pyramid transformer, which generates long-range and multi-scale representations. The PtDeepLab model can achieve intuitive noise reduction in audio, which helps to separate clean audio from the mixture signal. Extensive experimental results showed that the proposed model has a better denoising performance than state-of-the-art methods.","2023","2025-02-26 20:39:18","2025-02-26 20:39:18","","92540-92549","","","11","","","","","","","","","","English","","","","WOS:001060261700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;59</p>","","","Audio denoising; DeepLabV3+; NETWORK; NOISE; SEPARATION; SPEECH ENHANCEMENT; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A7JRUPRQ","journalArticle","2023","Tampu, IE; Eklund, A; Johansson, K; Gimm, O; Haj-Hosseini, N","Diseased thyroid tissue classification in OCT images using deep learning: Towards surgical decision support","JOURNAL OF BIOPHOTONICS","","1864-063X","10.1002/jbio.202200227","","Intraoperative guidance tools for thyroid surgery based on optical coherence tomography (OCT) could aid distinguish between normal and diseased tissue. However, OCT images are difficult to interpret, thus, real-time automatic analysis could support the clinical decision-making. In this study, several deep learning models were investigated for thyroid disease classification on 2D and 3D OCT data obtained from ex vivo specimens of 22 patients undergoing surgery and diagnosed with several thyroid pathologies. Additionally, two open-access datasets were used to evaluate the custom models. On the thyroid dataset, the best performance was achieved by the 3D vision transformer model with a Matthew's correlation coefficient (MCC) of 0.79 (accuracy = 0.90) for the normal-versus-abnormal classification. On the open-access datasets, the custom models achieved the best performance (MCC > 0.88, accuracy > 0.96). Results obtained for the normal-versus-abnormal classification suggest OCT, complemented with deep learning-based analysis, as a tool for real-time automatic diseased tissue identification in thyroid surgery.","2023-02","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","2","16","","","","","","","","","","English","","","","WOS:000881833000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","convolutional neural networks; optical coherence tomography; OPTICAL COHERENCE TOMOGRAPHY; surgical guidance; thyroid; tissue classification; vision transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MH4BB267","journalArticle","2022","Song, Z; Xu, WX; Dong, HL; Wang, XW; Cao, YQ; Huang, PJ; Hou, DB; Wu, ZF; Wang, ZY","Research on Cyanobacterial-Bloom Detection Based on Multispectral Imaging and Deep-Learning Method","SENSORS","","1424-8220","10.3390/s22124571","","Frequent outbreaks of cyanobacterial blooms have become one of the most challenging water ecosystem issues and a critical concern in environmental protection. To overcome the poor stability of traditional detection algorithms, this paper proposes a method for detecting cyanobacterial blooms based on a deep-learning algorithm. An improved vegetation-index method based on a multispectral image taken by an Unmanned Aerial Vehicle (UAV) was adopted to extract inconspicuous spectral features of cyanobacterial blooms. To enhance the recognition accuracy of cyanobacterial blooms in complex scenes with noise such as reflections and shadows, an improved transformer model based on a feature-enhancement module and pixel-correction fusion was employed. The algorithm proposed in this paper was implemented in several rivers in China, achieving a detection accuracy of cyanobacterial blooms of more than 85%. The estimate of the proportion of the algae bloom contamination area and the severity of pollution were basically accurate. This paper can lay a foundation for ecological and environmental departments for the effective prevention and control of cyanobacterial blooms.","2022-06","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","12","22","","","","","","","","","","English","","","","WOS:000819605000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","ALGAL BLOOMS; cyanobacterial blooms; deep learning; DIANCHI; LAKE; remote-sensing technology; VEGETATION; vegetation index","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4REC9HDN","journalArticle","2024","Jiang, LZ; Du, HZ; Bu, YF; Zhao, CY; Lu, HL; Yan, J","Deep learning-based multilabel compound-fault diagnosis in centrifugal pumps","OCEAN ENGINEERING","","0029-8018","10.1016/j.oceaneng.2024.119697","","In this study, the issue of centrifugal pumps used in marine engineering is addressed, as they are susceptible to malfunction owing to long-term operation in highly corrosive seawater and extreme weather conditions, resulting in operational interruptions and safety risks. We propose a high-precision intelligent fault-diagnosis method for multiple fault types based on deep learning. In this method, continuous wavelet transform is firstly employed to extract signal time-frequency domain features. Subsequently, the Swin transformer model is used to process the wavelet time-frequency images converted from signals. Finally, multilabel classification methods are combined to diagnose various complex faults. The effectiveness of the proposed method is validated using a dataset obtained from simulation experiments pertaining to centrifugal-pump faults. The results show that the proposed method achieves 100% accuracy in diagnosing 27 types of faults and provides excellent diagnosis even under limited compound-fault samples, thus offering an efficient and practical method for fault diagnosis in centrifugal pumps used in marine engineering.","2024-12-15","2025-02-26 20:39:18","2025-02-26 20:39:18","","","","","314","","","","","","","","","","English","","","","WOS:001358515500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Centrifugal pump; Compound faults; Fault diagnosis; MACHINERY; Multilabel classification; Swin transformer; TRANSFORM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P6JAQF7E","journalArticle","2024","Zhou, JJ; Liu, BL; Xiong, YP; Chiu, C; Liu, FY; Gong, XY","FAT: Field-Aware Transformer for Point Cloud Segmentation With Adaptive Attention Fields","IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS","","1551-3203","10.1109/TII.2024.3393572","","Point cloud segmentation is crucial for various industrial applications, such as autonomous driving and robotics. Recent developments underscore the significant potential of transformer models in this field. However, existing attention mechanisms apply the same feature learning paradigm for all points equally, ignoring the considerable size differences among objects in a scene. To rectify this, we introduce the field-aware transformer (FAT), engineered to tailor effective receptive fields to objects of varying sizes. Our FAT achieves field-aware learning through two primary components: the multigranularity attention (MGA) scheme and the reattention module. The MGA scheme is proficient in aggregating tokens from distant areas while preserving multiscale features within each attention layer. The reattention module dynamically adjusts the attention scores to the fine- and coarse-grained features output by MGA for each point. Extensive experimental results underscore the effectiveness and efficiency of our FAT, which delivers state-of-the-art performance on both the stanford 3D indoor scene dataset (S3DIS) and ScanNetV2 datasets.","2024-09","2025-02-26 20:39:19","2025-02-26 20:39:19","","10825-10835","","9","20","","","","","","","","","","English","","","","WOS:001226154600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;7</p>","","","3-D scene understanding; multigranularity attention (MGA); point cloud; semantic segmentation; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LN9RJU49","journalArticle","2023","Cakir, A; Gurkan, M","Modified query expansion through generative adversarial networks for information extraction in e-commerce","MACHINE LEARNING WITH APPLICATIONS","","2666-8270","10.1016/j.mlwa.2023.100509","","This work addresses an alternative approach for query expansion (QE) using a generative adversarial network (GAN) to enhance the effectiveness of information search in e -commerce. We propose a modified QE conditional GAN ( m QE-CGAN) framework, which resolves keywords by expanding the query with a synthetically generated query that proposes semantic information from text input. we train a sequence -tosequence transformer model as the generator to produce keywords and use a recurrent neural network model as the discriminator to classify an adversarial output with the generator. with the modified CGAN framework, Various forms of semantic insights gathered from the query -document corpus are introduced to the generation process. We leverage these insights as conditions for the generator model and discuss their effectiveness for the query expansion task. our experiments demonstrate that the utilization of condition structures within the m QE- CGAN framework can increase the semantic similarity between generated sequences and reference documents up to nearly 10% compared to baseline models.","2023-12-15","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","14","","","","","","","","","","English","","","","WOS:001221698100005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Conditional neural networks; E-commerce; Generative adversarial networks; Information retrieval; Query expansion; RETRIEVAL; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NWT5P9ZQ","journalArticle","2023","Lim, YM; Hong, YH; Kang, GH; Chung, CW","Highly efficient plasma generation in inductively coupled plasmas using a parallel capacitor","JOURNAL OF VACUUM SCIENCE & TECHNOLOGY A","","0734-2101","10.1116/6.0002180","","A highly efficient plasma source is developed in inductively coupled plasmas (ICPs) using a parallel capacitor, which is connected to an antenna in parallel. The power absorbed by the ICP is proportional to the equivalent resistance of the ICP. In order to improve the plasma generation, a parallel resonance is used between the parallel capacitor and the equivalent inductance by the plasma and the antenna. In all experiments conducted under an H-mode regime where the inductive heating is dominant, the resistance of a load involving the plasma increases about ten times near the resonance, and the power consumed by the plasma is greatly increased. Consequently, the electron density is greatly increased up to about 350% in the argon plasma and is significantly increased up to about 1000% in the oxygen plasma. For analysis, the transformer model of the ICP and the power balance equation of the global model are introduced, and they show good agreement with the experimental results. Published under an exclusive license by the AVS.","2023-01","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","1","41","","","","","","","","","","English","","","","WOS:000906004900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","DISCHARGE; ELECTRON-ENERGY DISTRIBUTION; PARAMETERS; TEMPERATURE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FRY56IJG","journalArticle","2025","Gao, YL; Xing, F; Kang, LP; Zhang, MM; Qin, CY","Ultra-Short-Term Wind Power Forecasting Based on DT-DSCTransformer Model","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2025.3537158","","When using the Transformer model for wind power prediction, the accuracy of the model predictions tends to be reduced due to the shift in the wind power data distribution, channel mixing, and the inability of the model to establish strong correlations. To address these challenges, this paper proposes an ultra-short-term wind power prediction model based on the DT-DSCTransformer. First, the model applies DT's self-learning standardization and de-standardization parameters to standardize the input and de-standardize the output, mitigating the impact forecasting of data distribution shifts on prediction accuracy. Second, the proposed De-Stationary Channel Attention (DSCAttention) mechanism is introduced. By incorporating De-Stationary Attention (DSAttention) into the channel attention mechanism while maintaining channel independence, the model establishes stronger inter-channel correlations, addressing the performance degradation caused by channel mixing and weak correlations. Finally, experimental analysis demonstrates that the proposed model achieves the highest prediction accuracy compared to commonly used time series forecasting models.","2025","2025-02-26 20:39:19","2025-02-26 20:39:19","","22919-22930","","","13","","","","","","","","","","English","","","","WOS:001416143900004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Accuracy; Computational modeling; Correlation; Data models; distribution shift; DSCAttention; DT; Forecasting; Prediction algorithms; Predictive models; Transformer; Transformers; Wind power generation; wind power prediction; Wind speed","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U29XW2J8","journalArticle","2024","Yue, XP; Zhang, CN; Wang, ZJ; Yu, Y; Cong, SQ; Shen, YM; Zhao, JC","Hierarchical transformer speech depression detection model research based on Dynamic window and Attention merge","PEERJ COMPUTER SCIENCE","","2376-5992","10.7717/peerj-cs.2348","","Depression Detection of Speech is widely applied due to its ease of acquisition and imbuing with emotion. However, there exist challenges in effectively segmenting and integrating depressed speech segments. Multiple merges can also lead to blurred original information. These problems diminish the effectiveness of existing models. This article proposes a Hierarchical Transformer model for speech depression detection based on dynamic window and attention merge, abbreviated as DWAM-Former. DWAM-Former utilizes a Learnable Speech Split module (LSSM) to effectively separate the phonemes and words within an entire speech segment. Moreover, the Adaptive Attention Merge module (AAM) is introduced to generate representative feature representations for each phoneme and word in the sentence. DWAM-Former also associates the original feature information with the merged features through a Variable- Length Residual module (VL-RM), reducing feature loss caused by multiple mergers. DWAM-Former has achieved highly competitive results in the depression detection dataset DAIC-WOZ. An MF1 score of 0.788 is received in the experiment, representing a 7.5% improvement over previous research.","2024-09-26","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","10","","","","","","","","","","English","","","","WOS:001321698100002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","Hierarchical framework; Speech emotion recognition; Speech signal processing; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3TPT7V3Q","journalArticle","2024","Sulun, S; Viana, P; Davies, MEP","Movie trailer genre classification using multimodal pretrained features","EXPERT SYSTEMS WITH APPLICATIONS","","0957-4174","10.1016/j.eswa.2024.125209","","We introduce a novel method for movie genre classification, capitalizing on a diverse set of readily accessible pretrained models. These models extract high-level features related to visual scenery, objects, characters, text, speech, music, and audio effects. To intelligently fuse these pretrained features, we train small classifier models with low time and memory requirements. Employing the transformer model, our approach utilizes all video and audio frames of movie trailers without performing any temporal pooling, efficiently exploiting the correspondence between all elements, as opposed to the fixed and low number of frames typically used by traditional methods. Our approach fuses features originating from different tasks and modalities, with different dimensionalities, different temporal lengths, and complex dependencies as opposed to current approaches. Our method outperforms state-of-the-art movie genre classification models in terms of precision, recall, and mean average precision (mAP). To foster future research, we make the pretrained features for the entire MovieNet dataset, along with our genre classification code and the trained models, publicly available.","2024-12-15","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","258","","","","","","","","","","English","","","","WOS:001304778000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;49</p>","","","Cinematic trailer classification; Multimodal features; NEURAL-NETWORKS; Transformers; Video classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UV88GJUE","journalArticle","2024","Zhang, ZW; Meng, LH; Gu, YT","SageFormer: Series-Aware Framework for Long-Term Multivariate Time-Series Forecasting","IEEE INTERNET OF THINGS JOURNAL","","2327-4662","10.1109/JIOT.2024.3363451","","In the burgeoning ecosystem of Internet of Things, multivariate time-series (MTS) data has become ubiquitous, highlighting the fundamental role of time-series forecasting across numerous applications. The crucial challenge of long-term MTS forecasting requires adept models capable of capturing both intra- and inter-series dependencies. Recent advancements in deep learning, notably Transformers, have shown promise. However, many prevailing methods either marginalize interseries dependencies or overlook them entirely. To bridge this gap, this article introduces a novel series-aware framework, explicitly designed to emphasize the significance of such dependencies. At the heart of this framework lies our specific implementation: the SageFormer. As a series-aware graph-enhanced Transformer model, SageFormer proficiently discerns and models the intricate relationships between series using graph structures. Beyond capturing diverse temporal patterns, it also curtails redundant information across series. Notably, the series-aware framework seamlessly integrates with existing Transformer-based models, enriching their ability to comprehend interseries relationships. Extensive experiments on real-world and synthetic data sets validate the superior performance of SageFormer against contemporary state-of-the-art approaches.","2024-05-15","2025-02-26 20:39:19","2025-02-26 20:39:19","","18435-18448","","10","11","","","","","","","","","","English","","","","WOS:001221337300046","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Interseries dependencies; time-series forecasting; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RLVXKW52","journalArticle","2023","Zhang, ZH; Liu, BL; Li, YN","FURSformer: Semantic Segmentation Network for Remote Sensing Images with Fused Heterogeneous Features","ELECTRONICS","","2079-9292","10.3390/electronics12143113","","Semantic segmentation of remote sensing images poses a formidable challenge within this domain. Our investigation commences with a pilot study aimed at scrutinizing the advantages and disadvantages of employing a Transformer architecture and a CNN architecture in remote sensing imagery (RSI). Our objective is to substantiate the indispensability of both local and global information for RSI analysis. In this research article, we harness the potential of the Transformer model to establish global contextual understanding while incorporating an additional convolution module for localized perception. Nonetheless, a direct fusion of these heterogeneous information sources often yields subpar outcomes. To address this limitation, we propose an innovative hierarchical fusion feature information module that this model can fuse Transformer and CNN features using an ensemble-to-set approach, thereby enhancing information compatibility. Our proposed model, named FURSformer, amalgamates the strengths of the Transformer architecture and CNN. The experimental results clearly demonstrate the effectiveness of this approach. Notably, our model achieved an outstanding accuracy of 90.78% mAccuracy on the DLRSD dataset.","2023-07","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","14","12","","","","","","","","","","English","","","","WOS:001035158900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;42</p>","","","CNN; remote sensing images; semantic segmentation; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BILK5SJV","journalArticle","2022","Bai, ZW; Liu, JP; Wang, MQ; Yuan, CX; Wang, XJ","Exploiting Diverse Information in Pre-Trained Language Model for Multi-Choice Machine Reading Comprehension","APPLIED SCIENCES-BASEL","","2076-3417","10.3390/app12063072","","Answering different multi-choice machine reading comprehension (MRC) questions generally requires different information due to the abundant diversity of the questions, options and passages. Recently, pre-trained language models which provide rich information have been widely used to address MRC tasks. Most of the existing work only focuses on the output representation at the top layer of the models; the subtle and beneficial information provided by the intermediate layers is ignored. This paper therefore proposes a multi-decision based transformer model that builds multiple decision modules by utilizing the outputs at different layers to confront the various questions and passages. To avoid the information diversity in different layers being damaged during fine-tuning, we also propose a learning rate decaying method to control the updating speed of the parameters in different blocks. Experimental results on multiple publicly available datasets show that our model can answer different questions by utilizing the representation in different layers and speed up the inference procedure with considerable accuracy.","2022-03","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","6","12","","","","","","","","","","English","","","","WOS:000776877000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","learning rate decaying; multi-choice machine reading comprehension; multi-decision based transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RLKBBJS5","journalArticle","2024","Cao, RJ; Zhao, ZY; Un, KF; Yu, WH; Martins, RP; Mak, PI","An FPGA-Based Transformer Accelerator With Parallel Unstructured Sparsity Handling for Question-Answering Applications","IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS II-EXPRESS BRIEFS","","1549-7747","10.1109/TCSII.2024.3462560","","Dataflow management provides limited performance improvement to the transformer model due to its lesser weight reuse than the convolution neural network. The cosFormer reduced computational complexity while achieving comparable performance to the vanilla transformer for natural language processing tasks. However, the unstructured sparsity in the cosFormer makes it a challenge to be implemented efficiently. This brief proposes a parallel unstructured sparsity handling (PUSH) scheme to compute sparse-dense matrix multiplication (SDMM) efficiently. It transforms unstructured sparsity into structured sparsity and reduces the total memory access by balancing the memory accesses of the sparse and dense matrices in the SDMM. We also employ unstructured weight pruning cooperating with PUSH to further increase the structured sparsity of the model. Through verification on an FPGA platform, the proposed accelerator achieves a throughput of 2.82 TOPS and an energy efficiency of 144.8 GOPs/W for HotpotQA dataset with long sequences.","2024-11","2025-02-26 20:39:19","2025-02-26 20:39:19","","4688-4692","","11","71","","","","","","","","","","English","","","","WOS:001348293900026","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","Circuits; Computational modeling; Dataflow; digital accelerator; EFFICIENT; Energy efficiency; energy-efficient; field-programmable gate array (FPGA); Hardware; Sparse matrices; sparsity; Throughput; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QXPS5ZIR","journalArticle","2024","Wang, DS; Feng, Y; Li, JW; Liu, S; Zhou, MM; Zhang, DM; Li, HG","CFNAM-PG: Bridging Phonetic and Glyphic Information for Chinese Full Name and Abbreviation Matching Based on Simbert and DenseNet","INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS","","1875-6891","10.1007/s44196-024-00549-x","","Matching abbreviated names with their full names (full-abbr matching) plays a key role in data integration, address matching, information retrieval, and other fields. Traditional full-abbr matching technology often encounters issues related to near homophones and near homoglyphs. First, a near-homophone full-abbr matching model based on Simbert and VGG was first proposed, which integrates character and speech features, leveraging a speech recognition model and combining a brain-like cognitive learning dual-process mechanism which involves linguistic knowledge and neural network together. Second, to address the problem of near-homoglyph full-abbr matching in Chinese, a DenseNet-based model that fuses glyph structure and image features was proposed, in which statistical feature extractors are employed to extract feature vectors for glyphic features including stroke, Wubi and structural features separately. Lastly, the near-homophone model and the near-homoglyph model are coupled to work together in the full-abbr matching task, in which expert knowledge is used as a component of the feature optimizer. Experimental results showed that the integrated model significantly increased the matching accuracy to 87.5%, demonstrating a 12.3% improvement.","2024-06-24","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","1","17","","","","","","","","","","English","","","","WOS:001253220200004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;12</p>","","","Abbreviation matching; Full name; Multimodal feature fusion; Near homoglyph; Near homophone","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9NN2MEP5","journalArticle","2024","Chan, RKW; Wang, BX","Do long-term acoustic-phonetic features and mel-frequency cepstral coefficients provide complementary speaker-specific information for forensic voice comparison?","FORENSIC SCIENCE INTERNATIONAL","","0379-0738","10.1016/j.forsciint.2024.112199","","A growing number of studies in forensic voice comparison have explored how elements of phonetic analysis and automatic speaker recognition systems may be integrated for optimal speaker discrimination performance. However, few studies have investigated the evidential value of long-term speech features using forensicallyrelevant speech data. This paper reports an empirical validation study that assesses the evidential strength of the following long-term features: fundamental frequency (F0), formant distributions, laryngeal voice quality, mel-frequency cepstral coefficients (MFCCs), and combinations thereof. Non-contemporaneous recordings with speech style mismatch from 75 male Australian English speakers were analyzed. Results show that 1) MFCCs outperform long-term acoustic phonetic features; 2) source and filter features do not provide considerably complementary speaker-specific information; and 3) the addition of long-term phonetic features to an MFCCsbased system does not lead to meaningful improvement in system performance. Implications for the complementarity of phonetic analysis and automatic speaker recognition systems are discussed.","2024-10","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","363","","","","","","","","","","English","","","","WOS:001301775800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","Forensic voice comparison; FUSION; IDENTIFICATION; Likelihood-ratio; Long-term acoustic-phonetic features; Mel-frequency cepstral coefficients; Non-contemporaneous recordings; Speech style mismatch; VARIABILITY; WORD RECOGNITION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"86NUD9Z7","journalArticle","2022","Joshy, AA; Rajan, R","Automated Dysarthria Severity Classification: A Study on Acoustic Features and Deep Learning Techniques","IEEE TRANSACTIONS ON NEURAL SYSTEMS AND REHABILITATION ENGINEERING","","1534-4320","10.1109/TNSRE.2022.3169814","","Assessing the severity level of dysarthria can provide an insight into the patient's improvement, assist pathologists to plan therapy, and aid automatic dysarthric speech recognition systems. In this article, we present a comparative study on the classification of dysarthria severity levels using different deep learning techniques and acoustic features. First, we evaluate the basic architectural choices such as deep neural network (DNN), convolutional neural network, gated recurrent units and long short-term memory network using the basic speech features, namely, Mel-frequency cepstral coefficients (MFCCs) and constant-Q cepstral coefficients. Next, speech-disorder specific features computed from prosody, articulation, phonation and glottal functioning are evaluated on DNN models. Finally, we explore the utility of low-dimensional feature representation using subspace modeling to give i-vectors, which are then classified using DNN models. Evaluation is done using the standard UA-Speech and TORGO databases. By giving an accuracy of 93.97% under the speaker-dependent scenario and 49.22% under the speaker-independent scenario for the UA-Speech database, the DNN classifier using MFCC-based i-vectors outperforms other systems.","2022","2025-02-26 20:39:19","2025-02-26 20:39:19","","1147-1157","","","30","","","","","","","","","","English","","","","WOS:000790812300009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;25<br/>Total Times Cited:&nbsp;&nbsp;25<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","ARTICULATION; Databases; Deep learning; Diseases; dysarthria; Estimation; i-vectors; Neural networks; severity assessment; SPEECH; Speech recognition; Support vector machines","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RFA24XLN","journalArticle","2021","Li, DD; Zhou, YJ; Wang, Z; Gao, DQ","Exploiting the potentialities of features for speech emotion recognition","INFORMATION SCIENCES","","0020-0255","10.1016/j.ins.2020.09.047","","In recent years, studies on speech signals have increasingly paid attention to emotional information. The most challenging aspect in speech emotion recognition (SER) is choosing the optimal speech feature representation. According to the statistical analysis, the roles of each speech feature differ under different emotions, indicating that different features have different abilities in distinguishing emotions. This study proposes an emotional-category based feature weighting (ECFW) method, which aims at finding the prominence of each feature under different emotions and applying this prominence as priori knowledge. Furthermore, previous studies have paid little attention to matching the relationship between speech features and models. This study argues that different combinations of models and features result in large differences in the performance of SER, which are evaluated by several experiments. Features must be modeled with appropriate approaches to extract the most valuable information for emotional representation. Then, the best combinations of features and models are selected to test our method. The method is applied on three commonly used speech emotion databases, IEMOCAP, MASC, and EMO-DB. The results show that ECFW significantly improves the performance of SER tasks. (C) 2020 Elsevier Inc. All rights reserved.","2021-02-16","2025-02-26 20:39:19","2025-02-26 20:39:19","","328-343","","","548","","","","","","","","","","English","","","","WOS:000596037700002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;31<br/>Total Times Cited:&nbsp;&nbsp;31<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Deep learning; Feature optimization; Feature selection; FEATURE-SELECTION; NEURAL-NETWORKS; SPECTRAL FEATURES; Speech emotion recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"35TEP5K8","journalArticle","2025","François, C; Rodriguez-Fornells, A; Cerda-Company, X; Agut, T; Bosch, L","Impact of late to moderate preterm birth on minimal pair word-learning","CHILD DEVELOPMENT","","0009-3920","10.1111/cdev.14160","","Little is known about language development after late-to-moderate premature birth, the most significant part of prematurity worldwide. We examined minimal-pair word-learning skills in 18 eighteen-month-old healthy full-term (mean gestational age [GA] at birth = 39.6 weeks; 7 males; 100% Caucasian) and 18 healthy late-to-moderate preterm infants (mean GA at birth 33.7 weeks; 11 males; 100% Caucasian). Data were collected in the local urban area of Barcelona city from May 2015 to August 2016. Toddlers first associated two pseudo-words, forming a minimal pair based on a voice onset time distinction of the initial consonant, with two unfamiliar objects during a habituation phase. A visual choice test assessed their recognition of the two novel word-object associations and some familiar word-object pairs. While full-terms successfully mapped the similar sounding pair of novel words (d = 1.57), preterms could not (d = 0.17). These results suggest that late to moderate preterm birth can hinder basic associative learning mechanisms relying on fine temporal speech features.","2025-01","2025-02-26 20:39:19","2025-02-26 20:39:19","","203-216","","1","96","","","","","","","","","","English","","","","WOS:001304420700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;95</p>","","","CHILDREN BORN; HUMAN INFANTS; LANGUAGE-DEVELOPMENT; LONG-TERM OUTCOMES; PHONETIC DETAIL; PHONOLOGICAL SPECIFICITY; SPEECH-PERCEPTION; SYLLABIC DURATION; VOCABULARY SIZE; VOICE ONSET TIME","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q5FYVKWE","journalArticle","2023","Atenco, JC; Moreno, JC; Ramirez, JM","Audiovisual Biometric Network with Deep Feature Fusion for Identification and Text Prompted Verification","ALGORITHMS","","1999-4893","10.3390/a16020066","","In this work we present a bimodal multitask network for audiovisual biometric recognition. The proposed network performs the fusion of features extracted from face and speech data through a weighted sum to jointly optimize the contribution of each modality, aiming for the identification of a client. The extracted speech features are simultaneously used in a speech recognition task with random digit sequences. Text prompted verification is performed by fusing the scores obtained from the matching of bimodal embeddings with the Word Error Rate (WER) metric calculated from the accuracy of the transcriptions. The score fusion outputs a value that can be compared with a threshold to accept or reject the identity of a client. Training and evaluation was carried out by using our proprietary database BIOMEX-DB and VidTIMIT audiovisual database. Our network achieved an accuracy of 100% and an Equal Error Rate (EER) of 0.44% for identification and verification, respectively, in the best case. To the best of our knowledge, this is the first system that combines the mutually related tasks previously described for biometric recognition.","2023-02","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","2","16","","","","","","","","","","English","","","","WOS:000937770500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;63</p>","","","deep feature fusion; face recognition; multimodal biometrics; multitask learning; RECOGNITION; speaker recognition; text prompted verification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KU3DKGJT","journalArticle","2024","Accou, B; Bollens, L; Gillis, M; Verheijen, W; Van Hamme, H; Francart, T","SparrKULee: A Speech-Evoked Auditory Response Repository from KU Leuven, Containing the EEG of 85 Participants","DATA","","2306-5729","10.3390/data9080094","","Researchers investigating the neural mechanisms underlying speech perception often employ electroencephalography (EEG) to record brain activity while participants listen to spoken language. The high temporal resolution of EEG enables the study of neural responses to fast and dynamic speech signals. Previous studies have successfully extracted speech characteristics from EEG data and, conversely, predicted EEG activity from speech features. Machine learning techniques are generally employed to construct encoding and decoding models, which necessitate a substantial quantity of data. We present SparrKULee, a Speech-evoked Auditory Repository of EEG data, measured at KU Leuven, comprising 64-channel EEG recordings from 85 young individuals with normal hearing, each of whom listened to 90-150 min of natural speech. This dataset is more extensive than any currently available dataset in terms of both the number of participants and the quantity of data per participant. It is suitable for training larger machine learning models. We evaluate the dataset using linear and state-of-the-art non-linear models in a speech encoding/decoding and match/mismatch paradigm, providing benchmark scores for future research.","2024-08","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","8","9","","","","","","","","","","English","","","","WOS:001307412000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","auditory EEG; dataset; ENTRAINMENT; ENVELOPE; speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3HS5I35F","journalArticle","2022","Shen, YF; Liu, QQ; Fan, ZX; Liu, JJ; Wumaier, A","Self-Supervised Pre-Trained Speech Representation Based End-to-End Mispronunciation Detection and Diagnosis of Mandarin","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2022.3212417","","Mispronunciation Detection and Diagnosis (MDD) is an essential basic technology in Computer-Assisted Pronunciation Training (CAPT) and Computer-Assisted Language Learning (CALL). MDD research in Mandarin is faced with the problem of lack of relevant data, which is a typical low-resource scenario. In recent years, self-supervised pre-trained speech representation has developed rapidly and achieved significant performance improvement in low-resource speech recognition scenarios, making it necessary to be applied to MDD tasks. First, we build a Mandarin MDD dataset called PSC-Reading for the Putonghua Proficiency Test (PSC) passage reading section. Then we extended the end-to-end MDD system based on CTC/Attention hybrid architecture and Transformer architecture, using features extracted from self-supervised pre-training speech representation models such as Wav2Vec 2.0 and WavLM to replace conventional speech features like MFCC and Fbank, and conduct experiments on the PSC-Reading dataset. Experimental results show that, compared with the baseline model CNN-RNN-CTC, our WavLM-based model obtains 20.5% relative improvement on the F1 score metric.","2022","2025-02-26 20:39:19","2025-02-26 20:39:19","","106451-106462","","","10","","","","","","","","","","English","","","","WOS:000866458400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","CAPT; Computational modeling; Context modeling; Feature extraction; Hidden Markov models; MDD; self-supervised learning; Self-supervised learning; Speech recognition; Task analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6IW797FR","journalArticle","2025","Madan, S; Gahalawat, M; Guha, T; Goecke, R; Subramanian, R","Explainable human-centered traits from head motion and facial expression dynamics","PLOS ONE","","1932-6203","10.1371/journal.pone.0313883","","We explore the efficacy of multimodal behavioral cues for explainable prediction of personality and interview-specific traits. We utilize elementary head-motion units named kinemes, atomic facial movements termed action units and speech features to estimate these human-centered traits. Empirical results confirm that kinemes and action units enable discovery of multiple trait-specific behaviors while also enabling explainability in support of the predictions. For fusing cues, we explore decision and feature-level fusion, and an additive attention-based fusion strategy which quantifies the relative importance of the three modalities for trait prediction. Examining various long-short term memory (LSTM) architectures for classification and regression on the MIT Interview and First Impressions Candidate Screening (FICS) datasets, we note that: (1) Multimodal approaches outperform unimodal counterparts, achieving the highest PCC of 0.98 for Excited-Friendly traits in MIT and 0.57 for Extraversion in FICS; (2) Efficient trait predictions and plausible explanations are achieved with both unimodal and multimodal approaches, and (3) Following the thin-slice approach, effective trait prediction is achieved even from two-second behavioral snippets. Our implementation code is available at: https://github.com/deepsurbhi8/Explainable_Human_Traits_Prediction.","2025-01-17","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","1","20","","","","","","","","","","English","","","","WOS:001407853100046","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;77</p>","","","5-FACTOR MODEL; BEHAVIOR; INTERVIEW; PERFORMANCE; PERSONALITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I6L8ZL2P","journalArticle","2022","Wen, SJ; Wu, H; Yang, JH","Research on Voice-Driven Facial Expression Film and Television Animation Based on Compromised Node Detection in Wireless Sensor Networks","COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE","","1687-5265","10.1155/2022/8563818","","With the continuous development of social economy, film and television animation, as the spiritual needs of ordinary people, is more and more popular. Especially for the development of emerging technologies, the corresponding voice can be used to change AI expression. But at the same time, how to ensure the synchronization of language sound and facial expression is one of the difficulties in animation transformation. Relying on the compromised node detection of wireless sensor networks, this paper combs the synchronous traffic flow between the speech signals and facial expressions, finds the pattern distribution of facial motion based on unsupervised classification, realizes training and learning through neural networks, and realizes one-to-one mapping to facial expressions by using the rhyme distribution of speech features. It avoids the defect of robustness of speech recognition, improves the learning ability of speech recognition, and realizes the driving analysis of facial expression film and television animation. The simulation results show that the compromised node detection in wireless sensor networks is effective and can support the analysis and research of speech-driven facial expression film and television animation.","2022-01-24","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","2022","","","","","","","","","","English","","","","WOS:000783317100004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","IDENTITY; MODELS; RECOGNITION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DMANKDZA","journalArticle","2022","Su, N; Othman, R","Decomposition and Recognition of English Speech Features Based on Neutrosophic Set Fuzzy Control and Random Matrix Theory","MATHEMATICAL PROBLEMS IN ENGINEERING","","1024-123X","10.1155/2022/3879266","","In order to improve the effect of special decomposition and recognition of English speech, based on the idea of neutrosophic set fuzzy control, this paper uses Bayesian method as the basic algorithm of speech recognition to improve the algorithm in combination with English waveform characteristics. Moreover, this paper uses a semi-supervised learning method to process English speech waveform data, collects relevant data through the English speech input system, and then labels the data and obtains a new English speech data set through training and learning. In addition, this paper uses multiple iterations of labeling to obtain the ideal output data, uses neutrosophic set fuzzy control algorithms and machine learning algorithms to perform English speech feature decomposition and recognition, and uses feature parameter extraction methods to perform signal feature extraction. Finally, this article combines the needs of English speech recognition to build a system model and uses simulation tests to perform performance analysis of English speech feature decomposition and recognition model. The results of the research show that the improved algorithm and system model proposed in this paper have relatively good effects.","2022-06-29","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","2022","","","","","","","","","","English","","","","WOS:000831628700018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","MACHINE LEARNING-METHODS; MODELS; PREDICTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6YS3VSXY","journalArticle","2024","Mohn, JL; Baese-Berk, MM; Jaramillo, S","Selectivity to acoustic features of human speech in the auditory cortex of the mouse","HEARING RESEARCH","","0378-5955","10.1016/j.heares.2023.108920","","A better understanding of the neural mechanisms of speech processing can have a major impact in the development of strategies for language learning and in addressing disorders that affect speech comprehension. Technical limitations in research with human subjects hinder a comprehensive exploration of these processes, making animal models essential for advancing the characterization of how neural circuits make speech perception possible. Here, we investigated the mouse as a model organism for studying speech processing and explored whether distinct regions of the mouse auditory cortex are sensitive to specific acoustic features of speech. We found that mice can learn to categorize frequency-shifted human speech sounds based on differences in formant transitions (FT) and voice onset time (VOT). Moreover, neurons across various auditory cortical regions were selective to these speech features, with a higher proportion of speech-selective neurons in the dorso-posterior region. Last, many of these neurons displayed mixed-selectivity for both features, an attribute that was most common in dorsal regions of the auditory cortex. Our results demonstrate that the mouse serves as a valuable model for studying the detailed mechanisms of speech feature encoding and neural plasticity during speech-sound learning.","2024-01","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","441","","","","","","","","","","English","","","","WOS:001132090000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","REPRESENTATION; RESPONSES; SOUNDS; ULTRASONIC VOCALIZATIONS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YSP63QEX","journalArticle","2022","Alkomah, F; Salati, S; Ma, XG","A New Hate Speech Detection System based on Textual and Psychological Features","INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS","","2158-107X","","","Hate speech often spreads on social media and harms individuals and the community. Machine learning models have been proposed to detect hate speech in social media; however, several issues presently limit the performance of current approaches. One challenge is the issue of having diverse comprehensions of hate speech constructs which will lead to many speech categories and different interpretations. In addition, certain language-specific features, and short text issues, such as Twitter, exacerbate the problem. Moreover, current machine learning approaches lack universality due to small datasets and the adoption of a few features of hateful speech. This paper develops and builds new feature sets based on frequencies of textual tokens and psychological characteristics. Then, the study evaluates several machine learning methods over a large dataset. Results showed that the Random Forest and BERT methods are the most valuable for detecting hate speech content. Furthermore, the most dominant features that are helpful for hate speech detection methods combine psychological features and Term-Frequency Inverse Document-Frequency (TFIDF) features. Therefore, the proposed approach could identify hate speech on social media platforms like Twitter.","2022-06","2025-02-26 20:39:19","2025-02-26 20:39:19","","860-869","","8","13","","","","","","","","","","English","","","","WOS:000858436600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","hate speech classification; hate speech features; hate speech methods; identify speech platforms -Hate speech detection; SOCIAL MEDIA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LUCXX6FT","journalArticle","2021","Cenceschi, S; Meluzzi, C; Trivilini, A","The Variability of Vowels' Formants in Forensic Speech","IEEE INSTRUMENTATION & MEASUREMENT MAGAZINE","","1094-6969","10.1109/MIM.2021.9345600","","Speech analysis plays a pivotal role in the exploitation of forensic recordings in resolving a wide range of questions. Although this topic may include a large set of methodologies based on varied digital features (MFCC, Centroid, Harmonicity, VOT, etc., cf. [1]), this work approaches the theme from a phonetic perspective, taking into consideration the vowel formants, and focusing on their variability and difficulty of measurement. Formants correspond to the resonant frequencies of the vocal tract and are, therefore, sensible to specific speaker-related variations such as age and sex. In this respect, formants' variation contributes to characterizing the subjective timbre of the person. For this reason, formants' values are largely used in forensics [2], with all the practical problems that come with them, and in particular when dealing with speaker recognition or discrimination [3], [4]. Indeed, formants' values correspond to specific frequencies of the sound signal and are usually reported in Hertz. They are, however, affected by numerous internal and external variables, so that although on average they are characteristic of the individual speaker, they always vary within frequency bands that cannot be defined in absolute terms [5]. How, then, is it possible to provide reliable answers to forensic questions? In essence, it is up to the specialist to determine if there are the conditions to carry out an analysis, and to understand, for example, whether the differences between formants' values could be ascribed to two different speakers or the difference is too subtle to justify this claim. What should be measurable today, and must be defined at the level of jurisprudence, is therefore the professionalism of the expert. However, this is still heterogeneous in different countries, although several codes of practice such as the International Association for Forensic Phonetics or engineering society ones have been validated.","2021-02","2025-02-26 20:39:19","2025-02-26 20:39:19","","38-41","","1","24","","","","","","","","","","English","","","","WOS:000615033900007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;12</p>","","","Forensics; Phonetics; Resonant frequency; Speaker Recognition; Speech analysis; Timbre","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JQT4SPQJ","journalArticle","2024","Li, CT; Wan, Y; Yang, FR; Yang, J","Multi-scale Information Aggregation for Spoofing Detection","EURASIP JOURNAL ON AUDIO SPEECH AND MUSIC PROCESSING","","1687-4722","10.1186/s13636-024-00379-x","","Synthesis artifacts that span scales from small to large are important cues for spoofing detection. However, few spoofing detection models leverage artifacts across different scales together. In this paper, we propose a spoofing detection system built on SincNet and Deep Layer Aggregation (DLA), which leverages speech representations at different levels to distinguish synthetic speech. DLA is totally convolutional with an iterative tree-like structure. The unique topology of DLA makes possible compounding of speech features from convolution layers at different depths, and therefore the local and the global speech representations can be incorporated simultaneously. Moreover, SincNet is employed as the frontend feature extractor to circumvent manual feature extraction and selection. SincNet can learn fine-grained features directly from the input speech waveform, thus making the proposed spoofing detection system end-to-end. The proposed system outperforms the baselines when tested on ASVspoof LA and DF datasets. Notably, our single model surpasses all competing systems in ASVspoof DF competition with an equal error rate (EER) of 13.99%, which demonstrates the importance of multi-scale information aggregation for synthetic speech detection.","2024-11-05","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","1","2024","","","","","","","","","","English","","","","WOS:001350704400002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","Convolutional neural network; Deep fake detection; Deep learning; Information aggregation; SPEAKER RECOGNITION; Voice anti-spoofing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SGER7QEM","journalArticle","2024","Xu, XM","Improving Monaural Speech Enhancement by Mapping to Fixed Simulation Space With Knowledge Distillation","IEEE SIGNAL PROCESSING LETTERS","","1070-9908","10.1109/LSP.2024.3355746","","Monaural speech enhancement (SE) is a versatile and cost-effective approach that leverages recordings from a single microphone. However, it falls short of multi-channel SE due to the absence of spatial cues. These cues, present in multi-channel recordings, aid in distinguishing speech from noise more effectively. To bridge this gap, we introduce a method for mapping monaural speech into a fixed simulation space. Here, single-channel recordings are transformed into a predefined binaural format, enhancing the differentiation between target speech and noise components. This is achieved through knowledge distillation, enabling the monaural SE model to learn simulated binaural speech features from a pre-trained binaural SE model. It is important to note that we use a single type of binaural room impulse response and the monaural input of the student to simulate binaural speech. This way, our approach bypasses the paradox of generating virtual spatial information from monaural speech, while still benefiting from the spatial cues of binaural speech. Rigorous experiments demonstrate the effectiveness of our proposed method, showcasing its superior performance compared to recent monaural SE techniques in terms of PESQ and STOI scores.","2024","2025-02-26 20:39:19","2025-02-26 20:39:19","","386-390","","","31","","","","","","","","","","English","","","","WOS:001166563800003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","fixed binaural presentation; fixed simulation space; knowledge distillation; Monaural speech enhancement; NET; SEPARATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GUGHSAN7","journalArticle","2024","Yao, SS; Xiao, ZX; Niu, K","Rate-Distortion-Perception Optimized Neural Speech Transmission System for High-Fidelity Semantic Communications","SENSORS","","1424-8220","10.3390/s24103169","","We consider the problem of learned speech transmission. Existing methods have exploited joint source-channel coding (JSCC) to encode speech directly to transmitted symbols to improve the robustness over noisy channels. However, the fundamental limit of these methods is the failure of identification of content diversity across speech frames, leading to inefficient transmission. In this paper, we propose a novel neural speech transmission framework named NST. It can be optimized for superior rate-distortion-perception (RDP) performance toward the goal of high-fidelity semantic communication. Particularly, a learned entropy model assesses latent speech features to quantify the semantic content complexity, which facilitates the adaptive transmission rate allocation. NST enables a seamless integration of the source content with channel state information through variable-length joint source-channel coding, which maximizes the coding gain. Furthermore, we present a streaming variant of NST, which adopts causal coding based on sliding windows. Experimental results verify that NST outperforms existing speech transmission methods including separation-based and JSCC solutions in terms of RDP performance. Streaming NST achieves low-latency transmission with a slight quality degradation, which is tailored for real-time speech communication.","2024-05","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","10","24","","","","","","","","","","English","","","","WOS:001231409900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","joint source-channel coding; semantic communications; speech transmission","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7H86BYES","journalArticle","2023","Yang, H","Application of PNN-HMM Model Based on Emotion-Speech Combination in Broadcast Intelligent Communication Analysis","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3301127","","The emotive manifestation of a news anchor ought not to be arbitrary, but rather meticulously crafted and refined to elicit a more coherent emotional response. Hence, the identification of the appropriate emotional disposition during news broadcasts constitutes a meritorious domain of inquiry. To address concerns related to imprecise extraction of speech features and intricate detection of emotional states in broadcasting, this study presents an innovative Chinese pronunciation system predicated on speech recognition. The GA-SVM algorithm is employed to ascertain the endpoint of input Chinese speech signals and extract emotional feature parameters. For the recognition of the emotional temperament in broadcast speech, a PNN model is utilized to execute the decoding process of Viterbi in HMM. Experimental findings evince that the SVM optimized by GA attains a robust classification effect across diverse test samples. Moreover, the PNN-HMM model exhibits a noteworthy capacity to withstand noise during Chinese speech extraction, thereby enabling accurate discernment of the emotional characteristics of the speech under examination. Additionally, this research furnishes a valuable point of reference for the application of intelligent classification technology to audio information.","2023","2025-02-26 20:39:19","2025-02-26 20:39:19","","80854-80862","","","11","","","","","","","","","","English","","","","WOS:001045224500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","broadcasting and hosting; emotional classification; GA-SVM; PNN-HMM; RECOGNITION; speech feature","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GTHLJLJ5","journalArticle","2022","Raghu, K; Sadanandam, M","Emotion Recognition from Speech Utterances with Hybrid Spectral Features Using Machine Learning Algorithms","TRAITEMENT DU SIGNAL","","0765-0019","10.18280/ts.390222","","Speech Emotion Recognition is always a complicated task in the domain of Speech Processing Research, though many research works have been done. The first and foremost challenge of SER is to selecting the Speech Emotion Database (Corpora), then extracting the related speech features and finally construct an appropriate Classification model. An effort is created during this work to discover the speech prosodies, spectral and combination of features with their dynamism to illustrate and classify the emotions of speech signal. The intrinsic or fine variations of speech samples are combined with the static delivery parameters within the Speech Emotion Recognition (SER) to refine the accuracy. The work in this paper, carried out the experiments on RAVDESS, IIITH IIITH-TEMD and our developed Database of native language DETL (Database for Emotions in Telugu Language) Speech Emotion Databases. This work extracted features like MFCC and Hybrid Features (MFCC-F??MFCC-F????MFCC) then finally applied those individual features and Combination of Features to different Classification models like SVM and MLP. We have got approximately 75%, 78% and 81% of accuracy for MLP with hybrid combination features on the above Databases respectively.","2022-04","2025-02-26 20:39:19","2025-02-26 20:39:19","","603-609","","2","39","","","","","","","","","","English","","","","WOS:000798489300023","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;20</p>","","","feature extraction; MLP; NEURAL-NETWORK; SER; speech prosody; SVM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QVMY6YSF","journalArticle","2024","Leonard, MK; Gwilliams, L; Sellers, KK; Chung, JE; Xu, D; Mischler, G; Mesgarani, N; Welkenhuysen, M; Dutta, B; Chang, EF","Large-scale single-neuron speech sound encoding across the depth of human cortex","NATURE","","0028-0836","10.1038/s41586-023-06839-2","","Understanding the neural basis of speech perception requires that we study the human brain both at the scale of the fundamental computational unit of neurons and in their organization across the depth of cortex. Here we used high-density Neuropixels arrays(1-3) to record from 685 neurons across cortical layers at nine sites in a high-level auditory region that is critical for speech, the superior temporal gyrus(4,5), while participants listened to spoken sentences. Single neurons encoded a wide range of speech sound cues, including features of consonants and vowels, relative vocal pitch, onsets, amplitude envelope and sequence statistics. Neurons at each cross-laminar recording exhibited dominant tuning to a primary speech feature while also containing a substantial proportion of neurons that encoded other features contributing to heterogeneous selectivity. Spatially, neurons at similar cortical depths tended to encode similar speech features. Activity across all cortical layers was predictive of high-frequency field potentials (electrocorticography), providing a neuronal origin for macroelectrode recordings from the cortical surface. Together, these results establish single-neuron tuning across the cortical laminae as an important dimension of speech encoding in human superior temporal gyrus.","2024-02-15","2025-02-26 20:39:19","2025-02-26 20:39:19","","593-+","","7999","626","","","","","","","","","","English","","","","WOS:001163408400006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;25<br/>Total Times Cited:&nbsp;&nbsp;27<br/>Cited Reference Count:&nbsp;&nbsp;70</p>","","","AUDITORY-CORTEX; CAT; CELLS; COMPREHENSION; CONNECTIONS; FIELDS; LAMINAR; PERCEPTION; RESPONSES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3HHANPKV","journalArticle","2022","Hung, CH; Wang, SS; Wang, CT; Fang, SH","Using SincNet for Learning Pathological Voice Disorders","SENSORS","","1424-8220","10.3390/s22176634","","Deep learning techniques such as convolutional neural networks (CNN) have been successfully applied to identify pathological voices. However, the major disadvantage of using these advanced models is the lack of interpretability in explaining the predicted outcomes. This drawback further introduces a bottleneck for promoting the classification or detection of voice-disorder systems, especially in this pandemic period. In this paper, we proposed using a series of learnable sinc functions to replace the very first layer of a commonly used CNN to develop an explainable SincNet system for classifying or detecting pathological voices. The applied sinc filters, a front-end signal processor in SincNet, are critical for constructing the meaningful layer and are directly used to extract the acoustic features for following networks to generate high-level voice information. We conducted our tests on three different Far Eastern Memorial Hospital voice datasets. From our evaluations, the proposed approach achieves the highest 7%-accuracy and 9%-sensitivity improvements from conventional methods and thus demonstrates superior performance in predicting input pathological waveforms of the SincNet system. More importantly, we intended to give possible explanations between the system output and the first-layer extracted speech features based on our evaluated results.","2022-09","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","17","22","","","","","","","","","","English","","","","WOS:000851951900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","classification; convolutional neural network; pathological voice; sinc functions; SincNet","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S7BFMQGJ","journalArticle","2022","Kwon, HJ; Kim, MJ; Baek, JW; Chung, K","Voice Frequency Synthesis using VAW- GAN based Amplitude Scaling for Emotion Transformation","KSII TRANSACTIONS ON INTERNET AND INFORMATION SYSTEMS","","1976-7277","10.3837/tiis.2022.02.018","","Mostly, artificial intelligence does not show any definite change in emotions. For this reason, it is hard to demonstrate empathy in communication with humans. If frequency modification is applied to neutral emotions, or if a different emotional frequency is added to them, it is possible to develop artificial intelligence with emotions. This study proposes the emotion conversion using the Generative Adversarial Network (GAN) based voice frequency synthesis. The proposed method extracts a frequency from speech data of twenty-four actors and actresses. In other words, it extracts voice features of their different emotions, preserves linguistic features, and converts emotions only. After that, it generates a frequency in variational auto-encoding Wasserstein generative adversarial network (VAW-GAN) in order to make prosody and preserve linguistic information. That makes it possible to learn speech features in parallel. Finally, it corrects a frequency by employing Amplitude Scaling. With the use of the spectral conversion of logarithmic scale, it is converted into a frequency in consideration of human hearing features. Accordingly, the proposed technique provides the emotion conversion of speeches in order to express emotions in line with artificially generated voices or speeches.","2022-02-28","2025-02-26 20:39:19","2025-02-26 20:39:19","","713-725","","2","16","","","","","","","","","","English","","","","WOS:000767305400018","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","Emotion Transformation; Generative Adversarial Network; MODEL; Voice Analysis; Voice Frequency Synthesis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RF2NR6FY","journalArticle","2021","Inceoglu, S","Exploring the relationship between explicit instruction, pronunciation awareness, and the development of L2 French connected speech processes","LANGUAGE AWARENESS","","0965-8416","10.1080/09658416.2021.1881527","","The general consensus in second language (L2) acquisition research that instruction facilitates L2 development has been confirmed in a growing number of meta-analyses and research syntheses conducted in an increasingly wide range of L2 areas, including, recently, pronunciation instruction. Yet, little research has been done on the psycholinguistics aspects and ongoing processes of pronunciation learning. The present study examines the relationship between explicit instruction, learners' pronunciation awareness, and the development of enchainements and liaisons (i.e. measures of connected speech) in L2 French. Thirty learners of French enrolled in a 12-week pronunciation and phonetics course submitted five oral recordings of reading passages. These were collected bi-weekly and analyzed in relation to learners' reflective journal entries that were submitted a week before and a week after each recording. Findings showed a significant improvement in the production of connected speech features, and the results of binomial mixed effects models revealed an effect of pronunciation (self-)awareness on pronunciation change. Pedagogical implications of self-reflective journals and limitations to this approach are discussed.","2021-10-02","2025-02-26 20:39:19","2025-02-26 20:39:19","","336-354","","4","30","","","","","","","","","","English","","","","WOS:000616926200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","explicit instruction; L2 French learner; L2 pronunciation development; noticing; Pronunciation awareness; self-reflective journal","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W5IJABMG","journalArticle","2024","Fradi, A; Daoudi, K","Reduced-rank spectral mixtures Gaussian processes for probabilistic time-frequency representations","SIGNAL PROCESSING","","0165-1684","10.1016/j.sigpro.2023.109355","","Deterministic time-frequency representations are commonly used in signal processing, particularly in audio processing. Whilst presenting many potential advantages, their probabilistic counterparts are not widely used, essentially because of the computational load and the lack of clear interpretability of the different underlying models. However, using state space models, they have been shown recently to be equivalent to Spectral Mixtures Gaussian processes (SM-GP). This pioneer work unlocks this problem and opens the path for the development of tractable and interpretable probabilistic time-frequency analysis. In this paper, we propose a relatively simple yet a significant improvement of that work in terms of computational complexity, flexibility and practical application. To do so, we use a recent approach for covariance approximation to develop an algorithm for faster inference of SM-GP, while opting for a frequency -domain approach to hyperparameter learning. We illustrate the practical potential of our method using voiced speech data. We first show that key speech features can be accurately learned from the data. Second, we show that our method can yield better performances in denoising.","2024-05","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","218","","","","","","","","","","English","","","","WOS:001164015300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","Gaussian process; Probabilistic filter banks; Probabilistic time-frequency analysis; Reduced-rank covariances; Spectral mixtures Gaussian process","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NCITB5PW","journalArticle","2023","Kim, ES; Shin, DJ; Cho, ST; Chung, KJ","Artificial Intelligence-Based Speech Analysis System for Medical Support","INTERNATIONAL NEUROUROLOGY JOURNAL","","2093-4777","10.5213/inj.2346136.068","","Purpose: Prior research has indicated that stroke can influence the symptoms and presentation of neurogenic bladder, with various patterns emerging, including abnormal facial and linguistic characteristics. Language patterns, in particular, can be easily recognized. In this paper, we propose a platform that accurately analyzes the voices of stroke patients with neurogenic bladder, enabling early detection and prevention of the condition.Methods: In this study, we developed an artificial intelligence-based speech analysis diagnostic system to assess the risk of stroke associated with neurogenic bladder disease in elderly individuals. The proposed method involves recording the voice of a stroke patient while they speak a specific sentence, analyzing it to extract unique feature data, and then offering a voice alarm service through a mobile application. The system processes and classifies abnormalities, and issues alarm events based on analyzed voice data.Results: In order to assess the performance of the software, we first obtained the validation accuracy and training accuracy from the training data. Subsequently, we applied the analysis model by inputting both abnormal and normal data and tested the out-comes. The analysis model was evaluated by processing 30 abnormal data points and 30 normal data points in real time. The re-sults demonstrated a high test accuracy of 98.7% for normal data and 99.6% for abnormal data.Conclusions: Patients with neurogenic bladder due to stroke experience long-term consequences, such as physical and cogni-tive impairments, even when they receive prompt medical attention and treatment. As chronic diseases become increasingly prevalent in our aging society, it is essential to investigate digital treatments for conditions like stroke that lead to significant se-quelae. This artificial intelligence-based healthcare convergence medical device aims to provide patients with timely and safe medical care through mobile services, ultimately reducing national social costs.","2023-06","2025-02-26 20:39:19","2025-02-26 20:39:19","","99-105","","2","27","","","","","","","","","","English","","","","WOS:001032339000004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","Deep learning; Diagnosis support system; Neurogenic bladder; Speech recognition; Stroke; STROKE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D84B7SBN","journalArticle","2023","Zhang, HJ; Chen, YH; Zhuo, HK","Unit middleware for implementation of human-machine interconnection intelligent ecology construction","JOURNAL OF BIG DATA","","2196-1115","10.1186/s40537-023-00787-4","","General speech recognition models require large capacity and strong computing power. Based on small capacity and low computing power to realize speech analysis and semantic recognition is a research area with great challenges for constructing intelligent ecology of the Internet of Things. For this purpose, we set up the unit middleware for the implementation of human-machine interconnection, namely human-machine interaction based on phonetics and semantics control for constructing intelligent ecology of the Internet of Things. First, through calculation, theoretical derivation and verification we present a kind of novel deep hybrid intelligent algorithm, which has realized speech analysis and semantic recognition. Second, it is to establish unit middleware using the embedded chip as the core on the motherboard. Third, it is to develop the important auxiliary tools writer-burner and cross-compiler. Fourth, it is to prune procedures and system, download, burn and write the algorithms and codes into the unit middleware and cross-compile. Fifth, it is to expand the functions of the motherboard, provide more components and interfaces, for example including RFID(Radio Frequency Identification, RFID), ZigBee, Wi-Fi, GPRS(General Packet Radio Services, GPRS), RS-232 serial port, USB(Universal Serial Bus, USB) interfaces and so on. Sixth, we take advantage of algorithms, software and hardware to make machines ""understand"" human speech and ""think"" and ""comprehend"" human intentions so as to implement human-machine interconnection, which further structure the intelligent ecology of the Internet of Things. At last, the experimental results denote that the unit middleware have very good effect, fast recognition speed, high accuracy and good stability, consequently realizing the intelligent ecology construction of the Internet of Things.","2023-06-21","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","1","10","","","","","","","","","","English","","","","WOS:001012431500002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","ACCESS; DEEP; Deep belief network; Deep bidirectional long short term memory network; Deep hybrid neural networks; Embedded and internet of things; Intelligent ecology construction; INTERNET; NEURAL-NETWORKS; SPEECH; Speech recognition semantic control; VEHICLES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WAP5B87M","journalArticle","2023","Scimeca, S; Amato, F; Olmo, G; Asci, F; Suppa, A; Costantini, G; Saggio, G","Robust and language-independent acoustic features in Parkinson's disease","FRONTIERS IN NEUROLOGY","","1664-2295","10.3389/fneur.2023.1198058","","IntroductionThe analysis of vocal samples from patients with Parkinson's disease (PDP) can be relevant in supporting early diagnosis and disease monitoring. Intriguingly, speech analysis embeds several complexities influenced by speaker characteristics (e.g., gender and language) and recording conditions (e.g., professional microphones or smartphones, supervised, or non-supervised data collection). Moreover, the set of vocal tasks performed, such as sustained phonation, reading text, or monologue, strongly affects the speech dimension investigated, the feature extracted, and, as a consequence, the performance of the overall algorithm. MethodsWe employed six datasets, including a cohort of 176 Healthy Control (HC) participants and 178 PDP from different nationalities (i.e., Italian, Spanish, Czech), recorded in variable scenarios through various devices (i.e., professional microphones and smartphones), and performing several speech exercises (i.e., vowel phonation, sentence repetition). Aiming to identify the effectiveness of different vocal tasks and the trustworthiness of features independent of external co-factors such as language, gender, and data collection modality, we performed several intra- and inter-corpora statistical analyses. In addition, we compared the performance of different feature selection and classification models to evaluate the most robust and performing pipeline. ResultsAccording to our results, the combined use of sustained phonation and sentence repetition should be preferred over a single exercise. As for the set of features, the Mel Frequency Cepstral Coefficients demonstrated to be among the most effective parameters in discriminating between HC and PDP, also in the presence of heterogeneous languages and acquisition techniques. ConclusionEven though preliminary, the results of this work can be exploited to define a speech protocol that can effectively capture vocal alterations while minimizing the effort required to the patient. Moreover, the statistical analysis identified a set of features minimally dependent on gender, language, and recording modalities. This discloses the feasibility of extensive cross-corpora tests to develop robust and reliable tools for disease monitoring and staging and PDP follow-up.","2023-06-13","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","14","","","","","","","","","","English","","","","WOS:001016965100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","acoustic features; CLASSIFICATION; DIAGNOSIS; machine learning; Parkinson's disease; speech analysis; statistical analysis; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M25X67JC","journalArticle","2023","Lan, G; Fadeev, AS","Method of Modeling and Harmonic Synthesis of Phonemes of Human Speech with Emotional Coloring","AUTOMATIC DOCUMENTATION AND MATHEMATICAL LINGUISTICS","","0005-1055","10.3103/S0005105523040040","","Text-to-speech synthesis technology is one of the most important elements in the field of working with human speech. This paper makes an introductory analysis of speaker's speech sets recorded with different emotional coloration. That enables the identification of patterns in the frequency dynamics of harmonics and the development of a method for the analytical description of the emotional coloration of speech. We propose a model that describes changes in frequency in the vowels and phonemes pronounced with an emotional connotation. The model is based on the use of sigmoid functions and the results of a technique that allows the synthesis of the signal of emotionally colored phonemes.","2023-08","2025-02-26 20:39:19","2025-02-26 20:39:19","","219-227","","4","57","","","","","","","","","","English","","","","WOS:001105052600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","emotional coloring of speech; harmonic; phoneme; sigmoid function; speech analysis; speech synthesis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"INMPFM7H","journalArticle","2025","Amjad, H; Sekhon, VK; Wolff, JL; Samus, QM; Roth, DL","Hospitalization outcomes among older adults living undiagnosed or unaware of dementia","ALZHEIMER'S & DEMENTIA: DIAGNOSIS, ASSESSMENT & DISEASE MONITORING","","2352-8729","10.1002/dad2.70051","","INTRODUCTIONMany persons with dementia are undiagnosed or unaware of dementia, which may affect hospitalization outcomes.METHODSWe evaluated differences in length of stay, days not at home, discharge destination, and 30-day readmissions over 1 year in 6296 older adults in the National Health and Aging Trends Study with linked Medicare claims. Multivariable-adjusted models compared outcomes across no dementia, undiagnosed dementia, unaware but diagnosed with dementia, and aware and diagnosed with dementia.RESULTSPersons with undiagnosed dementia had longer length of stay and were more likely to be discharged to a facility (44.8% vs. 19.3%) compared to no dementia; differences persisted in multivariable models. Persons undiagnosed or unaware experienced outcomes similar to persons aware and diagnosed except for more 30-day readmissions in the undiagnosed (adjusted odds ratio [95% confidence interval] 2.05 [1.01, 4.16]).DISCUSSIONPersons undiagnosed or unaware of dementia experience worse hospitalization outcomes, suggesting potential clinically significant implications of unrecognized dementia.Highlights Persons with undiagnosed versus no dementia have worse hospitalization outcomes. Persons with undiagnosed dementia have more 30-day readmissions compared to persons diagnosed. Lack of clinician or family recognition of dementia may adversely affect hospitalization outcomes.","2025-01","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","1","17","","","","","","","","","","English","","","","WOS:001396965600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","ASSOCIATION; COGNITIVE IMPAIRMENT; COHORT; COST; dementia awareness; dementia detection; DIAGNOSIS; HEALTH; health services use; hospitalization outcomes; ILLNESS; INFORMANT INTERVIEW; PRIMARY-CARE; RISK; undiagnosed dementia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9XBDUIHB","journalArticle","2024","Agmon, G; Pradhan, S; Ash, S; Nevler, N; Liberman, M; Grossman, M; Cho, SHY","Automated Measures of Syntactic Complexity in Natural Speech Production: Older and Younger Adults as a Case Study","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2023_JSLHR-23-00009","","Purpose: Multiple methods have been suggested for quantifying syntactic complexity in speech. We compared eight automated syntactic complexity metrics to determine which best captured verified syntactic differences between old and young adults. Method: We used natural speech samples produced in a picture description task by younger (n = 76, ages 18-22 years) and older (n = 36, ages 53-89 years) healthy participants, manually transcribed and segmented into sentences. We manually verified that older participants produced fewer complex structures. We developed a metric of syntactic complexity using automatically extracted syntactic structures as features in a multidimensional metric. We compared our metric to seven other metrics: Yngve score, Frazier score, Frazier-Roark score, developmental level, syntactic frequency, mean dependency distance, and sentence length. We examined the success of each metric in identifying the age group using logistic regression models. We repeated the analysis with automatic transcription and segmentation using an automatic speech recognition (ASR) system. Results: Our multidimensional metric was successful in predicting age group (area under the curve [AUC] = 0.87), and it performed better than the other metrics. High AUCs were also achieved by the Yngve score (0.84) and sentence length (0.84). However, in a fully automated pipeline with ASR, the performance of these two metrics dropped (to 0.73 and 0.46, respectively), while the performance of the multidimensional metric remained relatively high (0.81). Conclusions: Syntactic complexity in spontaneous speech can be quantified by directly assessing syntactic structures and considering them in a multivariable manner. It can be derived automatically, saving considerable time and effort compared to manually analyzing large-scale corpora, while maintaining high face validity and robustness.","2024-02","2025-02-26 20:39:19","2025-02-26 20:39:19","","545-561","","2","67","","","","","","","","","","English","","","","WOS:001208295700009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;136</p>","","","AGE; AGRAMMATISM; DEPENDENCY DISTANCE; Editor: John Sabatini; FMRI; INDEX; LANGUAGE COMPREHENSION; NEURAL BASIS; PATTERNS; PERSPECTIVE; SENTENCE COMPREHENSION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WHX4IWVA","journalArticle","2024","Hutchins, TL; Knox, SE; Fletcher, EC","Natural language acquisition and gestalt language processing: A critical analysis of their application to autism and speech language therapy","AUTISM & DEVELOPMENTAL LANGUAGE IMPAIRMENTS","","2396-9415","10.1177/23969415241249944","","Background and Aim: Recently, there has been a lot of interest surrounding the term gestalt language processor (GLP) which is associated with Natural Language Acquisition (NLA): a protocol intended to support the language development of autistic people. In NLA, delayed echolalia is presumed raw source material that GLPs use to acquire language in a stage-like progression from delayed echolalia to spontaneous speech. The aim of this article is to evaluate NLA in light of relevant literatures to allow scrutiny of NLA claims. Main contributions: First, we review the notion of gestalt language and situate it in the broader literature on language styles to update understanding of its significance. We then review the links from gestalt language processing to autism and identify definitional and conceptual problems and clarify the construct 'episodic memory'. We discuss the 'raw material view of delayed echolalia' and identify theoretical and empirical shortcomings. Finally, we review Blanc's language stages and their accompanying assessment and language support recommendations and challenge their validity. Conclusions & Implications: The term 'gestalt language processor' is definitionally and conceptually troubled, the assertion that autistic people are GLPs is misleading and unhelpful, and evidence is lacking that GLP represents a legitimate clinical entity. The theoretical basis of NLA lacks empirical support. NLA stages are implausible and their accompanying assessment and support recommendations lack justification. We recommend the use of alternate, individualized, theoretically-sound, evidence-based, neurodiversity-affirming supports that are sensitive and responsive to the heterogeneity that defines autism.","2024","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","9","","","","","","","","","","English","","","","WOS:001229555100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;154</p>","","","Autism spectrum disorders; COMMUNICATION; DELAYED ECHOLALIA; FORMULAIC LANGUAGE; gestalt language; GRAMMAR; INDIVIDUAL-DIFFERENCES; INTERACTIONAL RESOURCE; language impairment /disorder; MEMORY; PARENT VERBAL RESPONSIVENESS; SPECTRUM DISORDERS; speech and language therapy; YOUNG-CHILDREN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VV6IRBM5","journalArticle","2023","Dashti, F; Asadi, M; Yadegari, F","Morphosemantic treatment of inflection of verb tense in Persian-speaking aphasic patients with agrammatism: a single-subject study","APHASIOLOGY","","0268-7038","10.1080/02687038.2021.2010272","","Background The production of verb inflection, especially tense marking, is commonly impaired in persons with agrammatic aphasia. In Persian, verbs are inflected in three tenses the past, present, and future, and play a key role in the sentence.A group of theories attributes verb inflection errors to syntactic or semantic deficits in sentence formulation. Aims The present study intends to investigate the effect of morphosemantic treatment on the inflection of regular and irregular verbs in the past, present, and future tenses in Persian-speaking agrammatic participants. Methods & Procedure A single-subject study with an ABA design was performed to evaluate the effect of morphosemantic treatment on four Persian-speaking agrammatic participants. In the current study, in addition to presenting descriptive statistics and visual analysis, percent of non-overlapping data (PND) was used to determine whether there was an effect of intervention during the treatment phase, and d1 statistics of effect size analysis was used to determine whether there was a maintenance effect during the withdrawal phase. Outcomes & Results All participants demonstrated significant improvement in the trained regular and irregular tenses and generalized to the production of tense morphology on untrained regular and irregular verbs. The effect of therapy was maintained for a three-week follow-up. Also, the morphosemantic intervention was associated with an increase in most narrative measures and language tests scores. Conclusions Therapy for verb inflection in spontaneous speech is clinically important. The current study demonstrated that morphosemantic intervention could be successfully used for tense marker deficits in Persian-speaking participants with aphasia and agrammatism.","2023-02-01","2025-02-26 20:39:19","2025-02-26 20:39:19","","288-306","","2","37","","","","","","","","","","English","","","","WOS:000724704500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","agrammatism; AGREEMENT; Aphasia; BRAIN; BROCAS; COMPREHENSION; EFFICACY; NOUNS; RETRIEVAL; single-subject design; treatment efficacy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7H95U4DS","journalArticle","2023","Clementz, BA; Chattopadhyay, I; Trotti, RL; Parker, DA; Gershon, ES; Hill, SK; Ivleva, EI; Keedy, SK; Keshavan, MS; Mcdowell, JE; Pearlson, GD; Tamminga, CA; Gibbons, RD","Clinical characterization and differentiation of B-SNIP psychosis Biotypes: Algorithmic Diagnostics for Efficient Prescription of Treatments (ADEPT)-1","SCHIZOPHRENIA RESEARCH","","0920-9964","10.1016/j.schres.2023.08.006","","Clinically defined psychosis diagnoses are neurobiologically heterogeneous. The B-SNIP consortium identified and validated more neurobiologically homogeneous psychosis Biotypes using an extensive battery of neurocognitive and psychophysiological laboratory measures. However, typically the first step in any diagnostic evaluation is the clinical interview. In this project, we evaluated if psychosis Biotypes have clinical characteristics that can support their differentiation in addition to obtaining laboratory testing. Clinical interview data from 1907 individuals with a psychosis Biotype were used to create a diagnostic algorithm. The features were 58 ratings from standard clinical scales. Extremely randomized tree algorithms were used to evaluate sensitivity, specificity, and overall classification success. Biotype classification accuracy peaked at 91 % with the use of 57 items on average. A reduced feature set of 28 items, though, also showed 81 % classification accuracy. Using this reduced item set, we found that only 10-11 items achieved a one-vs-all (Biotype-1 or not, Biotype-2 or not, Biotype-3 or not) area under the sensitivity-specificity curve of .78 to .81. The top clinical characteristics for differentiating psychosis Biotypes, in order of importance, were (i) difficulty in abstract thinking, (ii) multiple indicators of social functioning, (iii) conceptual disorganization, (iv) severity of hallucinations, (v) stereotyped thinking, (vi) suspiciousness, (vii) unusual thought content, (viii) lack of spontaneous speech, and (ix) severity of delusions. These features were remarkably different from those that differentiated DSM psychosis diagnoses. This low-burden adaptive algorithm achieved reasonable classification accuracy and will support Biotype-specific etiological and treatment investigations even in under-resourced clinical and research environments.","2023-10","2025-02-26 20:39:19","2025-02-26 20:39:19","","143-151","","","260","","","","","","","","","","English","","","","WOS:001106835200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","BIOMARKERS; BIPOLAR-SCHIZOPHRENIA NETWORK; BRAIN; FAMILIALITY; INHIBITORY CONTROL; INTERMEDIATE PHENOTYPES; PROGRESS; RELIABILITY; SCALE; SPECIFICITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TCKDVSIA","journalArticle","2023","Kissel, I; Papeleu, T; Verbeke, J; Van Lierde, K; Meerschman, I; D'haeseleer, E","Immediate effects of a semi-occluded water-resistance ventilation mask on vocal outcomes in women with dysphonia","JOURNAL OF COMMUNICATION DISORDERS","","0021-9924","10.1016/j.jcomdis.2023.106331","","Introduction: Semi-occluded vocal tract exercises (SOVTEs) are frequently used exercises in voice therapy. An important shortcoming to most SOVTEs is the inability to include continuous speech in these exercises. A variation of water-resistance therapy (WRT), during which a patient phonates through a resonance tube ending in water, was developed to include continuous speech: the semi-occluded water resistance ventilation mask (SOVM-WR). The current study investigated the immediate effects of this innovative technique on vocal outcomes of women with dysphonia.Methods: A pretest-posttest randomized controlled trial was performed. Twenty female participants were randomly assigned to the experimental SOVM-WR group or the WRT (control) group. A blinded multidimensional voice assessment was conducted before and after a 30-minute therapy session with the assigned technique.Results: No significant changes were found in acoustic or auditory-perceptual vocal outcomes in either of the groups, except for a significant increase in lowest frequency in both groups. Patientreported outcomes (PROMs) showed significant improvements of vocal comfort, vocal effort, and voice quality in both groups, and participants indicated that they would use the techniques at home.Conclusions: The similar results of the SOVM-WR to WRT and promising PROMs confirm its suitability as an alternative to the latter technique. Potential reasons for a lack of improvement of objective and auditory-perceptual vocal outcomes are vocal fatigue, tube dimensions and immersion, and the small sample size. Large-scale and longitudinal research is needed to examine whether the SOVM-WR has a higher transfer to spontaneous speech than WRT after a full therapy program.","2023-05","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","103","","","","","","","","","","English","","","","WOS:000988144300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","Dysphonia; EXERCISES; INDEX; LIP-TRILL; mask; PHONATION; QUALITY-OF-LIFE; RESONANCE TUBE; Semi -occluded water -resistance ventilation; SOVT; STRAW; TRACT; Voice therapy; VOICE THERAPY; Water -resistance therapy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TL5R8SGA","journalArticle","2022","Ransmayr, L; Fuchs, A; Ransmayr-Tepser, S; Kommenda, R; Kögl, M; Schwingenschuh, P; Fellner, F; Guger, M; Eggers, C; Darkow, R; Mangesius, S; Ransmayr, G","Differences in aphasia syndromes between progressive supranuclear palsy-Richardson's syndrome, behavioral variant frontotemporal dementia and Alzheimer's dementia","JOURNAL OF NEURAL TRANSMISSION","","0300-9564","10.1007/s00702-022-02524-2","","Language impairments, hallmarks of speech/language variant progressive supranuclear palsy, also occur in Richardson's syndrome (PSP-RS). Impaired communication may interfere with daily activities. Therefore, assessment of language functions is crucial. It is uncertain whether the Aachen Aphasia Test (AAT) is practicable in PSP-RS, behavioral variant frontotemporal dementia (bvFTD) and Alzheimer's dementia (AD) and language deficits differ in these disorders. 28 PSP-RS, 24 AD, and 24 bvFTD patients were investigated using the AAT and the CERAD-Plus battery. 16-25% of all patients failed in AAT subtests for various reasons. The AAT syndrome algorithm diagnosed amnestic aphasia in 5 (23%) PSP-RS, 7 (36%) bvFTD and 6 (30%) AD patients, Broca aphasia in 1 PSP-RS and 1 bvFTD patient, Wernicke aphasia in 1 bvFTD and 3 (15%) AD patients. However, aphasic symptoms resembled non-fluent primary progressive aphasia in 14 PSP-RS patients. In up to 46% of PSP-RS patients, 61% of bvFTD and 64% of AD patients significant impairments were found in the AAT subtests spontaneous speech, written language, naming, language repetition, language comprehension and the Token subtest. The CERAD-Plus subtest semantic fluency revealed significant impairment in 81% of PSP-RS, 61% of bvFTD, 44% of AD patients, the phonemic fluency subtest in 31, 40 and 31%, respectively. In contrast to bvFTD and AD, severity of language impairment did not correlate with cognitive decline in PSP-RS. In summary, the patterns of aphasia differ between the diagnoses. Local frontal language networks might be impaired in PSP-RS, whereas in AD and bvFTD, more widespread neuropathology might underly language impairment.","2022-08","2025-02-26 20:39:19","2025-02-26 20:39:19","","1039-1048","","8","129","","","","","","","","","","English","","","","WOS:000823317700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;41</p>","","","ACCURACY; Alzheimer's dementia; Behavioral variant frontotemporal dementia; Cognitive impairment; CRITERIA; DIAGNOSIS; DISEASE; LANGUAGE; Non-fluent agrammatic primary progressive aphasia; Progressive supranuclear palsy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6NZY3PD8","journalArticle","2022","Corps, RE; Knudsen, B; Meyer, AS","Overrated gaps: Inter-speaker gaps provide limited information about the timing of turns in conversation","COGNITION","","0010-0277","10.1016/j.cognition.2022.105037","","Corpus analyses have shown that turn-taking in conversation is much faster than laboratory studies of speech planning would predict. To explain fast turn-taking, Levinson and Torreira (2015) proposed that speakers are highly proactive: They begin to plan a response to their interlocutor's turn as soon as they have understood its gist, and launch this planned response when the turn-end is imminent. Thus, fast turn-taking is possible because speakers use the time while their partner is talking to plan their own utterance. In the present study, we asked how much time upcoming speakers actually have to plan their utterances. Following earlier psycholinguistic work, we used transcripts of spoken conversations in Dutch, German, and English. These transcripts consisted of segments, which are continuous stretches of speech by one speaker. In the psycholinguistic and phonetic liter-ature, such segments have often been used as proxies for turns. We found that in all three corpora, large pro-portions of the segments comprised of only one or two words, which on our estimate does not give the next speaker enough time to fully plan a response. Further analyses showed that speakers indeed often did not respond to the immediately preceding segment of their partner, but continued an earlier segment of their own. More generally, our findings suggest that speech segments derived from transcribed corpora do not necessarily correspond to turns, and the gaps between speech segments therefore only provide limited information about the planning and timing of turns.","2022-06","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","223","","","","","","","","","","English","","","","WOS:000793732500011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;92</p>","","","ADDRESSEE BACKCHANNELS; BETWEEN-SPEAKER; COMPETITION; Conversation; Corpus analysis; DIALOGUE; Gaps; INITIATION; LANGUAGE; ORGANIZATION; PREDICTION; REPAIR; Speech production; SPONTANEOUS SPEECH; Turn-taking","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QZ8DU76K","journalArticle","2023","Mark, H; Lilja, J; Havstam, C","Long-term longitudinal follow-up of individuals with UCLP after Gothenburg two-stage palate closure: surgical and speech outcomes","JOURNAL OF PLASTIC SURGERY AND HAND SURGERY","","2000-656X","10.2340/jphs.v58.7317","","Background: Delayed hard palate closure in unilateral cleft lip and palate (UCLP) patients show on a safe surgical method and good speech outcome, however, occurrence of orally retracted articulation before hard palate closure at 8 years. The aim of this study was to describe surgical and speech outcome in UCLP patients closing the hard palate at 3 years. Methods: A consecutive of 28 participants were operated with Gothenburg two-stage method including soft palate closure at 6 months and hard palate at 3 years. Surgical and speech outcome were evaluated. Recordings of sentences and spontaneous speech at 5, 10, 16, and 19 years were analyzed blindly and independently by three speech-language pathologists. Compensatory articulation, hypernasality, hyponasality, weak pressure consonants, and nasal air leakage were evaluated on ordinal four-point and intelligibility and perceived velopharyngeal function on three-point scales. Results: Long-term follow-up revealed a safe surgical method. Articulation disorders were present in 25-30% at 5-year but largely not later. About 20% had incompetent velopharyngeal function at 5 years but none at 19 years. Most participants were well intelligible after 5 years. Hard palate closure at 3 years indicated less occurrence of orally retracted articulation compared with a cohort who had hard palate closure at 8.2 years. Conclusions: Long-term, follow-up of individuals with UCLP after Gothenburg two-stage palate closure including closure of the soft palate closure at 6 months and hard palate at 3 years of age shows a safe surgical method and indicates less retracted oral articulation compared with hard palate closure at 8 years.","2023","2025-02-26 20:39:19","2025-02-26 20:39:19","","19-25","","","58","","","","","","","","","","English","","","","WOS:001157817200005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","BORN; CHILDREN; Cleft; DIFFERENT DELAYS; HARD PALATE; INTERVENTIONS; Palatal repair; PRIMARY EARLY VELOPLASTY; PRIMARY SURGERY; Retracted articulation; SCANDCLEFT RANDOMIZED-TRIALS; Speech; STAGE; UNILATERAL CLEFT-LIP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2XKXB94B","journalArticle","2024","Oh, S; Park, H","The impact of native language on second language rhythm acquisition: Insights from a cross-linguistic and intra-language corpus study","LINGUISTIC RESEARCH","","1229-1374","10.17250/khisli.41.3.202412.003","","Linguistic Re search 41(3): 391-429. This study investigates how native language (L1) rhythm structure influences the acquisition of second language (L2) rhythm across 20 different languages and within a single language group. Utilizing diverse corpora of L1 and L2 speech samples from various languages, we explored the rhythmic patterns of syllable-timed (e.g., Korean) and stress-timed (e.g., English) language speakers. Our findings reveal that L2 learners from syllable-timed language backgrounds can achieve rhythm patterns similar to native English speakers, challenging the notion that L1 rhythm disparities inherently disadvantage learners. This supports the Speech Learning Model (SLM), suggesting that learners with rhythmically contrasting native languages may acquire L2 rhythm more effectively than those with similar rhythmic structures. Furthermore, we examined the effect of speech style (reading vs. spontaneous) on rhythm production. Native Korean speakers consistently exhibited higher durational variability in spontaneous speech compared to reading in both L1 and L2, contrary to expectations that educational focus would lead to increased variability in reading. This pattern underscores the potential influence of individual speech traits, suggesting that L1 rhythmic tendencies persist in L2 production. Our study highlights the need for further research into the interplay between L1 and L2 rhythm acquisition and the impact of speech style across diverse language backgrounds. This research contributes to understanding the broader applicability of the SLM and the role of speech style in rhythm production. (Soongsil University <middle dot> University of Wisconsin-Milwaukee)","2024","2025-02-26 20:39:19","2025-02-26 20:39:19","","391-429","","3","41","","","","","","","","","","English","","","","WOS:001391228100003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;61</p>","","","1ST; durational variability; ENGLISH; FOREIGN ACCENT; L2 acquisition; L2 ACQUISITION; LEARNERS; PVI; rhythm; SLM; SPEAKING RATE; SPEECH RHYTHM; speech style; STRESS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T4VI36MV","journalArticle","2023","Lyakso, E; Ruban, N; Frolova, O; Mekala, MA","The children's emotional speech recognition by adults: Cross-cultural study on Russian and Tamil language","PLOS ONE","","1932-6203","10.1371/journal.pone.0272837","","The current study investigated the features of cross-cultural recognition of four basic emotions ""joy-neutral (calm state)-sad-anger"" in the spontaneous and acting speech of Indian and Russian children aged 8-12 years across Russian and Tamil languages. The research tasks were to examine the ability of Russian and Indian experts to recognize the state of Russian and Indian children by their speech, determine the acoustic features of correctly recognized speech samples, and specify the influence of the expert's language on the cross-cultural recognition of the emotional states of children. The study includes a perceptual auditory study by listeners and instrumental spectrographic analysis of child speech. Different accuracy and agreement between Russian and Indian experts were shown in recognizing the emotional states of Indian and Russian children by their speech, with more accurate recognition of the emotional state of children in their native language, in acting speech vs spontaneous speech. Both groups of experts recognize the state of anger via acting speech with the high agreement. The difference between the groups of experts was in the definition of joy, sadness, and neutral states depending on the test material with a different agreement. Speech signals with emphasized differences in acoustic patterns were more accurately classified by experts as belonging to emotions of different activation. The data showed that, despite the universality of basic emotions, on the one hand, the cultural environment affects their expression and perception, on the other hand, there are universal non-linguistic acoustic features of the voice that allow us to identify emotions via speech.","2023-02-15","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","2","18","","","","","","","","","","English","","","","WOS:001056479600006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","FACIAL EXPRESSIONS; NONVERBAL DIALECTS; PROSODY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QU2Y2CXK","journalArticle","2022","Jungblut, M; Mais, C; Binkofski, FC; Schüppen, A","The efficacy of a directed rhythmic-melodic voice training in the treatment of chronic non-fluent aphasia-Behavioral and imaging results","JOURNAL OF NEUROLOGY","","0340-5354","10.1007/s00415-022-11163-2","","The main objective of this study was to investigate the efficacy of a directed rhythmic-melodic voice training (SIPARI) compared to language therapy with the focus on improvement in expressive linguistic performance. 20 patients suffering from chronic non-fluent aphasia, allocated by coin tossing to either of the groups, participated in 32 single therapy sessions over a period of 4 months. Before and after therapy, independent testers performed a standardized language test (Aachener Aphasie Test). Behavioral assessments revealed that improvements of patients of the experimental group were clinically significant compared to those of the control group. These improvements concerned the description level articulation and prosody for spontaneous speech and the subtests repetition, naming, and comprehension. Based on these improvements, a significant increase in profile level (effect size (ES) = 2.028, p < 0.001) was assessed, an overall and clinically relevant measure of the severity of aphasia. Additional fMRI examinations yielded activation in the left superior frontal gyrus for the post-minus pre- therapy assessments only for participants of the experimental group. Since this brain region is reported to be particularly involved in executive processing, we assume that the directed procedure of the SIPARI treatment with regard to musical, linguistic, and cognitive function potentially holds the key for successful language rehabilitation. While our imaging results hint at a possible explanation for its efficacy, our behavioral results corroborate the efficacy of this therapy in the treatment of chronic non-fluent aphasia patients. DRKS00026730, 19.10.21, retrospectively registered https://www.drks.de/drks_web/navigate.do?navigationId=trial.HTML&TRIAL _ID=DRKS00026730","2022-09","2025-02-26 20:39:19","2025-02-26 20:39:19","","5070-5084","","9","269","","","","","","","","","","English","","","","WOS:000799066900003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;83</p>","","","APRAXIA; BRAIN-DAMAGE; Chronic non-fluent aphasia; COMPREHENSION; Executive functions; fMRI; GLOBAL BURDEN; INDUCED RECOVERY; INTONATION THERAPY; LANGUAGE; Language therapy; Left superior frontal gyrus; PERCEPTION; SIPARI; SPEECH; WORKING-MEMORY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9AAGMTX4","journalArticle","2022","Karimian, F; Mohammadi, R; Bemani, Z; Kazemi, Y; Kianfar, F","Phonological Mean Length of Utterance in 48-60-Month-old Persian-Speaking Children With Isfahani Accent: Comparison of Story Generation","ARCHIVES OF REHABILITATION","","2538-6247","10.32598/RJ.23.3.3344.1","","Objective Phonological Mean Length of Utterance (PMLU), a quantitative measure for assessing phonologi-cal skills, is a diagnostic and clinical criterion in phonological development. Moreover, it is an indicator show-ing the efficacy of the intervention. The PMLU is a word level measure that can be calculated on the child's transcribed speech sample (transcription). To calculate PMLU, all consonants and vowels of the child's pro-duced words, and target words (standard production of words in native adults) are individually scored. The proportion of Whole-Word Proximity (PWP), another phonological quantitative measure, includes the ratio of the produced PMLU to the targeted word PMLU. PWP indirectly reflects the intelligibility of speech. Since languages are distinctive in syllabic and phonological structures, PMLU should be studied as a lan-guage-specific measure. PMLU has specifically been designed to assess phonological skills in spontaneous speech. Spontaneous speech sampling methods are advantageous since they consider the effect of mor-phological and syntactic skills, length, and complexity of words, and they could show the normal develop-ment of word complexity. This study was conducted to determine PMLU and PWP in 48 to 60 months old Persian-speaking children with Isfahani accents and to compare them in story generation and conversation sampling methods. The potential sensitivity of PMLU to growth was also examined. Materials & Methods This is an observational and cross-sectional study that was conducted for one year in 2016 in Isfahan City, Iran. A total of 100 children (51 boys and 49 girls) aged 48-60 months participated in story generation sampling, and 67 children (32 boys and 35 girls) participated in conversation sampling. The participants were selected from 261 kindergartens under the supervision of the Welfare Organization of Isfahan Province using the convenience sampling method. After completing the consent form and con-sidering the inclusion criteria, conversation and story-generation samples were collected. Audio samplings were done in the same room using the same software (Clear Record Litev. 2.1). Raters transcribed the first 50 words of the recorded speech samples. Finally, we used the formula to calculate the target PMLU and child PMLU based on the normal production of an adult who speaks Persian with an Isfahani accent and the child's production, respectively. To evaluate inter-rater reliability, raters randomly transcribed 20% of all samples to recalculate values. Participants' story generation and conversation scores were entered into SPSS16 separately. The Kolmogorov-Smirnov test was used to examine the data distribution. Based on the data distribution, paired t-test and Wilcoxon test were used to compare measurements, and the Pearson and Spearman tests were used to investigate the associations. Results Child PMLU, target PMLU, and PWP measures of the story generation method were 8.794, 8.811, 0.998, and those of the conversation method were 9.068, 9.093, and 0.998, respectively. Correlation test re-sults showed significant relationship between age and PWP in story generation (r=0.308) and conversation (r=0.313). Comparing child PMLU in story generation and conversation showed a significant relationship between child PMLU in both sampling methods (P=0.000). The result of the target PMLU comparison in two methods of story generation and conversation (P=0.000) was significant. PWP did not significantly differ between the two sampling methods (P=0.973). The inter-rater reliability was calculated at 0.70. Conclusion This study can be used as a basis for quantitative studies in the field of children's phonological assessment using Persian whole words. However, longitudinal studies in different age groups with a high level of evidence in this field can convince therapists to use whole-word measures in clinics.","2022","2025-02-26 20:39:19","2025-02-26 20:39:19","","392-411","","3","23","","","","","","","","","","English","","","","WOS:000892848100005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;23</p>","","","Conversation; CONVERSATION; Persian-speaking children with Isafahani accent; Phonological mean length of utterance; Phonological skill; Story generation; WHOLE-WORD MEASURES; Whole-word proximity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HCEBCETK","journalArticle","2025","Thipparthy, KR; Kollu, A; Kulkarni, C; Dutta, AK; Doshi, H; Kashyap, A; Sinha, KP; Kondaveeti, SB; Gupta, R","Discrete variational autoencoders BERT model-based transcranial focused ultrasound for Alzheimer's disease detection","JOURNAL OF NEUROSCIENCE METHODS","","0165-0270","10.1016/j.jneumeth.2025.110386","","Research background: Alzheimer's Disease (AD) is a neurodegenerative condition marked by symptoms including aphasia and diminished verbal fluency. Researchers have employed phonetic attributes, fluency, pauses, and various paralinguistic traits, or derived aspects from transcribed text, to identify Alzheimer's disease. Methods and methodology: Nevertheless, conventional acoustic feature-based detection techniques are constrained in their ability to capture semantic information, and the process of transcribing speech into text is both timeconsuming and labour-intensive. Non-invasive brain stimulation (NBS), encompassing methods such as trans- cranial magnetic stimulation (TMS) and Transcranial focused ultrasound (tFUS), has been investigated as a potential intervention to enhance cognitive functions and communication in Alzheimer's patients, demonstrating efficacy in modulating brain activity and promoting neuroplasticity. This research utilises Discrete Variational Autoencoders to transform speech into pseudo-phoneme sequences, subsequently applying the BERT (Bidirectional Encoder Representations from Transformers) model to analyse the relationships among these pseudo- phoneme sequences. This research proposes a tFUS-BERT model to encapsulate the linguistic representations of audio. Result analysis: The proposed tFUS-BERT model demonstrated its effectiveness with an accuracy of 76.06 % when combined with Wav2vec 2.0 and 71.83 % with Hu-BERT, outperforming the baseline by 5.63 % on the ADReSSo dataset. Additionally, the model exhibited superior performance in capturing linguistic representations compared to traditional acoustic methods, showcasing its potential for accurate and scalable Alzheimer's detection. Comparison with previous studies: The model attains an accuracy of 70.42 % on the ADReSSo (Alzheimer's Dementia Recognition through Spontaneous Speech Only) dataset, reflecting a 5.63 % enhancement compared to the baseline system.","2025-04","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","416","","","","","","","","","","English","","","","WOS:001423207700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Alzheimer's Neurodegenerative Condition; BERT Model; DECOMPOSITION; Discrete Variational Autoencoders; Non-invasive Brain Stimulation; SYSTEMS; Transcranial focused ultrasound","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9SY4XB7P","journalArticle","2023","Iwarsson, J; Naes, J; Hollen, R","Measuring speaking rate: how do objective measurements correlate with audio-perceptual ratings?","LOGOPEDICS PHONIATRICS VOCOLOGY","","1401-5439","10.1080/14015439.2021.1988702","","Objective Although speaking rate is central for many speech disorders, no consensus exists regarding the measurement of this feature. The purpose of this study was to examine the correlations between perceptual listener evaluations and various measures of speaking rate. Furthermore, the study investigated the relationship between speaking rate and articulation rate and how pauses in speech affect the perceived tempo. Method Nine healthy females were selected to produce stimuli representing three habitual speech tempi during semi-spontaneous speech: slow (n = 3), neutral (n = 3) and fast (n = 3). Speaking rate was analyzed both by manual calculation and through automatic detection by a script to the computer-based program Praat. Thirty untrained male and female listeners evaluated the recordings with regard to speech tempo on visual analogue scales from very slow to very fast. Results Large, significant correlations (Pearson's r) were found between all objective measures of speaking rate and perceptual listener evaluations. Words/minute showed the largest correlation (.91), followed by syllables/second (.89), while articulation rate (pauses excluded) as automatically measured by the script, showed the smallest correlation (.69). Possible explanations for the findings are discussed. Conclusion Untrained listeners' evaluation of speech tempo in normal subjects correlated strongly with objective measurements. The results both support the use of auditive-perceptual evaluation of tempo and the use of automatic script analysis for clinical use. Speaking rate (pauses included) showed better consistency with perceptual listener evaluations than articulation rate.","2023-04-03","2025-02-26 20:39:19","2025-02-26 20:39:19","","57-66","","2","48","","","","","","","","","","English","","","","WOS:000709707700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","AGE; BETWEEN-SPEAKER; CHILDREN; dysphonia assessment; INTERSPEAKER VARIATION; minute; motor speech disorders; perceptual ratings; second; second language acquisition; SOUND PRESSURE LEVEL; Speaking rate; SPEECH RATE; speech tempo; syllables; TEMPO; VOICE; voice analysis; words; YOUNG-ADULT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BB89KAJA","journalArticle","2023","Park, H; Obermeyer, J; Kornisch, M; Hall, J; Ontario, C","Semantic Aspects of Verb Production in Various Discourse Tasks in People With Nonfluent Aphasia","AMERICAN JOURNAL OF SPEECH-LANGUAGE PATHOLOGY","","1058-0360","10.1044/2023_AJSLP-22-00293","","Purpose: The purpose of this study was to investigate how people with non-fluent aphasia produce semantically weighted verbs compared to people without aphasia, as well as how a discourse elicitation task affects verb production in people with nonfluent aphasia and people without aphasia. Method: This study included 30 people with nonfluent aphasia and 32 age-matched people without aphasia from AphasiaBank. Language samples of five different discourse tasks were obtained and coded for heavy, light, and be-copular verbs. The number of verbs per utterance and the proportion of heavy, light, and be-copular verbs were compared between groups and between tasks. Results: People with nonfluent aphasia showed a similar proportion of heavy verbs but reduced verbs per utterance and proportion of light verbs compared to people without aphasia. With regard to discourse task effects, we found a trend for a higher proportion of heavy verbs in sequential picture descriptions, and a higher proportion of be-copular verbs and lower proportion of heavy verbs for a recount compared to other tasks in people without aphasia. The discourse task effects were minimally found in people with nonfluent aphasia. Conclusions: Our results suggest that people with nonfluent aphasia present with relatively preserved heavy verb production but with impaired production of light verbs in discourse. In addition, it appears that discourse tasks do not significantly influence the type of verbs produced by people with nonfluent aphasia possibly due to the floor effects and wide range of individual variability. This study is a preliminary effort to evaluate methodological factors that impact verb production; future studies are needed to develop a framework for clinical decision making when selecting a discourse elicitation task for people with aphasia.","2023-10","2025-02-26 20:39:19","2025-02-26 20:39:19","","2418-2429","","5","32","","","","","","","","","","English","","","","WOS:001087433600003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","ACCESS; ADULTS; AGE; DIVERSITY; NOUNS; PROCEDURAL DISCOURSE; REPETITION; RETRIEVAL; SPONTANEOUS SPEECH; WEIGHT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V3W7IZ8T","journalArticle","2023","Corona-Hernández, H; de Boer, JN; Brederoo, SG; Voppel, AE; Sommer, IEC","Assessing coherence through linguistic connectives: Analysis of speech in patients with schizophrenia-spectrum disorders","SCHIZOPHRENIA RESEARCH","","0920-9964","10.1016/j.schres.2022.06.013","","Background: Incoherent speech is a core diagnostic symptom of schizophrenia-spectrum disorders (SSD) that can be studied using semantic space models. Since linguistic connectives signal relations between words, they and their surrounding words might represent linguistic loci to detect unusual coherence in speech. Therefore, we investigated whether connectives' measures are useful to assess incoherent speech in SSD.Methods: Connectives and their surrounding words were extracted from transcripts of spontaneous speech of 50 SSD-patients and 50 control participants. Using word2vec, two different cosine similarities were calculated: those of connectives and their surrounding words (connectives-related similarity), and those of free-of-connectives words-chunks (non-connectives similarity). Differences between groups in proportion of five types of connectives were assessed using generalized logistic models, and connectives-related similarity was analyzed through non-parametric multivariate analysis of variance. These features were evaluated in classification tasks to differentiate between groups. Results: SSD-patients used less contingency (e.g., because) (p = .008) and multiclass connectives (e.g., as) (p < .001) than control participants. SSD-patients had higher minimum similarity of multiclass (adj-p = .04) and temporality connectives (e.g., after) (adj-p < .001), narrower similarity-range of expansion (e.g., and) (adj-p = .002) and multiclass connectives (adj-p = .04), and lower maximum similarity of expansion connectives (adj-p = .005). Using connectives' features alone, SSD-patients and controls could be distinguished with 85 % accuracy.Discussion: Our results show that SSD-speech can be distinguished from speech of control participants with high accuracy, based solely on connectives' features. We conclude that including connectives could strengthen computational models to categorize SSD.","2023-09","2025-02-26 20:39:19","2025-02-26 20:39:19","","48-58","","","259","","","","","","","","","","English","","","","WOS:001106779100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Classification; COMPLEXITY; Disorganized speech; DUTCH; FREQUENCY; Grammatical connectivity; LANGUAGE; NARRATIVES; PANSS; PSYCHOSIS; Schizophrenia-spectrum disorders; Semantic cosine similarity; Word2vec","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PB6LQ6IT","journalArticle","2023","Hogoboom, A; Rouch, M; Lauerman, D; Pauselli, L; Compton, MT","Initial evidence of vowel space reduction in a subset of individuals with schizophrenia","SCHIZOPHRENIA RESEARCH","","0920-9964","10.1016/j.schres.2023.03.026","","Objective: Acoustic phonetic measures have been found to correlate with negative symptoms of schizophrenia, thus offering a path toward quantitative measurement of such symptoms. These acoustic properties include F1 and F2 measurements (affected by tongue height and tongue forward/back position, respectively), which determine a general ""vowel space."" Among patients and controls, we consider two phonetic measures of vowel space: average Euclidean distance from a participant's mean F1 and mean F2, and density of vowels around one standard deviation of mean F1 and of F2. Methods: Structured and spontaneous speech of 148 participants (70 patients and 78 controls) was recorded and measured acoustically. We examined correlations between the phonetic measures of vowel space and ratings of aprosody obtained using two clinical research measures, the Scale for the Assessment of Negative Symptoms (SANS) and the Clinical Assessment Interview for Negative Symptoms (CAINS).Results: Vowel space measurements were significantly associated with patient/control status, attributed to a cluster of 13 patients whose phonetic values correspond to reduced vowel space as assessed by both phoenetic measures. No correlation was found between phonetic measures and relevant items and averages of ratings on the SANS and CAINS. Reduced vowel space appears to affect only a subset of patients with schizophrenia, potentially those on higher antipsychotic dosages.Conclusions: Acoustic phonetic measures may be more sensitive measures of constricted vowel space than clinical research rating scales of aprosody or monotone speech. Replications are needed before further interpretation of this novel finding, including potential medication effects.","2023-05","2025-02-26 20:39:19","2025-02-26 20:39:19","","158-164","","","255","","","","","","","","","","English","","","","WOS:000969128000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","ACOUSTIC ANALYSIS; Aprosody; CONSENSUS COGNITIVE BATTERY; Linguistics; NEGATIVE SYMPTOM SEVERITY; Negative symptoms; Phonetics; Schizophrenia; SPEAKING; SPEECH; Vowel space","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WN4YMGWL","journalArticle","2024","Singh, NK; Chanu, YJ; Pangsatabam, H","MECOS: A bilingual Manipuri-English spontaneous code-switching speech corpus for automatic speech recognition","COMPUTER SPEECH AND LANGUAGE","","0885-2308","10.1016/j.csl.2024.101627","","In this study, we introduce a new code-switched speech database with 57h of Manipuri-English annotated spontaneous speech. Manipuri is an official language of India and is primarily spoken in the north-eastern Indian state of Manipur. Most Manipur native speakers today are bilingual and frequently use code switching in everyday discussions. By carefully assessing the amount of code-switched speech in each video, recordings from YouTube are gathered. 21,339 utterances and 291,731 instances of code switching are present in the database. Given the code-switching nature of the data, a proper annotation procedure is used, and the data are manually annotated using the Meitei Mayek unicode font and the roman alphabets for Manipuri and English, respectively. The transcription includes the information of the speakers, non-speech information, and the corresponding annotation. The aim of this research is to construct an automatic speech recognition (ASR) system as well as offer a thorough analysis and details of the speech corpus. We believe that our research is the first to use an ASR system for Manipuri-English code-switched speech. To evaluate the performance, ASR systems based on hybrid deep neural network and hidden Markov model (DNN-HMM), time delay neural network (TDNN), hybrid time delay neural network and long short-term memory (TDNN-LSTM) and three end-to-end (E2E) models i. e. hybrid connectionist temporal classification and attention model (CTC-Attention), Conformer, wav2vec XLSR are developed for Manipuri-English language. In comparison to other models, pure TDNN produces outcomes that are clearly superior.","2024-08","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","87","","","","","","","","","","English","","","","WOS:001204378700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Artificial intelligence; Conformer; Deep neural network; Manipuri -English; Speech recognition; Time delay neural network; Transformer; wav2vec","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7SM3XTGH","journalArticle","2023","Shan, Y","Form (Prosody)-Meaning (Pragmatics) pairings of discourse markers: A case study of Ni zhidao ('You Know') as a construction in Chinese media interviews","LANGUAGE & COMMUNICATION","","0271-5309","10.1016/j.langcom.2023.09.004","","This article makes the first empirical corpus-based study of the actual performance of the discourse marker (DM) ni zhidao (NZ) in Chinese media interview conversations from the perspective of synchronic Construction Grammar (CxG).(1) The main objective is to pair the prosody of NZ at varying utterance positions ('form' properties at prosodic and discourse structural levels) with its pragmatic functions ('meaning' properties at the discourse communicative level), to enhance our understanding within the existing literature, specifically in relation to pragmatics in spontaneous speech, and provide implications for the broader study of discourse markers. The analysis of the 'form' properties of NZ reveals distinct, context-specific attributes of such prosodic metrics as duration, tempo, pause, F-0, and intensity at varying utterance positions; the analysis of its 'meaning' properties discovers pragmatic functions with characteristic utterance distributions; and the form-meaning pairing between prosody and pragmatics highlights the roles of prosody in deciphering and materializing pragmatics and of pragmatics in underlying and motivating prosody. This study has shown that insights gained from CxG can enhance our understanding of the fields of pragmatics, discourse, and interaction, and specific linguistic phenomena whose importance has been entrenched in these domains can be sufficiently explained using CxG. It follows that the notion of construction can be extended to the discourse (e.g., dialogue and conversation) level to approach the complexities of spoken language and address diverse elusive pragmatic issues like DMs effectively. (C) 2023 Elsevier Ltd. All rights reserved.","2023-11","2025-02-26 20:39:19","2025-02-26 20:39:19","","136-154","","","93","","","","","","","","","","English","","","","WOS:001099167400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;135</p>","","","COMMUNICATION; Construction; Construction grammar; Discourse marker; EMOTION; FOCUS; GRAMMAR; GRAMMATICALIZATION; Media interview conversation; POSITION; PROSODIC CUES; Prosody-pragmatics pairing; ROLES; SPOKEN LANGUAGE; YOU-KNOW","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R9ESB7SW","journalArticle","2023","Diachek, E; Brown-Schmidt, S","The Effect of Disfluency on Memory for What Was Said","JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION","","0278-7393","10.1037/xlm0001156","","Disfluencies such as pauses, ""um""s, and ""uh""s are common interruptions in the speech stream. Previous work probing memory for disfluent speech shows memory benefits for disfluent compared to fluent materials. Complementary evidence from studies of language production and comprehension have been argued to show that different disfluency types appear in distinct contexts and, as a result, serve as a meaningful cue. If the disfluency-memory boost is a result of sensitivity to these form-meaning mappings, forms of disfluency that cue new upcoming information (fillers and pauses) may produce a stronger memory boost compared to forms that reflect speaker difficulty (repetitions). If the disfluency-memory boost is simply due to the attentional-orienting properties of a disruption to fluent speech, different disfluency forms may produce similar memory benefit. Experiments 1 and 2 compared the relative mnemonic benefit of three types of disfluent interruptions. Experiments 3 and 4 examined the scope of the disfluency-memory boost to probe its cognitive underpinnings. Across the four experiments, we observed a disfluency-memory boost for three types of disfluency that were tested. This boost was local and position dependent, only manifesting when the disfluency immediately preceded a critical memory probe word at the end of the sentence. Our findings reveal a short-lived disfluency-memory boost that manifests at the end of the sentence but is evoked by multiple types of disfluent forms, consistent with the idea that disfluencies bring attentional focus to immediately upcoming material. The downstream consequence of this localized memory benefit is better understanding and encoding of the speaker's message.","2023-08","2025-02-26 20:39:19","2025-02-26 20:39:19","","1306-1324","","8","49","","","","","","","","","","English","","","","WOS:000827800500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;92</p>","","","ATTENTION; disfluency; FILLED PAUSES; filler; HESITATION; LISTENERS; memory; pause; PREDICTION; repetition; SERIAL POSITION; SPONTANEOUS SPEECH; UH; UM; WORDS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BBD9YP5F","journalArticle","2023","Morihara, K; Ota, S; Kakinuma, K; Kawakami, N; Higashiyama, Y; Kanno, S; Tanaka, F; Suzuki, K","Buccofacial apraxia in primary progressive aphasia","CORTEX","","0010-9452","10.1016/j.cortex.2022.10.010","","Buccofacial apraxia (BFA) is associated with nonfluent/agrammatic variant primary pro-gressive aphasia (nfvPPA) as well as with the severity of apraxia of speech (AOS), a core symptom of nfvPPA. However, an association with agrammatism has not been established. The aim of this study was to examine the association between BFA and agrammatism in nfvPPA and to determine differences in atrophic regions in primary progressive aphasia (PPA) with and without BFA. Seventy-four patients with PPA were recruited, including 34, 15, 10, and 15 patients with nfvPPA, semantic variant PPA, logopenic variant PPA, and unclassified PPA, respectively. All patients underwent language examination and BFA evaluations. Voxel-based morphometry (VBM) was performed to determine whether at-rophy of a specific lesion correlated with the presence of BFA. BFA was observed in 20 and 3 patients with nfvPPA and unclassified PPA, respectively. In a comparison of patients with nfvPPA with and without BFA, the BFA group showed significantly worse spontaneous speech and writing in the Western Aphasia Battery. The agrammatism ratio or the ratio of agrammatic errors to the total number of particles was higher in the BFA group; however, the severity of prosodic and phonetic components of AOS did not differ between the two groups. VBM showed that the severity of BFA correlated with atrophy of the opercular and triangular areas of the inferior frontal gyrus to a part of the left middle frontal gyrus. BFA has a different anatomical basis from AOS in patients with nfvPPA and that BFA is char-acterized by more anterior degeneration compared to that of AOS.(c) 2022 Elsevier Ltd. All rights reserved.","2023-01","2025-02-26 20:39:19","2025-02-26 20:39:19","","61-70","","","158","","","","","","","","","","English","","","","WOS:000903749600005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Agrammatism; Apraxia of speech; Buccofacial apraxia; FACE APRAXIA; ORAL APRAXIA; OROFACIAL APRAXIA; PATHOLOGY; Primary progressive aphasia; SPEECH; STROKE; SUPRANUCLEAR PALSY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QRCMARA9","journalArticle","2022","Lai, LF; Gooden, S","Language Contact, Language Ecology, and Intonational Variation in the Yami Community","LANGUAGE AND SPEECH","","0023-8309","10.1177/00238309221115636","","This study investigates socioprosodic variation in Yami, a moribund indigenous language under intense contact with Mandarin in Taiwan: 32 bilingual (Yami-dominant, balanced, Mandarin-dominant) and 5 Yami-monolingual participants were recruited. We used an Interactive Card Game to elicit semi-spontaneous speech for neutral questions (NQ), default declarative questions (DQ1), and declarative questions with lighter incredulity (DQ2). Results reveal that (1) yes/no question intonation in Yami is highly variable; (2) on a broad community level, the DQ1-DQ2 distinction is absent from Yami; and (3) there is prosodic hybridization and innovation in bilingual speech. In particular, we see significant differences in DQ1 and NQ productions, with DQ1s having a rising nuclear configuration, higher pitch level, and wider pitch span, while NQs are realized with a mid-level pattern, lower pitch level, and narrower pitch span. DQ2 utterances exhibited highly varied nuclear configuration patterns with no significant differences in either pitch level or pitch span in DQ1-DQ2 comparisons. Yet, there is evidence that a hybridized DQ2 has begun to be integrated into Yami among younger bilinguals, suggesting that present-day Yami is in flux and is undergoing restructuring. These intonational variations are not easily attributable to a weakened Yami identity. Rather, younger bilinguals, who are leading the change, are highly dedicated to cultural practices and show strong rootedness in their Indigenous identity. Seemingly, while these less fluent speakers no longer use Yami to fulfill their everyday communicative needs, they are leaning more on its socio-indexical functions to reflect their ethnocultural identity.","2022-12","2025-02-26 20:39:19","2025-02-26 20:39:19","","791-832","","4","65","","","","","","","","","","English","","","","WOS:000843802100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;112</p>","","","ACCENT; BILINGUALS; CATALAN; ENGLISH; FUNDAMENTAL-FREQUENCY; IDENTITY; Indigenous identity; language ecology; SARAMACCAN; socio-indexical function; Socioprosodic variation; SPLIT; TONE; Yami","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"62MKH9TL","journalArticle","2023","Kuc, J; Michta, T","The Impact of COVID-19 on Voice, Speech, and Language: An Interdisciplinary Study of COVID-19 Survivors","GEMA ONLINE JOURNAL OF LANGUAGE STUDIES","","1675-8021","10.17576/gema-2023-2303-03","","The long-term effects of a COVID-19 infection are complex and may pose significant challenges for individuals and societies. Thus, it is important to understand the full impact it may have on many aspects of a survivor's life, including their voice, speech, and language. The study aimed to diagnose the types of speech disorders that occur in COVID-19 survivors, to investigate how long the speech disorders last, and to determine whether or not there was any correlation between the patient's age and their score in each of the categories of the Grade, Roughness, Breathiness, Asthenia, and Strain (GRBAS) scale. A total of 30 people aged between 30 and 60 years (15 men and 15 women) participated in this study. A speech evaluation was conducted using 4 types of tests: recordings of spontaneous speech, a test of repetition of words and sentences, a monologue, and a series of automated word sequences. The perceptual evaluation of the patients' speech was carried out by means of the GRBAS scale. We found that the majority of patients (25 out of 30) used excessive force to produce voice. We also found a significant weakening of the ability to produce voice immediately after the disease in all subjects. No significant correlations were found between the patient's age and individual scores on the GRBAS scale. Our findings highlight the multifaceted nature of the impact of COVID-19 on communication abilities, underscoring the need for collaborative efforts across various fields to effectively address the challenges faced by COVID-19 survivors.","2023-08","2025-02-26 20:39:19","2025-02-26 20:39:19","","42-57","","3","23","","","","","","","","","","English","","","","WOS:001161215000003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","COVID-19; speech disorders; speech pathology; speech therapy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4ALM7X8I","journalArticle","2023","Dumpala, SH; Dikaios, K; Rodriguez, S; Langley, R; Rempel, S; Uher, R; Oore, S","Manifestation of depression in speech overlaps with characteristics used to represent and recognize speaker identity","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-023-35184-7","","The sound of a person's voice is commonly used to identify the speaker. The sound of speech is also starting to be used to detect medical conditions, such as depression. It is not known whether the manifestations of depression in speech overlap with those used to identify the speaker. In this paper, we test the hypothesis that the representations of personal identity in speech, known as speaker embeddings, improve the detection of depression and estimation of depressive symptoms severity. We further examine whether changes in depression severity interfere with the recognition of speaker's identity. We extract speaker embeddings from models pre-trained on a large sample of speakers from the general population without information on depression diagnosis. We test these speaker embeddings for severity estimation in independent datasets consisting of clinical interviews (DAIC-WOZ), spontaneous speech (VocalMind), and longitudinal data (VocalMind). We also use the severity estimates to predict presence of depression. Speaker embeddings, combined with established acoustic features (OpenSMILE), predicted severity with root mean square error (RMSE) values of 6.01 and 6.28 in DAIC-WOZ and VocalMind datasets, respectively, lower than acoustic features alone or speaker embeddings alone. When used to detect depression, speaker embeddings showed higher balanced accuracy (BAc) and surpassed previous state-of-the-art performance in depression detection from speech, with BAc values of 66% and 64% in DAIC-WOZ and VocalMind datasets, respectively. Results from a subset of participants with repeated speech samples show that the speaker identification is affected by changes in depression severity. These results suggest that depression overlaps with personal identity in the acoustic space. While speaker embeddings improve depression detection and severity estimation, deterioration or improvement in mood may interfere with speaker verification.","2023-07-10","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","1","13","","","","","","","","","","English","","","","WOS:001027101700020","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;7<br/>Cited Reference Count:&nbsp;&nbsp;48</p>","","","FEATURES; PHQ-9; SCORE; VECTORS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F536PIZJ","journalArticle","2021","Cassarly, C; Doyle, A; Ly, T; Horn, J; Aitchison, M; Elm, J; Fridriksson, J; Bonilha, L","Speech Entrainment for Aphasia Recovery (SpARc) phase II trial design","CONTEMPORARY CLINICAL TRIALS COMMUNICATIONS","","2451-8654","10.1016/j.conctc.2021.100876","","Background: and purpose: Speech entrainment therapy (SET) is a computerized therapeutic approach that involves mimicking an audiovisual speech model to improve speech production. In a pilot study using SET for treatment of post-stroke non-fluent aphasia, significant gains were achieved in verbs per minute (VPM) during discourse using untrained items 1 and 6 weeks after treatment, suggesting that SET may yield meaningful improvements in fluent spontaneous speech for individuals with non-fluent aphasia. Methods: The Speech Entrainment for Aphasia Recovery (SpARc) trial is a prospective, randomized, assessorblinded, multicenter phase II clinical trial studying persons with chronic post-stroke non-fluent aphasia. Participants will be randomized to 3 weeks, 4.5 weeks, or 6 weeks of SET delivered via telehealth or a no SET control condition for 6 weeks. 80 adults (ages 21-81) with history of left hemisphere ischemic or hemorrhagic stroke with residual chronic (>6 months post stroke) non-fluent aphasia diagnosed by the Western Aphasia BatteryRevised (WAB-R) will be randomized (1:1:1:1) over 4 years. The trial will be conducted at the clinical research facilities at three sites: the Medical University of South Carolina, the University of South Carolina, and the University of Utah. Conclusions: This paper details the trial design of the SpARc trial, which aims to determine the dose of SET that will generate the highest effect size on speech fluency, VPM, sustained at 3 months post-treatment compared to a no SET control arm, for individuals with chronic post-stroke non-fluent aphasia to permit a future definitive trial to test the clinical utility of SET.","2021-12","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","24","","","","","","","","","","English","","","","WOS:000728561400007","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Aphasia; APRAXIA; DEPRESSION; FACES PAIN SCALE; MELODIC INTONATION THERAPY; Non-fluent speech; Randomized controlled trial; RATING-SCALE; RETRIEVAL; Speech production; STROKE; Study design","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FPVUJC3G","journalArticle","2024","Stan, JHV; Hillman, RE; Krusemark, C; Muise, J; Stadelman-Cohen, T; Mehta, DD; Sternad, D","Floating Ball Voice Therapy: Preliminary Effects on Outcomes and Predicting Individual Patient Differences in Generalization","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2024_JSLHR-23-00727","","Purpose: Floating ball voice therapy (FBVT) is a voice-controlled virtual environment based on a common treatment component across multiple evidence- based therapies: improved vocal efficiency (target) via practicing voicing with modified resonance and airflow (ingredient). This study preliminarily tested FBVT's effects on outcomes and the potential for its novel variability metrics to predict individual patient generalization . Method: Ten patients with nonphonotraumatic vocal hyperfunction (NPVH) practiced FBVT for 10 days. Outcomes were assessed by a vocal efficiency ratio, a validated NPVH index, the patient-reported Voice-Related Quality of Life (V-RQOL), and forced-choice auditory judgments of overall severity. Exploration in early practice (Day 1) was estimated by how the patient's two-dimensional variability (mean airflow and intensity) related to error (difference between the patient-produced and normative vocal efficiency ratio). Generalization from the game to spontaneous speech was evaluated using the validated NPVH index. Results: Ten days of FBVT were associated with improved vocal efficiency (Cohen's d = 1.3), NPVH index (d = - 1.1), V-RQOL total score (d = 0.9), and overall severity (odds ratio = 2.5). Patients who generalized on Day 10 exhibited airflow/intensity exploration that was more aligned with the error gradient on Day 1 (d = 0.6-1.2). Conclusions: A relatively small dosage of FBVT (i.e., 10 practice sessions) was associated with multiple improved voice therapy outcomes. The FBVT variability metrics on Practice Day 1 demonstrated strong potential to predict which patients generalized to connected speech. Future work can more thoroughly evaluate effects on outcomes and characterizing the quality of vocal exploration with a larger patient population. Supplemental Material: https://doi.org/10.23641/asha.27040873","2024-10","2025-02-26 20:39:19","2025-02-26 20:39:19","","3521-3535","","10","67","","","","","","","","","","English","","","","WOS:001343395000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;69</p>","","","DISORDERS; FEMALE; FUNCTIONAL DYSPHONIA; FUNDAMENTAL-FREQUENCY; KNOWLEDGE; NOISE; SUBGLOTTAL PRESSURE; TERM; VOCAL HYPERFUNCTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IVKLFQ8N","journalArticle","2024","Weston, H; Pouw, W; Fuchs, S","On the Relation Between Leg Motion Rate and Speech Tempo During Submaximal Cycling Exercise","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2023_JSLHR-23-00178","","Purpose: This study investigated whether temporal coupling was present between lower limb motion rate and different speech tempi during different exercise intensities. We hypothesized that increased physical workload would increase cycling rate and that this could account for previous findings of increased speech tempo during exercise. We also investigated whether the choice of speech task (read vs. spontaneous speech) affected results. Method: Forty-eight women who were ages 18-35 years participated. A within-participant design was used with fixed-order physical workload and counterbalanced speech task conditions. Motion capture and acoustic data were collected during exercise and at rest. Speech tempo was assessed using the amplitude envelope and two derived intrinsic mode functions that approximated syllable-like and footlike oscillations in the speech signal. Analyses were conducted with linear mixed-effects models. Results: No direct entrainment between leg cycling rate and speech rate was observed. Leg cycling rate significantly increased from low to moderate workload for both speech tasks. All measures of speech tempo decreased when participants changed from rest to either low or moderate workload. Conclusions: Speech tempo does not show temporal coupling with the rate of self-generated leg motion at group level, which highlights the need to investigate potential faster scale momentary coupling. The unexpected finding that speech tempo decreases with increased physical workload may be explained by multiple mental and physical factors that are more diverse and individual than anticipated. The implication for real-world contexts is that even light physical activity-functionally equivalent to walking-may impact speech tempo.","2024-10","2025-02-26 20:39:19","2025-02-26 20:39:19","","3931-3946","","10","67","","","","","","","","","","English","","","","WOS:001356380400004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","CADENCE; COORDINATION; ENTRAINMENT; GESTURE; HEART-RATE; MOVEMENT; PATTERNS; PEDAL RATE; SEX-DIFFERENCES; VENTILATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M5K9PAXA","journalArticle","2024","Svaldi, C; Paquier, P; Keulen, S; van Elp, H; Catsman-Berrevoets, C; Kingma, A; Jonkers, R; Kohnen, S; de Aguiar, V","Characterising the Long-Term Language Impairments of Children Following Cerebellar Tumour Surgery by Extracting Psycholinguistic Properties from Spontaneous Language","CEREBELLUM","","1473-4222","10.1007/s12311-023-01563-z","","Following cerebellar tumour surgery, children may suffer impairments of spontaneous language. Yet, the language processing deficits underlying these impairments are poorly understood. This study is the first to try to identify these deficits for four levels of language processing in cerebellar tumour survivors. The spontaneous language of twelve patients who underwent cerebellar tumour surgery (age range 3-24 years) was compared against his or her controls using individual case statistics. A distinction was made between patients who experienced postoperative cerebellar mutism syndrome (pCMS) and those who did not. Time since surgery ranged between 11 months and 12;3 years. In order to identify the impaired language processing levels at each processing level (i.e., lexical, semantic, phonological and/or morphosyntactic) nouns and verbs produced in the spontaneous language samples were rated for psycholinguistic variables (e.g., concreteness). Standard spontaneous language measures (e.g., type-token ratio) were calculated as well. First, inter-individual heterogeneity was observed in the spontaneous language outcomes in both groups. Nine out of twelve patients showed language processing deficits three of whom were diagnosed with pCMS. Results implied impairments across all levels of language processing. In the pCMS-group, the impairments observed were predominantly morphosyntactic and semantic, but the variability in nature of the spontaneous language impairments was larger in the non-pCMS-group. Patients treated with cerebellar tumour surgery may show long-term spontaneous language impairments irrespective of a previous pCMS diagnosis. Individualised and comprehensive postoperative language assessments seem necessary, given the inter-individual heterogeneity in the language outcomes.","2024-04","2025-02-26 20:39:19","2025-02-26 20:39:19","","523-544","","2","23","","","","","","","","","","English","","","","WOS:000987121900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;93</p>","","","ACQUISITION; APHASIA; Cerebellum; CHILDHOOD; COGNITIVE DEFICITS; MEDULLOBLASTOMA; MUTISM SYNDROME; Posterior fossa surgery; POSTERIOR-FOSSA TUMORS; Postoperative cerebellar mutism syndrome; Spontaneous language; SPONTANEOUS SPEECH; VERB ARGUMENT STRUCTURE; Word properties; WORD-FREQUENCY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z5I38Q2Z","journalArticle","2023","Rocha, LFM; de Almeida, SAF; Paula, LA","FICTIVE DIRECT DISCOURSE: CONCEPTUAL PERSPECTIVE AS AN ARGUMENTATIVE INTERSUBJECTIVE STRATEGY","CADERNOS DE ESTUDOS LINGUISTICOS","","0102-5767","10.20396/cel.v65i00.8672324","","The present work is aimed at studying a type of Fictivity in direct speech and the distinct ways it operates both discursively and intersubjectively by drawing on real speech data of Brazilian Portuguese spoken in the state of Minas Gerais. The study relies on Cognitive Linguistics, outlining the concept of construal as guiding the hypothesis that in their face-to-face interactions speaker and addressee use the Conversation Frame in order to structure Fictive Interaction (PASCUAL, 2014), especially the type here under study - Fictive Direct Speech (ROCHA, 2022) - as an intersubjective and argumentative device. The notion of (inter)subjectivity (VERHAGEN, 2005; TRAUGOTT; DASHER, 2005) intertwined with the notion of construal (VERHAGEN, 2005; TALMY, 2000; LANGACKER, 2008) is viewed as either linguistically codifying the attention of the speaker towards his/her addressee or as cognitively signalling alignment of perspectives (ALMEIDA, 2019). In regard to methodology, a corpus was compiled from spontaneous speech recordings at a beauty salon for the present analysis. We have adopted a methodology which blends a corpus-based and a corpus-driven approach to data (MCENERY; HARDIE, 2012; TOGNINI-BONELLI, 2001) thus allowing the corpora to guide our analysis. Apart from that, the qualitative approach to data not only conveyed Fictive Interaction samples of Fictive Direct Speech but also made it possible to identify distinct semantic-syntactic patterns exhibiting specific prosodic features. The results make the empirical acceptability of the phenomenon clear and reveal the use of Fictive Direct Speech as an attentional frame, and perspective-taking as an intersubjective and argumentative device for ultimately aligning different vantage points through discourse.","2023","2025-02-26 20:39:19","2025-02-26 20:39:19","","1-16","","","65","","","","","","","","","","English","","","","WOS:001048180600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;26</p>","","","construal; fictive direct speech; fictivity; intersubjectivity; vantage point","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EBNH8Q4W","journalArticle","2025","Li, HL; Xie, XH","Cerebellar activity and functional connectivity in subacute subcortical aphasia: Association with language recovery","NEUROSCIENCE","","0306-4522","10.1016/j.neuroscience.2024.11.077","","Loss of language function (aphasia) is a common complication after stroke, and post-stroke recovery remains highly unpredictable due to the absence of reliable neurobiomarkers. Growing evidence points to involvement of the cerebellum in language processing; however, it is unclear if abnormal cerebellar activity and altered functional connectivity (FC) to language-related regions of cerebral cortex are underlying neural mechanisms for subcortical aphasia. In this longitudinal observational study, we used resting-state functional magnetic resonance imaging to examine potential abnormalities in spontaneous cerebellar activity and resting-state (rs)FC with language networks among post-stroke patients with subacute subcortical aphasia (n = 19) compared to healthy controls (HCs, n = 18). In addition, correlations between rsFC variables and language performance metrics were examined at post-stroke baseline and at follow-up. Compared to HCs, patients with subacute subcortical aphasia exhibited significantly reduced fractional amplitude of low frequency fluctuations, a measure of spontaneous activity, in the right cerebellar Crus II (rCrus II) region and reduced rsFC between rCrus II and left inferior frontal gyrus (LIFG), left angular gyrus (LAG), and left middle temporal gyrus (LMTG). Both rCrus II-LAG and rCrus II-LMTG rsFC values were positively correlated with Aphasia Battery of Chinese scores at baseline. Baseline rCrus II-LIFG rsFC was also positively correlated with spontaneous speech and naming scores at follow-up. A stronger baseline rCrus II-LIFG rsFC predicted superior recovery of language function post-stroke. We conclude that the right cerebellum may be an effective therapeutic target for subcortical aphasia.","2025-01-26","2025-02-26 20:39:19","2025-02-26 20:39:19","","320-326","","","565","","","","","","","","","","English","","","","WOS:001385581300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","BRAIN; Cerebellum; FMRI; imaging; INVOLVEMENT; Language-related cortical areas; MOTOR; Resting-state functional magnetic resonance; STROKE; Subacute subcortical aphasia; TOPOGRAPHY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NJM7RZTG","journalArticle","2024","Jiang, ZH; He, MP; Zhang, CC; Chen, XE","The effect of mobile application-based technology on post-stroke aphasia: a systematic review","FRONTIERS IN NEUROLOGY","","1664-2295","10.3389/fneur.2024.1405209","","Background: Enhancing speech-language therapy remains the most effective strategy for improving post-stroke aphasia, However, conventional face-to-face interventions often lack the necessary therapeutic intensity. In recent years, mobile application-based speech-language therapy has emerged progressively, offering new opportunities for independent rehabilitation among aphasic patients. This review aims to evaluate the impact of mobile application-based interventions on post-stroke aphasic. Methods: By conducting a systematic search across five databases (PubMed, Web of Science, EMBASE, CINAHL, and Scopus), we identified and included studies that investigated the utilization of mobile application-based technologies (such as computers, iPads, etc.) for treating post-stroke aphasia. Results: This study included 15 research investigations, including 10 randomized controlled trials (RCTs), four self-controlled studies and one cross-over experimental design study. Among these, eight studies demonstrated the efficacy of mobile application-based therapy in enhancing overall language functionality for post-stroke aphasia patients, three studies highlighted its potential for improving communication skills, three studies observed its positive impact on spontaneous speech expression. Moreover, four studies indicated its effectiveness in enhancing naming abilities, two studies underscored the positive influence of mobile application-based interventions on the quality of life for individuals with aphasia. Six studies noted that speech improvement effects were maintained during the follow-up period. Conclusion: The results of this review demonstrate the potential of mobile application-based interventions for improving speech-language function in individuals with aphasia. However, further high-quality research is needed to establish their effects across different domains and to delve into the comparative advantages of various treatment approaches.","2024-06-12","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","15","","","","","","","","","","English","","","","WOS:001253594000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","aphasia; COMMUNICATION; EFFICACY; LANGUAGE THERAPY; mobile application; PEOPLE; post-stroke; QUALITY; SPEECH; speech and language therapy; STROKE; systematic review; USUAL CARE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P2XVG3LF","journalArticle","2024","Daikoku, T","Temporal dynamics of uncertainty and prediction error in musical improvisation across different periods","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-73689-x","","Human improvisational acts contain an innate individuality, derived from one's experiences based on epochal and cultural backgrounds. Musical improvisation, much like spontaneous speech, reveals intricate facets of the improviser's state of mind and emotional character. However, the specific musical components that reveal such individuality remain largely unexplored. Within the framework of human statistical learning and predictive processing, this study examined the temporal dynamics of uncertainty and surprise (prediction error) in a piece of musical improvisation. This cognitive process reconciles the raw auditory cues, such as melody and rhythm, with the musical predictive models shaped by its prior experiences. This study employed the Hierarchical Bayesian Statistical Learning (HBSL) model to analyze a corpus of 456 Jazz improvisations, spanning 1905 to 2009, from 78 distinct Jazz musicians. The results indicated distinctive temporal patterns of surprise and uncertainty, especially in pitch and pitch-rhythm sequences, revealing era-specific features from the early 20th to the 21st centuries. Conversely, rhythm sequences exhibited a consistent degree of uncertainty across eras. Further, the acoustic properties remain unchanged across different periods. These findings highlight the importance of how temporal dynamics of surprise and uncertainty in improvisational music change over periods, profoundly influencing the distinctive methodologies artists adopt for improvisation in each era. Further, it is suggested that the development of improvisational music can be attributed to the adaptive statistical learning mechanisms. This study explores the period-specific characteristics in the temporal dynamics of improvisational music, emphasizing how artists adapt their methods to resonate with the cultural and emotional contexts of their times. Such shifts in improvisational ways offer a window into understanding how artists intuitively respond and adapt their craft to resonate with the cultural zeitgeist and the emotional landscapes of their respective times.","2024-09-27","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","1","14","","","","","","","","","","English","","","","WOS:001354536300194","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","EMOTION; Epochal development; Individuality bayesian; LANGUAGE; Music; Uncertainty","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LFHP26RL","journalArticle","2024","Cavalcanti, JC; Eriksson, A; Barbosa, PA","Multiparametric Analysis of Speaking Fundamental Frequency in Genetically Related Speakers Using Different Speech Materials: Some Forensic Implications","JOURNAL OF VOICE","","0892-1997","10.1016/j.jvoice.2021.08.013","","Objectives. To assess the speaker -discriminatory potential of a set of fundamental frequency estimates in intraidentical twin pair comparisons and cross -pair comparisons (i.e., among all speakers). Participants. A total of 20 Brazilian Portuguese speakers of the same dialect, namely 10 male identical twin pairs aged between 19 and 35, were recruited. Method. The participants were recorded directly through professional microphones while taking part in a spontaneous dialogue over mobile phones. Acoustic measurements were performed in connected speech samples, and in lengthened vowels, at least 160 ms long produced during spontaneous speech. Results. f 0 baseline, central tendency, and extreme values were found mostly discriminatory in intra-twin pair and cross -pair comparisons. These were also the estimates displaying the largest effect sizes. Overall, only three identical twins were found statistically different regarding their f 0 patterns in connected speech, but not for lengthened vowel -based f0 metrics. Estimates off 0 variation and modulation were found the least discriminatory across speakers, which may signal the control of speaking style and dialect on dynamic patterns off 0. Concerning system performance, the base value off 0 (f 0 baseline) was found the most reliable metric, displaying the lowest equal error rate (EER). Conclusions. The outcomes suggest that, although identical twins were very closely related regarding their f 0 patterns, some pairs could still be differentiated acoustically, only in connected speech. Such findings reinforce the relevance of analyzing long-term f 0 metrics for speaker comparison purposes, with particular consideration to f 0 baseline. Furthermore, f 0 differences across subjects were suggested as more expressive in connected speech than in lengthened vowels.","2024-01","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","1","38","","","","","","","","","","English","","","","WOS:001164381200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","frequency-Acoustic phonetics-Forensic; MONOZYGOTIC TWINS; phonetics-Forensic phonetics-Identical; phonetics-Identical twins; SMOKING; Speaking fundamental frequency-Acoustic; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"57K3X8EB","journalArticle","2022","Tang, HJ; Fan, SH; Niu, XY; Li, ZH; Xiao, PY; Zeng, JS; Xing, SH","Remote cortical atrophy and language outcomes after chronic left subcortical stroke with aphasia","FRONTIERS IN NEUROSCIENCE","","1662-453X","10.3389/fnins.2022.853169","","ObjectiveSubcortical stroke can cause a variety of language deficits. However, the neural mechanisms underlying subcortical aphasia after stroke remain incompletely elucidated. We aimed to determine the effects of distant cortical structures on aphasia outcomes and examine the correlation of cortical thickness measures with connecting tracts integrity after chronic left subcortical stroke. MethodsThirty-two patients and 30 healthy control subjects underwent MRI scanning and language assessment with the Western Aphasia Battery-Revised (WAB-R) subtests. Among patients, the cortical thickness in brain regions that related to language performance were assessed by the FreeSurfer software. Fiber tracts connecting the identified cortical regions to stroke lesions were reconstructed to determine its correlations with the cortical thickness measures across individual patient. ResultsCortical thickness in different parts of the left fronto-temporo-parietal (FTP) regions were positively related to auditory-verbal comprehension, spontaneous speech and naming/word finding abilities when controlling for key demographic variables and lesion size. Cortical thickness decline in the identified cortical regions was positively correlated with integrity loss of fiber tracts connected to stroke lesions. Additionally, no significant difference in cortical thickness was found across the left hemisphere between the subgroup of patients with hypoperfusion (HP) and those without HP at stroke onset. ConclusionsThese findings suggest that remote cortical atrophy independently predicts language outcomes in patients with chronic left subcortical stroke and aphasia and that cortical thinning in these regions might relate to integrity loss of fiber tracts connected to stroke lesions.","2022-08-03","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","16","","","","","","","","","","English","","","","WOS:000841162100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","aphasia; BROCAS AREA; cortical thickness; DEGENERATION; diffusion tensor imaging; FREE-WATER ELIMINATION; HYPOPERFUSION; INFARCTION; MOTOR RECOVERY; NEGLECT; outcomes; POSTSTROKE APHASIA; subcortical stroke; TRANSCRANIAL MAGNETIC STIMULATION; VOLUME CHANGES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FE5PIFND","journalArticle","2021","Cuprych, R; Boksa, E","Realization of intonation structures in reading attempt and spontaneous speech in the elderly","MEDICAL STUDIES-STUDIA MEDYCZNE","","1899-1874","10.5114/ms.2021.112383","","Introduction: The articulation activities of respondents with healthy physiological aging of the brain structures is a significant differentiating factor because slight changes occur on the suprasegmental plane of the language. In the linguistic prosody, the most important elements of the act of utterance emerge in the foreground, which relates to lexical stress (the syllable in a word is stressed), emphatic stress (the word in a sentence is stressed), and intonation (chanting in a sentence, questions, statements). The indicated elements are directed by the part of the right hemisphere of the brain that is responsible for processing and understanding speech prosody, i.e. the posterior cortex in the area of the Sylvius sulcus and the lower part of the right frontal lobe. Aim of the research: Identifying suprasegmental features of language on the example of selected read texts and spontaneous oral statements. Material and methods: The study was conducted in a group of healthy seniors attending classes organized by clubs and retirement homes. The spectrographic method was used, including the Praat speech program. The graphic version is presented in the form of intonograms. Results: Minor disturbances in the rhythmic-intonation structure were found in the subjects without concomitant speech organ dysfunctions and without previous neurological episodes that could affect the implementation of intonation structures. Conclusions: The realization of particular intonation structures is influenced by the speaker's emotions, intentions, and attitude towards the interlocutor. This means that intonation is of great importance in the process of not only realizing certain levels of language organization, but also in the communicative situation, and thus in the implementation of grammatical and semantic functions.","2021","2025-02-26 20:39:19","2025-02-26 20:39:19","","288-294","","4","37","","","","","","","","","","English","","","","WOS:000740725500003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","speech intonation structure; speech prosody; speech test program","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"77FWCU83","journalArticle","2024","Soleymanpour, M; Johnson, MT; Soleymanpour, R; Berry, J","Accurate synthesis of dysarthric Speech for ASR data augmentation","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2024.103112","","Dysarthria is a motor speech disorder often characterized by reduced speech intelligibility through slow, uncoordinated control of speech production muscles. Automatic Speech Recognition (ASR) systems can help dysarthric talkers communicate more effectively. However, robust dysarthria-specific ASR requires a significant amount of training speech, which is not readily available for dysarthric talkers. This paper presents a new dysarthric speech synthesis method for the purpose of ASR training data augmentation. Differences in prosodic and acoustic characteristics of dysarthric spontaneous speech at varying severity levels are important components for dysarthric speech modeling, synthesis, and augmentation. For dysarthric speech synthesis, a modified neural multi-talker TTS is implemented by adding a dysarthria severity level coefficient and a pause insertion model to synthesize dysarthric speech for varying severity levels. To evaluate the effectiveness for synthesis of training data for ASR, dysarthria-specific speech recognition was used. Results show that a DNN-HMM - HMM model trained on additional synthetic dysarthric speech achieves relative Word Error Rate (WER) improvement of 12.2 % compared to the baseline, and that the addition of the severity level and pause insertion controls decrease WER by 6.5 %, showing the effectiveness of adding these parameters. Overall results on the TORGO database demonstrate that using dysarthric synthetic speech to increase the amount of dysarthric-patterned speech for training has significant impact on the dysarthric ASR systems. In addition, we have conducted a subjective evaluation to evaluate the dysarthricness and similarity of synthesized speech. Our subjective evaluation shows that the perceived dysarthricness of synthesized speech is similar to that of true dysarthric speech, especially for higher levels of dysarthria. Audio samples are available at https:// mohammadelc.github.io/SpeechGroupUKY/","2024-10","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","164","","","","","","","","","","English","","","","WOS:001303994600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","Data augmentation; Dysarthria; MODELS; RECOGNITION; SPEAKERS; Speech recognition; Speech-to-text; Synthesized speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FQ8AQV8P","journalArticle","2023","Wang, LP; Qi, CY; Gu, MM; Yan, M; Qi, QD","Effects of stepped speech rehabilitation and psychological intervention on speech disorders and cognitive function in Parkinson disease patients","MEDICINE","","0025-7974","10.1097/MD.0000000000036420","","To examine the impact of stepwise speech rehabilitation exercise therapy in the treatment of patients with Parkinson speech problems under psychological intervention on clinical results and cognitive functioning. Parkinson speech disorder patients who met the inclusion criteria were selected and divided into a control group and an observation group for training respectively. The control group used conventional nursing methods, including training in orofacial movement, vocalization, pitch, volume and breath control. The observation group used stepwise speech rehabilitation exercise intervention combined with psychotherapy nursing programme. In the statistical analysis, independent sample t-test and chi-square test were used to test the significance of the data processing methods. In the statistical analysis of baseline functional level (P > .05). The difference was not statistically significant. After 7 weeks of training, the mFDA level and speech intelligibility increased in both the observation and control groups. From the situation analysis of ""modified drinking test"" and the comparison of UPDRS-I scores, it can be seen that dysphagia and Parkinson dysphasia were reduced in both groups after training. The observation group spontaneous speech dimension was greater than the control group by around 0.07 in the aphasia comparison. Both groups displayed an upward trend in their MMSE and Montreal Cognitive Assessment (MoCA) when measuring cognitive function; the evaluation of P300, constructive function, and quality of life revealed this. The observation group P300 potential score was 0.13 points higher than that of the control group. The therapeutic training of stepped speech rehabilitation exercise care combined with psychological intervention has significant nursing effects on patients with Parkinson disease speech disorders, and the patients' cognitive functions have been effectively improved.","2023-12-29","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","52","102","","","","","","","","","","English","","","","WOS:001134264400011","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;19</p>","","","cognitive functioning; nursing outcomes; psychological interventions; rehabilitative exercise care; speech patients with Parkinson disease; stepwise","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NW7J44VD","journalArticle","2023","Horne, KS; Ceslis, A; Mosley, P; Adam, R; Robinson, GA","The Role of Apathy in Spontaneous Verbal and Nonverbal Behaviors: A Transdiagnostic Pilot Study in Neurodegeneration","COGNITIVE AND BEHAVIORAL NEUROLOGY","","1543-3633","10.1097/WNN.0000000000000345","","Background:Apathy, characterized by a quantifiable reduction in motivation or goal-directed behavior, is a multidimensional syndrome that has been observed across many neurodegenerative diseases.Objective:To develop a novel task measuring spontaneous action initiation (ie, a nonverbal equivalent to spontaneous speech tasks) and to investigate the association between apathy and executive functions such as the voluntary initiation of speech and actions and energization (ie, ability to initiate and sustain a response).Method:We compared the energization and executive functioning performance of 10 individuals with neurodegenerative disease and clinically significant apathy with that of age-matched healthy controls (HC). We also investigated the association between self-reported scores on the Apathy Evaluation Scale (AES) and performance on energization tasks.Results:The individuals with apathy made significantly fewer task-related actions than the HC on the novel spontaneous action task, and their scores on the AES were negatively correlated with spontaneous task-related actions, providing preliminary evidence for the task's construct validity. In addition, the individuals with apathy performed more poorly than the HC on all of the energization tasks, regardless of task type or stimulus modality, suggesting difficulty in sustaining voluntary responding over time. Most of the tasks also correlated negatively with the AES score. However, the individuals with apathy also performed more poorly on some of the executive function tasks, particularly those involving self-monitoring.Conclusion:Our work presents a novel experimental task for measuring spontaneous action initiation-a key symptom of apathy-and suggests a possible contribution of apathy to neuropsychological deficits such as poor energization.","2023-09","2025-02-26 20:39:19","2025-02-26 20:39:19","","178-193","","3","36","","","","","","","","","","English","","","","WOS:001060013400005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;114</p>","","","ALZHEIMERS-DISEASE; apathy; dementia; EVALUATION SCALE; EXECUTIVE FUNCTION; executive functions; FRONTAL-LOBE; MILD COGNITIVE IMPAIRMENT; MULTIDIMENSIONAL APATHY; NEUROPSYCHIATRIC SYMPTOMS; PARKINSONS-DISEASE; PROGRESSIVE SUPRANUCLEAR PALSY; PSYCHOMETRIC PROPERTIES; spontaneous actions","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A6ZSUQMT","journalArticle","2024","Sasisekaran, J; Lei, XF","Effects of task variations on language productivity, syntactic complexity, and stuttering in children who stutter","CLINICAL LINGUISTICS & PHONETICS","","0269-9206","10.1080/02699206.2023.2232517","","Purpose. The aim of this preliminary study was to compare the effects of variations in task demands on: (a) language productivity in sentences categorised into stuttered vs. non-stuttered sentences; (b) syntactic complexity in stuttered vs. non-stuttered sentence categories, and (c) stuttering and typical disfluencies in school-age children who stutter (CWS). Language Sample Analysis (LSA) was conducted on samples from three tasks - Conversation, fable retell, and critical thinking based on the fables. Methods. Participants were 14 CWS categorised into younger (9 to 12-year-olds, n = 8) and older age groups (13 to 15-year-olds, n = 6). The Computerized Language ANalysis program was used to conduct language and disfluency analyses. Repeated measures analysis of variance and nonparametric statistical analyses were used to investigate: (a) Language productivity in total number of words and sentences by task and sentence category; (b) Syntactic complexity at the word- (use of metacognitive verbs), phrase- (use of verb phrases), and utterance (Mean Length of Utterances in words, MLUw) levels by task and sentence category; and (c) Disfluencies measured using % stuttered syllables (%SS) and % typical disfluencies (%TD). Results and Conclusions. Task effects in language productivity did not differ by sentence category and suggested limited influences of propositionality and volubility in stuttering. In contrast, higher syntactic complexity was obtained in the stuttered compared to non-stuttered sentences at the word, phrase, and utterance levels and it was the same task - conversation, that elicited the effect. Additionally, variations in task demands did not result in significant differences in %SS. The findings inform assessment planning with the selection of tasks guided by task demands and assessment requirements.","2024-07-02","2025-02-26 20:39:19","2025-02-26 20:39:19","","605-625","","7","38","","","","","","","","","","English","","","","WOS:001054194300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","ADOLESCENTS; CONVERSATION; DISFLUENCIES; FLUENCY; language productivity; LENGTH; PRESCHOOL-CHILDREN; SAMPLE ANALYSIS; SPOKEN; SPONTANEOUS SPEECH; Stuttering; syntactic complexity; task variations; typical disfluencies; YOUNG-CHILDREN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ICSHLIKE","journalArticle","2023","Mochizuki, M; Uchiyama, Y; Domen, K; Koyama, T","Automated Tractography for the Assessment of Aphasia in Acute Care Stroke Rehabilitation: A Case Series","PROGRESS IN REHABILITATION MEDICINE","","2432-1354","10.2490/prm.20230041","","Background: Aphasia is a common disorder among stroke patients. Assessment of aphasia is essential for scheduling appropriate rehabilitative treatment. Although this is conventionally accomplished using neuropsychological test batteries, these tests are not always accessible because of attention and/or consciousness disturbances during acute care. To overcome this issue, we have introduced a newly developed automated tractography known as XTRACT. Cases: Diffusiontensor images were acquired from three patients on days 10-14. Brain images were processed by XTRACT, which automatically extracts neural tracts using standardized protocols. Fractional anisotropy (FA) values were then bilaterally evaluated in the following neural tracts associated with aphasia: arcuate fasciculus, inferior fronto-occipital fasciculus, middle longitudinal fasciculus, inferior longitudinal fasciculus, and uncinate fasciculus. Case 1 had word-finding difficulty on admission. FA values in the lesioned left hemisphere were not decreased in all tracts and this patient fully recovered during acute care. Case 2 had reduced spontaneous speech and a low FA value in the left arcuate fasciculus. Rehabilitative treatment was scheduled to improve the verbal output of sentences and word recall. Case 3 could not complete the conventional aphasia test battery because of attention disturbance. He had low FA values in all tracts in the left hemisphere. Rehabilitative treatment was designed to focus on both speaking and auditory comprehension. Discussion: Automated tractography enables quantitative assessment of the neural damage associated with aphasia, even in patients with attention and/or consciousness disturbances. This modality can aid in the assessment of aphasia and allows the planning of appropriate rehabilitative treatment.","2023","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","8","","","","","","","","","","English","","","","WOS:001266638300016","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","automatic; DIFFUSION TENSOR TRACTOGRAPHY; evaluation; FASCICULUS; FRACTIONAL ANISOTROPY; ISCHEMIC-STROKE; LANGUAGE; neuroimaging; RECOVERY; standardized; tract","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W5KGYGP4","journalArticle","2024","Xu, F; Zheng, QH; Shi, J; Yan, KY; Wang, MW","Pre-training and ensembling based Alzheimer's disease detection","TECHNOLOGY AND HEALTH CARE","","0928-7329","10.3233/THC-230571","","BACKGROUND: Alzheimer's disease (AD) endangers the physical and mental health of the elderly, constituting one of the most crucial social challenges. Due to lack of effective AD intervention drugs, it is very important to diagnose AD in the early stage, especially in the Mild Cognitive Impairment (MCI) phase. OBJECTIVE: At present, an automatic classification technology is urgently needed to assist doctors in analyzing the status of the candidate patient. The artificial intelligence enhanced Alzheimer's disease detection can reduce costs to detect Alzheimer's disease. METHODS: In this paper, a novel pre-trained ensemble-based AD detection (PEADD) framework with three base learners (i.e., ResNet, VGG, and EfficientNet) for both the audio-based and PET (Positron Emission Tomography)-based AD detection is proposed under a unified image modality. Specifically, the effectiveness of context-enriched image modalities instead of the traditional speech modality (i.e., context-free audio matrix) for the audio-based AD detection, along with simple and efficient image denoising strategy has been inspected comprehensively. Meanwhile, the PET-based AD detection based on the denoised PET image has been described. Furthermore, different voting methods for applying an ensemble strategy (i.e., hard voting and soft voting) has been investigated in detail. RESULTS: The results showed that the classification accuracy was 92% and 99% on the audio-based and PET-based AD datasets, respectively. Our extensive experimental results demonstrate that our PEADD outperforms the state-of-the-art methods on both audio-based and PET-based AD datasets simultaneously. CONCLUSIONS: The network model can provide an objective basis for doctors to detect Alzheimer's Disease.","2024","2025-02-26 20:39:19","2025-02-26 20:39:19","","379-395","","1","32","","","","","","","","","","English","","","","WOS:001146748400033","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Alzhemier's disease; early detection; ensembling; MILD COGNITIVE IMPAIRMENT; modality; pre-training; RECOGNITION; SPONTANEOUS SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7QKERH75","journalArticle","2023","Subert, M; Novotny, M; Tykalová, T; Srpová, B; Friedová, L; Uher, T; Horáková, D; Rusz, J","Lexical and syntactic deficits analyzed via automated natural language processing: the new monitoring tool in multiple sclerosis","THERAPEUTIC ADVANCES IN NEUROLOGICAL DISORDERS","","1756-2856","10.1177/17562864231180719","","Background:Impairment of higher language functions associated with natural spontaneous speech in multiple sclerosis (MS) remains underexplored. Objectives:We presented a fully automated method for discriminating MS patients from healthy controls based on lexical and syntactic linguistic features. Methods:We enrolled 120 MS individuals with Expanded Disability Status Scale ranging from 1 to 6.5 and 120 age-, sex-, and education-matched healthy controls. Linguistic analysis was performed with fully automated methods based on automatic speech recognition and natural language processing techniques using eight lexical and syntactic features acquired from the spontaneous discourse. Fully automated annotations were compared with human annotations. Results:Compared with healthy controls, lexical impairment in MS consisted of an increase in content words (p = 0.037), a decrease in function words (p = 0.007), and overuse of verbs at the expense of noun (p = 0.047), while syntactic impairment manifested as shorter utterance length (p = 0.002), and low number of coordinate clause (p < 0.001). A fully automated language analysis approach enabled discrimination between MS and controls with an area under the curve of 0.70. A significant relationship was detected between shorter utterance length and lower symbol digit modalities test score (r = 0.25, p = 0.008). Strong associations between a majority of automatically and manually computed features were observed (r > 0.88, p < 0.001). Conclusion:Automated discourse analysis has the potential to provide an easy-to-implement and low-cost language-based biomarker of cognitive decline in MS for future clinical trials.","2023-06","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","16","","","","","","","","","","English","","","","WOS:001013115100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","automated linguistic analysis; COGNITIVE IMPAIRMENT; DYSFUNCTION; FATIGUE; IMPACT; language; multiple sclerosis; nature language processing; RISK; SCALE; spontaneous discourse","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CCULSGIV","journalArticle","2022","Trawick, S; Bero, T","Gender assignment: Monolingual constraints contribute to a bilingual outcome","INTERNATIONAL JOURNAL OF BILINGUALISM","","1367-0069","10.1177/13670069211053466","","Aims and objectives: This study explores the well-researched topic of gender assignment to English nouns in Spanish discourse through a usage-based framework. The goal is to elucidate the relative impact of both previously studied and novel constraints on the variable application of feminine determiners. Methodology: A variationist analysis of English nouns surrounded by Spanish discourse in the spontaneous speech of bilinguals. Data and analysis: Data come from the New Mexico Spanish-English Bilingual Corpus. Tokens (N = 707) were coded for independent variables and submitted to a logistic regression. The goodness of fit was determined via the area under the receiver operating characteristic (ROC) curve method. Findings: All independent variables were selected as significant by the logistic regression model. Based on factor weight ranges, the hierarchy of constraints is the following, from the most to the least impactful: Analogical Gender, Phonological Shape, Syntactic Role, and Determiner Definiteness. These results suggest that bilinguals utilize a variety of constraints in gender assignment, as opposed to a single default strategy. Originality: While previous studies have tested and found similar results for constraints such as analogical gender and phonological shape, none have offered a unified analysis explaining findings from a usage-based approach. The originality and utility of this approach is most apparent in the discussions of prototypicality and schematicity. Significance/implications: A corpus-based approach and usage-based theory is shown to bring new insight to a topic of interest in many other linguistic sub-fields. The discussion reinterprets previous conclusions about gender assignment using a framework not proposed in previous research, despite similar overall results.","2022-04","2025-02-26 20:39:19","2025-02-26 20:39:19","","181-197","","2","26","","","","","","","","","","English","","","","WOS:000717629100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","analogical gender; bilingual outcomes; Gender assignment; lone noun insertions; phonological shape; prototypicality; SPANISH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VEJHM5M6","journalArticle","2022","Gong, P; Jiao, XR; Yang, ZX","A case of Landau-Kleffner syndrome with SLC26A4-related hearing impairment","ACTA EPILEPTOLOGICA","","2096-9384","10.1186/s42494-021-00067-9","","Background Landau-Kleffner syndrome (LKS) is an acquired aphasia and electroencephalogram (EEG) abnormalities mainly in temporoparietal areas. SLC26A4 mutations can cause hearing loss associated with enlarged vestibular aqueduct (EVA).Case presentations We report a case of LKS in a 5-year-old boy with non-syndromic EVA due to homozygous mutations of c.919-2A>G (IVS7-2A>G) in SLC26A4. He had normal language development before 2 years old. At the age of 2.5 years, he was admitted to the hospital due to remarkable language delay, and diagnosed with hearing loss with EVA. The seizures started at 4.4 years of age and EEG recording showed electrical status epilepticus during sleep (ESES) with a posterior-temporal predominance. He received cochlear implantation in the right ear at 4.7 years of age, which improved his hearing and language skills. The nocturnal focal motor seizures recurred at 4.9 years of age. Then a remarkable inability to respond to calls and reduction in spontaneous speech were noticed. He was treated with methylprednisolone at 5 years old, which controlled the seizures, suppressed ESES, and remarkably improved the language ability. The absence of seizures maintained until the last follow-up at 5.3 years of age, with further improvements in EEG recording and language ability.Conclusions The co-existence of LKS and hearing loss caused by SLC26A4 mutations increases the difficulty of LKS diagnosis, especially in the presence of hearing loss and impaired language skills. EEG discharges predominantly in temporoparietal areas, the occurrence of ESES, and language improvement after antiepileptic medications are potential indicators for LKS diagnosis.","2022-01-04","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","1","4","","","","","","","","","","English","","","","WOS:001125296000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","CHILDREN; COCHLEAR IMPLANTATION; Epilepsy; GENE; Hearing loss; Landau-Kleffner syndrome; SLC26A4; SLC26A4 MUTATIONS; VESTIBULAR AQUEDUCT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HEA3FPVS","journalArticle","2023","Kim, Y; Sidtis, D; Sidtis, JJ","Singing and Speaking Ability in Parkinson's Disease and Spinocerebellar Ataxia","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2022_JSLHR-22-00274","","Purpose: This study examined spontaneous, spoken-to-a-model, and two sung modes in speakers with Parkinson's disease (PD), speakers with cerebellar dis-ease (CD), and healthy controls. Vocal performance was measured by intellig-ibility scores and listeners' perceptual ratings. Method: Participants included speakers with hypokinetic dysarthria secondary to PD, those with ataxic dysarthria secondary to CD, and healthy speakers. Partici-pants produced utterances in four vocal modes: spontaneous speech, spoken -to-a-model, sung-to-a-model, and spontaneous singing. For spoken-to-a-model and sung-to-a-model modes, written material was provided the model. For spon-taneous singing, participants sang songs that they endorsed as familiar. Depen-dent variables: In Experiment I, listeners orthographically transcribed the audio samples of the first three vocal modes. In Experiment IIa, raters evaluated the accuracy of the pitch and rhythm of the spontaneous singing of familiar songs. Finally, familiar songs and sung-to-a-model utterances were rated on a compe-tency scale by a second group of raters (Experiment IIb). Results: Results showed increases in intelligibility during the spoken-to-a -model mode compared with the spontaneous mode in both PD and CD groups. Singing enhanced the vocal output of speakers with PD more than in speakers with CD, as measured by percent intelligibility. PD participants' pitch and rhythm accuracy and competency in singing familiar songs was rated more favorably than those produced by CD participants. Conclusions: The findings reveal a vocal task effect for spoken utterances in both groups. Sung exemplars, more impaired in CD, suggest a significant involvement of the cerebellum in singing. Supplemental Material: https://doi.org/10.23641/asha.21809544","2023-01","2025-02-26 20:39:19","2025-02-26 20:39:19","","126-153","","1","66","","","","","","","","","","English","","","","WOS:000925631800009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;101</p>","","","ACOUSTIC ANALYSIS; ARTICULATION RATE; BRAIN; DYSARTHRIA; INTELLIGIBILITY; MULTIPLE-SCLEROSIS; RHYTHMIC AUDITORY-STIMULATION; SPEECH RATE; TASK; VOICE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KTHPZZ3C","journalArticle","2021","Alyahya, RSW; Halai, AD; Conroy, P; Ralph, MAL","Content Word Production during Discourse in Aphasia: Deficits in Word Quantity, Not Lexical-Semantic Complexity","JOURNAL OF COGNITIVE NEUROSCIENCE","","0898-929X","10.1162/jocn_a_01772","","Although limited and reduced connected speech production is one, if not the most, prominent feature of aphasia, few studies have examined the properties of content words produced during discourse in aphasia, in comparison to the many investigations of single-word production. In this study, we used a distributional analysis approach to investigate the properties of content word production during discourse by 46 participants spanning a wide range of chronic poststroke aphasia and 20 neurotypical adults, using different stimuli that elicited three discourse genres (descriptive, narrative, and procedural). Initially, we inspected the discourse data with respect to the quantity of production, lexical-semantic diversity, and psycholinguistic features (frequency and imageability) of content words. Subsequently, we created a ""lexical-semantic landscape,"" which is sensitive to subtle changes and allowed us to evaluate the pattern of changes in discourse production across groups. Relative to neurotypical adults, all persons with aphasia (both fluent and nonfluent) showed significant reduction in the quantity and diversity of production, but the lexical-semantic complexity of word production directly mirrored neurotypical performance. Specifically, persons with aphasia produced the same rate of nouns/verbs, and their discourse samples covered the full range of word frequency and imageability, albeit with reduced word quantity. These findings provide novel evidence that, unlike in other disorders (e.g., semantic dementia), discourse production in poststroke aphasia has relatively preserved lexical-semantic complexity but demonstrates significantly compromised quantity of content word production. Voxel-wise lesion-symptom mapping using both univariate and multivariate approaches revealed left frontal regions particularly the pars opercularis, insular cortex, and central and frontal opercular cortices supporting word retrieval during connected speech, irrespective of their word class or lexical-semantic complexity.","2021-11-05","2025-02-26 20:39:19","2025-02-26 20:39:19","","2494-2511","","12","33","","","","","","","","","","English","","","","WOS:000731690600005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","BRAIN; DEMENTIA; FLUENT; IMPAIRMENT; MODELS; NOUNS; OBJECT; SPONTANEOUS SPEECH; SYSTEM; VERB RETRIEVAL","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R8R94JSC","journalArticle","2021","Kim, JY; Repiso-Puigdelliura, G","Keeping a Critical Eye on Majority Language Influence: The Case of Uptalk in Heritage Spanish","LANGUAGES","","2226-471X","10.3390/languages6010013","","The goal of this study is to highlight the importance of taking into account variations in monolingual grammars before discussing majority language influence as a possible source of heritage speakers' divergent grammars. In this study, we examine the production of uptalk in Spanish by heritage speakers of Mexican Spanish in Southern California. Uptalk (i.e., rising intonation contour at the end of a non-question utterance) is frequently associated with California English. Thus, heritage speakers' use of uptalk is often considered to be influenced from English intonation (i.e., the majority language). Although uptalk in Spanish is not well understood, it has been observed in Mexican Spanish, which calls attention to the importance of investigating uptalk in monolingual Spanish. Using a dyadic interaction task, we obtained spontaneous speech data of 16 heritage speakers and 16 monolingual speakers of Mexican Spanish and compared the phonological and phonetic properties of uptalks produced by the two groups. Our results demonstrated that the heritage speakers and the monolingual speakers produced uptalks with similar frequencies and mainly used L+H* HH% and L* HH% contours. However, the two groups had more differences than similarities. Specifically, heritage speakers' uptalks presented less dynamic contours and were produced with flatter rises than monolinguals' uptalks. Heritage speakers' divergent patterns showed close resemblance with patterns in English, suggesting majority language influence as a valid source of divergence. We discuss possible avenues for future research for a better understanding of the role of majority language influence on heritage Spanish uptalk.","2021-03","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","1","6","","","","","","","","","","English","","","","WOS:000636307600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;8<br/>Total Times Cited:&nbsp;&nbsp;11<br/>Cited Reference Count:&nbsp;&nbsp;105</p>","","","CONTACT; CONTRAST; FOCUS; heritage language intonation; heritage speakers; INTONATION; PERCEPTION; POLAR QUESTIONS; PROSODIC VARIATION; Spanish phonetics and phonology; SPEAKERS; uptalk","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CUNJLNLJ","journalArticle","2021","Bensoussan, Y; Park, C; Johns, M; Brown, S; Pinto, J; Chang, JS; Courey, M","A Comparison of an Artificial Intelligence Tool to Fundamental Frequency as an Outcome Measure in People Seeking a More Feminine Voice","LARYNGOSCOPE","","0023-852X","10.1002/lary.29605","","Objectives/Hypothesis An artificial intelligence (AI) tool was developed using audio clips of cis-male and cis-female voices based on spectral analysis to assess %probability of a voice being perceived as female (%Prob female). This program was validated with 92% accuracy in cisgender speakers. The aim of the study was to assess the relationship of f(o) on %Prob female by a validated AI tool in a cohort of trans females who underwent intervention to feminize their voice with behavioral modification and/or surgery. Study Design Cohort study. Methods Fundamental frequency (f(o)) from prolonged vowel sounds (f(o)/a/) and f(o) from spontaneous speech (f(o)-sp) were measured using the Kay Pentax Computerized Speech Lab (Montvale, NJ) in trans females postintervention. The same voice samples were analyzed by the AI tool for %Prob female. Chi-square analysis and regression models were performed accepting >50% Prob female as female voice. Results Forty-two patients were available for analysis after intervention. f(o)-sp post-treatment was positively correlated with %Prob female (R = 0.645 [P < .001]). Chi-square analysis showed a significant association between AI %Prob female >50% for the speech samples and f(o)-sp >160 Hz (P < .01). Sixteen of 42 patients reached an f(o)-sp >160 Hz. Of these, the AI program only perceived nine patients as female (>50 %Prob female). Conclusion Patients with f(o)-sp >160 Hz after feminization treatments are not necessarily perceived as having a high probability of being female by a validated AI tool. AI may represent a useful outcome measurement tool for patients undergoing gender affirming voice care. Level of Evidence 3 Laryngoscope, 2021","2021-11","2025-02-26 20:39:19","2025-02-26 20:39:19","","2567-2571","","11","131","","","","","","","","","","English","","","","WOS:000648943400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;16</p>","","","affirming voice care; artificial intelligence; gender recognition; gender‐; Transgender females; voice‐","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WRDSIEER","journalArticle","2021","Feenaughty, L; Guo, LY; Weinstock-Guttman, B; Ray, M; Benedict, RHB; Tjaden, K","Impact of Cognitive Impairment and Dysarthria on Spoken Language in Multiple Sclerosis","JOURNAL OF THE INTERNATIONAL NEUROPSYCHOLOGICAL SOCIETY","","1355-6177","10.1017/S1355617720001113","","Objective: To investigate the impact of cognitive impairment on spoken language produced by speakers with multiple sclerosis (MS) with and without dysarthria. Method: Sixty speakers comprised operationally defined groups. Speakers produced a spontaneous speech sample to obtain speech timing measures of speech rate, articulation rate, and silent pause frequency and duration. Twenty listeners judged the overall perceptual severity of the samples using a visual analog scale that ranged from no impairment to severe impairment (speech severity). A 2 x 2 factorial design examined main and interaction effects of dysarthria and cognitive impairment on speech timing measures and speech severity in individuals with MS. Each speaker group with MS was further compared to a healthy control group. Exploratory regression analyses examined relationships between cognitive and biopsychosocial variables and speech timing measures and perceptual judgments of speech severity, for speakers with MS. Results: Speech timing was significantly slower for speakers with dysarthria compared to speakers with MS without dysarthria. Silent pause durations also significantly differed for speakers with both dysarthria and cognitive impairment compared to MS speakers without either impairment. Significant interactions between dysarthria and cognitive factors revealed comorbid dysarthria and cognitive impairment contributed to slowed speech rates in MS, whereas dysarthria alone impacted perceptual judgments of speech severity. Speech severity was strongly related to pause duration. Conclusions: The findings suggest the nature in which dysarthria and cognitive symptoms manifest in objective, acoustic measures of speech timing and perceptual judgments of severity is complex.","2021-05","2025-02-26 20:39:19","2025-02-26 20:39:19","","450-460","","5","27","","","","","","","","","","English","","","","WOS:000651515000005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Articulation disorders; ARTICULATION RATE; Cognitive science; COMPLEXITY; DYSFUNCTION; INDIVIDUALS; INFORMATION; INTELLIGIBILITY; Multiple sclerosis; Neurobehavioral manifestations; Neuropsychology; PARKINSONS-DISEASE; PAUSE CHARACTERISTICS; PROCESSING SPEED; SEVERITY; Speech production measurement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MHWTAIS3","journalArticle","2022","Gazzola, M; Leal, S; Pedroni, B; Rocha, FT; Pompéia, S; Aluísio, S","Text complexity of open educational resources in Portuguese: mixing written and spoken registers in a multi-task approach","LANGUAGE RESOURCES AND EVALUATION","","1574-020X","10.1007/s10579-021-09571-3","","This paper presents a study on text complexity of Open Educational Resources (OER) in Brazilian Portuguese. In a data analysis of the Brazilian Ministry of Education Integrated Platform (MEC-RED) carried out in September 2020, 86% of the resources on the platform did not have any grade level classification, making it difficult to find, use, and expand them. The text complexity task in the Natural Language Processing research area can be used to identify texts that have adequate linguistic complexity for specific grade levels, allowing to complete the stage of education metadata in MEC-RED. However, some types of MEC-RED's resources do not present any information about their stage of education, making it unfeasible to compile a balanced dataset of OER for training a text complexity predictor. This study is driven and enabled by a recently created corpus of transcribed spoken narratives produced by fourth graders to first graders of high school which were collected to evaluate the development of language abilities. A multi-task learning (MTL) approach via hard parameter sharing of hidden layers was adopted to train three models that share all parameters in their hidden layers. The main objective of this study was to explore the relationship between three text complexity tasks by jointly learning to predict text readability, using coarse and fine-grained datasets of written, spoken and domain texts (a small dataset of OER resources) to overcome the lack of grade classified resources in MEC-RED. Our MTL model with two auxiliary tasks presents a F-measure of 0.955, an improvement of 0.15 points over our previous results.","2022-06","2025-02-26 20:39:19","2025-02-26 20:39:19","","621-650","","2","56","","","","","","","","","","English","","","","WOS:000740603200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;36</p>","","","Multi-task learning; Open educational resources; Spontaneous speech; Text complexity; Transcribed narratives","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IYC8ZV77","journalArticle","2023","Alam, N; Munjal, S; Panda, NK; Kumar, R; Gupta, S","Efficacy of Jellow app as an adjunct to stimulation therapy in improvement in language and quality of life in patients with chronic Broca's Aphasia","DISABILITY AND REHABILITATION-ASSISTIVE TECHNOLOGY","","1748-3107","10.1080/17483107.2021.1892844","","Purpose: Stimulation approach is a therapy technique to improve language production using auditory and visual stimulation. Jellow app is a mobile app designed for compensating for impaired language skills and may be used in the intervention of persons with aphasia. The study aimed to determine the benefits of using the Jellow app as a facilitator of stimulus therapy to improve language and psychosocial domains in chronic Broca's Aphasia. Methods: Ten right-handed male adults with Broca's Aphasia were assessed on WAB and SIQOL39g tests. The control group (n = 5) was enrolled only for stimulation therapy. Pictures of objects were used for therapy with the help of auditory or auditory and visual cues. In the study group (n = 5), along with stimulus therapy, subjects were also trained on the use of icons in the Jellow app to facilitate functional communication needs. After six-months tests were readministered. Results: Post-therapy, on WAB, the improvement in spontaneous speech, repetition, and naming were found to be significantly more in the study group (4.6 +/- 0.55, 4.89 +/- 0.56, 5.74 +/- 0.24 respectively) than the control group (2.6 +/- 0.89, 3.22 +/- 0.49, 3.97 +/- 0.3 respectively) on 2-sample t-test. Similarly, significantly more improvement was seen in the communication domain of SAQOL39g in the study group (2.03 +/- 0.17) compared to the control group (1.14 +/- 0.45). Conclusion: Use of the Jellow app may be a beneficial adjunct to stimulation therapy for improving linguistic abilities and quality of life in persons with chronic Broca's aphasia.","2023-07-04","2025-02-26 20:39:19","2025-02-26 20:39:19","","596-602","","5","18","","","","","","","","","","English","","","","WOS:000627263400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;44</p>","","","AAC; Functional communication; HOME; nonfluent Aphasia; quality of life; REHABILITATION; SPEECH; STROKE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WHBLXH7Z","journalArticle","2024","Fromm, D; Dalton, SG; Brick, A; Olaiya, G; Hill, S; Greenhouse, J; Macwhinney, B","The Case of the Cookie Jar: Differences in Typical Language Use in Dementia","JOURNAL OF ALZHEIMERS DISEASE","","1387-2877","10.3233/JAD-230844","","Background:Findings from language sample analyses can provide efficient and effective indicators of cognitive impairment in older adults.Objective:This study used newly automated core lexicon analyses of Cookie Theft picture descriptions to assess differences in typical use across three groups.Methods:Participants included adults without diagnosed cognitive impairments (Control), adults diagnosed with Alzheimer's disease (ProbableAD), and adults diagnosed with mild cognitive impairment (MCI). Cookie Theft picture descriptions were transcribed and analyzed using CLAN.Results:Results showed that the ProbableAD group used significantly fewer core lexicon words overall than the MCI and Control groups. For core lexicon content words (nouns, verbs), however, both the MCI and ProbableAD groups produced significantly fewer words than the Control group. The groups did not differ in their use of core lexicon function words. The ProbableAD group was also slower to produce most of the core lexicon words than the MCI and Control groups. The MCI group was slower than the Control group for only two of the core lexicon content words. All groups mentioned a core lexicon word in the top left quadrant of the picture early in the description. The ProbableAD group was then significantly slower than the other groups to mention a core lexicon word in the other quadrants.Conclusions:This standard and simple-to-administer task reveals group differences in overall core lexicon scores and the amount of time until the speaker produces the key items. Clinicians and researchers can use these tools for both early assessment and measurement of change over time.","2024","2025-02-26 20:39:19","2025-02-26 20:39:19","","1417-1434","","4","100","","","","","","","","","","English","","","","WOS:001402744800002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Alzheimer's disease; ALZHEIMERS-DISEASE; CONNECTED LANGUAGE; CORE LEXICON; DEFICITS; HISTORY; language; mild cognitive impairment; MILD COGNITIVE IMPAIRMENT; PERFORMANCE; PICTURE DESCRIPTION; PROGRESSION; speech; SPONTANEOUS SPEECH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AREBUXTE","journalArticle","2024","Eaton, CT; Thomas, S","To make a long story short: A descriptive study of formulaic language use in post-stroke fluent aphasia","APHASIOLOGY","","0268-7038","10.1080/02687038.2023.2265101","","BackgroundLanguage sample analysis is a common tool for inventorying an individual's linguistic strengths and weaknesses. Although most research has focused on quantifying propositional or novel language production, studies suggest that individuals with aphasia, specifically nonfluent aphasia, produce high percentages of formulaic language relative to healthy controls. To date, little is known about how individuals with fluent aphasia subtypes use formulaic language and how the elicitation task influences their production.AimsThe purpose of this research was to comprehensively describe patterns of formulaic language use in various discourse tasks in language samples of individuals with fluent aphasia.Methods & ProceduresThe retrospective analysis included discourse samples from Aphasiabank from 142 individuals with anomic, conduction, and Wernicke's aphasia across four monologic discourse tasks. After identifying and classifying formulaic items into nine types, percentages of formulaic language were calculated for each participant and discourse task. Non-parametric statistics and Pearson's correlations were used to compare production patterns and explore relationships between language severity and formulaic item types.Outcomes & ResultsUnique patterns of formulaic language were observed across groups including lower proportions of fillers in individuals with Wernicke's aphasia and higher proportions of yes/no variants and speech formulas in individuals with conduction aphasia. Production patterns were most influenced by discourse task in individuals with anomic aphasia. Formulaic language use did not correlate with aphasia severity as measured by aphasia quotient.ConclusionsFindings add to the evidence base describing formulaic language usage in individuals with post-stroke aphasia, which serves as a necessary foundation for eventual clinical application.","2024-07-02","2025-02-26 20:39:19","2025-02-26 20:39:19","","1180-1194","","7","38","","","","","","","","","","English","","","","WOS:001075447900001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","aphasia; DISCOURSE; Formulaic language; LISTENER FAMILIARITY; SPEECH; spontaneous speech","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6YK94Q9D","journalArticle","2023","Castilla-Earls, A; Horne, AOV","Recast Therapy for Treating Syntax in Bilingual Children With Developmental Language Disorder: A Feasibility and Early Efficacy Study Examining the Role of Language of Intervention on Outcomes","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2023_JSLHR-22-00452","","Purpose: The purpose of this study is to examine the feasibility of the delivery of complex syntax recast therapy via telepractice to Spanish-English bilingual children and provide preliminary evidence of the efficacy of this approach. Method: Fifteen bilingual children with developmental language disorders were stratified based on language proficiency and randomized to one of three treatment conditions: Spanish only (n = 5), English only (n = 6), or Spanish + English (n = 4). Using a within-subject design, we hypothesized that we could document treatment efficacy based on change in the treated structure in the absence of change in an untreated comparison structure. All 15 children completed similar to 16 hr of treatment via telepractice and participated in pre- and posttesting of their production of conditional adverbs (treated structure) and subject relative clauses (untreated structure) carried out by a masked assessor. Results: Analyses included all participants. Treatment fidelity was high, and participant attendance was remarkable, indicating feasibility. Regarding efficacy, recast therapy led to group-level gains on treated syntactic structures that exceeded those observed for the untreated comparison structure. For the 11 children who received therapy in only one language, approximately equal gains were observed in both the treated and untreated languages for conditional adverbials. Conclusions: Preliminary evidence suggests that for highly overlapping structures like conditional adverbials, recast therapy is effective and leads to change in both of the child's languages. Larger studies are required to understand how language of administration and proficiency may affect outcomes.","2023-08","2025-02-26 20:39:19","2025-02-26 20:39:19","","2783-2801","","8","66","","","","","","","","","","English","","","","WOS:001056733600015","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;100</p>","","","ACQUISITION; COMPLEXITY; ENGLISH; IMPAIRMENT; LEARNERS; PRESCHOOL; SCHOOL-AGE-CHILDREN; SPANISH-SPEAKING CHILDREN; SPONTANEOUS SPEECH; SUBJECT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GLIDM54V","journalArticle","2023","Oh, C; Morris, R; Wang, XH; Raskin, MS","Analysis of emotional prosody as a tool for differential diagnosis of cognitive impairments: a pilot research","FRONTIERS IN PSYCHOLOGY","","1664-1078","10.3389/fpsyg.2023.1129406","","IntroductionThis pilot research was designed to investigate if prosodic features from running spontaneous speech could differentiate dementia of the Alzheimer's type (DAT), vascular dementia (VaD), mild cognitive impairment (MCI), and healthy cognition. The study included acoustic measurements of prosodic features (Study 1) and listeners' perception of emotional prosody differences (Study 2). MethodsFor Study 1, prerecorded speech samples describing the Cookie Theft picture from 10 individuals with DAT, 5 with VaD, 9 with MCI, and 10 neurologically healthy controls (NHC) were obtained from the DementiaBank. The descriptive narratives by each participant were separated into utterances. These utterances were measured on 22 acoustic features via the Praat software and analyzed statistically using the principal component analysis (PCA), regression, and Mahalanobis distance measures. ResultsThe analyses on acoustic data revealed a set of five factors and four salient features (i.e., pitch, amplitude, rate, and syllable) that discriminate the four groups. For Study 2, a group of 28 listeners served as judges of emotions expressed by the speakers. After a set of training and practice sessions, they were instructed to indicate the emotions they heard. Regression measures were used to analyze the perceptual data. The perceptual data indicated that the factor underlying pitch measures had the greatest strength for the listeners to separate the groups. DiscussionThe present pilot work showed that using acoustic measures of prosodic features may be a functional method for differentiating among DAT, VaD, MCI, and NHC. Future studies with data collected under a controlled environment using better stimuli are warranted.","2023-06-22","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","14","","","","","","","","","","English","","","","WOS:001020046300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;54</p>","","","acoustic analysis; ALZHEIMERS-DISEASE; ARTICULATION; COMMUNICATION; CUES; dementia; DEMENTIA; diagnosis; emotion; listener perception; mild cognitive impairment; PERCEPTION; prosody; SPEECH; VOCAL EXPRESSION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C2S9VADH","journalArticle","2021","Cravotta, A; Prieto, P; Bus, MG","Exploring the effects of restraining the use of gestures on narrative speech","SPEECH COMMUNICATION","","0167-6393","10.1016/j.specom.2021.09.005","","Research on gesture production has emphasized the strong relationship between speech and gesture. Studies have explored whether the inability to gesture is detrimental to speech at different levels. However, findings are still inconclusive and research that focuses on a complete set of acoustic prosodic measures, including F0 and intensity are lacking. Also, studies have used very controlled tasks but evidence is lacking about spontaneous speech. The present study investigates the effects of restraining hand gestures on semi-spontaneous narrative speech. Twenty native Italian speakers described the content of short comic strips to a listener in two conditions: Non-Restraining gestures (N); Restraining gestures (R) (i.e., the speakers had to sit on their hands). The following speech variables were examined: speech length (number of words and speech length in seconds), disfluencies (filled pauses, self-corrections, repetitions, insertions, interruptions) and prosodic properties related to speech rate, F0 and intensity. Overall, the results showed that speakers' inability to gesture does not significantly affect their narrative speech performance in terms of speech length, fluency and acoustic features. When repeating the analysis with the exclusion of the participants who gestured very little in the N condition, however, a slightly different pattern of results emerged; this leaves open the possibility that the inability to gesture may impact individuals differently, depending on the extent to which they rely on gesture when speaking. Further work is needed to shed more light on the role of gestures on the prosodic level of speech production which also takes into account individuals' communicative and cognitive inclinations.","2021-12","2025-02-26 20:39:19","2025-02-26 20:39:19","","25-36","","","135","","","","","","","","","","English","","","","WOS:000712095800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;78</p>","","","Acoustic measures; AIR-FLOW; Disfluency; Fluency; FREQUENCY; HAND GESTURES; INDIVIDUAL-DIFFERENCES; LANGUAGE; LEXICAL RETRIEVAL; MOVEMENTS; Narrative speech; PERSONALITY; Restraining gestures; VOCAL FRY; WORKING-MEMORY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2NACERUZ","journalArticle","2024","van Tellingen, M; Hurkmans, J; Terband, H; van de Zande, AM; Maassen, B; Jonkers, R","Speech and Music Therapy in the Treatment of Childhood Apraxia of Speech: An Introduction and a Case Study","JOURNAL OF SPEECH LANGUAGE AND HEARING RESEARCH","","1092-4388","10.1044/2023_JSLHR-22-00619","","Purpose: Speech-Music Therapy for Aphasia (SMTA), a method that combines speech therapy and music therapy, is introduced as a treatment method for childhood apraxia of speech (CAS). SMTA will be evaluated in a proof-of-principle study. The first case study is presented herein. Method: SMTA was evaluated in a study with a single-subject experimental design comparing 10 weeks of treatment with 2 months of no treatment. The research protocol included a pretest, baseline phase, treatment phase, posttest, no-treatment phase, and follow-up test. The participant was a boy with CAS aged 5;8 (years;months). Outcome measures were selected to reflect both intelligibility in daily communication as well as features of CAS and speech motor planning and programming. Results: Results on the Intelligibility in Context Scale-Dutch (ICS-Dutch) and in the analysis of a spontaneous speech sample suggest generalization of treatment effects. Improvements were found in measures that reflect complex speech motor skills, that is, the production of consonant clusters and consistency. Conclusions: This case study showed that speech production of the participant improved after treatment with SMTA. Although intelligibility as measured with the ICS-Dutch improved over the study period, objectifying changes at the level of intelligibility in daily communication proved to be difficult. Additional measures may be necessary to gain more insight into treatment effects at this level. Overall, the results of this first case study provide sufficient support and important leads for further evaluation of SMTA in the treatment of CAS in a proof-of-principle study.","2024-09","2025-02-26 20:39:19","2025-02-26 20:39:19","","3269-3287","","9","67","","","","","","","","","","English","","","","WOS:001337552200002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","CHILDREN; COMMUNICATION; DEVELOPMENTAL APRAXIA; DYSPROSODY; INTELLIGIBILITY; LANGUAGE; MELODIC INTONATION THERAPY; OUTCOMES; RELIABILITY; VALIDITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AXSKTSLV","journalArticle","2023","Srivastava, A; Selloni, A; Bilgrami, ZR; Sarac, C; Mcgowan, A; Cotter, M; Bayer, J; Spark, J; Krcmar, M; Formica, M; Gwyther, K; Hartmann, J; Ellenberg, E; Polari, A; Mcgorry, P; Shah, JL; Yung, AR; Mizrahi, R; Corcoran, CM; Cecchi, GA; Nelson, B","Differential Expression of Anomalous Self-Experiences in Spontaneous Speech in Clinical High-Risk and Early-Course Psychosis Quantified by Natural Language Processing","BIOLOGICAL PSYCHIATRY-COGNITIVE NEUROSCIENCE AND NEUROIMAGING","","2451-9022","10.1016/j.bpsc.2023.06.007","","BACKGROUND: Basic self-disturbance, or anomalous self-experiences (ASEs), is a core feature of the schizophrenia spectrum. We propose a novel method of natural language processing to quantify ASEs in spoken language by direct comparison to an inventory of self-disturbance, the Inventory of Psychotic-Like Anomalous Self-Experiences (IPASE). We hypothesized that there would be increased similarity in open-ended speech to the IPASE items in individuals with early-course psychosis (PSY) compared with healthy individuals, with clinical high-risk (CHR) individuals intermediate in similarity.METHODS: Open-ended interviews were obtained from 170 healthy control participants, 167 CHR participants, and 89 PSY participants. We calculated the semantic similarity between IPASE items and ""I"" sentences from transcribed speech samples using S-BERT (Sentence Bidirectional Encoder Representation from Text). Kolmogorov-Smirnov tests were used to compare distributions across groups. A nonnegative matrix factorization of cosine similarity was performed to rank IPASE items.RESULTS: Spoken language of CHR individuals had the greatest semantic similarity to IPASE items when compared to both healthy control (s = 0.44, p < 10(-14)) and PSY (s = 0.36, p < 10(-6)) individuals, while IPASE scores were higher among PSY than CHR group participants. In addition, the nonnegative matrix factorization approach produced a data-driven domain that differentiated the CHR group from the others.CONCLUSIONS: We found that open-ended interviews elicited language with increased semantic similarity to the IPASE by participants in the CHR group compared with patients with psychosis. This demonstrates the utility of these methods for differentiating patients from healthy control participants. This complementary approach has the capacity to scale to large studies investigating phenomenological features of schizophrenia and potentially other clinical populations.","2023-10","2025-02-26 20:39:19","2025-02-26 20:39:19","","1005-1012","","10","8","","","","","","","","","","English","","","","WOS:001092027500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;35</p>","","","CORE; PSYCHOPATHOLOGY; SCALE; SCHIZOPHRENIA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3TWUK75R","journalArticle","2021","DeJonckere, P; Lebacq, J","Intraglottal Aerodynamics at Vocal Fold Vibration Onset","JOURNAL OF VOICE","","0892-1997","10.1016/j.jvoice.2019.08.002","","The most frequently observed type of voice onset in spontaneous speech in normal subjects is the soft onset, and it may be considered as the ""physiological"" onset. It starts from an immobile narrow glottal slit crossed by a continuous airflow, and then a few oscillations (even a single one in some cases) precede the first glottal closure. It is a transient event, during which the acting forces, lung pressure, intraglottal pressure, myoelastic tension of the vocal fold (VF) oscillator and inertance of the supraglottal vocal tract, interact to progressively reach the steady state of a sustained oscillation. Combined measurements of flow, area, and pressure provide a detailed qualitative and quantitative analysis of the intraglottal mechanical events at the precise moment of starting oscillation in a physiological (soft or soft/breathy) onset. Our in vivo measurements of airflow and glottal area show that the very first oscillation occurs exactly at the time when turbulence appears at the level of the glottal narrowing, ie, when the Reynolds number reaches its critical value. The turbulence may be assumed to trigger an oscillator consisting in the ensemble of the VFs and the air of the vocal tract, which is known to be weakly damped. Turbulence can act here as an aspecific flick, triggering the oscillator, the frequency of oscillation being determined by its mechanical properties. Furthermore, the first noticeable glottal oscillations are sinusoidal: the VFs are neither steeply sucked together by a negative Bernoulli pressure, nor burst apart by the lung pressure. Our measurements show that, at the critical time, the rising positive lung pressure is balanced by the rising negative Bernoulli pressure generated by the transglottal flow.","2021-01","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","1","35","","","","","","","","","","English","","","","WOS:000616864700022","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;22</p>","","","Bernoulli; DYNAMICS; Intraglottal pressure; PARAMETERS; PRESSURE MEASUREMENTS; Reynolds number; Turbulence; Vocal onset","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CRDG3MT9","journalArticle","2024","Graziano, M; Gullberg, M","Providing evidence for a well-worn stereotype: Italians and Swedes do gesture differently","FRONTIERS IN COMMUNICATION","","2297-900X","10.3389/fcomm.2024.1314120","","Across cultures and languages spontaneous speech is often accompanied by gestures. It is a popular belief that people in Italy gesture more than people in Northern Europe, such as in Sweden. Despite this general assumption few studies empirically investigate cultural differences in gesture frequency and gesture function under similar circumstances. This study compares the spoken and gestural behaviours of Italian and Swedish speakers, assumed to represent gesture-rich vs. gesture-sparse cultures. We examine the groups' gestural behaviour for frequency, and in terms of possible differences in rhetorical style probing the distribution of gestural functions (referential vs. pragmatic) across narrative levels (narrative, metanarrative, and paranarrative). The results show that (1) Italians overall do gesture more than Swedes; (2) Italians produce more pragmatic gestures than Swedes who produce more referential gestures; (3) both groups show sensitivity to narrative level: referential gestures mainly occur with narrative clauses, and pragmatic gestures with meta- and paranarrative clauses. However, the overall group preferences for different functions still lead to different styles. These findings indicate that the two groups differ in gesture rate and, more interestingly, in rhetorical styles, one focused on events and actions in speech and gesture (Swedish), the other alternating between events in speech and gesture, and the highlighting of the presentation of new pieces of information in gesture only (Italian). We propose that the findings suggest that the two groups conceptualise narrative production in different ways reflected in two different rhetorical styles revealed by gesture production more than by speech.","2024-03-26","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","9","","","","","","","","","","English","","","","WOS:001198343000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","AMERICAN; bimodal narrative; CHINESE; COMMUNICATION; crosscultural/linguistic differences; DISCOURSE; FREQUENCY; gesture; INFORMATION STATUS; LANGUAGE; REPRESENTATION; rhetorical styles; SPEECH; speech production","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A3KBBJA8","journalArticle","2022","Stark, BC; Cofoid, C","Task-Specific Iconic Gesturing During Spoken Discourse in Aphasia","AMERICAN JOURNAL OF SPEECH-LANGUAGE PATHOLOGY","","1058-0360","10.1044/2021_AJSLP-20-00271","","Purpose: In persons living with aphasia, we will explore the relationship between iconic gesture production during spontaneous speech and discourse task, spoken language, and demographic information. Method: Employing the AphasiaBank database, we coded iconic gestures in 75 speakers with aphasia during two spoken discourse tasks: a procedural narrative, which involved participants telling the experimenter how to make a sandwich (""Sandwich""), and a picture sequence narrative, which had participants describe the picture sequence to the experimenter (""Window""). Forty-three produced a gesture during both tasks, and we further evaluate data from this subgroup as a more direct comparison between tasks. Results: More iconic gestures, at a higher rate, were produced during the procedural narrative. For both tasks, there was a relationship between iconic gesture rate, modeled as iconic gestures per word, and metrics of language dysfluency extracted from the discourse task as well as a metric of fluency extracted from a standardized battery. Iconic gesture production was correlated with aphasia duration, which was driven by performance during only a single task (Window), but not with other demographic metrics, such as aphasia severity or age. We also provide preliminary evidence for task differences shown through the lens of two types of iconic gestures. Conclusions: While speech-language pathologists have utilized gesture in therapy for poststroke aphasia, due to its possible facilitatory role in spoken language, there has been considerably less work in understanding how gesture differs across naturalistic tasks and how we can best utilize this information to better assess gesture in aphasia and improve multimodal treatment for aphasia. Furthermore, our results contribute to gesture theory, particularly, about the role of gesture across naturalistic tasks and its relationship with spoken language.","2022-01","2025-02-26 20:39:19","2025-02-26 20:39:19","","30-47","","1","31","","","","","","","","","","English","","","","WOS:000745047800004","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;10<br/>Total Times Cited:&nbsp;&nbsp;12<br/>Cited Reference Count:&nbsp;&nbsp;75</p>","","","ADULTS; CO-SPEECH GESTURES; COMMUNICATION; HAND GESTURES; LANGUAGE; MOVEMENTS; PEOPLE; RIGHT-HEMISPHERE; SPEAKERS; TELL US","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VLWR7PHP","journalArticle","2021","Basilico, S; Ciricugno, A; Gelosa, G; Magnani, FG; Mosca, L; Popescu, C; Garibotto, V; Sberna, M; Paulesu, E; Bottini, G","Clinical Characterization of Atypical Primary Progressive Aphasia in a 3-Year Longitudinal Study: A Case Report","COGNITIVE AND BEHAVIORAL NEUROLOGY","","1543-3633","10.1097/WNN.0000000000000273","","The logopenic variant of primary progressive aphasia (lvPPA) is the most recent variant of primary progressive aphasia (PPA) to be identified; thus far, it has been poorly investigated. Despite being typically associated with Alzheimer disease (AD), lvPPA has recently been linked to frontotemporal lobe degeneration (FTLD), with distinctive cognitive and neural features that are worthy of further investigation. Here, we describe the neuropsychological and linguistic profile, as well as cerebral abnormalities, of an individual exhibiting PPA and carrying a pathogenetic variant in the GRN gene, from a 3-year longitudinal perspective. The individual's initial profile resembled lvPPA because it was characterized by word-finding difficulties and phonological errors in spontaneous speech in addition to sentence repetition and phonological short-term memory impairments. The individual's structural and metabolic imaging data demonstrated left temporal and bilateral frontal atrophy and hypometabolism, respectively. On follow-up, as the pathology progressed, dysprosody, stereotypical speech patterns, agrammatism, and orofacial apraxia appeared, suggesting an overlap with the nonfluent variant of PPA (nfvPPA). Severe sentence comprehension impairment also became evident. Our longitudinal and multidisciplinary diagnostic approach allowed us to better characterize the progression of a GRN-positive lvPPA profile, providing neuropsychological and imaging indicators that might be helpful to improve classification between different PPA variants and to address a nosological issue. Finally, we discuss the importance of early diagnosis of PPA given the possible overlap between different PPA variants during the progression of the pathology.","2021-09","2025-02-26 20:39:19","2025-02-26 20:39:19","","233-244","","3","34","","","","","","","","","","English","","","","WOS:000696558000010","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;64</p>","","","3 VARIANTS; ALZHEIMERS; DEMENTIA; EPISODIC BUFFER; FRONTAL ASSESSMENT BATTERY; frontotemporal lobar degeneration; FRONTOTEMPORAL LOBAR DEGENERATION; LANGUAGE; logopenic; longitudinal; MINI-MENTAL-STATE; MRI; neuropsychological assessment; NORMATIVE VALUES; PATHOLOGY; PET; primary progressive aphasia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"58PHTISE","journalArticle","2024","Wang, W; Motagh, M; Xia, ZG; Plank, S; Li, Z; Orynbaikyzy, A; Zhou, C; Roessner, S","A framework for automated landslide dating utilizing SAR-Derived Parameters Time-Series, An Enhanced Transformer Model, and Dynamic Thresholding","INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION","","1569-8432","10.1016/j.jag.2024.103795","","Determining the timing of landslide occurrence is crucial for establishing an accurate, comprehensive and systematic landslide inventory while assessing the potential for reducing landslide risk. Unfortunately, many existing landslide inventories lack temporal information such as the precise time of landslide events. Optical and Synthetic Aperture Radar (SAR) sensors are the most commonly used remote sensing technologies for landslide detection. Unlike optical sensors, SAR sensors are not affected by cloudy conditions and provide valuable imagery regardless of sunlight availability. Therefore, SAR-derived parameters, i.e., SAR amplitude, interferometric coherence, and polarimetric features (alpha and entropy), offer a higher temporal resolution for detecting landslide occurrence times compared to optical data. Despite the advantages, there is currently no universally accepted automatic method for determining the time of landslide events using SAR data. This is due to the lack of anomaly labels and the high time -series volatility in detecting landslide occurrence times. Despite advances in deep -learning methods for anomaly detection in time -series, only a few of them can address these challenges in our case. In this paper, we propose an unsupervised multivariate transformed -based deep -learning model to automatically and efficiently estimate landslide occurrence times using multivariate SAR-derived parameters time -series analysis. The designed gated relative position can increase robustness and temporal context information, by learning global temporal trends in the time -series. Subsequently, the time -series of the anomaly score derived from the proposed Transformer model is analyzed using an adaptive thresholding strategy to dynamically and automatically mark anomalies related to the landslide occurrence. Our research focuses on collapsed landslides characterized by dramatic changes in ground surface topography, with a particular attention for the need of a prior knowledge about landslide boundaries. We assess the performance of the proposed methodology for several collapsed landslides including the July 21, 2020 Shaziba and 23 July, 2019 Shuicheng landslides in China, March 19, 2019 Takht landslide in Iran, June 15, 2018 Jalgyz-Jangak and May 25, 2018 Kugart landslides in Kyrgyzstan, July 7, 2018 Hitardalur landslide in Iceland, and January 25, 2019 Brumadinho landslide in Brazil. In comparison to commonly used neural networks like the LSTM algorithm, our proposed framework leads to a more accurate estimate for the time of landslide failure using time -series of SAR-derived parameters. Furthermore, our results suggest the great potential of SAR data to narrow the time period detected from optical data when used in conjunction with them.","2024-05","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","129","","","","","","","","","","English","","","","WOS:001224354800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;66</p>","","","Anomaly detection; AREAS; COHERENCE; DECORRELATION; Deep-learning; INVERSION; Landslide; MULTITEMPORAL SAR; POLARIMETRIC SCATTERING; ROUGHNESS; SAR; SATELLITE; SOIL-MOISTURE RETRIEVAL; SYNTHETIC-APERTURE RADAR","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R33JDWGW","journalArticle","2023","Wei, WY; Fu, XS; Zhu, YQ; Lu, N; Ma, SQ","Classification and Prediction of Driver's Mental Workload Based on Long Time Sequences and Multiple Physiological Factors","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3300721","","The driver's mental workload is closely related to driving safety. However, how to analyze the driver's mental workload in a reasonable and correct manner remains an open question. As an important factor to evaluate mental workload, changes in physiology encounter two clear problems: (1) Physiological factor contains multi-characteristic indicators, there is a lack of reasonable means for synchronizing multi-dimensional tabular data, and the limits of tabular data processing in the evaluation of mental workload have a significant impact on the evaluation results. (2) The physiological data obtained during the driving process are of the time-series variety. The correlation of numerous indicators must be considered in time-series data correlation analysis. Mental workload should be the result of multiple indicators interacting over time, rather than a single instant. In this regard, we propose a model, that is the long time sequences and multiple physiological factors(LTS-MPF), for classifying and predicting multiple physiological changes in the time series. In contrast to previous methods of processing data in a single instant, LTS-MPF can directly analyze all time-series factors that may affect the driver's mental workload during a time interval, such as Heart rate growth, Heart rate variability, and Electrodermal activity, and so on. Furthermore, LTS-MPF can predict the driver's mental workload in the next 1s as well as classify the current sequence's results. Specifically, we collect physiological data from drivers via sensors. These collected data are processed and transformed into tabular data. The table's columns represent features, while the rows represent all feature data at one moment in time. The row order also indicates the forward and backward order of the different moments. We convert each row in this table into an embedding feature and feed the entire table into our proposed LTS-MPF based on the Transformer model. The LTS-MPF achieves time series correlation while eliminating column feature series irrelevance. The experiment results reveal that LTS-MPF exceeds earlier techniques in forecasting the driver's mental workload, with an accuracy of up to 94.3%. And its accuracy in predicting mental workload in the future for one second can reach 93.5%. These findings suggest that LTS-MPF can be utilized to not only better evaluate a driver's mental workload in the present, but also in the future, providing solid data for early warning of dangerous driving behaviors and enhancing driving safety.","2023","2025-02-26 20:39:19","2025-02-26 20:39:19","","81725-81736","","","11","","","","","","","","","","English","","","","WOS:001047258400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","Driver's mental workload; HEART-RATE; long time sequences and multiple physio-logical factors; physiological factor; RESPONSES; tabular data; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"38XT59DT","journalArticle","2024","Khoruzhaya, AN; Kozlov, DV; Arzamasov, KM; Kremneva, EI","Comparison of an Ensemble of Machine Learning Models and the BERT Language Model for Analysis of Text Descriptions of Brain CT Reports to Determine the Presence of Intracranial","SOVREMENNYE TEHNOLOGII V MEDICINE","","2076-4243","10.17691/stm2024.16.1.03","","The aim of this study is to train and test an ensemble of machine learning models, as well as to compare its performance with the BERT language model pre -trained on medical data to perform simple binary classification, i.e., determine the presence/absence of the signs of intracranial hemorrhage (ICH) in brain CT reports. Materials and Methods. Seven machine learning algorithms and three text vectorization techniques were selected as models to solve the binary classification problem. These models were trained on textual data represented by 3980 brain CT reports from 56 inpatient medical facilities in Moscow. The study utilized three text vectorization techniques: bag of words, TF-IDF, and Word2Vec. The resulting data were then processed by the following machine learning algorithms: decision tree, random forest, logistic regression, nearest neighbors, support vector machines, Catboost, and XGboost. Data analysis and pre-processing were performed using NLTK (Natural Language Toolkit, version 3.6.5), libraries for character -based and statistical processing of natural language, and Scikit-learn (version 0.24.2), a library for machine learning containing tools to tackle classification challenges. MedRuBertTiny2 was taken as a BERT transformer model pre -trained on medical data. Results. Based on the training and testing outcomes from seven machine learning algorithms, the authors selected three algorithms that yielded the highest metrics (i.e. sensitivity and specificity): CatBoost, logistic regression, and nearest neighbors. The highest metrics were achieved by the bag of words technique. These algorithms were assembled into an ensemble using the stacking technique. The sensitivity and specificity for the validation dataset separated from the original sample were 0.93 and 0.90, respectively. Next, the ensemble and the BERT model were trained on an independent dataset containing 9393 textual radiology reports also divided into training and test sets. Once the ensemble was tested on this dataset, the resulting sensitivity and specificity were 0.92 and 0.90, respectively. The BERT model tested on these data demonstrated a sensitivity of 0.97 and a specificity of 0.90. Conclusion. When analyzing textual reports of brain CT scans with signs of intracranial hemorrhage, the trained ensemble demonstrated high accuracy metrics. Still, manual quality control of the results is required during its application. The pre -trained BERT transformer model, additionally trained on diagnostic textual reports, demonstrated higher accuracy metrics (p<0.05). The results show promise in terms of finding specific values for both binary classification task and in-depth analysis of unstructured medical information.","2024","2025-02-26 20:39:19","2025-02-26 20:39:19","","27-34","","1","16","","","","","","","","","","English","","","","WOS:001178880600002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;27</p>","","","BERT; computed tomography; diagnostic reports; intracranial hemorrhage; machine learning; natural language processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6G62BIBA","journalArticle","2024","Jahin, MA; Shovon, MSH; Mridha, MF; Islam, MR; Watanobe, Y","A hybrid transformer and attention based recurrent neural network for robust and interpretable sentiment analysis of tweets","SCIENTIFIC REPORTS","","2045-2322","10.1038/s41598-024-76079-5","","Sentiment analysis is a pivotal tool in understanding public opinion, consumer behavior, and social trends, underpinning applications ranging from market research to political analysis. However, existing sentiment analysis models frequently encounter challenges related to linguistic diversity, model generalizability, explainability, and limited availability of labeled datasets. To address these shortcomings, we propose the Transformer and Attention-based Bidirectional LSTM for Sentiment Analysis (TRABSA) model, a novel hybrid sentiment analysis framework that integrates transformer-based architecture, attention mechanism, and recurrent neural networks like BiLSTM. The TRABSA model leverages the powerful RoBERTa-based transformer model for initial feature extraction, capturing complex linguistic nuances from a vast corpus of tweets. This is followed by an attention mechanism that highlights the most informative parts of the text, enhancing the model's focus on critical sentiment-bearing elements. Finally, the BiLSTM networks process these refined features, capturing temporal dependencies and improving the overall sentiment classification into positive, neutral, and negative classes. Leveraging the latest RoBERTa-based transformer model trained on a vast corpus of 124M tweets, our research bridges existing gaps in sentiment analysis benchmarks, ensuring state-of-the-art accuracy and relevance. Furthermore, we contribute to data diversity by augmenting existing datasets with 411,885 tweets from 32 English-speaking countries and 7,500 tweets from various US states. This study also compares six word-embedding techniques, identifying the most robust preprocessing and embedding methodologies crucial for accurate sentiment analysis and model performance. We meticulously label tweets into positive, neutral, and negative classes using three distinct lexicon-based approaches and select the best one, ensuring optimal sentiment analysis outcomes and model efficacy. Here, we demonstrate that the TRABSA model outperforms the current seven traditional machine learning models, four stacking models, and four hybrid deep learning models, yielding notable gain in accuracy (94%) and effectiveness with a macro average precision of 94%, recall of 93%, and F1-score of 94%. Our further evaluation involves two extended and four external datasets, demonstrating the model's consistent superiority, robustness, and generalizability across diverse contexts and datasets. Finally, by conducting a thorough study with SHAP and LIME explainable visualization approaches, we offer insights into the interpretability of the TRABSA model, improving comprehension and confidence in the model's predictions. Our study results make it easier to analyze how citizens respond to resources and events during pandemics since they are integrated into a decision-support system. Applications of this system provide essential assistance for efficient pandemic management, such as resource planning, crowd control, policy formation, vaccination tactics, and quick reaction programs.","2024-10-22","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","1","14","","","","","","","","","","English","","","","WOS:001340425900006","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","Attention-based BiLSTM; LIME; RoBERTa Transformer; SHAP; Tweet Sentiment Analysis; Unsupervised Labeling; XAI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N6T36LBN","journalArticle","2025","Carunta, C; Carunta, A; Popa, CA","Heavy and Lightweight Deep Learning Models for Semantic Segmentation: A Survey","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2025.3529812","","Semantic segmentation is an important computer vision task due to its numerous real-world applications such as autonomous driving, video surveillance, medical image analysis, robotics, augmented reality, among others, and its popularity increased with the development of deep learning approaches. We provide a detailed review comprising the most significant methods for both heavy and lightweight two-dimensional (2D) semantic segmentation, starting with the introduction of convolutional neural networks until the use of Transformer architecture, the latter being a widely adopted model with state-of-the-art results in several artificial intelligence fields. The methods involved are described from the architectural design perspective, including encoder-decoder architectures, multi-resolution branches approaches, two-pathway encoder architectures, attention-based models, and pyramid-based models. Additionally, some of the most popular datasets and performance metrics are presented. Further, we investigate the limitations of these methods, compare their performance on Pascal VOC 2012, Cityscapes, and ADE20K datasets, and finally indicate future research directions.","2025","2025-02-26 20:39:19","2025-02-26 20:39:19","","17745-17765","","","13","","","","","","","","","","English","","","","WOS:001410357500014","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;236</p>","","","AGGREGATION; ALGORITHM; Complex deep learning models; Computer architecture; CONTEXT; Context modeling; convolutional neural networks; Convolutional neural networks; DECODER; Deep learning; DISEASE; Feature extraction; FUSION NETWORK; Image resolution; real-time models; semantic segmentation; Semantic segmentation; Semantics; Surveys; Training; TRANSFORMER; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NA9ASJZA","journalArticle","2024","Liu, YX; Luo, Y; Lu, X; Gao, H; He, RK; Zhang, X; Zhang, XG; Li, YX","Genotypic-phenotypic landscape computation based on first principle and deep learning","BRIEFINGS IN BIOINFORMATICS","","1467-5463","10.1093/bib/bbae191","","The relationship between genotype and fitness is fundamental to evolution, but quantitatively mapping genotypes to fitness has remained challenging. We propose the Phenotypic-Embedding theorem (P-E theorem) that bridges genotype-phenotype through an encoder-decoder deep learning framework. Inspired by this, we proposed a more general first principle for correlating genotype-phenotype, and the P-E theorem provides a computable basis for the application of first principle. As an application example of the P-E theorem, we developed the Co-attention based Transformer model to bridge Genotype and Fitness model, a Transformer-based pre-train foundation model with downstream supervised fine-tuning that can accurately simulate the neutral evolution of viruses and predict immune escape mutations. Accordingly, following the calculation path of the P-E theorem, we accurately obtained the basic reproduction number (${R}_0$) of SARS-CoV-2 from first principles, quantitatively linked immune escape to viral fitness and plotted the genotype-fitness landscape. The theoretical system we established provides a general and interpretable method to construct genotype-phenotype landscapes, providing a new paradigm for studying theoretical and computational biology.","2024-05-02","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","3","25","","","","","","","","","","English","","","","WOS:001273737500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;24</p>","","","CONVERGENT EVOLUTION; deep learning; genotype-fitness landscape; immune escape; interpretability; SARS-CoV-2; the relative basic reproduction number (R0)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BPP3JRS4","journalArticle","2023","Helali, H; Khedher, A","Performance study of control strategies applied to smart transformer model based on a five-level cascaded H-bridge rectifier","COMPUTERS & ELECTRICAL ENGINEERING","","0045-7906","10.1016/j.compeleceng.2023.108864","","This paper proposes a Smart transformer (ST) model comprising a five-level Cascaded H-Bridge (CHB) rectifier at its medium voltage stage, dual active bridge converters at its high-frequency stage, and a four-leg inverter at its low voltage stage. Indeed, the CHB rectifier enables the improvement of ST modularity and the integration of many Renewable Energy Sources (RESs). Nevertheless, the high integration of RESs can lead to voltage fluctuations due to their intermittent energy production which can affect the ST behavior. Therefore, a robust controller is required to improve the ST's dynamic performance. In this context, vector-oriented control, Sliding Mode Control (SMC), and adaptive backstepping control are studied in this paper. To select the most appropriate controllers, a series of simulations under anomalous conditions, including voltage variations, parametric variations, and fault occurrence, are performed using Matlab software. The obtained simulation results demonstrate that SMC provides the best performance and the greatest robustness.","2023-09","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","110","","","","","","","","","","English","","","","WOS:001047445400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;18</p>","","","Adaptive backstepping control; Cascaded H -bridge converter; Dual active bridge converter; Faults; Four -leg inverter; Parametric variations; Sliding mode control; Smart transformer; Vector -oriented control; Voltage variations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MCWG62T6","journalArticle","2023","Wang, JY; Li, Y; Li, P; Wang, XB; Yu, ZY; Meng, TN","Analysis of temperature characteristics of power transformer withstand short circuit shock for two seconds","ENERGY REPORTS","","2352-4847","10.1016/j.egyr.2023.05.210","","The occurrence of a short-circuit fault in a transformer results in a rapid increase in the short-circuit current, and the temperature of the transformer winding rises rapidly. At present, many scholars use analytical formulas to solve for the average temperature of transformer short-circuit for two seconds, but the transient change of the temperature of transformer short-circuit for two seconds is less considered. In order to counter this phenomenon, this paper establishes a two-dimensional planar power transformer model, simulates its fluid-temperature coupling field, and obtains its temperature distribution results. In this thesis, the steady-state fluid-temperature field of 40 000 kVA/110 kV oil-immersed power transformers under rated working condition is analyzed. Secondly, on the basis of static analysis, the temperature characteristics after two seconds of short circuit is analyzed numerically. Finally, by comparing the simulated value with the formula calculation value, the calculation results were verified. (c) 2023 The Authors. Published by Elsevier Ltd. This is an open access article under the CCBY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).","2023-10","2025-02-26 20:39:19","2025-02-26 20:39:19","","1049-1059","","","9","","","","","","","","","","English","","","","WOS:001124237300114","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;11</p>","","","FLUID-FLOW; Fluid-temperature field; HEAT-TRANSFER; Numerical analysis; Oil-immersed transformer; Temperature characteristics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z9M795JG","journalArticle","2022","Jia, X; Wang, YB; Peng, YX; Chen, SY","Semantic association enhancement transformer with relative position for image captioning","MULTIMEDIA TOOLS AND APPLICATIONS","","1380-7501","10.1007/s11042-022-12776-5","","Transformer-based architectures have shown encouraging results in image captioning. They usually utilize self-attention based methods to establish the semantic association between objects in an image for predicting caption. However, when appearance features between the candidate object and query object show weak dependence, the self-attention based methods are hard to capture the semantic association between them. In this paper, a Semantic Association Enhancement Transformer model is proposed to address the above challenge. First, an Appearance-Geometry Multi-Head Attention is introduced to model a visual relationship by integrating the geometry features and appearance features of the objects. The visual relationship characterizes the semantic association and relative position among the objects. Secondly, a Visual Relationship Improving module is presented to weigh the importance of appearance feature and geometry feature of query object to the modeled visual relationship. Then, the visual relationship among different objects is adaptively improved according to the constructed importance, especially the objects with weak dependence on appearance features, thereby enhancing their semantic association. Extensive experiments on MS COCO dataset demonstrate that the proposed method outperforms the state-of-the-art methods.","2022-06","2025-02-26 20:39:19","2025-02-26 20:39:19","","21349-21367","","15","81","","","","","","","","","","English","","","","WOS:000769256200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;6<br/>Total Times Cited:&nbsp;&nbsp;6<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","ATTENTION; Image captioning; Relative position; Semantic connection; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MHSRE6V9","journalArticle","2025","Xiao, YN; Pu, Q; Wang, CX; Jia, XT; Sun, SX; Jin, Q; Wang, XL; Wang, B; Sun, P; Liu, FM; Lu, GY","Wearable Self-Powered Pressure Sensors Based on alk-Ti3C2Tx Regulating Contact Barrier Difference for Noncontact Motion Object Recognition","ADVANCED SCIENCE","","2198-3844","10.1002/advs.202416504","","Wearable self-powered pressure sensors present tremendous potential for object recognition. However, the fluctuated approach speed and distance may compromise the device output, thus affecting the recognition accuracy. Herein, a wearable self-powered pressure sensor with high sensitivity (1.48 V kPa(-1)), high output (130.5V), and high permeability (259.98 mm s(-1)) are developed where the contact barrier difference and triboelectric charge density of the triboelectric layer surface are dynamically regulated by modulating the surface groups resulting in a lower dielectric loss and higher output. The sensor leverages the polarity difference between the target object and the sensitive material to generate electrical signals at different speeds and distances through an electrostatic induction mechanism. With the assistance of the Transformer model with a self-attention mechanism, an average recognition accuracy of 94.3% is achieved by acquiring sensing signals at different speeds and distances. Simulating the ability of human vision, enables visually impaired people to acclimate to their surroundings more easily and independently and provides a critical advancement in the assistance of the blind with daily life.","2025-02-07","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","","","","","","","","","","","English","","","","WOS:001416317400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","alk-Ti3C2Tx; contact barrier difference regulation; motion object recognition; noncontact sensing; self-powered pressure sensor; TRIBOELECTRIC NANOGENERATOR","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VM49QIQZ","journalArticle","2024","Wu, P; Fang, XW; Fang, H; Gong, ZY; Kan, DY","An Event Log Repair Method Based on Masked Transformer Model","APPLIED ARTIFICIAL INTELLIGENCE","","0883-9514","10.1080/08839514.2024.2346059","","The effectiveness of business process analysis heavily relies on the quality of event logs. However, the presence of outliers and missing values often compromises the integrity of event logs, consequently exerting adverse effects on process analysis and associated decision-making. Existing log repair research mainly focuses on the reconstruction of missing activity, whereas few efforts are carried out from the perspective of predicting missing activity. This paper introduces a log repair approach based on a masked Transformer, which innovatively combines the self-attention mechanism of Transformers with the task of event log repair. Firstly, by employing various masking strategies, we simulate diverse low-quality event log scenarios that may occur in practical situations. Subsequently, a Masked Language Model is trained on preprocessed datasets to predict masked activities by leveraging contextual information within traces, thereby capturing behavioral information of activities in the event log. Upon completion of model training, we apply it to real event log data for repair tasks. The proposed approach, originating from the perspective of event logs, does not rely on any a priori knowledge related to business process models for generating event logs. Experimental results demonstrate that the masked Transformer-based approach outperforms baseline methods in most event log repair tasks.","2024-12-31","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","1","38","","","","","","","","","","English","","","","WOS:001222855000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;53</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M2YPS2HX","journalArticle","2024","Liu, RS; Zayed, T; Xiao, R; Hu, QF","Time-Transformer for acoustic leak detection in water distribution network","JOURNAL OF CIVIL STRUCTURAL HEALTH MONITORING","","2190-5452","10.1007/s13349-024-00845-2","","Accurate leak detection for water distribution networks (WDNs) is a critical task to minimize water loss and ensure efficient infrastructure management. Machine learning (ML) algorithms have demonstrated significant potential in establishing effective acoustic leak detection systems. However, the utilization of time-series models, specifically designed to handle sequential signals, in the field of water leak detection remains relatively unexplored, and there is a lack of research discussing their applicability in this context. Therefore, this study introduces a novel approach for precise leak detection in WDNs using a Time-Transformer model, which effectively captures long-range dependencies through self-attention mechanisms, enabling it to outperform other time-series models. This study conducted field experiments on WDNs in Hong Kong to demonstrate the superior performance of the proposed approach in accurately detecting leaks. The model structure is optimized through parametric experiments. Besides, leak detection and t-SNE results highlight the model's significant potential to enhance leak detection in WDNs compared to 1D-CNN and CNN-LSTM. The proposed Transformer-based model shows significant potential in advancing leak detection in WDNs, improving accuracy and precision, and supporting efficient water management.","2024-08-27","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","","","","","","","","","","","English","","","","WOS:001298766600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;62</p>","","","Acoustic leak detection; Machine learning; NOISE; PIPES; SIGNALS; Transformer; Water distribution networks; WAVE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JBKJETH6","journalArticle","2024","Varanasi, LNS; Karri, SPK","STNILM: Switch Transformer based Non-Intrusive Load Monitoring for short and long duration appliances","SUSTAINABLE ENERGY GRIDS & NETWORKS","","2352-4677","10.1016/j.segan.2023.101246","","Non-Intrusive Load Monitoring (NILM) is a technique used by contemporary energy management systems to predict and optimize appliance load distribution in real time. The real-time reduction of energy consumption and improvement of electricity efficiency are two major benefits of energy disaggregation. Transformer models have made NILM far better at forecasting device power values. Due to the absence of inductive bias in the local context, transformers may not be able to capture local signal patterns in sequence-to-point settings. In this work, we present a Switch Transformer based Non-Intrusive Load Monitoring (STNILM). STNILM utilizes switching and routing layers by replacing the vanilla transformer final layers to accurately estimate the power signals of short and long duration domestic appliances. It also uses self attention mechanisms to extract global dependencies between the aggregate and the domestic appliance signals. STNILM works with minimal dataset pre-processing and unbalanced. With extensive experiments and quantitative analysis, we demonstrate the efficiency and effectiveness of the proposed STNILM with considerable improvements in terms of accuracy and F1-score compared to state-of-the-art baselines.","2024-03","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","37","","","","","","","","","","English","","","","WOS:001144080300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Deep learning algorithm; DISAGGREGATION; Energy disaggregation; Non-Intrusive Load Monitoring (NILM); Sequence-to-sequence learning; TIME; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y2KNTTZS","journalArticle","2024","Chen, TH; Li, YY; Qiao, QH","Fine-grained bird image classification based on counterfactual method of vision transformer model","JOURNAL OF SUPERCOMPUTING","","0920-8542","10.1007/s11227-023-05701-6","","The accurate identification of bird image is of great significance to protecting the ecological environment and bird species diversity. To address the issue of low recognition accuracy arising from the similarities in features among different bird species and the susceptibility of shallow edge features to loss, this paper proposes a fine-grained bird image classification model that incorporates hierarchical feature fusion and counterfactual feature selection. The model is based on vision transformer and builds a hierarchical feature fusion module and a counterfactual feature enhancement module. The hierarchical feature fusion module superimposes shallow features rich in fine-grained information into deep features to improve the problem of lack of edge detail information in key features. The counterfactual feature enhancement module selects distinguishing features through counterfactual intervention to reduce classification errors caused by highly similar features of different species of birds. The experimental results show that the method can achieve 91.9% and 91.4% accuracy on two available datasets, CUB-200-2011 and NABirds, respectively, which is higher than the current mainstream fine-grained bird recognition algorithms and shows excellent classification performance.","2024-03","2025-02-26 20:39:19","2025-02-26 20:39:19","","6221-6239","","5","80","","","","","","","","","","English","","","","WOS:001087717000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;50</p>","","","Bird image classification; Deep learning; Fine-grained visual classification; Vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BVSHGU9G","journalArticle","2024","Zhu, YL; Li, M; Ma, X; Wang, YF; Li, GL; Zhang, Y; Liu, YL; Hassanien, RHE","Solar irradiance prediction with variable time lengths and multi-parameters in full climate conditions based on photovoltaic greenhouse","ENERGY CONVERSION AND MANAGEMENT","","0196-8904","10.1016/j.enconman.2024.118758","","Photovoltaic power generation can provide energy for greenhouses and achieve high quality and high yield of crops. In reality, solar irradiance is fluctuating and intermittent. Thus, the key to ensure efficient photovoltaic power use under greenhouse environmental conditions is to provide an accurate prediction of solar irradiance. Yet, currently studies on irradiance prediction in terms of the variable time lengths, multi-parameter and full climate conditions are rather limited. To improve the comprehensive performance of the prediction model, this paper proposes models of irradiance time series prediction such as Pyraformer, Informer, Transformer and TimesNet. Those models were tested based on the synergistic combination of weather conditions (WC), sunshine time accumulation (STA/h), instantaneous total irradiance (ITI/(W/m2)) and irradiance daily accumulation (IDA/(MJ/m2)). The model performance was rigorously evaluated with 9 prediction lengths, 5 training days, 4 seasons and 5 days for 9 weather conditions. The results showed that the Transformer model had the best overall prediction performance for STA, ITI, IDA and WC at different time steps of 10 min to 24 h. All models were suitable for predicting time series within 1 h. However, TimesNet model was not suitable for predicting time series with steps outside 1 h. On the other hand, by using the sun combination dataset, the Transformer model had the best performance at a time step of 10 min. The mean absolute error (MAE), mean-square error (MSE), root mean squared error (RMSE) and coefficient of determination (R2) of ITI were 0.118 W/m2, 0.059 W/m2, 0.243 W/m2 and 93.9 %, respectively. When exploring the minimum dataset, with the increase of data samples, the prediction effect of TimesNet showed an increasing trend. While, Transformer had the best prediction effect for the dataset with one year of use. When exploring seasonality, Pyraformer model had the best prediction effect on winter and summer, and TimesNet had the best prediction effect on autumn and spring. Local prediction of 9 climate conditions showed that the effects of snow and dust storm were not ideal. The research results showed that the characterization factors that were closely linked to irradiance. The prediction scheme proposed in this paper combined the advantages of different time steps, different factor combination datasets, different data volumes and seasonality, which greatly improves the generalization ability of the model. This study can provide a reference for irradiance prediction and more refined management of photovoltaic (PV) greenhouse.","2024-09-01","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","315","","","","","","","","","","English","","","","WOS:001306147000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Full climate conditions; greenhouse; MODEL; Multi-parameter; Refined management of photovoltaic; Solar irradiance prediction; Variable time lengths","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3NM5BXBG","journalArticle","2021","Nitski, O; Azhie, A; Qazi-Arisar, FA; Wang, XQ; Ma, SH; Lilly, L; Watt, KD; Levitsky, J; Asrani, SK; Lee, DS; Rubin, BB; Bhat, M; Wang, B","Long-term mortality risk stratification of liver transplant recipients: real-time application of deep learning algorithms on longitudinal data","LANCET DIGITAL HEALTH","","2589-7500","10.1016/S2589-7500(21)00040-6","","Background Survival of liver transplant recipients beyond 1 year since transplantation is compromised by an increased risk of cancer, cardiovascular events, infection, and graft failure. Few clinical tools are available to identify patients at risk of these complications, which would flag them for screening tests and potentially life-saving interventions. In this retrospective analysis, we aimed to assess the ability of deep learning algorithms of longitudinal data from two prospective cohorts to predict complications resulting in death after liver transplantation over multiple timeframes, compared with logistic regression models. Methods In this machine learning analysis, model development was done on a set of 42 146 liver transplant recipients (mean age 48 & middot;6 years [SD 17 & middot;3]; 17 196 [40 & middot;8%] women) from the Scientific Registry of Transplant Recipients (SRTR) in the USA. Transferability of the model was further evaluated by fine-tuning on a dataset from the University Health Network (UHN) in Canada (n=3269; mean age 52 & middot;5 years [11 & middot;1]; 1079 [33 & middot;0%] women). The primary outcome was cause of death, as recorded in the databases, due to cardiovascular causes, infection, graft failure, or cancer, within 1 year and 5 years of each follow-up examination after transplantation. We compared the performance of four deep learning models against logistic regression, assessing performance using the area under the receiver operating characteristic curve (AUROC). Findings In both datasets, deep learning models outperformed logistic regression, with the Transformer model achieving the highest AUROCs in both datasets (p<0 & middot;0001). The AUROC for the Transformer model across all outcomes in the SRTR dataset was 0 & middot;804 (99% CI 0 & middot;795-0 & middot;854) for 1-year predictions and 0 & middot;733 (0 & middot;729-0 & middot;769) for 5-year predictions. In the UHN dataset, the AUROC for the top-performing deep learning model was 0 & middot;807 (0 & middot;795-0 & middot;842) for 1-year predictions and 0 & middot;722 (0 & middot;705-0 & middot;764) for 5-year predictions. AUROCs ranged from 0 & middot;695 (0 & middot;680-0 & middot;713) for prediction of death from infection within 5 years to 0 & middot;859 (0 & middot;847-0 & middot;871) for prediction of death by graft failure within 1 year. Interpretation Deep learning algorithms can incorporate longitudinal information to continuously predict long-term outcomes after liver transplantation, outperforming logistic regression models. Physicians could use these algorithms at routine follow-up visits to identify liver transplant recipients at risk for adverse outcomes and prevent these complications by modifying management based on ranked features.","2021-05","2025-02-26 20:39:19","2025-02-26 20:39:19","","E295-E305","","5","3","","","","","","","","","","English","","","","WOS:000642286500009","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;50<br/>Total Times Cited:&nbsp;&nbsp;53<br/>Cited Reference Count:&nbsp;&nbsp;31</p>","","","DEATH; FUTURE; GRAFT FAILURE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BRFIEPLA","journalArticle","2024","Sharma, S; Kumar, A; Rathore, NS; Sharma, S","Intrusion detection and prevention systems in industrial IoT network","SADHANA-ACADEMY PROCEEDINGS IN ENGINEERING SCIENCES","","0256-2499","10.1007/s12046-024-02567-z","","The Industrial IoT system often struggles to identify malignant traffic and may cause disruption in the flow of work or even hazardous situations. The previously described techniques to identify such intrusions work well but not enough to be implemented in such environments where it is very difficult to identify malignant traffic in loads of benign ones. Hence, an intrusion detection system is needed that works well with very highly unbalanced datasets. Therefore, we developed a transformer model that gives a high accuracy and combined it with a boosting module that decreases false negatives, which is highly required. This model is applied to the UNSW-2018-IoT-Botnet dataset, which is publicly available in the cloudstor network. Thus, the classified traffic identified as malignant is eliminated from the system using prevention techniques. The paper also extends the model to classify among five different traffics for the same dataset, in which some of the traffics are very difficult to distinguish, such as DoS and DDoS traffic. The experiments on such data sets have shown much better results, which proves that the model classifies well and can be implemented practically as well.","2024-08-31","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","3","49","","","","","","","","","","English","","","","WOS:001302562300002","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","ANALYTICS; attack; DEEP LEARNING APPROACH; Deep-learning; industrial IoT; INTERNET; intrusion detection; intrusion prevention systems; THINGS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"26RGPIKD","journalArticle","2024","Jittanon, S; Mensin, Y; Ketjoy, N; Termritthikun, C","Net Metering Prediction in Prosumer Building With Temporal Fusion Transformer Models","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3438945","","The growing global demand for electrical energy, together with the significant problem of increasing carbon dioxide emissions, have become urgent issues. The inefficient use of electricity exacerbates these challenges. Smart grid technology is emerging as a solution, employing innovative approaches to solve these problems. Within this context, this research emphasizes the identification of the most effective forecasting model for demand prediction. Utilizing the Transformer-based model, Temporal Fusion Transformer (TFT), together with the Naresuan University, School of Renewable Energy and Smart Grid Technology (SGtech) net metering dataset, we explored the influence of additional features on forecasting models, categorizing them into net metering data, weather-related attributes including temperature, dew point, weather conditions, and wind direction, and supplementary features related to the operational behavior of SGtech, specifically workday and time-of-day. Our experimentation shows that integrating workday and time-of-day data alongside net metering data significantly enhances prediction precision compared to other combinations. The TFT model outperforms popular time series forecasting models, including Neural Basis Expansion Analysis for Time Series (N-BEATS) and Neural Hierarchical Interpolation for Time Series (N-HiTS), in accuracy and parameter efficiency while maintaining inference times.","2024","2025-02-26 20:39:19","2025-02-26 20:39:19","","109457-109469","","","12","","","","","","","","","","English","","","","WOS:001291883300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;30</p>","","","Deep learning; EFFICIENT; energy forecasting; MACHINE; prosumer building; sustainable development goals; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PD5LGDHZ","journalArticle","2023","Fan, X; Chang, H; Huo, LZ; Hu, CM","GF-1/6 Satellite Pixel-by-Pixel Quality Tagging Algorithm","REMOTE SENSING","","2072-4292","10.3390/rs15071955","","The Landsat and Sentinel series satellites contain their own quality tagging data products, marking the source image pixel by pixel with several specific semantic categories. These data products generally contain categories such as cloud, cloud shadow, land, water body, and snow. Due to the lack of mid-wave and thermal infrared bands, the accuracy of traditional cloud detection algorithm is unstable when facing Chinese Gaofen-1/6 (GF-1/6) data. Moreover, it is challenging to distinguish clouds from snow. In order to produce GF-1/6 satellite pixel-by-pixel quality tagging data products, this paper builds a training sample set of more than 100,000 image pairs, primarily using Sentinel-2 satellite data. Then, we adopt the Swin Transformer model with a self-attention mechanism for GF-1/6 satellite image quality tagging. Experiments show that the model's overall accuracy reaches the level of Fmask v4.6 with more than 10,000 training samples, and the model can distinguish between cloud and snow correctly. Our GF-1/6 quality tagging algorithm can meet the requirements of the ""Analysis Ready Data (ARD) Technology Research for Domestic Satellite"" project.","2023-04","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","7","15","","","","","","","","","","English","","","","WOS:000970157200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","Analysis Ready Data; cloud detection; CLOUD SHADOW DETECTION; Fmask; GF-1; Sentinel-2; Swin Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RRQ6H9S9","journalArticle","2024","Shen, LM; Deng, L; Liu, XL; Wang, YQ; Chen, XH; Liu, J","A generative adversarial network based on an efficient transformer for high-fidelity flow field reconstruction","PHYSICS OF FLUIDS","","1070-6631","10.1063/5.0215681","","The reconstruction of high-fidelity flow fields from low-fidelity data has attracted considerable attention in fluid dynamics but poses many challenges to existing deep learning methods due to the spatiotemporal complexity of flows and the lack of standardized benchmark datasets. In this study, we generate a low- and high-fidelity dataset containing 25 600 snapshots of four representative flow dynamics simulations using eight different numerical-precision and grid-resolution configurations. Using this dataset, we develop a physics-guided transformer-based generative adversarial network (PgTransGAN) for concurrently handling numerical-precision and grid-resolution enhancement. PgTransGAN leverages a dual-discriminator-based generative adversarial network for capturing continuous spatial and temporal dynamics of flows and applies a soft-constraint approach to enforce physical consistency in the reconstructed data using gradient information. An efficient transformer model is also developed to obtain the long-term temporal dependencies and further alleviate storage constraints. We compare the performance of PgTransGAN against standard linear interpolation and solutions based solely on convolutional neural networks or generative adversarial networks, and demonstrate that our method achieves better reconstruction quality at the data, image, and physics levels with an upscaling factor of 4 or even 8 in each grid dimension.","2024-07","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","7","36","","","","","","","","","","English","","","","WOS:001283011300013","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;52</p>","","","SUPERRESOLUTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3NGGRBNQ","journalArticle","2024","Lu, WZ; Qian, ML; Xia, YY; Lu, YM; Shen, JY; Fu, QM; Lu, Y","Crack _PSTU: Crack detection based on the U-Net framework combined with Swin Transformer","STRUCTURES","","2352-0124","10.1016/j.istruc.2024.106241","","Cracks serve as a significant indicator of aging infrastructure. While the surfaces of traditional infrastructures are visually inspected manually, this approach is labor-intensive, highly subjective, and often surpasses the capabilities of available inspection personnel. Although some researchers have employed traditional image processing and machine learning techniques to address these challenges, the presence of irregular crack shapes, complex lighting conditions, and limitations in detecting only a single type of surface crack complicate automatic crack detection. Recent research indicates that deep learning methods are increasingly leading in image-based feature extraction, object detection, and pixel attribute analysis. This paper introduces a method, Crack_PSTU (Pretrained Swin Transformer U-Net), which leverages the U-Net framework and Swin Transformer model for infrastructure crack classification and detection tasks. Specifically, we utilize a pre-trained Swin Transformer network as the encoder and implement the decoder using convolution, pooling, and other operations, creating a ""U""-shaped model architecture. Our experiments encompassed 11,298 crack images from varied scenes, with 9603 designated for training and 1695 for validation. The findings reveal that our approach surpasses other algorithms for this dataset.","2024-04","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","62","","","","","","","","","","English","","","","WOS:001218082000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","Crack detection; Deep learning; Swin Transformer; Transfer learning; U-Net","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SYEWEWFW","journalArticle","2024","Guan, BX; Zhu, XH; Yuan, SB","A T5-based interpretable reading comprehension model with more accurate evidence training","INFORMATION PROCESSING & MANAGEMENT","","0306-4573","10.1016/j.ipm.2023.103584","","Pre-trained language models (PLMs) have achieved outstanding performance on Machine Reading Comprehension (MRC) tasks, but these models' interpretability remains uncertain. In this paper, we exploit the strengths of the pre-trained T5 (Text-to-Text Transfer Transformer) model on evidence inference to improve the interpretability of the MRC model and propose an interpretable reading comprehension model based on T5, which is trained on a more accurate evidence corpus and can infer precise interpretations for the generated answers. First, we propose a novel T5-based Semantic Textual Similarity (STS) model to label training evidences more precisely, including label reconstruction and data augmentation. Then, we propose a T5-based interpretable reading comprehension model with more accurate evidence training, including a threshold-based method to filter out erroneous evidence during model training. Experiments show that our model significantly outperforms the baseline BERT (Pseudo-data Training) model by 8.7 and 8.0 points for the evidence F1-score of SQuAD1.1 respectively in the base and large levels. Our code is available at https://github.com/MN-Guan/T5-InterMRC.","2024-03","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","2","61","","","","","","","","","","English","","","","WOS:001123631000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;3<br/>Cited Reference Count:&nbsp;&nbsp;58</p>","","","Explainable artificial intelligence; Machine reading comprehension; Pre-trained language models; Semantic textual similarity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F5KLD86P","journalArticle","2023","Li, Y; Zeng, GP; Wang, LP; Tan, K","Accurate Stride-Length Estimation Based on LT-StrideNet for Pedestrian Dead Reckoning Using a Shank-Mounted Sensor","MICROMACHINES","","2072-666X","10.3390/mi14061170","","Pedestrian dead reckoning (PDR) is a self-contained positioning technology and has been a significant research topic in recent years. Pedestrian-stride-length estimation is the core part of the PDR system and directly affects the performance of the PDR. The current stride-length-estimation method is difficult to adapt to changes in pedestrian walking speed, which leads to a rapid increase in the error of the PDR. In this paper, a new deep-learning model based on long short-term memory (LSTM) and Transformer, LT-StrideNet, is proposed to estimate pedestrian-stride length. Next, a shank-mounted PDR framework is built based on the proposed stride-length-estimation method. In the PDR framework, the detection of pedestrian stride is achieved by peak detection with a dynamic threshold. An extended Kalman filter (EKF) model is adopted to fuse the gyroscope, accelerometer, and magnetometer. The experimental results show that the proposed stride-length-estimation method can effectively adapt to changes in pedestrian walking speed, and our PDR framework has excellent positioning performance.","2023-06","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","6","14","","","","","","","","","","English","","","","WOS:001014841600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;32</p>","","","FILTER; inertial measurement unit (IMU); Kalman filter; pedestrian dead reckoning; stride-length estimation; SYSTEM; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"42PHX7JX","journalArticle","2023","Sima, W; Zou, BY; Yang, M; Duan, P; Zhou, Y; Peng, DX; Cheng, KX; de Leon, F","Reconstructing Primary Voltages Across Inductive VTs - Part I: Methodology","IEEE TRANSACTIONS ON POWER DELIVERY","","0885-8977","10.1109/TPWRD.2022.3213666","","Inductive voltage transformers (VTs) are the most widely used instrument transformers in power grids operating at 35 kV and below. Frequently, however, during disturbances, the secondary signals are not replicas of the primary voltages because of eddy current effects, capacitive effects, and nonlinearities. In this two-part paper, a new inverse method considering the frequency-dependent characteristics and nonlinearities is proposed to reconstruct the primary voltage from a distorted secondary signal. In Part I, the framework of the method is presented and then realized with two inverse models. An inverse black-box model is used to compensate the eddy currents and capacitive effects, and an inverse duality-derived model is used to consider the nonlinearities. Methods for model parameter determination are described. Experimental validation and analysis of the proposed method are afforded in Part II. The inverse method effectively improves the primary voltage measurement of VTs without any auxiliary high-voltage equipment. The proposed method provides accurate primary voltage waveforms of VTs during disturbances.","2023-04","2025-02-26 20:39:19","2025-02-26 20:39:19","","1353-1362","","2","38","","","","","","","","","","English","","","","WOS:000965906300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;55</p>","","","ACCURATE; Biological system modeling; CIRCUIT; Duality-derived model; FERRORESONANCE; FREQUENCY-RESPONSE; IDENTIFICATION; Inverse problems; Magnetic flux; Mathematical models; Nonlinear distortion; PARAMETERS; PASSIVITY; POTENTIAL TRANSFORMER; primary voltage; saturation; transformer black-box model; TRANSFORMER MODEL; Transient analysis; Voltage measurement; VT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A5BS46XR","journalArticle","2024","Liu, Z; Xu, XD; Luo, B; Yang, CH; Gui, WH; Dubljevic, S","Accelerated MPC: A real-time model predictive control acceleration method based on TSMixer and 2D block stochastic configuration network imitative controller","CHEMICAL ENGINEERING RESEARCH & DESIGN","","0263-8762","10.1016/j.cherd.2024.07.030","","Modern industrial processes demand real-time model predictive control (MPC) method within the constraints of limited computing resources. This paper introduces an accelerated MPC method to address the issue. Specifically, we employ the time series mixing model (TSMixer) to construct a predictive model capable of accurately forecasting the behavior of the system under control. Furthermore, we extend the capabilities of TSMixer by integrating a feature classification model (TSMixer with FCM). This enhanced version takes into account both future information and static variables, resulting in superior accuracy compared to the transformer model while maintaining a significantly smaller parameter count. Finally, to further enhance MPC's responsiveness, we develop a two-dimensional block stochastic configuration network (2D-BSCN) imitative controller. This innovative network clones the behavior of rolling optimization, effectively replacing online optimization to reduce computational time. The experimental results show that the accelerated MPC has an excellent performance in numerical simulation and actual industrial processes. Notably, the algorithm achieves a smaller FLOPs and tracking time than other state-of-the-art models, well within the requirement for industrial process control.","2024-08","2025-02-26 20:39:19","2025-02-26 20:39:19","","837-852","","","208","","","","","","","","","","English","","","","WOS:001282667400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;39</p>","","","Feature classification; Imitative controller; KINETICS; Model acceleration; Stochastic configuration network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PTCDHKES","journalArticle","2024","Chen, W; Liao, Y; Dai, R; Dong, YL; Huang, LY","EEG-based emotion recognition using graph convolutional neural network with dual attention mechanism","FRONTIERS IN COMPUTATIONAL NEUROSCIENCE","","1662-5188","10.3389/fncom.2024.1416494","","EEG-based emotion recognition is becoming crucial in brain-computer interfaces (BCI). Currently, most researches focus on improving accuracy, while neglecting further research on the interpretability of models, we are committed to analyzing the impact of different brain regions and signal frequency bands on emotion generation based on graph structure. Therefore, this paper proposes a method named Dual Attention Mechanism Graph Convolutional Neural Network (DAMGCN). Specifically, we utilize graph convolutional neural networks to model the brain network as a graph to extract representative spatial features. Furthermore, we employ the self-attention mechanism of the Transformer model which allocates more electrode channel weights and signal frequency band weights to important brain regions and frequency bands. The visualization of attention mechanism clearly demonstrates the weight allocation learned by DAMGCN. During the performance evaluation of our model on the DEAP, SEED, and SEED-IV datasets, we achieved the best results on the SEED dataset, showing subject-dependent experiments' accuracy of 99.42% and subject-independent experiments' accuracy of 73.21%. The results are demonstrably superior to the accuracies of most existing models in the realm of EEG-based emotion recognition.","2024-07-19","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","18","","","","","","","","","","English","","","","WOS:001282742300001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;65</p>","","","attention mechanism; EEG; electrode channels; emotion recognition; ENTROPY; frequency bands; graph convolutional neural network; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DD6E2GD7","journalArticle","2024","Remya, S; Anjali, T; Sugumaran, V","A Novel Transfer Learning Framework for Multimodal Skin Lesion Analysis","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2024.3385340","","Skin lesion classification is a pivotal process in dermatology, enabling the early detection and precise diagnosis of skin diseases, leading to improved patient outcomes. Deep learning has shown great potential for this task by leveraging its ability to learn complex patterns from images. However, diagnostic accuracy is compromised by exclusive reliance on single-modality images. This research work proposes an innovative framework that unifies a Vision Transformer model with transfer learning, channel attention mechanism, and ROI for the accurate detection of skin conditions, including skin cancer. The proposed approach blends computer vision and machine-learning techniques, leveraging a comprehensive dataset comprised of macroscopic dermoscopic images, appended with patient metadata. Compared with conventional techniques, the proposed methodology exhibits significant improvements in various parameters, including sensitivity, specificity, and precision. Moreover, it demonstrates outstanding performance in real-world datasets, reinforcing its potential for clinical implementation. With a remarkable accuracy of 99%, the method outperforms existing approaches. Overall, this investigation underscores the transformative impact of deep learning and multimodal data analysis in the dermoscopic domain, projecting substantial headway into the field of skin lesion analytic diagnosis.","2024","2025-02-26 20:39:19","2025-02-26 20:39:19","","50738-50754","","","12","","","","","","","","","","English","","","","WOS:001204932000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;4<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","CANCER; CLASSIFICATION; DEEP; deep learning; dermatology; DISEASE; multimodal data analysis; Skin lesion classification; transfer learning; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WWPSLUQR","journalArticle","2023","Wang, SH; Huang, Z; Zhang, BJ; Heng, XR; Jiang, YY; Sun, XX","Plot-aware transformer for recommender systems","ELECTRONIC RESEARCH ARCHIVE","","2688-1594","10.3934/era.2023160","","Plot text is very valuable supporting information in movie recommendations. It has several characteristics: 1) It is rich in content. Each movie often has a document of more than 200 words to describe it, which can give the movie a rich semantic meaning. 2) Objectivity. Plot texts are different from review information. A movie may have thousands of reviews with mixed and conflicting opinions. However, a film has only one plot text, which is fair in tone and does not take a position. Despite its appealing properties and potential for accurate movie portrayal, the lack of a building block for effectively mining plot semantics has led to the marginalization of plot text in the design of movie recommendation algorithms. Therefore, in this paper, we explore the application of the Transformer, currently the best natural language processing module, to learning movie plot texts to help achieve more accurate rating prediction. We propose the ""Plot-Aware Transformer"" model (PAT) to model the process of ""user-movie"" rating interaction. We test the PAT model on several movie datasets and demonstrated that the model is competitive. In all tasks, PAT achieves state-of-the-art performance compared to baseline experiments.","2023","2025-02-26 20:39:19","2025-02-26 20:39:19","","3169-3186","","6","31","","","","","","","","","","English","","","","WOS:001048581700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","embedding representation; Plot-Aware Transformer; recommendation algorithms; semantics mining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RZY65ZEY","journalArticle","2022","Shickel, B; Silva, B; Ozrazgat-Baslanti, T; Ren, YF; Khezeli, K; Guan, ZY; Tighe, PJ; Bihorac, A; Rashidi, P","Multi-dimensional patient acuity estimation with longitudinal EHR tokenization and flexible transformer networks","FRONTIERS IN DIGITAL HEALTH","","2673-253X","10.3389/fdgth.2022.1029191","","Transformer model architectures have revolutionized the natural language processing (NLP) domain and continue to produce state-of-the-art results in text-based applications. Prior to the emergence of transformers, traditional NLP models such as recurrent and convolutional neural networks demonstrated promising utility for patient-level predictions and health forecasting from longitudinal datasets. However, to our knowledge only few studies have explored transformers for predicting clinical outcomes from electronic health record (EHR) data, and in our estimation, none have adequately derived a health-specific tokenization scheme to fully capture the heterogeneity of EHR systems. In this study, we propose a dynamic method for tokenizing both discrete and continuous patient data, and present a transformer-based classifier utilizing a joint embedding space for integrating disparate temporal patient measurements. We demonstrate the feasibility of our clinical AI framework through multi-task ICU patient acuity estimation, where we simultaneously predict six mortality and readmission outcomes. Our longitudinal EHR tokenization and transformer modeling approaches resulted in more accurate predictions compared with baseline machine learning models, which suggest opportunities for future multimodal data integrations and algorithmic support tools using clinical transformer networks.","2022-11-09","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","4","","","","","","","","","","English","","","","WOS:001046023100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;5<br/>Total Times Cited:&nbsp;&nbsp;5<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","clinical decision support; critical care; deep learning; electronic health records; patient acuity; SCORE; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CDYSRM2Z","journalArticle","2022","Dong, XF; Zhang, HX; Zhu, L; Nie, LQ; Liu, L","Hierarchical Feature Aggregation Based on Transformer for Image-Text Matching","IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY","","1051-8215","10.1109/TCSVT.2022.3164230","","In order to carry out more accurate retrieval across image-text modalities, some scholars use fine-grained feature to align image and text. Most of them directly use attention mechanism to align image regions and words in the sentence, and ignore the fact that semantics related to an object is abstract and cannot be accurately expressed by object information alone. To overcome this weakness, we propose a hierarchical feature aggregation algorithm based on graph convolutional networks (GCN) to facilitate object semantic integrity by integrating attributes of an object and relations between objects hierarchically in both image and text modalities. In order to eliminate the semantic gap between modalities, we propose a cross-modal feature fusion method based on transformer to generate modal-specific feature representations by integrating both the object feature and global feature from the other modality. Then we map the fusion feature into a common space. Experiment results on the most frequently-used datasets MSCOCO and Flickr30K show the effectiveness of the proposed model compared with the latest methods.","2022-09","2025-02-26 20:39:19","2025-02-26 20:39:19","","6437-6447","","9","32","","","","","","","","","","English","","","","WOS:000849300000058","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;32<br/>Total Times Cited:&nbsp;&nbsp;33<br/>Cited Reference Count:&nbsp;&nbsp;57</p>","","","Bit error rate; Correlation; Feature extraction; GRAPH ATTENTION; graph convolutional network; Image reconstruction; Image-text alignment; NETWORK; Semantics; transformer model; Transformers; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C37MYACS","journalArticle","2022","Ni, RZ; Chen, J; Yang, C; Li, C; Qiu, RC; Liu, ZG; Li, RX; Gao, L; Li, YW","A temperature calculation method of oil immersed transformer considering delay effects and multiple environmental factors","ELECTRIC POWER SYSTEMS RESEARCH","","0378-7796","10.1016/j.epsr.2022.108260","","In the traditional transformer temperature calculation methods, the hot spot temperature (HST) is obtained by calculating the oil temperature rise, winding temperature rise, and then adding the ambient temperature. However, there is a gap between the HST calculated by this method and the measured temperature. There are two reasons for this phenomenon, the influence of environmental factors on the internal temperature of trans-former has delay effect, and the influence of multiple environmental factors is not considered. By making cor-responding improvements in these two aspects, an improved transformer HST calculation method is proposed. By comparing the calculated temperature of the improved method with the measured temperature, it is concluded that the internal temperature of the transformer can be well fitted by the proposed method. Through the comparative analysis with the traditional method, it is found that the calculation accuracy has been greatly improved. By analyzing the working data of transformers in different regions, different seasons and different operating years, the influence of multiple environmental factors on the temperature calculation and its change trend are summarized, and the effectiveness of this method is verified.","2022-12","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","213","","","","","","","","","","English","","","","WOS:000860767400005","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;7<br/>Total Times Cited:&nbsp;&nbsp;8<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","Delay effects; Environmental factors; FUNDAMENTAL APPROACH; Hot spot temperature; HOT-SPOT TEMPERATURE; POWER TRANSFORMERS; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3KEZVMQ8","journalArticle","2024","Chen, HW; Yoshimori, A; Bajorath, J","Extension of multi-site analogue series with potent compounds using a bidirectional transformer-based chemical language model","RSC MEDICINAL CHEMISTRY","","2632-8682","10.1039/d4md00423j","","Generating potent compounds for evolving analogue series (AS) is a key challenge in medicinal chemistry. The versatility of chemical language models (CLMs) makes it possible to formulate this challenge as an off-the-beaten-path prediction task. In this work, we have devised a coding and tokenization scheme for evolving AS with multiple substitution sites (multi-site AS) and implemented a bidirectional transformer to predict new potent analogues for such series. Scientific foundations of this approach are discussed and, as a benchmark, the transformer model is compared to a recurrent neural network (RNN) for the prediction of analogues of AS with single substitution sites. Furthermore, the transformer is shown to successfully predict potent analogues with varying R-group combinations for multi-site AS having activity against many different targets. Prediction of R-group combinations for extending AS with potent compounds represents a novel approach for compound optimization. Shown is the extension of an analogue series with a new potent compound using a chemical language model. Substitution sites and non-hydrogen R-groups are colored in red (the log-likelihood score for the new analogue is reported in parentheses).","2024-07-17","2025-02-26 20:39:19","2025-02-26 20:39:19","","2527-2537","","7","15","","","","","","","","","","English","","","","WOS:001251316500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","DRUG DISCOVERY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PHTY78Z9","journalArticle","2024","Lu, K; Min, DG","AiPE: A Novel Transformer-Based Pose Estimation Method","ELECTRONICS","","2079-9292","10.3390/electronics13050967","","Human pose estimation is an important problem in computer vision because it is the foundation for many advanced semantic tasks and downstream applications. Although some convolutional neural network-based pose estimation methods have achieved good results, these networks are still limited for restricted receptive fields and weak robustness, leading to poor detection performance in scenarios with blur or low resolution. Additionally, their highly parallelized strategy is likely to cause significant computational demands, requiring high computing power. In comparison to the convolutional neural networks, the transformer-based methods offer advantages such as flexible stacking, global perspective, and parallel computation. Based on the great benefits, a novel transformer-based human pose estimation method is developed, which employees multi-head self-attention mechanisms and offset windows to effectively suppress the quick growth of the computational complexity near human keypoints. Experimental results under detailed visual comparison and quantitative analysis demonstrate that the proposed method can efficiently deal with the pose estimation problem in challenging scenarios, such as blurry or occluded scenes. Furthermore, the errors in human skeleton mapping caused by keypoint occlusion or omission can be effectively corrected, so the accuracy of pose estimation results is greatly improved.","2024-03","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","5","13","","","","","","","","","","English","","","","WOS:001182833100001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;33</p>","","","attention; computer vision; pose estimation; transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AS7PFLM7","journalArticle","2023","Wu, R; Liu, C; Han, T; Yao, JC; Jiang, DX","A planetary gearbox fault diagnosis method based on time-series imaging feature fusion and a transformer model","MEASUREMENT SCIENCE AND TECHNOLOGY","","0957-0233","10.1088/1361-6501/ac9e6c","","As a crucial component in the transmission system, a planetary gearbox has a relatively complicated structure and usually operates under complex working conditions and a severe noisy environment, making it challenging to achieve precise and efficient fault diagnosis. Along with the development of artificial intelligence techniques, end-to-end fault diagnosis frameworks have been widely studied, among which convolutional and recurrent neural networks are the mainstream backbone networks. However, these networks have shortcomings in computational efficiency and feature extraction, which lead to the application of a self-attention mechanism. This paper presents a fault diagnosis method based on frequency domain Gramian angular field (GAF) and Markov transition field (MTF) features for planetary gearboxes by combining the characteristics of vibration signal fault diagnosis and transformer network structure. The experiments show that the frequency domain GAF-MTF features can effectively reduce the influence of time shifting between samples and improve diagnostic accuracy. Furthermore, comparisons with other mainstream models indicate that the proposed method can obtain competitive results and achieve more accurate and robust performance under noisy conditions.","2023-02-01","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","2","34","","","","","","","","","","English","","","","WOS:000885933000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;16<br/>Total Times Cited:&nbsp;&nbsp;17<br/>Cited Reference Count:&nbsp;&nbsp;47</p>","","","CONVOLUTIONAL NEURAL-NETWORK; deep learning; fault diagnosis; feature fusion; INTELLIGENT DIAGNOSIS; planetary gearbox; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TW2LGI3K","journalArticle","2023","Fan, CY; Su, Q; Xiao, ZF; Su, H; Hou, AJ; Luan, B","ViT-FRD: A Vision Transformer Model for Cardiac MRI Image Segmentation Based on Feature Recombination Distillation","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3302522","","Cardiac magnetic resonance imaging analysis has been a useful tool in screening patients for heart disease. Early, timely and accurate diagnosis of diseases of the heart series is the key to effective treatment. MRI provides important material for the diagnosis of cardiac diseases. The rise of deep learning has transformed computer-aided diagnostic systems, especially in the field of medical imaging. Existing work on cardiac structure segmentation models based on MRI imaging mainly relies on convolutional neural networks (CNNs), which lack model diversity and limit the prediction performance. This paper introduces Visual Transformer with Feature Recombination and Feature Distillation(ViT-FRD), a novel learning pipeline that combines a visual transformer (ViT) and a CNN through knowledge refinement. The training procedure allows the student model, i.e., ViT, to learn from the teacher model, i.e., CNN, by optimizing distillation losses. Meanwhile, ViT-FRD provides two performance boosters to increase the efficacy and efficiency of training. The proposed method is validated on two cardiac MRI image datasets. The findings demonstrate that ViT-FRD achieves SOTA and outperforms the widely used baseline model.","2023","2025-02-26 20:39:19","2025-02-26 20:39:19","","129763-129772","","","11","","","","","","","","","","English","","","","WOS:001107311700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;9<br/>Total Times Cited:&nbsp;&nbsp;9<br/>Cited Reference Count:&nbsp;&nbsp;28</p>","","","CNN; feature distillation; feature recombination; heart segmentation; MRI; ViT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2JVNBZY3","journalArticle","2025","Shu, X; Yang, H; Liu, X; Feng, RH; Shen, JW; Hu, YZ; Chen, Z; Tang, AH","State of health estimation for lithium-ion batteries based on voltage segment and transformer","JOURNAL OF ENERGY STORAGE","","2352-152X","10.1016/j.est.2024.115200","","Machine learning techniques have been widely employed in state of health (SOH) estimation of lithium-ion batteries deployed in electric vehicles. However, due to various driving habits and complex environmental conditions, machine learning based training models are intractable to involve all the possible conditions and lead to satisfactory estimation results all the time. To solve it, an efficient SOH estimation algorithm is proposed based on tailored voltage segment and an up-to-date transformer model. First, the voltage variation is investigated during the battery charging process at different SOH. Through analyzing the variation trend of the charging voltage slope, a specific voltage segment is extracted as the health feature to characterize the SOH variation. Then, a transformer network integrating a multi-head self-attention mechanism is proposed to capture temporal information and excavate useful features, thereby achieving precise SOH estimation. The experiments demonstrate that the algorithm leads to the maximum absolute estimation errors of less than 2.00 %. Compared with state-of-the-art algorithms, the proposed method achieves optimal SOH estimation accuracy, proving its high accuracy and stability.","2025-02-01","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","108","","","","","","","","","","English","","","","WOS:001412028400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;37</p>","","","Attentional mechanisms; Charging voltage segment; lithium-ion batteries; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JR6B9F6W","journalArticle","2024","Cui, SY; Hui, B","Dual-Dependency Attention Transformer for Fine-Grained Visual Classification","SENSORS","","1424-8220","10.3390/s24072337","","Visual transformers (ViTs) are widely used in various visual tasks, such as fine-grained visual classification (FGVC). However, the self-attention mechanism, which is the core module of visual transformers, leads to quadratic computational and memory complexity. The sparse-attention and local-attention approaches currently used by most researchers are not suitable for FGVC tasks. These tasks require dense feature extraction and global dependency modeling. To address this challenge, we propose a dual-dependency attention transformer model. It decouples global token interactions into two paths. The first is a position-dependency attention pathway based on the intersection of two types of grouped attention. The second is a semantic dependency attention pathway based on dynamic central aggregation. This approach enhances the high-quality semantic modeling of discriminative cues while reducing the computational cost to linear computational complexity. In addition, we develop discriminative enhancement strategies. These strategies increase the sensitivity of high-confidence discriminative cue tracking with a knowledge-based representation approach. Experiments on three datasets, NABIRDS, CUB, and DOGS, show that the method is suitable for fine-grained image classification. It finds a balance between computational cost and performance.","2024-04","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","7","24","","","","","","","","","","English","","","","WOS:001200794700001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;76</p>","","","deep learning; fine-grained visual classification; NETWORK; vision transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PMUBY8SF","journalArticle","2024","Chen, ZW; Chen, Y; Xia, F; Cheng, TL; Huang, SX; Xiang, NW","DC Bias Content Extraction of Power Transformer Under AC and DC Environment and its Suppression Measures","IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS","","0278-0046","10.1109/TIE.2023.3303633","","The phenomenon of transformer dc bias (TDB) will saturate the transformer core, resulting in the local overheating, accelerating the ageing of insulating material, and even affecting the transformer safe operation. Therefore, it is of great significance to carry out the TDB detection and suppression. In this article, first, according to the distortion characteristics of the transformer excitation current under TDB. This article presents a method for measuring the bias voltage content of the transformer in the ac/dc environment to detect TDB. Second, the value of TDB is calculated by measuring the voltage difference before and after the dc bias, so as to obtain the degree of TDB. The feasibility of this scheme is verified by multigroup simulations of single-phase transformer (SPT) and three-phase transformer (TPT). Finally, the SPT and TPT simulated experiments of TDB are designed, and one kind of TDB suppression is carried out based on a hybrid transformer model. The experimental results are in good agreement with the simulation results, which can provide certain reference for TDB control in the dc transmission and ac/dc distribution networks.","2024-07","2025-02-26 20:39:19","2025-02-26 20:39:19","","7853-7863","","7","71","","","","","","","","","","English","","","","WOS:001076236800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;3<br/>Total Times Cited:&nbsp;&nbsp;4<br/>Cited Reference Count:&nbsp;&nbsp;21</p>","","","Bias voltage detection; dc bias; excitation current; SYSTEM; transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MDMSZSFQ","journalArticle","2023","Brauwers, G; Frasincar, F","A Survey on Aspect-Based Sentiment Classification","ACM COMPUTING SURVEYS","","0360-0300","10.1145/3503044","","With the constantly growing number of reviews and other sentiment-bearing texts on the Web, the demand for automatic sentiment analysis algorithms continues to expand. Aspect-based sentiment classification (ABSC) allows for the automatic extraction of highly fine-grained sentiment information from text documents or sentences. In this survey, the rapidly evolving state of the research on ABSC is reviewed. A novel taxonomy is proposed that categorizes the ABSC models into three major categories: knowledge-based, machine learning, and hybrid models. This taxonomy is accompanied with summarizing overviews of the reported model performances, and both technical and intuitive explanations of the various ABSC models. State-of-theart ABSC models are discussed, such as models based on the transformer model, and hybrid deep learning models that incorporate knowledge bases. Additionally, various techniques for representing the model inputs and evaluating the model outputs are reviewed. Furthermore, trends in the research on ABSC are identified and a discussion is provided on the ways in which the field of ABSC can be advanced in the future.","2023-05","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","4","55","","","","","","","","","","English","","","","WOS:000890647400001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;68<br/>Total Times Cited:&nbsp;&nbsp;70<br/>Cited Reference Count:&nbsp;&nbsp;233</p>","","","Aspect-based sentiment classification; attention models; deep learning; EMBEDDINGS; hybrid models; KNOWLEDGE; knowledge-based models; LSTM; MACHINE; NEURAL-NETWORK; PRINCIPLES; REPRESENTATIONS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U73GFKRT","journalArticle","2023","Shehzad, K; Zhenhua, T; Shoukat, S; Saeed, A; Ahmad, I; Bhatti, SS; Chelloug, SA","A Deep-Ensemble-Learning-Based Approach for Skin Cancer Diagnosis","ELECTRONICS","","2079-9292","10.3390/electronics12061342","","Skin cancer is one of the widespread diseases among existing cancer types. More importantly, the detection of lesions in early diagnosis has tremendously attracted researchers ' attention. Thus, artificial intelligence (AI)-based techniques have supported the early diagnosis of skin cancer by investigating deep-learning-based convolutional neural networks (CNN). However, the current methods remain challenging in detecting melanoma in dermoscopic images. Therefore, in this paper, we propose an ensemble model that uses the vision of both EfficientNetV2S and Swin-Transformer models to detect the early focal zone of skin cancer. Hence, we considerthat the former architecture leads to greater accuracy, while the latter model has the advantage of recognizing dark parts in an image. We have modified the fifth block of the EfficientNetV2S model and have included the Swin-Transformer model. Our experiments demonstrate that the constructed ensemble model has attained a higher level of accuracy over the individual models and has also decreased the losses as compared to traditional strategies. The proposed model achieved an accuracy score of 99.10%, a sensitivity of 99.27%, and a specificity score of 99.80%.","2023-03","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","6","12","","","","","","","","","","English","","","","WOS:000958140600001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;20<br/>Total Times Cited:&nbsp;&nbsp;20<br/>Cited Reference Count:&nbsp;&nbsp;38</p>","","","deep ensemble learning; dermoscopy; EfficientNetV2S; ensemble model; skin cancer; Swin-Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XSEVNTSQ","journalArticle","2021","Wen, W; Liu, YB; Ouyang, CP; Lin, Q; Chung, T","Enhanced prototypical network for few-shot relation extraction","INFORMATION PROCESSING & MANAGEMENT","","0306-4573","10.1016/j.ipm.2021.102596","","Most existing methods for relation extraction tasks depend heavily on large-scale annotated data; they cannot learn from existing knowledge and have low generalization ability. It is urgent for us to solve the above problems by further developing few-shot learning methods. Because of the limitations of the most commonly used CNN model which is not good at sequence labeling and capturing long-range dependencies, we proposed a novel model that integrates the transformer model into a prototypical network for more powerful relation-level feature extraction. The transformer connects tokens directly to adapt to long sequence learning without catastrophic forgetting and is able to gain more enhanced semantic information by learning from several representation subspaces in parallel for each word. We evaluate our method on three tasks, including in-domain, cross-domain and cross-sentence tasks. Our method achieves a trade-off between performance and computation and has an approximately 8% improvement in different settings over the state-of-the-art prototypical network. In addition, our experiments also show that our approach is competitive when considering cross-domain transfer and cross-sentence relation extraction in few-shot learning methods.","2021-07","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","4","58","","","","","","","","","","English","","","","WOS:000658372100035","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;31<br/>Total Times Cited:&nbsp;&nbsp;33<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Few-shot learning; Relation extraction; Transformer","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JAX4WLS4","journalArticle","2025","Younas, W; Chen, R; Zhao, J; Iqbal, T; Sharaf, M; Imran, A","SPERT: Reinforcement Learning-Enhanced Transformer Model for Agile Story Point Estimation","INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING","","0218-1940","10.1142/S0218194025500044","","Story point estimation is a key practice in Agile project management that assigns effort values to user stories, helping teams manage workloads effectively. Inaccurate story point estimation can lead to project delays, resource misallocation and budget overruns. This study introduces Story Point Estimation using Reinforced Transformers (SPERT), a novel model that integrates transformer-based embeddings with reinforcement learning (RL) to improve the accuracy of story point estimation. SPERT utilizes Bidirectional Encoder Representations from Transformers (BERT) embeddings, which capture the deep semantic relationships within user stories, while the RL component refines predictions dynamically based on project feedback. We evaluate SPERT across multiple Agile projects and benchmark its performance against state-of-the-art models, including SBERT-XG, LHC-SE, Deep-SE and TF-IDF-SE. Results demonstrate that SPERT outperforms these models in terms of Mean Absolute Error (MAE), Median Absolute Error (MdAE) and Standardized Accuracy (SA). Statistical analysis using Wilcoxon tests and A12 effect size confirms the significance of SPERT's performance, highlighting its ability to generalize across diverse projects and improve estimation accuracy in Agile environments.","2025-02-06","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","","","","","","","","","","","","English","","","","WOS:001414295500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;51</p>","","","Agile project management; BERT; machine learning; RL; SOFTWARE EFFORT ESTIMATION; story point estimation; transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CBKTYMS3","journalArticle","2023","Dong, CX; Feng, XL; Wang, YC; Wei, X","Spatiotemporal Exogenous Variables Enhanced Model for Traffic Flow Prediction","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2023.3311818","","Traffic flow prediction is a vital component of Intelligent Transportation Systems (ITS). However, it is extremely challenging to predict traffic flow accurately for a large-scale road network over multiple time horizons, due to the complex and dynamic spatiotemporal dependencies involved. To address this issue, we propose a Spatiotemporal Exogenous Variables Enhanced Transformer (SEE-Transformer) model, which leverages the Graph Attention Networks and Transformer architectures and incorporates the exogenous variables of traffic data. Specifically, we introduce rich exogenous variables, including spatial and temporal information of traffic data, to enhance the model's ability to capture spatiotemporal dependencies at a network level. We construct traffic graphs based on the social connection of sensors and the traffic pattern similarity of sensors and use them as model inputs along with the exogenous variables. The SEE-Transformer achieves excellent prediction accuracy with the help of the Graph Attention Networks and Transformer mechanisms. Extensive experiments on the PeMS freeway dataset confirm that the SEE-Transformer consistently outperforms current models.","2023","2025-02-26 20:39:19","2025-02-26 20:39:19","","95958-95973","","","11","","","","","","","","","","English","","","","WOS:001081615500001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;56</p>","","","Data models; DEEP; exogenous variables; graph attention networks; Hidden Markov models; KALMAN FILTER; LEARNING ALGORITHM; Predictive models; Roads; spatiotemporal dependencies; Spatiotemporal phenomena; Traffic control; Traffic flow prediction; transformer; Transformers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZSSGN37T","journalArticle","2025","Wu, ML; Zhang, J; Xu, PD; Liang, YJ; Dai, YX; Gao, TL; Bai, YY","Bearing Fault Diagnosis for Cross-Condition Scenarios Under Data Scarcity Based on Transformer Transfer Learning Network","ELECTRONICS","","2079-9292","10.3390/electronics14030515","","Motor-bearing fault diagnosis is critical for industrial equipment reliability, yet traditional data-driven methods require extensive labeled data, which are often scarce in real-world applications. To address this challenge, we propose a Transformer transfer learning network (TTLN) for accurate fault diagnosis under cross-condition scenarios, particularly when target domain data are limited. First, we develop a Transformer-based fault diagnosis model that captures long-range dependencies in sequential data through self-attention, achieving high accuracy under single operating conditions. Second, we introduce the TTLN framework, which integrates domain adaptation to align marginal and conditional distributions, enabling robust cross-condition fault diagnosis with minimal target domain samples. Finally, we validated the proposed method on the CWRU and PU datasets, demonstrating the TTLN's superior performance in data-scarce scenarios. For example, the TTLN achieved over 95% accuracy with only 100 target samples, outperforming traditional methods and fine-tuning-based approaches. The results underscore the TTLN's effectiveness in cross-condition fault diagnosis, offering a practical solution for industrial applications with limited labeled data.","2025-02","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","3","14","","","","","","","","","","English","","","","WOS:001418550000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;46</p>","","","AUTOENCODER; bearing fault diagnosis; domain adaptation; multiple operating conditions; transfer learning; Transformer model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LC8J7PRH","journalArticle","2025","Yan, YL; Zhan, YW; He, HY","Adaptive Fusion and Edge-Oriented Enhancement for Brain Tumor Segmentation With Missing Modalities","INTERNATIONAL JOURNAL OF IMAGING SYSTEMS AND TECHNOLOGY","","0899-9457","10.1002/ima.70012","","Magnetic resonance imaging (MRI) offers comprehensive information about brain structures, enabling excellent performance in brain tumor segmentation using multimodal MRI in many methods. Nonetheless, missing modalities are common in clinical practice, which can significantly degrade segmentation performance. Current brain tumor segmentation methods often struggle to maintain feature consistency and robustness in multimodal feature fusion when modalities are missing and face difficulties in accurately capturing tumor boundaries. In this study, we propose an adaptive fusion and edge-oriented enhancement method to address these challenges. Our approach introduces learnable parameters and a masked attention mechanism in the transformer model to achieve cross-modal adaptive fusion, ensuring consistent feature representation even with missing data. To aggregate more information, we integrate multimodal and multi-level features through a hierarchical context integration module. Additionally, to tackle the complex morphology of brain tumor regions, we design an edge-enhanced deformable convolution module that captures deformation information and edge features from incomplete multimodal images, enabling precise tumor localization. Evaluations on the widely recognized BRATS2018 and BRATS2020 datasets demonstrate that our approach significantly surpasses existing brain tumor segmentation techniques in scenarios with missing modalities.","2025-01","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","1","35","","","","","","","","","","English","","","","WOS:001391809200001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;43</p>","","","brain tumor segmentation; COMPLETION; cross-modal adaptive fusion; edge-oriented enhancement; missing modalities; NETWORK","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WZZBTL2M","journalArticle","2024","Li, D; Zhu, BQ; Xu, KL; Yang, S; Feng, DW; Liu, B; Wang, HM","Enhanced Cross-Modal Transformer Model for Video Semantic Similarity Measurement","IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS II-EXPRESS BRIEFS","","1549-7747","10.1109/TCSII.2023.3302801","","Video processing is critical to many industrial systems. Semantic similarity measures for videos aim to evaluate the semantic distance of videos, and its downstream applications seem obvious, such as deduplication, related matching, ranking and content diversity control. Despite sustainable efforts, many previous approaches require large-scale human annotation for the training purpose, which can be difficult to obtain in practical settings. Moreover, previous methods struggle to characterize the interactions between multiple modalities, which severely constraints the performance. To address aforementioned challenges, in this brief, we introduce a novel framework to measure the semantic similarity of the video. Specifically, to address the limited annotated datasets, we firstly propose a pre-training paradigm leveraging weakly-supervised label classification. Moreover, our approach proposes an Enhanced Cross-modal Transformer (ECT) block, to fully utilize the interaction information between video and textural features. Various optimization strategies have also been proposed to improve the performance of the model. Despite its conceptually simpleness, extensive experiments demonstrate the effectiveness of the proposed approach on the semantic similarity measurement tasks.","2024-01","2025-02-26 20:39:19","2025-02-26 20:39:19","","475-479","","1","71","","","","","","","","","","English","","","","WOS:001141870700027","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;0<br/>Total Times Cited:&nbsp;&nbsp;0<br/>Cited Reference Count:&nbsp;&nbsp;15</p>","","","Encoding; Integrated circuit modeling; Multi-modal learning; Semantics; Task analysis; Training; transformer; Transformers; video representation learning; video semantic similarity; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T82IZNAG","journalArticle","2023","Zhang, YZ; Wang, TY; You, Y; Wang, DC; Zhang, DY; Lv, YC; Lu, MY; Zhang, XS","YOLO-Sp: A Novel Transformer-Based Deep Learning Model for Achnatherum splendens Detection","AGRICULTURE-BASEL","","2077-0472","10.3390/agriculture13061197","","The growth of Achnatherum splendens (A. splendens) inhibits the growth of dominant grassland herbaceous species, resulting in a loss of grassland biomass and a worsening of the grassland ecological environment. Therefore, it is crucial to identify the dynamic development of A. splendens adequately. This study intended to offer a transformer-based A. splendens detection model named YOLO-Sp through ground-based visible spectrum proximal sensing images. YOLO-Sp achieved 98.4% and 95.4% AP values in object detection and image segmentation for A. splendens, respectively, outperforming previous SOTA algorithms. The research indicated that Transformer had great potential for monitoring A. splendens. Under identical training settings, the AP value of YOLO-Sp was greater by more than 5% than that of YOLOv5. The model's average accuracy was 98.6% in trials conducted at genuine test sites. The experiment revealed that factors such as the amount of light, the degree of grass growth, and the camera resolution would affect the detection accuracy. This study could contribute to the monitoring and assessing grass plant biomass in grasslands.","2023-06","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","6","13","","","","","","","","","","English","","","","WOS:001016852800001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;1<br/>Total Times Cited:&nbsp;&nbsp;1<br/>Cited Reference Count:&nbsp;&nbsp;45</p>","","","Achnatherum splendens; CHINA; deep learning; DYNAMICS; GRASSLAND; grassland environment; image segmentation; transformer model; VEGETATION; WATER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NKRL5FZY","journalArticle","2023","Kchaou, S; Boujelbane, R; Hadrich, L","Hybrid Pipeline for Building Arabic Tunisian Dialect-standard Arabic Neural Machine Translation Model from Scratch","ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING","","2375-4699","10.1145/3568674","","Deep Learning is one of the most promising technologies compared to other methods in the context of machine translation. It has been proven to achieve impressive results on large amounts of parallel data for well-endowed languages. Nevertheless, for low-resource languages such as the Arabic Dialects, Deep Learning models failed due to the lack of available parallel corpora. In this article, we present a method to create a parallel corpus to build an effective NMT model able to translate into MSA, Tunisian Dialect texts present in social networks. For this, we propose a set of data augmentation methods aiming to increase the size of the state-of-the-art parallel corpus. By evaluating the impact of this step, we noticed that it has effectively boosted both the size and the quality of the corpus. Then, using the resulted corpus, we compare the effectiveness of CNN, RNN and transformers models to translate Tunisian Dialect into MSA. Experiments show that a better translation is achieved by the transformer model with a BLEU score of 60 vs., respectively, 33.36 and 53.98 with RNN and CNN models.","2023-03","2025-02-26 20:39:19","2025-02-26 20:39:19","","","","3","22","","","","","","","","","","English","","","","WOS:000998922200023","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;2<br/>Total Times Cited:&nbsp;&nbsp;2<br/>Cited Reference Count:&nbsp;&nbsp;34</p>","","","Arabic Tunisian Dialect; data augmentation; Modern Standard Arabic; Neural Machine Translation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FZH27AMN","journalArticle","2021","Zhang, Y; Wang, L; Wang, XQ; Zhang, CY; Ge, JM; Tang, J; Su, A; Duan, HL","Data augmentation and transfer learning strategies for reaction prediction in low chemical data regimes","ORGANIC CHEMISTRY FRONTIERS","","2052-4129","10.1039/d0qo01636e","","Effective and rapid deep learning method to predict chemical reactions contributes to the research and development of organic chemistry and drug discovery. Despite the outstanding capability of deep learning in retrosynthesis and forward synthesis, predictions based on small chemical datasets generally result in a low accuracy due to an insufficiency of reaction examples. Here, we introduce a new state-of-the-art method, which integrates transfer learning with the transformer model to predict the outcomes of the Baeyer-Villiger reaction which is a representative small dataset reaction. The results demonstrate that introducing a transfer learning strategy markedly improves the top-1 accuracy of the transformer-transfer learning model (81.8%) over that of the transformer-baseline model (58.4%). Moreover, we further introduce data augmentation to the input reaction SMILES, which allows for a better performance and improves the accuracy of the transformer-transfer learning model (86.7%). In summary, both transfer learning and data augmentation methods significantly improve the predictive performance of transformer models, which are powerful methods used in the field of chemistry to eliminate the restriction of limited training data.","2021-04-07","2025-02-26 20:39:20","2025-02-26 20:39:20","","","","7","8","","","","","","","","","","English","","","","WOS:000637156200003","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;34<br/>Total Times Cited:&nbsp;&nbsp;37<br/>Cited Reference Count:&nbsp;&nbsp;40</p>","","","COMPUTER; DESIGN; LANGUAGE; MODEL; MOLECULAR TRANSFORMER; NEURAL-NETWORKS; OUTCOMES; RETROSYNTHESIS; SMILES; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JLS6G8RQ","journalArticle","2021","Thara, S; Poornachandran, P","Transformer Based Language Identification for Malayalam-English Code-Mixed Text","IEEE ACCESS","","2169-3536","10.1109/ACCESS.2021.3104106","","Social media users have the proclivity to write majority of the data for under resourced languages in code-mixed format. Code-mixing is defined as mixing of two or more languages in a single sentence. Research in code-mixed text helps apprehend security threats, prevalent on social media platforms. In such instances, language identification is an imperative task of code-mixed text. The focus of this paper is to carry out a word-level language identification (WLLI) of Malayalam-English code-mixed data, from social media platforms like YouTube. This study was centered around BERT, a transformer model, along with its variants - CamemBERT, DistilBERT - for intuitive perception of the language at the word-level. The propounded approach entails tagging Malayalam-English code-mixed data set with six labels: Malayalam (mal), English (eng), acronyms (acr), universal (univ), mixed (mix) and undefined (undef). Newly developed corpus of Malayalam-English was deployed for appraisal of the effectiveness of state-of-the-art models like BERT. Evaluation of the proffered approach, accomplished with other code-mixed language such as Hindi-English, notched a 9% increase in the F1-score.","2021","2025-02-26 20:39:20","2025-02-26 20:39:20","","118837-118850","","","9","","","","","","","","","","English","","","","WOS:000692179000001","","","","<p>Times Cited in Web of Science Core Collection:&nbsp;&nbsp;13<br/>Total Times Cited:&nbsp;&nbsp;13<br/>Cited Reference Count:&nbsp;&nbsp;60</p>","","","bidirectional encoder representations from transformers (BERT); code-mixed; corpus preparation; deep learning; EXTRACTION; language identification; Natural language processing; text mining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""