{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88a63f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library \n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import zlib\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# third-party libraries\n",
    "from typing import List \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "from spacy.tokens import Doc, Token\n",
    "import nltk\n",
    "from tqdm.notebook import tqdm\n",
    "from natsort import natsorted\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# local module\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from project_config import from_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd477f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp resources\n",
    "# nltk corpora\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "# spacy model \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "STOP_WORDS = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e28480e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PITT_DEMENTIA_PATH = from_root(\"Pitt\", \"Dementia\", \"cookie\")\n",
    "PITT_CONTROL_PATH = from_root(\"Pitt\", \"Control\", \"cookie\")\n",
    "ADRESS_TRAIN_CD_PATH = from_root(\"ADReSS-IS2020-data\", \"train\", \"transcription\", \"cd\")\n",
    "ADRESS_TRAIN_CC_PATH = from_root(\"ADReSS-IS2020-data\", \"train\", \"transcription\", \"cc\")\n",
    "ADRESS_TEST_PATH = from_root(\"ADReSS-IS2020-data\", \"test\", \"transcription\")\n",
    "\n",
    "OUT_DATA_DIR = from_root(\"data\")\n",
    "\n",
    "SAVE_PATHS = {\n",
    "    \"adress_train\": from_root(\"data\", \"adress_train.tsv\"),\n",
    "    \"adress_test\": from_root(\"data\", \"adress_test.tsv\"),\n",
    "    \"pitt_control\": from_root(\"data\", \"pitt_control.tsv\"),\n",
    "    \"pitt_ad\": from_root(\"data\", \"pitt_ad.tsv\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3142d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebfb01e709234d74bd49210bf1e1d99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scanning cookie:   0%|          | 0/306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665bc5f1397542708431d288325eef9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scanning cookie:   0%|          | 0/243 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 educated guess age entries (AD)\n",
      "Found 60 educated guess age entries (Control)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# NOTE:\n",
    "# The following code is used to collect the age of the patients from the \n",
    "# transcripts. The age is collected from the @ID line in the transcript files \n",
    "# where the age is in the format of \"XX;00.\"\n",
    "# This step is inteded for reporting and analysis purposes only, thus you can \n",
    "# skip this step. \n",
    "# =============================================================================\n",
    "def collect_exact_educated_guesses(base_dir: str) -> pd.DataFrame:\n",
    "    results = []\n",
    "    cha_files = []\n",
    "    for root, _, files in os.walk(base_dir):\n",
    "        cha_files.extend([\n",
    "            os.path.join(root, file)\n",
    "            for file in files if file.endswith(\".cha\")\n",
    "        ])\n",
    "\n",
    "    for file_path in tqdm(cha_files, desc=f\"Scanning {os.path.basename(base_dir)}\"):\n",
    "        file_id = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    if line.startswith(\"@ID\") and \"|PAR|\" in line:\n",
    "                        parts = line.strip().split(\"|\")\n",
    "                        if len(parts) > 4:\n",
    "                            raw_age = parts[3].strip()\n",
    "                            if re.fullmatch(r\"\\d{2};00\\.\", raw_age):\n",
    "                                results.append({\n",
    "                                    \"ID\": file_id,\n",
    "                                    \"raw_age\": raw_age\n",
    "                                })\n",
    "                        break  # only need to inspect one @ID line\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def save_sorted_educated_guesses(df: pd.DataFrame, out_path: str, label: str) -> None:\n",
    "    df = df.set_index(\"ID\")\n",
    "    df = df.loc[natsorted(df.index)].reset_index()\n",
    "    df.to_csv(out_path, sep=\"\\t\", index=False)\n",
    "    print(f\"Found {len(df)} educated guess age entries ({label})\")\n",
    "\n",
    "df_ad = collect_exact_educated_guesses(PITT_DEMENTIA_PATH)\n",
    "df_control = collect_exact_educated_guesses(PITT_CONTROL_PATH)\n",
    "\n",
    "save_sorted_educated_guesses(\n",
    "    df_ad,\n",
    "    os.path.join(OUT_DATA_DIR, \"pitt_educated_guess_ages_ad.tsv\"),\n",
    "    label=\"AD\"\n",
    ")\n",
    "\n",
    "save_sorted_educated_guesses(\n",
    "    df_control,\n",
    "    os.path.join(OUT_DATA_DIR, \"pitt_educated_guess_ages_control.tsv\"),\n",
    "    label=\"Control\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae01f8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fdc9440401e458d90474a7f7d3dd458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing ADReSS-train:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77fa31c1b864cdd8c305d5460fc7e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing ADReSS-train:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a167b4b15fd443748cbad28f9fc06a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing ADReSS-train:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18a555299864c90949760485fa3825d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing ADReSS-train:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f186366f993f4d2b816645bd086ee512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing ADReSS-test:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da056f60184d4f39903d394430def555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing ADReSS-test:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cde9c31aca645bf9ace211fe3b73e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Pitt-Control:   0%|          | 0/243 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1909e4d12d8469e921a4793f4103570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Pitt-Dementia:   0%|          | 0/306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c4c0cf4f4848cb97abd2e77edbbbac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Pitt-Control:   0%|          | 0/243 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea69b75c84d645e4b8cb38a7aaaa22fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Pitt-Dementia:   0%|          | 0/306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Title: ADReSS Challenge Analysis Notebook\n",
    "# Author: Thomas Searle\n",
    "# Date: 2020\n",
    "# Code version: N/A (not versioned)\n",
    "# Type: Source code (Jupyter Notebook)\n",
    "# Availability: https://github.com/tomolopolis/ADReSS_Challenge/blob/master/Analysis.ipynb\n",
    "# Note: The following code was inspired by the above source.\n",
    "# =============================================================================\n",
    "\n",
    "def clean_cha_line(text: str, roberta: bool = False) -> str:\n",
    "    # remove timestamps (e.g., \u001500000432_00000550\u0015)\n",
    "    text = re.sub(r'\u0015.*?\u0015', '', text)\n",
    "    # remove annotations like [//], [*], etc.\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    # remove non-verbal info in parentheses\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "    if roberta:\n",
    "        # remove all non-alphanumeric characters except whitespace\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    else:\n",
    "        # remove all non-alphanumeric characters but keep punctuation like ., !, ?\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s\\.\\!\\?]', '', text)\n",
    "    # normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "            \n",
    "    return text\n",
    "\n",
    "def remove_duplicate_words(text: str) -> str:\n",
    "    # used code from: https://stackoverflow.com/questions/17238587/python-regular-expression-to-remove-repeated-words\n",
    "    # remove consecutive duplicate words (e.g., \"the the\", \"from from\")\n",
    "    cleaned_text = re.sub(r'\\b(\\w+)(?:\\s+\\1\\b)+', r'\\1', text, flags=re.IGNORECASE)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def extract_transcript_only(\n",
    "    file_path: str, \n",
    "    label: int | None = None, \n",
    "    dataset: str | None = None,\n",
    "    remove_duplicates: bool = False\n",
    ") -> dict:\n",
    "    file_name = os.path.basename(file_path)\n",
    "    file_id = file_name.split(\".cha\")[0]\n",
    "\n",
    "    record = {\"ID\": file_id, \"dataset\": dataset, \"label\": label}\n",
    "    transcript = []\n",
    "    disfluency_count = 0\n",
    "    pause_count = 0\n",
    "    utterance_count = 0\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "        i = 0\n",
    "        while i < len(lines):\n",
    "            line = lines[i].strip()\n",
    "\n",
    "            # extract metadata\n",
    "            if line.startswith(\"@ID\"):\n",
    "                parts = line.split(\"|\")\n",
    "                if len(parts) > 4 and parts[2].strip() == \"PAR\":\n",
    "                    if parts[4].strip():\n",
    "                        record[\"gender\"] = parts[4].strip()[0]\n",
    "                    else:\n",
    "                        record[\"gender\"] = None\n",
    "                    raw_age = parts[3].strip()\n",
    "                    try:\n",
    "                        if raw_age:\n",
    "                            # extract digits before semicolon\n",
    "                            fixed_age = int(raw_age.split(\";\")[0])\n",
    "                            record[\"age\"] = fixed_age\n",
    "                    except:\n",
    "                        record[\"age\"] = None\n",
    "                    try:\n",
    "                        if len(parts) > 8 and parts[8].strip():\n",
    "                            # print(\"MMSE score found:\", parts[8].strip())\n",
    "                            record[\"mmse\"] = float(parts[8].strip())\n",
    "                    except:\n",
    "                        record[\"mmse\"] = None\n",
    "\n",
    "            # participant lines\n",
    "            if line.startswith(\"*PAR:\"):\n",
    "                utterance_count += 1\n",
    "                raw_text = line.split(\":\", 1)[1].strip()\n",
    "\n",
    "                #  if participant has more than one line of text continue reading\n",
    "                i += 1\n",
    "                while i < len(lines):\n",
    "                    next_line = lines[i].strip()\n",
    "                    if next_line.startswith(\"*\") or next_line.startswith(\"@\") or next_line.startswith(\"%\"):\n",
    "                        break  # not a continuation\n",
    "                    raw_text += \" \" + next_line\n",
    "                    i += 1\n",
    "                #  count disfluency and pause features \n",
    "                for tag in [\"[//]\", \"[/]\", \"[/-]\", \"[*]\", \"[+...\", \"+//.\", \"[+\"]:\n",
    "                    disfluency_count += raw_text.count(tag)\n",
    "                pause_count += len(re.findall(r\"\\(\\.\\)\", raw_text))           # short pause\n",
    "                pause_count += len(re.findall(r\"\\(\\.\\.\\)\", raw_text))         # medium pause\n",
    "                pause_count += len(re.findall(r\"\\(\\.\\.\\.\\)\", raw_text))       # long pause\n",
    "                pause_count += len(re.findall(r\"\\(\\d+\\.\\d+\\)\", raw_text))     # timed pause\n",
    "\n",
    "                cleaned_text = clean_cha_line(raw_text, roberta=remove_duplicates)\n",
    "                if remove_duplicates: # for RoBERTa models\n",
    "                    cleaned_text = remove_duplicate_words(cleaned_text)\n",
    "                transcript.append(cleaned_text)\n",
    "\n",
    "                continue \n",
    "            i += 1\n",
    "\n",
    "    full_text = \" \".join(transcript)\n",
    "    record[\"transcription\"] = full_text\n",
    "    record[\"disfluencies\"] = disfluency_count\n",
    "    record[\"pause_count\"] = pause_count\n",
    "    record[\"utterance_count\"] = utterance_count\n",
    "    return record\n",
    "\n",
    "\n",
    "def collect_data_from_directory(\n",
    "    base_dir: str, \n",
    "    label: int | None, \n",
    "    dataset_tag: str,\n",
    "    remove_duplicates: bool = False\n",
    ") -> list[dict]:\n",
    "    all_records = []\n",
    "    cha_files = []\n",
    "    for root, _, files in os.walk(base_dir):\n",
    "        cha_files.extend([\n",
    "            os.path.join(root, file)\n",
    "            for file in files if file.endswith(\".cha\")\n",
    "        ])\n",
    "\n",
    "    for file_path in tqdm(cha_files, desc=f\"Processing {dataset_tag}\"):\n",
    "        try:\n",
    "            data = extract_transcript_only(file_path, label=label, dataset=dataset_tag, remove_duplicates=remove_duplicates)\n",
    "            all_records.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "    return all_records\n",
    "\n",
    "\n",
    "# ADReSS datasets (RF = keep duplicates, RoBERTa = remove them)\n",
    "adress_train_cd = collect_data_from_directory(ADRESS_TRAIN_CD_PATH, 1, \"ADReSS-train\", remove_duplicates=False)\n",
    "adress_train_cc = collect_data_from_directory(ADRESS_TRAIN_CC_PATH, 0, \"ADReSS-train\", remove_duplicates=False)\n",
    "adress_train_cd_roberta = collect_data_from_directory(ADRESS_TRAIN_CD_PATH, 1, \"ADReSS-train\", remove_duplicates=True)\n",
    "adress_train_cc_roberta = collect_data_from_directory(ADRESS_TRAIN_CC_PATH, 0, \"ADReSS-train\", remove_duplicates=True)\n",
    "\n",
    "adress_test_rf = collect_data_from_directory(ADRESS_TEST_PATH, None, \"ADReSS-test\", remove_duplicates=False)\n",
    "adress_test_roberta = collect_data_from_directory(ADRESS_TEST_PATH, None, \"ADReSS-test\", remove_duplicates=True)\n",
    "\n",
    "# Pitt datasets (do the same)\n",
    "pitt_control_rf = collect_data_from_directory(PITT_CONTROL_PATH, 0, \"Pitt-Control\", remove_duplicates=False)\n",
    "pitt_dementia_rf = collect_data_from_directory(PITT_DEMENTIA_PATH, 1, \"Pitt-Dementia\", remove_duplicates=False)\n",
    "pitt_control_roberta = collect_data_from_directory(PITT_CONTROL_PATH, 0, \"Pitt-Control\", remove_duplicates=True)\n",
    "pitt_dementia_roberta = collect_data_from_directory(PITT_DEMENTIA_PATH, 1, \"Pitt-Dementia\", remove_duplicates=True)\n",
    "\n",
    "# combine and save datasets\n",
    "df_adress_train_rf = pd.DataFrame(adress_train_cd + adress_train_cc)\n",
    "df_adress_train_roberta = pd.DataFrame(adress_train_cd_roberta + adress_train_cc_roberta)\n",
    "\n",
    "df_adress_test = pd.DataFrame(adress_test_rf)\n",
    "df_adress_test_roberta = pd.DataFrame(adress_test_roberta)\n",
    "\n",
    "df_pitt_control = pd.DataFrame(pitt_control_rf)\n",
    "df_pitt_control_roberta = pd.DataFrame(pitt_control_roberta)\n",
    "\n",
    "df_pitt_ad = pd.DataFrame(pitt_dementia_rf)\n",
    "df_pitt_ad_roberta = pd.DataFrame(pitt_dementia_roberta)\n",
    "\n",
    "#  for RF\n",
    "df_adress_train_rf.to_csv(SAVE_PATHS[\"adress_train\"], sep=\"\\t\", index=False)\n",
    "df_adress_test.to_csv(SAVE_PATHS[\"adress_test\"], sep=\"\\t\", index=False)\n",
    "df_pitt_control.to_csv(SAVE_PATHS[\"pitt_control\"], sep=\"\\t\", index=False)\n",
    "df_pitt_ad.to_csv(SAVE_PATHS[\"pitt_ad\"], sep=\"\\t\", index=False)\n",
    "\n",
    "# for RoBERTa -> drop duplicates and the features (only needs raw text)\n",
    "df_adress_train_roberta.drop(columns=[\"disfluencies\", \"pause_count\", \"utterance_count\"], errors=\"ignore\")\\\n",
    "    .to_csv(from_root(\"data\", \"adress_train_roberta.tsv\"), sep=\"\\t\", index=False)\n",
    "\n",
    "df_adress_test_roberta.drop(columns=[\"disfluencies\", \"pause_count\", \"utterance_count\"], errors=\"ignore\")\\\n",
    "    .to_csv(from_root(\"data\", \"adress_test_roberta.tsv\"), sep=\"\\t\", index=False)\n",
    "\n",
    "df_pitt_control_roberta.drop(columns=[\"disfluencies\", \"pause_count\", \"utterance_count\"], errors=\"ignore\")\\\n",
    "    .to_csv(from_root(\"data\", \"pitt_control_roberta.tsv\"), sep=\"\\t\", index=False)\n",
    "\n",
    "df_pitt_ad_roberta.drop(columns=[\"disfluencies\", \"pause_count\", \"utterance_count\"], errors=\"ignore\")\\\n",
    "    .to_csv(from_root(\"data\", \"pitt_ad_roberta.tsv\"), sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "88c4f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NOTE:\n",
    "# The files `manual_age_fix_pitt_ad.tsv` and `manual_age_fix_pitt_control.tsv`\n",
    "# were manually created based on the demographic spreadsheet available from \n",
    "# the Pitt Corpus (TalkBank). These files contain corrected age values for \n",
    "# participants where the transcript data was missing.\n",
    "#\n",
    "# These files are not required to run the pipeline. You may skip this cell\n",
    "# if you do not have these files or prefer not to apply manual age corrections.\n",
    "# =============================================================================\n",
    "\n",
    "MANUAL_AGE_AD_PATH = from_root(\"data\", \"raw\", \"manual_age_fix_pitt_ad.tsv\")\n",
    "MANUAL_AGE_CONTROL_PATH = from_root(\"data\", \"raw\", \"manual_age_fix_pitt_control.tsv\")\n",
    "PITT_AD_SAVE_PATH = from_root(\"data\", \"pitt_ad.tsv\")\n",
    "PITT_CONTROL_SAVE_PATH = from_root(\"data\", \"pitt_control.tsv\")\n",
    "\n",
    "\n",
    "def apply_manual_age_fix(\n",
    "    df: pd.DataFrame, \n",
    "    manual_path: str, \n",
    "    save_path: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Changes age values in df with manually corrected ones from official spreadsheet.\n",
    "    \"\"\"\n",
    "    manual_ages = pd.read_csv(manual_path, sep=\"\\t\")\n",
    "    df = df.merge(manual_ages, on=\"ID\", how=\"left\", suffixes=(\"\", \"_manual\"))\n",
    "    df.loc[df[\"age_manual\"].notna(), \"age\"] = df[\"age_manual\"]\n",
    "    df.drop(columns=\"age_manual\", inplace=True)\n",
    "    df.to_csv(save_path, sep=\"\\t\", index=False)\n",
    "    return df\n",
    "\n",
    "df_pitt_ad = apply_manual_age_fix(df_pitt_ad, MANUAL_AGE_AD_PATH, PITT_AD_SAVE_PATH)\n",
    "df_pitt_control = apply_manual_age_fix(df_pitt_control, MANUAL_AGE_CONTROL_PATH, PITT_CONTROL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6c79fc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IU_KEYWORDS = [\"cookie\", \"girl\", \"boy\", \"mother\", \"chair\", \"jar\", \"sink\", \"kitchen\",\n",
    "               \"water\", \"hand\", \"cupboard\", \"stool\", \"plate\", \"overflowing\"]\n",
    "\n",
    "FIRST_PERSON_PRONOUNS = {\"i\", \"me\", \"my\", \"mine\", \"we\", \"us\", \"our\", \"ours\"}\n",
    "THIRD_PERSON_PRONOUNS = {\"he\", \"him\", \"his\", \"she\", \"her\", \"hers\", \"they\", \"them\", \"their\", \"theirs\"}\n",
    "\n",
    "\n",
    "def type_token_ratio(tokens : List[str]) -> float:\n",
    "    # calculates the ratio of unique words to total words (lexical diversity)\n",
    "    types = set(tokens)\n",
    "    if tokens: \n",
    "        return len(types) / len(tokens)\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "\n",
    "def honore_statistic(tokens : List[str]) -> float:\n",
    "    # calculates lexical richness, giving more weight to words appearing once\n",
    "    N = len(tokens)\n",
    "    V = len(set(tokens))\n",
    "    if V == 0:\n",
    "        return 0\n",
    "    V1 = 0 # count of unique words (only appear once)\n",
    "    word_counts = Counter(tokens)\n",
    "    for word, freq in word_counts.items():\n",
    "        if freq == 1:\n",
    "            V1 += 1\n",
    "    if V > 0 and V1 < V:\n",
    "        return 100 * math.log(N) / (1 - V1 / V)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def idea_density(tokens : List[str]) -> float:\n",
    "    # estimates the density of content words (nouns, verbs, adjectives, adverbs)\n",
    "    # how much info is packed into the text -> proportion of content words to total tokens\n",
    "    content_pos = {\"NOUN\", \"VERB\", \"ADJ\", \"ADV\"}\n",
    "    if not tokens:\n",
    "        return 0\n",
    "    doc = nlp(\" \".join(tokens))\n",
    "    count = 0\n",
    "    for token in doc:\n",
    "        if token.pos_ in content_pos:\n",
    "            count += 1\n",
    "    return count/len(tokens)\n",
    "\n",
    "\n",
    "def compression_ratio(text : str) -> float:\n",
    "    # measures text complexity by calculating the ratio of compressed to uncompressed text size\n",
    "    raw = text.encode(\"utf-8\")\n",
    "    compressed = zlib.compress(raw)\n",
    "    return len(compressed) / len(raw) if raw else 0\n",
    "\n",
    "\n",
    "def count_iu_keywords(tokens : List[str]) -> int:\n",
    "    # counts the number of IU keywords in the text\n",
    "    count = 0\n",
    "    for token in tokens:\n",
    "        if token.lower() in IU_KEYWORDS:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def moving_average_ttr(tokens: List[str], window_size: int = 50) -> float:\n",
    "    # MATTR Calculation (Moving-Average TTR)\n",
    "    if len(tokens) < window_size:\n",
    "        return len(set(tokens)) / len(tokens) if tokens else 0\n",
    "    ttr_values = []\n",
    "    for i in range(len(tokens) - window_size + 1):\n",
    "        window = tokens[i:i + window_size]\n",
    "        ttr_values.append(len(set(window)) / window_size)\n",
    "    return np.mean(ttr_values)\n",
    "\n",
    "\n",
    "def count_cfg_rules(doc : Doc) -> Counter:\n",
    "    # count CFG Production Rules\n",
    "    production_counter = Counter()\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            rule = f\"{token.pos_} -> {' '.join(child.pos_ for child in token.children)}\"\n",
    "            production_counter[rule] += 1\n",
    "    return production_counter\n",
    "\n",
    "\n",
    "def compute_repetition_score(sentences: List[str]) -> float:\n",
    "    # measure Repetition via Cosine Distance\n",
    "    if len(sentences) < 2:\n",
    "        return 0\n",
    "    vectorizer = CountVectorizer().fit(sentences)\n",
    "    vectors = vectorizer.transform(sentences).toarray()\n",
    "    similarities = []\n",
    "    for i in range(len(vectors)):\n",
    "        for j in range(i+1, len(vectors)):\n",
    "            norm_i = np.linalg.norm(vectors[i])\n",
    "            norm_j = np.linalg.norm(vectors[j])\n",
    "            if norm_i != 0 and norm_j != 0:\n",
    "                sim = np.dot(vectors[i], vectors[j]) / (norm_i * norm_j)\n",
    "                similarities.append(sim)\n",
    "    if similarities:\n",
    "        return np.mean(similarities)\n",
    "    return 0\n",
    "\n",
    "\n",
    "def brunet_index(tokens: List[str]) -> float:\n",
    "    # Brunet Index -> measures lexical richness\n",
    "    n = len(tokens)\n",
    "    v = len(set(tokens))\n",
    "    if n > 0:\n",
    "        return n ** (v ** -0.165)\n",
    "    return 0\n",
    "\n",
    "\n",
    "def named_entity_count(doc : Doc) -> int:\n",
    "    entity_count = 0\n",
    "    for ent in doc.ents: \n",
    "        entity_count += 1\n",
    "    return entity_count\n",
    "\n",
    "\n",
    "def noun_verb_ratio(noun_ratio: float, verb_ratio: float) -> float:\n",
    "    if verb_ratio != 0:\n",
    "        return noun_ratio / verb_ratio\n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_tree_depth(token : Token) -> int:\n",
    "    children = list(token.children)\n",
    "    if not children:\n",
    "        return 1\n",
    "    depths = []\n",
    "    for child in children:\n",
    "        depths.append(get_tree_depth(child))\n",
    "    return 1 + max(depths) \n",
    "\n",
    "\n",
    "def extract_linguistic_features(row : pd.Series) -> pd.Series:\n",
    "    text = row[\"transcription\"]\n",
    "    doc = nlp(text)\n",
    "    tokens = []\n",
    "    # lemmatized tokens (for all lexical metrics, e.g., running, ran, run -> run)\n",
    "    for token in doc:\n",
    "        if token.is_alpha:\n",
    "            tokens.append(token.lemma_.lower())\n",
    "    \n",
    "    mattr_value = moving_average_ttr(tokens)\n",
    "    cfg_counter = count_cfg_rules(doc)\n",
    "    repetition_score = compute_repetition_score([sent.text for sent in doc.sents])\n",
    "    brunet = brunet_index(tokens)\n",
    "    named_ents = named_entity_count(doc)\n",
    "\n",
    "    # POS tagging -> tags like grammatical roles (noun, verb, etc.) \n",
    "    pos_counts = Counter()\n",
    "    for token in doc:\n",
    "        pos_counts[token.pos_] += 1\n",
    "\n",
    "    num_words = len(tokens)  \n",
    "    sents = list(doc.sents) # sentence segmentation\n",
    "    num_sents = len(sents) # num of sentences\n",
    "    num_cius = count_iu_keywords(tokens) \n",
    "\n",
    "    # prononun counts\n",
    "    first_pron_count = 0\n",
    "    third_pron_count = 0 \n",
    "    stopword_count = 0\n",
    "    for t in tokens:\n",
    "        if t in FIRST_PERSON_PRONOUNS:\n",
    "            first_pron_count += 1\n",
    "        if t in THIRD_PERSON_PRONOUNS:\n",
    "            third_pron_count += 1\n",
    "        if t in STOP_WORDS:\n",
    "            stopword_count += 1\n",
    "    \n",
    "    # POS ratios\n",
    "    pronoun_ratio = pos_counts.get(\"PRON\", 0) / num_words if num_words else 0\n",
    "    first_person_ratio = first_pron_count / num_words if num_words else 0\n",
    "    third_person_ratio = third_pron_count / num_words if num_words else 0\n",
    "    stopword_ratio = stopword_count / num_words if num_words else 0\n",
    "    noun_ratio = pos_counts.get(\"NOUN\", 0) / num_words if num_words else 0\n",
    "    verb_ratio = pos_counts.get(\"VERB\", 0) / num_words if num_words else 0\n",
    "    prep_ratio = pos_counts.get(\"ADP\", 0) / num_words if num_words else 0\n",
    "    adv_ratio = pos_counts.get(\"ADV\", 0) / num_words if num_words else 0\n",
    "    auxiliary_ratio = pos_counts.get(\"AUX\", 0) / num_words if num_words else 0\n",
    "\n",
    "    noun_verb = noun_verb_ratio(noun_ratio, verb_ratio)\n",
    "    mean_sentence_length = num_words / num_sents if num_sents else 0\n",
    "\n",
    "    # parse tree depth\n",
    "    sentence_tree_depths = []\n",
    "    for sent in sents:\n",
    "        sentence_tree_depths.append(get_tree_depth(sent.root))\n",
    "    parse_tree_depth = max(sentence_tree_depths) if sentence_tree_depths else 0\n",
    "\n",
    "    # clause count\n",
    "    clause_labels = {\"ccomp\", \"advcl\", \"relcl\"}\n",
    "    clause_count = 0\n",
    "    for token in doc:\n",
    "        if token.dep_ in clause_labels:\n",
    "            clause_count += 1\n",
    "    clauses_per_sentence = clause_count / num_sents if num_sents else 0\n",
    "    \n",
    "    # content density --> proportion of content words (nouns, verbs, adjectives, adverbs) to total tokens\n",
    "    content_density_sum = 0\n",
    "    for tag in [\"NOUN\", \"VERB\", \"ADJ\", \"ADV\"]:\n",
    "        content_density_sum += pos_counts.get(tag, 0)\n",
    "    content_density = content_density_sum / num_words if num_words else 0\n",
    "\n",
    "    features = {\n",
    "        \"word_count\": num_words,\n",
    "        \"unique_words\": len(set(tokens)),\n",
    "        \"type_token_ratio\": type_token_ratio(tokens),\n",
    "        \"honore_statistic\": honore_statistic(tokens),\n",
    "        \"idea_density\": idea_density(tokens),\n",
    "        \"compression_ratio\": compression_ratio(text),\n",
    "        \"content_density\": content_density,\n",
    "        \"pronoun_ratio\": pronoun_ratio,\n",
    "        \"first_person_ratio\": first_person_ratio,\n",
    "        \"third_person_ratio\": third_person_ratio,\n",
    "        \"stopword_ratio\": stopword_ratio,\n",
    "        \"noun_ratio\": noun_ratio,\n",
    "        \"verb_ratio\": verb_ratio,\n",
    "        \"prep_ratio\": prep_ratio,\n",
    "        \"adv_ratio\": adv_ratio,\n",
    "        \"auxiliary_ratio\": auxiliary_ratio,\n",
    "        \"mean_sentence_length\": mean_sentence_length,\n",
    "        \"num_sentences\": num_sents,\n",
    "        \"IU_count\": num_cius,\n",
    "        \"IU_density\": num_cius / num_words if num_words else 0,\n",
    "        \"parse_tree_depth\": parse_tree_depth,\n",
    "        \"clauses_per_sentence\": clauses_per_sentence,\n",
    "        \"disfluency_count\": row.get(\"disfluencies\", 0),\n",
    "        \"pause_count\": row.get(\"pause_count\", 0),\n",
    "        \"utterance_count\": row.get(\"utterance_count\", 0),\n",
    "        \"mattr\": mattr_value,\n",
    "        \"repetition_score\": repetition_score,\n",
    "        \"cfg_np_to_nn\": cfg_counter.get(\"NOUN -> NOUN\", 0),\n",
    "        \"cfg_np_to_det_noun\": cfg_counter.get(\"NOUN -> DET NOUN\", 0),\n",
    "        \"brunet_index\": brunet,\n",
    "        \"named_entity_count\": named_ents,\n",
    "        \"noun_verb_ratio\": noun_verb,\n",
    "    }\n",
    "    return pd.Series(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5459c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: Adress Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f578f00aa34f5daab6970ae99acf54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: Adress Test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2718354d0e41b7b6e26cf4322ddf89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: Pitt Control\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab39e0bdd8fc4e82befa15092b7ee787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/243 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: Pitt Ad\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "263252250f86452bbfc20665233d2f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "INPUT_FILES = {\n",
    "    \"adress_train\": from_root(\"data\", \"adress_train.tsv\"),\n",
    "    \"adress_test\": from_root(\"data\", \"adress_test.tsv\"),\n",
    "    \"pitt_control\": from_root(\"data\", \"pitt_control.tsv\"),\n",
    "    \"pitt_ad\": from_root(\"data\", \"pitt_ad.tsv\"),\n",
    "}\n",
    "\n",
    "def process_and_save(input_path: str, output_path: str) -> None:\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Input file not found: {input_path}\")\n",
    "        return \n",
    "    \n",
    "    df = pd.read_csv(input_path, sep=\"\\t\")\n",
    "    features_df = df.progress_apply(extract_linguistic_features, axis=1)\n",
    "    metadata_cols = [\"ID\", \"label\", \"gender\", \"age\"]\n",
    "    available_cols = []\n",
    "    for col in metadata_cols: \n",
    "        if col in df.columns: \n",
    "            available_cols.append(col)\n",
    "\n",
    "    final_df = pd.concat([df[available_cols], features_df], axis=1)\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)  \n",
    "    final_df.to_csv(output_path, sep=\"\\t\", index=False)\n",
    "\n",
    "\n",
    "for name, input_path in INPUT_FILES.items():\n",
    "    print(f\"Processing dataset: {name.replace('_', ' ').title()}\")\n",
    "    filename = os.path.basename(input_path).replace(\".tsv\", \"_features.tsv\")\n",
    "    output_path = from_root(\"data\", \"features\", filename)\n",
    "    process_and_save(input_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b280ea",
   "metadata": {},
   "source": [
    "**The part below is for the thesis paper not needed for the pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8db9192e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['label', 'age', 'word_count', 'unique_words', 'type_token_ratio', 'honore_statistic', 'idea_density', 'compression_ratio', 'content_density', 'pronoun_ratio', 'first_person_ratio', 'third_person_ratio', 'stopword_ratio', 'noun_ratio', 'verb_ratio', 'prep_ratio', 'adv_ratio', 'auxiliary_ratio', 'mean_sentence_length', 'num_sentences', 'IU_count', 'IU_density', 'parse_tree_depth', 'clauses_per_sentence', 'disfluency_count', 'pause_count', 'utterance_count', 'mattr', 'repetition_score', 'cfg_np_to_nn', 'cfg_np_to_det_noun', 'brunet_index', 'named_entity_count', 'noun_verb_ratio']\n",
      "      IU_density                     type_token_ratio                      \\\n",
      "            mean       std    median             mean       std    median   \n",
      "label                                                                       \n",
      "0       0.119730  0.035808  0.115074         0.586401  0.099737  0.574342   \n",
      "1       0.097872  0.051844  0.092515         0.572017  0.118254  0.580323   \n",
      "\n",
      "      repetition_score                     brunet_index                       \n",
      "                  mean       std    median         mean       std     median  \n",
      "label                                                                         \n",
      "0             0.132664  0.061413  0.127692    10.591629  1.237124  10.527332  \n",
      "1             0.110213  0.047741  0.103745    10.513043  1.727979  10.332960  \n",
      "IU_density t-test: t=-2.549, p=0.0124\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(from_root(\"data\", \"features\", \"adress_train_features.tsv\"), sep=\"\\t\")\n",
    "\n",
    "numeric_cols = df.select_dtypes(include='number').columns\n",
    "df_numeric = df[numeric_cols]\n",
    "\n",
    "print(\"Numeric columns:\", df_numeric.columns.tolist())\n",
    "\n",
    "group_stats = df_numeric.groupby(\"label\").agg([\"mean\", \"std\", \"median\"])\n",
    "print(group_stats[[\"IU_density\", \"type_token_ratio\", \"repetition_score\", \"brunet_index\"]])\n",
    "\n",
    "ad = df[df[\"label\"] == 1][\"IU_density\"]\n",
    "control = df[df[\"label\"] == 0][\"IU_density\"]\n",
    "\n",
    "t_stat, p = ttest_ind(ad, control, equal_var=False)\n",
    "print(f\"IU_density t-test: t={t_stat:.3f}, p={p:.4f}\")\n",
    "\n",
    "sns.boxplot(data=df, x=\"label\", y=\"IU_density\")\n",
    "plt.xticks([0, 1], [\"Control\", \"AD\"])\n",
    "plt.title(\"IU Density by Diagnosis Group\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c289127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label                   1.000000\n",
      "adv_ratio               0.403065\n",
      "pronoun_ratio           0.285975\n",
      "disfluency_count        0.209101\n",
      "pause_count             0.193129\n",
      "first_person_ratio      0.174741\n",
      "compression_ratio       0.131539\n",
      "third_person_ratio      0.126588\n",
      "stopword_ratio          0.123894\n",
      "noun_verb_ratio         0.066652\n",
      "age                     0.031347\n",
      "num_sentences           0.017286\n",
      "utterance_count         0.014554\n",
      "cfg_np_to_nn           -0.024427\n",
      "brunet_index           -0.026384\n",
      "clauses_per_sentence   -0.033364\n",
      "named_entity_count     -0.050365\n",
      "type_token_ratio       -0.066221\n",
      "word_count             -0.066332\n",
      "idea_density           -0.073763\n",
      "content_density        -0.093702\n",
      "cfg_np_to_det_noun     -0.123508\n",
      "verb_ratio             -0.152289\n",
      "mean_sentence_length   -0.153531\n",
      "parse_tree_depth       -0.161076\n",
      "mattr                  -0.161750\n",
      "noun_ratio             -0.190855\n",
      "repetition_score       -0.201769\n",
      "unique_words           -0.204298\n",
      "IU_density             -0.240346\n",
      "honore_statistic       -0.254715\n",
      "prep_ratio             -0.262625\n",
      "auxiliary_ratio        -0.303027\n",
      "IU_count               -0.362233\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "correlations = df.corr(numeric_only=True)[\"label\"].sort_values(ascending=False)\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c5da53ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 feature  control_mean      ad_mean    t_stat   p_value\n",
      "14             adv_ratio      0.025123     0.046332  4.534454  0.000019\n",
      "18              IU_count     12.759259     8.907407 -4.001145  0.000117\n",
      "15       auxiliary_ratio      0.085455     0.064970 -3.273782  0.001453\n",
      "7          pronoun_ratio      0.114284     0.142251  3.072618  0.002726\n",
      "13            prep_ratio      0.090165     0.074676 -2.802253  0.006057\n",
      "3       honore_statistic   1670.128886  1408.417423 -2.711896  0.007811\n",
      "19            IU_density      0.119730     0.097872 -2.549234  0.012411\n",
      "22      disfluency_count      7.166667    11.314815  2.201495  0.031176\n",
      "1           unique_words     62.870370    53.962963 -2.148692  0.033959\n",
      "26      repetition_score      0.132664     0.110213 -2.120957  0.036400\n",
      "23           pause_count      0.888889     1.537037  2.026533  0.045921\n",
      "11            noun_ratio      0.215161     0.192652 -2.001769  0.048416\n",
      "8     first_person_ratio      0.018105     0.024560  1.827179  0.070737\n",
      "25                 mattr      0.695366     0.676466 -1.687545  0.094619\n",
      "20      parse_tree_depth      6.907407     6.351852 -1.680324  0.095934\n",
      "16  mean_sentence_length      8.314779     7.592087 -1.599669  0.112655\n",
      "12            verb_ratio      0.153125     0.142147 -1.586420  0.115626\n",
      "5      compression_ratio      0.519453     0.536111  1.366148  0.175127\n",
      "9     third_person_ratio      0.041553     0.050131  1.313874  0.191978\n",
      "10        stopword_ratio      0.533188     0.550065  1.285467  0.201931\n",
      "28    cfg_np_to_det_noun      1.037037     0.814815 -1.281404  0.202860\n",
      "6        content_density      0.426669     0.417106 -0.968979  0.335179\n",
      "4           idea_density      0.430242     0.422962 -0.761516  0.448347\n",
      "31       noun_verb_ratio      1.507784     1.672992  0.687749  0.494093\n",
      "0             word_count    114.796296   106.444444 -0.684435  0.495305\n",
      "2       type_token_ratio      0.586401     0.572017 -0.683288  0.495958\n",
      "30    named_entity_count      0.981481     0.870370 -0.519199  0.604705\n",
      "21  clauses_per_sentence      0.322332     0.306306 -0.343695  0.731786\n",
      "29          brunet_index     10.591629    10.513043 -0.271734  0.786410\n",
      "27          cfg_np_to_nn      0.425926     0.388889 -0.251562  0.801942\n",
      "17         num_sentences     13.925926    14.203704  0.177992  0.859170\n",
      "24       utterance_count     13.703704    13.925926  0.149863  0.881238\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(from_root(\"data\", \"features\", \"adress_train_features.tsv\"), sep=\"\\t\")\n",
    "numeric_cols = df.select_dtypes(include='number').columns.drop(['label', 'age'], errors='ignore')\n",
    "# print(\"Numeric columns:\", numeric_cols.tolist())\n",
    "results = []\n",
    "\n",
    "# comparing AD (1) w/ Control (0) for each feature -> linguistic features section thesis\n",
    "for col in numeric_cols:\n",
    "    ad_vals = df[df[\"label\"] == 1][col].dropna()\n",
    "    ctrl_vals = df[df[\"label\"] == 0][col].dropna()\n",
    "\n",
    "    ad_mean = ad_vals.mean()\n",
    "    ctrl_mean = ctrl_vals.mean()\n",
    "    ad_std = ad_vals.std()\n",
    "    ctrl_std = ctrl_vals.std()\n",
    "    t_stat, p_val = ttest_ind(ad_vals, ctrl_vals, equal_var=False)\n",
    "\n",
    "    results.append({\n",
    "        \"feature\": col,\n",
    "        \"control_mean\": ctrl_mean,\n",
    "        \"ad_mean\": ad_mean,\n",
    "        \"t_stat\": t_stat,\n",
    "        \"p_value\": p_val\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df[\"abs_t\"] = results_df[\"t_stat\"].abs()\n",
    "results_df = results_df.sort_values(by=\"p_value\")\n",
    "print(results_df[[\"feature\", \"control_mean\", \"ad_mean\", \"t_stat\", \"p_value\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fed1d44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    306\n",
      "0    243\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# pitt datasets\n",
    "df_control = pd.read_csv(from_root(\"data\", \"features\", \"pitt_control_features.tsv\"), sep=\"\\t\")\n",
    "df_ad = pd.read_csv(from_root(\"data\", \"features\", \"pitt_ad_features.tsv\"), sep=\"\\t\")\n",
    "df_pitt = pd.concat([df_control, df_ad], ignore_index=True)\n",
    "\n",
    "print(df_pitt['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "19215f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 feature  control_mean      ad_mean    t_stat       p_value\n",
      "14             adv_ratio      0.023847     0.037851  6.977150  8.980402e-12\n",
      "15       auxiliary_ratio      0.083060     0.065735 -6.807358  2.704571e-11\n",
      "18              IU_count     12.362140     9.875817 -6.037921  2.948502e-09\n",
      "7          pronoun_ratio      0.112584     0.133003  5.973073  4.209458e-09\n",
      "22      disfluency_count      6.345679     8.836601  4.590215  5.647545e-06\n",
      "9     third_person_ratio      0.042586     0.053615  4.558027  6.380172e-06\n",
      "19            IU_density      0.117550     0.102398 -4.223311  2.822976e-05\n",
      "11            noun_ratio      0.216061     0.200704 -3.905788  1.056692e-04\n",
      "3       honore_statistic   1588.196763  1449.526707 -3.746415  1.992373e-04\n",
      "23           pause_count      1.078189     1.575163  3.545974  4.249589e-04\n",
      "4           idea_density      0.432278     0.420411 -3.229214  1.315988e-03\n",
      "10        stopword_ratio      0.539112     0.553587  3.089106  2.110140e-03\n",
      "6        content_density      0.426761     0.415511 -3.000909  2.814519e-03\n",
      "1           unique_words     62.736626    57.179739 -2.904732  3.835751e-03\n",
      "12            verb_ratio      0.152885     0.145775 -2.671900  7.777583e-03\n",
      "20      parse_tree_depth      7.004115     6.598039 -2.581097  1.014569e-02\n",
      "13            prep_ratio      0.092419     0.085910 -2.549816  1.105250e-02\n",
      "26      repetition_score      0.140969     0.128124 -2.205211  2.788272e-02\n",
      "16  mean_sentence_length      8.723032     8.299003 -2.008661  4.509665e-02\n",
      "5      compression_ratio      0.520018     0.529513  1.910333  5.661377e-02\n",
      "21  clauses_per_sentence      0.359674     0.325753 -1.733521  8.357755e-02\n",
      "25                 mattr      0.689598     0.681920 -1.531281  1.262793e-01\n",
      "27          cfg_np_to_nn      0.288066     0.372549  1.466247  1.431894e-01\n",
      "0             word_count    115.102881   108.078431 -1.351212  1.772197e-01\n",
      "8     first_person_ratio      0.017710     0.019357  1.166978  2.437279e-01\n",
      "2       type_token_ratio      0.582427     0.573924 -1.011063  3.124389e-01\n",
      "30    named_entity_count      1.094650     0.996732 -0.823118  4.108499e-01\n",
      "28    cfg_np_to_det_noun      1.069959     1.000000 -0.776840  4.376157e-01\n",
      "24       utterance_count     13.115226    12.816993 -0.577087  5.641206e-01\n",
      "17         num_sentences     13.440329    13.232026 -0.380218  7.039319e-01\n",
      "29          brunet_index     10.597519    10.564447 -0.296989  7.665878e-01\n",
      "31       noun_verb_ratio      1.492900     1.502918  0.170022  8.650608e-01\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = df_pitt.select_dtypes(include='number').columns.drop(['label', 'age'], errors='ignore')\n",
    "\n",
    "results = []\n",
    "\n",
    "for col in numeric_cols:\n",
    "    ad_vals = df_pitt[df_pitt[\"label\"] == 1][col].dropna()\n",
    "    ctrl_vals = df_pitt[df_pitt[\"label\"] == 0][col].dropna()\n",
    "\n",
    "    ad_mean = ad_vals.mean()\n",
    "    ctrl_mean = ctrl_vals.mean()\n",
    "    t_stat, p_val = ttest_ind(ad_vals, ctrl_vals, equal_var=False)\n",
    "\n",
    "    results.append({\n",
    "        \"feature\": col,\n",
    "        \"control_mean\": ctrl_mean,\n",
    "        \"ad_mean\": ad_mean,\n",
    "        \"t_stat\": t_stat,\n",
    "        \"p_value\": p_val\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df[\"abs_t\"] = results_df[\"t_stat\"].abs()\n",
    "results_df = results_df.sort_values(by=\"p_value\")\n",
    "print(results_df[[\"feature\", \"control_mean\", \"ad_mean\", \"t_stat\", \"p_value\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
